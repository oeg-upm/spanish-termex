{
    "id": "H-26",
    "original_text": "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT Machine learning is commonly used to improve ranked retrieval systems. Due to computational difficulties, few learning techniques have been developed to directly optimize for mean average precision (MAP), despite its widespread use in evaluating such systems. Existing approaches optimizing MAP either do not find a globally optimal solution, or are computationally expensive. In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of MAP. We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora (WT10g), comparing against SVMs optimized for accuracy and ROCArea. In most cases we show our method to produce statistically significant improvements in MAP scores. Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval Models General Terms Algorithm, Theory, Experimentation 1. INTRODUCTION State of the art information retrieval systems commonly use machine learning techniques to learn ranking functions. However, most current approaches do not optimize for the evaluation measure most often used, namely Mean Average Precision (MAP). Instead, current algorithms tend to take one of two general approaches. The first approach is to learn a model that estimates the probability of a document being relevant given a query (e.g., [18, 14]). If solved effectively, the ranking with best MAP performance can easily be derived from the probabilities of relevance. However, achieving high MAP only requires finding a good ordering of the documents. As a result, finding good probabilities requires solving a more difficult problem than necessary, likely requiring more training data to achieve the same MAP performance. The second common approach is to learn a function that maximizes a surrogate measure. Performance measures optimized include accuracy [17, 15], ROCArea [1, 5, 10, 11, 13, 21] or modifications of ROCArea [4], and NDCG [2, 3]. Learning a model to optimize for such measures might result in suboptimal MAP performance. In fact, although some previous systems have obtained good MAP performance, it is known that neither achieving optimal accuracy nor ROCArea can guarantee optimal MAP performance[7]. In this paper, we present a general approach for learning ranking functions that maximize MAP performance. Specifically, we present an SVM algorithm that globally optimizes a hinge-loss relaxation of MAP. This approach simplifies the process of obtaining ranking functions with high MAP performance by avoiding additional intermediate steps and heuristics. The new algorithm also makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for accuracy and ROCArea. In contrast to recent work directly optimizing for MAP performance by Metzler & Croft [16] and Caruana et al. [6], our technique is computationally efficient while finding a globally optimal solution. Like [6, 16], our method learns a linear model, but is much more efficient in practice and, unlike [16], can handle many thousands of features. We now describe the algorithm in detail and provide proof of correctness. Following this, we provide an analysis of running time. We finish with empirical results from experiments on the TREC 9 and TREC 10 Web Track corpus. We have also developed a software package implementing our algorithm that is available for public use1 . 2. THE LEARNING PROBLEM Following the standard machine learning setup, our goal is to learn a function h : X → Y between an input space X (all possible queries) and output space Y (rankings over a corpus). In order to quantify the quality of a prediction, ˆy = h(x), we will consider a loss function ∆ : Y × Y → . ∆(y, ˆy) quantifies the penalty for making prediction ˆy if the correct output is y. The loss function allows us to incorporate specific performance measures, which we will exploit 1 http://svmrank.yisongyue.com for optimizing MAP. We restrict ourselves to the supervised learning scenario, where input/output pairs (x, y) are available for training and are assumed to come from some fixed distribution P(x, y). The goal is to find a function h such that the risk (i.e., expected loss), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), is minimized. Of course, P(x, y) is unknown. But given a finite set of training pairs, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, the performance of h on S can be measured by the empirical risk, R∆ S (h) = 1 n nX i=1 ∆(yi, h(xi)). In the case of learning a ranked retrieval function, X denotes a space of queries, and Y the space of (possibly weak) rankings over some corpus of documents C = {d1, . . . ,d|C|}. We can define average precision loss as ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), where rank(y) is a vector of the rank values of each document in C. For example, for a corpus of two documents, {d1, d2}, with d1 having higher rank than d2, rank(y ) = (1, 0). We assume true rankings have two rank values, where relevant documents have rank value 1 and non-relevant documents rank value 0. We further assume that all predicted rankings are complete rankings (no ties). Let p = rank(y) and ˆp = rank(ˆy). The average precision score is defined as MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, where rel = |{i : pi = 1}| is the number of relevant documents, and Prec@j is the percentage of relevant documents in the top j documents in predicted ranking ˆy. MAP is the mean of the average precision scores of a group of queries. 2.1 MAP vs ROCArea Most learning algorithms optimize for accuracy or ROCArea. While optimizing for these measures might achieve good MAP performance, we use two simple examples to show it can also be suboptimal in terms of MAP. ROCArea assigns equal penalty to each misordering of a relevant/non-relevant pair. In contrast, MAP assigns greater penalties to misorderings higher up in the predicted ranking. Using our notation, ROCArea can be defined as ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], where p is the true (weak) ranking, ˆp is the predicted ranking, and 1[b] is the indicator function conditioned on b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Table 1: Toy Example and Models Suppose we have a hypothesis space with only two hypothesis functions, h1 and h2, as shown in Table 1. These two hypotheses predict a ranking for query x over a corpus of eight documents. Hypothesis MAP ROCArea h1(x) 0.59 0.47 h2(x) 0.51 0.53 Table 2: Performance of Toy Models Table 2 shows the MAP and ROCArea scores of h1 and h2. Here, a learning method which optimizes for ROCArea would choose h2 since that results in a higher ROCArea score, but this yields a suboptimal MAP score. 2.2 MAP vs Accuracy Using a very similar example, we now demonstrate how optimizing for accuracy might result in suboptimal MAP. Models which optimize for accuracy are not directly concerned with the ranking. Instead, they learn a threshold such that documents scoring higher than the threshold can be classified as relevant and documents scoring lower as nonrelevant. Doc ID 1 2 3 4 5 6 7 8 9 10 11 p 1 0 0 0 0 1 1 1 1 0 0 rank(h1(x)) 11 10 9 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 9 10 11 Table 3: Toy Example and Models We consider again a hypothesis space with two hypotheses. Table 3 shows the predictions of the two hypotheses on a single query x. Hypothesis MAP Best Acc. h1(q) 0.70 0.64 h2(q) 0.64 0.73 Table 4: Performance of Toy Models Table 4 shows the MAP and best accuracy scores of h1(q) and h2(q). The best accuracy refers to the highest achievable accuracy on that ranking when considering all possible thresholds. For instance, with h1(q), a threshold between documents 1 and 2 gives 4 errors (documents 6-9 incorrectly classified as non-relevant), yielding an accuracy of 0.64. Similarly, with h2(q), a threshold between documents 5 and 6 gives 3 errors (documents 10-11 incorrectly classified as relevant, and document 1 as non-relevant), yielding an accuracy of 0.73. A learning method which optimizes for accuracy would choose h2 since that results in a higher accuracy score, but this yields a suboptimal MAP score. 3. OPTIMIZING AVERAGE PRECISION We build upon the approach used by [13] for optimizing ROCArea. Unlike ROCArea, however, MAP does not decompose linearly in the examples and requires a substantially extended algorithm, which we describe in this section. Recall that the true ranking is a weak ranking with two rank values (relevant and non-relevant). Let Cx and C¯x denote the set of relevant and non-relevant documents of C for query x, respectively. We focus on functions which are parametrized by a weight vector w, and thus wish to find w to minimize the empirical risk, R∆ S (w) ≡ R∆ S (h(·; w)). Our approach is to learn a discriminant function F : X × Y → over input-output pairs. Given query x, we can derive a prediction by finding the ranking y that maximizes the discriminant function: h(x; w) = argmax y∈Y F(x, y; w). (1) We assume F to be linear in some combined feature representation of inputs and outputs Ψ(x, y) ∈ RN , i.e., F(x, y; w) = wT Ψ(x, y). (2) The combined feature function we use is Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))] , where φ : X × C → N is a feature mapping function from a query/document pair to a point in N dimensional space2 . We represent rankings as a matrix of pairwise orderings, Y ⊂ {−1, 0, +1}|C|×|C| . For any y ∈ Y, yij = +1 if di is ranked ahead of dj, and yij = −1 if dj is ranked ahead of di, and yij = 0 if di and dj have equal rank. We consider only matrices which correspond to valid rankings (i.e, obeying antisymmetry and transitivity). Intuitively, Ψ is a summation over the vector differences of all relevant/non-relevant document pairings. Since we assume predicted rankings to be complete rankings, yij is either +1 or −1 (never 0). Given a learned weight vector w, predicting a ranking (i.e. solving equation (1)) given query x reduces to picking each yij to maximize wT Ψ(x, y). As is also discussed in [13], this is attained by sorting the documents by wT φ(x, d) in descending order. We will discuss later the choices of φ we used for our experiments. 3.1 Structural SVMs The above formulation is very similar to learning a straightforward linear model while training on the pairwise difference of relevant/non-relevant document pairings. Many SVM-based approaches optimize over these pairwise differences (e.g., [5, 10, 13, 4]), although these methods do not optimize for MAP during training. Previously, it was not clear how to incorporate non-linear multivariate loss functions such as MAP loss directly into global optimization problems such as SVM training. We now present a method based on structural SVMs [19] to address this problem. We use the structural SVM formulation, presented in Optimization Problem 1, to learn a w ∈ RN . Optimization Problem 1. (Structural SVM) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) The objective function to be minimized (3) is a tradeoff between model complexity, w 2 , and a hinge loss relaxation of MAP loss, P ξi. As is usual in SVM training, C is a 2 For example, one dimension might be the number of times the query words appear in the document. Algorithm 1 Cutting plane algorithm for solving OP 1 within tolerance . 1: Input: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ for all i = 1, . . . , n 3: repeat 4: for i = 1, . . . , n do 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: compute ˆy = argmaxy∈Y H(y; w) 7: compute ξi = max{0, maxy∈Wi H(y; w)} 8: if H(ˆy; w) > ξi + then 9: Wi ← Wi ∪ {ˆy} 10: w ← optimize (3) over W = S i Wi 11: end if 12: end for 13: until no Wi has changed during iteration parameter that controls this tradeoff and can be tuned to achieve good performance in different training tasks. For each (xi, yi) in the training set, a set of constraints of the form in equation (4) is added to the optimization problem. Note that wT Ψ(x, y) is exactly our discriminant function F(x, y; w) (see equation (2)). During prediction, our model chooses the ranking which maximizes the discriminant (1). If the discriminant value for an incorrect ranking y is greater than for the true ranking yi (e.g., F(xi, y; w) > F(xi, yi; w)), then corresponding slack variable, ξi, must be at least ∆(yi, y) for that constraint to be satisfied. Therefore, the sum of slacks, P ξi, upper bounds the MAP loss. This is stated formally in Proposition 1. Proposition 1. Let ξ∗ (w) be the optimal solution of the slack variables for OP 1 for a given weight vector w. Then 1 n Pn i=1 ξi is an upper bound on the empirical risk R∆ S (w). (see [19] for proof) Proposition 1 shows that OP 1 learns a ranking function that optimizes an upper bound on MAP error on the training set. Unfortunately there is a problem: a constraint is required for every possible wrong output y, and the number of possible wrong outputs is exponential in the size of C. Fortunately, we may employ Algorithm 1 to solve OP 1. Algorithm 1 is a cutting plane algorithm, iteratively introducing constraints until we have solved the original problem within a desired tolerance [19]. The algorithm starts with no constraints, and iteratively finds for each example (xi, yi) the output ˆy associated with the most violated constraint. If the corresponding constraint is violated by more than we introduce ˆy into the working set Wi of active constraints for example i, and re-solve (3) using the updated W. It can be shown that Algorithm 1s outer loop is guaranteed to halt within a polynomial number of iterations for any desired precision . Theorem 1. Let ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y) , ¯∆ = maxi maxy ∆(yi, y), and for any > 0, Algorithm 1 terminates after adding at most max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff constraints to the working set W. (see [19] for proof) However, within the inner loop of this algorithm we have to compute argmaxy∈Y H(y; w), where H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), or equivalently, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), since wT Ψ(xi, yi) is constant with respect to y. Though closely related to the classification procedure, this has the substantial complication that we must contend with the additional ∆(yi, y) term. Without the ability to efficiently find the most violated constraint (i.e., solve argmaxy∈Y H(y, w)), the constraint generation procedure is not tractable. 3.2 Finding the Most Violated Constraint Using OP 1 and optimizing to ROCArea loss (∆roc), the problem of finding the most violated constraint, or solving argmaxy∈Y H(y, w) (henceforth argmax H), is addressed in [13]. Solving argmax H for ∆map is more difficult. This is primarily because ROCArea decomposes nicely into a sum of scores computed independently on each relative ordering of a relevant/non-relevant document pair. MAP, on the other hand, does not decompose in the same way as ROCArea. The main algorithmic contribution of this paper is an efficient method for solving argmax H for ∆map. One useful property of ∆map is that it is invariant to swapping two documents with equal relevance. For example, if documents da and db are both relevant, then swapping the positions of da and db in any ranking does not affect ∆map. By extension, ∆map is invariant to any arbitrary permutation of the relevant documents amongst themselves and of the non-relevant documents amongst themselves. However, this reshuﬄing will affect the discriminant score, wT Ψ(x, y). This leads us to Observation 1. Observation 1. Consider rankings which are constrained by fixing the relevance at each position in the ranking (e.g., the 3rd document in the ranking must be relevant). Every ranking which satisfies the same set of constraints will have the same ∆map. If the relevant documents are sorted by wT φ(x, d) in descending order, and the non-relevant documents are likewise sorted by wT φ(x, d), then the interleaving of the two sorted lists which satisfies the constraints will maximize H for that constrained set of rankings. Observation 1 implies that in the ranking which maximizes H, the relevant documents will be sorted by wT φ(x, d), and the non-relevant documents will also be sorted likewise. By first sorting the relevant and non-relevant documents, the problem is simplified to finding the optimal interleaving of two sorted lists. For the rest of our discussion, we assume that the relevant documents and non-relevant documents are both sorted by descending wT φ(x, d). For convenience, we also refer to relevant documents as {dx 1 , . . . dx |Cx|} = Cx , and non-relevant documents as {d¯x 1 , . . . d¯x |C¯x|} = C¯x . We define δj(i1, i2), with i1 < i2, as the change in H from when the highest ranked relevant document ranked after d¯x j is dx i1 to when it is dx i2 . For i2 = i1 + 1, we have δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5) where si = wT φ(x, di). The first term in (5) is the change in ∆map when the ith relevant document has j non-relevant documents ranked before it, as opposed to j −1. The second term is the change in the discriminant score, wT Ψ(x, y), when yij changes from +1 to −1. . . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . . Figure 1: Example for δj(i, i + 1) Figure 1 gives a conceptual example for δj(i, i + 1). The bottom ranking differs from the top only where d¯x j slides up one rank. The difference in the value of H for these two rankings is exactly δj(i, i + 1). For any i1 < i2, we can then define δj(i1, i2) as δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) or equivalently, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) . Let o1, . . . , o|C¯x| encode the positions of the non-relevant documents, where dx oj is the highest ranked relevant document ranked after the jth non-relevant document. Due to Observation 1, this encoding uniquely identifies a complete ranking. We can recover the ranking as yij = 8 >>>< >>>: 0 if i = j sign(si − sj) if di, dj equal relevance sign(oj − i − 0.5) if di = dx i , dj = d¯x j sign(j − oi + 0.5) if di = d¯x i , dj = dx j . (7) We can now reformulate H into a new objective function, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), where ¯y is the true (weak) ranking. Conceptually H starts with a perfect ranking ¯y, and adds the change in H when each successive non-relevant document slides up the ranking. We can then reformulate the argmax H problem as argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) s.t. o1 ≤ . . . ≤ o|C¯x|. (9) Algorithm 2 describes the algorithm used to solve equation (8). Conceptually, Algorithm 2 starts with a perfect ranking. Then for each successive non-relevant document, the algorithm modifies the solution by sliding that document up the ranking to locally maximize H while keeping the positions of the other non-relevant documents constant. 3.2.1 Proof of Correctness Algorithm 2 is greedy in the sense that it finds the best position of each non-relevant document independently from the other non-relevant documents. In other words, the algorithm maximizes H for each non-relevant document, d¯x j , Algorithm 2 Finding the Most Violated Constraint (argmax H) for Algorithm 1 with ∆map 1: Input: w, Cx , C¯x 2: sort Cx and C¯x in descending order of wT φ(x, d) 3: sx i ← wT φ(x, dx i ), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i ), i = 1, . . . , |C¯x | 5: for j = 1, . . . , |C¯x | do 6: optj ← argmaxk δj(k, |Cx | + 1) 7: end for 8: encode ˆy according to (7) 9: return ˆy without considering the positions of the other non-relevant documents, and thus ignores the constraints of (9). In order for the solution to be feasible, the jth non-relevant document must be ranked after the first j − 1 non-relevant documents, thus satisfying opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. (10) If the solution is feasible, the it clearly solves (8). Therefore, it suffices to prove that Algorithm 2 satisfies (10). We first prove that δj(·, ·) is monotonically decreasing in j. Lemma 1. For any 1 ≤ i1 < i2 ≤ |Cx | + 1 and 1 ≤ j < |C¯x |, it must be the case that δj+1(i1, i2) ≤ δj(i1, i2). Proof. Recall from (6) that both δj(i1, i2) and δj+1(i1, i2) are summations of i2 − i1 terms. We will show that each term in the summation of δj+1(i1, i2) is no greater than the corresponding term in δj(i1, i2), or δj+1(k, k + 1) ≤ δj(k, k + 1) for k = i1, . . . , i2 − 1. Each term in δj(k, k +1) and δj+1(k, k +1) can be further decomposed into two parts (see (5)). We will show that each part of δj+1(k, k + 1) is no greater than the corresponding part in δj(k, k + 1). In other words, we will show that both j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) and −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) are true for the aforementioned values of j and k. It is easy to see that (11) is true by observing that for any two positive integers 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1 , and choosing a = j and b = j + k. The second inequality (12) holds because Algorithm 2 first sorts d¯x in descending order of s¯x , implying s¯x j+1 ≤ s¯x j . Thus we see that each term in δj+1 is no greater than the corresponding term in δj, which completes the proof. The result of Lemma 1 leads directly to our main correctness result: Theorem 2. In Algorithm 2, the computed values of optj satisfy (10), implying that the solution returned by Algorithm 2 is feasible and thus optimal. Proof. We will prove that optj ≤ optj+1 holds for any 1 ≤ j < |C¯x |, thus implying (10). Since Algorithm 2 computes optj as optj = argmax k δj(k, |Cx | + 1), (13) then by definition of δj (6), for any 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0. Using Lemma 1, we know that δj+1(i, optj) ≤ δj(i, optj) < 0, which implies that for any 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0. Suppose for contradiction that optj+1 < optj. Then δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), which contradicts (13). Therefore, it must be the case that optj ≤ optj+1, which completes the proof. 3.2.2 Running Time The running time of Algorithm 2 can be split into two parts. The first part is the sort by wT φ(x, d), which requires O(n log n) time, where n = |Cx | + |C¯x |. The second part computes each optj, which requires O(|Cx | · |C¯x |) time. Though in the worst case this is O(n2 ), the number of relevant documents, |Cx |, is often very small (e.g., constant with respect to n), in which case the running time for the second part is simply O(n). For most real-world datasets, Algorithm 2 is dominated by the sort and has complexity O(n log n). Algorithm 1 is guaranteed to halt in a polynomial number of iterations [19], and each iteration runs Algorithm 2. Virtually all well-performing models were trained in a reasonable amount of time (usually less than one hour). Once training is complete, making predictions on query x using the resulting hypothesis h(x|w) requires only sorting by wT φ(x, d). We developed our software using a Python interface3 to SVMstruct , since the Python language greatly simplified the coding process. To improve performance, it is advisable to use the standard C implementation4 of SVMstruct . 4. EXPERIMENT SETUP The main goal of our experiments is to evaluate whether directly optimizing MAP leads to improved MAP performance compared to conventional SVM methods that optimize a substitute loss such as accuracy or ROCArea. We empirically evaluate our method using two sets of TREC Web Track queries, one each from TREC 9 and TREC 10 (topics 451-500 and 501-550), both of which used the WT10g corpus. For each query, TREC provides the relevance judgments of the documents. We generated our features using the scores of existing retrieval functions on these queries. While our method is agnostic to the meaning of the features, we chose to use existing retrieval functions as a simple yet effective way of acquiring useful features. As such, our 3 http://www.cs.cornell.edu/~tomf/svmpython/ 4 http://svmlight.joachims.org/svm_struct.html Dataset Base Funcs Features TREC 9 Indri 15 750 TREC 10 Indri 15 750 TREC 9 Submissions 53 2650 TREC 10 Submissions 18 900 Table 5: Dataset Statistics experiments essentially test our methods ability to re-rank the highly ranked documents (e.g., re-combine the scores of the retrieval functions) to improve MAP. We compare our method against the best retrieval functions trained on (henceforth base functions), as well as against previously proposed SVM methods. Comparing with the best base functions tests our methods ability to learn a useful combination. Comparing with previous SVM methods allows us to test whether optimizing directly for MAP (as opposed to accuracy or ROCArea) achieves a higher MAP score in practice. The rest of this section describes the base functions and the feature generation method in detail. 4.1 Choosing Retrieval Functions We chose two sets of base functions for our experiments. For the first set, we generated three indices over the WT10g corpus using Indri5 . The first index was generated using default settings, the second used Porter-stemming, and the last used Porter-stemming and Indris default stopwords. For both TREC 9 and TREC 10, we used the description portion of each query and scored the documents using five of Indris built-in retrieval methods, which are Cosine Similarity, TFIDF, Okapi, Language Model with Dirichlet Prior, and Language Model with Jelinek-Mercer Prior. All parameters were kept as their defaults. We computed the scores of these five retrieval methods over the three indices, giving 15 base functions in total. For each query, we considered the scores of documents found in the union of the top 1000 documents of each base function. For our second set of base functions, we used scores from the TREC 9 [8] and TREC 10 [9] Web Track submissions. We used only the non-manual, non-short submissions from both years. For TREC 9 and TREC 10, there were 53 and 18 such submissions, respectively. A typical submission contained scores of its top 1000 documents. b ca wT φ(x,d) f(d|x) Figure 2: Example Feature Binning 4.2 Generating Features In order to generate input examples for our method, a concrete instantiation of φ must be provided. For each doc5 http://www.lemurproject.org TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236Best Func. 0.204 39/11 ** 0.181 37/13 ** 2nd Best 0.199 38/12 ** 0.174 43/7 ** 3rd Best 0.188 34/16 ** 0.174 38/12 ** Table 6: Comparison with Indri Functions ument d scored by a set of retrieval functions F on query x, we generate the features as a vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf , where f(d|x) denotes the score that retrieval function f assigns to document d for query x, and each Kf is a set of real values. From a high level, we are expressing the score of each retrieval function using |Kf | + 1 bins. Since we are using linear kernels, one can think of the learning problem as finding a good piecewise-constant combination of the scores of the retrieval functions. Figure 2 shows an example of our feature mapping method. In this example we have a single feature F = {f}. Here, Kf = {a, b, c}, and the weight vector is w = wa, wb, wc . For any document d and query x, we have wT φ(x, d) = 8 >>< >>: 0 if f(d|x) < a wa if a ≤ f(d|x) < b wa + wb if b ≤ f(d|x) < c wa + wb + wc if c ≤ f(d|x) . This is expressed qualitatively in Figure 2, where wa and wb are positive, and wc is negative. We ran our main experiments using four choices of F: the set of aforementioned Indri retrieval functions for TREC 9 and TREC 10, and the Web Track submissions for TREC 9 and TREC 10. For each F and each function f ∈ F, we chose 50 values for Kf which are reasonably spaced and capture the sensitive region of f. Using the four choices of F, we generated four datasets for our main experiments. Table 5 contains statistics of the generated datasets. There are many ways to generate features, and we are not advocating our method over others. This was simply an efficient means to normalize the outputs of different functions and allow for a more expressive model. 5. EXPERIMENTS For each dataset in Table 5, we performed 50 trials. For each trial, we train on 10 randomly selected queries, and select another 5 queries at random for a validation set. Models were trained using a wide range of C values. The model which performed best on the validation set was selected and tested on the remaining 35 queries. All queries were selected to be in the training, validation and test sets the same number of times. Using this setup, we performed the same experiments while using our method (SVM∆ map), an SVM optimizing for ROCArea (SVM∆ roc) [13], and a conventional classification SVM (SVMacc) [20]. All SVM methods used a linear kernel. We reported the average performance of all models over the 50 trials. 5.1 Comparison with Base Functions In analyzing our results, the first question to answer is, can SVM∆ map learn a model which outperforms the best base TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287Best Func. 0.280 28/22 0.283 29/21 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 36/14 ** Table 7: Comparison with TREC Submissions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288Best Func. 0.280 27/23 0.283 31/19 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 35/15 ** Table 8: Comparison with TREC Subm. (w/o best) functions? Table 6 presents the comparison of SVM∆ map with the best Indri base functions. Each column group contains the macro-averaged MAP performance of SVM∆ map or a base function. The W/L columns show the number of queries where SVM∆ map achieved a higher MAP score. Significance tests were performed using the two-tailed Wilcoxon signed rank test. Two stars indicate a significance level of 0.95. All tables displaying our experimental results are structured identically. Here, we find that SVM∆ map significantly outperforms the best base functions. Table 7 shows the comparison when trained on TREC submissions. While achieving a higher MAP score than the best base functions, the performance difference between SVM∆ map the base functions is not significant. Given that many of these submissions use scoring functions which are carefully crafted to achieve high MAP, it is possible that the best performing submissions use techniques which subsume the techniques of the other submissions. As a result, SVM∆ map would not be able to learn a hypothesis which can significantly out-perform the best submission. Hence, we ran the same experiments using a modified dataset where the features computed using the best submission were removed. Table 8 shows the results (note that we are still comparing against the best submission though we are not using it for training). Notice that while the performance of SVM∆ map degraded slightly, the performance was still comparable with that of the best submission. 5.2 Comparison w/ Previous SVM Methods The next question to answer is, does SVM∆ map produce higher MAP scores than previous SVM methods? Tables 9 and 10 present the results of SVM∆ map, SVM∆ roc, and SVMacc when trained on the Indri retrieval functions and TREC submissions, respectively. Table 11 contains the corresponding results when trained on the TREC submissions without the best submission. To start with, our results indicate that SVMacc was not competitive with SVM∆ map and SVM∆ roc, and at times underperformed dramatically. As such, we tried several approaches to improve the performance of SVMacc. 5.2.1 Alternate SVMacc Methods One issue which may cause SVMacc to underperform is the severe imbalance between relevant and non-relevant docTREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236SVM∆ roc 0.237 29/21 0.234 24/26 SVMacc 0.147 47/3 ** 0.155 47/3 ** SVMacc2 0.219 39/11 ** 0.207 43/7 ** SVMacc3 0.113 49/1 ** 0.153 45/5 ** SVMacc4 0.155 48/2 ** 0.155 48/2 ** Table 9: Trained on Indri Functions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287SVM∆ roc 0.282 29/21 0.278 35/15 ** SVMacc 0.213 49/1 ** 0.222 49/1 ** SVMacc2 0.270 34/16 ** 0.261 42/8 ** SVMacc3 0.133 50/0 ** 0.182 46/4 ** SVMacc4 0.233 47/3 ** 0.238 46/4 ** Table 10: Trained on TREC Submissions uments. The vast majority of the documents are not relevant. SVMacc2 addresses this problem by assigning more penalty to false negative errors. For each dataset, the ratio of the false negative to false positive penalties is equal to the ratio of the number non-relevant and relevant documents in that dataset. Tables 9, 10 and 11 indicate that SVMacc2 still performs significantly worse than SVM∆ map. Another possible issue is that SVMacc attempts to find just one discriminating threshold b that is query-invariant. It may be that different queries require different values of b. Having the learning method trying to find a good b value (when one does not exist) may be detrimental. We took two approaches to address this issue. The first method, SVMacc3, converts the retrieval function scores into percentiles. For example, for document d, query q and retrieval function f, if the score f(d|q) is in the top 90% of the scores f(·|q) for query q, then the converted score is f (d|q) = 0.9. Each Kf contains 50 evenly spaced values between 0 and 1. Tables 9, 10 and 11 show that the performance of SVMacc3 was also not competitive with SVM∆ map. The second method, SVMacc4, normalizes the scores given by f for each query. For example, assume for query q that f outputs scores in the range 0.2 to 0.7. Then for document d, if f(d|q) = 0.6, the converted score would be f (d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8. Each Kf contains 50 evenly spaced values between 0 and 1. Again, Tables 9, 10 and 11 show that SVMacc4 was not competitive with SVM∆ map 5.2.2 MAP vs ROCArea SVM∆ roc performed much better than SVMacc in our experiments. When trained on Indri retrieval functions (see Table 9), the performance of SVM∆ roc was slight, though not significantly, worse than the performances of SVM∆ map. However, Table 10 shows that SVM∆ map did significantly outperform SVM∆ roc when trained on the TREC submissions. Table 11 shows the performance of the models when trained on the TREC submissions with the best submission removed. The performance of most models degraded by a small amount, with SVM∆ map still having the best performance. TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Table 11: Trained on TREC Subm. (w/o Best) 6. CONCLUSIONS AND FUTURE WORK We have presented an SVM method that directly optimizes MAP. It provides a principled approach and avoids difficult to control heuristics. We formulated the optimization problem and presented an algorithm which provably finds the solution in polynomial time. We have shown empirically that our method is generally superior to or competitive with conventional SVMs methods. Our new method makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for Accuracy and ROCArea. The computational cost for training is very reasonable in practice. Since other methods typically require tuning multiple heuristics, we also expect to train fewer models before finding one which achieves good performance. The learning framework used by our method is fairly general. A natural extension of this framework would be to develop methods to optimize for other important IR measures, such as Normalized Discounted Cumulative Gain [2, 3, 4, 12] and Mean Reciprocal Rank. 7. ACKNOWLEDGMENTS This work was funded under NSF Award IIS-0412894, NSF CAREER Award 0237381, and a gift from Yahoo! Research. The third author was also partly supported by a Microsoft Research Fellowship. 8. REFERENCES [1] B. T. Bartell, G. W. Cottrell, and R. K. Belew. Automatic combination of multiple ranked retrieval systems. In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender. Learning to rank using gradient descent. In Proceedings of the International Conference on Machine Learning (ICML), 2005. [3] C. J. C. Burges, R. Ragno, and Q. Le. Learning to rank with non-smooth cost functions. In Proceedings of the International Conference on Advances in Neural Information Processing Systems (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang, and H.-W. Hon. Adapting ranking SVM to document retrieval. In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [5] B. Carterette and D. Petkova. Learning a ranking from pairwise preferences. In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew, and A. Ksikes. Ensemble selection from libraries of models. In Proceedings of the International Conference on Machine Learning (ICML), 2004. [7] J. Davis and M. Goadrich. The relationship between precision-recall and ROC curves. In Proceedings of the International Conference on Machine Learning (ICML), 2006. [8] D. Hawking. Overview of the TREC-9 web track. In Proceedings of TREC-2000, 2000. [9] D. Hawking and N. Craswell. Overview of the TREC-2001 web track. In Proceedings of TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel, and K. Obermayer. Large margin rank boundaries for ordinal regression. Advances in large margin classifiers, 2000. [11] A. Herschtal and B. Raskutti. Optimising area under the ROC curve using gradient descent. In Proceedings of the International Conference on Machine Learning (ICML), 2004. [12] K. Jarvelin and J. Kekalainen. Ir evaluation methods for retrieving highly relevant documents. In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2000. [13] T. Joachims. A support vector method for multivariate performance measures. In Proceedings of the International Conference on Machine Learning (ICML), pages 377-384, New York, NY, USA, 2005. ACM Press. [14] J. Lafferty and C. Zhai. Document language models, query models, and risk minimization for information retrieval. In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 111-119, 2001. [15] Y. Lin, Y. Lee, and G. Wahba. Support vector machines for classification in nonstandard situations. Machine Learning, 46:191-202, 2002. [16] D. Metzler and W. B. Croft. A markov random field model for term dependencies. In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 472-479, 2005. [17] K. Morik, P. Brockhausen, and T. Joachims. Combining statistical learning with a knowledge-based approach. In Proceedings of the International Conference on Machine Learning, 1999. [18] S. Robertson. The probability ranking principle in ir. journal of documentation. Journal of Documentation, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun. Large margin methods for structured and interdependent output variables. Journal of Machine Learning Research (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik. Statistical Learning Theory. Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz. Optimizing classifier performance via approximation to the Wilcoxon-Mann-Witney statistic. In Proceedings of the International Conference on Machine Learning (ICML), 2003.",
    "original_translation": "Un método de Vectores de Soporte para optimizar la Precisión Promedio Yisong Yue Universidad de Cornell Ithaca, NY, EE. UU. yyue@cs.cornell.edu Thomas Finley Universidad de Cornell Ithaca, NY, EE. UU. tomf@cs.cornell.edu Filip Radlinski Universidad de Cornell Ithaca, NY, EE. UU. filip@cs.cornell.edu Thorsten Joachims Universidad de Cornell Ithaca, NY, EE. UU. tj@cs.cornell.edu RESUMEN El aprendizaje automático se utiliza comúnmente para mejorar los sistemas de recuperación clasificados. Debido a dificultades computacionales, se han desarrollado pocas técnicas de aprendizaje para optimizar directamente la precisión media promedio (MAP), a pesar de su uso generalizado en la evaluación de dichos sistemas. Los enfoques existentes que optimizan el MAP no encuentran una solución óptima global o son computacionalmente costosos. Por el contrario, presentamos un algoritmo de aprendizaje SVM general que encuentra de manera eficiente una solución óptima global para una relajación directa de MAP. Evaluamos nuestro enfoque utilizando los corpus de la pista web TREC 9 y TREC 10 (WT10g), comparando con SVM optimizados para precisión y área bajo la curva ROC. En la mayoría de los casos mostramos nuestro método para producir mejoras estadísticamente significativas en las puntuaciones de MAP. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de Recuperación Términos Generales Algoritmo, Teoría, Experimentación 1. INTRODUCCIÓN Los sistemas de recuperación de información de última generación comúnmente utilizan técnicas de aprendizaje automático para aprender funciones de clasificación. Sin embargo, la mayoría de los enfoques actuales no están optimizados para la medida de evaluación más utilizada, es decir, la Precisión Promedio Media (MAP). En cambio, los algoritmos actuales tienden a seguir uno de dos enfoques generales. El primer enfoque es aprender un modelo que estime la probabilidad de que un documento sea relevante dado una consulta (por ejemplo, [18, 14]). Si se resuelve de manera efectiva, la clasificación con el mejor rendimiento de MAP puede derivarse fácilmente de las probabilidades de relevancia. Sin embargo, lograr un MAP alto solo requiere encontrar un buen ordenamiento de los documentos. Como resultado, encontrar buenas probabilidades requiere resolver un problema más difícil de lo necesario, probablemente necesitando más datos de entrenamiento para lograr el mismo rendimiento de MAP. El segundo enfoque común es aprender una función que maximice una medida sustituta. Las medidas de rendimiento optimizadas incluyen precisión [17, 15], área bajo la curva ROC [1, 5, 10, 11, 13, 21] o modificaciones del área bajo la curva ROC [4], y NDCG [2, 3]. Aprender un modelo para optimizar tales medidas podría resultar en un rendimiento de MAP subóptimo. De hecho, aunque algunos sistemas anteriores han obtenido un buen rendimiento de MAP, se sabe que ni lograr una precisión óptima ni un área bajo la curva ROC pueden garantizar un rendimiento de MAP óptimo[7]. En este artículo, presentamos un enfoque general para aprender funciones de clasificación que maximizan el rendimiento de MAP. Específicamente, presentamos un algoritmo SVM que optimiza globalmente una relajación de pérdida de bisagra de MAP. Este enfoque simplifica el proceso de obtener funciones de clasificación con un alto rendimiento de MAP al evitar pasos intermedios adicionales y heurísticas. El nuevo algoritmo también hace que sea conceptualmente tan fácil optimizar las SVM para MAP como anteriormente solo era posible para precisión y ROCArea. A diferencia del trabajo reciente que optimiza directamente el rendimiento de MAP realizado por Metzler & Croft [16] y Caruana et al. [6], nuestra técnica es eficiente computacionalmente al encontrar una solución óptima a nivel global. Al igual que [6, 16], nuestro método aprende un modelo lineal, pero es mucho más eficiente en la práctica y, a diferencia de [16], puede manejar miles de características. Ahora describimos el algoritmo en detalle y proporcionamos la prueba de corrección. A continuación, proporcionamos un análisis del tiempo de ejecución. Concluimos con los resultados empíricos de experimentos en el corpus de la pista web TREC 9 y TREC 10. También hemos desarrollado un paquete de software que implementa nuestro algoritmo y está disponible para uso público. EL PROBLEMA DEL APRENDIZAJE Siguiendo la configuración estándar del aprendizaje automático, nuestro objetivo es aprender una función h: X → Y entre un espacio de entrada X (todas las consultas posibles) y un espacio de salida Y (clasificaciones sobre un corpus). Para cuantificar la calidad de una predicción, ˆy = h(x), consideraremos una función de pérdida ∆ : Y × Y → . ∆(y, ˆy) cuantifica la penalización por hacer la predicción ˆy si la salida correcta es y. La función de pérdida nos permite incorporar medidas específicas de rendimiento, las cuales explotaremos en http://svmrank.yisongyue.com para optimizar el MAP. Nos restringimos al escenario de aprendizaje supervisado, donde pares de entrada/salida (x, y) están disponibles para el entrenamiento y se asume que provienen de alguna distribución fija P(x, y). El objetivo es encontrar una función h tal que el riesgo (es decir, la pérdida esperada), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), se minimice. Por supuesto, P(x, y) es desconocido. Pero dado un conjunto finito de pares de entrenamiento, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, el rendimiento de h en S puede medirse mediante el riesgo empírico, R∆ S (h) = 1 n ∑ i=1 n ∆(yi, h(xi)). En el caso de aprender una función de recuperación clasificada, X denota un espacio de consultas, y Y el espacio de clasificaciones (posiblemente débiles) sobre algún corpus de documentos C = {d1, . . . ,d|C|}. Podemos definir la pérdida de precisión promedio como ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), donde rank(y) es un vector de los valores de rango de cada documento en C. Por ejemplo, para un corpus de dos documentos, {d1, d2}, con d1 teniendo un rango más alto que d2, rank(y) = (1, 0). Suponemos que las clasificaciones verdaderas tienen dos valores de clasificación, donde los documentos relevantes tienen un valor de clasificación 1 y los documentos no relevantes tienen un valor de clasificación 0. Además, asumimos que todas las clasificaciones predichas son clasificaciones completas (sin empates). Sea p = rango(y) y ˆp = rango(ˆy). La puntuación de precisión promedio se define como MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, donde rel = |{i : pi = 1}| es el número de documentos relevantes, y Prec@j es el porcentaje de documentos relevantes en los primeros j documentos en la clasificación predicha ˆy. MAP es la media de las puntuaciones de precisión promedio de un grupo de consultas. La mayoría de los algoritmos de aprendizaje se optimizan para precisión o ROCArea. Si bien optimizar estas medidas podría lograr un buen rendimiento de MAP, usamos dos ejemplos simples para mostrar que también puede ser subóptimo en términos de MAP. ROCArea asigna una penalización igual a cada desordenamiento de un par relevante/no relevante. Por el contrario, MAP asigna mayores penalizaciones a los errores de ordenamiento más arriba en la clasificación predicha. Usando nuestra notación, el Área bajo la Curva ROC (ROCArea) se puede definir como ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], donde p es el ranking verdadero (débil), ˆp es el ranking predicho, y 1[b] es la función indicadora condicionada a b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Tabla 1: Ejemplo y Modelos Supongamos que tenemos un espacio de hipótesis con solo dos funciones de hipótesis, h1 y h2, como se muestra en la Tabla 1. Estas dos hipótesis predicen un ranking para la consulta x sobre un corpus de ocho documentos. Tabla 2: Rendimiento de los Modelos de Juguete La Tabla 2 muestra las puntuaciones de MAP y ROCArea de h1 y h2. Aquí, un método de aprendizaje que optimiza para el Área bajo la curva ROC elegiría h2 ya que esto resulta en un puntaje de Área bajo la curva ROC más alto, pero esto produce un puntaje de MAP subóptimo. 2.2 MAP vs Precisión Usando un ejemplo muy similar, ahora demostramos cómo optimizar para la precisión podría resultar en un puntaje de MAP subóptimo. Los modelos que se optimizan para la precisión no están directamente preocupados por la clasificación. En cambio, aprenden un umbral tal que los documentos que obtienen una puntuación superior al umbral pueden ser clasificados como relevantes y los documentos que obtienen una puntuación inferior como no relevantes. Consideramos nuevamente un espacio de hipótesis con dos hipótesis. La Tabla 3 muestra las predicciones de las dos hipótesis en una única consulta x. Hipótesis MAP Mejor Precisión h1(q) 0.70 0.64 h2(q) 0.64 0.73 Tabla 4: Rendimiento de los Modelos de Juguete La Tabla 4 muestra los puntajes de MAP y mejor precisión de h1(q) y h2(q). La mejor precisión se refiere a la precisión más alta alcanzable en esa clasificación al considerar todos los umbrales posibles. Por ejemplo, con h1(q), un umbral entre los documentos 1 y 2 da 4 errores (documentos 6-9 clasificados incorrectamente como no relevantes), lo que resulta en una precisión de 0.64. De manera similar, con h2(q), un umbral entre los documentos 5 y 6 da 3 errores (los documentos 10-11 clasificados incorrectamente como relevantes, y el documento 1 como no relevante), lo que resulta en una precisión de 0.73. Un método de aprendizaje que optimiza la precisión elegiría h2 ya que esto resulta en un puntaje de precisión más alto, pero esto produce un puntaje de MAP subóptimo. 3. OPTIMIZANDO LA PRECISIÓN PROMEDIO Nos basamos en el enfoque utilizado por [13] para optimizar el Área bajo la Curva ROC. A diferencia de ROCArea, sin embargo, MAP no se descompone linealmente en los ejemplos y requiere un algoritmo sustancialmente extendido, el cual describimos en esta sección. Recuerda que la clasificación verdadera es una clasificación débil con dos valores de clasificación (relevante y no relevante). Que Cx y C¯x denoten el conjunto de documentos relevantes y no relevantes de C para la consulta x, respectivamente. Nos enfocamos en funciones que están parametrizadas por un vector de peso w, y por lo tanto deseamos encontrar w para minimizar el riesgo empírico, R∆ S (w) ≡ R∆ S (h(·; w)). Nuestro enfoque es aprender una función discriminante F: X × Y → sobre pares de entrada-salida. Dada la consulta x, podemos derivar una predicción encontrando la clasificación y que maximiza la función discriminante: h(x; w) = argmax y∈Y F(x, y; w). (1) Suponemos que F es lineal en alguna representación de características combinadas de entradas y salidas Ψ(x, y) ∈ RN, es decir, F(x, y; w) = wT Ψ(x, y). (2) La función de características combinadas que utilizamos es Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))], donde φ: X × C → N es una función de mapeo de características de un par consulta/documento a un punto en un espacio dimensional N. Representamos las clasificaciones como una matriz de ordenamientos por pares, Y ⊂ {−1, 0, +1}|C|×|C| . Para cualquier y ∈ Y, yij = +1 si di está clasificado por delante de dj, y yij = −1 si dj está clasificado por delante de di, y yij = 0 si di y dj tienen el mismo rango. Consideramos solo matrices que corresponden a clasificaciones válidas (es decir, que cumplen con la antisimetría y la transitividad). De manera intuitiva, Ψ es una suma de las diferencias vectoriales de todos los pares de documentos relevantes/no relevantes. Dado que asumimos que las clasificaciones predichas son clasificaciones completas, yij es o bien +1 o −1 (nunca 0). Dado un vector de pesos aprendido w, predecir un ranking (es decir, resolver la ecuación (1)) dado una consulta x se reduce a elegir cada yij para maximizar wT Ψ(x, y). Como también se discute en [13], esto se logra ordenando los documentos por wT φ(x, d) en orden descendente. Discutiremos más adelante las elecciones de φ que utilizamos para nuestros experimentos. 3.1 SVM Estructurales La formulación anterior es muy similar a aprender un modelo lineal directo mientras se entrena en la diferencia de pares de documentos relevantes/no relevantes. Muchos enfoques basados en SVM optimizan sobre estas diferencias en pares (por ejemplo, [5, 10, 13, 4]), aunque estos métodos no optimizan para el MAP durante el entrenamiento. Anteriormente, no estaba claro cómo incorporar funciones de pérdida multivariadas no lineales como la pérdida MAP directamente en problemas de optimización global como el entrenamiento de SVM. Ahora presentamos un método basado en SVM estructurales [19] para abordar este problema. Utilizamos la formulación del SVM estructural, presentada en el Problema de Optimización 1, para aprender un w ∈ RN. Problema de optimización 1. (SVM estructural) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) La función objetivo a minimizar (3) es un compromiso entre la complejidad del modelo, w 2 , y una relajación de pérdida de MAP mediante la pérdida de bisagra, P ξi. Como es habitual en el entrenamiento de SVM, C es igual a 2. Por ejemplo, una dimensión podría ser el número de veces que las palabras de la consulta aparecen en el documento. Algoritmo 1 Algoritmo de plano de corte para resolver OP 1 dentro de la tolerancia. 1: Entrada: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ para todo i = 1, . . . , n 3: repetir 4: para i = 1, . . . , n hacer 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: calcular ˆy = argmaxy∈Y H(y; w) 7: calcular ξi = max{0, maxy∈Wi H(y; w)} 8: si H(ˆy; w) > ξi + entonces 9: Wi ← Wi ∪ {ˆy} 10: w ← optimizar (3) sobre W = S i Wi 11: fin si 12: fin para 13: hasta que ningún Wi haya cambiado durante la iteración parámetro que controla este equilibrio y puede ajustarse para lograr un buen rendimiento en diferentes tareas de entrenamiento. Para cada (xi, yi) en el conjunto de entrenamiento, se añade un conjunto de restricciones de la forma en la ecuación (4) al problema de optimización. Ten en cuenta que wT Ψ(x, y) es exactamente nuestra función discriminante F(x, y; w) (ver ecuación (2)). Durante la predicción, nuestro modelo elige el ranking que maximiza el discriminante (1). Si el valor del discriminante para una clasificación incorrecta y es mayor que para la clasificación verdadera yi (por ejemplo, F(xi, y; w) > F(xi, yi; w)), entonces la variable de holgura correspondiente, ξi, debe ser al menos ∆(yi, y) para que se cumpla esa restricción. Por lo tanto, la suma de los márgenes, P ξi, acota superiormente la pérdida MAP. Esto se establece formalmente en la Proposición 1. Proposición 1. Sea ξ∗ (w) la solución óptima de las variables de holgura para OP 1 para un vector de peso dado w. Entonces 1 n Pn i=1 ξi es una cota superior del riesgo empírico R∆ S (w). (ver [19] para la prueba) La Proposición 1 muestra que OP 1 aprende una función de clasificación que optimiza una cota superior del error de MAP en el conjunto de entrenamiento. Desafortunadamente hay un problema: se requiere una restricción para cada posible resultado incorrecto y, y el número de resultados incorrectos posibles es exponencial en el tamaño de C. Afortunadamente, podemos emplear el Algoritmo 1 para resolver OP 1. El algoritmo 1 es un algoritmo de plano de corte, introduciendo iterativamente restricciones hasta que hayamos resuelto el problema original dentro de una tolerancia deseada [19]. El algoritmo comienza sin restricciones y encuentra de forma iterativa, para cada ejemplo (xi, yi), la salida ˆy asociada con la restricción más violada. Si la restricción correspondiente es violada por más de lo que introducimos ˆy en el conjunto de trabajo Wi de restricciones activas, por ejemplo i, y volvemos a resolver (3) usando el W actualizado. Se puede demostrar que el bucle externo del Algoritmo 1 está garantizado a detenerse dentro de un número polinomial de iteraciones para cualquier precisión deseada. Teorema 1. Sea ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y), ¯∆ = maxi maxy ∆(yi, y), y para cualquier > 0, el Algoritmo 1 termina después de agregar a lo sumo max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff restricciones al conjunto de trabajo W. (ver [19] para la prueba) Sin embargo, dentro del bucle interno de este algoritmo tenemos que calcular argmaxy∈Y H(y; w), donde H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), o equivalentemente, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), ya que wT Ψ(xi, yi) es constante con respecto a y. Aunque está estrechamente relacionado con el procedimiento de clasificación, esto tiene la complicación sustancial de que debemos lidiar con el término adicional ∆(yi, y). Sin la capacidad de encontrar eficientemente la restricción más violada (es decir, resolver argmaxy∈Y H(y, w)), el procedimiento de generación de restricciones no es viable. 3.2 Encontrar la restricción más violada utilizando OP 1 y optimizando la pérdida de ROCArea (∆roc), el problema de encontrar la restricción más violada, o resolver argmaxy∈Y H(y, w) (en adelante argmax H), se aborda en [13]. Resolver argmax H para ∆map es más difícil. Esto se debe principalmente a que ROCArea se descompone de manera ordenada en una suma de puntuaciones calculadas de forma independiente en cada ordenamiento relativo de un par de documentos relevantes/no relevantes. MAP, por otro lado, no se descompone de la misma manera que ROCArea. La principal contribución algorítmica de este artículo es un método eficiente para resolver argmax H para ∆map. Una propiedad útil de ∆map es que es invariante al intercambiar dos documentos con igual relevancia. Por ejemplo, si los documentos da y db son ambos relevantes, entonces intercambiar las posiciones de da y db en cualquier clasificación no afecta a ∆map. Por extensión, ∆map es invariante a cualquier permutación arbitraria de los documentos relevantes entre sí y de los documentos no relevantes entre sí. Sin embargo, esta reorganización afectará la puntuación del discriminante, wT Ψ(x, y). Esto nos lleva a la Observación 1. Observación 1. Considera clasificaciones que estén limitadas por fijar la relevancia en cada posición de la clasificación (por ejemplo, el tercer documento en la clasificación debe ser relevante). Cada clasificación que cumpla con el mismo conjunto de restricciones tendrá el mismo ∆map. Si los documentos relevantes están ordenados por wT φ(x, d) en orden descendente, y los documentos no relevantes también están ordenados de la misma manera por wT φ(x, d), entonces la intercalación de las dos listas ordenadas que cumpla con las restricciones maximizará H para ese conjunto de clasificaciones restringidas. La Observación 1 implica que en la clasificación que maximiza H, los documentos relevantes se ordenarán por wT φ(x, d), y los documentos no relevantes también se ordenarán de la misma manera. Al ordenar primero los documentos relevantes y no relevantes, el problema se simplifica a encontrar la intercalación óptima de dos listas ordenadas. Para el resto de nuestra discusión, asumimos que los documentos relevantes y no relevantes están ordenados por wT φ(x, d) en orden descendente. Para mayor comodidad, también nos referimos a los documentos relevantes como {dx 1 , . . . dx |Cx|} = Cx, y a los documentos no relevantes como {d¯x 1 , . . . d¯x |C¯x|} = C¯x. Definimos δj(i1, i2), con i1 < i2, como el cambio en H desde cuando el documento relevante de mayor rango clasificado después de d¯x j es dx i1 hasta que es dx i2. Para i2 = i1 + 1, tenemos δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5), donde si = wT φ(x, di). El primer término en (5) es el cambio en ∆map cuando el documento relevante i tiene j documentos no relevantes clasificados antes de él, en lugar de j-1. El segundo término es el cambio en la puntuación del discriminante, wT Ψ(x, y), cuando yij cambia de +1 a −1. . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . . Figura 1: Ejemplo para δj(i, i + 1). La Figura 1 proporciona un ejemplo conceptual para δj(i, i + 1). La clasificación inferior difiere de la superior solo cuando d¯x j sube un rango. La diferencia en el valor de H para estas dos clasificaciones es exactamente δj(i, i + 1). Para cualquier i1 < i2, podemos definir δj(i1, i2) como δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) o equivalentemente, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) . Deja que o1, . . . , o|C¯x| codifiquen las posiciones de los documentos no relevantes, donde dx oj es el documento relevante de mayor rango clasificado después del j-ésimo documento no relevante. Debido a la Observación 1, esta codificación identifica de forma única un ranking completo. Podemos recuperar la clasificación como yij = 8 >>>< >>>: 0 si i = j sign(si − sj) si di, dj relevancia igual signo(oj − i − 0.5) si di = dx i , dj = d¯x j signo(j − oi + 0.5) si di = d¯x i , dj = dx j. (7) Ahora podemos reformular H en una nueva función objetivo, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), donde ¯y es la verdadera clasificación (débil). Conceptualmente, H comienza con una clasificación perfecta ¯y y agrega el cambio en H cuando cada documento no relevante sucesivo sube en la clasificación. Luego podemos reformular el problema argmax H como argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) sujeto a o1 ≤ . . . ≤ o|C¯x|. (9) El Algoritmo 2 describe el algoritmo utilizado para resolver la ecuación (8). Conceptualmente, el Algoritmo 2 comienza con un ranking perfecto. Entonces, para cada documento no relevante sucesivo, el algoritmo modifica la solución deslizando ese documento hacia arriba en la clasificación para maximizar localmente H, manteniendo las posiciones de los otros documentos no relevantes constantes. 3.2.1 Prueba de Corrección El Algoritmo 2 es codicioso en el sentido de que encuentra la mejor posición de cada documento no relevante de forma independiente de los otros documentos no relevantes. En otras palabras, el algoritmo maximiza H para cada documento no relevante, d¯x j, Algoritmo 2 Encontrar la Restricción Más Violada (argmax H) para el Algoritmo 1 con ∆map 1: Entrada: w, Cx, C¯x 2: ordenar Cx y C¯x en orden descendente de wT φ(x, d) 3: sx i ← wT φ(x, dx i), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i), i = 1, . . . , |C¯x | 5: para j = 1, . . . , |C¯x | hacer 6: optj ← argmaxk δj(k, |Cx| + 1) 7: fin para 8: codificar ˆy de acuerdo con (7) 9: devolver ˆy sin considerar las posiciones de los otros documentos no relevantes, y así ignora las restricciones de (9). Para que la solución sea factible, el documento no relevante j-ésimo debe ser clasificado después de los primeros j-1 documentos no relevantes, satisfaciendo así opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. Si la solución es factible, entonces claramente resuelve (8). Por lo tanto, basta con demostrar que el Algoritmo 2 cumple con (10). Primero demostramos que δj(·, ·) es monótonamente decreciente en j. Lema 1. Para cualquier 1 ≤ i1 < i2 ≤ |Cx | + 1 y 1 ≤ j < |C¯x |, debe ser el caso que δj+1(i1, i2) ≤ δj(i1, i2). Prueba. Recuerde que tanto δj(i1, i2) como δj+1(i1, i2) son sumas de términos i2 − i1. Mostraremos que cada término en la suma de δj+1(i1, i2) no es mayor que el término correspondiente en δj(i1, i2), o δj+1(k, k + 1) ≤ δj(k, k + 1) para k = i1, . . . , i2 − 1. Cada término en δj(k, k +1) y δj+1(k, k +1) puede ser descompuesto aún más en dos partes (ver (5)). Mostraremos que cada parte de δj+1(k, k + 1) no es mayor que la parte correspondiente en δj(k, k + 1). En otras palabras, demostraremos que tanto j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) como −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) son verdaderos para los valores mencionados de j y k. Es fácil ver que (11) es verdadero observando que para cualquier par de enteros positivos 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1, y eligiendo a = j y b = j + k. La segunda desigualdad (12) se cumple porque el Algoritmo 2 primero ordena d¯x en orden descendente de s¯x, lo que implica s¯x j+1 ≤ s¯x j. Así vemos que cada término en δj+1 no es mayor que el término correspondiente en δj, lo cual completa la prueba. El resultado del Lema 1 conduce directamente a nuestro resultado principal de corrección: Teorema 2. En el Algoritmo 2, los valores calculados de optj satisfacen (10), lo que implica que la solución devuelta por el Algoritmo 2 es factible y, por lo tanto, óptima. Prueba. Demostraremos que optj ≤ optj+1 se cumple para cualquier 1 ≤ j < |C¯x|, implicando así (10). Dado que el Algoritmo 2 calcula optj como optj = argmax k δj(k, |Cx | + 1), (13), entonces por definición de δj (6), para cualquier 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0. Usando el Lema 1, sabemos que δj+1(i, optj) ≤ δj(i, optj) < 0, lo que implica que para cualquier 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0. Supongamos por contradicción que optj+1 < optj. Entonces δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), lo cual contradice (13). Por lo tanto, debe ser el caso que optj ≤ optj+1, lo cual completa la prueba. 3.2.2 Tiempo de ejecución El tiempo de ejecución del Algoritmo 2 se puede dividir en dos partes. La primera parte es la clasificación por wT φ(x, d), lo cual requiere un tiempo de O(n log n), donde n = |Cx | + |C¯x |. La segunda parte calcula cada optj, lo cual requiere un tiempo de O(|Cx| · |C¯x|). Aunque en el peor de los casos esto es O(n2), el número de documentos relevantes, |Cx|, suele ser muy pequeño (por ejemplo, constante con respecto a n), en cuyo caso el tiempo de ejecución para la segunda parte es simplemente O(n). Para la mayoría de los conjuntos de datos del mundo real, el Algoritmo 2 está dominado por la ordenación y tiene una complejidad O(n log n). El Algoritmo 1 está garantizado de detenerse en un número polinómico de iteraciones [19], y cada iteración ejecuta el Algoritmo 2. Prácticamente todos los modelos que funcionaron bien fueron entrenados en un tiempo razonable (generalmente menos de una hora). Una vez que el entrenamiento esté completo, hacer predicciones sobre la consulta x usando la hipótesis resultante h(x|w) solo requiere ordenar por wT φ(x, d). Desarrollamos nuestro software utilizando una interfaz de Python a SVMstruct, ya que el lenguaje Python simplificó en gran medida el proceso de codificación. Para mejorar el rendimiento, es recomendable utilizar la implementación estándar en C de SVMstruct. CONFIGURACIÓN DEL EXPERIMENTO El objetivo principal de nuestros experimentos es evaluar si la optimización directa de MAP conduce a un rendimiento de MAP mejorado en comparación con los métodos convencionales de SVM que optimizan una pérdida sustituta como la precisión o el área bajo la curva ROC. Evaluamos empíricamente nuestro método utilizando dos conjuntos de consultas de la TREC Web Track, uno de TREC 9 y otro de TREC 10 (temas 451-500 y 501-550), ambos de los cuales utilizaron el corpus WT10g. Para cada consulta, TREC proporciona las evaluaciones de relevancia de los documentos. Generamos nuestras características utilizando las puntuaciones de las funciones de recuperación existentes en estas consultas. Si bien nuestro método es agnóstico al significado de las características, elegimos utilizar funciones de recuperación existentes como una forma simple pero efectiva de adquirir características útiles. Por lo tanto, nuestros experimentos de estadísticas de conjuntos de datos básicos esencialmente prueban la capacidad de nuestros métodos para volver a clasificar los documentos altamente clasificados (por ejemplo, volver a combinar las puntuaciones de las funciones de recuperación) para mejorar el MAP. Comparamos nuestro método con las mejores funciones de recuperación entrenadas (en adelante, funciones base), así como con los métodos SVM propuestos anteriormente. Comparar con las mejores funciones base pone a prueba la capacidad de nuestros métodos para aprender una combinación útil. Comparar con métodos SVM anteriores nos permite probar si optimizar directamente para el MAP (en lugar de precisión o área bajo la curva ROC) logra una puntuación de MAP más alta en la práctica. El resto de esta sección describe las funciones base y el método de generación de características en detalle. 4.1 Elección de Funciones de Recuperación Elegimos dos conjuntos de funciones base para nuestros experimentos. Para el primer conjunto, generamos tres índices sobre el corpus WT10g utilizando Indri5. El primer índice fue generado utilizando la configuración predeterminada, el segundo utilizó Porter-stemming, y el último utilizó Porter-stemming y las palabras vacías predeterminadas de Indris. Para TREC 9 y TREC 10, utilizamos la parte de descripción de cada consulta y puntuamos los documentos utilizando cinco de los métodos de recuperación integrados en Indri, que son Similitud Coseno, TFIDF, Okapi, Modelo de Lenguaje con Prior de Dirichlet y Modelo de Lenguaje con Prior de Jelinek-Mercer. Todos los parámetros se mantuvieron en sus valores predeterminados. Calculamos las puntuaciones de estos cinco métodos de recuperación sobre los tres índices, dando un total de 15 funciones base. Para cada consulta, consideramos las puntuaciones de los documentos encontrados en la unión de los mejores 1000 documentos de cada función base. Para nuestro segundo conjunto de funciones base, utilizamos puntuaciones de las presentaciones de la pista web TREC 9 [8] y TREC 10 [9]. Utilizamos solo las presentaciones no manuales y no breves de ambos años. Para TREC 9 y TREC 10, hubo 53 y 18 envíos de este tipo, respectivamente. Una presentación típica contenía puntajes de sus 1000 documentos principales. b ca wT φ(x,d) f(d|x) Figura 2: Ejemplo de Agrupación de Características 4.2 Generación de Características Para generar ejemplos de entrada para nuestro método, se debe proporcionar una instancia concreta de φ. Para cada documento d puntuado por un conjunto de funciones de recuperación F en la consulta x, generamos las características como un vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf, donde f(d|x) denota la puntuación que la función de recuperación f asigna al documento d para la consulta x, y cada Kf es un conjunto de valores reales. Desde un nivel alto, estamos expresando la puntuación de cada función de recuperación utilizando |Kf | + 1 contenedores. Dado que estamos utilizando núcleos lineales, se puede pensar en el problema de aprendizaje como encontrar una buena combinación de piezas constantes de los puntajes de las funciones de recuperación. La Figura 2 muestra un ejemplo de nuestro método de mapeo de características. En este ejemplo tenemos una única característica F = {f}. Aquí, Kf = {a, b, c}, y el vector de pesos es w = wa, wb, wc. Para cualquier documento d y consulta x, tenemos wT φ(x, d) = 8 >>< >>: 0 si f(d|x) < a wa si a ≤ f(d|x) < b wa + wb si b ≤ f(d|x) < c wa + wb + wc si c ≤ f(d|x) . Esto se expresa cualitativamente en la Figura 2, donde wa y wb son positivos, y wc es negativo. Realizamos nuestros experimentos principales utilizando cuatro opciones de F: el conjunto de las funciones de recuperación de Indri mencionadas anteriormente para TREC 9 y TREC 10, y las presentaciones de la pista web para TREC 9 y TREC 10. Para cada F y cada función f ∈ F, elegimos 50 valores para Kf que estuvieran razonablemente espaciados y capturaran la región sensible de f. Utilizando las cuatro opciones de F, generamos cuatro conjuntos de datos para nuestros experimentos principales. La Tabla 5 contiene estadísticas de los conjuntos de datos generados. Hay muchas formas de generar características, y no estamos abogando por nuestro método sobre los demás. Esto fue simplemente un medio eficiente para normalizar las salidas de diferentes funciones y permitir un modelo más expresivo. EXPERIMENTOS Para cada conjunto de datos en la Tabla 5, realizamos 50 pruebas. Para cada prueba, entrenamos con 10 consultas seleccionadas al azar, y seleccionamos otras 5 consultas al azar para un conjunto de validación. Los modelos fueron entrenados utilizando una amplia gama de valores de C. El modelo que tuvo mejor rendimiento en el conjunto de validación fue seleccionado y probado en las 35 consultas restantes. Todas las consultas fueron seleccionadas para estar en los conjuntos de entrenamiento, validación y prueba la misma cantidad de veces. Utilizando esta configuración, realizamos los mismos experimentos mientras usábamos nuestro método (mapa SVM∆), un SVM optimizando para ROCArea (SVM∆ roc) [13], y un SVM de clasificación convencional (SVMacc) [20]. Todos los métodos de SVM utilizaron un kernel lineal. Informamos sobre el rendimiento promedio de todos los modelos en las 50 pruebas. 5.1 Comparación con Funciones Base Al analizar nuestros resultados, la primera pregunta a responder es, ¿puede SVM∆ map aprender un modelo que supere al mejor modelo base TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.290 - 0.287Mejor Func. 0.280 28/22 0.283 29/21 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 36/14 ** Tabla 7: Comparación con Envíos TREC TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288Mejor Func. 0.280 27/23 0.283 31/19 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 35/15 ** Tabla 8: Comparación con Funciones de Envíos TREC (sin el mejor) La Tabla 6 presenta la comparación del mapa SVM∆ con las mejores funciones base de Indri. Cada grupo de columnas contiene el rendimiento del MAP macro-promediado de SVM∆ map o una función base. Las columnas W/L muestran el número de consultas donde SVM∆ map logró un puntaje MAP más alto. Se realizaron pruebas de significancia utilizando la prueba de rango con signo de Wilcoxon de dos colas. Dos estrellas indican un nivel de significancia de 0.95. Todas las tablas que muestran nuestros resultados experimentales están estructuradas de manera idéntica. Aquí encontramos que SVM∆ mapea significativamente mejor que las mejores funciones base. La Tabla 7 muestra la comparación cuando se entrena con las presentaciones de TREC. Si bien logra una puntuación de MAP más alta que las mejores funciones base, la diferencia de rendimiento entre SVM∆ y las funciones base no es significativa. Dado que muchas de estas presentaciones utilizan funciones de puntuación cuidadosamente diseñadas para lograr un alto MAP, es posible que las presentaciones con mejor rendimiento utilicen técnicas que engloben las técnicas de las otras presentaciones. Como resultado, el mapa SVM∆ no sería capaz de aprender una hipótesis que pueda superar significativamente la mejor presentación. Por lo tanto, realizamos los mismos experimentos utilizando un conjunto de datos modificado en el que se eliminaron las características calculadas utilizando la mejor presentación. La tabla 8 muestra los resultados (ten en cuenta que aún estamos comparando con la mejor presentación, aunque no la estamos utilizando para el entrenamiento). Observa que si bien el rendimiento del SVM∆ map se degradó ligeramente, aún era comparable con el de la mejor presentación. 5.2 Comparación con Métodos SVM Anteriores La siguiente pregunta a responder es, ¿produce el SVM∆ map puntajes MAP más altos que los métodos SVM anteriores? Las tablas 9 y 10 presentan los resultados de SVM∆ map, SVM∆ roc y SVMacc cuando se entrenan con las funciones de recuperación de Indri y las presentaciones de TREC, respectivamente. La Tabla 11 contiene los resultados correspondientes cuando se entrena con las presentaciones de TREC sin la mejor presentación. Para empezar, nuestros resultados indican que SVMacc no fue competitivo con SVM∆ map y SVM∆ roc, y a veces tuvo un rendimiento notablemente inferior. Por lo tanto, probamos varios enfoques para mejorar el rendimiento de SVMacc. 5.2.1 Métodos alternativos de SVMacc Un problema que puede causar que SVMacc tenga un rendimiento deficiente es el desequilibrio severo entre documentos relevantes y no relevantes. La gran mayoría de los documentos no son relevantes. SVMacc2 aborda este problema asignando una penalización mayor a los errores de falsos negativos. Para cada conjunto de datos, la proporción de las penalizaciones por falsos negativos a falsos positivos es igual a la proporción entre el número de documentos no relevantes y relevantes en ese conjunto de datos. Las tablas 9, 10 y 11 indican que SVMacc2 sigue teniendo un rendimiento significativamente peor que SVM∆ map. Otro posible problema es que SVMacc intenta encontrar solo un umbral discriminatorio b que sea invariable a la consulta. Puede ser que diferentes consultas requieran diferentes valores de b. Tener el método de aprendizaje intentando encontrar un buen valor de b (cuando no existe) puede ser perjudicial. Tomamos dos enfoques para abordar este problema. El primer método, SVMacc3, convierte las puntuaciones de la función de recuperación en percentiles. Por ejemplo, para el documento d, la consulta q y la función de recuperación f, si la puntuación f(d|q) se encuentra en el 90% superior de las puntuaciones f(·|q) para la consulta q, entonces la puntuación convertida es f(d|q) = 0.9. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Las tablas 9, 10 y 11 muestran que el rendimiento de SVMacc3 tampoco fue competitivo con SVM∆ map. El segundo método, SVMacc4, normaliza las puntuaciones dadas por f para cada consulta. Por ejemplo, suponga para la consulta q que f produce puntuaciones en el rango de 0.2 a 0.7. Entonces, para el documento d, si f(d|q) = 0.6, la puntuación convertida sería f(d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Nuevamente, las Tablas 9, 10 y 11 muestran que SVMacc4 no fue competitivo con SVM∆ map 5.2.2 MAP vs ROCArea. SVM∆ roc tuvo un rendimiento mucho mejor que SVMacc en nuestros experimentos. Cuando se entrenó con las funciones de recuperación de Indri (ver Tabla 9), el rendimiento de SVM∆ roc fue ligeramente, aunque no significativamente, peor que el rendimiento de SVM∆ map. Sin embargo, la Tabla 10 muestra que el mapa SVM∆ superó significativamente al roc SVM∆ cuando se entrenó con las presentaciones de TREC. La tabla 11 muestra el rendimiento de los modelos cuando se entrenan con las presentaciones de TREC y se elimina la mejor presentación. El rendimiento de la mayoría de los modelos se degradó ligeramente, con SVM∆ map aún teniendo el mejor rendimiento. TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288 SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Tabla 11: Entrenado en TREC Subm. (sin Mejor) 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado un método SVM que optimiza directamente el MAP. Proporciona un enfoque basado en principios y evita heurísticas difíciles de controlar. Formulamos el problema de optimización y presentamos un algoritmo que encuentra la solución de manera demostrable en tiempo polinómico. Hemos demostrado empíricamente que nuestro método es generalmente superior o competitivo con los métodos convencionales de SVM. Nuestro nuevo método hace que sea conceptualmente tan fácil optimizar SVMs para MAP como anteriormente solo era posible para Precisión y Área bajo la curva ROC. El costo computacional para el entrenamiento es muy razonable en la práctica. Dado que otros métodos suelen requerir ajustar múltiples heurísticas, también esperamos entrenar menos modelos antes de encontrar uno que logre un buen rendimiento. El marco de aprendizaje utilizado por nuestro método es bastante general. Una extensión natural de este marco sería desarrollar métodos para optimizar otras medidas importantes de IR, como la Ganancia Acumulada Normalizada Descontada [2, 3, 4, 12] y la Reciprocidad Media de Rango. 7. AGRADECIMIENTOS Este trabajo fue financiado bajo el Premio NSF IIS-0412894, el Premio NSF CAREER 0237381 y un obsequio de Yahoo! Investigación. El tercer autor también fue parcialmente apoyado por una Beca de Investigación de Microsoft. 8. REFERENCIAS [1] B. T. Bartell, G. W. Cottrell y R. K. Belew. Combinación automática de múltiples sistemas de recuperación clasificados. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2005. [3] C. J. C. Burges, R. Ragno y Q. Lo. Aprendizaje para clasificar con funciones de costo no suaves. En Actas de la Conferencia Internacional sobre Avances en Sistemas de Información Neural (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang y H.-W. Hon. Adaptando el SVM de clasificación para la recuperación de documentos. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [5] B. Carterette y D. Petkova. Aprendiendo un ranking a partir de preferencias por pares. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew y A. Ksikes. Selección de conjunto de bibliotecas de modelos. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [7] J. Davis y M. Goadrich. La relación entre las curvas de precisión-recall y ROC. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2006. [8] D. Hawking. Resumen de la pista web TREC-9. En Actas de TREC-2000, 2000. [9] D. Hawking y N. Craswell. Resumen de la pista web TREC-2001. En Actas de TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel y K. Obermayer. Límites de rango de margen amplio para regresión ordinal. Avances en clasificadores de márgenes amplios, 2000. [11] A. Herschtal y B. Raskutti. Optimizando el área bajo la curva ROC utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [12] K. Jarvelin y J. Kekalainen. Métodos de evaluación para recuperar documentos altamente relevantes. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2000. [13] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), páginas 377-384, Nueva York, NY, EE. UU., 2005. ACM Press. [14] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), páginas 111-119, 2001. [15] Y. Lin, Y. Lee y G. Wahba. Máquinas de vectores de soporte para clasificación en situaciones no estándar. Aprendizaje automático, 46:191-202, 2002. [16] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [17] K. Morik, P. Brockhausen y T. Joachims. Combinando el aprendizaje estadístico con un enfoque basado en el conocimiento. En Actas de la Conferencia Internacional sobre Aprendizaje Automático, 1999. [18] S. Robertson. El principio de clasificación de probabilidad en la revista IR de documentación. Revista de Documentación, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims y Y. Altun. Métodos de margen amplio para variables de salida estructuradas e interdependientes. Revista de Investigación en Aprendizaje Automático (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik. Teoría del Aprendizaje Estadístico. Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz. \n\nWiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer y R. Wolniewicz. Optimizando el rendimiento del clasificador mediante la aproximación a la estadística de Wilcoxon-Mann-Witney. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2003.",
    "original_sentences": [
        "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT Machine learning is commonly used to improve ranked retrieval systems.",
        "Due to computational difficulties, few learning techniques have been developed to directly optimize for mean average precision (MAP), despite its widespread use in evaluating such systems.",
        "Existing approaches optimizing MAP either do not find a globally optimal solution, or are computationally expensive.",
        "In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of MAP.",
        "We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora (WT10g), comparing against SVMs optimized for accuracy and ROCArea.",
        "In most cases we show our method to produce statistically significant improvements in MAP scores.",
        "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval Models General Terms Algorithm, Theory, Experimentation 1.",
        "INTRODUCTION State of the art information retrieval systems commonly use machine learning techniques to learn ranking functions.",
        "However, most current approaches do not optimize for the evaluation measure most often used, namely Mean Average Precision (MAP).",
        "Instead, current algorithms tend to take one of two general approaches.",
        "The first approach is to learn a model that estimates the probability of a document being relevant given a query (e.g., [18, 14]).",
        "If solved effectively, the ranking with best MAP performance can easily be derived from the probabilities of relevance.",
        "However, achieving high MAP only requires finding a good ordering of the documents.",
        "As a result, finding good probabilities requires solving a more difficult problem than necessary, likely requiring more training data to achieve the same MAP performance.",
        "The second common approach is to learn a function that maximizes a surrogate measure.",
        "Performance measures optimized include accuracy [17, 15], ROCArea [1, 5, 10, 11, 13, 21] or modifications of ROCArea [4], and NDCG [2, 3].",
        "Learning a model to optimize for such measures might result in suboptimal MAP performance.",
        "In fact, although some previous systems have obtained good MAP performance, it is known that neither achieving optimal accuracy nor ROCArea can guarantee optimal MAP performance[7].",
        "In this paper, we present a general approach for learning ranking functions that maximize MAP performance.",
        "Specifically, we present an SVM algorithm that globally optimizes a hinge-loss relaxation of MAP.",
        "This approach simplifies the process of obtaining ranking functions with high MAP performance by avoiding additional intermediate steps and heuristics.",
        "The new algorithm also makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for accuracy and ROCArea.",
        "In contrast to recent work directly optimizing for MAP performance by Metzler & Croft [16] and Caruana et al. [6], our technique is computationally efficient while finding a globally optimal solution.",
        "Like [6, 16], our method learns a linear model, but is much more efficient in practice and, unlike [16], can handle many thousands of features.",
        "We now describe the algorithm in detail and provide proof of correctness.",
        "Following this, we provide an analysis of running time.",
        "We finish with empirical results from experiments on the TREC 9 and TREC 10 Web Track corpus.",
        "We have also developed a software package implementing our algorithm that is available for public use1 . 2.",
        "THE LEARNING PROBLEM Following the standard machine learning setup, our goal is to learn a function h : X → Y between an input space X (all possible queries) and output space Y (rankings over a corpus).",
        "In order to quantify the quality of a prediction, ˆy = h(x), we will consider a loss function ∆ : Y × Y → . ∆(y, ˆy) quantifies the penalty for making prediction ˆy if the correct output is y.",
        "The loss function allows us to incorporate specific performance measures, which we will exploit 1 http://svmrank.yisongyue.com for optimizing MAP.",
        "We restrict ourselves to the supervised learning scenario, where input/output pairs (x, y) are available for training and are assumed to come from some fixed distribution P(x, y).",
        "The goal is to find a function h such that the risk (i.e., expected loss), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), is minimized.",
        "Of course, P(x, y) is unknown.",
        "But given a finite set of training pairs, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, the performance of h on S can be measured by the empirical risk, R∆ S (h) = 1 n nX i=1 ∆(yi, h(xi)).",
        "In the case of learning a ranked retrieval function, X denotes a space of queries, and Y the space of (possibly weak) rankings over some corpus of documents C = {d1, . . . ,d|C|}.",
        "We can define average precision loss as ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), where rank(y) is a vector of the rank values of each document in C. For example, for a corpus of two documents, {d1, d2}, with d1 having higher rank than d2, rank(y ) = (1, 0).",
        "We assume true rankings have two rank values, where relevant documents have rank value 1 and non-relevant documents rank value 0.",
        "We further assume that all predicted rankings are complete rankings (no ties).",
        "Let p = rank(y) and ˆp = rank(ˆy).",
        "The average precision score is defined as MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, where rel = |{i : pi = 1}| is the number of relevant documents, and Prec@j is the percentage of relevant documents in the top j documents in predicted ranking ˆy.",
        "MAP is the mean of the average precision scores of a group of queries. 2.1 MAP vs ROCArea Most learning algorithms optimize for accuracy or ROCArea.",
        "While optimizing for these measures might achieve good MAP performance, we use two simple examples to show it can also be suboptimal in terms of MAP.",
        "ROCArea assigns equal penalty to each misordering of a relevant/non-relevant pair.",
        "In contrast, MAP assigns greater penalties to misorderings higher up in the predicted ranking.",
        "Using our notation, ROCArea can be defined as ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], where p is the true (weak) ranking, ˆp is the predicted ranking, and 1[b] is the indicator function conditioned on b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Table 1: Toy Example and Models Suppose we have a hypothesis space with only two hypothesis functions, h1 and h2, as shown in Table 1.",
        "These two hypotheses predict a ranking for query x over a corpus of eight documents.",
        "Hypothesis MAP ROCArea h1(x) 0.59 0.47 h2(x) 0.51 0.53 Table 2: Performance of Toy Models Table 2 shows the MAP and ROCArea scores of h1 and h2.",
        "Here, a learning method which optimizes for ROCArea would choose h2 since that results in a higher ROCArea score, but this yields a suboptimal MAP score. 2.2 MAP vs Accuracy Using a very similar example, we now demonstrate how optimizing for accuracy might result in suboptimal MAP.",
        "Models which optimize for accuracy are not directly concerned with the ranking.",
        "Instead, they learn a threshold such that documents scoring higher than the threshold can be classified as relevant and documents scoring lower as nonrelevant.",
        "Doc ID 1 2 3 4 5 6 7 8 9 10 11 p 1 0 0 0 0 1 1 1 1 0 0 rank(h1(x)) 11 10 9 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 9 10 11 Table 3: Toy Example and Models We consider again a hypothesis space with two hypotheses.",
        "Table 3 shows the predictions of the two hypotheses on a single query x. Hypothesis MAP Best Acc. h1(q) 0.70 0.64 h2(q) 0.64 0.73 Table 4: Performance of Toy Models Table 4 shows the MAP and best accuracy scores of h1(q) and h2(q).",
        "The best accuracy refers to the highest achievable accuracy on that ranking when considering all possible thresholds.",
        "For instance, with h1(q), a threshold between documents 1 and 2 gives 4 errors (documents 6-9 incorrectly classified as non-relevant), yielding an accuracy of 0.64.",
        "Similarly, with h2(q), a threshold between documents 5 and 6 gives 3 errors (documents 10-11 incorrectly classified as relevant, and document 1 as non-relevant), yielding an accuracy of 0.73.",
        "A learning method which optimizes for accuracy would choose h2 since that results in a higher accuracy score, but this yields a suboptimal MAP score. 3.",
        "OPTIMIZING AVERAGE PRECISION We build upon the approach used by [13] for optimizing ROCArea.",
        "Unlike ROCArea, however, MAP does not decompose linearly in the examples and requires a substantially extended algorithm, which we describe in this section.",
        "Recall that the true ranking is a weak ranking with two rank values (relevant and non-relevant).",
        "Let Cx and C¯x denote the set of relevant and non-relevant documents of C for query x, respectively.",
        "We focus on functions which are parametrized by a weight vector w, and thus wish to find w to minimize the empirical risk, R∆ S (w) ≡ R∆ S (h(·; w)).",
        "Our approach is to learn a discriminant function F : X × Y → over input-output pairs.",
        "Given query x, we can derive a prediction by finding the ranking y that maximizes the discriminant function: h(x; w) = argmax y∈Y F(x, y; w). (1) We assume F to be linear in some combined feature representation of inputs and outputs Ψ(x, y) ∈ RN , i.e., F(x, y; w) = wT Ψ(x, y). (2) The combined feature function we use is Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))] , where φ : X × C → N is a feature mapping function from a query/document pair to a point in N dimensional space2 .",
        "We represent rankings as a matrix of pairwise orderings, Y ⊂ {−1, 0, +1}|C|×|C| .",
        "For any y ∈ Y, yij = +1 if di is ranked ahead of dj, and yij = −1 if dj is ranked ahead of di, and yij = 0 if di and dj have equal rank.",
        "We consider only matrices which correspond to valid rankings (i.e, obeying antisymmetry and transitivity).",
        "Intuitively, Ψ is a summation over the vector differences of all relevant/non-relevant document pairings.",
        "Since we assume predicted rankings to be complete rankings, yij is either +1 or −1 (never 0).",
        "Given a learned weight vector w, predicting a ranking (i.e. solving equation (1)) given query x reduces to picking each yij to maximize wT Ψ(x, y).",
        "As is also discussed in [13], this is attained by sorting the documents by wT φ(x, d) in descending order.",
        "We will discuss later the choices of φ we used for our experiments. 3.1 Structural SVMs The above formulation is very similar to learning a straightforward linear model while training on the pairwise difference of relevant/non-relevant document pairings.",
        "Many SVM-based approaches optimize over these pairwise differences (e.g., [5, 10, 13, 4]), although these methods do not optimize for MAP during training.",
        "Previously, it was not clear how to incorporate non-linear multivariate loss functions such as MAP loss directly into global optimization problems such as SVM training.",
        "We now present a method based on structural SVMs [19] to address this problem.",
        "We use the structural SVM formulation, presented in Optimization Problem 1, to learn a w ∈ RN .",
        "Optimization Problem 1. (Structural SVM) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) The objective function to be minimized (3) is a tradeoff between model complexity, w 2 , and a hinge loss relaxation of MAP loss, P ξi.",
        "As is usual in SVM training, C is a 2 For example, one dimension might be the number of times the query words appear in the document.",
        "Algorithm 1 Cutting plane algorithm for solving OP 1 within tolerance . 1: Input: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ for all i = 1, . . . , n 3: repeat 4: for i = 1, . . . , n do 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: compute ˆy = argmaxy∈Y H(y; w) 7: compute ξi = max{0, maxy∈Wi H(y; w)} 8: if H(ˆy; w) > ξi + then 9: Wi ← Wi ∪ {ˆy} 10: w ← optimize (3) over W = S i Wi 11: end if 12: end for 13: until no Wi has changed during iteration parameter that controls this tradeoff and can be tuned to achieve good performance in different training tasks.",
        "For each (xi, yi) in the training set, a set of constraints of the form in equation (4) is added to the optimization problem.",
        "Note that wT Ψ(x, y) is exactly our discriminant function F(x, y; w) (see equation (2)).",
        "During prediction, our model chooses the ranking which maximizes the discriminant (1).",
        "If the discriminant value for an incorrect ranking y is greater than for the true ranking yi (e.g., F(xi, y; w) > F(xi, yi; w)), then corresponding slack variable, ξi, must be at least ∆(yi, y) for that constraint to be satisfied.",
        "Therefore, the sum of slacks, P ξi, upper bounds the MAP loss.",
        "This is stated formally in Proposition 1.",
        "Proposition 1.",
        "Let ξ∗ (w) be the optimal solution of the slack variables for OP 1 for a given weight vector w. Then 1 n Pn i=1 ξi is an upper bound on the empirical risk R∆ S (w). (see [19] for proof) Proposition 1 shows that OP 1 learns a ranking function that optimizes an upper bound on MAP error on the training set.",
        "Unfortunately there is a problem: a constraint is required for every possible wrong output y, and the number of possible wrong outputs is exponential in the size of C. Fortunately, we may employ Algorithm 1 to solve OP 1.",
        "Algorithm 1 is a cutting plane algorithm, iteratively introducing constraints until we have solved the original problem within a desired tolerance [19].",
        "The algorithm starts with no constraints, and iteratively finds for each example (xi, yi) the output ˆy associated with the most violated constraint.",
        "If the corresponding constraint is violated by more than we introduce ˆy into the working set Wi of active constraints for example i, and re-solve (3) using the updated W. It can be shown that Algorithm 1s outer loop is guaranteed to halt within a polynomial number of iterations for any desired precision .",
        "Theorem 1.",
        "Let ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y) , ¯∆ = maxi maxy ∆(yi, y), and for any > 0, Algorithm 1 terminates after adding at most max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff constraints to the working set W. (see [19] for proof) However, within the inner loop of this algorithm we have to compute argmaxy∈Y H(y; w), where H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), or equivalently, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), since wT Ψ(xi, yi) is constant with respect to y.",
        "Though closely related to the classification procedure, this has the substantial complication that we must contend with the additional ∆(yi, y) term.",
        "Without the ability to efficiently find the most violated constraint (i.e., solve argmaxy∈Y H(y, w)), the constraint generation procedure is not tractable. 3.2 Finding the Most Violated Constraint Using OP 1 and optimizing to ROCArea loss (∆roc), the problem of finding the most violated constraint, or solving argmaxy∈Y H(y, w) (henceforth argmax H), is addressed in [13].",
        "Solving argmax H for ∆map is more difficult.",
        "This is primarily because ROCArea decomposes nicely into a sum of scores computed independently on each relative ordering of a relevant/non-relevant document pair.",
        "MAP, on the other hand, does not decompose in the same way as ROCArea.",
        "The main algorithmic contribution of this paper is an efficient method for solving argmax H for ∆map.",
        "One useful property of ∆map is that it is invariant to swapping two documents with equal relevance.",
        "For example, if documents da and db are both relevant, then swapping the positions of da and db in any ranking does not affect ∆map.",
        "By extension, ∆map is invariant to any arbitrary permutation of the relevant documents amongst themselves and of the non-relevant documents amongst themselves.",
        "However, this reshuﬄing will affect the discriminant score, wT Ψ(x, y).",
        "This leads us to Observation 1.",
        "Observation 1.",
        "Consider rankings which are constrained by fixing the relevance at each position in the ranking (e.g., the 3rd document in the ranking must be relevant).",
        "Every ranking which satisfies the same set of constraints will have the same ∆map.",
        "If the relevant documents are sorted by wT φ(x, d) in descending order, and the non-relevant documents are likewise sorted by wT φ(x, d), then the interleaving of the two sorted lists which satisfies the constraints will maximize H for that constrained set of rankings.",
        "Observation 1 implies that in the ranking which maximizes H, the relevant documents will be sorted by wT φ(x, d), and the non-relevant documents will also be sorted likewise.",
        "By first sorting the relevant and non-relevant documents, the problem is simplified to finding the optimal interleaving of two sorted lists.",
        "For the rest of our discussion, we assume that the relevant documents and non-relevant documents are both sorted by descending wT φ(x, d).",
        "For convenience, we also refer to relevant documents as {dx 1 , . . . dx |Cx|} = Cx , and non-relevant documents as {d¯x 1 , . . . d¯x |C¯x|} = C¯x .",
        "We define δj(i1, i2), with i1 < i2, as the change in H from when the highest ranked relevant document ranked after d¯x j is dx i1 to when it is dx i2 .",
        "For i2 = i1 + 1, we have δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5) where si = wT φ(x, di).",
        "The first term in (5) is the change in ∆map when the ith relevant document has j non-relevant documents ranked before it, as opposed to j −1.",
        "The second term is the change in the discriminant score, wT Ψ(x, y), when yij changes from +1 to −1. . . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . .",
        "Figure 1: Example for δj(i, i + 1) Figure 1 gives a conceptual example for δj(i, i + 1).",
        "The bottom ranking differs from the top only where d¯x j slides up one rank.",
        "The difference in the value of H for these two rankings is exactly δj(i, i + 1).",
        "For any i1 < i2, we can then define δj(i1, i2) as δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) or equivalently, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) .",
        "Let o1, . . . , o|C¯x| encode the positions of the non-relevant documents, where dx oj is the highest ranked relevant document ranked after the jth non-relevant document.",
        "Due to Observation 1, this encoding uniquely identifies a complete ranking.",
        "We can recover the ranking as yij = 8 >>>< >>>: 0 if i = j sign(si − sj) if di, dj equal relevance sign(oj − i − 0.5) if di = dx i , dj = d¯x j sign(j − oi + 0.5) if di = d¯x i , dj = dx j . (7) We can now reformulate H into a new objective function, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), where ¯y is the true (weak) ranking.",
        "Conceptually H starts with a perfect ranking ¯y, and adds the change in H when each successive non-relevant document slides up the ranking.",
        "We can then reformulate the argmax H problem as argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) s.t. o1 ≤ . . . ≤ o|C¯x|. (9) Algorithm 2 describes the algorithm used to solve equation (8).",
        "Conceptually, Algorithm 2 starts with a perfect ranking.",
        "Then for each successive non-relevant document, the algorithm modifies the solution by sliding that document up the ranking to locally maximize H while keeping the positions of the other non-relevant documents constant. 3.2.1 Proof of Correctness Algorithm 2 is greedy in the sense that it finds the best position of each non-relevant document independently from the other non-relevant documents.",
        "In other words, the algorithm maximizes H for each non-relevant document, d¯x j , Algorithm 2 Finding the Most Violated Constraint (argmax H) for Algorithm 1 with ∆map 1: Input: w, Cx , C¯x 2: sort Cx and C¯x in descending order of wT φ(x, d) 3: sx i ← wT φ(x, dx i ), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i ), i = 1, . . . , |C¯x | 5: for j = 1, . . . , |C¯x | do 6: optj ← argmaxk δj(k, |Cx | + 1) 7: end for 8: encode ˆy according to (7) 9: return ˆy without considering the positions of the other non-relevant documents, and thus ignores the constraints of (9).",
        "In order for the solution to be feasible, the jth non-relevant document must be ranked after the first j − 1 non-relevant documents, thus satisfying opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. (10) If the solution is feasible, the it clearly solves (8).",
        "Therefore, it suffices to prove that Algorithm 2 satisfies (10).",
        "We first prove that δj(·, ·) is monotonically decreasing in j. Lemma 1.",
        "For any 1 ≤ i1 < i2 ≤ |Cx | + 1 and 1 ≤ j < |C¯x |, it must be the case that δj+1(i1, i2) ≤ δj(i1, i2).",
        "Proof.",
        "Recall from (6) that both δj(i1, i2) and δj+1(i1, i2) are summations of i2 − i1 terms.",
        "We will show that each term in the summation of δj+1(i1, i2) is no greater than the corresponding term in δj(i1, i2), or δj+1(k, k + 1) ≤ δj(k, k + 1) for k = i1, . . . , i2 − 1.",
        "Each term in δj(k, k +1) and δj+1(k, k +1) can be further decomposed into two parts (see (5)).",
        "We will show that each part of δj+1(k, k + 1) is no greater than the corresponding part in δj(k, k + 1).",
        "In other words, we will show that both j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) and −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) are true for the aforementioned values of j and k. It is easy to see that (11) is true by observing that for any two positive integers 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1 , and choosing a = j and b = j + k. The second inequality (12) holds because Algorithm 2 first sorts d¯x in descending order of s¯x , implying s¯x j+1 ≤ s¯x j .",
        "Thus we see that each term in δj+1 is no greater than the corresponding term in δj, which completes the proof.",
        "The result of Lemma 1 leads directly to our main correctness result: Theorem 2.",
        "In Algorithm 2, the computed values of optj satisfy (10), implying that the solution returned by Algorithm 2 is feasible and thus optimal.",
        "Proof.",
        "We will prove that optj ≤ optj+1 holds for any 1 ≤ j < |C¯x |, thus implying (10).",
        "Since Algorithm 2 computes optj as optj = argmax k δj(k, |Cx | + 1), (13) then by definition of δj (6), for any 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0.",
        "Using Lemma 1, we know that δj+1(i, optj) ≤ δj(i, optj) < 0, which implies that for any 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0.",
        "Suppose for contradiction that optj+1 < optj.",
        "Then δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), which contradicts (13).",
        "Therefore, it must be the case that optj ≤ optj+1, which completes the proof. 3.2.2 Running Time The running time of Algorithm 2 can be split into two parts.",
        "The first part is the sort by wT φ(x, d), which requires O(n log n) time, where n = |Cx | + |C¯x |.",
        "The second part computes each optj, which requires O(|Cx | · |C¯x |) time.",
        "Though in the worst case this is O(n2 ), the number of relevant documents, |Cx |, is often very small (e.g., constant with respect to n), in which case the running time for the second part is simply O(n).",
        "For most real-world datasets, Algorithm 2 is dominated by the sort and has complexity O(n log n).",
        "Algorithm 1 is guaranteed to halt in a polynomial number of iterations [19], and each iteration runs Algorithm 2.",
        "Virtually all well-performing models were trained in a reasonable amount of time (usually less than one hour).",
        "Once training is complete, making predictions on query x using the resulting hypothesis h(x|w) requires only sorting by wT φ(x, d).",
        "We developed our software using a Python interface3 to SVMstruct , since the Python language greatly simplified the coding process.",
        "To improve performance, it is advisable to use the standard C implementation4 of SVMstruct . 4.",
        "EXPERIMENT SETUP The main goal of our experiments is to evaluate whether directly optimizing MAP leads to improved MAP performance compared to conventional SVM methods that optimize a substitute loss such as accuracy or ROCArea.",
        "We empirically evaluate our method using two sets of TREC Web Track queries, one each from TREC 9 and TREC 10 (topics 451-500 and 501-550), both of which used the WT10g corpus.",
        "For each query, TREC provides the relevance judgments of the documents.",
        "We generated our features using the scores of existing retrieval functions on these queries.",
        "While our method is agnostic to the meaning of the features, we chose to use existing retrieval functions as a simple yet effective way of acquiring useful features.",
        "As such, our 3 http://www.cs.cornell.edu/~tomf/svmpython/ 4 http://svmlight.joachims.org/svm_struct.html Dataset Base Funcs Features TREC 9 Indri 15 750 TREC 10 Indri 15 750 TREC 9 Submissions 53 2650 TREC 10 Submissions 18 900 Table 5: Dataset Statistics experiments essentially test our methods ability to re-rank the highly ranked documents (e.g., re-combine the scores of the retrieval functions) to improve MAP.",
        "We compare our method against the best retrieval functions trained on (henceforth base functions), as well as against previously proposed SVM methods.",
        "Comparing with the best base functions tests our methods ability to learn a useful combination.",
        "Comparing with previous SVM methods allows us to test whether optimizing directly for MAP (as opposed to accuracy or ROCArea) achieves a higher MAP score in practice.",
        "The rest of this section describes the base functions and the feature generation method in detail. 4.1 Choosing Retrieval Functions We chose two sets of base functions for our experiments.",
        "For the first set, we generated three indices over the WT10g corpus using Indri5 .",
        "The first index was generated using default settings, the second used Porter-stemming, and the last used Porter-stemming and Indris default stopwords.",
        "For both TREC 9 and TREC 10, we used the description portion of each query and scored the documents using five of Indris built-in retrieval methods, which are Cosine Similarity, TFIDF, Okapi, Language Model with Dirichlet Prior, and Language Model with Jelinek-Mercer Prior.",
        "All parameters were kept as their defaults.",
        "We computed the scores of these five retrieval methods over the three indices, giving 15 base functions in total.",
        "For each query, we considered the scores of documents found in the union of the top 1000 documents of each base function.",
        "For our second set of base functions, we used scores from the TREC 9 [8] and TREC 10 [9] Web Track submissions.",
        "We used only the non-manual, non-short submissions from both years.",
        "For TREC 9 and TREC 10, there were 53 and 18 such submissions, respectively.",
        "A typical submission contained scores of its top 1000 documents. b ca wT φ(x,d) f(d|x) Figure 2: Example Feature Binning 4.2 Generating Features In order to generate input examples for our method, a concrete instantiation of φ must be provided.",
        "For each doc5 http://www.lemurproject.org TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236Best Func. 0.204 39/11 ** 0.181 37/13 ** 2nd Best 0.199 38/12 ** 0.174 43/7 ** 3rd Best 0.188 34/16 ** 0.174 38/12 ** Table 6: Comparison with Indri Functions ument d scored by a set of retrieval functions F on query x, we generate the features as a vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf , where f(d|x) denotes the score that retrieval function f assigns to document d for query x, and each Kf is a set of real values.",
        "From a high level, we are expressing the score of each retrieval function using |Kf | + 1 bins.",
        "Since we are using linear kernels, one can think of the learning problem as finding a good piecewise-constant combination of the scores of the retrieval functions.",
        "Figure 2 shows an example of our feature mapping method.",
        "In this example we have a single feature F = {f}.",
        "Here, Kf = {a, b, c}, and the weight vector is w = wa, wb, wc .",
        "For any document d and query x, we have wT φ(x, d) = 8 >>< >>: 0 if f(d|x) < a wa if a ≤ f(d|x) < b wa + wb if b ≤ f(d|x) < c wa + wb + wc if c ≤ f(d|x) .",
        "This is expressed qualitatively in Figure 2, where wa and wb are positive, and wc is negative.",
        "We ran our main experiments using four choices of F: the set of aforementioned Indri retrieval functions for TREC 9 and TREC 10, and the Web Track submissions for TREC 9 and TREC 10.",
        "For each F and each function f ∈ F, we chose 50 values for Kf which are reasonably spaced and capture the sensitive region of f. Using the four choices of F, we generated four datasets for our main experiments.",
        "Table 5 contains statistics of the generated datasets.",
        "There are many ways to generate features, and we are not advocating our method over others.",
        "This was simply an efficient means to normalize the outputs of different functions and allow for a more expressive model. 5.",
        "EXPERIMENTS For each dataset in Table 5, we performed 50 trials.",
        "For each trial, we train on 10 randomly selected queries, and select another 5 queries at random for a validation set.",
        "Models were trained using a wide range of C values.",
        "The model which performed best on the validation set was selected and tested on the remaining 35 queries.",
        "All queries were selected to be in the training, validation and test sets the same number of times.",
        "Using this setup, we performed the same experiments while using our method (SVM∆ map), an SVM optimizing for ROCArea (SVM∆ roc) [13], and a conventional classification SVM (SVMacc) [20].",
        "All SVM methods used a linear kernel.",
        "We reported the average performance of all models over the 50 trials. 5.1 Comparison with Base Functions In analyzing our results, the first question to answer is, can SVM∆ map learn a model which outperforms the best base TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287Best Func. 0.280 28/22 0.283 29/21 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 36/14 ** Table 7: Comparison with TREC Submissions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288Best Func. 0.280 27/23 0.283 31/19 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 35/15 ** Table 8: Comparison with TREC Subm. (w/o best) functions?",
        "Table 6 presents the comparison of SVM∆ map with the best Indri base functions.",
        "Each column group contains the macro-averaged MAP performance of SVM∆ map or a base function.",
        "The W/L columns show the number of queries where SVM∆ map achieved a higher MAP score.",
        "Significance tests were performed using the two-tailed Wilcoxon signed rank test.",
        "Two stars indicate a significance level of 0.95.",
        "All tables displaying our experimental results are structured identically.",
        "Here, we find that SVM∆ map significantly outperforms the best base functions.",
        "Table 7 shows the comparison when trained on TREC submissions.",
        "While achieving a higher MAP score than the best base functions, the performance difference between SVM∆ map the base functions is not significant.",
        "Given that many of these submissions use scoring functions which are carefully crafted to achieve high MAP, it is possible that the best performing submissions use techniques which subsume the techniques of the other submissions.",
        "As a result, SVM∆ map would not be able to learn a hypothesis which can significantly out-perform the best submission.",
        "Hence, we ran the same experiments using a modified dataset where the features computed using the best submission were removed.",
        "Table 8 shows the results (note that we are still comparing against the best submission though we are not using it for training).",
        "Notice that while the performance of SVM∆ map degraded slightly, the performance was still comparable with that of the best submission. 5.2 Comparison w/ Previous SVM Methods The next question to answer is, does SVM∆ map produce higher MAP scores than previous SVM methods?",
        "Tables 9 and 10 present the results of SVM∆ map, SVM∆ roc, and SVMacc when trained on the Indri retrieval functions and TREC submissions, respectively.",
        "Table 11 contains the corresponding results when trained on the TREC submissions without the best submission.",
        "To start with, our results indicate that SVMacc was not competitive with SVM∆ map and SVM∆ roc, and at times underperformed dramatically.",
        "As such, we tried several approaches to improve the performance of SVMacc. 5.2.1 Alternate SVMacc Methods One issue which may cause SVMacc to underperform is the severe imbalance between relevant and non-relevant docTREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236SVM∆ roc 0.237 29/21 0.234 24/26 SVMacc 0.147 47/3 ** 0.155 47/3 ** SVMacc2 0.219 39/11 ** 0.207 43/7 ** SVMacc3 0.113 49/1 ** 0.153 45/5 ** SVMacc4 0.155 48/2 ** 0.155 48/2 ** Table 9: Trained on Indri Functions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287SVM∆ roc 0.282 29/21 0.278 35/15 ** SVMacc 0.213 49/1 ** 0.222 49/1 ** SVMacc2 0.270 34/16 ** 0.261 42/8 ** SVMacc3 0.133 50/0 ** 0.182 46/4 ** SVMacc4 0.233 47/3 ** 0.238 46/4 ** Table 10: Trained on TREC Submissions uments.",
        "The vast majority of the documents are not relevant.",
        "SVMacc2 addresses this problem by assigning more penalty to false negative errors.",
        "For each dataset, the ratio of the false negative to false positive penalties is equal to the ratio of the number non-relevant and relevant documents in that dataset.",
        "Tables 9, 10 and 11 indicate that SVMacc2 still performs significantly worse than SVM∆ map.",
        "Another possible issue is that SVMacc attempts to find just one discriminating threshold b that is query-invariant.",
        "It may be that different queries require different values of b.",
        "Having the learning method trying to find a good b value (when one does not exist) may be detrimental.",
        "We took two approaches to address this issue.",
        "The first method, SVMacc3, converts the retrieval function scores into percentiles.",
        "For example, for document d, query q and retrieval function f, if the score f(d|q) is in the top 90% of the scores f(·|q) for query q, then the converted score is f (d|q) = 0.9.",
        "Each Kf contains 50 evenly spaced values between 0 and 1.",
        "Tables 9, 10 and 11 show that the performance of SVMacc3 was also not competitive with SVM∆ map.",
        "The second method, SVMacc4, normalizes the scores given by f for each query.",
        "For example, assume for query q that f outputs scores in the range 0.2 to 0.7.",
        "Then for document d, if f(d|q) = 0.6, the converted score would be f (d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8.",
        "Each Kf contains 50 evenly spaced values between 0 and 1.",
        "Again, Tables 9, 10 and 11 show that SVMacc4 was not competitive with SVM∆ map 5.2.2 MAP vs ROCArea SVM∆ roc performed much better than SVMacc in our experiments.",
        "When trained on Indri retrieval functions (see Table 9), the performance of SVM∆ roc was slight, though not significantly, worse than the performances of SVM∆ map.",
        "However, Table 10 shows that SVM∆ map did significantly outperform SVM∆ roc when trained on the TREC submissions.",
        "Table 11 shows the performance of the models when trained on the TREC submissions with the best submission removed.",
        "The performance of most models degraded by a small amount, with SVM∆ map still having the best performance.",
        "TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Table 11: Trained on TREC Subm. (w/o Best) 6.",
        "CONCLUSIONS AND FUTURE WORK We have presented an SVM method that directly optimizes MAP.",
        "It provides a principled approach and avoids difficult to control heuristics.",
        "We formulated the optimization problem and presented an algorithm which provably finds the solution in polynomial time.",
        "We have shown empirically that our method is generally superior to or competitive with conventional SVMs methods.",
        "Our new method makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for Accuracy and ROCArea.",
        "The computational cost for training is very reasonable in practice.",
        "Since other methods typically require tuning multiple heuristics, we also expect to train fewer models before finding one which achieves good performance.",
        "The learning framework used by our method is fairly general.",
        "A natural extension of this framework would be to develop methods to optimize for other important IR measures, such as Normalized Discounted Cumulative Gain [2, 3, 4, 12] and Mean Reciprocal Rank. 7.",
        "ACKNOWLEDGMENTS This work was funded under NSF Award IIS-0412894, NSF CAREER Award 0237381, and a gift from Yahoo!",
        "Research.",
        "The third author was also partly supported by a Microsoft Research Fellowship. 8.",
        "REFERENCES [1] B. T. Bartell, G. W. Cottrell, and R. K. Belew.",
        "Automatic combination of multiple ranked retrieval systems.",
        "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
        "Learning to rank using gradient descent.",
        "In Proceedings of the International Conference on Machine Learning (ICML), 2005. [3] C. J. C. Burges, R. Ragno, and Q.",
        "Le.",
        "Learning to rank with non-smooth cost functions.",
        "In Proceedings of the International Conference on Advances in Neural Information Processing Systems (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y.",
        "Liu, H. Li, Y. Huang, and H.-W. Hon.",
        "Adapting ranking SVM to document retrieval.",
        "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [5] B. Carterette and D. Petkova.",
        "Learning a ranking from pairwise preferences.",
        "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew, and A. Ksikes.",
        "Ensemble selection from libraries of models.",
        "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [7] J. Davis and M. Goadrich.",
        "The relationship between precision-recall and ROC curves.",
        "In Proceedings of the International Conference on Machine Learning (ICML), 2006. [8] D. Hawking.",
        "Overview of the TREC-9 web track.",
        "In Proceedings of TREC-2000, 2000. [9] D. Hawking and N. Craswell.",
        "Overview of the TREC-2001 web track.",
        "In Proceedings of TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel, and K. Obermayer.",
        "Large margin rank boundaries for ordinal regression.",
        "Advances in large margin classifiers, 2000. [11] A. Herschtal and B. Raskutti.",
        "Optimising area under the ROC curve using gradient descent.",
        "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [12] K. Jarvelin and J. Kekalainen.",
        "Ir evaluation methods for retrieving highly relevant documents.",
        "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2000. [13] T. Joachims.",
        "A support vector method for multivariate performance measures.",
        "In Proceedings of the International Conference on Machine Learning (ICML), pages 377-384, New York, NY, USA, 2005.",
        "ACM Press. [14] J. Lafferty and C. Zhai.",
        "Document language models, query models, and risk minimization for information retrieval.",
        "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 111-119, 2001. [15] Y. Lin, Y. Lee, and G. Wahba.",
        "Support vector machines for classification in nonstandard situations.",
        "Machine Learning, 46:191-202, 2002. [16] D. Metzler and W. B. Croft.",
        "A markov random field model for term dependencies.",
        "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 472-479, 2005. [17] K. Morik, P. Brockhausen, and T. Joachims.",
        "Combining statistical learning with a knowledge-based approach.",
        "In Proceedings of the International Conference on Machine Learning, 1999. [18] S. Robertson.",
        "The probability ranking principle in ir. journal of documentation.",
        "Journal of Documentation, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.",
        "Large margin methods for structured and interdependent output variables.",
        "Journal of Machine Learning Research (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik.",
        "Statistical Learning Theory.",
        "Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz.",
        "Optimizing classifier performance via approximation to the Wilcoxon-Mann-Witney statistic.",
        "In Proceedings of the International Conference on Machine Learning (ICML), 2003."
    ],
    "translated_text_sentences": [
        "Un método de Vectores de Soporte para optimizar la Precisión Promedio Yisong Yue Universidad de Cornell Ithaca, NY, EE. UU. yyue@cs.cornell.edu Thomas Finley Universidad de Cornell Ithaca, NY, EE. UU. tomf@cs.cornell.edu Filip Radlinski Universidad de Cornell Ithaca, NY, EE. UU. filip@cs.cornell.edu Thorsten Joachims Universidad de Cornell Ithaca, NY, EE. UU. tj@cs.cornell.edu RESUMEN El aprendizaje automático se utiliza comúnmente para mejorar los sistemas de recuperación clasificados.",
        "Debido a dificultades computacionales, se han desarrollado pocas técnicas de aprendizaje para optimizar directamente la precisión media promedio (MAP), a pesar de su uso generalizado en la evaluación de dichos sistemas.",
        "Los enfoques existentes que optimizan el MAP no encuentran una solución óptima global o son computacionalmente costosos.",
        "Por el contrario, presentamos un algoritmo de aprendizaje SVM general que encuentra de manera eficiente una solución óptima global para una relajación directa de MAP.",
        "Evaluamos nuestro enfoque utilizando los corpus de la pista web TREC 9 y TREC 10 (WT10g), comparando con SVM optimizados para precisión y área bajo la curva ROC.",
        "En la mayoría de los casos mostramos nuestro método para producir mejoras estadísticamente significativas en las puntuaciones de MAP.",
        "Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de Recuperación Términos Generales Algoritmo, Teoría, Experimentación 1.",
        "INTRODUCCIÓN Los sistemas de recuperación de información de última generación comúnmente utilizan técnicas de aprendizaje automático para aprender funciones de clasificación.",
        "Sin embargo, la mayoría de los enfoques actuales no están optimizados para la medida de evaluación más utilizada, es decir, la Precisión Promedio Media (MAP).",
        "En cambio, los algoritmos actuales tienden a seguir uno de dos enfoques generales.",
        "El primer enfoque es aprender un modelo que estime la probabilidad de que un documento sea relevante dado una consulta (por ejemplo, [18, 14]).",
        "Si se resuelve de manera efectiva, la clasificación con el mejor rendimiento de MAP puede derivarse fácilmente de las probabilidades de relevancia.",
        "Sin embargo, lograr un MAP alto solo requiere encontrar un buen ordenamiento de los documentos.",
        "Como resultado, encontrar buenas probabilidades requiere resolver un problema más difícil de lo necesario, probablemente necesitando más datos de entrenamiento para lograr el mismo rendimiento de MAP.",
        "El segundo enfoque común es aprender una función que maximice una medida sustituta.",
        "Las medidas de rendimiento optimizadas incluyen precisión [17, 15], área bajo la curva ROC [1, 5, 10, 11, 13, 21] o modificaciones del área bajo la curva ROC [4], y NDCG [2, 3].",
        "Aprender un modelo para optimizar tales medidas podría resultar en un rendimiento de MAP subóptimo.",
        "De hecho, aunque algunos sistemas anteriores han obtenido un buen rendimiento de MAP, se sabe que ni lograr una precisión óptima ni un área bajo la curva ROC pueden garantizar un rendimiento de MAP óptimo[7].",
        "En este artículo, presentamos un enfoque general para aprender funciones de clasificación que maximizan el rendimiento de MAP.",
        "Específicamente, presentamos un algoritmo SVM que optimiza globalmente una relajación de pérdida de bisagra de MAP.",
        "Este enfoque simplifica el proceso de obtener funciones de clasificación con un alto rendimiento de MAP al evitar pasos intermedios adicionales y heurísticas.",
        "El nuevo algoritmo también hace que sea conceptualmente tan fácil optimizar las SVM para MAP como anteriormente solo era posible para precisión y ROCArea.",
        "A diferencia del trabajo reciente que optimiza directamente el rendimiento de MAP realizado por Metzler & Croft [16] y Caruana et al. [6], nuestra técnica es eficiente computacionalmente al encontrar una solución óptima a nivel global.",
        "Al igual que [6, 16], nuestro método aprende un modelo lineal, pero es mucho más eficiente en la práctica y, a diferencia de [16], puede manejar miles de características.",
        "Ahora describimos el algoritmo en detalle y proporcionamos la prueba de corrección.",
        "A continuación, proporcionamos un análisis del tiempo de ejecución.",
        "Concluimos con los resultados empíricos de experimentos en el corpus de la pista web TREC 9 y TREC 10.",
        "También hemos desarrollado un paquete de software que implementa nuestro algoritmo y está disponible para uso público.",
        "EL PROBLEMA DEL APRENDIZAJE Siguiendo la configuración estándar del aprendizaje automático, nuestro objetivo es aprender una función h: X → Y entre un espacio de entrada X (todas las consultas posibles) y un espacio de salida Y (clasificaciones sobre un corpus).",
        "Para cuantificar la calidad de una predicción, ˆy = h(x), consideraremos una función de pérdida ∆ : Y × Y → . ∆(y, ˆy) cuantifica la penalización por hacer la predicción ˆy si la salida correcta es y.",
        "La función de pérdida nos permite incorporar medidas específicas de rendimiento, las cuales explotaremos en http://svmrank.yisongyue.com para optimizar el MAP.",
        "Nos restringimos al escenario de aprendizaje supervisado, donde pares de entrada/salida (x, y) están disponibles para el entrenamiento y se asume que provienen de alguna distribución fija P(x, y).",
        "El objetivo es encontrar una función h tal que el riesgo (es decir, la pérdida esperada), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), se minimice.",
        "Por supuesto, P(x, y) es desconocido.",
        "Pero dado un conjunto finito de pares de entrenamiento, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, el rendimiento de h en S puede medirse mediante el riesgo empírico, R∆ S (h) = 1 n ∑ i=1 n ∆(yi, h(xi)).",
        "En el caso de aprender una función de recuperación clasificada, X denota un espacio de consultas, y Y el espacio de clasificaciones (posiblemente débiles) sobre algún corpus de documentos C = {d1, . . . ,d|C|}.",
        "Podemos definir la pérdida de precisión promedio como ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), donde rank(y) es un vector de los valores de rango de cada documento en C. Por ejemplo, para un corpus de dos documentos, {d1, d2}, con d1 teniendo un rango más alto que d2, rank(y) = (1, 0).",
        "Suponemos que las clasificaciones verdaderas tienen dos valores de clasificación, donde los documentos relevantes tienen un valor de clasificación 1 y los documentos no relevantes tienen un valor de clasificación 0.",
        "Además, asumimos que todas las clasificaciones predichas son clasificaciones completas (sin empates).",
        "Sea p = rango(y) y ˆp = rango(ˆy).",
        "La puntuación de precisión promedio se define como MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, donde rel = |{i : pi = 1}| es el número de documentos relevantes, y Prec@j es el porcentaje de documentos relevantes en los primeros j documentos en la clasificación predicha ˆy.",
        "MAP es la media de las puntuaciones de precisión promedio de un grupo de consultas. La mayoría de los algoritmos de aprendizaje se optimizan para precisión o ROCArea.",
        "Si bien optimizar estas medidas podría lograr un buen rendimiento de MAP, usamos dos ejemplos simples para mostrar que también puede ser subóptimo en términos de MAP.",
        "ROCArea asigna una penalización igual a cada desordenamiento de un par relevante/no relevante.",
        "Por el contrario, MAP asigna mayores penalizaciones a los errores de ordenamiento más arriba en la clasificación predicha.",
        "Usando nuestra notación, el Área bajo la Curva ROC (ROCArea) se puede definir como ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], donde p es el ranking verdadero (débil), ˆp es el ranking predicho, y 1[b] es la función indicadora condicionada a b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Tabla 1: Ejemplo y Modelos Supongamos que tenemos un espacio de hipótesis con solo dos funciones de hipótesis, h1 y h2, como se muestra en la Tabla 1.",
        "Estas dos hipótesis predicen un ranking para la consulta x sobre un corpus de ocho documentos.",
        "Tabla 2: Rendimiento de los Modelos de Juguete La Tabla 2 muestra las puntuaciones de MAP y ROCArea de h1 y h2.",
        "Aquí, un método de aprendizaje que optimiza para el Área bajo la curva ROC elegiría h2 ya que esto resulta en un puntaje de Área bajo la curva ROC más alto, pero esto produce un puntaje de MAP subóptimo. 2.2 MAP vs Precisión Usando un ejemplo muy similar, ahora demostramos cómo optimizar para la precisión podría resultar en un puntaje de MAP subóptimo.",
        "Los modelos que se optimizan para la precisión no están directamente preocupados por la clasificación.",
        "En cambio, aprenden un umbral tal que los documentos que obtienen una puntuación superior al umbral pueden ser clasificados como relevantes y los documentos que obtienen una puntuación inferior como no relevantes.",
        "Consideramos nuevamente un espacio de hipótesis con dos hipótesis.",
        "La Tabla 3 muestra las predicciones de las dos hipótesis en una única consulta x. Hipótesis MAP Mejor Precisión h1(q) 0.70 0.64 h2(q) 0.64 0.73 Tabla 4: Rendimiento de los Modelos de Juguete La Tabla 4 muestra los puntajes de MAP y mejor precisión de h1(q) y h2(q).",
        "La mejor precisión se refiere a la precisión más alta alcanzable en esa clasificación al considerar todos los umbrales posibles.",
        "Por ejemplo, con h1(q), un umbral entre los documentos 1 y 2 da 4 errores (documentos 6-9 clasificados incorrectamente como no relevantes), lo que resulta en una precisión de 0.64.",
        "De manera similar, con h2(q), un umbral entre los documentos 5 y 6 da 3 errores (los documentos 10-11 clasificados incorrectamente como relevantes, y el documento 1 como no relevante), lo que resulta en una precisión de 0.73.",
        "Un método de aprendizaje que optimiza la precisión elegiría h2 ya que esto resulta en un puntaje de precisión más alto, pero esto produce un puntaje de MAP subóptimo. 3.",
        "OPTIMIZANDO LA PRECISIÓN PROMEDIO Nos basamos en el enfoque utilizado por [13] para optimizar el Área bajo la Curva ROC.",
        "A diferencia de ROCArea, sin embargo, MAP no se descompone linealmente en los ejemplos y requiere un algoritmo sustancialmente extendido, el cual describimos en esta sección.",
        "Recuerda que la clasificación verdadera es una clasificación débil con dos valores de clasificación (relevante y no relevante).",
        "Que Cx y C¯x denoten el conjunto de documentos relevantes y no relevantes de C para la consulta x, respectivamente.",
        "Nos enfocamos en funciones que están parametrizadas por un vector de peso w, y por lo tanto deseamos encontrar w para minimizar el riesgo empírico, R∆ S (w) ≡ R∆ S (h(·; w)).",
        "Nuestro enfoque es aprender una función discriminante F: X × Y → sobre pares de entrada-salida.",
        "Dada la consulta x, podemos derivar una predicción encontrando la clasificación y que maximiza la función discriminante: h(x; w) = argmax y∈Y F(x, y; w). (1) Suponemos que F es lineal en alguna representación de características combinadas de entradas y salidas Ψ(x, y) ∈ RN, es decir, F(x, y; w) = wT Ψ(x, y). (2) La función de características combinadas que utilizamos es Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))], donde φ: X × C → N es una función de mapeo de características de un par consulta/documento a un punto en un espacio dimensional N.",
        "Representamos las clasificaciones como una matriz de ordenamientos por pares, Y ⊂ {−1, 0, +1}|C|×|C| .",
        "Para cualquier y ∈ Y, yij = +1 si di está clasificado por delante de dj, y yij = −1 si dj está clasificado por delante de di, y yij = 0 si di y dj tienen el mismo rango.",
        "Consideramos solo matrices que corresponden a clasificaciones válidas (es decir, que cumplen con la antisimetría y la transitividad).",
        "De manera intuitiva, Ψ es una suma de las diferencias vectoriales de todos los pares de documentos relevantes/no relevantes.",
        "Dado que asumimos que las clasificaciones predichas son clasificaciones completas, yij es o bien +1 o −1 (nunca 0).",
        "Dado un vector de pesos aprendido w, predecir un ranking (es decir, resolver la ecuación (1)) dado una consulta x se reduce a elegir cada yij para maximizar wT Ψ(x, y).",
        "Como también se discute en [13], esto se logra ordenando los documentos por wT φ(x, d) en orden descendente.",
        "Discutiremos más adelante las elecciones de φ que utilizamos para nuestros experimentos. 3.1 SVM Estructurales La formulación anterior es muy similar a aprender un modelo lineal directo mientras se entrena en la diferencia de pares de documentos relevantes/no relevantes.",
        "Muchos enfoques basados en SVM optimizan sobre estas diferencias en pares (por ejemplo, [5, 10, 13, 4]), aunque estos métodos no optimizan para el MAP durante el entrenamiento.",
        "Anteriormente, no estaba claro cómo incorporar funciones de pérdida multivariadas no lineales como la pérdida MAP directamente en problemas de optimización global como el entrenamiento de SVM.",
        "Ahora presentamos un método basado en SVM estructurales [19] para abordar este problema.",
        "Utilizamos la formulación del SVM estructural, presentada en el Problema de Optimización 1, para aprender un w ∈ RN.",
        "Problema de optimización 1. (SVM estructural) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) La función objetivo a minimizar (3) es un compromiso entre la complejidad del modelo, w 2 , y una relajación de pérdida de MAP mediante la pérdida de bisagra, P ξi.",
        "Como es habitual en el entrenamiento de SVM, C es igual a 2. Por ejemplo, una dimensión podría ser el número de veces que las palabras de la consulta aparecen en el documento.",
        "Algoritmo 1 Algoritmo de plano de corte para resolver OP 1 dentro de la tolerancia. 1: Entrada: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ para todo i = 1, . . . , n 3: repetir 4: para i = 1, . . . , n hacer 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: calcular ˆy = argmaxy∈Y H(y; w) 7: calcular ξi = max{0, maxy∈Wi H(y; w)} 8: si H(ˆy; w) > ξi + entonces 9: Wi ← Wi ∪ {ˆy} 10: w ← optimizar (3) sobre W = S i Wi 11: fin si 12: fin para 13: hasta que ningún Wi haya cambiado durante la iteración parámetro que controla este equilibrio y puede ajustarse para lograr un buen rendimiento en diferentes tareas de entrenamiento.",
        "Para cada (xi, yi) en el conjunto de entrenamiento, se añade un conjunto de restricciones de la forma en la ecuación (4) al problema de optimización.",
        "Ten en cuenta que wT Ψ(x, y) es exactamente nuestra función discriminante F(x, y; w) (ver ecuación (2)).",
        "Durante la predicción, nuestro modelo elige el ranking que maximiza el discriminante (1).",
        "Si el valor del discriminante para una clasificación incorrecta y es mayor que para la clasificación verdadera yi (por ejemplo, F(xi, y; w) > F(xi, yi; w)), entonces la variable de holgura correspondiente, ξi, debe ser al menos ∆(yi, y) para que se cumpla esa restricción.",
        "Por lo tanto, la suma de los márgenes, P ξi, acota superiormente la pérdida MAP.",
        "Esto se establece formalmente en la Proposición 1.",
        "Proposición 1.",
        "Sea ξ∗ (w) la solución óptima de las variables de holgura para OP 1 para un vector de peso dado w. Entonces 1 n Pn i=1 ξi es una cota superior del riesgo empírico R∆ S (w). (ver [19] para la prueba) La Proposición 1 muestra que OP 1 aprende una función de clasificación que optimiza una cota superior del error de MAP en el conjunto de entrenamiento.",
        "Desafortunadamente hay un problema: se requiere una restricción para cada posible resultado incorrecto y, y el número de resultados incorrectos posibles es exponencial en el tamaño de C. Afortunadamente, podemos emplear el Algoritmo 1 para resolver OP 1.",
        "El algoritmo 1 es un algoritmo de plano de corte, introduciendo iterativamente restricciones hasta que hayamos resuelto el problema original dentro de una tolerancia deseada [19].",
        "El algoritmo comienza sin restricciones y encuentra de forma iterativa, para cada ejemplo (xi, yi), la salida ˆy asociada con la restricción más violada.",
        "Si la restricción correspondiente es violada por más de lo que introducimos ˆy en el conjunto de trabajo Wi de restricciones activas, por ejemplo i, y volvemos a resolver (3) usando el W actualizado. Se puede demostrar que el bucle externo del Algoritmo 1 está garantizado a detenerse dentro de un número polinomial de iteraciones para cualquier precisión deseada.",
        "Teorema 1.",
        "Sea ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y), ¯∆ = maxi maxy ∆(yi, y), y para cualquier > 0, el Algoritmo 1 termina después de agregar a lo sumo max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff restricciones al conjunto de trabajo W. (ver [19] para la prueba) Sin embargo, dentro del bucle interno de este algoritmo tenemos que calcular argmaxy∈Y H(y; w), donde H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), o equivalentemente, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), ya que wT Ψ(xi, yi) es constante con respecto a y.",
        "Aunque está estrechamente relacionado con el procedimiento de clasificación, esto tiene la complicación sustancial de que debemos lidiar con el término adicional ∆(yi, y).",
        "Sin la capacidad de encontrar eficientemente la restricción más violada (es decir, resolver argmaxy∈Y H(y, w)), el procedimiento de generación de restricciones no es viable. 3.2 Encontrar la restricción más violada utilizando OP 1 y optimizando la pérdida de ROCArea (∆roc), el problema de encontrar la restricción más violada, o resolver argmaxy∈Y H(y, w) (en adelante argmax H), se aborda en [13].",
        "Resolver argmax H para ∆map es más difícil.",
        "Esto se debe principalmente a que ROCArea se descompone de manera ordenada en una suma de puntuaciones calculadas de forma independiente en cada ordenamiento relativo de un par de documentos relevantes/no relevantes.",
        "MAP, por otro lado, no se descompone de la misma manera que ROCArea.",
        "La principal contribución algorítmica de este artículo es un método eficiente para resolver argmax H para ∆map.",
        "Una propiedad útil de ∆map es que es invariante al intercambiar dos documentos con igual relevancia.",
        "Por ejemplo, si los documentos da y db son ambos relevantes, entonces intercambiar las posiciones de da y db en cualquier clasificación no afecta a ∆map.",
        "Por extensión, ∆map es invariante a cualquier permutación arbitraria de los documentos relevantes entre sí y de los documentos no relevantes entre sí.",
        "Sin embargo, esta reorganización afectará la puntuación del discriminante, wT Ψ(x, y).",
        "Esto nos lleva a la Observación 1.",
        "Observación 1.",
        "Considera clasificaciones que estén limitadas por fijar la relevancia en cada posición de la clasificación (por ejemplo, el tercer documento en la clasificación debe ser relevante).",
        "Cada clasificación que cumpla con el mismo conjunto de restricciones tendrá el mismo ∆map.",
        "Si los documentos relevantes están ordenados por wT φ(x, d) en orden descendente, y los documentos no relevantes también están ordenados de la misma manera por wT φ(x, d), entonces la intercalación de las dos listas ordenadas que cumpla con las restricciones maximizará H para ese conjunto de clasificaciones restringidas.",
        "La Observación 1 implica que en la clasificación que maximiza H, los documentos relevantes se ordenarán por wT φ(x, d), y los documentos no relevantes también se ordenarán de la misma manera.",
        "Al ordenar primero los documentos relevantes y no relevantes, el problema se simplifica a encontrar la intercalación óptima de dos listas ordenadas.",
        "Para el resto de nuestra discusión, asumimos que los documentos relevantes y no relevantes están ordenados por wT φ(x, d) en orden descendente.",
        "Para mayor comodidad, también nos referimos a los documentos relevantes como {dx 1 , . . . dx |Cx|} = Cx, y a los documentos no relevantes como {d¯x 1 , . . . d¯x |C¯x|} = C¯x.",
        "Definimos δj(i1, i2), con i1 < i2, como el cambio en H desde cuando el documento relevante de mayor rango clasificado después de d¯x j es dx i1 hasta que es dx i2.",
        "Para i2 = i1 + 1, tenemos δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5), donde si = wT φ(x, di).",
        "El primer término en (5) es el cambio en ∆map cuando el documento relevante i tiene j documentos no relevantes clasificados antes de él, en lugar de j-1.",
        "El segundo término es el cambio en la puntuación del discriminante, wT Ψ(x, y), cuando yij cambia de +1 a −1. . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . .",
        "Figura 1: Ejemplo para δj(i, i + 1). La Figura 1 proporciona un ejemplo conceptual para δj(i, i + 1).",
        "La clasificación inferior difiere de la superior solo cuando d¯x j sube un rango.",
        "La diferencia en el valor de H para estas dos clasificaciones es exactamente δj(i, i + 1).",
        "Para cualquier i1 < i2, podemos definir δj(i1, i2) como δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) o equivalentemente, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) .",
        "Deja que o1, . . . , o|C¯x| codifiquen las posiciones de los documentos no relevantes, donde dx oj es el documento relevante de mayor rango clasificado después del j-ésimo documento no relevante.",
        "Debido a la Observación 1, esta codificación identifica de forma única un ranking completo.",
        "Podemos recuperar la clasificación como yij = 8 >>>< >>>: 0 si i = j sign(si − sj) si di, dj relevancia igual signo(oj − i − 0.5) si di = dx i , dj = d¯x j signo(j − oi + 0.5) si di = d¯x i , dj = dx j. (7) Ahora podemos reformular H en una nueva función objetivo, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), donde ¯y es la verdadera clasificación (débil).",
        "Conceptualmente, H comienza con una clasificación perfecta ¯y y agrega el cambio en H cuando cada documento no relevante sucesivo sube en la clasificación.",
        "Luego podemos reformular el problema argmax H como argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) sujeto a o1 ≤ . . . ≤ o|C¯x|. (9) El Algoritmo 2 describe el algoritmo utilizado para resolver la ecuación (8).",
        "Conceptualmente, el Algoritmo 2 comienza con un ranking perfecto.",
        "Entonces, para cada documento no relevante sucesivo, el algoritmo modifica la solución deslizando ese documento hacia arriba en la clasificación para maximizar localmente H, manteniendo las posiciones de los otros documentos no relevantes constantes. 3.2.1 Prueba de Corrección El Algoritmo 2 es codicioso en el sentido de que encuentra la mejor posición de cada documento no relevante de forma independiente de los otros documentos no relevantes.",
        "En otras palabras, el algoritmo maximiza H para cada documento no relevante, d¯x j, Algoritmo 2 Encontrar la Restricción Más Violada (argmax H) para el Algoritmo 1 con ∆map 1: Entrada: w, Cx, C¯x 2: ordenar Cx y C¯x en orden descendente de wT φ(x, d) 3: sx i ← wT φ(x, dx i), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i), i = 1, . . . , |C¯x | 5: para j = 1, . . . , |C¯x | hacer 6: optj ← argmaxk δj(k, |Cx| + 1) 7: fin para 8: codificar ˆy de acuerdo con (7) 9: devolver ˆy sin considerar las posiciones de los otros documentos no relevantes, y así ignora las restricciones de (9).",
        "Para que la solución sea factible, el documento no relevante j-ésimo debe ser clasificado después de los primeros j-1 documentos no relevantes, satisfaciendo así opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. Si la solución es factible, entonces claramente resuelve (8).",
        "Por lo tanto, basta con demostrar que el Algoritmo 2 cumple con (10).",
        "Primero demostramos que δj(·, ·) es monótonamente decreciente en j. Lema 1.",
        "Para cualquier 1 ≤ i1 < i2 ≤ |Cx | + 1 y 1 ≤ j < |C¯x |, debe ser el caso que δj+1(i1, i2) ≤ δj(i1, i2).",
        "Prueba.",
        "Recuerde que tanto δj(i1, i2) como δj+1(i1, i2) son sumas de términos i2 − i1.",
        "Mostraremos que cada término en la suma de δj+1(i1, i2) no es mayor que el término correspondiente en δj(i1, i2), o δj+1(k, k + 1) ≤ δj(k, k + 1) para k = i1, . . . , i2 − 1.",
        "Cada término en δj(k, k +1) y δj+1(k, k +1) puede ser descompuesto aún más en dos partes (ver (5)).",
        "Mostraremos que cada parte de δj+1(k, k + 1) no es mayor que la parte correspondiente en δj(k, k + 1).",
        "En otras palabras, demostraremos que tanto j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) como −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) son verdaderos para los valores mencionados de j y k. Es fácil ver que (11) es verdadero observando que para cualquier par de enteros positivos 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1, y eligiendo a = j y b = j + k. La segunda desigualdad (12) se cumple porque el Algoritmo 2 primero ordena d¯x en orden descendente de s¯x, lo que implica s¯x j+1 ≤ s¯x j.",
        "Así vemos que cada término en δj+1 no es mayor que el término correspondiente en δj, lo cual completa la prueba.",
        "El resultado del Lema 1 conduce directamente a nuestro resultado principal de corrección: Teorema 2.",
        "En el Algoritmo 2, los valores calculados de optj satisfacen (10), lo que implica que la solución devuelta por el Algoritmo 2 es factible y, por lo tanto, óptima.",
        "Prueba.",
        "Demostraremos que optj ≤ optj+1 se cumple para cualquier 1 ≤ j < |C¯x|, implicando así (10).",
        "Dado que el Algoritmo 2 calcula optj como optj = argmax k δj(k, |Cx | + 1), (13), entonces por definición de δj (6), para cualquier 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0.",
        "Usando el Lema 1, sabemos que δj+1(i, optj) ≤ δj(i, optj) < 0, lo que implica que para cualquier 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0.",
        "Supongamos por contradicción que optj+1 < optj.",
        "Entonces δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), lo cual contradice (13).",
        "Por lo tanto, debe ser el caso que optj ≤ optj+1, lo cual completa la prueba. 3.2.2 Tiempo de ejecución El tiempo de ejecución del Algoritmo 2 se puede dividir en dos partes.",
        "La primera parte es la clasificación por wT φ(x, d), lo cual requiere un tiempo de O(n log n), donde n = |Cx | + |C¯x |.",
        "La segunda parte calcula cada optj, lo cual requiere un tiempo de O(|Cx| · |C¯x|).",
        "Aunque en el peor de los casos esto es O(n2), el número de documentos relevantes, |Cx|, suele ser muy pequeño (por ejemplo, constante con respecto a n), en cuyo caso el tiempo de ejecución para la segunda parte es simplemente O(n).",
        "Para la mayoría de los conjuntos de datos del mundo real, el Algoritmo 2 está dominado por la ordenación y tiene una complejidad O(n log n).",
        "El Algoritmo 1 está garantizado de detenerse en un número polinómico de iteraciones [19], y cada iteración ejecuta el Algoritmo 2.",
        "Prácticamente todos los modelos que funcionaron bien fueron entrenados en un tiempo razonable (generalmente menos de una hora).",
        "Una vez que el entrenamiento esté completo, hacer predicciones sobre la consulta x usando la hipótesis resultante h(x|w) solo requiere ordenar por wT φ(x, d).",
        "Desarrollamos nuestro software utilizando una interfaz de Python a SVMstruct, ya que el lenguaje Python simplificó en gran medida el proceso de codificación.",
        "Para mejorar el rendimiento, es recomendable utilizar la implementación estándar en C de SVMstruct.",
        "CONFIGURACIÓN DEL EXPERIMENTO El objetivo principal de nuestros experimentos es evaluar si la optimización directa de MAP conduce a un rendimiento de MAP mejorado en comparación con los métodos convencionales de SVM que optimizan una pérdida sustituta como la precisión o el área bajo la curva ROC.",
        "Evaluamos empíricamente nuestro método utilizando dos conjuntos de consultas de la TREC Web Track, uno de TREC 9 y otro de TREC 10 (temas 451-500 y 501-550), ambos de los cuales utilizaron el corpus WT10g.",
        "Para cada consulta, TREC proporciona las evaluaciones de relevancia de los documentos.",
        "Generamos nuestras características utilizando las puntuaciones de las funciones de recuperación existentes en estas consultas.",
        "Si bien nuestro método es agnóstico al significado de las características, elegimos utilizar funciones de recuperación existentes como una forma simple pero efectiva de adquirir características útiles.",
        "Por lo tanto, nuestros experimentos de estadísticas de conjuntos de datos básicos esencialmente prueban la capacidad de nuestros métodos para volver a clasificar los documentos altamente clasificados (por ejemplo, volver a combinar las puntuaciones de las funciones de recuperación) para mejorar el MAP.",
        "Comparamos nuestro método con las mejores funciones de recuperación entrenadas (en adelante, funciones base), así como con los métodos SVM propuestos anteriormente.",
        "Comparar con las mejores funciones base pone a prueba la capacidad de nuestros métodos para aprender una combinación útil.",
        "Comparar con métodos SVM anteriores nos permite probar si optimizar directamente para el MAP (en lugar de precisión o área bajo la curva ROC) logra una puntuación de MAP más alta en la práctica.",
        "El resto de esta sección describe las funciones base y el método de generación de características en detalle. 4.1 Elección de Funciones de Recuperación Elegimos dos conjuntos de funciones base para nuestros experimentos.",
        "Para el primer conjunto, generamos tres índices sobre el corpus WT10g utilizando Indri5.",
        "El primer índice fue generado utilizando la configuración predeterminada, el segundo utilizó Porter-stemming, y el último utilizó Porter-stemming y las palabras vacías predeterminadas de Indris.",
        "Para TREC 9 y TREC 10, utilizamos la parte de descripción de cada consulta y puntuamos los documentos utilizando cinco de los métodos de recuperación integrados en Indri, que son Similitud Coseno, TFIDF, Okapi, Modelo de Lenguaje con Prior de Dirichlet y Modelo de Lenguaje con Prior de Jelinek-Mercer.",
        "Todos los parámetros se mantuvieron en sus valores predeterminados.",
        "Calculamos las puntuaciones de estos cinco métodos de recuperación sobre los tres índices, dando un total de 15 funciones base.",
        "Para cada consulta, consideramos las puntuaciones de los documentos encontrados en la unión de los mejores 1000 documentos de cada función base.",
        "Para nuestro segundo conjunto de funciones base, utilizamos puntuaciones de las presentaciones de la pista web TREC 9 [8] y TREC 10 [9].",
        "Utilizamos solo las presentaciones no manuales y no breves de ambos años.",
        "Para TREC 9 y TREC 10, hubo 53 y 18 envíos de este tipo, respectivamente.",
        "Una presentación típica contenía puntajes de sus 1000 documentos principales. b ca wT φ(x,d) f(d|x) Figura 2: Ejemplo de Agrupación de Características 4.2 Generación de Características Para generar ejemplos de entrada para nuestro método, se debe proporcionar una instancia concreta de φ.",
        "Para cada documento d puntuado por un conjunto de funciones de recuperación F en la consulta x, generamos las características como un vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf, donde f(d|x) denota la puntuación que la función de recuperación f asigna al documento d para la consulta x, y cada Kf es un conjunto de valores reales.",
        "Desde un nivel alto, estamos expresando la puntuación de cada función de recuperación utilizando |Kf | + 1 contenedores.",
        "Dado que estamos utilizando núcleos lineales, se puede pensar en el problema de aprendizaje como encontrar una buena combinación de piezas constantes de los puntajes de las funciones de recuperación.",
        "La Figura 2 muestra un ejemplo de nuestro método de mapeo de características.",
        "En este ejemplo tenemos una única característica F = {f}.",
        "Aquí, Kf = {a, b, c}, y el vector de pesos es w = wa, wb, wc.",
        "Para cualquier documento d y consulta x, tenemos wT φ(x, d) = 8 >>< >>: 0 si f(d|x) < a wa si a ≤ f(d|x) < b wa + wb si b ≤ f(d|x) < c wa + wb + wc si c ≤ f(d|x) .",
        "Esto se expresa cualitativamente en la Figura 2, donde wa y wb son positivos, y wc es negativo.",
        "Realizamos nuestros experimentos principales utilizando cuatro opciones de F: el conjunto de las funciones de recuperación de Indri mencionadas anteriormente para TREC 9 y TREC 10, y las presentaciones de la pista web para TREC 9 y TREC 10.",
        "Para cada F y cada función f ∈ F, elegimos 50 valores para Kf que estuvieran razonablemente espaciados y capturaran la región sensible de f. Utilizando las cuatro opciones de F, generamos cuatro conjuntos de datos para nuestros experimentos principales.",
        "La Tabla 5 contiene estadísticas de los conjuntos de datos generados.",
        "Hay muchas formas de generar características, y no estamos abogando por nuestro método sobre los demás.",
        "Esto fue simplemente un medio eficiente para normalizar las salidas de diferentes funciones y permitir un modelo más expresivo.",
        "EXPERIMENTOS Para cada conjunto de datos en la Tabla 5, realizamos 50 pruebas.",
        "Para cada prueba, entrenamos con 10 consultas seleccionadas al azar, y seleccionamos otras 5 consultas al azar para un conjunto de validación.",
        "Los modelos fueron entrenados utilizando una amplia gama de valores de C.",
        "El modelo que tuvo mejor rendimiento en el conjunto de validación fue seleccionado y probado en las 35 consultas restantes.",
        "Todas las consultas fueron seleccionadas para estar en los conjuntos de entrenamiento, validación y prueba la misma cantidad de veces.",
        "Utilizando esta configuración, realizamos los mismos experimentos mientras usábamos nuestro método (mapa SVM∆), un SVM optimizando para ROCArea (SVM∆ roc) [13], y un SVM de clasificación convencional (SVMacc) [20].",
        "Todos los métodos de SVM utilizaron un kernel lineal.",
        "Informamos sobre el rendimiento promedio de todos los modelos en las 50 pruebas. 5.1 Comparación con Funciones Base Al analizar nuestros resultados, la primera pregunta a responder es, ¿puede SVM∆ map aprender un modelo que supere al mejor modelo base TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.290 - 0.287Mejor Func. 0.280 28/22 0.283 29/21 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 36/14 ** Tabla 7: Comparación con Envíos TREC TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288Mejor Func. 0.280 27/23 0.283 31/19 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 35/15 ** Tabla 8: Comparación con Funciones de Envíos TREC (sin el mejor)",
        "La Tabla 6 presenta la comparación del mapa SVM∆ con las mejores funciones base de Indri.",
        "Cada grupo de columnas contiene el rendimiento del MAP macro-promediado de SVM∆ map o una función base.",
        "Las columnas W/L muestran el número de consultas donde SVM∆ map logró un puntaje MAP más alto.",
        "Se realizaron pruebas de significancia utilizando la prueba de rango con signo de Wilcoxon de dos colas.",
        "Dos estrellas indican un nivel de significancia de 0.95.",
        "Todas las tablas que muestran nuestros resultados experimentales están estructuradas de manera idéntica.",
        "Aquí encontramos que SVM∆ mapea significativamente mejor que las mejores funciones base.",
        "La Tabla 7 muestra la comparación cuando se entrena con las presentaciones de TREC.",
        "Si bien logra una puntuación de MAP más alta que las mejores funciones base, la diferencia de rendimiento entre SVM∆ y las funciones base no es significativa.",
        "Dado que muchas de estas presentaciones utilizan funciones de puntuación cuidadosamente diseñadas para lograr un alto MAP, es posible que las presentaciones con mejor rendimiento utilicen técnicas que engloben las técnicas de las otras presentaciones.",
        "Como resultado, el mapa SVM∆ no sería capaz de aprender una hipótesis que pueda superar significativamente la mejor presentación.",
        "Por lo tanto, realizamos los mismos experimentos utilizando un conjunto de datos modificado en el que se eliminaron las características calculadas utilizando la mejor presentación.",
        "La tabla 8 muestra los resultados (ten en cuenta que aún estamos comparando con la mejor presentación, aunque no la estamos utilizando para el entrenamiento).",
        "Observa que si bien el rendimiento del SVM∆ map se degradó ligeramente, aún era comparable con el de la mejor presentación. 5.2 Comparación con Métodos SVM Anteriores La siguiente pregunta a responder es, ¿produce el SVM∆ map puntajes MAP más altos que los métodos SVM anteriores?",
        "Las tablas 9 y 10 presentan los resultados de SVM∆ map, SVM∆ roc y SVMacc cuando se entrenan con las funciones de recuperación de Indri y las presentaciones de TREC, respectivamente.",
        "La Tabla 11 contiene los resultados correspondientes cuando se entrena con las presentaciones de TREC sin la mejor presentación.",
        "Para empezar, nuestros resultados indican que SVMacc no fue competitivo con SVM∆ map y SVM∆ roc, y a veces tuvo un rendimiento notablemente inferior.",
        "Por lo tanto, probamos varios enfoques para mejorar el rendimiento de SVMacc. 5.2.1 Métodos alternativos de SVMacc Un problema que puede causar que SVMacc tenga un rendimiento deficiente es el desequilibrio severo entre documentos relevantes y no relevantes.",
        "La gran mayoría de los documentos no son relevantes.",
        "SVMacc2 aborda este problema asignando una penalización mayor a los errores de falsos negativos.",
        "Para cada conjunto de datos, la proporción de las penalizaciones por falsos negativos a falsos positivos es igual a la proporción entre el número de documentos no relevantes y relevantes en ese conjunto de datos.",
        "Las tablas 9, 10 y 11 indican que SVMacc2 sigue teniendo un rendimiento significativamente peor que SVM∆ map.",
        "Otro posible problema es que SVMacc intenta encontrar solo un umbral discriminatorio b que sea invariable a la consulta.",
        "Puede ser que diferentes consultas requieran diferentes valores de b.",
        "Tener el método de aprendizaje intentando encontrar un buen valor de b (cuando no existe) puede ser perjudicial.",
        "Tomamos dos enfoques para abordar este problema.",
        "El primer método, SVMacc3, convierte las puntuaciones de la función de recuperación en percentiles.",
        "Por ejemplo, para el documento d, la consulta q y la función de recuperación f, si la puntuación f(d|q) se encuentra en el 90% superior de las puntuaciones f(·|q) para la consulta q, entonces la puntuación convertida es f(d|q) = 0.9.",
        "Cada Kf contiene 50 valores equidistantes entre 0 y 1.",
        "Las tablas 9, 10 y 11 muestran que el rendimiento de SVMacc3 tampoco fue competitivo con SVM∆ map.",
        "El segundo método, SVMacc4, normaliza las puntuaciones dadas por f para cada consulta.",
        "Por ejemplo, suponga para la consulta q que f produce puntuaciones en el rango de 0.2 a 0.7.",
        "Entonces, para el documento d, si f(d|q) = 0.6, la puntuación convertida sería f(d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8.",
        "Cada Kf contiene 50 valores equidistantes entre 0 y 1.",
        "Nuevamente, las Tablas 9, 10 y 11 muestran que SVMacc4 no fue competitivo con SVM∆ map 5.2.2 MAP vs ROCArea. SVM∆ roc tuvo un rendimiento mucho mejor que SVMacc en nuestros experimentos.",
        "Cuando se entrenó con las funciones de recuperación de Indri (ver Tabla 9), el rendimiento de SVM∆ roc fue ligeramente, aunque no significativamente, peor que el rendimiento de SVM∆ map.",
        "Sin embargo, la Tabla 10 muestra que el mapa SVM∆ superó significativamente al roc SVM∆ cuando se entrenó con las presentaciones de TREC.",
        "La tabla 11 muestra el rendimiento de los modelos cuando se entrenan con las presentaciones de TREC y se elimina la mejor presentación.",
        "El rendimiento de la mayoría de los modelos se degradó ligeramente, con SVM∆ map aún teniendo el mejor rendimiento.",
        "TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288 SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Tabla 11: Entrenado en TREC Subm. (sin Mejor) 6.",
        "CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado un método SVM que optimiza directamente el MAP.",
        "Proporciona un enfoque basado en principios y evita heurísticas difíciles de controlar.",
        "Formulamos el problema de optimización y presentamos un algoritmo que encuentra la solución de manera demostrable en tiempo polinómico.",
        "Hemos demostrado empíricamente que nuestro método es generalmente superior o competitivo con los métodos convencionales de SVM.",
        "Nuestro nuevo método hace que sea conceptualmente tan fácil optimizar SVMs para MAP como anteriormente solo era posible para Precisión y Área bajo la curva ROC.",
        "El costo computacional para el entrenamiento es muy razonable en la práctica.",
        "Dado que otros métodos suelen requerir ajustar múltiples heurísticas, también esperamos entrenar menos modelos antes de encontrar uno que logre un buen rendimiento.",
        "El marco de aprendizaje utilizado por nuestro método es bastante general.",
        "Una extensión natural de este marco sería desarrollar métodos para optimizar otras medidas importantes de IR, como la Ganancia Acumulada Normalizada Descontada [2, 3, 4, 12] y la Reciprocidad Media de Rango. 7.",
        "AGRADECIMIENTOS Este trabajo fue financiado bajo el Premio NSF IIS-0412894, el Premio NSF CAREER 0237381 y un obsequio de Yahoo!",
        "Investigación.",
        "El tercer autor también fue parcialmente apoyado por una Beca de Investigación de Microsoft. 8.",
        "REFERENCIAS [1] B. T. Bartell, G. W. Cottrell y R. K. Belew.",
        "Combinación automática de múltiples sistemas de recuperación clasificados.",
        "En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender.",
        "Aprendiendo a clasificar utilizando descenso de gradiente.",
        "En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2005. [3] C. J. C. Burges, R. Ragno y Q.",
        "Lo.",
        "Aprendizaje para clasificar con funciones de costo no suaves.",
        "En Actas de la Conferencia Internacional sobre Avances en Sistemas de Información Neural (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y.",
        "Liu, H. Li, Y. Huang y H.-W. Hon.",
        "Adaptando el SVM de clasificación para la recuperación de documentos.",
        "En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [5] B. Carterette y D. Petkova.",
        "Aprendiendo un ranking a partir de preferencias por pares.",
        "En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew y A. Ksikes.",
        "Selección de conjunto de bibliotecas de modelos.",
        "En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [7] J. Davis y M. Goadrich.",
        "La relación entre las curvas de precisión-recall y ROC.",
        "En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2006. [8] D. Hawking.",
        "Resumen de la pista web TREC-9.",
        "En Actas de TREC-2000, 2000. [9] D. Hawking y N. Craswell.",
        "Resumen de la pista web TREC-2001.",
        "En Actas de TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel y K. Obermayer.",
        "Límites de rango de margen amplio para regresión ordinal.",
        "Avances en clasificadores de márgenes amplios, 2000. [11] A. Herschtal y B. Raskutti.",
        "Optimizando el área bajo la curva ROC utilizando descenso de gradiente.",
        "En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [12] K. Jarvelin y J. Kekalainen.",
        "Métodos de evaluación para recuperar documentos altamente relevantes.",
        "En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2000. [13] T. Joachims.",
        "Un método de vector de soporte para medidas de rendimiento multivariadas.",
        "En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), páginas 377-384, Nueva York, NY, EE. UU., 2005.",
        "ACM Press. [14] J. Lafferty y C. Zhai.",
        "Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información.",
        "En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), páginas 111-119, 2001. [15] Y. Lin, Y. Lee y G. Wahba.",
        "Máquinas de vectores de soporte para clasificación en situaciones no estándar.",
        "Aprendizaje automático, 46:191-202, 2002. [16] D. Metzler y W. B. Croft.",
        "Un modelo de campo aleatorio de Markov para dependencias entre términos.",
        "En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [17] K. Morik, P. Brockhausen y T. Joachims.",
        "Combinando el aprendizaje estadístico con un enfoque basado en el conocimiento.",
        "En Actas de la Conferencia Internacional sobre Aprendizaje Automático, 1999. [18] S. Robertson.",
        "El principio de clasificación de probabilidad en la revista IR de documentación.",
        "Revista de Documentación, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims y Y. Altun.",
        "Métodos de margen amplio para variables de salida estructuradas e interdependientes.",
        "Revista de Investigación en Aprendizaje Automático (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik.",
        "Teoría del Aprendizaje Estadístico.",
        "Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz. \n\nWiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer y R. Wolniewicz.",
        "Optimizando el rendimiento del clasificador mediante la aproximación a la estadística de Wilcoxon-Mann-Witney.",
        "En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2003."
    ],
    "error_count": 3,
    "keys": {
        "machine learning": {
            "translated_key": "aprendizaje automático",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT <br>machine learning</br> is commonly used to improve ranked retrieval systems.",
                "Due to computational difficulties, few learning techniques have been developed to directly optimize for mean average precision (MAP), despite its widespread use in evaluating such systems.",
                "Existing approaches optimizing MAP either do not find a globally optimal solution, or are computationally expensive.",
                "In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of MAP.",
                "We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora (WT10g), comparing against SVMs optimized for accuracy and ROCArea.",
                "In most cases we show our method to produce statistically significant improvements in MAP scores.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval Models General Terms Algorithm, Theory, Experimentation 1.",
                "INTRODUCTION State of the art information retrieval systems commonly use <br>machine learning</br> techniques to learn ranking functions.",
                "However, most current approaches do not optimize for the evaluation measure most often used, namely Mean Average Precision (MAP).",
                "Instead, current algorithms tend to take one of two general approaches.",
                "The first approach is to learn a model that estimates the probability of a document being relevant given a query (e.g., [18, 14]).",
                "If solved effectively, the ranking with best MAP performance can easily be derived from the probabilities of relevance.",
                "However, achieving high MAP only requires finding a good ordering of the documents.",
                "As a result, finding good probabilities requires solving a more difficult problem than necessary, likely requiring more training data to achieve the same MAP performance.",
                "The second common approach is to learn a function that maximizes a surrogate measure.",
                "Performance measures optimized include accuracy [17, 15], ROCArea [1, 5, 10, 11, 13, 21] or modifications of ROCArea [4], and NDCG [2, 3].",
                "Learning a model to optimize for such measures might result in suboptimal MAP performance.",
                "In fact, although some previous systems have obtained good MAP performance, it is known that neither achieving optimal accuracy nor ROCArea can guarantee optimal MAP performance[7].",
                "In this paper, we present a general approach for learning ranking functions that maximize MAP performance.",
                "Specifically, we present an SVM algorithm that globally optimizes a hinge-loss relaxation of MAP.",
                "This approach simplifies the process of obtaining ranking functions with high MAP performance by avoiding additional intermediate steps and heuristics.",
                "The new algorithm also makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for accuracy and ROCArea.",
                "In contrast to recent work directly optimizing for MAP performance by Metzler & Croft [16] and Caruana et al. [6], our technique is computationally efficient while finding a globally optimal solution.",
                "Like [6, 16], our method learns a linear model, but is much more efficient in practice and, unlike [16], can handle many thousands of features.",
                "We now describe the algorithm in detail and provide proof of correctness.",
                "Following this, we provide an analysis of running time.",
                "We finish with empirical results from experiments on the TREC 9 and TREC 10 Web Track corpus.",
                "We have also developed a software package implementing our algorithm that is available for public use1 . 2.",
                "THE LEARNING PROBLEM Following the standard <br>machine learning</br> setup, our goal is to learn a function h : X → Y between an input space X (all possible queries) and output space Y (rankings over a corpus).",
                "In order to quantify the quality of a prediction, ˆy = h(x), we will consider a loss function ∆ : Y × Y → . ∆(y, ˆy) quantifies the penalty for making prediction ˆy if the correct output is y.",
                "The loss function allows us to incorporate specific performance measures, which we will exploit 1 http://svmrank.yisongyue.com for optimizing MAP.",
                "We restrict ourselves to the supervised learning scenario, where input/output pairs (x, y) are available for training and are assumed to come from some fixed distribution P(x, y).",
                "The goal is to find a function h such that the risk (i.e., expected loss), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), is minimized.",
                "Of course, P(x, y) is unknown.",
                "But given a finite set of training pairs, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, the performance of h on S can be measured by the empirical risk, R∆ S (h) = 1 n nX i=1 ∆(yi, h(xi)).",
                "In the case of learning a ranked retrieval function, X denotes a space of queries, and Y the space of (possibly weak) rankings over some corpus of documents C = {d1, . . . ,d|C|}.",
                "We can define average precision loss as ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), where rank(y) is a vector of the rank values of each document in C. For example, for a corpus of two documents, {d1, d2}, with d1 having higher rank than d2, rank(y ) = (1, 0).",
                "We assume true rankings have two rank values, where relevant documents have rank value 1 and non-relevant documents rank value 0.",
                "We further assume that all predicted rankings are complete rankings (no ties).",
                "Let p = rank(y) and ˆp = rank(ˆy).",
                "The average precision score is defined as MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, where rel = |{i : pi = 1}| is the number of relevant documents, and Prec@j is the percentage of relevant documents in the top j documents in predicted ranking ˆy.",
                "MAP is the mean of the average precision scores of a group of queries. 2.1 MAP vs ROCArea Most learning algorithms optimize for accuracy or ROCArea.",
                "While optimizing for these measures might achieve good MAP performance, we use two simple examples to show it can also be suboptimal in terms of MAP.",
                "ROCArea assigns equal penalty to each misordering of a relevant/non-relevant pair.",
                "In contrast, MAP assigns greater penalties to misorderings higher up in the predicted ranking.",
                "Using our notation, ROCArea can be defined as ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], where p is the true (weak) ranking, ˆp is the predicted ranking, and 1[b] is the indicator function conditioned on b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Table 1: Toy Example and Models Suppose we have a hypothesis space with only two hypothesis functions, h1 and h2, as shown in Table 1.",
                "These two hypotheses predict a ranking for query x over a corpus of eight documents.",
                "Hypothesis MAP ROCArea h1(x) 0.59 0.47 h2(x) 0.51 0.53 Table 2: Performance of Toy Models Table 2 shows the MAP and ROCArea scores of h1 and h2.",
                "Here, a learning method which optimizes for ROCArea would choose h2 since that results in a higher ROCArea score, but this yields a suboptimal MAP score. 2.2 MAP vs Accuracy Using a very similar example, we now demonstrate how optimizing for accuracy might result in suboptimal MAP.",
                "Models which optimize for accuracy are not directly concerned with the ranking.",
                "Instead, they learn a threshold such that documents scoring higher than the threshold can be classified as relevant and documents scoring lower as nonrelevant.",
                "Doc ID 1 2 3 4 5 6 7 8 9 10 11 p 1 0 0 0 0 1 1 1 1 0 0 rank(h1(x)) 11 10 9 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 9 10 11 Table 3: Toy Example and Models We consider again a hypothesis space with two hypotheses.",
                "Table 3 shows the predictions of the two hypotheses on a single query x. Hypothesis MAP Best Acc. h1(q) 0.70 0.64 h2(q) 0.64 0.73 Table 4: Performance of Toy Models Table 4 shows the MAP and best accuracy scores of h1(q) and h2(q).",
                "The best accuracy refers to the highest achievable accuracy on that ranking when considering all possible thresholds.",
                "For instance, with h1(q), a threshold between documents 1 and 2 gives 4 errors (documents 6-9 incorrectly classified as non-relevant), yielding an accuracy of 0.64.",
                "Similarly, with h2(q), a threshold between documents 5 and 6 gives 3 errors (documents 10-11 incorrectly classified as relevant, and document 1 as non-relevant), yielding an accuracy of 0.73.",
                "A learning method which optimizes for accuracy would choose h2 since that results in a higher accuracy score, but this yields a suboptimal MAP score. 3.",
                "OPTIMIZING AVERAGE PRECISION We build upon the approach used by [13] for optimizing ROCArea.",
                "Unlike ROCArea, however, MAP does not decompose linearly in the examples and requires a substantially extended algorithm, which we describe in this section.",
                "Recall that the true ranking is a weak ranking with two rank values (relevant and non-relevant).",
                "Let Cx and C¯x denote the set of relevant and non-relevant documents of C for query x, respectively.",
                "We focus on functions which are parametrized by a weight vector w, and thus wish to find w to minimize the empirical risk, R∆ S (w) ≡ R∆ S (h(·; w)).",
                "Our approach is to learn a discriminant function F : X × Y → over input-output pairs.",
                "Given query x, we can derive a prediction by finding the ranking y that maximizes the discriminant function: h(x; w) = argmax y∈Y F(x, y; w). (1) We assume F to be linear in some combined feature representation of inputs and outputs Ψ(x, y) ∈ RN , i.e., F(x, y; w) = wT Ψ(x, y). (2) The combined feature function we use is Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))] , where φ : X × C → N is a feature mapping function from a query/document pair to a point in N dimensional space2 .",
                "We represent rankings as a matrix of pairwise orderings, Y ⊂ {−1, 0, +1}|C|×|C| .",
                "For any y ∈ Y, yij = +1 if di is ranked ahead of dj, and yij = −1 if dj is ranked ahead of di, and yij = 0 if di and dj have equal rank.",
                "We consider only matrices which correspond to valid rankings (i.e, obeying antisymmetry and transitivity).",
                "Intuitively, Ψ is a summation over the vector differences of all relevant/non-relevant document pairings.",
                "Since we assume predicted rankings to be complete rankings, yij is either +1 or −1 (never 0).",
                "Given a learned weight vector w, predicting a ranking (i.e. solving equation (1)) given query x reduces to picking each yij to maximize wT Ψ(x, y).",
                "As is also discussed in [13], this is attained by sorting the documents by wT φ(x, d) in descending order.",
                "We will discuss later the choices of φ we used for our experiments. 3.1 Structural SVMs The above formulation is very similar to learning a straightforward linear model while training on the pairwise difference of relevant/non-relevant document pairings.",
                "Many SVM-based approaches optimize over these pairwise differences (e.g., [5, 10, 13, 4]), although these methods do not optimize for MAP during training.",
                "Previously, it was not clear how to incorporate non-linear multivariate loss functions such as MAP loss directly into global optimization problems such as SVM training.",
                "We now present a method based on structural SVMs [19] to address this problem.",
                "We use the structural SVM formulation, presented in Optimization Problem 1, to learn a w ∈ RN .",
                "Optimization Problem 1. (Structural SVM) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) The objective function to be minimized (3) is a tradeoff between model complexity, w 2 , and a hinge loss relaxation of MAP loss, P ξi.",
                "As is usual in SVM training, C is a 2 For example, one dimension might be the number of times the query words appear in the document.",
                "Algorithm 1 Cutting plane algorithm for solving OP 1 within tolerance . 1: Input: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ for all i = 1, . . . , n 3: repeat 4: for i = 1, . . . , n do 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: compute ˆy = argmaxy∈Y H(y; w) 7: compute ξi = max{0, maxy∈Wi H(y; w)} 8: if H(ˆy; w) > ξi + then 9: Wi ← Wi ∪ {ˆy} 10: w ← optimize (3) over W = S i Wi 11: end if 12: end for 13: until no Wi has changed during iteration parameter that controls this tradeoff and can be tuned to achieve good performance in different training tasks.",
                "For each (xi, yi) in the training set, a set of constraints of the form in equation (4) is added to the optimization problem.",
                "Note that wT Ψ(x, y) is exactly our discriminant function F(x, y; w) (see equation (2)).",
                "During prediction, our model chooses the ranking which maximizes the discriminant (1).",
                "If the discriminant value for an incorrect ranking y is greater than for the true ranking yi (e.g., F(xi, y; w) > F(xi, yi; w)), then corresponding slack variable, ξi, must be at least ∆(yi, y) for that constraint to be satisfied.",
                "Therefore, the sum of slacks, P ξi, upper bounds the MAP loss.",
                "This is stated formally in Proposition 1.",
                "Proposition 1.",
                "Let ξ∗ (w) be the optimal solution of the slack variables for OP 1 for a given weight vector w. Then 1 n Pn i=1 ξi is an upper bound on the empirical risk R∆ S (w). (see [19] for proof) Proposition 1 shows that OP 1 learns a ranking function that optimizes an upper bound on MAP error on the training set.",
                "Unfortunately there is a problem: a constraint is required for every possible wrong output y, and the number of possible wrong outputs is exponential in the size of C. Fortunately, we may employ Algorithm 1 to solve OP 1.",
                "Algorithm 1 is a cutting plane algorithm, iteratively introducing constraints until we have solved the original problem within a desired tolerance [19].",
                "The algorithm starts with no constraints, and iteratively finds for each example (xi, yi) the output ˆy associated with the most violated constraint.",
                "If the corresponding constraint is violated by more than we introduce ˆy into the working set Wi of active constraints for example i, and re-solve (3) using the updated W. It can be shown that Algorithm 1s outer loop is guaranteed to halt within a polynomial number of iterations for any desired precision .",
                "Theorem 1.",
                "Let ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y) , ¯∆ = maxi maxy ∆(yi, y), and for any > 0, Algorithm 1 terminates after adding at most max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff constraints to the working set W. (see [19] for proof) However, within the inner loop of this algorithm we have to compute argmaxy∈Y H(y; w), where H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), or equivalently, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), since wT Ψ(xi, yi) is constant with respect to y.",
                "Though closely related to the classification procedure, this has the substantial complication that we must contend with the additional ∆(yi, y) term.",
                "Without the ability to efficiently find the most violated constraint (i.e., solve argmaxy∈Y H(y, w)), the constraint generation procedure is not tractable. 3.2 Finding the Most Violated Constraint Using OP 1 and optimizing to ROCArea loss (∆roc), the problem of finding the most violated constraint, or solving argmaxy∈Y H(y, w) (henceforth argmax H), is addressed in [13].",
                "Solving argmax H for ∆map is more difficult.",
                "This is primarily because ROCArea decomposes nicely into a sum of scores computed independently on each relative ordering of a relevant/non-relevant document pair.",
                "MAP, on the other hand, does not decompose in the same way as ROCArea.",
                "The main algorithmic contribution of this paper is an efficient method for solving argmax H for ∆map.",
                "One useful property of ∆map is that it is invariant to swapping two documents with equal relevance.",
                "For example, if documents da and db are both relevant, then swapping the positions of da and db in any ranking does not affect ∆map.",
                "By extension, ∆map is invariant to any arbitrary permutation of the relevant documents amongst themselves and of the non-relevant documents amongst themselves.",
                "However, this reshuﬄing will affect the discriminant score, wT Ψ(x, y).",
                "This leads us to Observation 1.",
                "Observation 1.",
                "Consider rankings which are constrained by fixing the relevance at each position in the ranking (e.g., the 3rd document in the ranking must be relevant).",
                "Every ranking which satisfies the same set of constraints will have the same ∆map.",
                "If the relevant documents are sorted by wT φ(x, d) in descending order, and the non-relevant documents are likewise sorted by wT φ(x, d), then the interleaving of the two sorted lists which satisfies the constraints will maximize H for that constrained set of rankings.",
                "Observation 1 implies that in the ranking which maximizes H, the relevant documents will be sorted by wT φ(x, d), and the non-relevant documents will also be sorted likewise.",
                "By first sorting the relevant and non-relevant documents, the problem is simplified to finding the optimal interleaving of two sorted lists.",
                "For the rest of our discussion, we assume that the relevant documents and non-relevant documents are both sorted by descending wT φ(x, d).",
                "For convenience, we also refer to relevant documents as {dx 1 , . . . dx |Cx|} = Cx , and non-relevant documents as {d¯x 1 , . . . d¯x |C¯x|} = C¯x .",
                "We define δj(i1, i2), with i1 < i2, as the change in H from when the highest ranked relevant document ranked after d¯x j is dx i1 to when it is dx i2 .",
                "For i2 = i1 + 1, we have δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5) where si = wT φ(x, di).",
                "The first term in (5) is the change in ∆map when the ith relevant document has j non-relevant documents ranked before it, as opposed to j −1.",
                "The second term is the change in the discriminant score, wT Ψ(x, y), when yij changes from +1 to −1. . . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . .",
                "Figure 1: Example for δj(i, i + 1) Figure 1 gives a conceptual example for δj(i, i + 1).",
                "The bottom ranking differs from the top only where d¯x j slides up one rank.",
                "The difference in the value of H for these two rankings is exactly δj(i, i + 1).",
                "For any i1 < i2, we can then define δj(i1, i2) as δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) or equivalently, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) .",
                "Let o1, . . . , o|C¯x| encode the positions of the non-relevant documents, where dx oj is the highest ranked relevant document ranked after the jth non-relevant document.",
                "Due to Observation 1, this encoding uniquely identifies a complete ranking.",
                "We can recover the ranking as yij = 8 >>>< >>>: 0 if i = j sign(si − sj) if di, dj equal relevance sign(oj − i − 0.5) if di = dx i , dj = d¯x j sign(j − oi + 0.5) if di = d¯x i , dj = dx j . (7) We can now reformulate H into a new objective function, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), where ¯y is the true (weak) ranking.",
                "Conceptually H starts with a perfect ranking ¯y, and adds the change in H when each successive non-relevant document slides up the ranking.",
                "We can then reformulate the argmax H problem as argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) s.t. o1 ≤ . . . ≤ o|C¯x|. (9) Algorithm 2 describes the algorithm used to solve equation (8).",
                "Conceptually, Algorithm 2 starts with a perfect ranking.",
                "Then for each successive non-relevant document, the algorithm modifies the solution by sliding that document up the ranking to locally maximize H while keeping the positions of the other non-relevant documents constant. 3.2.1 Proof of Correctness Algorithm 2 is greedy in the sense that it finds the best position of each non-relevant document independently from the other non-relevant documents.",
                "In other words, the algorithm maximizes H for each non-relevant document, d¯x j , Algorithm 2 Finding the Most Violated Constraint (argmax H) for Algorithm 1 with ∆map 1: Input: w, Cx , C¯x 2: sort Cx and C¯x in descending order of wT φ(x, d) 3: sx i ← wT φ(x, dx i ), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i ), i = 1, . . . , |C¯x | 5: for j = 1, . . . , |C¯x | do 6: optj ← argmaxk δj(k, |Cx | + 1) 7: end for 8: encode ˆy according to (7) 9: return ˆy without considering the positions of the other non-relevant documents, and thus ignores the constraints of (9).",
                "In order for the solution to be feasible, the jth non-relevant document must be ranked after the first j − 1 non-relevant documents, thus satisfying opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. (10) If the solution is feasible, the it clearly solves (8).",
                "Therefore, it suffices to prove that Algorithm 2 satisfies (10).",
                "We first prove that δj(·, ·) is monotonically decreasing in j. Lemma 1.",
                "For any 1 ≤ i1 < i2 ≤ |Cx | + 1 and 1 ≤ j < |C¯x |, it must be the case that δj+1(i1, i2) ≤ δj(i1, i2).",
                "Proof.",
                "Recall from (6) that both δj(i1, i2) and δj+1(i1, i2) are summations of i2 − i1 terms.",
                "We will show that each term in the summation of δj+1(i1, i2) is no greater than the corresponding term in δj(i1, i2), or δj+1(k, k + 1) ≤ δj(k, k + 1) for k = i1, . . . , i2 − 1.",
                "Each term in δj(k, k +1) and δj+1(k, k +1) can be further decomposed into two parts (see (5)).",
                "We will show that each part of δj+1(k, k + 1) is no greater than the corresponding part in δj(k, k + 1).",
                "In other words, we will show that both j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) and −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) are true for the aforementioned values of j and k. It is easy to see that (11) is true by observing that for any two positive integers 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1 , and choosing a = j and b = j + k. The second inequality (12) holds because Algorithm 2 first sorts d¯x in descending order of s¯x , implying s¯x j+1 ≤ s¯x j .",
                "Thus we see that each term in δj+1 is no greater than the corresponding term in δj, which completes the proof.",
                "The result of Lemma 1 leads directly to our main correctness result: Theorem 2.",
                "In Algorithm 2, the computed values of optj satisfy (10), implying that the solution returned by Algorithm 2 is feasible and thus optimal.",
                "Proof.",
                "We will prove that optj ≤ optj+1 holds for any 1 ≤ j < |C¯x |, thus implying (10).",
                "Since Algorithm 2 computes optj as optj = argmax k δj(k, |Cx | + 1), (13) then by definition of δj (6), for any 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0.",
                "Using Lemma 1, we know that δj+1(i, optj) ≤ δj(i, optj) < 0, which implies that for any 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0.",
                "Suppose for contradiction that optj+1 < optj.",
                "Then δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), which contradicts (13).",
                "Therefore, it must be the case that optj ≤ optj+1, which completes the proof. 3.2.2 Running Time The running time of Algorithm 2 can be split into two parts.",
                "The first part is the sort by wT φ(x, d), which requires O(n log n) time, where n = |Cx | + |C¯x |.",
                "The second part computes each optj, which requires O(|Cx | · |C¯x |) time.",
                "Though in the worst case this is O(n2 ), the number of relevant documents, |Cx |, is often very small (e.g., constant with respect to n), in which case the running time for the second part is simply O(n).",
                "For most real-world datasets, Algorithm 2 is dominated by the sort and has complexity O(n log n).",
                "Algorithm 1 is guaranteed to halt in a polynomial number of iterations [19], and each iteration runs Algorithm 2.",
                "Virtually all well-performing models were trained in a reasonable amount of time (usually less than one hour).",
                "Once training is complete, making predictions on query x using the resulting hypothesis h(x|w) requires only sorting by wT φ(x, d).",
                "We developed our software using a Python interface3 to SVMstruct , since the Python language greatly simplified the coding process.",
                "To improve performance, it is advisable to use the standard C implementation4 of SVMstruct . 4.",
                "EXPERIMENT SETUP The main goal of our experiments is to evaluate whether directly optimizing MAP leads to improved MAP performance compared to conventional SVM methods that optimize a substitute loss such as accuracy or ROCArea.",
                "We empirically evaluate our method using two sets of TREC Web Track queries, one each from TREC 9 and TREC 10 (topics 451-500 and 501-550), both of which used the WT10g corpus.",
                "For each query, TREC provides the relevance judgments of the documents.",
                "We generated our features using the scores of existing retrieval functions on these queries.",
                "While our method is agnostic to the meaning of the features, we chose to use existing retrieval functions as a simple yet effective way of acquiring useful features.",
                "As such, our 3 http://www.cs.cornell.edu/~tomf/svmpython/ 4 http://svmlight.joachims.org/svm_struct.html Dataset Base Funcs Features TREC 9 Indri 15 750 TREC 10 Indri 15 750 TREC 9 Submissions 53 2650 TREC 10 Submissions 18 900 Table 5: Dataset Statistics experiments essentially test our methods ability to re-rank the highly ranked documents (e.g., re-combine the scores of the retrieval functions) to improve MAP.",
                "We compare our method against the best retrieval functions trained on (henceforth base functions), as well as against previously proposed SVM methods.",
                "Comparing with the best base functions tests our methods ability to learn a useful combination.",
                "Comparing with previous SVM methods allows us to test whether optimizing directly for MAP (as opposed to accuracy or ROCArea) achieves a higher MAP score in practice.",
                "The rest of this section describes the base functions and the feature generation method in detail. 4.1 Choosing Retrieval Functions We chose two sets of base functions for our experiments.",
                "For the first set, we generated three indices over the WT10g corpus using Indri5 .",
                "The first index was generated using default settings, the second used Porter-stemming, and the last used Porter-stemming and Indris default stopwords.",
                "For both TREC 9 and TREC 10, we used the description portion of each query and scored the documents using five of Indris built-in retrieval methods, which are Cosine Similarity, TFIDF, Okapi, Language Model with Dirichlet Prior, and Language Model with Jelinek-Mercer Prior.",
                "All parameters were kept as their defaults.",
                "We computed the scores of these five retrieval methods over the three indices, giving 15 base functions in total.",
                "For each query, we considered the scores of documents found in the union of the top 1000 documents of each base function.",
                "For our second set of base functions, we used scores from the TREC 9 [8] and TREC 10 [9] Web Track submissions.",
                "We used only the non-manual, non-short submissions from both years.",
                "For TREC 9 and TREC 10, there were 53 and 18 such submissions, respectively.",
                "A typical submission contained scores of its top 1000 documents. b ca wT φ(x,d) f(d|x) Figure 2: Example Feature Binning 4.2 Generating Features In order to generate input examples for our method, a concrete instantiation of φ must be provided.",
                "For each doc5 http://www.lemurproject.org TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236Best Func. 0.204 39/11 ** 0.181 37/13 ** 2nd Best 0.199 38/12 ** 0.174 43/7 ** 3rd Best 0.188 34/16 ** 0.174 38/12 ** Table 6: Comparison with Indri Functions ument d scored by a set of retrieval functions F on query x, we generate the features as a vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf , where f(d|x) denotes the score that retrieval function f assigns to document d for query x, and each Kf is a set of real values.",
                "From a high level, we are expressing the score of each retrieval function using |Kf | + 1 bins.",
                "Since we are using linear kernels, one can think of the learning problem as finding a good piecewise-constant combination of the scores of the retrieval functions.",
                "Figure 2 shows an example of our feature mapping method.",
                "In this example we have a single feature F = {f}.",
                "Here, Kf = {a, b, c}, and the weight vector is w = wa, wb, wc .",
                "For any document d and query x, we have wT φ(x, d) = 8 >>< >>: 0 if f(d|x) < a wa if a ≤ f(d|x) < b wa + wb if b ≤ f(d|x) < c wa + wb + wc if c ≤ f(d|x) .",
                "This is expressed qualitatively in Figure 2, where wa and wb are positive, and wc is negative.",
                "We ran our main experiments using four choices of F: the set of aforementioned Indri retrieval functions for TREC 9 and TREC 10, and the Web Track submissions for TREC 9 and TREC 10.",
                "For each F and each function f ∈ F, we chose 50 values for Kf which are reasonably spaced and capture the sensitive region of f. Using the four choices of F, we generated four datasets for our main experiments.",
                "Table 5 contains statistics of the generated datasets.",
                "There are many ways to generate features, and we are not advocating our method over others.",
                "This was simply an efficient means to normalize the outputs of different functions and allow for a more expressive model. 5.",
                "EXPERIMENTS For each dataset in Table 5, we performed 50 trials.",
                "For each trial, we train on 10 randomly selected queries, and select another 5 queries at random for a validation set.",
                "Models were trained using a wide range of C values.",
                "The model which performed best on the validation set was selected and tested on the remaining 35 queries.",
                "All queries were selected to be in the training, validation and test sets the same number of times.",
                "Using this setup, we performed the same experiments while using our method (SVM∆ map), an SVM optimizing for ROCArea (SVM∆ roc) [13], and a conventional classification SVM (SVMacc) [20].",
                "All SVM methods used a linear kernel.",
                "We reported the average performance of all models over the 50 trials. 5.1 Comparison with Base Functions In analyzing our results, the first question to answer is, can SVM∆ map learn a model which outperforms the best base TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287Best Func. 0.280 28/22 0.283 29/21 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 36/14 ** Table 7: Comparison with TREC Submissions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288Best Func. 0.280 27/23 0.283 31/19 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 35/15 ** Table 8: Comparison with TREC Subm. (w/o best) functions?",
                "Table 6 presents the comparison of SVM∆ map with the best Indri base functions.",
                "Each column group contains the macro-averaged MAP performance of SVM∆ map or a base function.",
                "The W/L columns show the number of queries where SVM∆ map achieved a higher MAP score.",
                "Significance tests were performed using the two-tailed Wilcoxon signed rank test.",
                "Two stars indicate a significance level of 0.95.",
                "All tables displaying our experimental results are structured identically.",
                "Here, we find that SVM∆ map significantly outperforms the best base functions.",
                "Table 7 shows the comparison when trained on TREC submissions.",
                "While achieving a higher MAP score than the best base functions, the performance difference between SVM∆ map the base functions is not significant.",
                "Given that many of these submissions use scoring functions which are carefully crafted to achieve high MAP, it is possible that the best performing submissions use techniques which subsume the techniques of the other submissions.",
                "As a result, SVM∆ map would not be able to learn a hypothesis which can significantly out-perform the best submission.",
                "Hence, we ran the same experiments using a modified dataset where the features computed using the best submission were removed.",
                "Table 8 shows the results (note that we are still comparing against the best submission though we are not using it for training).",
                "Notice that while the performance of SVM∆ map degraded slightly, the performance was still comparable with that of the best submission. 5.2 Comparison w/ Previous SVM Methods The next question to answer is, does SVM∆ map produce higher MAP scores than previous SVM methods?",
                "Tables 9 and 10 present the results of SVM∆ map, SVM∆ roc, and SVMacc when trained on the Indri retrieval functions and TREC submissions, respectively.",
                "Table 11 contains the corresponding results when trained on the TREC submissions without the best submission.",
                "To start with, our results indicate that SVMacc was not competitive with SVM∆ map and SVM∆ roc, and at times underperformed dramatically.",
                "As such, we tried several approaches to improve the performance of SVMacc. 5.2.1 Alternate SVMacc Methods One issue which may cause SVMacc to underperform is the severe imbalance between relevant and non-relevant docTREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236SVM∆ roc 0.237 29/21 0.234 24/26 SVMacc 0.147 47/3 ** 0.155 47/3 ** SVMacc2 0.219 39/11 ** 0.207 43/7 ** SVMacc3 0.113 49/1 ** 0.153 45/5 ** SVMacc4 0.155 48/2 ** 0.155 48/2 ** Table 9: Trained on Indri Functions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287SVM∆ roc 0.282 29/21 0.278 35/15 ** SVMacc 0.213 49/1 ** 0.222 49/1 ** SVMacc2 0.270 34/16 ** 0.261 42/8 ** SVMacc3 0.133 50/0 ** 0.182 46/4 ** SVMacc4 0.233 47/3 ** 0.238 46/4 ** Table 10: Trained on TREC Submissions uments.",
                "The vast majority of the documents are not relevant.",
                "SVMacc2 addresses this problem by assigning more penalty to false negative errors.",
                "For each dataset, the ratio of the false negative to false positive penalties is equal to the ratio of the number non-relevant and relevant documents in that dataset.",
                "Tables 9, 10 and 11 indicate that SVMacc2 still performs significantly worse than SVM∆ map.",
                "Another possible issue is that SVMacc attempts to find just one discriminating threshold b that is query-invariant.",
                "It may be that different queries require different values of b.",
                "Having the learning method trying to find a good b value (when one does not exist) may be detrimental.",
                "We took two approaches to address this issue.",
                "The first method, SVMacc3, converts the retrieval function scores into percentiles.",
                "For example, for document d, query q and retrieval function f, if the score f(d|q) is in the top 90% of the scores f(·|q) for query q, then the converted score is f (d|q) = 0.9.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Tables 9, 10 and 11 show that the performance of SVMacc3 was also not competitive with SVM∆ map.",
                "The second method, SVMacc4, normalizes the scores given by f for each query.",
                "For example, assume for query q that f outputs scores in the range 0.2 to 0.7.",
                "Then for document d, if f(d|q) = 0.6, the converted score would be f (d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Again, Tables 9, 10 and 11 show that SVMacc4 was not competitive with SVM∆ map 5.2.2 MAP vs ROCArea SVM∆ roc performed much better than SVMacc in our experiments.",
                "When trained on Indri retrieval functions (see Table 9), the performance of SVM∆ roc was slight, though not significantly, worse than the performances of SVM∆ map.",
                "However, Table 10 shows that SVM∆ map did significantly outperform SVM∆ roc when trained on the TREC submissions.",
                "Table 11 shows the performance of the models when trained on the TREC submissions with the best submission removed.",
                "The performance of most models degraded by a small amount, with SVM∆ map still having the best performance.",
                "TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Table 11: Trained on TREC Subm. (w/o Best) 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented an SVM method that directly optimizes MAP.",
                "It provides a principled approach and avoids difficult to control heuristics.",
                "We formulated the optimization problem and presented an algorithm which provably finds the solution in polynomial time.",
                "We have shown empirically that our method is generally superior to or competitive with conventional SVMs methods.",
                "Our new method makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for Accuracy and ROCArea.",
                "The computational cost for training is very reasonable in practice.",
                "Since other methods typically require tuning multiple heuristics, we also expect to train fewer models before finding one which achieves good performance.",
                "The learning framework used by our method is fairly general.",
                "A natural extension of this framework would be to develop methods to optimize for other important IR measures, such as Normalized Discounted Cumulative Gain [2, 3, 4, 12] and Mean Reciprocal Rank. 7.",
                "ACKNOWLEDGMENTS This work was funded under NSF Award IIS-0412894, NSF CAREER Award 0237381, and a gift from Yahoo!",
                "Research.",
                "The third author was also partly supported by a Microsoft Research Fellowship. 8.",
                "REFERENCES [1] B. T. Bartell, G. W. Cottrell, and R. K. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the International Conference on <br>machine learning</br> (ICML), 2005. [3] C. J. C. Burges, R. Ragno, and Q.",
                "Le.",
                "Learning to rank with non-smooth cost functions.",
                "In Proceedings of the International Conference on Advances in Neural Information Processing Systems (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y.",
                "Liu, H. Li, Y. Huang, and H.-W. Hon.",
                "Adapting ranking SVM to document retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [5] B. Carterette and D. Petkova.",
                "Learning a ranking from pairwise preferences.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew, and A. Ksikes.",
                "Ensemble selection from libraries of models.",
                "In Proceedings of the International Conference on <br>machine learning</br> (ICML), 2004. [7] J. Davis and M. Goadrich.",
                "The relationship between precision-recall and ROC curves.",
                "In Proceedings of the International Conference on <br>machine learning</br> (ICML), 2006. [8] D. Hawking.",
                "Overview of the TREC-9 web track.",
                "In Proceedings of TREC-2000, 2000. [9] D. Hawking and N. Craswell.",
                "Overview of the TREC-2001 web track.",
                "In Proceedings of TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel, and K. Obermayer.",
                "Large margin rank boundaries for ordinal regression.",
                "Advances in large margin classifiers, 2000. [11] A. Herschtal and B. Raskutti.",
                "Optimising area under the ROC curve using gradient descent.",
                "In Proceedings of the International Conference on <br>machine learning</br> (ICML), 2004. [12] K. Jarvelin and J. Kekalainen.",
                "Ir evaluation methods for retrieving highly relevant documents.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2000. [13] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proceedings of the International Conference on <br>machine learning</br> (ICML), pages 377-384, New York, NY, USA, 2005.",
                "ACM Press. [14] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 111-119, 2001. [15] Y. Lin, Y. Lee, and G. Wahba.",
                "Support vector machines for classification in nonstandard situations.",
                "<br>machine learning</br>, 46:191-202, 2002. [16] D. Metzler and W. B. Croft.",
                "A markov random field model for term dependencies.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 472-479, 2005. [17] K. Morik, P. Brockhausen, and T. Joachims.",
                "Combining statistical learning with a knowledge-based approach.",
                "In Proceedings of the International Conference on <br>machine learning</br>, 1999. [18] S. Robertson.",
                "The probability ranking principle in ir. journal of documentation.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.",
                "Large margin methods for structured and interdependent output variables.",
                "Journal of <br>machine learning</br> Research (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik.",
                "Statistical Learning Theory.",
                "Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz.",
                "Optimizing classifier performance via approximation to the Wilcoxon-Mann-Witney statistic.",
                "In Proceedings of the International Conference on <br>machine learning</br> (ICML), 2003."
            ],
            "original_annotated_samples": [
                "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT <br>machine learning</br> is commonly used to improve ranked retrieval systems.",
                "INTRODUCTION State of the art information retrieval systems commonly use <br>machine learning</br> techniques to learn ranking functions.",
                "THE LEARNING PROBLEM Following the standard <br>machine learning</br> setup, our goal is to learn a function h : X → Y between an input space X (all possible queries) and output space Y (rankings over a corpus).",
                "In Proceedings of the International Conference on <br>machine learning</br> (ICML), 2005. [3] C. J. C. Burges, R. Ragno, and Q.",
                "In Proceedings of the International Conference on <br>machine learning</br> (ICML), 2004. [7] J. Davis and M. Goadrich."
            ],
            "translated_annotated_samples": [
                "Un método de Vectores de Soporte para optimizar la Precisión Promedio Yisong Yue Universidad de Cornell Ithaca, NY, EE. UU. yyue@cs.cornell.edu Thomas Finley Universidad de Cornell Ithaca, NY, EE. UU. tomf@cs.cornell.edu Filip Radlinski Universidad de Cornell Ithaca, NY, EE. UU. filip@cs.cornell.edu Thorsten Joachims Universidad de Cornell Ithaca, NY, EE. UU. tj@cs.cornell.edu RESUMEN El <br>aprendizaje automático</br> se utiliza comúnmente para mejorar los sistemas de recuperación clasificados.",
                "INTRODUCCIÓN Los sistemas de recuperación de información de última generación comúnmente utilizan técnicas de <br>aprendizaje automático</br> para aprender funciones de clasificación.",
                "EL PROBLEMA DEL APRENDIZAJE Siguiendo la configuración estándar del <br>aprendizaje automático</br>, nuestro objetivo es aprender una función h: X → Y entre un espacio de entrada X (todas las consultas posibles) y un espacio de salida Y (clasificaciones sobre un corpus).",
                "En Actas de la Conferencia Internacional sobre <br>Aprendizaje Automático</br> (ICML), 2005. [3] C. J. C. Burges, R. Ragno y Q.",
                "En Actas de la Conferencia Internacional sobre <br>Aprendizaje Automático</br> (ICML), 2004. [7] J. Davis y M. Goadrich."
            ],
            "translated_text": "Un método de Vectores de Soporte para optimizar la Precisión Promedio Yisong Yue Universidad de Cornell Ithaca, NY, EE. UU. yyue@cs.cornell.edu Thomas Finley Universidad de Cornell Ithaca, NY, EE. UU. tomf@cs.cornell.edu Filip Radlinski Universidad de Cornell Ithaca, NY, EE. UU. filip@cs.cornell.edu Thorsten Joachims Universidad de Cornell Ithaca, NY, EE. UU. tj@cs.cornell.edu RESUMEN El <br>aprendizaje automático</br> se utiliza comúnmente para mejorar los sistemas de recuperación clasificados. Debido a dificultades computacionales, se han desarrollado pocas técnicas de aprendizaje para optimizar directamente la precisión media promedio (MAP), a pesar de su uso generalizado en la evaluación de dichos sistemas. Los enfoques existentes que optimizan el MAP no encuentran una solución óptima global o son computacionalmente costosos. Por el contrario, presentamos un algoritmo de aprendizaje SVM general que encuentra de manera eficiente una solución óptima global para una relajación directa de MAP. Evaluamos nuestro enfoque utilizando los corpus de la pista web TREC 9 y TREC 10 (WT10g), comparando con SVM optimizados para precisión y área bajo la curva ROC. En la mayoría de los casos mostramos nuestro método para producir mejoras estadísticamente significativas en las puntuaciones de MAP. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de Recuperación Términos Generales Algoritmo, Teoría, Experimentación 1. INTRODUCCIÓN Los sistemas de recuperación de información de última generación comúnmente utilizan técnicas de <br>aprendizaje automático</br> para aprender funciones de clasificación. Sin embargo, la mayoría de los enfoques actuales no están optimizados para la medida de evaluación más utilizada, es decir, la Precisión Promedio Media (MAP). En cambio, los algoritmos actuales tienden a seguir uno de dos enfoques generales. El primer enfoque es aprender un modelo que estime la probabilidad de que un documento sea relevante dado una consulta (por ejemplo, [18, 14]). Si se resuelve de manera efectiva, la clasificación con el mejor rendimiento de MAP puede derivarse fácilmente de las probabilidades de relevancia. Sin embargo, lograr un MAP alto solo requiere encontrar un buen ordenamiento de los documentos. Como resultado, encontrar buenas probabilidades requiere resolver un problema más difícil de lo necesario, probablemente necesitando más datos de entrenamiento para lograr el mismo rendimiento de MAP. El segundo enfoque común es aprender una función que maximice una medida sustituta. Las medidas de rendimiento optimizadas incluyen precisión [17, 15], área bajo la curva ROC [1, 5, 10, 11, 13, 21] o modificaciones del área bajo la curva ROC [4], y NDCG [2, 3]. Aprender un modelo para optimizar tales medidas podría resultar en un rendimiento de MAP subóptimo. De hecho, aunque algunos sistemas anteriores han obtenido un buen rendimiento de MAP, se sabe que ni lograr una precisión óptima ni un área bajo la curva ROC pueden garantizar un rendimiento de MAP óptimo[7]. En este artículo, presentamos un enfoque general para aprender funciones de clasificación que maximizan el rendimiento de MAP. Específicamente, presentamos un algoritmo SVM que optimiza globalmente una relajación de pérdida de bisagra de MAP. Este enfoque simplifica el proceso de obtener funciones de clasificación con un alto rendimiento de MAP al evitar pasos intermedios adicionales y heurísticas. El nuevo algoritmo también hace que sea conceptualmente tan fácil optimizar las SVM para MAP como anteriormente solo era posible para precisión y ROCArea. A diferencia del trabajo reciente que optimiza directamente el rendimiento de MAP realizado por Metzler & Croft [16] y Caruana et al. [6], nuestra técnica es eficiente computacionalmente al encontrar una solución óptima a nivel global. Al igual que [6, 16], nuestro método aprende un modelo lineal, pero es mucho más eficiente en la práctica y, a diferencia de [16], puede manejar miles de características. Ahora describimos el algoritmo en detalle y proporcionamos la prueba de corrección. A continuación, proporcionamos un análisis del tiempo de ejecución. Concluimos con los resultados empíricos de experimentos en el corpus de la pista web TREC 9 y TREC 10. También hemos desarrollado un paquete de software que implementa nuestro algoritmo y está disponible para uso público. EL PROBLEMA DEL APRENDIZAJE Siguiendo la configuración estándar del <br>aprendizaje automático</br>, nuestro objetivo es aprender una función h: X → Y entre un espacio de entrada X (todas las consultas posibles) y un espacio de salida Y (clasificaciones sobre un corpus). Para cuantificar la calidad de una predicción, ˆy = h(x), consideraremos una función de pérdida ∆ : Y × Y → . ∆(y, ˆy) cuantifica la penalización por hacer la predicción ˆy si la salida correcta es y. La función de pérdida nos permite incorporar medidas específicas de rendimiento, las cuales explotaremos en http://svmrank.yisongyue.com para optimizar el MAP. Nos restringimos al escenario de aprendizaje supervisado, donde pares de entrada/salida (x, y) están disponibles para el entrenamiento y se asume que provienen de alguna distribución fija P(x, y). El objetivo es encontrar una función h tal que el riesgo (es decir, la pérdida esperada), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), se minimice. Por supuesto, P(x, y) es desconocido. Pero dado un conjunto finito de pares de entrenamiento, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, el rendimiento de h en S puede medirse mediante el riesgo empírico, R∆ S (h) = 1 n ∑ i=1 n ∆(yi, h(xi)). En el caso de aprender una función de recuperación clasificada, X denota un espacio de consultas, y Y el espacio de clasificaciones (posiblemente débiles) sobre algún corpus de documentos C = {d1, . . . ,d|C|}. Podemos definir la pérdida de precisión promedio como ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), donde rank(y) es un vector de los valores de rango de cada documento en C. Por ejemplo, para un corpus de dos documentos, {d1, d2}, con d1 teniendo un rango más alto que d2, rank(y) = (1, 0). Suponemos que las clasificaciones verdaderas tienen dos valores de clasificación, donde los documentos relevantes tienen un valor de clasificación 1 y los documentos no relevantes tienen un valor de clasificación 0. Además, asumimos que todas las clasificaciones predichas son clasificaciones completas (sin empates). Sea p = rango(y) y ˆp = rango(ˆy). La puntuación de precisión promedio se define como MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, donde rel = |{i : pi = 1}| es el número de documentos relevantes, y Prec@j es el porcentaje de documentos relevantes en los primeros j documentos en la clasificación predicha ˆy. MAP es la media de las puntuaciones de precisión promedio de un grupo de consultas. La mayoría de los algoritmos de aprendizaje se optimizan para precisión o ROCArea. Si bien optimizar estas medidas podría lograr un buen rendimiento de MAP, usamos dos ejemplos simples para mostrar que también puede ser subóptimo en términos de MAP. ROCArea asigna una penalización igual a cada desordenamiento de un par relevante/no relevante. Por el contrario, MAP asigna mayores penalizaciones a los errores de ordenamiento más arriba en la clasificación predicha. Usando nuestra notación, el Área bajo la Curva ROC (ROCArea) se puede definir como ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], donde p es el ranking verdadero (débil), ˆp es el ranking predicho, y 1[b] es la función indicadora condicionada a b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Tabla 1: Ejemplo y Modelos Supongamos que tenemos un espacio de hipótesis con solo dos funciones de hipótesis, h1 y h2, como se muestra en la Tabla 1. Estas dos hipótesis predicen un ranking para la consulta x sobre un corpus de ocho documentos. Tabla 2: Rendimiento de los Modelos de Juguete La Tabla 2 muestra las puntuaciones de MAP y ROCArea de h1 y h2. Aquí, un método de aprendizaje que optimiza para el Área bajo la curva ROC elegiría h2 ya que esto resulta en un puntaje de Área bajo la curva ROC más alto, pero esto produce un puntaje de MAP subóptimo. 2.2 MAP vs Precisión Usando un ejemplo muy similar, ahora demostramos cómo optimizar para la precisión podría resultar en un puntaje de MAP subóptimo. Los modelos que se optimizan para la precisión no están directamente preocupados por la clasificación. En cambio, aprenden un umbral tal que los documentos que obtienen una puntuación superior al umbral pueden ser clasificados como relevantes y los documentos que obtienen una puntuación inferior como no relevantes. Consideramos nuevamente un espacio de hipótesis con dos hipótesis. La Tabla 3 muestra las predicciones de las dos hipótesis en una única consulta x. Hipótesis MAP Mejor Precisión h1(q) 0.70 0.64 h2(q) 0.64 0.73 Tabla 4: Rendimiento de los Modelos de Juguete La Tabla 4 muestra los puntajes de MAP y mejor precisión de h1(q) y h2(q). La mejor precisión se refiere a la precisión más alta alcanzable en esa clasificación al considerar todos los umbrales posibles. Por ejemplo, con h1(q), un umbral entre los documentos 1 y 2 da 4 errores (documentos 6-9 clasificados incorrectamente como no relevantes), lo que resulta en una precisión de 0.64. De manera similar, con h2(q), un umbral entre los documentos 5 y 6 da 3 errores (los documentos 10-11 clasificados incorrectamente como relevantes, y el documento 1 como no relevante), lo que resulta en una precisión de 0.73. Un método de aprendizaje que optimiza la precisión elegiría h2 ya que esto resulta en un puntaje de precisión más alto, pero esto produce un puntaje de MAP subóptimo. 3. OPTIMIZANDO LA PRECISIÓN PROMEDIO Nos basamos en el enfoque utilizado por [13] para optimizar el Área bajo la Curva ROC. A diferencia de ROCArea, sin embargo, MAP no se descompone linealmente en los ejemplos y requiere un algoritmo sustancialmente extendido, el cual describimos en esta sección. Recuerda que la clasificación verdadera es una clasificación débil con dos valores de clasificación (relevante y no relevante). Que Cx y C¯x denoten el conjunto de documentos relevantes y no relevantes de C para la consulta x, respectivamente. Nos enfocamos en funciones que están parametrizadas por un vector de peso w, y por lo tanto deseamos encontrar w para minimizar el riesgo empírico, R∆ S (w) ≡ R∆ S (h(·; w)). Nuestro enfoque es aprender una función discriminante F: X × Y → sobre pares de entrada-salida. Dada la consulta x, podemos derivar una predicción encontrando la clasificación y que maximiza la función discriminante: h(x; w) = argmax y∈Y F(x, y; w). (1) Suponemos que F es lineal en alguna representación de características combinadas de entradas y salidas Ψ(x, y) ∈ RN, es decir, F(x, y; w) = wT Ψ(x, y). (2) La función de características combinadas que utilizamos es Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))], donde φ: X × C → N es una función de mapeo de características de un par consulta/documento a un punto en un espacio dimensional N. Representamos las clasificaciones como una matriz de ordenamientos por pares, Y ⊂ {−1, 0, +1}|C|×|C| . Para cualquier y ∈ Y, yij = +1 si di está clasificado por delante de dj, y yij = −1 si dj está clasificado por delante de di, y yij = 0 si di y dj tienen el mismo rango. Consideramos solo matrices que corresponden a clasificaciones válidas (es decir, que cumplen con la antisimetría y la transitividad). De manera intuitiva, Ψ es una suma de las diferencias vectoriales de todos los pares de documentos relevantes/no relevantes. Dado que asumimos que las clasificaciones predichas son clasificaciones completas, yij es o bien +1 o −1 (nunca 0). Dado un vector de pesos aprendido w, predecir un ranking (es decir, resolver la ecuación (1)) dado una consulta x se reduce a elegir cada yij para maximizar wT Ψ(x, y). Como también se discute en [13], esto se logra ordenando los documentos por wT φ(x, d) en orden descendente. Discutiremos más adelante las elecciones de φ que utilizamos para nuestros experimentos. 3.1 SVM Estructurales La formulación anterior es muy similar a aprender un modelo lineal directo mientras se entrena en la diferencia de pares de documentos relevantes/no relevantes. Muchos enfoques basados en SVM optimizan sobre estas diferencias en pares (por ejemplo, [5, 10, 13, 4]), aunque estos métodos no optimizan para el MAP durante el entrenamiento. Anteriormente, no estaba claro cómo incorporar funciones de pérdida multivariadas no lineales como la pérdida MAP directamente en problemas de optimización global como el entrenamiento de SVM. Ahora presentamos un método basado en SVM estructurales [19] para abordar este problema. Utilizamos la formulación del SVM estructural, presentada en el Problema de Optimización 1, para aprender un w ∈ RN. Problema de optimización 1. (SVM estructural) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) La función objetivo a minimizar (3) es un compromiso entre la complejidad del modelo, w 2 , y una relajación de pérdida de MAP mediante la pérdida de bisagra, P ξi. Como es habitual en el entrenamiento de SVM, C es igual a 2. Por ejemplo, una dimensión podría ser el número de veces que las palabras de la consulta aparecen en el documento. Algoritmo 1 Algoritmo de plano de corte para resolver OP 1 dentro de la tolerancia. 1: Entrada: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ para todo i = 1, . . . , n 3: repetir 4: para i = 1, . . . , n hacer 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: calcular ˆy = argmaxy∈Y H(y; w) 7: calcular ξi = max{0, maxy∈Wi H(y; w)} 8: si H(ˆy; w) > ξi + entonces 9: Wi ← Wi ∪ {ˆy} 10: w ← optimizar (3) sobre W = S i Wi 11: fin si 12: fin para 13: hasta que ningún Wi haya cambiado durante la iteración parámetro que controla este equilibrio y puede ajustarse para lograr un buen rendimiento en diferentes tareas de entrenamiento. Para cada (xi, yi) en el conjunto de entrenamiento, se añade un conjunto de restricciones de la forma en la ecuación (4) al problema de optimización. Ten en cuenta que wT Ψ(x, y) es exactamente nuestra función discriminante F(x, y; w) (ver ecuación (2)). Durante la predicción, nuestro modelo elige el ranking que maximiza el discriminante (1). Si el valor del discriminante para una clasificación incorrecta y es mayor que para la clasificación verdadera yi (por ejemplo, F(xi, y; w) > F(xi, yi; w)), entonces la variable de holgura correspondiente, ξi, debe ser al menos ∆(yi, y) para que se cumpla esa restricción. Por lo tanto, la suma de los márgenes, P ξi, acota superiormente la pérdida MAP. Esto se establece formalmente en la Proposición 1. Proposición 1. Sea ξ∗ (w) la solución óptima de las variables de holgura para OP 1 para un vector de peso dado w. Entonces 1 n Pn i=1 ξi es una cota superior del riesgo empírico R∆ S (w). (ver [19] para la prueba) La Proposición 1 muestra que OP 1 aprende una función de clasificación que optimiza una cota superior del error de MAP en el conjunto de entrenamiento. Desafortunadamente hay un problema: se requiere una restricción para cada posible resultado incorrecto y, y el número de resultados incorrectos posibles es exponencial en el tamaño de C. Afortunadamente, podemos emplear el Algoritmo 1 para resolver OP 1. El algoritmo 1 es un algoritmo de plano de corte, introduciendo iterativamente restricciones hasta que hayamos resuelto el problema original dentro de una tolerancia deseada [19]. El algoritmo comienza sin restricciones y encuentra de forma iterativa, para cada ejemplo (xi, yi), la salida ˆy asociada con la restricción más violada. Si la restricción correspondiente es violada por más de lo que introducimos ˆy en el conjunto de trabajo Wi de restricciones activas, por ejemplo i, y volvemos a resolver (3) usando el W actualizado. Se puede demostrar que el bucle externo del Algoritmo 1 está garantizado a detenerse dentro de un número polinomial de iteraciones para cualquier precisión deseada. Teorema 1. Sea ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y), ¯∆ = maxi maxy ∆(yi, y), y para cualquier > 0, el Algoritmo 1 termina después de agregar a lo sumo max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff restricciones al conjunto de trabajo W. (ver [19] para la prueba) Sin embargo, dentro del bucle interno de este algoritmo tenemos que calcular argmaxy∈Y H(y; w), donde H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), o equivalentemente, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), ya que wT Ψ(xi, yi) es constante con respecto a y. Aunque está estrechamente relacionado con el procedimiento de clasificación, esto tiene la complicación sustancial de que debemos lidiar con el término adicional ∆(yi, y). Sin la capacidad de encontrar eficientemente la restricción más violada (es decir, resolver argmaxy∈Y H(y, w)), el procedimiento de generación de restricciones no es viable. 3.2 Encontrar la restricción más violada utilizando OP 1 y optimizando la pérdida de ROCArea (∆roc), el problema de encontrar la restricción más violada, o resolver argmaxy∈Y H(y, w) (en adelante argmax H), se aborda en [13]. Resolver argmax H para ∆map es más difícil. Esto se debe principalmente a que ROCArea se descompone de manera ordenada en una suma de puntuaciones calculadas de forma independiente en cada ordenamiento relativo de un par de documentos relevantes/no relevantes. MAP, por otro lado, no se descompone de la misma manera que ROCArea. La principal contribución algorítmica de este artículo es un método eficiente para resolver argmax H para ∆map. Una propiedad útil de ∆map es que es invariante al intercambiar dos documentos con igual relevancia. Por ejemplo, si los documentos da y db son ambos relevantes, entonces intercambiar las posiciones de da y db en cualquier clasificación no afecta a ∆map. Por extensión, ∆map es invariante a cualquier permutación arbitraria de los documentos relevantes entre sí y de los documentos no relevantes entre sí. Sin embargo, esta reorganización afectará la puntuación del discriminante, wT Ψ(x, y). Esto nos lleva a la Observación 1. Observación 1. Considera clasificaciones que estén limitadas por fijar la relevancia en cada posición de la clasificación (por ejemplo, el tercer documento en la clasificación debe ser relevante). Cada clasificación que cumpla con el mismo conjunto de restricciones tendrá el mismo ∆map. Si los documentos relevantes están ordenados por wT φ(x, d) en orden descendente, y los documentos no relevantes también están ordenados de la misma manera por wT φ(x, d), entonces la intercalación de las dos listas ordenadas que cumpla con las restricciones maximizará H para ese conjunto de clasificaciones restringidas. La Observación 1 implica que en la clasificación que maximiza H, los documentos relevantes se ordenarán por wT φ(x, d), y los documentos no relevantes también se ordenarán de la misma manera. Al ordenar primero los documentos relevantes y no relevantes, el problema se simplifica a encontrar la intercalación óptima de dos listas ordenadas. Para el resto de nuestra discusión, asumimos que los documentos relevantes y no relevantes están ordenados por wT φ(x, d) en orden descendente. Para mayor comodidad, también nos referimos a los documentos relevantes como {dx 1 , . . . dx |Cx|} = Cx, y a los documentos no relevantes como {d¯x 1 , . . . d¯x |C¯x|} = C¯x. Definimos δj(i1, i2), con i1 < i2, como el cambio en H desde cuando el documento relevante de mayor rango clasificado después de d¯x j es dx i1 hasta que es dx i2. Para i2 = i1 + 1, tenemos δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5), donde si = wT φ(x, di). El primer término en (5) es el cambio en ∆map cuando el documento relevante i tiene j documentos no relevantes clasificados antes de él, en lugar de j-1. El segundo término es el cambio en la puntuación del discriminante, wT Ψ(x, y), cuando yij cambia de +1 a −1. . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . . Figura 1: Ejemplo para δj(i, i + 1). La Figura 1 proporciona un ejemplo conceptual para δj(i, i + 1). La clasificación inferior difiere de la superior solo cuando d¯x j sube un rango. La diferencia en el valor de H para estas dos clasificaciones es exactamente δj(i, i + 1). Para cualquier i1 < i2, podemos definir δj(i1, i2) como δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) o equivalentemente, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) . Deja que o1, . . . , o|C¯x| codifiquen las posiciones de los documentos no relevantes, donde dx oj es el documento relevante de mayor rango clasificado después del j-ésimo documento no relevante. Debido a la Observación 1, esta codificación identifica de forma única un ranking completo. Podemos recuperar la clasificación como yij = 8 >>>< >>>: 0 si i = j sign(si − sj) si di, dj relevancia igual signo(oj − i − 0.5) si di = dx i , dj = d¯x j signo(j − oi + 0.5) si di = d¯x i , dj = dx j. (7) Ahora podemos reformular H en una nueva función objetivo, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), donde ¯y es la verdadera clasificación (débil). Conceptualmente, H comienza con una clasificación perfecta ¯y y agrega el cambio en H cuando cada documento no relevante sucesivo sube en la clasificación. Luego podemos reformular el problema argmax H como argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) sujeto a o1 ≤ . . . ≤ o|C¯x|. (9) El Algoritmo 2 describe el algoritmo utilizado para resolver la ecuación (8). Conceptualmente, el Algoritmo 2 comienza con un ranking perfecto. Entonces, para cada documento no relevante sucesivo, el algoritmo modifica la solución deslizando ese documento hacia arriba en la clasificación para maximizar localmente H, manteniendo las posiciones de los otros documentos no relevantes constantes. 3.2.1 Prueba de Corrección El Algoritmo 2 es codicioso en el sentido de que encuentra la mejor posición de cada documento no relevante de forma independiente de los otros documentos no relevantes. En otras palabras, el algoritmo maximiza H para cada documento no relevante, d¯x j, Algoritmo 2 Encontrar la Restricción Más Violada (argmax H) para el Algoritmo 1 con ∆map 1: Entrada: w, Cx, C¯x 2: ordenar Cx y C¯x en orden descendente de wT φ(x, d) 3: sx i ← wT φ(x, dx i), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i), i = 1, . . . , |C¯x | 5: para j = 1, . . . , |C¯x | hacer 6: optj ← argmaxk δj(k, |Cx| + 1) 7: fin para 8: codificar ˆy de acuerdo con (7) 9: devolver ˆy sin considerar las posiciones de los otros documentos no relevantes, y así ignora las restricciones de (9). Para que la solución sea factible, el documento no relevante j-ésimo debe ser clasificado después de los primeros j-1 documentos no relevantes, satisfaciendo así opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. Si la solución es factible, entonces claramente resuelve (8). Por lo tanto, basta con demostrar que el Algoritmo 2 cumple con (10). Primero demostramos que δj(·, ·) es monótonamente decreciente en j. Lema 1. Para cualquier 1 ≤ i1 < i2 ≤ |Cx | + 1 y 1 ≤ j < |C¯x |, debe ser el caso que δj+1(i1, i2) ≤ δj(i1, i2). Prueba. Recuerde que tanto δj(i1, i2) como δj+1(i1, i2) son sumas de términos i2 − i1. Mostraremos que cada término en la suma de δj+1(i1, i2) no es mayor que el término correspondiente en δj(i1, i2), o δj+1(k, k + 1) ≤ δj(k, k + 1) para k = i1, . . . , i2 − 1. Cada término en δj(k, k +1) y δj+1(k, k +1) puede ser descompuesto aún más en dos partes (ver (5)). Mostraremos que cada parte de δj+1(k, k + 1) no es mayor que la parte correspondiente en δj(k, k + 1). En otras palabras, demostraremos que tanto j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) como −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) son verdaderos para los valores mencionados de j y k. Es fácil ver que (11) es verdadero observando que para cualquier par de enteros positivos 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1, y eligiendo a = j y b = j + k. La segunda desigualdad (12) se cumple porque el Algoritmo 2 primero ordena d¯x en orden descendente de s¯x, lo que implica s¯x j+1 ≤ s¯x j. Así vemos que cada término en δj+1 no es mayor que el término correspondiente en δj, lo cual completa la prueba. El resultado del Lema 1 conduce directamente a nuestro resultado principal de corrección: Teorema 2. En el Algoritmo 2, los valores calculados de optj satisfacen (10), lo que implica que la solución devuelta por el Algoritmo 2 es factible y, por lo tanto, óptima. Prueba. Demostraremos que optj ≤ optj+1 se cumple para cualquier 1 ≤ j < |C¯x|, implicando así (10). Dado que el Algoritmo 2 calcula optj como optj = argmax k δj(k, |Cx | + 1), (13), entonces por definición de δj (6), para cualquier 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0. Usando el Lema 1, sabemos que δj+1(i, optj) ≤ δj(i, optj) < 0, lo que implica que para cualquier 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0. Supongamos por contradicción que optj+1 < optj. Entonces δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), lo cual contradice (13). Por lo tanto, debe ser el caso que optj ≤ optj+1, lo cual completa la prueba. 3.2.2 Tiempo de ejecución El tiempo de ejecución del Algoritmo 2 se puede dividir en dos partes. La primera parte es la clasificación por wT φ(x, d), lo cual requiere un tiempo de O(n log n), donde n = |Cx | + |C¯x |. La segunda parte calcula cada optj, lo cual requiere un tiempo de O(|Cx| · |C¯x|). Aunque en el peor de los casos esto es O(n2), el número de documentos relevantes, |Cx|, suele ser muy pequeño (por ejemplo, constante con respecto a n), en cuyo caso el tiempo de ejecución para la segunda parte es simplemente O(n). Para la mayoría de los conjuntos de datos del mundo real, el Algoritmo 2 está dominado por la ordenación y tiene una complejidad O(n log n). El Algoritmo 1 está garantizado de detenerse en un número polinómico de iteraciones [19], y cada iteración ejecuta el Algoritmo 2. Prácticamente todos los modelos que funcionaron bien fueron entrenados en un tiempo razonable (generalmente menos de una hora). Una vez que el entrenamiento esté completo, hacer predicciones sobre la consulta x usando la hipótesis resultante h(x|w) solo requiere ordenar por wT φ(x, d). Desarrollamos nuestro software utilizando una interfaz de Python a SVMstruct, ya que el lenguaje Python simplificó en gran medida el proceso de codificación. Para mejorar el rendimiento, es recomendable utilizar la implementación estándar en C de SVMstruct. CONFIGURACIÓN DEL EXPERIMENTO El objetivo principal de nuestros experimentos es evaluar si la optimización directa de MAP conduce a un rendimiento de MAP mejorado en comparación con los métodos convencionales de SVM que optimizan una pérdida sustituta como la precisión o el área bajo la curva ROC. Evaluamos empíricamente nuestro método utilizando dos conjuntos de consultas de la TREC Web Track, uno de TREC 9 y otro de TREC 10 (temas 451-500 y 501-550), ambos de los cuales utilizaron el corpus WT10g. Para cada consulta, TREC proporciona las evaluaciones de relevancia de los documentos. Generamos nuestras características utilizando las puntuaciones de las funciones de recuperación existentes en estas consultas. Si bien nuestro método es agnóstico al significado de las características, elegimos utilizar funciones de recuperación existentes como una forma simple pero efectiva de adquirir características útiles. Por lo tanto, nuestros experimentos de estadísticas de conjuntos de datos básicos esencialmente prueban la capacidad de nuestros métodos para volver a clasificar los documentos altamente clasificados (por ejemplo, volver a combinar las puntuaciones de las funciones de recuperación) para mejorar el MAP. Comparamos nuestro método con las mejores funciones de recuperación entrenadas (en adelante, funciones base), así como con los métodos SVM propuestos anteriormente. Comparar con las mejores funciones base pone a prueba la capacidad de nuestros métodos para aprender una combinación útil. Comparar con métodos SVM anteriores nos permite probar si optimizar directamente para el MAP (en lugar de precisión o área bajo la curva ROC) logra una puntuación de MAP más alta en la práctica. El resto de esta sección describe las funciones base y el método de generación de características en detalle. 4.1 Elección de Funciones de Recuperación Elegimos dos conjuntos de funciones base para nuestros experimentos. Para el primer conjunto, generamos tres índices sobre el corpus WT10g utilizando Indri5. El primer índice fue generado utilizando la configuración predeterminada, el segundo utilizó Porter-stemming, y el último utilizó Porter-stemming y las palabras vacías predeterminadas de Indris. Para TREC 9 y TREC 10, utilizamos la parte de descripción de cada consulta y puntuamos los documentos utilizando cinco de los métodos de recuperación integrados en Indri, que son Similitud Coseno, TFIDF, Okapi, Modelo de Lenguaje con Prior de Dirichlet y Modelo de Lenguaje con Prior de Jelinek-Mercer. Todos los parámetros se mantuvieron en sus valores predeterminados. Calculamos las puntuaciones de estos cinco métodos de recuperación sobre los tres índices, dando un total de 15 funciones base. Para cada consulta, consideramos las puntuaciones de los documentos encontrados en la unión de los mejores 1000 documentos de cada función base. Para nuestro segundo conjunto de funciones base, utilizamos puntuaciones de las presentaciones de la pista web TREC 9 [8] y TREC 10 [9]. Utilizamos solo las presentaciones no manuales y no breves de ambos años. Para TREC 9 y TREC 10, hubo 53 y 18 envíos de este tipo, respectivamente. Una presentación típica contenía puntajes de sus 1000 documentos principales. b ca wT φ(x,d) f(d|x) Figura 2: Ejemplo de Agrupación de Características 4.2 Generación de Características Para generar ejemplos de entrada para nuestro método, se debe proporcionar una instancia concreta de φ. Para cada documento d puntuado por un conjunto de funciones de recuperación F en la consulta x, generamos las características como un vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf, donde f(d|x) denota la puntuación que la función de recuperación f asigna al documento d para la consulta x, y cada Kf es un conjunto de valores reales. Desde un nivel alto, estamos expresando la puntuación de cada función de recuperación utilizando |Kf | + 1 contenedores. Dado que estamos utilizando núcleos lineales, se puede pensar en el problema de aprendizaje como encontrar una buena combinación de piezas constantes de los puntajes de las funciones de recuperación. La Figura 2 muestra un ejemplo de nuestro método de mapeo de características. En este ejemplo tenemos una única característica F = {f}. Aquí, Kf = {a, b, c}, y el vector de pesos es w = wa, wb, wc. Para cualquier documento d y consulta x, tenemos wT φ(x, d) = 8 >>< >>: 0 si f(d|x) < a wa si a ≤ f(d|x) < b wa + wb si b ≤ f(d|x) < c wa + wb + wc si c ≤ f(d|x) . Esto se expresa cualitativamente en la Figura 2, donde wa y wb son positivos, y wc es negativo. Realizamos nuestros experimentos principales utilizando cuatro opciones de F: el conjunto de las funciones de recuperación de Indri mencionadas anteriormente para TREC 9 y TREC 10, y las presentaciones de la pista web para TREC 9 y TREC 10. Para cada F y cada función f ∈ F, elegimos 50 valores para Kf que estuvieran razonablemente espaciados y capturaran la región sensible de f. Utilizando las cuatro opciones de F, generamos cuatro conjuntos de datos para nuestros experimentos principales. La Tabla 5 contiene estadísticas de los conjuntos de datos generados. Hay muchas formas de generar características, y no estamos abogando por nuestro método sobre los demás. Esto fue simplemente un medio eficiente para normalizar las salidas de diferentes funciones y permitir un modelo más expresivo. EXPERIMENTOS Para cada conjunto de datos en la Tabla 5, realizamos 50 pruebas. Para cada prueba, entrenamos con 10 consultas seleccionadas al azar, y seleccionamos otras 5 consultas al azar para un conjunto de validación. Los modelos fueron entrenados utilizando una amplia gama de valores de C. El modelo que tuvo mejor rendimiento en el conjunto de validación fue seleccionado y probado en las 35 consultas restantes. Todas las consultas fueron seleccionadas para estar en los conjuntos de entrenamiento, validación y prueba la misma cantidad de veces. Utilizando esta configuración, realizamos los mismos experimentos mientras usábamos nuestro método (mapa SVM∆), un SVM optimizando para ROCArea (SVM∆ roc) [13], y un SVM de clasificación convencional (SVMacc) [20]. Todos los métodos de SVM utilizaron un kernel lineal. Informamos sobre el rendimiento promedio de todos los modelos en las 50 pruebas. 5.1 Comparación con Funciones Base Al analizar nuestros resultados, la primera pregunta a responder es, ¿puede SVM∆ map aprender un modelo que supere al mejor modelo base TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.290 - 0.287Mejor Func. 0.280 28/22 0.283 29/21 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 36/14 ** Tabla 7: Comparación con Envíos TREC TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288Mejor Func. 0.280 27/23 0.283 31/19 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 35/15 ** Tabla 8: Comparación con Funciones de Envíos TREC (sin el mejor) La Tabla 6 presenta la comparación del mapa SVM∆ con las mejores funciones base de Indri. Cada grupo de columnas contiene el rendimiento del MAP macro-promediado de SVM∆ map o una función base. Las columnas W/L muestran el número de consultas donde SVM∆ map logró un puntaje MAP más alto. Se realizaron pruebas de significancia utilizando la prueba de rango con signo de Wilcoxon de dos colas. Dos estrellas indican un nivel de significancia de 0.95. Todas las tablas que muestran nuestros resultados experimentales están estructuradas de manera idéntica. Aquí encontramos que SVM∆ mapea significativamente mejor que las mejores funciones base. La Tabla 7 muestra la comparación cuando se entrena con las presentaciones de TREC. Si bien logra una puntuación de MAP más alta que las mejores funciones base, la diferencia de rendimiento entre SVM∆ y las funciones base no es significativa. Dado que muchas de estas presentaciones utilizan funciones de puntuación cuidadosamente diseñadas para lograr un alto MAP, es posible que las presentaciones con mejor rendimiento utilicen técnicas que engloben las técnicas de las otras presentaciones. Como resultado, el mapa SVM∆ no sería capaz de aprender una hipótesis que pueda superar significativamente la mejor presentación. Por lo tanto, realizamos los mismos experimentos utilizando un conjunto de datos modificado en el que se eliminaron las características calculadas utilizando la mejor presentación. La tabla 8 muestra los resultados (ten en cuenta que aún estamos comparando con la mejor presentación, aunque no la estamos utilizando para el entrenamiento). Observa que si bien el rendimiento del SVM∆ map se degradó ligeramente, aún era comparable con el de la mejor presentación. 5.2 Comparación con Métodos SVM Anteriores La siguiente pregunta a responder es, ¿produce el SVM∆ map puntajes MAP más altos que los métodos SVM anteriores? Las tablas 9 y 10 presentan los resultados de SVM∆ map, SVM∆ roc y SVMacc cuando se entrenan con las funciones de recuperación de Indri y las presentaciones de TREC, respectivamente. La Tabla 11 contiene los resultados correspondientes cuando se entrena con las presentaciones de TREC sin la mejor presentación. Para empezar, nuestros resultados indican que SVMacc no fue competitivo con SVM∆ map y SVM∆ roc, y a veces tuvo un rendimiento notablemente inferior. Por lo tanto, probamos varios enfoques para mejorar el rendimiento de SVMacc. 5.2.1 Métodos alternativos de SVMacc Un problema que puede causar que SVMacc tenga un rendimiento deficiente es el desequilibrio severo entre documentos relevantes y no relevantes. La gran mayoría de los documentos no son relevantes. SVMacc2 aborda este problema asignando una penalización mayor a los errores de falsos negativos. Para cada conjunto de datos, la proporción de las penalizaciones por falsos negativos a falsos positivos es igual a la proporción entre el número de documentos no relevantes y relevantes en ese conjunto de datos. Las tablas 9, 10 y 11 indican que SVMacc2 sigue teniendo un rendimiento significativamente peor que SVM∆ map. Otro posible problema es que SVMacc intenta encontrar solo un umbral discriminatorio b que sea invariable a la consulta. Puede ser que diferentes consultas requieran diferentes valores de b. Tener el método de aprendizaje intentando encontrar un buen valor de b (cuando no existe) puede ser perjudicial. Tomamos dos enfoques para abordar este problema. El primer método, SVMacc3, convierte las puntuaciones de la función de recuperación en percentiles. Por ejemplo, para el documento d, la consulta q y la función de recuperación f, si la puntuación f(d|q) se encuentra en el 90% superior de las puntuaciones f(·|q) para la consulta q, entonces la puntuación convertida es f(d|q) = 0.9. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Las tablas 9, 10 y 11 muestran que el rendimiento de SVMacc3 tampoco fue competitivo con SVM∆ map. El segundo método, SVMacc4, normaliza las puntuaciones dadas por f para cada consulta. Por ejemplo, suponga para la consulta q que f produce puntuaciones en el rango de 0.2 a 0.7. Entonces, para el documento d, si f(d|q) = 0.6, la puntuación convertida sería f(d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Nuevamente, las Tablas 9, 10 y 11 muestran que SVMacc4 no fue competitivo con SVM∆ map 5.2.2 MAP vs ROCArea. SVM∆ roc tuvo un rendimiento mucho mejor que SVMacc en nuestros experimentos. Cuando se entrenó con las funciones de recuperación de Indri (ver Tabla 9), el rendimiento de SVM∆ roc fue ligeramente, aunque no significativamente, peor que el rendimiento de SVM∆ map. Sin embargo, la Tabla 10 muestra que el mapa SVM∆ superó significativamente al roc SVM∆ cuando se entrenó con las presentaciones de TREC. La tabla 11 muestra el rendimiento de los modelos cuando se entrenan con las presentaciones de TREC y se elimina la mejor presentación. El rendimiento de la mayoría de los modelos se degradó ligeramente, con SVM∆ map aún teniendo el mejor rendimiento. TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288 SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Tabla 11: Entrenado en TREC Subm. (sin Mejor) 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado un método SVM que optimiza directamente el MAP. Proporciona un enfoque basado en principios y evita heurísticas difíciles de controlar. Formulamos el problema de optimización y presentamos un algoritmo que encuentra la solución de manera demostrable en tiempo polinómico. Hemos demostrado empíricamente que nuestro método es generalmente superior o competitivo con los métodos convencionales de SVM. Nuestro nuevo método hace que sea conceptualmente tan fácil optimizar SVMs para MAP como anteriormente solo era posible para Precisión y Área bajo la curva ROC. El costo computacional para el entrenamiento es muy razonable en la práctica. Dado que otros métodos suelen requerir ajustar múltiples heurísticas, también esperamos entrenar menos modelos antes de encontrar uno que logre un buen rendimiento. El marco de aprendizaje utilizado por nuestro método es bastante general. Una extensión natural de este marco sería desarrollar métodos para optimizar otras medidas importantes de IR, como la Ganancia Acumulada Normalizada Descontada [2, 3, 4, 12] y la Reciprocidad Media de Rango. 7. AGRADECIMIENTOS Este trabajo fue financiado bajo el Premio NSF IIS-0412894, el Premio NSF CAREER 0237381 y un obsequio de Yahoo! Investigación. El tercer autor también fue parcialmente apoyado por una Beca de Investigación de Microsoft. 8. REFERENCIAS [1] B. T. Bartell, G. W. Cottrell y R. K. Belew. Combinación automática de múltiples sistemas de recuperación clasificados. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre <br>Aprendizaje Automático</br> (ICML), 2005. [3] C. J. C. Burges, R. Ragno y Q. Lo. Aprendizaje para clasificar con funciones de costo no suaves. En Actas de la Conferencia Internacional sobre Avances en Sistemas de Información Neural (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang y H.-W. Hon. Adaptando el SVM de clasificación para la recuperación de documentos. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [5] B. Carterette y D. Petkova. Aprendiendo un ranking a partir de preferencias por pares. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew y A. Ksikes. Selección de conjunto de bibliotecas de modelos. En Actas de la Conferencia Internacional sobre <br>Aprendizaje Automático</br> (ICML), 2004. [7] J. Davis y M. Goadrich. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "ranked retrieval system": {
            "translated_key": "sistemas de recuperación clasificados",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT Machine learning is commonly used to improve <br>ranked retrieval system</br>s.",
                "Due to computational difficulties, few learning techniques have been developed to directly optimize for mean average precision (MAP), despite its widespread use in evaluating such systems.",
                "Existing approaches optimizing MAP either do not find a globally optimal solution, or are computationally expensive.",
                "In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of MAP.",
                "We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora (WT10g), comparing against SVMs optimized for accuracy and ROCArea.",
                "In most cases we show our method to produce statistically significant improvements in MAP scores.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval Models General Terms Algorithm, Theory, Experimentation 1.",
                "INTRODUCTION State of the art information retrieval systems commonly use machine learning techniques to learn ranking functions.",
                "However, most current approaches do not optimize for the evaluation measure most often used, namely Mean Average Precision (MAP).",
                "Instead, current algorithms tend to take one of two general approaches.",
                "The first approach is to learn a model that estimates the probability of a document being relevant given a query (e.g., [18, 14]).",
                "If solved effectively, the ranking with best MAP performance can easily be derived from the probabilities of relevance.",
                "However, achieving high MAP only requires finding a good ordering of the documents.",
                "As a result, finding good probabilities requires solving a more difficult problem than necessary, likely requiring more training data to achieve the same MAP performance.",
                "The second common approach is to learn a function that maximizes a surrogate measure.",
                "Performance measures optimized include accuracy [17, 15], ROCArea [1, 5, 10, 11, 13, 21] or modifications of ROCArea [4], and NDCG [2, 3].",
                "Learning a model to optimize for such measures might result in suboptimal MAP performance.",
                "In fact, although some previous systems have obtained good MAP performance, it is known that neither achieving optimal accuracy nor ROCArea can guarantee optimal MAP performance[7].",
                "In this paper, we present a general approach for learning ranking functions that maximize MAP performance.",
                "Specifically, we present an SVM algorithm that globally optimizes a hinge-loss relaxation of MAP.",
                "This approach simplifies the process of obtaining ranking functions with high MAP performance by avoiding additional intermediate steps and heuristics.",
                "The new algorithm also makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for accuracy and ROCArea.",
                "In contrast to recent work directly optimizing for MAP performance by Metzler & Croft [16] and Caruana et al. [6], our technique is computationally efficient while finding a globally optimal solution.",
                "Like [6, 16], our method learns a linear model, but is much more efficient in practice and, unlike [16], can handle many thousands of features.",
                "We now describe the algorithm in detail and provide proof of correctness.",
                "Following this, we provide an analysis of running time.",
                "We finish with empirical results from experiments on the TREC 9 and TREC 10 Web Track corpus.",
                "We have also developed a software package implementing our algorithm that is available for public use1 . 2.",
                "THE LEARNING PROBLEM Following the standard machine learning setup, our goal is to learn a function h : X → Y between an input space X (all possible queries) and output space Y (rankings over a corpus).",
                "In order to quantify the quality of a prediction, ˆy = h(x), we will consider a loss function ∆ : Y × Y → . ∆(y, ˆy) quantifies the penalty for making prediction ˆy if the correct output is y.",
                "The loss function allows us to incorporate specific performance measures, which we will exploit 1 http://svmrank.yisongyue.com for optimizing MAP.",
                "We restrict ourselves to the supervised learning scenario, where input/output pairs (x, y) are available for training and are assumed to come from some fixed distribution P(x, y).",
                "The goal is to find a function h such that the risk (i.e., expected loss), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), is minimized.",
                "Of course, P(x, y) is unknown.",
                "But given a finite set of training pairs, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, the performance of h on S can be measured by the empirical risk, R∆ S (h) = 1 n nX i=1 ∆(yi, h(xi)).",
                "In the case of learning a ranked retrieval function, X denotes a space of queries, and Y the space of (possibly weak) rankings over some corpus of documents C = {d1, . . . ,d|C|}.",
                "We can define average precision loss as ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), where rank(y) is a vector of the rank values of each document in C. For example, for a corpus of two documents, {d1, d2}, with d1 having higher rank than d2, rank(y ) = (1, 0).",
                "We assume true rankings have two rank values, where relevant documents have rank value 1 and non-relevant documents rank value 0.",
                "We further assume that all predicted rankings are complete rankings (no ties).",
                "Let p = rank(y) and ˆp = rank(ˆy).",
                "The average precision score is defined as MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, where rel = |{i : pi = 1}| is the number of relevant documents, and Prec@j is the percentage of relevant documents in the top j documents in predicted ranking ˆy.",
                "MAP is the mean of the average precision scores of a group of queries. 2.1 MAP vs ROCArea Most learning algorithms optimize for accuracy or ROCArea.",
                "While optimizing for these measures might achieve good MAP performance, we use two simple examples to show it can also be suboptimal in terms of MAP.",
                "ROCArea assigns equal penalty to each misordering of a relevant/non-relevant pair.",
                "In contrast, MAP assigns greater penalties to misorderings higher up in the predicted ranking.",
                "Using our notation, ROCArea can be defined as ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], where p is the true (weak) ranking, ˆp is the predicted ranking, and 1[b] is the indicator function conditioned on b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Table 1: Toy Example and Models Suppose we have a hypothesis space with only two hypothesis functions, h1 and h2, as shown in Table 1.",
                "These two hypotheses predict a ranking for query x over a corpus of eight documents.",
                "Hypothesis MAP ROCArea h1(x) 0.59 0.47 h2(x) 0.51 0.53 Table 2: Performance of Toy Models Table 2 shows the MAP and ROCArea scores of h1 and h2.",
                "Here, a learning method which optimizes for ROCArea would choose h2 since that results in a higher ROCArea score, but this yields a suboptimal MAP score. 2.2 MAP vs Accuracy Using a very similar example, we now demonstrate how optimizing for accuracy might result in suboptimal MAP.",
                "Models which optimize for accuracy are not directly concerned with the ranking.",
                "Instead, they learn a threshold such that documents scoring higher than the threshold can be classified as relevant and documents scoring lower as nonrelevant.",
                "Doc ID 1 2 3 4 5 6 7 8 9 10 11 p 1 0 0 0 0 1 1 1 1 0 0 rank(h1(x)) 11 10 9 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 9 10 11 Table 3: Toy Example and Models We consider again a hypothesis space with two hypotheses.",
                "Table 3 shows the predictions of the two hypotheses on a single query x. Hypothesis MAP Best Acc. h1(q) 0.70 0.64 h2(q) 0.64 0.73 Table 4: Performance of Toy Models Table 4 shows the MAP and best accuracy scores of h1(q) and h2(q).",
                "The best accuracy refers to the highest achievable accuracy on that ranking when considering all possible thresholds.",
                "For instance, with h1(q), a threshold between documents 1 and 2 gives 4 errors (documents 6-9 incorrectly classified as non-relevant), yielding an accuracy of 0.64.",
                "Similarly, with h2(q), a threshold between documents 5 and 6 gives 3 errors (documents 10-11 incorrectly classified as relevant, and document 1 as non-relevant), yielding an accuracy of 0.73.",
                "A learning method which optimizes for accuracy would choose h2 since that results in a higher accuracy score, but this yields a suboptimal MAP score. 3.",
                "OPTIMIZING AVERAGE PRECISION We build upon the approach used by [13] for optimizing ROCArea.",
                "Unlike ROCArea, however, MAP does not decompose linearly in the examples and requires a substantially extended algorithm, which we describe in this section.",
                "Recall that the true ranking is a weak ranking with two rank values (relevant and non-relevant).",
                "Let Cx and C¯x denote the set of relevant and non-relevant documents of C for query x, respectively.",
                "We focus on functions which are parametrized by a weight vector w, and thus wish to find w to minimize the empirical risk, R∆ S (w) ≡ R∆ S (h(·; w)).",
                "Our approach is to learn a discriminant function F : X × Y → over input-output pairs.",
                "Given query x, we can derive a prediction by finding the ranking y that maximizes the discriminant function: h(x; w) = argmax y∈Y F(x, y; w). (1) We assume F to be linear in some combined feature representation of inputs and outputs Ψ(x, y) ∈ RN , i.e., F(x, y; w) = wT Ψ(x, y). (2) The combined feature function we use is Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))] , where φ : X × C → N is a feature mapping function from a query/document pair to a point in N dimensional space2 .",
                "We represent rankings as a matrix of pairwise orderings, Y ⊂ {−1, 0, +1}|C|×|C| .",
                "For any y ∈ Y, yij = +1 if di is ranked ahead of dj, and yij = −1 if dj is ranked ahead of di, and yij = 0 if di and dj have equal rank.",
                "We consider only matrices which correspond to valid rankings (i.e, obeying antisymmetry and transitivity).",
                "Intuitively, Ψ is a summation over the vector differences of all relevant/non-relevant document pairings.",
                "Since we assume predicted rankings to be complete rankings, yij is either +1 or −1 (never 0).",
                "Given a learned weight vector w, predicting a ranking (i.e. solving equation (1)) given query x reduces to picking each yij to maximize wT Ψ(x, y).",
                "As is also discussed in [13], this is attained by sorting the documents by wT φ(x, d) in descending order.",
                "We will discuss later the choices of φ we used for our experiments. 3.1 Structural SVMs The above formulation is very similar to learning a straightforward linear model while training on the pairwise difference of relevant/non-relevant document pairings.",
                "Many SVM-based approaches optimize over these pairwise differences (e.g., [5, 10, 13, 4]), although these methods do not optimize for MAP during training.",
                "Previously, it was not clear how to incorporate non-linear multivariate loss functions such as MAP loss directly into global optimization problems such as SVM training.",
                "We now present a method based on structural SVMs [19] to address this problem.",
                "We use the structural SVM formulation, presented in Optimization Problem 1, to learn a w ∈ RN .",
                "Optimization Problem 1. (Structural SVM) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) The objective function to be minimized (3) is a tradeoff between model complexity, w 2 , and a hinge loss relaxation of MAP loss, P ξi.",
                "As is usual in SVM training, C is a 2 For example, one dimension might be the number of times the query words appear in the document.",
                "Algorithm 1 Cutting plane algorithm for solving OP 1 within tolerance . 1: Input: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ for all i = 1, . . . , n 3: repeat 4: for i = 1, . . . , n do 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: compute ˆy = argmaxy∈Y H(y; w) 7: compute ξi = max{0, maxy∈Wi H(y; w)} 8: if H(ˆy; w) > ξi + then 9: Wi ← Wi ∪ {ˆy} 10: w ← optimize (3) over W = S i Wi 11: end if 12: end for 13: until no Wi has changed during iteration parameter that controls this tradeoff and can be tuned to achieve good performance in different training tasks.",
                "For each (xi, yi) in the training set, a set of constraints of the form in equation (4) is added to the optimization problem.",
                "Note that wT Ψ(x, y) is exactly our discriminant function F(x, y; w) (see equation (2)).",
                "During prediction, our model chooses the ranking which maximizes the discriminant (1).",
                "If the discriminant value for an incorrect ranking y is greater than for the true ranking yi (e.g., F(xi, y; w) > F(xi, yi; w)), then corresponding slack variable, ξi, must be at least ∆(yi, y) for that constraint to be satisfied.",
                "Therefore, the sum of slacks, P ξi, upper bounds the MAP loss.",
                "This is stated formally in Proposition 1.",
                "Proposition 1.",
                "Let ξ∗ (w) be the optimal solution of the slack variables for OP 1 for a given weight vector w. Then 1 n Pn i=1 ξi is an upper bound on the empirical risk R∆ S (w). (see [19] for proof) Proposition 1 shows that OP 1 learns a ranking function that optimizes an upper bound on MAP error on the training set.",
                "Unfortunately there is a problem: a constraint is required for every possible wrong output y, and the number of possible wrong outputs is exponential in the size of C. Fortunately, we may employ Algorithm 1 to solve OP 1.",
                "Algorithm 1 is a cutting plane algorithm, iteratively introducing constraints until we have solved the original problem within a desired tolerance [19].",
                "The algorithm starts with no constraints, and iteratively finds for each example (xi, yi) the output ˆy associated with the most violated constraint.",
                "If the corresponding constraint is violated by more than we introduce ˆy into the working set Wi of active constraints for example i, and re-solve (3) using the updated W. It can be shown that Algorithm 1s outer loop is guaranteed to halt within a polynomial number of iterations for any desired precision .",
                "Theorem 1.",
                "Let ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y) , ¯∆ = maxi maxy ∆(yi, y), and for any > 0, Algorithm 1 terminates after adding at most max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff constraints to the working set W. (see [19] for proof) However, within the inner loop of this algorithm we have to compute argmaxy∈Y H(y; w), where H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), or equivalently, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), since wT Ψ(xi, yi) is constant with respect to y.",
                "Though closely related to the classification procedure, this has the substantial complication that we must contend with the additional ∆(yi, y) term.",
                "Without the ability to efficiently find the most violated constraint (i.e., solve argmaxy∈Y H(y, w)), the constraint generation procedure is not tractable. 3.2 Finding the Most Violated Constraint Using OP 1 and optimizing to ROCArea loss (∆roc), the problem of finding the most violated constraint, or solving argmaxy∈Y H(y, w) (henceforth argmax H), is addressed in [13].",
                "Solving argmax H for ∆map is more difficult.",
                "This is primarily because ROCArea decomposes nicely into a sum of scores computed independently on each relative ordering of a relevant/non-relevant document pair.",
                "MAP, on the other hand, does not decompose in the same way as ROCArea.",
                "The main algorithmic contribution of this paper is an efficient method for solving argmax H for ∆map.",
                "One useful property of ∆map is that it is invariant to swapping two documents with equal relevance.",
                "For example, if documents da and db are both relevant, then swapping the positions of da and db in any ranking does not affect ∆map.",
                "By extension, ∆map is invariant to any arbitrary permutation of the relevant documents amongst themselves and of the non-relevant documents amongst themselves.",
                "However, this reshuﬄing will affect the discriminant score, wT Ψ(x, y).",
                "This leads us to Observation 1.",
                "Observation 1.",
                "Consider rankings which are constrained by fixing the relevance at each position in the ranking (e.g., the 3rd document in the ranking must be relevant).",
                "Every ranking which satisfies the same set of constraints will have the same ∆map.",
                "If the relevant documents are sorted by wT φ(x, d) in descending order, and the non-relevant documents are likewise sorted by wT φ(x, d), then the interleaving of the two sorted lists which satisfies the constraints will maximize H for that constrained set of rankings.",
                "Observation 1 implies that in the ranking which maximizes H, the relevant documents will be sorted by wT φ(x, d), and the non-relevant documents will also be sorted likewise.",
                "By first sorting the relevant and non-relevant documents, the problem is simplified to finding the optimal interleaving of two sorted lists.",
                "For the rest of our discussion, we assume that the relevant documents and non-relevant documents are both sorted by descending wT φ(x, d).",
                "For convenience, we also refer to relevant documents as {dx 1 , . . . dx |Cx|} = Cx , and non-relevant documents as {d¯x 1 , . . . d¯x |C¯x|} = C¯x .",
                "We define δj(i1, i2), with i1 < i2, as the change in H from when the highest ranked relevant document ranked after d¯x j is dx i1 to when it is dx i2 .",
                "For i2 = i1 + 1, we have δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5) where si = wT φ(x, di).",
                "The first term in (5) is the change in ∆map when the ith relevant document has j non-relevant documents ranked before it, as opposed to j −1.",
                "The second term is the change in the discriminant score, wT Ψ(x, y), when yij changes from +1 to −1. . . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . .",
                "Figure 1: Example for δj(i, i + 1) Figure 1 gives a conceptual example for δj(i, i + 1).",
                "The bottom ranking differs from the top only where d¯x j slides up one rank.",
                "The difference in the value of H for these two rankings is exactly δj(i, i + 1).",
                "For any i1 < i2, we can then define δj(i1, i2) as δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) or equivalently, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) .",
                "Let o1, . . . , o|C¯x| encode the positions of the non-relevant documents, where dx oj is the highest ranked relevant document ranked after the jth non-relevant document.",
                "Due to Observation 1, this encoding uniquely identifies a complete ranking.",
                "We can recover the ranking as yij = 8 >>>< >>>: 0 if i = j sign(si − sj) if di, dj equal relevance sign(oj − i − 0.5) if di = dx i , dj = d¯x j sign(j − oi + 0.5) if di = d¯x i , dj = dx j . (7) We can now reformulate H into a new objective function, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), where ¯y is the true (weak) ranking.",
                "Conceptually H starts with a perfect ranking ¯y, and adds the change in H when each successive non-relevant document slides up the ranking.",
                "We can then reformulate the argmax H problem as argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) s.t. o1 ≤ . . . ≤ o|C¯x|. (9) Algorithm 2 describes the algorithm used to solve equation (8).",
                "Conceptually, Algorithm 2 starts with a perfect ranking.",
                "Then for each successive non-relevant document, the algorithm modifies the solution by sliding that document up the ranking to locally maximize H while keeping the positions of the other non-relevant documents constant. 3.2.1 Proof of Correctness Algorithm 2 is greedy in the sense that it finds the best position of each non-relevant document independently from the other non-relevant documents.",
                "In other words, the algorithm maximizes H for each non-relevant document, d¯x j , Algorithm 2 Finding the Most Violated Constraint (argmax H) for Algorithm 1 with ∆map 1: Input: w, Cx , C¯x 2: sort Cx and C¯x in descending order of wT φ(x, d) 3: sx i ← wT φ(x, dx i ), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i ), i = 1, . . . , |C¯x | 5: for j = 1, . . . , |C¯x | do 6: optj ← argmaxk δj(k, |Cx | + 1) 7: end for 8: encode ˆy according to (7) 9: return ˆy without considering the positions of the other non-relevant documents, and thus ignores the constraints of (9).",
                "In order for the solution to be feasible, the jth non-relevant document must be ranked after the first j − 1 non-relevant documents, thus satisfying opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. (10) If the solution is feasible, the it clearly solves (8).",
                "Therefore, it suffices to prove that Algorithm 2 satisfies (10).",
                "We first prove that δj(·, ·) is monotonically decreasing in j. Lemma 1.",
                "For any 1 ≤ i1 < i2 ≤ |Cx | + 1 and 1 ≤ j < |C¯x |, it must be the case that δj+1(i1, i2) ≤ δj(i1, i2).",
                "Proof.",
                "Recall from (6) that both δj(i1, i2) and δj+1(i1, i2) are summations of i2 − i1 terms.",
                "We will show that each term in the summation of δj+1(i1, i2) is no greater than the corresponding term in δj(i1, i2), or δj+1(k, k + 1) ≤ δj(k, k + 1) for k = i1, . . . , i2 − 1.",
                "Each term in δj(k, k +1) and δj+1(k, k +1) can be further decomposed into two parts (see (5)).",
                "We will show that each part of δj+1(k, k + 1) is no greater than the corresponding part in δj(k, k + 1).",
                "In other words, we will show that both j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) and −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) are true for the aforementioned values of j and k. It is easy to see that (11) is true by observing that for any two positive integers 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1 , and choosing a = j and b = j + k. The second inequality (12) holds because Algorithm 2 first sorts d¯x in descending order of s¯x , implying s¯x j+1 ≤ s¯x j .",
                "Thus we see that each term in δj+1 is no greater than the corresponding term in δj, which completes the proof.",
                "The result of Lemma 1 leads directly to our main correctness result: Theorem 2.",
                "In Algorithm 2, the computed values of optj satisfy (10), implying that the solution returned by Algorithm 2 is feasible and thus optimal.",
                "Proof.",
                "We will prove that optj ≤ optj+1 holds for any 1 ≤ j < |C¯x |, thus implying (10).",
                "Since Algorithm 2 computes optj as optj = argmax k δj(k, |Cx | + 1), (13) then by definition of δj (6), for any 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0.",
                "Using Lemma 1, we know that δj+1(i, optj) ≤ δj(i, optj) < 0, which implies that for any 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0.",
                "Suppose for contradiction that optj+1 < optj.",
                "Then δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), which contradicts (13).",
                "Therefore, it must be the case that optj ≤ optj+1, which completes the proof. 3.2.2 Running Time The running time of Algorithm 2 can be split into two parts.",
                "The first part is the sort by wT φ(x, d), which requires O(n log n) time, where n = |Cx | + |C¯x |.",
                "The second part computes each optj, which requires O(|Cx | · |C¯x |) time.",
                "Though in the worst case this is O(n2 ), the number of relevant documents, |Cx |, is often very small (e.g., constant with respect to n), in which case the running time for the second part is simply O(n).",
                "For most real-world datasets, Algorithm 2 is dominated by the sort and has complexity O(n log n).",
                "Algorithm 1 is guaranteed to halt in a polynomial number of iterations [19], and each iteration runs Algorithm 2.",
                "Virtually all well-performing models were trained in a reasonable amount of time (usually less than one hour).",
                "Once training is complete, making predictions on query x using the resulting hypothesis h(x|w) requires only sorting by wT φ(x, d).",
                "We developed our software using a Python interface3 to SVMstruct , since the Python language greatly simplified the coding process.",
                "To improve performance, it is advisable to use the standard C implementation4 of SVMstruct . 4.",
                "EXPERIMENT SETUP The main goal of our experiments is to evaluate whether directly optimizing MAP leads to improved MAP performance compared to conventional SVM methods that optimize a substitute loss such as accuracy or ROCArea.",
                "We empirically evaluate our method using two sets of TREC Web Track queries, one each from TREC 9 and TREC 10 (topics 451-500 and 501-550), both of which used the WT10g corpus.",
                "For each query, TREC provides the relevance judgments of the documents.",
                "We generated our features using the scores of existing retrieval functions on these queries.",
                "While our method is agnostic to the meaning of the features, we chose to use existing retrieval functions as a simple yet effective way of acquiring useful features.",
                "As such, our 3 http://www.cs.cornell.edu/~tomf/svmpython/ 4 http://svmlight.joachims.org/svm_struct.html Dataset Base Funcs Features TREC 9 Indri 15 750 TREC 10 Indri 15 750 TREC 9 Submissions 53 2650 TREC 10 Submissions 18 900 Table 5: Dataset Statistics experiments essentially test our methods ability to re-rank the highly ranked documents (e.g., re-combine the scores of the retrieval functions) to improve MAP.",
                "We compare our method against the best retrieval functions trained on (henceforth base functions), as well as against previously proposed SVM methods.",
                "Comparing with the best base functions tests our methods ability to learn a useful combination.",
                "Comparing with previous SVM methods allows us to test whether optimizing directly for MAP (as opposed to accuracy or ROCArea) achieves a higher MAP score in practice.",
                "The rest of this section describes the base functions and the feature generation method in detail. 4.1 Choosing Retrieval Functions We chose two sets of base functions for our experiments.",
                "For the first set, we generated three indices over the WT10g corpus using Indri5 .",
                "The first index was generated using default settings, the second used Porter-stemming, and the last used Porter-stemming and Indris default stopwords.",
                "For both TREC 9 and TREC 10, we used the description portion of each query and scored the documents using five of Indris built-in retrieval methods, which are Cosine Similarity, TFIDF, Okapi, Language Model with Dirichlet Prior, and Language Model with Jelinek-Mercer Prior.",
                "All parameters were kept as their defaults.",
                "We computed the scores of these five retrieval methods over the three indices, giving 15 base functions in total.",
                "For each query, we considered the scores of documents found in the union of the top 1000 documents of each base function.",
                "For our second set of base functions, we used scores from the TREC 9 [8] and TREC 10 [9] Web Track submissions.",
                "We used only the non-manual, non-short submissions from both years.",
                "For TREC 9 and TREC 10, there were 53 and 18 such submissions, respectively.",
                "A typical submission contained scores of its top 1000 documents. b ca wT φ(x,d) f(d|x) Figure 2: Example Feature Binning 4.2 Generating Features In order to generate input examples for our method, a concrete instantiation of φ must be provided.",
                "For each doc5 http://www.lemurproject.org TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236Best Func. 0.204 39/11 ** 0.181 37/13 ** 2nd Best 0.199 38/12 ** 0.174 43/7 ** 3rd Best 0.188 34/16 ** 0.174 38/12 ** Table 6: Comparison with Indri Functions ument d scored by a set of retrieval functions F on query x, we generate the features as a vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf , where f(d|x) denotes the score that retrieval function f assigns to document d for query x, and each Kf is a set of real values.",
                "From a high level, we are expressing the score of each retrieval function using |Kf | + 1 bins.",
                "Since we are using linear kernels, one can think of the learning problem as finding a good piecewise-constant combination of the scores of the retrieval functions.",
                "Figure 2 shows an example of our feature mapping method.",
                "In this example we have a single feature F = {f}.",
                "Here, Kf = {a, b, c}, and the weight vector is w = wa, wb, wc .",
                "For any document d and query x, we have wT φ(x, d) = 8 >>< >>: 0 if f(d|x) < a wa if a ≤ f(d|x) < b wa + wb if b ≤ f(d|x) < c wa + wb + wc if c ≤ f(d|x) .",
                "This is expressed qualitatively in Figure 2, where wa and wb are positive, and wc is negative.",
                "We ran our main experiments using four choices of F: the set of aforementioned Indri retrieval functions for TREC 9 and TREC 10, and the Web Track submissions for TREC 9 and TREC 10.",
                "For each F and each function f ∈ F, we chose 50 values for Kf which are reasonably spaced and capture the sensitive region of f. Using the four choices of F, we generated four datasets for our main experiments.",
                "Table 5 contains statistics of the generated datasets.",
                "There are many ways to generate features, and we are not advocating our method over others.",
                "This was simply an efficient means to normalize the outputs of different functions and allow for a more expressive model. 5.",
                "EXPERIMENTS For each dataset in Table 5, we performed 50 trials.",
                "For each trial, we train on 10 randomly selected queries, and select another 5 queries at random for a validation set.",
                "Models were trained using a wide range of C values.",
                "The model which performed best on the validation set was selected and tested on the remaining 35 queries.",
                "All queries were selected to be in the training, validation and test sets the same number of times.",
                "Using this setup, we performed the same experiments while using our method (SVM∆ map), an SVM optimizing for ROCArea (SVM∆ roc) [13], and a conventional classification SVM (SVMacc) [20].",
                "All SVM methods used a linear kernel.",
                "We reported the average performance of all models over the 50 trials. 5.1 Comparison with Base Functions In analyzing our results, the first question to answer is, can SVM∆ map learn a model which outperforms the best base TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287Best Func. 0.280 28/22 0.283 29/21 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 36/14 ** Table 7: Comparison with TREC Submissions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288Best Func. 0.280 27/23 0.283 31/19 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 35/15 ** Table 8: Comparison with TREC Subm. (w/o best) functions?",
                "Table 6 presents the comparison of SVM∆ map with the best Indri base functions.",
                "Each column group contains the macro-averaged MAP performance of SVM∆ map or a base function.",
                "The W/L columns show the number of queries where SVM∆ map achieved a higher MAP score.",
                "Significance tests were performed using the two-tailed Wilcoxon signed rank test.",
                "Two stars indicate a significance level of 0.95.",
                "All tables displaying our experimental results are structured identically.",
                "Here, we find that SVM∆ map significantly outperforms the best base functions.",
                "Table 7 shows the comparison when trained on TREC submissions.",
                "While achieving a higher MAP score than the best base functions, the performance difference between SVM∆ map the base functions is not significant.",
                "Given that many of these submissions use scoring functions which are carefully crafted to achieve high MAP, it is possible that the best performing submissions use techniques which subsume the techniques of the other submissions.",
                "As a result, SVM∆ map would not be able to learn a hypothesis which can significantly out-perform the best submission.",
                "Hence, we ran the same experiments using a modified dataset where the features computed using the best submission were removed.",
                "Table 8 shows the results (note that we are still comparing against the best submission though we are not using it for training).",
                "Notice that while the performance of SVM∆ map degraded slightly, the performance was still comparable with that of the best submission. 5.2 Comparison w/ Previous SVM Methods The next question to answer is, does SVM∆ map produce higher MAP scores than previous SVM methods?",
                "Tables 9 and 10 present the results of SVM∆ map, SVM∆ roc, and SVMacc when trained on the Indri retrieval functions and TREC submissions, respectively.",
                "Table 11 contains the corresponding results when trained on the TREC submissions without the best submission.",
                "To start with, our results indicate that SVMacc was not competitive with SVM∆ map and SVM∆ roc, and at times underperformed dramatically.",
                "As such, we tried several approaches to improve the performance of SVMacc. 5.2.1 Alternate SVMacc Methods One issue which may cause SVMacc to underperform is the severe imbalance between relevant and non-relevant docTREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236SVM∆ roc 0.237 29/21 0.234 24/26 SVMacc 0.147 47/3 ** 0.155 47/3 ** SVMacc2 0.219 39/11 ** 0.207 43/7 ** SVMacc3 0.113 49/1 ** 0.153 45/5 ** SVMacc4 0.155 48/2 ** 0.155 48/2 ** Table 9: Trained on Indri Functions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287SVM∆ roc 0.282 29/21 0.278 35/15 ** SVMacc 0.213 49/1 ** 0.222 49/1 ** SVMacc2 0.270 34/16 ** 0.261 42/8 ** SVMacc3 0.133 50/0 ** 0.182 46/4 ** SVMacc4 0.233 47/3 ** 0.238 46/4 ** Table 10: Trained on TREC Submissions uments.",
                "The vast majority of the documents are not relevant.",
                "SVMacc2 addresses this problem by assigning more penalty to false negative errors.",
                "For each dataset, the ratio of the false negative to false positive penalties is equal to the ratio of the number non-relevant and relevant documents in that dataset.",
                "Tables 9, 10 and 11 indicate that SVMacc2 still performs significantly worse than SVM∆ map.",
                "Another possible issue is that SVMacc attempts to find just one discriminating threshold b that is query-invariant.",
                "It may be that different queries require different values of b.",
                "Having the learning method trying to find a good b value (when one does not exist) may be detrimental.",
                "We took two approaches to address this issue.",
                "The first method, SVMacc3, converts the retrieval function scores into percentiles.",
                "For example, for document d, query q and retrieval function f, if the score f(d|q) is in the top 90% of the scores f(·|q) for query q, then the converted score is f (d|q) = 0.9.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Tables 9, 10 and 11 show that the performance of SVMacc3 was also not competitive with SVM∆ map.",
                "The second method, SVMacc4, normalizes the scores given by f for each query.",
                "For example, assume for query q that f outputs scores in the range 0.2 to 0.7.",
                "Then for document d, if f(d|q) = 0.6, the converted score would be f (d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Again, Tables 9, 10 and 11 show that SVMacc4 was not competitive with SVM∆ map 5.2.2 MAP vs ROCArea SVM∆ roc performed much better than SVMacc in our experiments.",
                "When trained on Indri retrieval functions (see Table 9), the performance of SVM∆ roc was slight, though not significantly, worse than the performances of SVM∆ map.",
                "However, Table 10 shows that SVM∆ map did significantly outperform SVM∆ roc when trained on the TREC submissions.",
                "Table 11 shows the performance of the models when trained on the TREC submissions with the best submission removed.",
                "The performance of most models degraded by a small amount, with SVM∆ map still having the best performance.",
                "TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Table 11: Trained on TREC Subm. (w/o Best) 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented an SVM method that directly optimizes MAP.",
                "It provides a principled approach and avoids difficult to control heuristics.",
                "We formulated the optimization problem and presented an algorithm which provably finds the solution in polynomial time.",
                "We have shown empirically that our method is generally superior to or competitive with conventional SVMs methods.",
                "Our new method makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for Accuracy and ROCArea.",
                "The computational cost for training is very reasonable in practice.",
                "Since other methods typically require tuning multiple heuristics, we also expect to train fewer models before finding one which achieves good performance.",
                "The learning framework used by our method is fairly general.",
                "A natural extension of this framework would be to develop methods to optimize for other important IR measures, such as Normalized Discounted Cumulative Gain [2, 3, 4, 12] and Mean Reciprocal Rank. 7.",
                "ACKNOWLEDGMENTS This work was funded under NSF Award IIS-0412894, NSF CAREER Award 0237381, and a gift from Yahoo!",
                "Research.",
                "The third author was also partly supported by a Microsoft Research Fellowship. 8.",
                "REFERENCES [1] B. T. Bartell, G. W. Cottrell, and R. K. Belew.",
                "Automatic combination of multiple <br>ranked retrieval system</br>s.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2005. [3] C. J. C. Burges, R. Ragno, and Q.",
                "Le.",
                "Learning to rank with non-smooth cost functions.",
                "In Proceedings of the International Conference on Advances in Neural Information Processing Systems (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y.",
                "Liu, H. Li, Y. Huang, and H.-W. Hon.",
                "Adapting ranking SVM to document retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [5] B. Carterette and D. Petkova.",
                "Learning a ranking from pairwise preferences.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew, and A. Ksikes.",
                "Ensemble selection from libraries of models.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [7] J. Davis and M. Goadrich.",
                "The relationship between precision-recall and ROC curves.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2006. [8] D. Hawking.",
                "Overview of the TREC-9 web track.",
                "In Proceedings of TREC-2000, 2000. [9] D. Hawking and N. Craswell.",
                "Overview of the TREC-2001 web track.",
                "In Proceedings of TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel, and K. Obermayer.",
                "Large margin rank boundaries for ordinal regression.",
                "Advances in large margin classifiers, 2000. [11] A. Herschtal and B. Raskutti.",
                "Optimising area under the ROC curve using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [12] K. Jarvelin and J. Kekalainen.",
                "Ir evaluation methods for retrieving highly relevant documents.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2000. [13] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proceedings of the International Conference on Machine Learning (ICML), pages 377-384, New York, NY, USA, 2005.",
                "ACM Press. [14] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 111-119, 2001. [15] Y. Lin, Y. Lee, and G. Wahba.",
                "Support vector machines for classification in nonstandard situations.",
                "Machine Learning, 46:191-202, 2002. [16] D. Metzler and W. B. Croft.",
                "A markov random field model for term dependencies.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 472-479, 2005. [17] K. Morik, P. Brockhausen, and T. Joachims.",
                "Combining statistical learning with a knowledge-based approach.",
                "In Proceedings of the International Conference on Machine Learning, 1999. [18] S. Robertson.",
                "The probability ranking principle in ir. journal of documentation.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.",
                "Large margin methods for structured and interdependent output variables.",
                "Journal of Machine Learning Research (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik.",
                "Statistical Learning Theory.",
                "Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz.",
                "Optimizing classifier performance via approximation to the Wilcoxon-Mann-Witney statistic.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2003."
            ],
            "original_annotated_samples": [
                "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT Machine learning is commonly used to improve <br>ranked retrieval system</br>s.",
                "Automatic combination of multiple <br>ranked retrieval system</br>s."
            ],
            "translated_annotated_samples": [
                "Un método de Vectores de Soporte para optimizar la Precisión Promedio Yisong Yue Universidad de Cornell Ithaca, NY, EE. UU. yyue@cs.cornell.edu Thomas Finley Universidad de Cornell Ithaca, NY, EE. UU. tomf@cs.cornell.edu Filip Radlinski Universidad de Cornell Ithaca, NY, EE. UU. filip@cs.cornell.edu Thorsten Joachims Universidad de Cornell Ithaca, NY, EE. UU. tj@cs.cornell.edu RESUMEN El aprendizaje automático se utiliza comúnmente para mejorar los <br>sistemas de recuperación clasificados</br>.",
                "Combinación automática de múltiples <br>sistemas de recuperación clasificados</br>."
            ],
            "translated_text": "Un método de Vectores de Soporte para optimizar la Precisión Promedio Yisong Yue Universidad de Cornell Ithaca, NY, EE. UU. yyue@cs.cornell.edu Thomas Finley Universidad de Cornell Ithaca, NY, EE. UU. tomf@cs.cornell.edu Filip Radlinski Universidad de Cornell Ithaca, NY, EE. UU. filip@cs.cornell.edu Thorsten Joachims Universidad de Cornell Ithaca, NY, EE. UU. tj@cs.cornell.edu RESUMEN El aprendizaje automático se utiliza comúnmente para mejorar los <br>sistemas de recuperación clasificados</br>. Debido a dificultades computacionales, se han desarrollado pocas técnicas de aprendizaje para optimizar directamente la precisión media promedio (MAP), a pesar de su uso generalizado en la evaluación de dichos sistemas. Los enfoques existentes que optimizan el MAP no encuentran una solución óptima global o son computacionalmente costosos. Por el contrario, presentamos un algoritmo de aprendizaje SVM general que encuentra de manera eficiente una solución óptima global para una relajación directa de MAP. Evaluamos nuestro enfoque utilizando los corpus de la pista web TREC 9 y TREC 10 (WT10g), comparando con SVM optimizados para precisión y área bajo la curva ROC. En la mayoría de los casos mostramos nuestro método para producir mejoras estadísticamente significativas en las puntuaciones de MAP. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de Recuperación Términos Generales Algoritmo, Teoría, Experimentación 1. INTRODUCCIÓN Los sistemas de recuperación de información de última generación comúnmente utilizan técnicas de aprendizaje automático para aprender funciones de clasificación. Sin embargo, la mayoría de los enfoques actuales no están optimizados para la medida de evaluación más utilizada, es decir, la Precisión Promedio Media (MAP). En cambio, los algoritmos actuales tienden a seguir uno de dos enfoques generales. El primer enfoque es aprender un modelo que estime la probabilidad de que un documento sea relevante dado una consulta (por ejemplo, [18, 14]). Si se resuelve de manera efectiva, la clasificación con el mejor rendimiento de MAP puede derivarse fácilmente de las probabilidades de relevancia. Sin embargo, lograr un MAP alto solo requiere encontrar un buen ordenamiento de los documentos. Como resultado, encontrar buenas probabilidades requiere resolver un problema más difícil de lo necesario, probablemente necesitando más datos de entrenamiento para lograr el mismo rendimiento de MAP. El segundo enfoque común es aprender una función que maximice una medida sustituta. Las medidas de rendimiento optimizadas incluyen precisión [17, 15], área bajo la curva ROC [1, 5, 10, 11, 13, 21] o modificaciones del área bajo la curva ROC [4], y NDCG [2, 3]. Aprender un modelo para optimizar tales medidas podría resultar en un rendimiento de MAP subóptimo. De hecho, aunque algunos sistemas anteriores han obtenido un buen rendimiento de MAP, se sabe que ni lograr una precisión óptima ni un área bajo la curva ROC pueden garantizar un rendimiento de MAP óptimo[7]. En este artículo, presentamos un enfoque general para aprender funciones de clasificación que maximizan el rendimiento de MAP. Específicamente, presentamos un algoritmo SVM que optimiza globalmente una relajación de pérdida de bisagra de MAP. Este enfoque simplifica el proceso de obtener funciones de clasificación con un alto rendimiento de MAP al evitar pasos intermedios adicionales y heurísticas. El nuevo algoritmo también hace que sea conceptualmente tan fácil optimizar las SVM para MAP como anteriormente solo era posible para precisión y ROCArea. A diferencia del trabajo reciente que optimiza directamente el rendimiento de MAP realizado por Metzler & Croft [16] y Caruana et al. [6], nuestra técnica es eficiente computacionalmente al encontrar una solución óptima a nivel global. Al igual que [6, 16], nuestro método aprende un modelo lineal, pero es mucho más eficiente en la práctica y, a diferencia de [16], puede manejar miles de características. Ahora describimos el algoritmo en detalle y proporcionamos la prueba de corrección. A continuación, proporcionamos un análisis del tiempo de ejecución. Concluimos con los resultados empíricos de experimentos en el corpus de la pista web TREC 9 y TREC 10. También hemos desarrollado un paquete de software que implementa nuestro algoritmo y está disponible para uso público. EL PROBLEMA DEL APRENDIZAJE Siguiendo la configuración estándar del aprendizaje automático, nuestro objetivo es aprender una función h: X → Y entre un espacio de entrada X (todas las consultas posibles) y un espacio de salida Y (clasificaciones sobre un corpus). Para cuantificar la calidad de una predicción, ˆy = h(x), consideraremos una función de pérdida ∆ : Y × Y → . ∆(y, ˆy) cuantifica la penalización por hacer la predicción ˆy si la salida correcta es y. La función de pérdida nos permite incorporar medidas específicas de rendimiento, las cuales explotaremos en http://svmrank.yisongyue.com para optimizar el MAP. Nos restringimos al escenario de aprendizaje supervisado, donde pares de entrada/salida (x, y) están disponibles para el entrenamiento y se asume que provienen de alguna distribución fija P(x, y). El objetivo es encontrar una función h tal que el riesgo (es decir, la pérdida esperada), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), se minimice. Por supuesto, P(x, y) es desconocido. Pero dado un conjunto finito de pares de entrenamiento, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, el rendimiento de h en S puede medirse mediante el riesgo empírico, R∆ S (h) = 1 n ∑ i=1 n ∆(yi, h(xi)). En el caso de aprender una función de recuperación clasificada, X denota un espacio de consultas, y Y el espacio de clasificaciones (posiblemente débiles) sobre algún corpus de documentos C = {d1, . . . ,d|C|}. Podemos definir la pérdida de precisión promedio como ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), donde rank(y) es un vector de los valores de rango de cada documento en C. Por ejemplo, para un corpus de dos documentos, {d1, d2}, con d1 teniendo un rango más alto que d2, rank(y) = (1, 0). Suponemos que las clasificaciones verdaderas tienen dos valores de clasificación, donde los documentos relevantes tienen un valor de clasificación 1 y los documentos no relevantes tienen un valor de clasificación 0. Además, asumimos que todas las clasificaciones predichas son clasificaciones completas (sin empates). Sea p = rango(y) y ˆp = rango(ˆy). La puntuación de precisión promedio se define como MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, donde rel = |{i : pi = 1}| es el número de documentos relevantes, y Prec@j es el porcentaje de documentos relevantes en los primeros j documentos en la clasificación predicha ˆy. MAP es la media de las puntuaciones de precisión promedio de un grupo de consultas. La mayoría de los algoritmos de aprendizaje se optimizan para precisión o ROCArea. Si bien optimizar estas medidas podría lograr un buen rendimiento de MAP, usamos dos ejemplos simples para mostrar que también puede ser subóptimo en términos de MAP. ROCArea asigna una penalización igual a cada desordenamiento de un par relevante/no relevante. Por el contrario, MAP asigna mayores penalizaciones a los errores de ordenamiento más arriba en la clasificación predicha. Usando nuestra notación, el Área bajo la Curva ROC (ROCArea) se puede definir como ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], donde p es el ranking verdadero (débil), ˆp es el ranking predicho, y 1[b] es la función indicadora condicionada a b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Tabla 1: Ejemplo y Modelos Supongamos que tenemos un espacio de hipótesis con solo dos funciones de hipótesis, h1 y h2, como se muestra en la Tabla 1. Estas dos hipótesis predicen un ranking para la consulta x sobre un corpus de ocho documentos. Tabla 2: Rendimiento de los Modelos de Juguete La Tabla 2 muestra las puntuaciones de MAP y ROCArea de h1 y h2. Aquí, un método de aprendizaje que optimiza para el Área bajo la curva ROC elegiría h2 ya que esto resulta en un puntaje de Área bajo la curva ROC más alto, pero esto produce un puntaje de MAP subóptimo. 2.2 MAP vs Precisión Usando un ejemplo muy similar, ahora demostramos cómo optimizar para la precisión podría resultar en un puntaje de MAP subóptimo. Los modelos que se optimizan para la precisión no están directamente preocupados por la clasificación. En cambio, aprenden un umbral tal que los documentos que obtienen una puntuación superior al umbral pueden ser clasificados como relevantes y los documentos que obtienen una puntuación inferior como no relevantes. Consideramos nuevamente un espacio de hipótesis con dos hipótesis. La Tabla 3 muestra las predicciones de las dos hipótesis en una única consulta x. Hipótesis MAP Mejor Precisión h1(q) 0.70 0.64 h2(q) 0.64 0.73 Tabla 4: Rendimiento de los Modelos de Juguete La Tabla 4 muestra los puntajes de MAP y mejor precisión de h1(q) y h2(q). La mejor precisión se refiere a la precisión más alta alcanzable en esa clasificación al considerar todos los umbrales posibles. Por ejemplo, con h1(q), un umbral entre los documentos 1 y 2 da 4 errores (documentos 6-9 clasificados incorrectamente como no relevantes), lo que resulta en una precisión de 0.64. De manera similar, con h2(q), un umbral entre los documentos 5 y 6 da 3 errores (los documentos 10-11 clasificados incorrectamente como relevantes, y el documento 1 como no relevante), lo que resulta en una precisión de 0.73. Un método de aprendizaje que optimiza la precisión elegiría h2 ya que esto resulta en un puntaje de precisión más alto, pero esto produce un puntaje de MAP subóptimo. 3. OPTIMIZANDO LA PRECISIÓN PROMEDIO Nos basamos en el enfoque utilizado por [13] para optimizar el Área bajo la Curva ROC. A diferencia de ROCArea, sin embargo, MAP no se descompone linealmente en los ejemplos y requiere un algoritmo sustancialmente extendido, el cual describimos en esta sección. Recuerda que la clasificación verdadera es una clasificación débil con dos valores de clasificación (relevante y no relevante). Que Cx y C¯x denoten el conjunto de documentos relevantes y no relevantes de C para la consulta x, respectivamente. Nos enfocamos en funciones que están parametrizadas por un vector de peso w, y por lo tanto deseamos encontrar w para minimizar el riesgo empírico, R∆ S (w) ≡ R∆ S (h(·; w)). Nuestro enfoque es aprender una función discriminante F: X × Y → sobre pares de entrada-salida. Dada la consulta x, podemos derivar una predicción encontrando la clasificación y que maximiza la función discriminante: h(x; w) = argmax y∈Y F(x, y; w). (1) Suponemos que F es lineal en alguna representación de características combinadas de entradas y salidas Ψ(x, y) ∈ RN, es decir, F(x, y; w) = wT Ψ(x, y). (2) La función de características combinadas que utilizamos es Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))], donde φ: X × C → N es una función de mapeo de características de un par consulta/documento a un punto en un espacio dimensional N. Representamos las clasificaciones como una matriz de ordenamientos por pares, Y ⊂ {−1, 0, +1}|C|×|C| . Para cualquier y ∈ Y, yij = +1 si di está clasificado por delante de dj, y yij = −1 si dj está clasificado por delante de di, y yij = 0 si di y dj tienen el mismo rango. Consideramos solo matrices que corresponden a clasificaciones válidas (es decir, que cumplen con la antisimetría y la transitividad). De manera intuitiva, Ψ es una suma de las diferencias vectoriales de todos los pares de documentos relevantes/no relevantes. Dado que asumimos que las clasificaciones predichas son clasificaciones completas, yij es o bien +1 o −1 (nunca 0). Dado un vector de pesos aprendido w, predecir un ranking (es decir, resolver la ecuación (1)) dado una consulta x se reduce a elegir cada yij para maximizar wT Ψ(x, y). Como también se discute en [13], esto se logra ordenando los documentos por wT φ(x, d) en orden descendente. Discutiremos más adelante las elecciones de φ que utilizamos para nuestros experimentos. 3.1 SVM Estructurales La formulación anterior es muy similar a aprender un modelo lineal directo mientras se entrena en la diferencia de pares de documentos relevantes/no relevantes. Muchos enfoques basados en SVM optimizan sobre estas diferencias en pares (por ejemplo, [5, 10, 13, 4]), aunque estos métodos no optimizan para el MAP durante el entrenamiento. Anteriormente, no estaba claro cómo incorporar funciones de pérdida multivariadas no lineales como la pérdida MAP directamente en problemas de optimización global como el entrenamiento de SVM. Ahora presentamos un método basado en SVM estructurales [19] para abordar este problema. Utilizamos la formulación del SVM estructural, presentada en el Problema de Optimización 1, para aprender un w ∈ RN. Problema de optimización 1. (SVM estructural) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) La función objetivo a minimizar (3) es un compromiso entre la complejidad del modelo, w 2 , y una relajación de pérdida de MAP mediante la pérdida de bisagra, P ξi. Como es habitual en el entrenamiento de SVM, C es igual a 2. Por ejemplo, una dimensión podría ser el número de veces que las palabras de la consulta aparecen en el documento. Algoritmo 1 Algoritmo de plano de corte para resolver OP 1 dentro de la tolerancia. 1: Entrada: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ para todo i = 1, . . . , n 3: repetir 4: para i = 1, . . . , n hacer 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: calcular ˆy = argmaxy∈Y H(y; w) 7: calcular ξi = max{0, maxy∈Wi H(y; w)} 8: si H(ˆy; w) > ξi + entonces 9: Wi ← Wi ∪ {ˆy} 10: w ← optimizar (3) sobre W = S i Wi 11: fin si 12: fin para 13: hasta que ningún Wi haya cambiado durante la iteración parámetro que controla este equilibrio y puede ajustarse para lograr un buen rendimiento en diferentes tareas de entrenamiento. Para cada (xi, yi) en el conjunto de entrenamiento, se añade un conjunto de restricciones de la forma en la ecuación (4) al problema de optimización. Ten en cuenta que wT Ψ(x, y) es exactamente nuestra función discriminante F(x, y; w) (ver ecuación (2)). Durante la predicción, nuestro modelo elige el ranking que maximiza el discriminante (1). Si el valor del discriminante para una clasificación incorrecta y es mayor que para la clasificación verdadera yi (por ejemplo, F(xi, y; w) > F(xi, yi; w)), entonces la variable de holgura correspondiente, ξi, debe ser al menos ∆(yi, y) para que se cumpla esa restricción. Por lo tanto, la suma de los márgenes, P ξi, acota superiormente la pérdida MAP. Esto se establece formalmente en la Proposición 1. Proposición 1. Sea ξ∗ (w) la solución óptima de las variables de holgura para OP 1 para un vector de peso dado w. Entonces 1 n Pn i=1 ξi es una cota superior del riesgo empírico R∆ S (w). (ver [19] para la prueba) La Proposición 1 muestra que OP 1 aprende una función de clasificación que optimiza una cota superior del error de MAP en el conjunto de entrenamiento. Desafortunadamente hay un problema: se requiere una restricción para cada posible resultado incorrecto y, y el número de resultados incorrectos posibles es exponencial en el tamaño de C. Afortunadamente, podemos emplear el Algoritmo 1 para resolver OP 1. El algoritmo 1 es un algoritmo de plano de corte, introduciendo iterativamente restricciones hasta que hayamos resuelto el problema original dentro de una tolerancia deseada [19]. El algoritmo comienza sin restricciones y encuentra de forma iterativa, para cada ejemplo (xi, yi), la salida ˆy asociada con la restricción más violada. Si la restricción correspondiente es violada por más de lo que introducimos ˆy en el conjunto de trabajo Wi de restricciones activas, por ejemplo i, y volvemos a resolver (3) usando el W actualizado. Se puede demostrar que el bucle externo del Algoritmo 1 está garantizado a detenerse dentro de un número polinomial de iteraciones para cualquier precisión deseada. Teorema 1. Sea ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y), ¯∆ = maxi maxy ∆(yi, y), y para cualquier > 0, el Algoritmo 1 termina después de agregar a lo sumo max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff restricciones al conjunto de trabajo W. (ver [19] para la prueba) Sin embargo, dentro del bucle interno de este algoritmo tenemos que calcular argmaxy∈Y H(y; w), donde H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), o equivalentemente, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), ya que wT Ψ(xi, yi) es constante con respecto a y. Aunque está estrechamente relacionado con el procedimiento de clasificación, esto tiene la complicación sustancial de que debemos lidiar con el término adicional ∆(yi, y). Sin la capacidad de encontrar eficientemente la restricción más violada (es decir, resolver argmaxy∈Y H(y, w)), el procedimiento de generación de restricciones no es viable. 3.2 Encontrar la restricción más violada utilizando OP 1 y optimizando la pérdida de ROCArea (∆roc), el problema de encontrar la restricción más violada, o resolver argmaxy∈Y H(y, w) (en adelante argmax H), se aborda en [13]. Resolver argmax H para ∆map es más difícil. Esto se debe principalmente a que ROCArea se descompone de manera ordenada en una suma de puntuaciones calculadas de forma independiente en cada ordenamiento relativo de un par de documentos relevantes/no relevantes. MAP, por otro lado, no se descompone de la misma manera que ROCArea. La principal contribución algorítmica de este artículo es un método eficiente para resolver argmax H para ∆map. Una propiedad útil de ∆map es que es invariante al intercambiar dos documentos con igual relevancia. Por ejemplo, si los documentos da y db son ambos relevantes, entonces intercambiar las posiciones de da y db en cualquier clasificación no afecta a ∆map. Por extensión, ∆map es invariante a cualquier permutación arbitraria de los documentos relevantes entre sí y de los documentos no relevantes entre sí. Sin embargo, esta reorganización afectará la puntuación del discriminante, wT Ψ(x, y). Esto nos lleva a la Observación 1. Observación 1. Considera clasificaciones que estén limitadas por fijar la relevancia en cada posición de la clasificación (por ejemplo, el tercer documento en la clasificación debe ser relevante). Cada clasificación que cumpla con el mismo conjunto de restricciones tendrá el mismo ∆map. Si los documentos relevantes están ordenados por wT φ(x, d) en orden descendente, y los documentos no relevantes también están ordenados de la misma manera por wT φ(x, d), entonces la intercalación de las dos listas ordenadas que cumpla con las restricciones maximizará H para ese conjunto de clasificaciones restringidas. La Observación 1 implica que en la clasificación que maximiza H, los documentos relevantes se ordenarán por wT φ(x, d), y los documentos no relevantes también se ordenarán de la misma manera. Al ordenar primero los documentos relevantes y no relevantes, el problema se simplifica a encontrar la intercalación óptima de dos listas ordenadas. Para el resto de nuestra discusión, asumimos que los documentos relevantes y no relevantes están ordenados por wT φ(x, d) en orden descendente. Para mayor comodidad, también nos referimos a los documentos relevantes como {dx 1 , . . . dx |Cx|} = Cx, y a los documentos no relevantes como {d¯x 1 , . . . d¯x |C¯x|} = C¯x. Definimos δj(i1, i2), con i1 < i2, como el cambio en H desde cuando el documento relevante de mayor rango clasificado después de d¯x j es dx i1 hasta que es dx i2. Para i2 = i1 + 1, tenemos δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5), donde si = wT φ(x, di). El primer término en (5) es el cambio en ∆map cuando el documento relevante i tiene j documentos no relevantes clasificados antes de él, en lugar de j-1. El segundo término es el cambio en la puntuación del discriminante, wT Ψ(x, y), cuando yij cambia de +1 a −1. . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . . Figura 1: Ejemplo para δj(i, i + 1). La Figura 1 proporciona un ejemplo conceptual para δj(i, i + 1). La clasificación inferior difiere de la superior solo cuando d¯x j sube un rango. La diferencia en el valor de H para estas dos clasificaciones es exactamente δj(i, i + 1). Para cualquier i1 < i2, podemos definir δj(i1, i2) como δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) o equivalentemente, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) . Deja que o1, . . . , o|C¯x| codifiquen las posiciones de los documentos no relevantes, donde dx oj es el documento relevante de mayor rango clasificado después del j-ésimo documento no relevante. Debido a la Observación 1, esta codificación identifica de forma única un ranking completo. Podemos recuperar la clasificación como yij = 8 >>>< >>>: 0 si i = j sign(si − sj) si di, dj relevancia igual signo(oj − i − 0.5) si di = dx i , dj = d¯x j signo(j − oi + 0.5) si di = d¯x i , dj = dx j. (7) Ahora podemos reformular H en una nueva función objetivo, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), donde ¯y es la verdadera clasificación (débil). Conceptualmente, H comienza con una clasificación perfecta ¯y y agrega el cambio en H cuando cada documento no relevante sucesivo sube en la clasificación. Luego podemos reformular el problema argmax H como argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) sujeto a o1 ≤ . . . ≤ o|C¯x|. (9) El Algoritmo 2 describe el algoritmo utilizado para resolver la ecuación (8). Conceptualmente, el Algoritmo 2 comienza con un ranking perfecto. Entonces, para cada documento no relevante sucesivo, el algoritmo modifica la solución deslizando ese documento hacia arriba en la clasificación para maximizar localmente H, manteniendo las posiciones de los otros documentos no relevantes constantes. 3.2.1 Prueba de Corrección El Algoritmo 2 es codicioso en el sentido de que encuentra la mejor posición de cada documento no relevante de forma independiente de los otros documentos no relevantes. En otras palabras, el algoritmo maximiza H para cada documento no relevante, d¯x j, Algoritmo 2 Encontrar la Restricción Más Violada (argmax H) para el Algoritmo 1 con ∆map 1: Entrada: w, Cx, C¯x 2: ordenar Cx y C¯x en orden descendente de wT φ(x, d) 3: sx i ← wT φ(x, dx i), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i), i = 1, . . . , |C¯x | 5: para j = 1, . . . , |C¯x | hacer 6: optj ← argmaxk δj(k, |Cx| + 1) 7: fin para 8: codificar ˆy de acuerdo con (7) 9: devolver ˆy sin considerar las posiciones de los otros documentos no relevantes, y así ignora las restricciones de (9). Para que la solución sea factible, el documento no relevante j-ésimo debe ser clasificado después de los primeros j-1 documentos no relevantes, satisfaciendo así opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. Si la solución es factible, entonces claramente resuelve (8). Por lo tanto, basta con demostrar que el Algoritmo 2 cumple con (10). Primero demostramos que δj(·, ·) es monótonamente decreciente en j. Lema 1. Para cualquier 1 ≤ i1 < i2 ≤ |Cx | + 1 y 1 ≤ j < |C¯x |, debe ser el caso que δj+1(i1, i2) ≤ δj(i1, i2). Prueba. Recuerde que tanto δj(i1, i2) como δj+1(i1, i2) son sumas de términos i2 − i1. Mostraremos que cada término en la suma de δj+1(i1, i2) no es mayor que el término correspondiente en δj(i1, i2), o δj+1(k, k + 1) ≤ δj(k, k + 1) para k = i1, . . . , i2 − 1. Cada término en δj(k, k +1) y δj+1(k, k +1) puede ser descompuesto aún más en dos partes (ver (5)). Mostraremos que cada parte de δj+1(k, k + 1) no es mayor que la parte correspondiente en δj(k, k + 1). En otras palabras, demostraremos que tanto j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) como −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) son verdaderos para los valores mencionados de j y k. Es fácil ver que (11) es verdadero observando que para cualquier par de enteros positivos 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1, y eligiendo a = j y b = j + k. La segunda desigualdad (12) se cumple porque el Algoritmo 2 primero ordena d¯x en orden descendente de s¯x, lo que implica s¯x j+1 ≤ s¯x j. Así vemos que cada término en δj+1 no es mayor que el término correspondiente en δj, lo cual completa la prueba. El resultado del Lema 1 conduce directamente a nuestro resultado principal de corrección: Teorema 2. En el Algoritmo 2, los valores calculados de optj satisfacen (10), lo que implica que la solución devuelta por el Algoritmo 2 es factible y, por lo tanto, óptima. Prueba. Demostraremos que optj ≤ optj+1 se cumple para cualquier 1 ≤ j < |C¯x|, implicando así (10). Dado que el Algoritmo 2 calcula optj como optj = argmax k δj(k, |Cx | + 1), (13), entonces por definición de δj (6), para cualquier 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0. Usando el Lema 1, sabemos que δj+1(i, optj) ≤ δj(i, optj) < 0, lo que implica que para cualquier 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0. Supongamos por contradicción que optj+1 < optj. Entonces δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), lo cual contradice (13). Por lo tanto, debe ser el caso que optj ≤ optj+1, lo cual completa la prueba. 3.2.2 Tiempo de ejecución El tiempo de ejecución del Algoritmo 2 se puede dividir en dos partes. La primera parte es la clasificación por wT φ(x, d), lo cual requiere un tiempo de O(n log n), donde n = |Cx | + |C¯x |. La segunda parte calcula cada optj, lo cual requiere un tiempo de O(|Cx| · |C¯x|). Aunque en el peor de los casos esto es O(n2), el número de documentos relevantes, |Cx|, suele ser muy pequeño (por ejemplo, constante con respecto a n), en cuyo caso el tiempo de ejecución para la segunda parte es simplemente O(n). Para la mayoría de los conjuntos de datos del mundo real, el Algoritmo 2 está dominado por la ordenación y tiene una complejidad O(n log n). El Algoritmo 1 está garantizado de detenerse en un número polinómico de iteraciones [19], y cada iteración ejecuta el Algoritmo 2. Prácticamente todos los modelos que funcionaron bien fueron entrenados en un tiempo razonable (generalmente menos de una hora). Una vez que el entrenamiento esté completo, hacer predicciones sobre la consulta x usando la hipótesis resultante h(x|w) solo requiere ordenar por wT φ(x, d). Desarrollamos nuestro software utilizando una interfaz de Python a SVMstruct, ya que el lenguaje Python simplificó en gran medida el proceso de codificación. Para mejorar el rendimiento, es recomendable utilizar la implementación estándar en C de SVMstruct. CONFIGURACIÓN DEL EXPERIMENTO El objetivo principal de nuestros experimentos es evaluar si la optimización directa de MAP conduce a un rendimiento de MAP mejorado en comparación con los métodos convencionales de SVM que optimizan una pérdida sustituta como la precisión o el área bajo la curva ROC. Evaluamos empíricamente nuestro método utilizando dos conjuntos de consultas de la TREC Web Track, uno de TREC 9 y otro de TREC 10 (temas 451-500 y 501-550), ambos de los cuales utilizaron el corpus WT10g. Para cada consulta, TREC proporciona las evaluaciones de relevancia de los documentos. Generamos nuestras características utilizando las puntuaciones de las funciones de recuperación existentes en estas consultas. Si bien nuestro método es agnóstico al significado de las características, elegimos utilizar funciones de recuperación existentes como una forma simple pero efectiva de adquirir características útiles. Por lo tanto, nuestros experimentos de estadísticas de conjuntos de datos básicos esencialmente prueban la capacidad de nuestros métodos para volver a clasificar los documentos altamente clasificados (por ejemplo, volver a combinar las puntuaciones de las funciones de recuperación) para mejorar el MAP. Comparamos nuestro método con las mejores funciones de recuperación entrenadas (en adelante, funciones base), así como con los métodos SVM propuestos anteriormente. Comparar con las mejores funciones base pone a prueba la capacidad de nuestros métodos para aprender una combinación útil. Comparar con métodos SVM anteriores nos permite probar si optimizar directamente para el MAP (en lugar de precisión o área bajo la curva ROC) logra una puntuación de MAP más alta en la práctica. El resto de esta sección describe las funciones base y el método de generación de características en detalle. 4.1 Elección de Funciones de Recuperación Elegimos dos conjuntos de funciones base para nuestros experimentos. Para el primer conjunto, generamos tres índices sobre el corpus WT10g utilizando Indri5. El primer índice fue generado utilizando la configuración predeterminada, el segundo utilizó Porter-stemming, y el último utilizó Porter-stemming y las palabras vacías predeterminadas de Indris. Para TREC 9 y TREC 10, utilizamos la parte de descripción de cada consulta y puntuamos los documentos utilizando cinco de los métodos de recuperación integrados en Indri, que son Similitud Coseno, TFIDF, Okapi, Modelo de Lenguaje con Prior de Dirichlet y Modelo de Lenguaje con Prior de Jelinek-Mercer. Todos los parámetros se mantuvieron en sus valores predeterminados. Calculamos las puntuaciones de estos cinco métodos de recuperación sobre los tres índices, dando un total de 15 funciones base. Para cada consulta, consideramos las puntuaciones de los documentos encontrados en la unión de los mejores 1000 documentos de cada función base. Para nuestro segundo conjunto de funciones base, utilizamos puntuaciones de las presentaciones de la pista web TREC 9 [8] y TREC 10 [9]. Utilizamos solo las presentaciones no manuales y no breves de ambos años. Para TREC 9 y TREC 10, hubo 53 y 18 envíos de este tipo, respectivamente. Una presentación típica contenía puntajes de sus 1000 documentos principales. b ca wT φ(x,d) f(d|x) Figura 2: Ejemplo de Agrupación de Características 4.2 Generación de Características Para generar ejemplos de entrada para nuestro método, se debe proporcionar una instancia concreta de φ. Para cada documento d puntuado por un conjunto de funciones de recuperación F en la consulta x, generamos las características como un vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf, donde f(d|x) denota la puntuación que la función de recuperación f asigna al documento d para la consulta x, y cada Kf es un conjunto de valores reales. Desde un nivel alto, estamos expresando la puntuación de cada función de recuperación utilizando |Kf | + 1 contenedores. Dado que estamos utilizando núcleos lineales, se puede pensar en el problema de aprendizaje como encontrar una buena combinación de piezas constantes de los puntajes de las funciones de recuperación. La Figura 2 muestra un ejemplo de nuestro método de mapeo de características. En este ejemplo tenemos una única característica F = {f}. Aquí, Kf = {a, b, c}, y el vector de pesos es w = wa, wb, wc. Para cualquier documento d y consulta x, tenemos wT φ(x, d) = 8 >>< >>: 0 si f(d|x) < a wa si a ≤ f(d|x) < b wa + wb si b ≤ f(d|x) < c wa + wb + wc si c ≤ f(d|x) . Esto se expresa cualitativamente en la Figura 2, donde wa y wb son positivos, y wc es negativo. Realizamos nuestros experimentos principales utilizando cuatro opciones de F: el conjunto de las funciones de recuperación de Indri mencionadas anteriormente para TREC 9 y TREC 10, y las presentaciones de la pista web para TREC 9 y TREC 10. Para cada F y cada función f ∈ F, elegimos 50 valores para Kf que estuvieran razonablemente espaciados y capturaran la región sensible de f. Utilizando las cuatro opciones de F, generamos cuatro conjuntos de datos para nuestros experimentos principales. La Tabla 5 contiene estadísticas de los conjuntos de datos generados. Hay muchas formas de generar características, y no estamos abogando por nuestro método sobre los demás. Esto fue simplemente un medio eficiente para normalizar las salidas de diferentes funciones y permitir un modelo más expresivo. EXPERIMENTOS Para cada conjunto de datos en la Tabla 5, realizamos 50 pruebas. Para cada prueba, entrenamos con 10 consultas seleccionadas al azar, y seleccionamos otras 5 consultas al azar para un conjunto de validación. Los modelos fueron entrenados utilizando una amplia gama de valores de C. El modelo que tuvo mejor rendimiento en el conjunto de validación fue seleccionado y probado en las 35 consultas restantes. Todas las consultas fueron seleccionadas para estar en los conjuntos de entrenamiento, validación y prueba la misma cantidad de veces. Utilizando esta configuración, realizamos los mismos experimentos mientras usábamos nuestro método (mapa SVM∆), un SVM optimizando para ROCArea (SVM∆ roc) [13], y un SVM de clasificación convencional (SVMacc) [20]. Todos los métodos de SVM utilizaron un kernel lineal. Informamos sobre el rendimiento promedio de todos los modelos en las 50 pruebas. 5.1 Comparación con Funciones Base Al analizar nuestros resultados, la primera pregunta a responder es, ¿puede SVM∆ map aprender un modelo que supere al mejor modelo base TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.290 - 0.287Mejor Func. 0.280 28/22 0.283 29/21 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 36/14 ** Tabla 7: Comparación con Envíos TREC TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288Mejor Func. 0.280 27/23 0.283 31/19 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 35/15 ** Tabla 8: Comparación con Funciones de Envíos TREC (sin el mejor) La Tabla 6 presenta la comparación del mapa SVM∆ con las mejores funciones base de Indri. Cada grupo de columnas contiene el rendimiento del MAP macro-promediado de SVM∆ map o una función base. Las columnas W/L muestran el número de consultas donde SVM∆ map logró un puntaje MAP más alto. Se realizaron pruebas de significancia utilizando la prueba de rango con signo de Wilcoxon de dos colas. Dos estrellas indican un nivel de significancia de 0.95. Todas las tablas que muestran nuestros resultados experimentales están estructuradas de manera idéntica. Aquí encontramos que SVM∆ mapea significativamente mejor que las mejores funciones base. La Tabla 7 muestra la comparación cuando se entrena con las presentaciones de TREC. Si bien logra una puntuación de MAP más alta que las mejores funciones base, la diferencia de rendimiento entre SVM∆ y las funciones base no es significativa. Dado que muchas de estas presentaciones utilizan funciones de puntuación cuidadosamente diseñadas para lograr un alto MAP, es posible que las presentaciones con mejor rendimiento utilicen técnicas que engloben las técnicas de las otras presentaciones. Como resultado, el mapa SVM∆ no sería capaz de aprender una hipótesis que pueda superar significativamente la mejor presentación. Por lo tanto, realizamos los mismos experimentos utilizando un conjunto de datos modificado en el que se eliminaron las características calculadas utilizando la mejor presentación. La tabla 8 muestra los resultados (ten en cuenta que aún estamos comparando con la mejor presentación, aunque no la estamos utilizando para el entrenamiento). Observa que si bien el rendimiento del SVM∆ map se degradó ligeramente, aún era comparable con el de la mejor presentación. 5.2 Comparación con Métodos SVM Anteriores La siguiente pregunta a responder es, ¿produce el SVM∆ map puntajes MAP más altos que los métodos SVM anteriores? Las tablas 9 y 10 presentan los resultados de SVM∆ map, SVM∆ roc y SVMacc cuando se entrenan con las funciones de recuperación de Indri y las presentaciones de TREC, respectivamente. La Tabla 11 contiene los resultados correspondientes cuando se entrena con las presentaciones de TREC sin la mejor presentación. Para empezar, nuestros resultados indican que SVMacc no fue competitivo con SVM∆ map y SVM∆ roc, y a veces tuvo un rendimiento notablemente inferior. Por lo tanto, probamos varios enfoques para mejorar el rendimiento de SVMacc. 5.2.1 Métodos alternativos de SVMacc Un problema que puede causar que SVMacc tenga un rendimiento deficiente es el desequilibrio severo entre documentos relevantes y no relevantes. La gran mayoría de los documentos no son relevantes. SVMacc2 aborda este problema asignando una penalización mayor a los errores de falsos negativos. Para cada conjunto de datos, la proporción de las penalizaciones por falsos negativos a falsos positivos es igual a la proporción entre el número de documentos no relevantes y relevantes en ese conjunto de datos. Las tablas 9, 10 y 11 indican que SVMacc2 sigue teniendo un rendimiento significativamente peor que SVM∆ map. Otro posible problema es que SVMacc intenta encontrar solo un umbral discriminatorio b que sea invariable a la consulta. Puede ser que diferentes consultas requieran diferentes valores de b. Tener el método de aprendizaje intentando encontrar un buen valor de b (cuando no existe) puede ser perjudicial. Tomamos dos enfoques para abordar este problema. El primer método, SVMacc3, convierte las puntuaciones de la función de recuperación en percentiles. Por ejemplo, para el documento d, la consulta q y la función de recuperación f, si la puntuación f(d|q) se encuentra en el 90% superior de las puntuaciones f(·|q) para la consulta q, entonces la puntuación convertida es f(d|q) = 0.9. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Las tablas 9, 10 y 11 muestran que el rendimiento de SVMacc3 tampoco fue competitivo con SVM∆ map. El segundo método, SVMacc4, normaliza las puntuaciones dadas por f para cada consulta. Por ejemplo, suponga para la consulta q que f produce puntuaciones en el rango de 0.2 a 0.7. Entonces, para el documento d, si f(d|q) = 0.6, la puntuación convertida sería f(d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Nuevamente, las Tablas 9, 10 y 11 muestran que SVMacc4 no fue competitivo con SVM∆ map 5.2.2 MAP vs ROCArea. SVM∆ roc tuvo un rendimiento mucho mejor que SVMacc en nuestros experimentos. Cuando se entrenó con las funciones de recuperación de Indri (ver Tabla 9), el rendimiento de SVM∆ roc fue ligeramente, aunque no significativamente, peor que el rendimiento de SVM∆ map. Sin embargo, la Tabla 10 muestra que el mapa SVM∆ superó significativamente al roc SVM∆ cuando se entrenó con las presentaciones de TREC. La tabla 11 muestra el rendimiento de los modelos cuando se entrenan con las presentaciones de TREC y se elimina la mejor presentación. El rendimiento de la mayoría de los modelos se degradó ligeramente, con SVM∆ map aún teniendo el mejor rendimiento. TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288 SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Tabla 11: Entrenado en TREC Subm. (sin Mejor) 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado un método SVM que optimiza directamente el MAP. Proporciona un enfoque basado en principios y evita heurísticas difíciles de controlar. Formulamos el problema de optimización y presentamos un algoritmo que encuentra la solución de manera demostrable en tiempo polinómico. Hemos demostrado empíricamente que nuestro método es generalmente superior o competitivo con los métodos convencionales de SVM. Nuestro nuevo método hace que sea conceptualmente tan fácil optimizar SVMs para MAP como anteriormente solo era posible para Precisión y Área bajo la curva ROC. El costo computacional para el entrenamiento es muy razonable en la práctica. Dado que otros métodos suelen requerir ajustar múltiples heurísticas, también esperamos entrenar menos modelos antes de encontrar uno que logre un buen rendimiento. El marco de aprendizaje utilizado por nuestro método es bastante general. Una extensión natural de este marco sería desarrollar métodos para optimizar otras medidas importantes de IR, como la Ganancia Acumulada Normalizada Descontada [2, 3, 4, 12] y la Reciprocidad Media de Rango. 7. AGRADECIMIENTOS Este trabajo fue financiado bajo el Premio NSF IIS-0412894, el Premio NSF CAREER 0237381 y un obsequio de Yahoo! Investigación. El tercer autor también fue parcialmente apoyado por una Beca de Investigación de Microsoft. 8. REFERENCIAS [1] B. T. Bartell, G. W. Cottrell y R. K. Belew. Combinación automática de múltiples <br>sistemas de recuperación clasificados</br>. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2005. [3] C. J. C. Burges, R. Ragno y Q. Lo. Aprendizaje para clasificar con funciones de costo no suaves. En Actas de la Conferencia Internacional sobre Avances en Sistemas de Información Neural (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang y H.-W. Hon. Adaptando el SVM de clasificación para la recuperación de documentos. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [5] B. Carterette y D. Petkova. Aprendiendo un ranking a partir de preferencias por pares. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew y A. Ksikes. Selección de conjunto de bibliotecas de modelos. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [7] J. Davis y M. Goadrich. La relación entre las curvas de precisión-recall y ROC. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2006. [8] D. Hawking. Resumen de la pista web TREC-9. En Actas de TREC-2000, 2000. [9] D. Hawking y N. Craswell. Resumen de la pista web TREC-2001. En Actas de TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel y K. Obermayer. Límites de rango de margen amplio para regresión ordinal. Avances en clasificadores de márgenes amplios, 2000. [11] A. Herschtal y B. Raskutti. Optimizando el área bajo la curva ROC utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [12] K. Jarvelin y J. Kekalainen. Métodos de evaluación para recuperar documentos altamente relevantes. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2000. [13] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), páginas 377-384, Nueva York, NY, EE. UU., 2005. ACM Press. [14] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), páginas 111-119, 2001. [15] Y. Lin, Y. Lee y G. Wahba. Máquinas de vectores de soporte para clasificación en situaciones no estándar. Aprendizaje automático, 46:191-202, 2002. [16] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [17] K. Morik, P. Brockhausen y T. Joachims. Combinando el aprendizaje estadístico con un enfoque basado en el conocimiento. En Actas de la Conferencia Internacional sobre Aprendizaje Automático, 1999. [18] S. Robertson. El principio de clasificación de probabilidad en la revista IR de documentación. Revista de Documentación, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims y Y. Altun. Métodos de margen amplio para variables de salida estructuradas e interdependientes. Revista de Investigación en Aprendizaje Automático (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik. Teoría del Aprendizaje Estadístico. Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz. \n\nWiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer y R. Wolniewicz. Optimizando el rendimiento del clasificador mediante la aproximación a la estadística de Wilcoxon-Mann-Witney. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2003. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "learning technique": {
            "translated_key": "técnicas de aprendizaje",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT Machine learning is commonly used to improve ranked retrieval systems.",
                "Due to computational difficulties, few <br>learning technique</br>s have been developed to directly optimize for mean average precision (MAP), despite its widespread use in evaluating such systems.",
                "Existing approaches optimizing MAP either do not find a globally optimal solution, or are computationally expensive.",
                "In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of MAP.",
                "We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora (WT10g), comparing against SVMs optimized for accuracy and ROCArea.",
                "In most cases we show our method to produce statistically significant improvements in MAP scores.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval Models General Terms Algorithm, Theory, Experimentation 1.",
                "INTRODUCTION State of the art information retrieval systems commonly use machine <br>learning technique</br>s to learn ranking functions.",
                "However, most current approaches do not optimize for the evaluation measure most often used, namely Mean Average Precision (MAP).",
                "Instead, current algorithms tend to take one of two general approaches.",
                "The first approach is to learn a model that estimates the probability of a document being relevant given a query (e.g., [18, 14]).",
                "If solved effectively, the ranking with best MAP performance can easily be derived from the probabilities of relevance.",
                "However, achieving high MAP only requires finding a good ordering of the documents.",
                "As a result, finding good probabilities requires solving a more difficult problem than necessary, likely requiring more training data to achieve the same MAP performance.",
                "The second common approach is to learn a function that maximizes a surrogate measure.",
                "Performance measures optimized include accuracy [17, 15], ROCArea [1, 5, 10, 11, 13, 21] or modifications of ROCArea [4], and NDCG [2, 3].",
                "Learning a model to optimize for such measures might result in suboptimal MAP performance.",
                "In fact, although some previous systems have obtained good MAP performance, it is known that neither achieving optimal accuracy nor ROCArea can guarantee optimal MAP performance[7].",
                "In this paper, we present a general approach for learning ranking functions that maximize MAP performance.",
                "Specifically, we present an SVM algorithm that globally optimizes a hinge-loss relaxation of MAP.",
                "This approach simplifies the process of obtaining ranking functions with high MAP performance by avoiding additional intermediate steps and heuristics.",
                "The new algorithm also makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for accuracy and ROCArea.",
                "In contrast to recent work directly optimizing for MAP performance by Metzler & Croft [16] and Caruana et al. [6], our technique is computationally efficient while finding a globally optimal solution.",
                "Like [6, 16], our method learns a linear model, but is much more efficient in practice and, unlike [16], can handle many thousands of features.",
                "We now describe the algorithm in detail and provide proof of correctness.",
                "Following this, we provide an analysis of running time.",
                "We finish with empirical results from experiments on the TREC 9 and TREC 10 Web Track corpus.",
                "We have also developed a software package implementing our algorithm that is available for public use1 . 2.",
                "THE LEARNING PROBLEM Following the standard machine learning setup, our goal is to learn a function h : X → Y between an input space X (all possible queries) and output space Y (rankings over a corpus).",
                "In order to quantify the quality of a prediction, ˆy = h(x), we will consider a loss function ∆ : Y × Y → . ∆(y, ˆy) quantifies the penalty for making prediction ˆy if the correct output is y.",
                "The loss function allows us to incorporate specific performance measures, which we will exploit 1 http://svmrank.yisongyue.com for optimizing MAP.",
                "We restrict ourselves to the supervised learning scenario, where input/output pairs (x, y) are available for training and are assumed to come from some fixed distribution P(x, y).",
                "The goal is to find a function h such that the risk (i.e., expected loss), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), is minimized.",
                "Of course, P(x, y) is unknown.",
                "But given a finite set of training pairs, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, the performance of h on S can be measured by the empirical risk, R∆ S (h) = 1 n nX i=1 ∆(yi, h(xi)).",
                "In the case of learning a ranked retrieval function, X denotes a space of queries, and Y the space of (possibly weak) rankings over some corpus of documents C = {d1, . . . ,d|C|}.",
                "We can define average precision loss as ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), where rank(y) is a vector of the rank values of each document in C. For example, for a corpus of two documents, {d1, d2}, with d1 having higher rank than d2, rank(y ) = (1, 0).",
                "We assume true rankings have two rank values, where relevant documents have rank value 1 and non-relevant documents rank value 0.",
                "We further assume that all predicted rankings are complete rankings (no ties).",
                "Let p = rank(y) and ˆp = rank(ˆy).",
                "The average precision score is defined as MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, where rel = |{i : pi = 1}| is the number of relevant documents, and Prec@j is the percentage of relevant documents in the top j documents in predicted ranking ˆy.",
                "MAP is the mean of the average precision scores of a group of queries. 2.1 MAP vs ROCArea Most learning algorithms optimize for accuracy or ROCArea.",
                "While optimizing for these measures might achieve good MAP performance, we use two simple examples to show it can also be suboptimal in terms of MAP.",
                "ROCArea assigns equal penalty to each misordering of a relevant/non-relevant pair.",
                "In contrast, MAP assigns greater penalties to misorderings higher up in the predicted ranking.",
                "Using our notation, ROCArea can be defined as ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], where p is the true (weak) ranking, ˆp is the predicted ranking, and 1[b] is the indicator function conditioned on b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Table 1: Toy Example and Models Suppose we have a hypothesis space with only two hypothesis functions, h1 and h2, as shown in Table 1.",
                "These two hypotheses predict a ranking for query x over a corpus of eight documents.",
                "Hypothesis MAP ROCArea h1(x) 0.59 0.47 h2(x) 0.51 0.53 Table 2: Performance of Toy Models Table 2 shows the MAP and ROCArea scores of h1 and h2.",
                "Here, a learning method which optimizes for ROCArea would choose h2 since that results in a higher ROCArea score, but this yields a suboptimal MAP score. 2.2 MAP vs Accuracy Using a very similar example, we now demonstrate how optimizing for accuracy might result in suboptimal MAP.",
                "Models which optimize for accuracy are not directly concerned with the ranking.",
                "Instead, they learn a threshold such that documents scoring higher than the threshold can be classified as relevant and documents scoring lower as nonrelevant.",
                "Doc ID 1 2 3 4 5 6 7 8 9 10 11 p 1 0 0 0 0 1 1 1 1 0 0 rank(h1(x)) 11 10 9 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 9 10 11 Table 3: Toy Example and Models We consider again a hypothesis space with two hypotheses.",
                "Table 3 shows the predictions of the two hypotheses on a single query x. Hypothesis MAP Best Acc. h1(q) 0.70 0.64 h2(q) 0.64 0.73 Table 4: Performance of Toy Models Table 4 shows the MAP and best accuracy scores of h1(q) and h2(q).",
                "The best accuracy refers to the highest achievable accuracy on that ranking when considering all possible thresholds.",
                "For instance, with h1(q), a threshold between documents 1 and 2 gives 4 errors (documents 6-9 incorrectly classified as non-relevant), yielding an accuracy of 0.64.",
                "Similarly, with h2(q), a threshold between documents 5 and 6 gives 3 errors (documents 10-11 incorrectly classified as relevant, and document 1 as non-relevant), yielding an accuracy of 0.73.",
                "A learning method which optimizes for accuracy would choose h2 since that results in a higher accuracy score, but this yields a suboptimal MAP score. 3.",
                "OPTIMIZING AVERAGE PRECISION We build upon the approach used by [13] for optimizing ROCArea.",
                "Unlike ROCArea, however, MAP does not decompose linearly in the examples and requires a substantially extended algorithm, which we describe in this section.",
                "Recall that the true ranking is a weak ranking with two rank values (relevant and non-relevant).",
                "Let Cx and C¯x denote the set of relevant and non-relevant documents of C for query x, respectively.",
                "We focus on functions which are parametrized by a weight vector w, and thus wish to find w to minimize the empirical risk, R∆ S (w) ≡ R∆ S (h(·; w)).",
                "Our approach is to learn a discriminant function F : X × Y → over input-output pairs.",
                "Given query x, we can derive a prediction by finding the ranking y that maximizes the discriminant function: h(x; w) = argmax y∈Y F(x, y; w). (1) We assume F to be linear in some combined feature representation of inputs and outputs Ψ(x, y) ∈ RN , i.e., F(x, y; w) = wT Ψ(x, y). (2) The combined feature function we use is Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))] , where φ : X × C → N is a feature mapping function from a query/document pair to a point in N dimensional space2 .",
                "We represent rankings as a matrix of pairwise orderings, Y ⊂ {−1, 0, +1}|C|×|C| .",
                "For any y ∈ Y, yij = +1 if di is ranked ahead of dj, and yij = −1 if dj is ranked ahead of di, and yij = 0 if di and dj have equal rank.",
                "We consider only matrices which correspond to valid rankings (i.e, obeying antisymmetry and transitivity).",
                "Intuitively, Ψ is a summation over the vector differences of all relevant/non-relevant document pairings.",
                "Since we assume predicted rankings to be complete rankings, yij is either +1 or −1 (never 0).",
                "Given a learned weight vector w, predicting a ranking (i.e. solving equation (1)) given query x reduces to picking each yij to maximize wT Ψ(x, y).",
                "As is also discussed in [13], this is attained by sorting the documents by wT φ(x, d) in descending order.",
                "We will discuss later the choices of φ we used for our experiments. 3.1 Structural SVMs The above formulation is very similar to learning a straightforward linear model while training on the pairwise difference of relevant/non-relevant document pairings.",
                "Many SVM-based approaches optimize over these pairwise differences (e.g., [5, 10, 13, 4]), although these methods do not optimize for MAP during training.",
                "Previously, it was not clear how to incorporate non-linear multivariate loss functions such as MAP loss directly into global optimization problems such as SVM training.",
                "We now present a method based on structural SVMs [19] to address this problem.",
                "We use the structural SVM formulation, presented in Optimization Problem 1, to learn a w ∈ RN .",
                "Optimization Problem 1. (Structural SVM) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) The objective function to be minimized (3) is a tradeoff between model complexity, w 2 , and a hinge loss relaxation of MAP loss, P ξi.",
                "As is usual in SVM training, C is a 2 For example, one dimension might be the number of times the query words appear in the document.",
                "Algorithm 1 Cutting plane algorithm for solving OP 1 within tolerance . 1: Input: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ for all i = 1, . . . , n 3: repeat 4: for i = 1, . . . , n do 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: compute ˆy = argmaxy∈Y H(y; w) 7: compute ξi = max{0, maxy∈Wi H(y; w)} 8: if H(ˆy; w) > ξi + then 9: Wi ← Wi ∪ {ˆy} 10: w ← optimize (3) over W = S i Wi 11: end if 12: end for 13: until no Wi has changed during iteration parameter that controls this tradeoff and can be tuned to achieve good performance in different training tasks.",
                "For each (xi, yi) in the training set, a set of constraints of the form in equation (4) is added to the optimization problem.",
                "Note that wT Ψ(x, y) is exactly our discriminant function F(x, y; w) (see equation (2)).",
                "During prediction, our model chooses the ranking which maximizes the discriminant (1).",
                "If the discriminant value for an incorrect ranking y is greater than for the true ranking yi (e.g., F(xi, y; w) > F(xi, yi; w)), then corresponding slack variable, ξi, must be at least ∆(yi, y) for that constraint to be satisfied.",
                "Therefore, the sum of slacks, P ξi, upper bounds the MAP loss.",
                "This is stated formally in Proposition 1.",
                "Proposition 1.",
                "Let ξ∗ (w) be the optimal solution of the slack variables for OP 1 for a given weight vector w. Then 1 n Pn i=1 ξi is an upper bound on the empirical risk R∆ S (w). (see [19] for proof) Proposition 1 shows that OP 1 learns a ranking function that optimizes an upper bound on MAP error on the training set.",
                "Unfortunately there is a problem: a constraint is required for every possible wrong output y, and the number of possible wrong outputs is exponential in the size of C. Fortunately, we may employ Algorithm 1 to solve OP 1.",
                "Algorithm 1 is a cutting plane algorithm, iteratively introducing constraints until we have solved the original problem within a desired tolerance [19].",
                "The algorithm starts with no constraints, and iteratively finds for each example (xi, yi) the output ˆy associated with the most violated constraint.",
                "If the corresponding constraint is violated by more than we introduce ˆy into the working set Wi of active constraints for example i, and re-solve (3) using the updated W. It can be shown that Algorithm 1s outer loop is guaranteed to halt within a polynomial number of iterations for any desired precision .",
                "Theorem 1.",
                "Let ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y) , ¯∆ = maxi maxy ∆(yi, y), and for any > 0, Algorithm 1 terminates after adding at most max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff constraints to the working set W. (see [19] for proof) However, within the inner loop of this algorithm we have to compute argmaxy∈Y H(y; w), where H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), or equivalently, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), since wT Ψ(xi, yi) is constant with respect to y.",
                "Though closely related to the classification procedure, this has the substantial complication that we must contend with the additional ∆(yi, y) term.",
                "Without the ability to efficiently find the most violated constraint (i.e., solve argmaxy∈Y H(y, w)), the constraint generation procedure is not tractable. 3.2 Finding the Most Violated Constraint Using OP 1 and optimizing to ROCArea loss (∆roc), the problem of finding the most violated constraint, or solving argmaxy∈Y H(y, w) (henceforth argmax H), is addressed in [13].",
                "Solving argmax H for ∆map is more difficult.",
                "This is primarily because ROCArea decomposes nicely into a sum of scores computed independently on each relative ordering of a relevant/non-relevant document pair.",
                "MAP, on the other hand, does not decompose in the same way as ROCArea.",
                "The main algorithmic contribution of this paper is an efficient method for solving argmax H for ∆map.",
                "One useful property of ∆map is that it is invariant to swapping two documents with equal relevance.",
                "For example, if documents da and db are both relevant, then swapping the positions of da and db in any ranking does not affect ∆map.",
                "By extension, ∆map is invariant to any arbitrary permutation of the relevant documents amongst themselves and of the non-relevant documents amongst themselves.",
                "However, this reshuﬄing will affect the discriminant score, wT Ψ(x, y).",
                "This leads us to Observation 1.",
                "Observation 1.",
                "Consider rankings which are constrained by fixing the relevance at each position in the ranking (e.g., the 3rd document in the ranking must be relevant).",
                "Every ranking which satisfies the same set of constraints will have the same ∆map.",
                "If the relevant documents are sorted by wT φ(x, d) in descending order, and the non-relevant documents are likewise sorted by wT φ(x, d), then the interleaving of the two sorted lists which satisfies the constraints will maximize H for that constrained set of rankings.",
                "Observation 1 implies that in the ranking which maximizes H, the relevant documents will be sorted by wT φ(x, d), and the non-relevant documents will also be sorted likewise.",
                "By first sorting the relevant and non-relevant documents, the problem is simplified to finding the optimal interleaving of two sorted lists.",
                "For the rest of our discussion, we assume that the relevant documents and non-relevant documents are both sorted by descending wT φ(x, d).",
                "For convenience, we also refer to relevant documents as {dx 1 , . . . dx |Cx|} = Cx , and non-relevant documents as {d¯x 1 , . . . d¯x |C¯x|} = C¯x .",
                "We define δj(i1, i2), with i1 < i2, as the change in H from when the highest ranked relevant document ranked after d¯x j is dx i1 to when it is dx i2 .",
                "For i2 = i1 + 1, we have δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5) where si = wT φ(x, di).",
                "The first term in (5) is the change in ∆map when the ith relevant document has j non-relevant documents ranked before it, as opposed to j −1.",
                "The second term is the change in the discriminant score, wT Ψ(x, y), when yij changes from +1 to −1. . . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . .",
                "Figure 1: Example for δj(i, i + 1) Figure 1 gives a conceptual example for δj(i, i + 1).",
                "The bottom ranking differs from the top only where d¯x j slides up one rank.",
                "The difference in the value of H for these two rankings is exactly δj(i, i + 1).",
                "For any i1 < i2, we can then define δj(i1, i2) as δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) or equivalently, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) .",
                "Let o1, . . . , o|C¯x| encode the positions of the non-relevant documents, where dx oj is the highest ranked relevant document ranked after the jth non-relevant document.",
                "Due to Observation 1, this encoding uniquely identifies a complete ranking.",
                "We can recover the ranking as yij = 8 >>>< >>>: 0 if i = j sign(si − sj) if di, dj equal relevance sign(oj − i − 0.5) if di = dx i , dj = d¯x j sign(j − oi + 0.5) if di = d¯x i , dj = dx j . (7) We can now reformulate H into a new objective function, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), where ¯y is the true (weak) ranking.",
                "Conceptually H starts with a perfect ranking ¯y, and adds the change in H when each successive non-relevant document slides up the ranking.",
                "We can then reformulate the argmax H problem as argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) s.t. o1 ≤ . . . ≤ o|C¯x|. (9) Algorithm 2 describes the algorithm used to solve equation (8).",
                "Conceptually, Algorithm 2 starts with a perfect ranking.",
                "Then for each successive non-relevant document, the algorithm modifies the solution by sliding that document up the ranking to locally maximize H while keeping the positions of the other non-relevant documents constant. 3.2.1 Proof of Correctness Algorithm 2 is greedy in the sense that it finds the best position of each non-relevant document independently from the other non-relevant documents.",
                "In other words, the algorithm maximizes H for each non-relevant document, d¯x j , Algorithm 2 Finding the Most Violated Constraint (argmax H) for Algorithm 1 with ∆map 1: Input: w, Cx , C¯x 2: sort Cx and C¯x in descending order of wT φ(x, d) 3: sx i ← wT φ(x, dx i ), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i ), i = 1, . . . , |C¯x | 5: for j = 1, . . . , |C¯x | do 6: optj ← argmaxk δj(k, |Cx | + 1) 7: end for 8: encode ˆy according to (7) 9: return ˆy without considering the positions of the other non-relevant documents, and thus ignores the constraints of (9).",
                "In order for the solution to be feasible, the jth non-relevant document must be ranked after the first j − 1 non-relevant documents, thus satisfying opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. (10) If the solution is feasible, the it clearly solves (8).",
                "Therefore, it suffices to prove that Algorithm 2 satisfies (10).",
                "We first prove that δj(·, ·) is monotonically decreasing in j. Lemma 1.",
                "For any 1 ≤ i1 < i2 ≤ |Cx | + 1 and 1 ≤ j < |C¯x |, it must be the case that δj+1(i1, i2) ≤ δj(i1, i2).",
                "Proof.",
                "Recall from (6) that both δj(i1, i2) and δj+1(i1, i2) are summations of i2 − i1 terms.",
                "We will show that each term in the summation of δj+1(i1, i2) is no greater than the corresponding term in δj(i1, i2), or δj+1(k, k + 1) ≤ δj(k, k + 1) for k = i1, . . . , i2 − 1.",
                "Each term in δj(k, k +1) and δj+1(k, k +1) can be further decomposed into two parts (see (5)).",
                "We will show that each part of δj+1(k, k + 1) is no greater than the corresponding part in δj(k, k + 1).",
                "In other words, we will show that both j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) and −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) are true for the aforementioned values of j and k. It is easy to see that (11) is true by observing that for any two positive integers 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1 , and choosing a = j and b = j + k. The second inequality (12) holds because Algorithm 2 first sorts d¯x in descending order of s¯x , implying s¯x j+1 ≤ s¯x j .",
                "Thus we see that each term in δj+1 is no greater than the corresponding term in δj, which completes the proof.",
                "The result of Lemma 1 leads directly to our main correctness result: Theorem 2.",
                "In Algorithm 2, the computed values of optj satisfy (10), implying that the solution returned by Algorithm 2 is feasible and thus optimal.",
                "Proof.",
                "We will prove that optj ≤ optj+1 holds for any 1 ≤ j < |C¯x |, thus implying (10).",
                "Since Algorithm 2 computes optj as optj = argmax k δj(k, |Cx | + 1), (13) then by definition of δj (6), for any 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0.",
                "Using Lemma 1, we know that δj+1(i, optj) ≤ δj(i, optj) < 0, which implies that for any 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0.",
                "Suppose for contradiction that optj+1 < optj.",
                "Then δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), which contradicts (13).",
                "Therefore, it must be the case that optj ≤ optj+1, which completes the proof. 3.2.2 Running Time The running time of Algorithm 2 can be split into two parts.",
                "The first part is the sort by wT φ(x, d), which requires O(n log n) time, where n = |Cx | + |C¯x |.",
                "The second part computes each optj, which requires O(|Cx | · |C¯x |) time.",
                "Though in the worst case this is O(n2 ), the number of relevant documents, |Cx |, is often very small (e.g., constant with respect to n), in which case the running time for the second part is simply O(n).",
                "For most real-world datasets, Algorithm 2 is dominated by the sort and has complexity O(n log n).",
                "Algorithm 1 is guaranteed to halt in a polynomial number of iterations [19], and each iteration runs Algorithm 2.",
                "Virtually all well-performing models were trained in a reasonable amount of time (usually less than one hour).",
                "Once training is complete, making predictions on query x using the resulting hypothesis h(x|w) requires only sorting by wT φ(x, d).",
                "We developed our software using a Python interface3 to SVMstruct , since the Python language greatly simplified the coding process.",
                "To improve performance, it is advisable to use the standard C implementation4 of SVMstruct . 4.",
                "EXPERIMENT SETUP The main goal of our experiments is to evaluate whether directly optimizing MAP leads to improved MAP performance compared to conventional SVM methods that optimize a substitute loss such as accuracy or ROCArea.",
                "We empirically evaluate our method using two sets of TREC Web Track queries, one each from TREC 9 and TREC 10 (topics 451-500 and 501-550), both of which used the WT10g corpus.",
                "For each query, TREC provides the relevance judgments of the documents.",
                "We generated our features using the scores of existing retrieval functions on these queries.",
                "While our method is agnostic to the meaning of the features, we chose to use existing retrieval functions as a simple yet effective way of acquiring useful features.",
                "As such, our 3 http://www.cs.cornell.edu/~tomf/svmpython/ 4 http://svmlight.joachims.org/svm_struct.html Dataset Base Funcs Features TREC 9 Indri 15 750 TREC 10 Indri 15 750 TREC 9 Submissions 53 2650 TREC 10 Submissions 18 900 Table 5: Dataset Statistics experiments essentially test our methods ability to re-rank the highly ranked documents (e.g., re-combine the scores of the retrieval functions) to improve MAP.",
                "We compare our method against the best retrieval functions trained on (henceforth base functions), as well as against previously proposed SVM methods.",
                "Comparing with the best base functions tests our methods ability to learn a useful combination.",
                "Comparing with previous SVM methods allows us to test whether optimizing directly for MAP (as opposed to accuracy or ROCArea) achieves a higher MAP score in practice.",
                "The rest of this section describes the base functions and the feature generation method in detail. 4.1 Choosing Retrieval Functions We chose two sets of base functions for our experiments.",
                "For the first set, we generated three indices over the WT10g corpus using Indri5 .",
                "The first index was generated using default settings, the second used Porter-stemming, and the last used Porter-stemming and Indris default stopwords.",
                "For both TREC 9 and TREC 10, we used the description portion of each query and scored the documents using five of Indris built-in retrieval methods, which are Cosine Similarity, TFIDF, Okapi, Language Model with Dirichlet Prior, and Language Model with Jelinek-Mercer Prior.",
                "All parameters were kept as their defaults.",
                "We computed the scores of these five retrieval methods over the three indices, giving 15 base functions in total.",
                "For each query, we considered the scores of documents found in the union of the top 1000 documents of each base function.",
                "For our second set of base functions, we used scores from the TREC 9 [8] and TREC 10 [9] Web Track submissions.",
                "We used only the non-manual, non-short submissions from both years.",
                "For TREC 9 and TREC 10, there were 53 and 18 such submissions, respectively.",
                "A typical submission contained scores of its top 1000 documents. b ca wT φ(x,d) f(d|x) Figure 2: Example Feature Binning 4.2 Generating Features In order to generate input examples for our method, a concrete instantiation of φ must be provided.",
                "For each doc5 http://www.lemurproject.org TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236Best Func. 0.204 39/11 ** 0.181 37/13 ** 2nd Best 0.199 38/12 ** 0.174 43/7 ** 3rd Best 0.188 34/16 ** 0.174 38/12 ** Table 6: Comparison with Indri Functions ument d scored by a set of retrieval functions F on query x, we generate the features as a vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf , where f(d|x) denotes the score that retrieval function f assigns to document d for query x, and each Kf is a set of real values.",
                "From a high level, we are expressing the score of each retrieval function using |Kf | + 1 bins.",
                "Since we are using linear kernels, one can think of the learning problem as finding a good piecewise-constant combination of the scores of the retrieval functions.",
                "Figure 2 shows an example of our feature mapping method.",
                "In this example we have a single feature F = {f}.",
                "Here, Kf = {a, b, c}, and the weight vector is w = wa, wb, wc .",
                "For any document d and query x, we have wT φ(x, d) = 8 >>< >>: 0 if f(d|x) < a wa if a ≤ f(d|x) < b wa + wb if b ≤ f(d|x) < c wa + wb + wc if c ≤ f(d|x) .",
                "This is expressed qualitatively in Figure 2, where wa and wb are positive, and wc is negative.",
                "We ran our main experiments using four choices of F: the set of aforementioned Indri retrieval functions for TREC 9 and TREC 10, and the Web Track submissions for TREC 9 and TREC 10.",
                "For each F and each function f ∈ F, we chose 50 values for Kf which are reasonably spaced and capture the sensitive region of f. Using the four choices of F, we generated four datasets for our main experiments.",
                "Table 5 contains statistics of the generated datasets.",
                "There are many ways to generate features, and we are not advocating our method over others.",
                "This was simply an efficient means to normalize the outputs of different functions and allow for a more expressive model. 5.",
                "EXPERIMENTS For each dataset in Table 5, we performed 50 trials.",
                "For each trial, we train on 10 randomly selected queries, and select another 5 queries at random for a validation set.",
                "Models were trained using a wide range of C values.",
                "The model which performed best on the validation set was selected and tested on the remaining 35 queries.",
                "All queries were selected to be in the training, validation and test sets the same number of times.",
                "Using this setup, we performed the same experiments while using our method (SVM∆ map), an SVM optimizing for ROCArea (SVM∆ roc) [13], and a conventional classification SVM (SVMacc) [20].",
                "All SVM methods used a linear kernel.",
                "We reported the average performance of all models over the 50 trials. 5.1 Comparison with Base Functions In analyzing our results, the first question to answer is, can SVM∆ map learn a model which outperforms the best base TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287Best Func. 0.280 28/22 0.283 29/21 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 36/14 ** Table 7: Comparison with TREC Submissions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288Best Func. 0.280 27/23 0.283 31/19 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 35/15 ** Table 8: Comparison with TREC Subm. (w/o best) functions?",
                "Table 6 presents the comparison of SVM∆ map with the best Indri base functions.",
                "Each column group contains the macro-averaged MAP performance of SVM∆ map or a base function.",
                "The W/L columns show the number of queries where SVM∆ map achieved a higher MAP score.",
                "Significance tests were performed using the two-tailed Wilcoxon signed rank test.",
                "Two stars indicate a significance level of 0.95.",
                "All tables displaying our experimental results are structured identically.",
                "Here, we find that SVM∆ map significantly outperforms the best base functions.",
                "Table 7 shows the comparison when trained on TREC submissions.",
                "While achieving a higher MAP score than the best base functions, the performance difference between SVM∆ map the base functions is not significant.",
                "Given that many of these submissions use scoring functions which are carefully crafted to achieve high MAP, it is possible that the best performing submissions use techniques which subsume the techniques of the other submissions.",
                "As a result, SVM∆ map would not be able to learn a hypothesis which can significantly out-perform the best submission.",
                "Hence, we ran the same experiments using a modified dataset where the features computed using the best submission were removed.",
                "Table 8 shows the results (note that we are still comparing against the best submission though we are not using it for training).",
                "Notice that while the performance of SVM∆ map degraded slightly, the performance was still comparable with that of the best submission. 5.2 Comparison w/ Previous SVM Methods The next question to answer is, does SVM∆ map produce higher MAP scores than previous SVM methods?",
                "Tables 9 and 10 present the results of SVM∆ map, SVM∆ roc, and SVMacc when trained on the Indri retrieval functions and TREC submissions, respectively.",
                "Table 11 contains the corresponding results when trained on the TREC submissions without the best submission.",
                "To start with, our results indicate that SVMacc was not competitive with SVM∆ map and SVM∆ roc, and at times underperformed dramatically.",
                "As such, we tried several approaches to improve the performance of SVMacc. 5.2.1 Alternate SVMacc Methods One issue which may cause SVMacc to underperform is the severe imbalance between relevant and non-relevant docTREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236SVM∆ roc 0.237 29/21 0.234 24/26 SVMacc 0.147 47/3 ** 0.155 47/3 ** SVMacc2 0.219 39/11 ** 0.207 43/7 ** SVMacc3 0.113 49/1 ** 0.153 45/5 ** SVMacc4 0.155 48/2 ** 0.155 48/2 ** Table 9: Trained on Indri Functions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287SVM∆ roc 0.282 29/21 0.278 35/15 ** SVMacc 0.213 49/1 ** 0.222 49/1 ** SVMacc2 0.270 34/16 ** 0.261 42/8 ** SVMacc3 0.133 50/0 ** 0.182 46/4 ** SVMacc4 0.233 47/3 ** 0.238 46/4 ** Table 10: Trained on TREC Submissions uments.",
                "The vast majority of the documents are not relevant.",
                "SVMacc2 addresses this problem by assigning more penalty to false negative errors.",
                "For each dataset, the ratio of the false negative to false positive penalties is equal to the ratio of the number non-relevant and relevant documents in that dataset.",
                "Tables 9, 10 and 11 indicate that SVMacc2 still performs significantly worse than SVM∆ map.",
                "Another possible issue is that SVMacc attempts to find just one discriminating threshold b that is query-invariant.",
                "It may be that different queries require different values of b.",
                "Having the learning method trying to find a good b value (when one does not exist) may be detrimental.",
                "We took two approaches to address this issue.",
                "The first method, SVMacc3, converts the retrieval function scores into percentiles.",
                "For example, for document d, query q and retrieval function f, if the score f(d|q) is in the top 90% of the scores f(·|q) for query q, then the converted score is f (d|q) = 0.9.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Tables 9, 10 and 11 show that the performance of SVMacc3 was also not competitive with SVM∆ map.",
                "The second method, SVMacc4, normalizes the scores given by f for each query.",
                "For example, assume for query q that f outputs scores in the range 0.2 to 0.7.",
                "Then for document d, if f(d|q) = 0.6, the converted score would be f (d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Again, Tables 9, 10 and 11 show that SVMacc4 was not competitive with SVM∆ map 5.2.2 MAP vs ROCArea SVM∆ roc performed much better than SVMacc in our experiments.",
                "When trained on Indri retrieval functions (see Table 9), the performance of SVM∆ roc was slight, though not significantly, worse than the performances of SVM∆ map.",
                "However, Table 10 shows that SVM∆ map did significantly outperform SVM∆ roc when trained on the TREC submissions.",
                "Table 11 shows the performance of the models when trained on the TREC submissions with the best submission removed.",
                "The performance of most models degraded by a small amount, with SVM∆ map still having the best performance.",
                "TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Table 11: Trained on TREC Subm. (w/o Best) 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented an SVM method that directly optimizes MAP.",
                "It provides a principled approach and avoids difficult to control heuristics.",
                "We formulated the optimization problem and presented an algorithm which provably finds the solution in polynomial time.",
                "We have shown empirically that our method is generally superior to or competitive with conventional SVMs methods.",
                "Our new method makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for Accuracy and ROCArea.",
                "The computational cost for training is very reasonable in practice.",
                "Since other methods typically require tuning multiple heuristics, we also expect to train fewer models before finding one which achieves good performance.",
                "The learning framework used by our method is fairly general.",
                "A natural extension of this framework would be to develop methods to optimize for other important IR measures, such as Normalized Discounted Cumulative Gain [2, 3, 4, 12] and Mean Reciprocal Rank. 7.",
                "ACKNOWLEDGMENTS This work was funded under NSF Award IIS-0412894, NSF CAREER Award 0237381, and a gift from Yahoo!",
                "Research.",
                "The third author was also partly supported by a Microsoft Research Fellowship. 8.",
                "REFERENCES [1] B. T. Bartell, G. W. Cottrell, and R. K. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2005. [3] C. J. C. Burges, R. Ragno, and Q.",
                "Le.",
                "Learning to rank with non-smooth cost functions.",
                "In Proceedings of the International Conference on Advances in Neural Information Processing Systems (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y.",
                "Liu, H. Li, Y. Huang, and H.-W. Hon.",
                "Adapting ranking SVM to document retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [5] B. Carterette and D. Petkova.",
                "Learning a ranking from pairwise preferences.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew, and A. Ksikes.",
                "Ensemble selection from libraries of models.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [7] J. Davis and M. Goadrich.",
                "The relationship between precision-recall and ROC curves.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2006. [8] D. Hawking.",
                "Overview of the TREC-9 web track.",
                "In Proceedings of TREC-2000, 2000. [9] D. Hawking and N. Craswell.",
                "Overview of the TREC-2001 web track.",
                "In Proceedings of TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel, and K. Obermayer.",
                "Large margin rank boundaries for ordinal regression.",
                "Advances in large margin classifiers, 2000. [11] A. Herschtal and B. Raskutti.",
                "Optimising area under the ROC curve using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [12] K. Jarvelin and J. Kekalainen.",
                "Ir evaluation methods for retrieving highly relevant documents.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2000. [13] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proceedings of the International Conference on Machine Learning (ICML), pages 377-384, New York, NY, USA, 2005.",
                "ACM Press. [14] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 111-119, 2001. [15] Y. Lin, Y. Lee, and G. Wahba.",
                "Support vector machines for classification in nonstandard situations.",
                "Machine Learning, 46:191-202, 2002. [16] D. Metzler and W. B. Croft.",
                "A markov random field model for term dependencies.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 472-479, 2005. [17] K. Morik, P. Brockhausen, and T. Joachims.",
                "Combining statistical learning with a knowledge-based approach.",
                "In Proceedings of the International Conference on Machine Learning, 1999. [18] S. Robertson.",
                "The probability ranking principle in ir. journal of documentation.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.",
                "Large margin methods for structured and interdependent output variables.",
                "Journal of Machine Learning Research (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik.",
                "Statistical Learning Theory.",
                "Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz.",
                "Optimizing classifier performance via approximation to the Wilcoxon-Mann-Witney statistic.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2003."
            ],
            "original_annotated_samples": [
                "Due to computational difficulties, few <br>learning technique</br>s have been developed to directly optimize for mean average precision (MAP), despite its widespread use in evaluating such systems.",
                "INTRODUCTION State of the art information retrieval systems commonly use machine <br>learning technique</br>s to learn ranking functions."
            ],
            "translated_annotated_samples": [
                "Debido a dificultades computacionales, se han desarrollado pocas <br>técnicas de aprendizaje</br> para optimizar directamente la precisión media promedio (MAP), a pesar de su uso generalizado en la evaluación de dichos sistemas.",
                "INTRODUCCIÓN Los sistemas de recuperación de información de última generación comúnmente utilizan <br>técnicas de aprendizaje automático</br> para aprender funciones de clasificación."
            ],
            "translated_text": "Un método de Vectores de Soporte para optimizar la Precisión Promedio Yisong Yue Universidad de Cornell Ithaca, NY, EE. UU. yyue@cs.cornell.edu Thomas Finley Universidad de Cornell Ithaca, NY, EE. UU. tomf@cs.cornell.edu Filip Radlinski Universidad de Cornell Ithaca, NY, EE. UU. filip@cs.cornell.edu Thorsten Joachims Universidad de Cornell Ithaca, NY, EE. UU. tj@cs.cornell.edu RESUMEN El aprendizaje automático se utiliza comúnmente para mejorar los sistemas de recuperación clasificados. Debido a dificultades computacionales, se han desarrollado pocas <br>técnicas de aprendizaje</br> para optimizar directamente la precisión media promedio (MAP), a pesar de su uso generalizado en la evaluación de dichos sistemas. Los enfoques existentes que optimizan el MAP no encuentran una solución óptima global o son computacionalmente costosos. Por el contrario, presentamos un algoritmo de aprendizaje SVM general que encuentra de manera eficiente una solución óptima global para una relajación directa de MAP. Evaluamos nuestro enfoque utilizando los corpus de la pista web TREC 9 y TREC 10 (WT10g), comparando con SVM optimizados para precisión y área bajo la curva ROC. En la mayoría de los casos mostramos nuestro método para producir mejoras estadísticamente significativas en las puntuaciones de MAP. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de Recuperación Términos Generales Algoritmo, Teoría, Experimentación 1. INTRODUCCIÓN Los sistemas de recuperación de información de última generación comúnmente utilizan <br>técnicas de aprendizaje automático</br> para aprender funciones de clasificación. Sin embargo, la mayoría de los enfoques actuales no están optimizados para la medida de evaluación más utilizada, es decir, la Precisión Promedio Media (MAP). En cambio, los algoritmos actuales tienden a seguir uno de dos enfoques generales. El primer enfoque es aprender un modelo que estime la probabilidad de que un documento sea relevante dado una consulta (por ejemplo, [18, 14]). Si se resuelve de manera efectiva, la clasificación con el mejor rendimiento de MAP puede derivarse fácilmente de las probabilidades de relevancia. Sin embargo, lograr un MAP alto solo requiere encontrar un buen ordenamiento de los documentos. Como resultado, encontrar buenas probabilidades requiere resolver un problema más difícil de lo necesario, probablemente necesitando más datos de entrenamiento para lograr el mismo rendimiento de MAP. El segundo enfoque común es aprender una función que maximice una medida sustituta. Las medidas de rendimiento optimizadas incluyen precisión [17, 15], área bajo la curva ROC [1, 5, 10, 11, 13, 21] o modificaciones del área bajo la curva ROC [4], y NDCG [2, 3]. Aprender un modelo para optimizar tales medidas podría resultar en un rendimiento de MAP subóptimo. De hecho, aunque algunos sistemas anteriores han obtenido un buen rendimiento de MAP, se sabe que ni lograr una precisión óptima ni un área bajo la curva ROC pueden garantizar un rendimiento de MAP óptimo[7]. En este artículo, presentamos un enfoque general para aprender funciones de clasificación que maximizan el rendimiento de MAP. Específicamente, presentamos un algoritmo SVM que optimiza globalmente una relajación de pérdida de bisagra de MAP. Este enfoque simplifica el proceso de obtener funciones de clasificación con un alto rendimiento de MAP al evitar pasos intermedios adicionales y heurísticas. El nuevo algoritmo también hace que sea conceptualmente tan fácil optimizar las SVM para MAP como anteriormente solo era posible para precisión y ROCArea. A diferencia del trabajo reciente que optimiza directamente el rendimiento de MAP realizado por Metzler & Croft [16] y Caruana et al. [6], nuestra técnica es eficiente computacionalmente al encontrar una solución óptima a nivel global. Al igual que [6, 16], nuestro método aprende un modelo lineal, pero es mucho más eficiente en la práctica y, a diferencia de [16], puede manejar miles de características. Ahora describimos el algoritmo en detalle y proporcionamos la prueba de corrección. A continuación, proporcionamos un análisis del tiempo de ejecución. Concluimos con los resultados empíricos de experimentos en el corpus de la pista web TREC 9 y TREC 10. También hemos desarrollado un paquete de software que implementa nuestro algoritmo y está disponible para uso público. EL PROBLEMA DEL APRENDIZAJE Siguiendo la configuración estándar del aprendizaje automático, nuestro objetivo es aprender una función h: X → Y entre un espacio de entrada X (todas las consultas posibles) y un espacio de salida Y (clasificaciones sobre un corpus). Para cuantificar la calidad de una predicción, ˆy = h(x), consideraremos una función de pérdida ∆ : Y × Y → . ∆(y, ˆy) cuantifica la penalización por hacer la predicción ˆy si la salida correcta es y. La función de pérdida nos permite incorporar medidas específicas de rendimiento, las cuales explotaremos en http://svmrank.yisongyue.com para optimizar el MAP. Nos restringimos al escenario de aprendizaje supervisado, donde pares de entrada/salida (x, y) están disponibles para el entrenamiento y se asume que provienen de alguna distribución fija P(x, y). El objetivo es encontrar una función h tal que el riesgo (es decir, la pérdida esperada), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), se minimice. Por supuesto, P(x, y) es desconocido. Pero dado un conjunto finito de pares de entrenamiento, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, el rendimiento de h en S puede medirse mediante el riesgo empírico, R∆ S (h) = 1 n ∑ i=1 n ∆(yi, h(xi)). En el caso de aprender una función de recuperación clasificada, X denota un espacio de consultas, y Y el espacio de clasificaciones (posiblemente débiles) sobre algún corpus de documentos C = {d1, . . . ,d|C|}. Podemos definir la pérdida de precisión promedio como ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), donde rank(y) es un vector de los valores de rango de cada documento en C. Por ejemplo, para un corpus de dos documentos, {d1, d2}, con d1 teniendo un rango más alto que d2, rank(y) = (1, 0). Suponemos que las clasificaciones verdaderas tienen dos valores de clasificación, donde los documentos relevantes tienen un valor de clasificación 1 y los documentos no relevantes tienen un valor de clasificación 0. Además, asumimos que todas las clasificaciones predichas son clasificaciones completas (sin empates). Sea p = rango(y) y ˆp = rango(ˆy). La puntuación de precisión promedio se define como MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, donde rel = |{i : pi = 1}| es el número de documentos relevantes, y Prec@j es el porcentaje de documentos relevantes en los primeros j documentos en la clasificación predicha ˆy. MAP es la media de las puntuaciones de precisión promedio de un grupo de consultas. La mayoría de los algoritmos de aprendizaje se optimizan para precisión o ROCArea. Si bien optimizar estas medidas podría lograr un buen rendimiento de MAP, usamos dos ejemplos simples para mostrar que también puede ser subóptimo en términos de MAP. ROCArea asigna una penalización igual a cada desordenamiento de un par relevante/no relevante. Por el contrario, MAP asigna mayores penalizaciones a los errores de ordenamiento más arriba en la clasificación predicha. Usando nuestra notación, el Área bajo la Curva ROC (ROCArea) se puede definir como ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], donde p es el ranking verdadero (débil), ˆp es el ranking predicho, y 1[b] es la función indicadora condicionada a b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Tabla 1: Ejemplo y Modelos Supongamos que tenemos un espacio de hipótesis con solo dos funciones de hipótesis, h1 y h2, como se muestra en la Tabla 1. Estas dos hipótesis predicen un ranking para la consulta x sobre un corpus de ocho documentos. Tabla 2: Rendimiento de los Modelos de Juguete La Tabla 2 muestra las puntuaciones de MAP y ROCArea de h1 y h2. Aquí, un método de aprendizaje que optimiza para el Área bajo la curva ROC elegiría h2 ya que esto resulta en un puntaje de Área bajo la curva ROC más alto, pero esto produce un puntaje de MAP subóptimo. 2.2 MAP vs Precisión Usando un ejemplo muy similar, ahora demostramos cómo optimizar para la precisión podría resultar en un puntaje de MAP subóptimo. Los modelos que se optimizan para la precisión no están directamente preocupados por la clasificación. En cambio, aprenden un umbral tal que los documentos que obtienen una puntuación superior al umbral pueden ser clasificados como relevantes y los documentos que obtienen una puntuación inferior como no relevantes. Consideramos nuevamente un espacio de hipótesis con dos hipótesis. La Tabla 3 muestra las predicciones de las dos hipótesis en una única consulta x. Hipótesis MAP Mejor Precisión h1(q) 0.70 0.64 h2(q) 0.64 0.73 Tabla 4: Rendimiento de los Modelos de Juguete La Tabla 4 muestra los puntajes de MAP y mejor precisión de h1(q) y h2(q). La mejor precisión se refiere a la precisión más alta alcanzable en esa clasificación al considerar todos los umbrales posibles. Por ejemplo, con h1(q), un umbral entre los documentos 1 y 2 da 4 errores (documentos 6-9 clasificados incorrectamente como no relevantes), lo que resulta en una precisión de 0.64. De manera similar, con h2(q), un umbral entre los documentos 5 y 6 da 3 errores (los documentos 10-11 clasificados incorrectamente como relevantes, y el documento 1 como no relevante), lo que resulta en una precisión de 0.73. Un método de aprendizaje que optimiza la precisión elegiría h2 ya que esto resulta en un puntaje de precisión más alto, pero esto produce un puntaje de MAP subóptimo. 3. OPTIMIZANDO LA PRECISIÓN PROMEDIO Nos basamos en el enfoque utilizado por [13] para optimizar el Área bajo la Curva ROC. A diferencia de ROCArea, sin embargo, MAP no se descompone linealmente en los ejemplos y requiere un algoritmo sustancialmente extendido, el cual describimos en esta sección. Recuerda que la clasificación verdadera es una clasificación débil con dos valores de clasificación (relevante y no relevante). Que Cx y C¯x denoten el conjunto de documentos relevantes y no relevantes de C para la consulta x, respectivamente. Nos enfocamos en funciones que están parametrizadas por un vector de peso w, y por lo tanto deseamos encontrar w para minimizar el riesgo empírico, R∆ S (w) ≡ R∆ S (h(·; w)). Nuestro enfoque es aprender una función discriminante F: X × Y → sobre pares de entrada-salida. Dada la consulta x, podemos derivar una predicción encontrando la clasificación y que maximiza la función discriminante: h(x; w) = argmax y∈Y F(x, y; w). (1) Suponemos que F es lineal en alguna representación de características combinadas de entradas y salidas Ψ(x, y) ∈ RN, es decir, F(x, y; w) = wT Ψ(x, y). (2) La función de características combinadas que utilizamos es Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))], donde φ: X × C → N es una función de mapeo de características de un par consulta/documento a un punto en un espacio dimensional N. Representamos las clasificaciones como una matriz de ordenamientos por pares, Y ⊂ {−1, 0, +1}|C|×|C| . Para cualquier y ∈ Y, yij = +1 si di está clasificado por delante de dj, y yij = −1 si dj está clasificado por delante de di, y yij = 0 si di y dj tienen el mismo rango. Consideramos solo matrices que corresponden a clasificaciones válidas (es decir, que cumplen con la antisimetría y la transitividad). De manera intuitiva, Ψ es una suma de las diferencias vectoriales de todos los pares de documentos relevantes/no relevantes. Dado que asumimos que las clasificaciones predichas son clasificaciones completas, yij es o bien +1 o −1 (nunca 0). Dado un vector de pesos aprendido w, predecir un ranking (es decir, resolver la ecuación (1)) dado una consulta x se reduce a elegir cada yij para maximizar wT Ψ(x, y). Como también se discute en [13], esto se logra ordenando los documentos por wT φ(x, d) en orden descendente. Discutiremos más adelante las elecciones de φ que utilizamos para nuestros experimentos. 3.1 SVM Estructurales La formulación anterior es muy similar a aprender un modelo lineal directo mientras se entrena en la diferencia de pares de documentos relevantes/no relevantes. Muchos enfoques basados en SVM optimizan sobre estas diferencias en pares (por ejemplo, [5, 10, 13, 4]), aunque estos métodos no optimizan para el MAP durante el entrenamiento. Anteriormente, no estaba claro cómo incorporar funciones de pérdida multivariadas no lineales como la pérdida MAP directamente en problemas de optimización global como el entrenamiento de SVM. Ahora presentamos un método basado en SVM estructurales [19] para abordar este problema. Utilizamos la formulación del SVM estructural, presentada en el Problema de Optimización 1, para aprender un w ∈ RN. Problema de optimización 1. (SVM estructural) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) La función objetivo a minimizar (3) es un compromiso entre la complejidad del modelo, w 2 , y una relajación de pérdida de MAP mediante la pérdida de bisagra, P ξi. Como es habitual en el entrenamiento de SVM, C es igual a 2. Por ejemplo, una dimensión podría ser el número de veces que las palabras de la consulta aparecen en el documento. Algoritmo 1 Algoritmo de plano de corte para resolver OP 1 dentro de la tolerancia. 1: Entrada: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ para todo i = 1, . . . , n 3: repetir 4: para i = 1, . . . , n hacer 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: calcular ˆy = argmaxy∈Y H(y; w) 7: calcular ξi = max{0, maxy∈Wi H(y; w)} 8: si H(ˆy; w) > ξi + entonces 9: Wi ← Wi ∪ {ˆy} 10: w ← optimizar (3) sobre W = S i Wi 11: fin si 12: fin para 13: hasta que ningún Wi haya cambiado durante la iteración parámetro que controla este equilibrio y puede ajustarse para lograr un buen rendimiento en diferentes tareas de entrenamiento. Para cada (xi, yi) en el conjunto de entrenamiento, se añade un conjunto de restricciones de la forma en la ecuación (4) al problema de optimización. Ten en cuenta que wT Ψ(x, y) es exactamente nuestra función discriminante F(x, y; w) (ver ecuación (2)). Durante la predicción, nuestro modelo elige el ranking que maximiza el discriminante (1). Si el valor del discriminante para una clasificación incorrecta y es mayor que para la clasificación verdadera yi (por ejemplo, F(xi, y; w) > F(xi, yi; w)), entonces la variable de holgura correspondiente, ξi, debe ser al menos ∆(yi, y) para que se cumpla esa restricción. Por lo tanto, la suma de los márgenes, P ξi, acota superiormente la pérdida MAP. Esto se establece formalmente en la Proposición 1. Proposición 1. Sea ξ∗ (w) la solución óptima de las variables de holgura para OP 1 para un vector de peso dado w. Entonces 1 n Pn i=1 ξi es una cota superior del riesgo empírico R∆ S (w). (ver [19] para la prueba) La Proposición 1 muestra que OP 1 aprende una función de clasificación que optimiza una cota superior del error de MAP en el conjunto de entrenamiento. Desafortunadamente hay un problema: se requiere una restricción para cada posible resultado incorrecto y, y el número de resultados incorrectos posibles es exponencial en el tamaño de C. Afortunadamente, podemos emplear el Algoritmo 1 para resolver OP 1. El algoritmo 1 es un algoritmo de plano de corte, introduciendo iterativamente restricciones hasta que hayamos resuelto el problema original dentro de una tolerancia deseada [19]. El algoritmo comienza sin restricciones y encuentra de forma iterativa, para cada ejemplo (xi, yi), la salida ˆy asociada con la restricción más violada. Si la restricción correspondiente es violada por más de lo que introducimos ˆy en el conjunto de trabajo Wi de restricciones activas, por ejemplo i, y volvemos a resolver (3) usando el W actualizado. Se puede demostrar que el bucle externo del Algoritmo 1 está garantizado a detenerse dentro de un número polinomial de iteraciones para cualquier precisión deseada. Teorema 1. Sea ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y), ¯∆ = maxi maxy ∆(yi, y), y para cualquier > 0, el Algoritmo 1 termina después de agregar a lo sumo max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff restricciones al conjunto de trabajo W. (ver [19] para la prueba) Sin embargo, dentro del bucle interno de este algoritmo tenemos que calcular argmaxy∈Y H(y; w), donde H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), o equivalentemente, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), ya que wT Ψ(xi, yi) es constante con respecto a y. Aunque está estrechamente relacionado con el procedimiento de clasificación, esto tiene la complicación sustancial de que debemos lidiar con el término adicional ∆(yi, y). Sin la capacidad de encontrar eficientemente la restricción más violada (es decir, resolver argmaxy∈Y H(y, w)), el procedimiento de generación de restricciones no es viable. 3.2 Encontrar la restricción más violada utilizando OP 1 y optimizando la pérdida de ROCArea (∆roc), el problema de encontrar la restricción más violada, o resolver argmaxy∈Y H(y, w) (en adelante argmax H), se aborda en [13]. Resolver argmax H para ∆map es más difícil. Esto se debe principalmente a que ROCArea se descompone de manera ordenada en una suma de puntuaciones calculadas de forma independiente en cada ordenamiento relativo de un par de documentos relevantes/no relevantes. MAP, por otro lado, no se descompone de la misma manera que ROCArea. La principal contribución algorítmica de este artículo es un método eficiente para resolver argmax H para ∆map. Una propiedad útil de ∆map es que es invariante al intercambiar dos documentos con igual relevancia. Por ejemplo, si los documentos da y db son ambos relevantes, entonces intercambiar las posiciones de da y db en cualquier clasificación no afecta a ∆map. Por extensión, ∆map es invariante a cualquier permutación arbitraria de los documentos relevantes entre sí y de los documentos no relevantes entre sí. Sin embargo, esta reorganización afectará la puntuación del discriminante, wT Ψ(x, y). Esto nos lleva a la Observación 1. Observación 1. Considera clasificaciones que estén limitadas por fijar la relevancia en cada posición de la clasificación (por ejemplo, el tercer documento en la clasificación debe ser relevante). Cada clasificación que cumpla con el mismo conjunto de restricciones tendrá el mismo ∆map. Si los documentos relevantes están ordenados por wT φ(x, d) en orden descendente, y los documentos no relevantes también están ordenados de la misma manera por wT φ(x, d), entonces la intercalación de las dos listas ordenadas que cumpla con las restricciones maximizará H para ese conjunto de clasificaciones restringidas. La Observación 1 implica que en la clasificación que maximiza H, los documentos relevantes se ordenarán por wT φ(x, d), y los documentos no relevantes también se ordenarán de la misma manera. Al ordenar primero los documentos relevantes y no relevantes, el problema se simplifica a encontrar la intercalación óptima de dos listas ordenadas. Para el resto de nuestra discusión, asumimos que los documentos relevantes y no relevantes están ordenados por wT φ(x, d) en orden descendente. Para mayor comodidad, también nos referimos a los documentos relevantes como {dx 1 , . . . dx |Cx|} = Cx, y a los documentos no relevantes como {d¯x 1 , . . . d¯x |C¯x|} = C¯x. Definimos δj(i1, i2), con i1 < i2, como el cambio en H desde cuando el documento relevante de mayor rango clasificado después de d¯x j es dx i1 hasta que es dx i2. Para i2 = i1 + 1, tenemos δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5), donde si = wT φ(x, di). El primer término en (5) es el cambio en ∆map cuando el documento relevante i tiene j documentos no relevantes clasificados antes de él, en lugar de j-1. El segundo término es el cambio en la puntuación del discriminante, wT Ψ(x, y), cuando yij cambia de +1 a −1. . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . . Figura 1: Ejemplo para δj(i, i + 1). La Figura 1 proporciona un ejemplo conceptual para δj(i, i + 1). La clasificación inferior difiere de la superior solo cuando d¯x j sube un rango. La diferencia en el valor de H para estas dos clasificaciones es exactamente δj(i, i + 1). Para cualquier i1 < i2, podemos definir δj(i1, i2) como δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) o equivalentemente, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) . Deja que o1, . . . , o|C¯x| codifiquen las posiciones de los documentos no relevantes, donde dx oj es el documento relevante de mayor rango clasificado después del j-ésimo documento no relevante. Debido a la Observación 1, esta codificación identifica de forma única un ranking completo. Podemos recuperar la clasificación como yij = 8 >>>< >>>: 0 si i = j sign(si − sj) si di, dj relevancia igual signo(oj − i − 0.5) si di = dx i , dj = d¯x j signo(j − oi + 0.5) si di = d¯x i , dj = dx j. (7) Ahora podemos reformular H en una nueva función objetivo, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), donde ¯y es la verdadera clasificación (débil). Conceptualmente, H comienza con una clasificación perfecta ¯y y agrega el cambio en H cuando cada documento no relevante sucesivo sube en la clasificación. Luego podemos reformular el problema argmax H como argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) sujeto a o1 ≤ . . . ≤ o|C¯x|. (9) El Algoritmo 2 describe el algoritmo utilizado para resolver la ecuación (8). Conceptualmente, el Algoritmo 2 comienza con un ranking perfecto. Entonces, para cada documento no relevante sucesivo, el algoritmo modifica la solución deslizando ese documento hacia arriba en la clasificación para maximizar localmente H, manteniendo las posiciones de los otros documentos no relevantes constantes. 3.2.1 Prueba de Corrección El Algoritmo 2 es codicioso en el sentido de que encuentra la mejor posición de cada documento no relevante de forma independiente de los otros documentos no relevantes. En otras palabras, el algoritmo maximiza H para cada documento no relevante, d¯x j, Algoritmo 2 Encontrar la Restricción Más Violada (argmax H) para el Algoritmo 1 con ∆map 1: Entrada: w, Cx, C¯x 2: ordenar Cx y C¯x en orden descendente de wT φ(x, d) 3: sx i ← wT φ(x, dx i), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i), i = 1, . . . , |C¯x | 5: para j = 1, . . . , |C¯x | hacer 6: optj ← argmaxk δj(k, |Cx| + 1) 7: fin para 8: codificar ˆy de acuerdo con (7) 9: devolver ˆy sin considerar las posiciones de los otros documentos no relevantes, y así ignora las restricciones de (9). Para que la solución sea factible, el documento no relevante j-ésimo debe ser clasificado después de los primeros j-1 documentos no relevantes, satisfaciendo así opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. Si la solución es factible, entonces claramente resuelve (8). Por lo tanto, basta con demostrar que el Algoritmo 2 cumple con (10). Primero demostramos que δj(·, ·) es monótonamente decreciente en j. Lema 1. Para cualquier 1 ≤ i1 < i2 ≤ |Cx | + 1 y 1 ≤ j < |C¯x |, debe ser el caso que δj+1(i1, i2) ≤ δj(i1, i2). Prueba. Recuerde que tanto δj(i1, i2) como δj+1(i1, i2) son sumas de términos i2 − i1. Mostraremos que cada término en la suma de δj+1(i1, i2) no es mayor que el término correspondiente en δj(i1, i2), o δj+1(k, k + 1) ≤ δj(k, k + 1) para k = i1, . . . , i2 − 1. Cada término en δj(k, k +1) y δj+1(k, k +1) puede ser descompuesto aún más en dos partes (ver (5)). Mostraremos que cada parte de δj+1(k, k + 1) no es mayor que la parte correspondiente en δj(k, k + 1). En otras palabras, demostraremos que tanto j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) como −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) son verdaderos para los valores mencionados de j y k. Es fácil ver que (11) es verdadero observando que para cualquier par de enteros positivos 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1, y eligiendo a = j y b = j + k. La segunda desigualdad (12) se cumple porque el Algoritmo 2 primero ordena d¯x en orden descendente de s¯x, lo que implica s¯x j+1 ≤ s¯x j. Así vemos que cada término en δj+1 no es mayor que el término correspondiente en δj, lo cual completa la prueba. El resultado del Lema 1 conduce directamente a nuestro resultado principal de corrección: Teorema 2. En el Algoritmo 2, los valores calculados de optj satisfacen (10), lo que implica que la solución devuelta por el Algoritmo 2 es factible y, por lo tanto, óptima. Prueba. Demostraremos que optj ≤ optj+1 se cumple para cualquier 1 ≤ j < |C¯x|, implicando así (10). Dado que el Algoritmo 2 calcula optj como optj = argmax k δj(k, |Cx | + 1), (13), entonces por definición de δj (6), para cualquier 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0. Usando el Lema 1, sabemos que δj+1(i, optj) ≤ δj(i, optj) < 0, lo que implica que para cualquier 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0. Supongamos por contradicción que optj+1 < optj. Entonces δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), lo cual contradice (13). Por lo tanto, debe ser el caso que optj ≤ optj+1, lo cual completa la prueba. 3.2.2 Tiempo de ejecución El tiempo de ejecución del Algoritmo 2 se puede dividir en dos partes. La primera parte es la clasificación por wT φ(x, d), lo cual requiere un tiempo de O(n log n), donde n = |Cx | + |C¯x |. La segunda parte calcula cada optj, lo cual requiere un tiempo de O(|Cx| · |C¯x|). Aunque en el peor de los casos esto es O(n2), el número de documentos relevantes, |Cx|, suele ser muy pequeño (por ejemplo, constante con respecto a n), en cuyo caso el tiempo de ejecución para la segunda parte es simplemente O(n). Para la mayoría de los conjuntos de datos del mundo real, el Algoritmo 2 está dominado por la ordenación y tiene una complejidad O(n log n). El Algoritmo 1 está garantizado de detenerse en un número polinómico de iteraciones [19], y cada iteración ejecuta el Algoritmo 2. Prácticamente todos los modelos que funcionaron bien fueron entrenados en un tiempo razonable (generalmente menos de una hora). Una vez que el entrenamiento esté completo, hacer predicciones sobre la consulta x usando la hipótesis resultante h(x|w) solo requiere ordenar por wT φ(x, d). Desarrollamos nuestro software utilizando una interfaz de Python a SVMstruct, ya que el lenguaje Python simplificó en gran medida el proceso de codificación. Para mejorar el rendimiento, es recomendable utilizar la implementación estándar en C de SVMstruct. CONFIGURACIÓN DEL EXPERIMENTO El objetivo principal de nuestros experimentos es evaluar si la optimización directa de MAP conduce a un rendimiento de MAP mejorado en comparación con los métodos convencionales de SVM que optimizan una pérdida sustituta como la precisión o el área bajo la curva ROC. Evaluamos empíricamente nuestro método utilizando dos conjuntos de consultas de la TREC Web Track, uno de TREC 9 y otro de TREC 10 (temas 451-500 y 501-550), ambos de los cuales utilizaron el corpus WT10g. Para cada consulta, TREC proporciona las evaluaciones de relevancia de los documentos. Generamos nuestras características utilizando las puntuaciones de las funciones de recuperación existentes en estas consultas. Si bien nuestro método es agnóstico al significado de las características, elegimos utilizar funciones de recuperación existentes como una forma simple pero efectiva de adquirir características útiles. Por lo tanto, nuestros experimentos de estadísticas de conjuntos de datos básicos esencialmente prueban la capacidad de nuestros métodos para volver a clasificar los documentos altamente clasificados (por ejemplo, volver a combinar las puntuaciones de las funciones de recuperación) para mejorar el MAP. Comparamos nuestro método con las mejores funciones de recuperación entrenadas (en adelante, funciones base), así como con los métodos SVM propuestos anteriormente. Comparar con las mejores funciones base pone a prueba la capacidad de nuestros métodos para aprender una combinación útil. Comparar con métodos SVM anteriores nos permite probar si optimizar directamente para el MAP (en lugar de precisión o área bajo la curva ROC) logra una puntuación de MAP más alta en la práctica. El resto de esta sección describe las funciones base y el método de generación de características en detalle. 4.1 Elección de Funciones de Recuperación Elegimos dos conjuntos de funciones base para nuestros experimentos. Para el primer conjunto, generamos tres índices sobre el corpus WT10g utilizando Indri5. El primer índice fue generado utilizando la configuración predeterminada, el segundo utilizó Porter-stemming, y el último utilizó Porter-stemming y las palabras vacías predeterminadas de Indris. Para TREC 9 y TREC 10, utilizamos la parte de descripción de cada consulta y puntuamos los documentos utilizando cinco de los métodos de recuperación integrados en Indri, que son Similitud Coseno, TFIDF, Okapi, Modelo de Lenguaje con Prior de Dirichlet y Modelo de Lenguaje con Prior de Jelinek-Mercer. Todos los parámetros se mantuvieron en sus valores predeterminados. Calculamos las puntuaciones de estos cinco métodos de recuperación sobre los tres índices, dando un total de 15 funciones base. Para cada consulta, consideramos las puntuaciones de los documentos encontrados en la unión de los mejores 1000 documentos de cada función base. Para nuestro segundo conjunto de funciones base, utilizamos puntuaciones de las presentaciones de la pista web TREC 9 [8] y TREC 10 [9]. Utilizamos solo las presentaciones no manuales y no breves de ambos años. Para TREC 9 y TREC 10, hubo 53 y 18 envíos de este tipo, respectivamente. Una presentación típica contenía puntajes de sus 1000 documentos principales. b ca wT φ(x,d) f(d|x) Figura 2: Ejemplo de Agrupación de Características 4.2 Generación de Características Para generar ejemplos de entrada para nuestro método, se debe proporcionar una instancia concreta de φ. Para cada documento d puntuado por un conjunto de funciones de recuperación F en la consulta x, generamos las características como un vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf, donde f(d|x) denota la puntuación que la función de recuperación f asigna al documento d para la consulta x, y cada Kf es un conjunto de valores reales. Desde un nivel alto, estamos expresando la puntuación de cada función de recuperación utilizando |Kf | + 1 contenedores. Dado que estamos utilizando núcleos lineales, se puede pensar en el problema de aprendizaje como encontrar una buena combinación de piezas constantes de los puntajes de las funciones de recuperación. La Figura 2 muestra un ejemplo de nuestro método de mapeo de características. En este ejemplo tenemos una única característica F = {f}. Aquí, Kf = {a, b, c}, y el vector de pesos es w = wa, wb, wc. Para cualquier documento d y consulta x, tenemos wT φ(x, d) = 8 >>< >>: 0 si f(d|x) < a wa si a ≤ f(d|x) < b wa + wb si b ≤ f(d|x) < c wa + wb + wc si c ≤ f(d|x) . Esto se expresa cualitativamente en la Figura 2, donde wa y wb son positivos, y wc es negativo. Realizamos nuestros experimentos principales utilizando cuatro opciones de F: el conjunto de las funciones de recuperación de Indri mencionadas anteriormente para TREC 9 y TREC 10, y las presentaciones de la pista web para TREC 9 y TREC 10. Para cada F y cada función f ∈ F, elegimos 50 valores para Kf que estuvieran razonablemente espaciados y capturaran la región sensible de f. Utilizando las cuatro opciones de F, generamos cuatro conjuntos de datos para nuestros experimentos principales. La Tabla 5 contiene estadísticas de los conjuntos de datos generados. Hay muchas formas de generar características, y no estamos abogando por nuestro método sobre los demás. Esto fue simplemente un medio eficiente para normalizar las salidas de diferentes funciones y permitir un modelo más expresivo. EXPERIMENTOS Para cada conjunto de datos en la Tabla 5, realizamos 50 pruebas. Para cada prueba, entrenamos con 10 consultas seleccionadas al azar, y seleccionamos otras 5 consultas al azar para un conjunto de validación. Los modelos fueron entrenados utilizando una amplia gama de valores de C. El modelo que tuvo mejor rendimiento en el conjunto de validación fue seleccionado y probado en las 35 consultas restantes. Todas las consultas fueron seleccionadas para estar en los conjuntos de entrenamiento, validación y prueba la misma cantidad de veces. Utilizando esta configuración, realizamos los mismos experimentos mientras usábamos nuestro método (mapa SVM∆), un SVM optimizando para ROCArea (SVM∆ roc) [13], y un SVM de clasificación convencional (SVMacc) [20]. Todos los métodos de SVM utilizaron un kernel lineal. Informamos sobre el rendimiento promedio de todos los modelos en las 50 pruebas. 5.1 Comparación con Funciones Base Al analizar nuestros resultados, la primera pregunta a responder es, ¿puede SVM∆ map aprender un modelo que supere al mejor modelo base TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.290 - 0.287Mejor Func. 0.280 28/22 0.283 29/21 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 36/14 ** Tabla 7: Comparación con Envíos TREC TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288Mejor Func. 0.280 27/23 0.283 31/19 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 35/15 ** Tabla 8: Comparación con Funciones de Envíos TREC (sin el mejor) La Tabla 6 presenta la comparación del mapa SVM∆ con las mejores funciones base de Indri. Cada grupo de columnas contiene el rendimiento del MAP macro-promediado de SVM∆ map o una función base. Las columnas W/L muestran el número de consultas donde SVM∆ map logró un puntaje MAP más alto. Se realizaron pruebas de significancia utilizando la prueba de rango con signo de Wilcoxon de dos colas. Dos estrellas indican un nivel de significancia de 0.95. Todas las tablas que muestran nuestros resultados experimentales están estructuradas de manera idéntica. Aquí encontramos que SVM∆ mapea significativamente mejor que las mejores funciones base. La Tabla 7 muestra la comparación cuando se entrena con las presentaciones de TREC. Si bien logra una puntuación de MAP más alta que las mejores funciones base, la diferencia de rendimiento entre SVM∆ y las funciones base no es significativa. Dado que muchas de estas presentaciones utilizan funciones de puntuación cuidadosamente diseñadas para lograr un alto MAP, es posible que las presentaciones con mejor rendimiento utilicen técnicas que engloben las técnicas de las otras presentaciones. Como resultado, el mapa SVM∆ no sería capaz de aprender una hipótesis que pueda superar significativamente la mejor presentación. Por lo tanto, realizamos los mismos experimentos utilizando un conjunto de datos modificado en el que se eliminaron las características calculadas utilizando la mejor presentación. La tabla 8 muestra los resultados (ten en cuenta que aún estamos comparando con la mejor presentación, aunque no la estamos utilizando para el entrenamiento). Observa que si bien el rendimiento del SVM∆ map se degradó ligeramente, aún era comparable con el de la mejor presentación. 5.2 Comparación con Métodos SVM Anteriores La siguiente pregunta a responder es, ¿produce el SVM∆ map puntajes MAP más altos que los métodos SVM anteriores? Las tablas 9 y 10 presentan los resultados de SVM∆ map, SVM∆ roc y SVMacc cuando se entrenan con las funciones de recuperación de Indri y las presentaciones de TREC, respectivamente. La Tabla 11 contiene los resultados correspondientes cuando se entrena con las presentaciones de TREC sin la mejor presentación. Para empezar, nuestros resultados indican que SVMacc no fue competitivo con SVM∆ map y SVM∆ roc, y a veces tuvo un rendimiento notablemente inferior. Por lo tanto, probamos varios enfoques para mejorar el rendimiento de SVMacc. 5.2.1 Métodos alternativos de SVMacc Un problema que puede causar que SVMacc tenga un rendimiento deficiente es el desequilibrio severo entre documentos relevantes y no relevantes. La gran mayoría de los documentos no son relevantes. SVMacc2 aborda este problema asignando una penalización mayor a los errores de falsos negativos. Para cada conjunto de datos, la proporción de las penalizaciones por falsos negativos a falsos positivos es igual a la proporción entre el número de documentos no relevantes y relevantes en ese conjunto de datos. Las tablas 9, 10 y 11 indican que SVMacc2 sigue teniendo un rendimiento significativamente peor que SVM∆ map. Otro posible problema es que SVMacc intenta encontrar solo un umbral discriminatorio b que sea invariable a la consulta. Puede ser que diferentes consultas requieran diferentes valores de b. Tener el método de aprendizaje intentando encontrar un buen valor de b (cuando no existe) puede ser perjudicial. Tomamos dos enfoques para abordar este problema. El primer método, SVMacc3, convierte las puntuaciones de la función de recuperación en percentiles. Por ejemplo, para el documento d, la consulta q y la función de recuperación f, si la puntuación f(d|q) se encuentra en el 90% superior de las puntuaciones f(·|q) para la consulta q, entonces la puntuación convertida es f(d|q) = 0.9. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Las tablas 9, 10 y 11 muestran que el rendimiento de SVMacc3 tampoco fue competitivo con SVM∆ map. El segundo método, SVMacc4, normaliza las puntuaciones dadas por f para cada consulta. Por ejemplo, suponga para la consulta q que f produce puntuaciones en el rango de 0.2 a 0.7. Entonces, para el documento d, si f(d|q) = 0.6, la puntuación convertida sería f(d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Nuevamente, las Tablas 9, 10 y 11 muestran que SVMacc4 no fue competitivo con SVM∆ map 5.2.2 MAP vs ROCArea. SVM∆ roc tuvo un rendimiento mucho mejor que SVMacc en nuestros experimentos. Cuando se entrenó con las funciones de recuperación de Indri (ver Tabla 9), el rendimiento de SVM∆ roc fue ligeramente, aunque no significativamente, peor que el rendimiento de SVM∆ map. Sin embargo, la Tabla 10 muestra que el mapa SVM∆ superó significativamente al roc SVM∆ cuando se entrenó con las presentaciones de TREC. La tabla 11 muestra el rendimiento de los modelos cuando se entrenan con las presentaciones de TREC y se elimina la mejor presentación. El rendimiento de la mayoría de los modelos se degradó ligeramente, con SVM∆ map aún teniendo el mejor rendimiento. TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288 SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Tabla 11: Entrenado en TREC Subm. (sin Mejor) 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado un método SVM que optimiza directamente el MAP. Proporciona un enfoque basado en principios y evita heurísticas difíciles de controlar. Formulamos el problema de optimización y presentamos un algoritmo que encuentra la solución de manera demostrable en tiempo polinómico. Hemos demostrado empíricamente que nuestro método es generalmente superior o competitivo con los métodos convencionales de SVM. Nuestro nuevo método hace que sea conceptualmente tan fácil optimizar SVMs para MAP como anteriormente solo era posible para Precisión y Área bajo la curva ROC. El costo computacional para el entrenamiento es muy razonable en la práctica. Dado que otros métodos suelen requerir ajustar múltiples heurísticas, también esperamos entrenar menos modelos antes de encontrar uno que logre un buen rendimiento. El marco de aprendizaje utilizado por nuestro método es bastante general. Una extensión natural de este marco sería desarrollar métodos para optimizar otras medidas importantes de IR, como la Ganancia Acumulada Normalizada Descontada [2, 3, 4, 12] y la Reciprocidad Media de Rango. 7. AGRADECIMIENTOS Este trabajo fue financiado bajo el Premio NSF IIS-0412894, el Premio NSF CAREER 0237381 y un obsequio de Yahoo! Investigación. El tercer autor también fue parcialmente apoyado por una Beca de Investigación de Microsoft. 8. REFERENCIAS [1] B. T. Bartell, G. W. Cottrell y R. K. Belew. Combinación automática de múltiples sistemas de recuperación clasificados. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2005. [3] C. J. C. Burges, R. Ragno y Q. Lo. Aprendizaje para clasificar con funciones de costo no suaves. En Actas de la Conferencia Internacional sobre Avances en Sistemas de Información Neural (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang y H.-W. Hon. Adaptando el SVM de clasificación para la recuperación de documentos. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [5] B. Carterette y D. Petkova. Aprendiendo un ranking a partir de preferencias por pares. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew y A. Ksikes. Selección de conjunto de bibliotecas de modelos. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [7] J. Davis y M. Goadrich. La relación entre las curvas de precisión-recall y ROC. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2006. [8] D. Hawking. Resumen de la pista web TREC-9. En Actas de TREC-2000, 2000. [9] D. Hawking y N. Craswell. Resumen de la pista web TREC-2001. En Actas de TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel y K. Obermayer. Límites de rango de margen amplio para regresión ordinal. Avances en clasificadores de márgenes amplios, 2000. [11] A. Herschtal y B. Raskutti. Optimizando el área bajo la curva ROC utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [12] K. Jarvelin y J. Kekalainen. Métodos de evaluación para recuperar documentos altamente relevantes. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2000. [13] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), páginas 377-384, Nueva York, NY, EE. UU., 2005. ACM Press. [14] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), páginas 111-119, 2001. [15] Y. Lin, Y. Lee y G. Wahba. Máquinas de vectores de soporte para clasificación en situaciones no estándar. Aprendizaje automático, 46:191-202, 2002. [16] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [17] K. Morik, P. Brockhausen y T. Joachims. Combinando el aprendizaje estadístico con un enfoque basado en el conocimiento. En Actas de la Conferencia Internacional sobre Aprendizaje Automático, 1999. [18] S. Robertson. El principio de clasificación de probabilidad en la revista IR de documentación. Revista de Documentación, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims y Y. Altun. Métodos de margen amplio para variables de salida estructuradas e interdependientes. Revista de Investigación en Aprendizaje Automático (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik. Teoría del Aprendizaje Estadístico. Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz. \n\nWiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer y R. Wolniewicz. Optimizando el rendimiento del clasificador mediante la aproximación a la estadística de Wilcoxon-Mann-Witney. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2003. ",
            "candidates": [],
            "error": [
                [
                    "técnicas de aprendizaje",
                    "técnicas de aprendizaje automático"
                ]
            ]
        },
        "mean average precision": {
            "translated_key": "precisión media promedio",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT Machine learning is commonly used to improve ranked retrieval systems.",
                "Due to computational difficulties, few learning techniques have been developed to directly optimize for <br>mean average precision</br> (MAP), despite its widespread use in evaluating such systems.",
                "Existing approaches optimizing MAP either do not find a globally optimal solution, or are computationally expensive.",
                "In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of MAP.",
                "We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora (WT10g), comparing against SVMs optimized for accuracy and ROCArea.",
                "In most cases we show our method to produce statistically significant improvements in MAP scores.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval Models General Terms Algorithm, Theory, Experimentation 1.",
                "INTRODUCTION State of the art information retrieval systems commonly use machine learning techniques to learn ranking functions.",
                "However, most current approaches do not optimize for the evaluation measure most often used, namely <br>mean average precision</br> (MAP).",
                "Instead, current algorithms tend to take one of two general approaches.",
                "The first approach is to learn a model that estimates the probability of a document being relevant given a query (e.g., [18, 14]).",
                "If solved effectively, the ranking with best MAP performance can easily be derived from the probabilities of relevance.",
                "However, achieving high MAP only requires finding a good ordering of the documents.",
                "As a result, finding good probabilities requires solving a more difficult problem than necessary, likely requiring more training data to achieve the same MAP performance.",
                "The second common approach is to learn a function that maximizes a surrogate measure.",
                "Performance measures optimized include accuracy [17, 15], ROCArea [1, 5, 10, 11, 13, 21] or modifications of ROCArea [4], and NDCG [2, 3].",
                "Learning a model to optimize for such measures might result in suboptimal MAP performance.",
                "In fact, although some previous systems have obtained good MAP performance, it is known that neither achieving optimal accuracy nor ROCArea can guarantee optimal MAP performance[7].",
                "In this paper, we present a general approach for learning ranking functions that maximize MAP performance.",
                "Specifically, we present an SVM algorithm that globally optimizes a hinge-loss relaxation of MAP.",
                "This approach simplifies the process of obtaining ranking functions with high MAP performance by avoiding additional intermediate steps and heuristics.",
                "The new algorithm also makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for accuracy and ROCArea.",
                "In contrast to recent work directly optimizing for MAP performance by Metzler & Croft [16] and Caruana et al. [6], our technique is computationally efficient while finding a globally optimal solution.",
                "Like [6, 16], our method learns a linear model, but is much more efficient in practice and, unlike [16], can handle many thousands of features.",
                "We now describe the algorithm in detail and provide proof of correctness.",
                "Following this, we provide an analysis of running time.",
                "We finish with empirical results from experiments on the TREC 9 and TREC 10 Web Track corpus.",
                "We have also developed a software package implementing our algorithm that is available for public use1 . 2.",
                "THE LEARNING PROBLEM Following the standard machine learning setup, our goal is to learn a function h : X → Y between an input space X (all possible queries) and output space Y (rankings over a corpus).",
                "In order to quantify the quality of a prediction, ˆy = h(x), we will consider a loss function ∆ : Y × Y → . ∆(y, ˆy) quantifies the penalty for making prediction ˆy if the correct output is y.",
                "The loss function allows us to incorporate specific performance measures, which we will exploit 1 http://svmrank.yisongyue.com for optimizing MAP.",
                "We restrict ourselves to the supervised learning scenario, where input/output pairs (x, y) are available for training and are assumed to come from some fixed distribution P(x, y).",
                "The goal is to find a function h such that the risk (i.e., expected loss), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), is minimized.",
                "Of course, P(x, y) is unknown.",
                "But given a finite set of training pairs, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, the performance of h on S can be measured by the empirical risk, R∆ S (h) = 1 n nX i=1 ∆(yi, h(xi)).",
                "In the case of learning a ranked retrieval function, X denotes a space of queries, and Y the space of (possibly weak) rankings over some corpus of documents C = {d1, . . . ,d|C|}.",
                "We can define average precision loss as ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), where rank(y) is a vector of the rank values of each document in C. For example, for a corpus of two documents, {d1, d2}, with d1 having higher rank than d2, rank(y ) = (1, 0).",
                "We assume true rankings have two rank values, where relevant documents have rank value 1 and non-relevant documents rank value 0.",
                "We further assume that all predicted rankings are complete rankings (no ties).",
                "Let p = rank(y) and ˆp = rank(ˆy).",
                "The average precision score is defined as MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, where rel = |{i : pi = 1}| is the number of relevant documents, and Prec@j is the percentage of relevant documents in the top j documents in predicted ranking ˆy.",
                "MAP is the mean of the average precision scores of a group of queries. 2.1 MAP vs ROCArea Most learning algorithms optimize for accuracy or ROCArea.",
                "While optimizing for these measures might achieve good MAP performance, we use two simple examples to show it can also be suboptimal in terms of MAP.",
                "ROCArea assigns equal penalty to each misordering of a relevant/non-relevant pair.",
                "In contrast, MAP assigns greater penalties to misorderings higher up in the predicted ranking.",
                "Using our notation, ROCArea can be defined as ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], where p is the true (weak) ranking, ˆp is the predicted ranking, and 1[b] is the indicator function conditioned on b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Table 1: Toy Example and Models Suppose we have a hypothesis space with only two hypothesis functions, h1 and h2, as shown in Table 1.",
                "These two hypotheses predict a ranking for query x over a corpus of eight documents.",
                "Hypothesis MAP ROCArea h1(x) 0.59 0.47 h2(x) 0.51 0.53 Table 2: Performance of Toy Models Table 2 shows the MAP and ROCArea scores of h1 and h2.",
                "Here, a learning method which optimizes for ROCArea would choose h2 since that results in a higher ROCArea score, but this yields a suboptimal MAP score. 2.2 MAP vs Accuracy Using a very similar example, we now demonstrate how optimizing for accuracy might result in suboptimal MAP.",
                "Models which optimize for accuracy are not directly concerned with the ranking.",
                "Instead, they learn a threshold such that documents scoring higher than the threshold can be classified as relevant and documents scoring lower as nonrelevant.",
                "Doc ID 1 2 3 4 5 6 7 8 9 10 11 p 1 0 0 0 0 1 1 1 1 0 0 rank(h1(x)) 11 10 9 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 9 10 11 Table 3: Toy Example and Models We consider again a hypothesis space with two hypotheses.",
                "Table 3 shows the predictions of the two hypotheses on a single query x. Hypothesis MAP Best Acc. h1(q) 0.70 0.64 h2(q) 0.64 0.73 Table 4: Performance of Toy Models Table 4 shows the MAP and best accuracy scores of h1(q) and h2(q).",
                "The best accuracy refers to the highest achievable accuracy on that ranking when considering all possible thresholds.",
                "For instance, with h1(q), a threshold between documents 1 and 2 gives 4 errors (documents 6-9 incorrectly classified as non-relevant), yielding an accuracy of 0.64.",
                "Similarly, with h2(q), a threshold between documents 5 and 6 gives 3 errors (documents 10-11 incorrectly classified as relevant, and document 1 as non-relevant), yielding an accuracy of 0.73.",
                "A learning method which optimizes for accuracy would choose h2 since that results in a higher accuracy score, but this yields a suboptimal MAP score. 3.",
                "OPTIMIZING AVERAGE PRECISION We build upon the approach used by [13] for optimizing ROCArea.",
                "Unlike ROCArea, however, MAP does not decompose linearly in the examples and requires a substantially extended algorithm, which we describe in this section.",
                "Recall that the true ranking is a weak ranking with two rank values (relevant and non-relevant).",
                "Let Cx and C¯x denote the set of relevant and non-relevant documents of C for query x, respectively.",
                "We focus on functions which are parametrized by a weight vector w, and thus wish to find w to minimize the empirical risk, R∆ S (w) ≡ R∆ S (h(·; w)).",
                "Our approach is to learn a discriminant function F : X × Y → over input-output pairs.",
                "Given query x, we can derive a prediction by finding the ranking y that maximizes the discriminant function: h(x; w) = argmax y∈Y F(x, y; w). (1) We assume F to be linear in some combined feature representation of inputs and outputs Ψ(x, y) ∈ RN , i.e., F(x, y; w) = wT Ψ(x, y). (2) The combined feature function we use is Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))] , where φ : X × C → N is a feature mapping function from a query/document pair to a point in N dimensional space2 .",
                "We represent rankings as a matrix of pairwise orderings, Y ⊂ {−1, 0, +1}|C|×|C| .",
                "For any y ∈ Y, yij = +1 if di is ranked ahead of dj, and yij = −1 if dj is ranked ahead of di, and yij = 0 if di and dj have equal rank.",
                "We consider only matrices which correspond to valid rankings (i.e, obeying antisymmetry and transitivity).",
                "Intuitively, Ψ is a summation over the vector differences of all relevant/non-relevant document pairings.",
                "Since we assume predicted rankings to be complete rankings, yij is either +1 or −1 (never 0).",
                "Given a learned weight vector w, predicting a ranking (i.e. solving equation (1)) given query x reduces to picking each yij to maximize wT Ψ(x, y).",
                "As is also discussed in [13], this is attained by sorting the documents by wT φ(x, d) in descending order.",
                "We will discuss later the choices of φ we used for our experiments. 3.1 Structural SVMs The above formulation is very similar to learning a straightforward linear model while training on the pairwise difference of relevant/non-relevant document pairings.",
                "Many SVM-based approaches optimize over these pairwise differences (e.g., [5, 10, 13, 4]), although these methods do not optimize for MAP during training.",
                "Previously, it was not clear how to incorporate non-linear multivariate loss functions such as MAP loss directly into global optimization problems such as SVM training.",
                "We now present a method based on structural SVMs [19] to address this problem.",
                "We use the structural SVM formulation, presented in Optimization Problem 1, to learn a w ∈ RN .",
                "Optimization Problem 1. (Structural SVM) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) The objective function to be minimized (3) is a tradeoff between model complexity, w 2 , and a hinge loss relaxation of MAP loss, P ξi.",
                "As is usual in SVM training, C is a 2 For example, one dimension might be the number of times the query words appear in the document.",
                "Algorithm 1 Cutting plane algorithm for solving OP 1 within tolerance . 1: Input: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ for all i = 1, . . . , n 3: repeat 4: for i = 1, . . . , n do 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: compute ˆy = argmaxy∈Y H(y; w) 7: compute ξi = max{0, maxy∈Wi H(y; w)} 8: if H(ˆy; w) > ξi + then 9: Wi ← Wi ∪ {ˆy} 10: w ← optimize (3) over W = S i Wi 11: end if 12: end for 13: until no Wi has changed during iteration parameter that controls this tradeoff and can be tuned to achieve good performance in different training tasks.",
                "For each (xi, yi) in the training set, a set of constraints of the form in equation (4) is added to the optimization problem.",
                "Note that wT Ψ(x, y) is exactly our discriminant function F(x, y; w) (see equation (2)).",
                "During prediction, our model chooses the ranking which maximizes the discriminant (1).",
                "If the discriminant value for an incorrect ranking y is greater than for the true ranking yi (e.g., F(xi, y; w) > F(xi, yi; w)), then corresponding slack variable, ξi, must be at least ∆(yi, y) for that constraint to be satisfied.",
                "Therefore, the sum of slacks, P ξi, upper bounds the MAP loss.",
                "This is stated formally in Proposition 1.",
                "Proposition 1.",
                "Let ξ∗ (w) be the optimal solution of the slack variables for OP 1 for a given weight vector w. Then 1 n Pn i=1 ξi is an upper bound on the empirical risk R∆ S (w). (see [19] for proof) Proposition 1 shows that OP 1 learns a ranking function that optimizes an upper bound on MAP error on the training set.",
                "Unfortunately there is a problem: a constraint is required for every possible wrong output y, and the number of possible wrong outputs is exponential in the size of C. Fortunately, we may employ Algorithm 1 to solve OP 1.",
                "Algorithm 1 is a cutting plane algorithm, iteratively introducing constraints until we have solved the original problem within a desired tolerance [19].",
                "The algorithm starts with no constraints, and iteratively finds for each example (xi, yi) the output ˆy associated with the most violated constraint.",
                "If the corresponding constraint is violated by more than we introduce ˆy into the working set Wi of active constraints for example i, and re-solve (3) using the updated W. It can be shown that Algorithm 1s outer loop is guaranteed to halt within a polynomial number of iterations for any desired precision .",
                "Theorem 1.",
                "Let ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y) , ¯∆ = maxi maxy ∆(yi, y), and for any > 0, Algorithm 1 terminates after adding at most max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff constraints to the working set W. (see [19] for proof) However, within the inner loop of this algorithm we have to compute argmaxy∈Y H(y; w), where H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), or equivalently, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), since wT Ψ(xi, yi) is constant with respect to y.",
                "Though closely related to the classification procedure, this has the substantial complication that we must contend with the additional ∆(yi, y) term.",
                "Without the ability to efficiently find the most violated constraint (i.e., solve argmaxy∈Y H(y, w)), the constraint generation procedure is not tractable. 3.2 Finding the Most Violated Constraint Using OP 1 and optimizing to ROCArea loss (∆roc), the problem of finding the most violated constraint, or solving argmaxy∈Y H(y, w) (henceforth argmax H), is addressed in [13].",
                "Solving argmax H for ∆map is more difficult.",
                "This is primarily because ROCArea decomposes nicely into a sum of scores computed independently on each relative ordering of a relevant/non-relevant document pair.",
                "MAP, on the other hand, does not decompose in the same way as ROCArea.",
                "The main algorithmic contribution of this paper is an efficient method for solving argmax H for ∆map.",
                "One useful property of ∆map is that it is invariant to swapping two documents with equal relevance.",
                "For example, if documents da and db are both relevant, then swapping the positions of da and db in any ranking does not affect ∆map.",
                "By extension, ∆map is invariant to any arbitrary permutation of the relevant documents amongst themselves and of the non-relevant documents amongst themselves.",
                "However, this reshuﬄing will affect the discriminant score, wT Ψ(x, y).",
                "This leads us to Observation 1.",
                "Observation 1.",
                "Consider rankings which are constrained by fixing the relevance at each position in the ranking (e.g., the 3rd document in the ranking must be relevant).",
                "Every ranking which satisfies the same set of constraints will have the same ∆map.",
                "If the relevant documents are sorted by wT φ(x, d) in descending order, and the non-relevant documents are likewise sorted by wT φ(x, d), then the interleaving of the two sorted lists which satisfies the constraints will maximize H for that constrained set of rankings.",
                "Observation 1 implies that in the ranking which maximizes H, the relevant documents will be sorted by wT φ(x, d), and the non-relevant documents will also be sorted likewise.",
                "By first sorting the relevant and non-relevant documents, the problem is simplified to finding the optimal interleaving of two sorted lists.",
                "For the rest of our discussion, we assume that the relevant documents and non-relevant documents are both sorted by descending wT φ(x, d).",
                "For convenience, we also refer to relevant documents as {dx 1 , . . . dx |Cx|} = Cx , and non-relevant documents as {d¯x 1 , . . . d¯x |C¯x|} = C¯x .",
                "We define δj(i1, i2), with i1 < i2, as the change in H from when the highest ranked relevant document ranked after d¯x j is dx i1 to when it is dx i2 .",
                "For i2 = i1 + 1, we have δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5) where si = wT φ(x, di).",
                "The first term in (5) is the change in ∆map when the ith relevant document has j non-relevant documents ranked before it, as opposed to j −1.",
                "The second term is the change in the discriminant score, wT Ψ(x, y), when yij changes from +1 to −1. . . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . .",
                "Figure 1: Example for δj(i, i + 1) Figure 1 gives a conceptual example for δj(i, i + 1).",
                "The bottom ranking differs from the top only where d¯x j slides up one rank.",
                "The difference in the value of H for these two rankings is exactly δj(i, i + 1).",
                "For any i1 < i2, we can then define δj(i1, i2) as δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) or equivalently, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) .",
                "Let o1, . . . , o|C¯x| encode the positions of the non-relevant documents, where dx oj is the highest ranked relevant document ranked after the jth non-relevant document.",
                "Due to Observation 1, this encoding uniquely identifies a complete ranking.",
                "We can recover the ranking as yij = 8 >>>< >>>: 0 if i = j sign(si − sj) if di, dj equal relevance sign(oj − i − 0.5) if di = dx i , dj = d¯x j sign(j − oi + 0.5) if di = d¯x i , dj = dx j . (7) We can now reformulate H into a new objective function, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), where ¯y is the true (weak) ranking.",
                "Conceptually H starts with a perfect ranking ¯y, and adds the change in H when each successive non-relevant document slides up the ranking.",
                "We can then reformulate the argmax H problem as argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) s.t. o1 ≤ . . . ≤ o|C¯x|. (9) Algorithm 2 describes the algorithm used to solve equation (8).",
                "Conceptually, Algorithm 2 starts with a perfect ranking.",
                "Then for each successive non-relevant document, the algorithm modifies the solution by sliding that document up the ranking to locally maximize H while keeping the positions of the other non-relevant documents constant. 3.2.1 Proof of Correctness Algorithm 2 is greedy in the sense that it finds the best position of each non-relevant document independently from the other non-relevant documents.",
                "In other words, the algorithm maximizes H for each non-relevant document, d¯x j , Algorithm 2 Finding the Most Violated Constraint (argmax H) for Algorithm 1 with ∆map 1: Input: w, Cx , C¯x 2: sort Cx and C¯x in descending order of wT φ(x, d) 3: sx i ← wT φ(x, dx i ), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i ), i = 1, . . . , |C¯x | 5: for j = 1, . . . , |C¯x | do 6: optj ← argmaxk δj(k, |Cx | + 1) 7: end for 8: encode ˆy according to (7) 9: return ˆy without considering the positions of the other non-relevant documents, and thus ignores the constraints of (9).",
                "In order for the solution to be feasible, the jth non-relevant document must be ranked after the first j − 1 non-relevant documents, thus satisfying opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. (10) If the solution is feasible, the it clearly solves (8).",
                "Therefore, it suffices to prove that Algorithm 2 satisfies (10).",
                "We first prove that δj(·, ·) is monotonically decreasing in j. Lemma 1.",
                "For any 1 ≤ i1 < i2 ≤ |Cx | + 1 and 1 ≤ j < |C¯x |, it must be the case that δj+1(i1, i2) ≤ δj(i1, i2).",
                "Proof.",
                "Recall from (6) that both δj(i1, i2) and δj+1(i1, i2) are summations of i2 − i1 terms.",
                "We will show that each term in the summation of δj+1(i1, i2) is no greater than the corresponding term in δj(i1, i2), or δj+1(k, k + 1) ≤ δj(k, k + 1) for k = i1, . . . , i2 − 1.",
                "Each term in δj(k, k +1) and δj+1(k, k +1) can be further decomposed into two parts (see (5)).",
                "We will show that each part of δj+1(k, k + 1) is no greater than the corresponding part in δj(k, k + 1).",
                "In other words, we will show that both j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) and −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) are true for the aforementioned values of j and k. It is easy to see that (11) is true by observing that for any two positive integers 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1 , and choosing a = j and b = j + k. The second inequality (12) holds because Algorithm 2 first sorts d¯x in descending order of s¯x , implying s¯x j+1 ≤ s¯x j .",
                "Thus we see that each term in δj+1 is no greater than the corresponding term in δj, which completes the proof.",
                "The result of Lemma 1 leads directly to our main correctness result: Theorem 2.",
                "In Algorithm 2, the computed values of optj satisfy (10), implying that the solution returned by Algorithm 2 is feasible and thus optimal.",
                "Proof.",
                "We will prove that optj ≤ optj+1 holds for any 1 ≤ j < |C¯x |, thus implying (10).",
                "Since Algorithm 2 computes optj as optj = argmax k δj(k, |Cx | + 1), (13) then by definition of δj (6), for any 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0.",
                "Using Lemma 1, we know that δj+1(i, optj) ≤ δj(i, optj) < 0, which implies that for any 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0.",
                "Suppose for contradiction that optj+1 < optj.",
                "Then δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), which contradicts (13).",
                "Therefore, it must be the case that optj ≤ optj+1, which completes the proof. 3.2.2 Running Time The running time of Algorithm 2 can be split into two parts.",
                "The first part is the sort by wT φ(x, d), which requires O(n log n) time, where n = |Cx | + |C¯x |.",
                "The second part computes each optj, which requires O(|Cx | · |C¯x |) time.",
                "Though in the worst case this is O(n2 ), the number of relevant documents, |Cx |, is often very small (e.g., constant with respect to n), in which case the running time for the second part is simply O(n).",
                "For most real-world datasets, Algorithm 2 is dominated by the sort and has complexity O(n log n).",
                "Algorithm 1 is guaranteed to halt in a polynomial number of iterations [19], and each iteration runs Algorithm 2.",
                "Virtually all well-performing models were trained in a reasonable amount of time (usually less than one hour).",
                "Once training is complete, making predictions on query x using the resulting hypothesis h(x|w) requires only sorting by wT φ(x, d).",
                "We developed our software using a Python interface3 to SVMstruct , since the Python language greatly simplified the coding process.",
                "To improve performance, it is advisable to use the standard C implementation4 of SVMstruct . 4.",
                "EXPERIMENT SETUP The main goal of our experiments is to evaluate whether directly optimizing MAP leads to improved MAP performance compared to conventional SVM methods that optimize a substitute loss such as accuracy or ROCArea.",
                "We empirically evaluate our method using two sets of TREC Web Track queries, one each from TREC 9 and TREC 10 (topics 451-500 and 501-550), both of which used the WT10g corpus.",
                "For each query, TREC provides the relevance judgments of the documents.",
                "We generated our features using the scores of existing retrieval functions on these queries.",
                "While our method is agnostic to the meaning of the features, we chose to use existing retrieval functions as a simple yet effective way of acquiring useful features.",
                "As such, our 3 http://www.cs.cornell.edu/~tomf/svmpython/ 4 http://svmlight.joachims.org/svm_struct.html Dataset Base Funcs Features TREC 9 Indri 15 750 TREC 10 Indri 15 750 TREC 9 Submissions 53 2650 TREC 10 Submissions 18 900 Table 5: Dataset Statistics experiments essentially test our methods ability to re-rank the highly ranked documents (e.g., re-combine the scores of the retrieval functions) to improve MAP.",
                "We compare our method against the best retrieval functions trained on (henceforth base functions), as well as against previously proposed SVM methods.",
                "Comparing with the best base functions tests our methods ability to learn a useful combination.",
                "Comparing with previous SVM methods allows us to test whether optimizing directly for MAP (as opposed to accuracy or ROCArea) achieves a higher MAP score in practice.",
                "The rest of this section describes the base functions and the feature generation method in detail. 4.1 Choosing Retrieval Functions We chose two sets of base functions for our experiments.",
                "For the first set, we generated three indices over the WT10g corpus using Indri5 .",
                "The first index was generated using default settings, the second used Porter-stemming, and the last used Porter-stemming and Indris default stopwords.",
                "For both TREC 9 and TREC 10, we used the description portion of each query and scored the documents using five of Indris built-in retrieval methods, which are Cosine Similarity, TFIDF, Okapi, Language Model with Dirichlet Prior, and Language Model with Jelinek-Mercer Prior.",
                "All parameters were kept as their defaults.",
                "We computed the scores of these five retrieval methods over the three indices, giving 15 base functions in total.",
                "For each query, we considered the scores of documents found in the union of the top 1000 documents of each base function.",
                "For our second set of base functions, we used scores from the TREC 9 [8] and TREC 10 [9] Web Track submissions.",
                "We used only the non-manual, non-short submissions from both years.",
                "For TREC 9 and TREC 10, there were 53 and 18 such submissions, respectively.",
                "A typical submission contained scores of its top 1000 documents. b ca wT φ(x,d) f(d|x) Figure 2: Example Feature Binning 4.2 Generating Features In order to generate input examples for our method, a concrete instantiation of φ must be provided.",
                "For each doc5 http://www.lemurproject.org TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236Best Func. 0.204 39/11 ** 0.181 37/13 ** 2nd Best 0.199 38/12 ** 0.174 43/7 ** 3rd Best 0.188 34/16 ** 0.174 38/12 ** Table 6: Comparison with Indri Functions ument d scored by a set of retrieval functions F on query x, we generate the features as a vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf , where f(d|x) denotes the score that retrieval function f assigns to document d for query x, and each Kf is a set of real values.",
                "From a high level, we are expressing the score of each retrieval function using |Kf | + 1 bins.",
                "Since we are using linear kernels, one can think of the learning problem as finding a good piecewise-constant combination of the scores of the retrieval functions.",
                "Figure 2 shows an example of our feature mapping method.",
                "In this example we have a single feature F = {f}.",
                "Here, Kf = {a, b, c}, and the weight vector is w = wa, wb, wc .",
                "For any document d and query x, we have wT φ(x, d) = 8 >>< >>: 0 if f(d|x) < a wa if a ≤ f(d|x) < b wa + wb if b ≤ f(d|x) < c wa + wb + wc if c ≤ f(d|x) .",
                "This is expressed qualitatively in Figure 2, where wa and wb are positive, and wc is negative.",
                "We ran our main experiments using four choices of F: the set of aforementioned Indri retrieval functions for TREC 9 and TREC 10, and the Web Track submissions for TREC 9 and TREC 10.",
                "For each F and each function f ∈ F, we chose 50 values for Kf which are reasonably spaced and capture the sensitive region of f. Using the four choices of F, we generated four datasets for our main experiments.",
                "Table 5 contains statistics of the generated datasets.",
                "There are many ways to generate features, and we are not advocating our method over others.",
                "This was simply an efficient means to normalize the outputs of different functions and allow for a more expressive model. 5.",
                "EXPERIMENTS For each dataset in Table 5, we performed 50 trials.",
                "For each trial, we train on 10 randomly selected queries, and select another 5 queries at random for a validation set.",
                "Models were trained using a wide range of C values.",
                "The model which performed best on the validation set was selected and tested on the remaining 35 queries.",
                "All queries were selected to be in the training, validation and test sets the same number of times.",
                "Using this setup, we performed the same experiments while using our method (SVM∆ map), an SVM optimizing for ROCArea (SVM∆ roc) [13], and a conventional classification SVM (SVMacc) [20].",
                "All SVM methods used a linear kernel.",
                "We reported the average performance of all models over the 50 trials. 5.1 Comparison with Base Functions In analyzing our results, the first question to answer is, can SVM∆ map learn a model which outperforms the best base TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287Best Func. 0.280 28/22 0.283 29/21 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 36/14 ** Table 7: Comparison with TREC Submissions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288Best Func. 0.280 27/23 0.283 31/19 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 35/15 ** Table 8: Comparison with TREC Subm. (w/o best) functions?",
                "Table 6 presents the comparison of SVM∆ map with the best Indri base functions.",
                "Each column group contains the macro-averaged MAP performance of SVM∆ map or a base function.",
                "The W/L columns show the number of queries where SVM∆ map achieved a higher MAP score.",
                "Significance tests were performed using the two-tailed Wilcoxon signed rank test.",
                "Two stars indicate a significance level of 0.95.",
                "All tables displaying our experimental results are structured identically.",
                "Here, we find that SVM∆ map significantly outperforms the best base functions.",
                "Table 7 shows the comparison when trained on TREC submissions.",
                "While achieving a higher MAP score than the best base functions, the performance difference between SVM∆ map the base functions is not significant.",
                "Given that many of these submissions use scoring functions which are carefully crafted to achieve high MAP, it is possible that the best performing submissions use techniques which subsume the techniques of the other submissions.",
                "As a result, SVM∆ map would not be able to learn a hypothesis which can significantly out-perform the best submission.",
                "Hence, we ran the same experiments using a modified dataset where the features computed using the best submission were removed.",
                "Table 8 shows the results (note that we are still comparing against the best submission though we are not using it for training).",
                "Notice that while the performance of SVM∆ map degraded slightly, the performance was still comparable with that of the best submission. 5.2 Comparison w/ Previous SVM Methods The next question to answer is, does SVM∆ map produce higher MAP scores than previous SVM methods?",
                "Tables 9 and 10 present the results of SVM∆ map, SVM∆ roc, and SVMacc when trained on the Indri retrieval functions and TREC submissions, respectively.",
                "Table 11 contains the corresponding results when trained on the TREC submissions without the best submission.",
                "To start with, our results indicate that SVMacc was not competitive with SVM∆ map and SVM∆ roc, and at times underperformed dramatically.",
                "As such, we tried several approaches to improve the performance of SVMacc. 5.2.1 Alternate SVMacc Methods One issue which may cause SVMacc to underperform is the severe imbalance between relevant and non-relevant docTREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236SVM∆ roc 0.237 29/21 0.234 24/26 SVMacc 0.147 47/3 ** 0.155 47/3 ** SVMacc2 0.219 39/11 ** 0.207 43/7 ** SVMacc3 0.113 49/1 ** 0.153 45/5 ** SVMacc4 0.155 48/2 ** 0.155 48/2 ** Table 9: Trained on Indri Functions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287SVM∆ roc 0.282 29/21 0.278 35/15 ** SVMacc 0.213 49/1 ** 0.222 49/1 ** SVMacc2 0.270 34/16 ** 0.261 42/8 ** SVMacc3 0.133 50/0 ** 0.182 46/4 ** SVMacc4 0.233 47/3 ** 0.238 46/4 ** Table 10: Trained on TREC Submissions uments.",
                "The vast majority of the documents are not relevant.",
                "SVMacc2 addresses this problem by assigning more penalty to false negative errors.",
                "For each dataset, the ratio of the false negative to false positive penalties is equal to the ratio of the number non-relevant and relevant documents in that dataset.",
                "Tables 9, 10 and 11 indicate that SVMacc2 still performs significantly worse than SVM∆ map.",
                "Another possible issue is that SVMacc attempts to find just one discriminating threshold b that is query-invariant.",
                "It may be that different queries require different values of b.",
                "Having the learning method trying to find a good b value (when one does not exist) may be detrimental.",
                "We took two approaches to address this issue.",
                "The first method, SVMacc3, converts the retrieval function scores into percentiles.",
                "For example, for document d, query q and retrieval function f, if the score f(d|q) is in the top 90% of the scores f(·|q) for query q, then the converted score is f (d|q) = 0.9.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Tables 9, 10 and 11 show that the performance of SVMacc3 was also not competitive with SVM∆ map.",
                "The second method, SVMacc4, normalizes the scores given by f for each query.",
                "For example, assume for query q that f outputs scores in the range 0.2 to 0.7.",
                "Then for document d, if f(d|q) = 0.6, the converted score would be f (d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Again, Tables 9, 10 and 11 show that SVMacc4 was not competitive with SVM∆ map 5.2.2 MAP vs ROCArea SVM∆ roc performed much better than SVMacc in our experiments.",
                "When trained on Indri retrieval functions (see Table 9), the performance of SVM∆ roc was slight, though not significantly, worse than the performances of SVM∆ map.",
                "However, Table 10 shows that SVM∆ map did significantly outperform SVM∆ roc when trained on the TREC submissions.",
                "Table 11 shows the performance of the models when trained on the TREC submissions with the best submission removed.",
                "The performance of most models degraded by a small amount, with SVM∆ map still having the best performance.",
                "TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Table 11: Trained on TREC Subm. (w/o Best) 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented an SVM method that directly optimizes MAP.",
                "It provides a principled approach and avoids difficult to control heuristics.",
                "We formulated the optimization problem and presented an algorithm which provably finds the solution in polynomial time.",
                "We have shown empirically that our method is generally superior to or competitive with conventional SVMs methods.",
                "Our new method makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for Accuracy and ROCArea.",
                "The computational cost for training is very reasonable in practice.",
                "Since other methods typically require tuning multiple heuristics, we also expect to train fewer models before finding one which achieves good performance.",
                "The learning framework used by our method is fairly general.",
                "A natural extension of this framework would be to develop methods to optimize for other important IR measures, such as Normalized Discounted Cumulative Gain [2, 3, 4, 12] and Mean Reciprocal Rank. 7.",
                "ACKNOWLEDGMENTS This work was funded under NSF Award IIS-0412894, NSF CAREER Award 0237381, and a gift from Yahoo!",
                "Research.",
                "The third author was also partly supported by a Microsoft Research Fellowship. 8.",
                "REFERENCES [1] B. T. Bartell, G. W. Cottrell, and R. K. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2005. [3] C. J. C. Burges, R. Ragno, and Q.",
                "Le.",
                "Learning to rank with non-smooth cost functions.",
                "In Proceedings of the International Conference on Advances in Neural Information Processing Systems (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y.",
                "Liu, H. Li, Y. Huang, and H.-W. Hon.",
                "Adapting ranking SVM to document retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [5] B. Carterette and D. Petkova.",
                "Learning a ranking from pairwise preferences.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew, and A. Ksikes.",
                "Ensemble selection from libraries of models.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [7] J. Davis and M. Goadrich.",
                "The relationship between precision-recall and ROC curves.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2006. [8] D. Hawking.",
                "Overview of the TREC-9 web track.",
                "In Proceedings of TREC-2000, 2000. [9] D. Hawking and N. Craswell.",
                "Overview of the TREC-2001 web track.",
                "In Proceedings of TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel, and K. Obermayer.",
                "Large margin rank boundaries for ordinal regression.",
                "Advances in large margin classifiers, 2000. [11] A. Herschtal and B. Raskutti.",
                "Optimising area under the ROC curve using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [12] K. Jarvelin and J. Kekalainen.",
                "Ir evaluation methods for retrieving highly relevant documents.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2000. [13] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proceedings of the International Conference on Machine Learning (ICML), pages 377-384, New York, NY, USA, 2005.",
                "ACM Press. [14] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 111-119, 2001. [15] Y. Lin, Y. Lee, and G. Wahba.",
                "Support vector machines for classification in nonstandard situations.",
                "Machine Learning, 46:191-202, 2002. [16] D. Metzler and W. B. Croft.",
                "A markov random field model for term dependencies.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 472-479, 2005. [17] K. Morik, P. Brockhausen, and T. Joachims.",
                "Combining statistical learning with a knowledge-based approach.",
                "In Proceedings of the International Conference on Machine Learning, 1999. [18] S. Robertson.",
                "The probability ranking principle in ir. journal of documentation.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.",
                "Large margin methods for structured and interdependent output variables.",
                "Journal of Machine Learning Research (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik.",
                "Statistical Learning Theory.",
                "Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz.",
                "Optimizing classifier performance via approximation to the Wilcoxon-Mann-Witney statistic.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2003."
            ],
            "original_annotated_samples": [
                "Due to computational difficulties, few learning techniques have been developed to directly optimize for <br>mean average precision</br> (MAP), despite its widespread use in evaluating such systems.",
                "However, most current approaches do not optimize for the evaluation measure most often used, namely <br>mean average precision</br> (MAP)."
            ],
            "translated_annotated_samples": [
                "Debido a dificultades computacionales, se han desarrollado pocas técnicas de aprendizaje para optimizar directamente la <br>precisión media promedio</br> (MAP), a pesar de su uso generalizado en la evaluación de dichos sistemas.",
                "Sin embargo, la mayoría de los enfoques actuales no están optimizados para la medida de evaluación más utilizada, es decir, la <br>Precisión Promedio Media</br> (MAP)."
            ],
            "translated_text": "Un método de Vectores de Soporte para optimizar la Precisión Promedio Yisong Yue Universidad de Cornell Ithaca, NY, EE. UU. yyue@cs.cornell.edu Thomas Finley Universidad de Cornell Ithaca, NY, EE. UU. tomf@cs.cornell.edu Filip Radlinski Universidad de Cornell Ithaca, NY, EE. UU. filip@cs.cornell.edu Thorsten Joachims Universidad de Cornell Ithaca, NY, EE. UU. tj@cs.cornell.edu RESUMEN El aprendizaje automático se utiliza comúnmente para mejorar los sistemas de recuperación clasificados. Debido a dificultades computacionales, se han desarrollado pocas técnicas de aprendizaje para optimizar directamente la <br>precisión media promedio</br> (MAP), a pesar de su uso generalizado en la evaluación de dichos sistemas. Los enfoques existentes que optimizan el MAP no encuentran una solución óptima global o son computacionalmente costosos. Por el contrario, presentamos un algoritmo de aprendizaje SVM general que encuentra de manera eficiente una solución óptima global para una relajación directa de MAP. Evaluamos nuestro enfoque utilizando los corpus de la pista web TREC 9 y TREC 10 (WT10g), comparando con SVM optimizados para precisión y área bajo la curva ROC. En la mayoría de los casos mostramos nuestro método para producir mejoras estadísticamente significativas en las puntuaciones de MAP. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de Recuperación Términos Generales Algoritmo, Teoría, Experimentación 1. INTRODUCCIÓN Los sistemas de recuperación de información de última generación comúnmente utilizan técnicas de aprendizaje automático para aprender funciones de clasificación. Sin embargo, la mayoría de los enfoques actuales no están optimizados para la medida de evaluación más utilizada, es decir, la <br>Precisión Promedio Media</br> (MAP). En cambio, los algoritmos actuales tienden a seguir uno de dos enfoques generales. El primer enfoque es aprender un modelo que estime la probabilidad de que un documento sea relevante dado una consulta (por ejemplo, [18, 14]). Si se resuelve de manera efectiva, la clasificación con el mejor rendimiento de MAP puede derivarse fácilmente de las probabilidades de relevancia. Sin embargo, lograr un MAP alto solo requiere encontrar un buen ordenamiento de los documentos. Como resultado, encontrar buenas probabilidades requiere resolver un problema más difícil de lo necesario, probablemente necesitando más datos de entrenamiento para lograr el mismo rendimiento de MAP. El segundo enfoque común es aprender una función que maximice una medida sustituta. Las medidas de rendimiento optimizadas incluyen precisión [17, 15], área bajo la curva ROC [1, 5, 10, 11, 13, 21] o modificaciones del área bajo la curva ROC [4], y NDCG [2, 3]. Aprender un modelo para optimizar tales medidas podría resultar en un rendimiento de MAP subóptimo. De hecho, aunque algunos sistemas anteriores han obtenido un buen rendimiento de MAP, se sabe que ni lograr una precisión óptima ni un área bajo la curva ROC pueden garantizar un rendimiento de MAP óptimo[7]. En este artículo, presentamos un enfoque general para aprender funciones de clasificación que maximizan el rendimiento de MAP. Específicamente, presentamos un algoritmo SVM que optimiza globalmente una relajación de pérdida de bisagra de MAP. Este enfoque simplifica el proceso de obtener funciones de clasificación con un alto rendimiento de MAP al evitar pasos intermedios adicionales y heurísticas. El nuevo algoritmo también hace que sea conceptualmente tan fácil optimizar las SVM para MAP como anteriormente solo era posible para precisión y ROCArea. A diferencia del trabajo reciente que optimiza directamente el rendimiento de MAP realizado por Metzler & Croft [16] y Caruana et al. [6], nuestra técnica es eficiente computacionalmente al encontrar una solución óptima a nivel global. Al igual que [6, 16], nuestro método aprende un modelo lineal, pero es mucho más eficiente en la práctica y, a diferencia de [16], puede manejar miles de características. Ahora describimos el algoritmo en detalle y proporcionamos la prueba de corrección. A continuación, proporcionamos un análisis del tiempo de ejecución. Concluimos con los resultados empíricos de experimentos en el corpus de la pista web TREC 9 y TREC 10. También hemos desarrollado un paquete de software que implementa nuestro algoritmo y está disponible para uso público. EL PROBLEMA DEL APRENDIZAJE Siguiendo la configuración estándar del aprendizaje automático, nuestro objetivo es aprender una función h: X → Y entre un espacio de entrada X (todas las consultas posibles) y un espacio de salida Y (clasificaciones sobre un corpus). Para cuantificar la calidad de una predicción, ˆy = h(x), consideraremos una función de pérdida ∆ : Y × Y → . ∆(y, ˆy) cuantifica la penalización por hacer la predicción ˆy si la salida correcta es y. La función de pérdida nos permite incorporar medidas específicas de rendimiento, las cuales explotaremos en http://svmrank.yisongyue.com para optimizar el MAP. Nos restringimos al escenario de aprendizaje supervisado, donde pares de entrada/salida (x, y) están disponibles para el entrenamiento y se asume que provienen de alguna distribución fija P(x, y). El objetivo es encontrar una función h tal que el riesgo (es decir, la pérdida esperada), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), se minimice. Por supuesto, P(x, y) es desconocido. Pero dado un conjunto finito de pares de entrenamiento, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, el rendimiento de h en S puede medirse mediante el riesgo empírico, R∆ S (h) = 1 n ∑ i=1 n ∆(yi, h(xi)). En el caso de aprender una función de recuperación clasificada, X denota un espacio de consultas, y Y el espacio de clasificaciones (posiblemente débiles) sobre algún corpus de documentos C = {d1, . . . ,d|C|}. Podemos definir la pérdida de precisión promedio como ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), donde rank(y) es un vector de los valores de rango de cada documento en C. Por ejemplo, para un corpus de dos documentos, {d1, d2}, con d1 teniendo un rango más alto que d2, rank(y) = (1, 0). Suponemos que las clasificaciones verdaderas tienen dos valores de clasificación, donde los documentos relevantes tienen un valor de clasificación 1 y los documentos no relevantes tienen un valor de clasificación 0. Además, asumimos que todas las clasificaciones predichas son clasificaciones completas (sin empates). Sea p = rango(y) y ˆp = rango(ˆy). La puntuación de precisión promedio se define como MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, donde rel = |{i : pi = 1}| es el número de documentos relevantes, y Prec@j es el porcentaje de documentos relevantes en los primeros j documentos en la clasificación predicha ˆy. MAP es la media de las puntuaciones de precisión promedio de un grupo de consultas. La mayoría de los algoritmos de aprendizaje se optimizan para precisión o ROCArea. Si bien optimizar estas medidas podría lograr un buen rendimiento de MAP, usamos dos ejemplos simples para mostrar que también puede ser subóptimo en términos de MAP. ROCArea asigna una penalización igual a cada desordenamiento de un par relevante/no relevante. Por el contrario, MAP asigna mayores penalizaciones a los errores de ordenamiento más arriba en la clasificación predicha. Usando nuestra notación, el Área bajo la Curva ROC (ROCArea) se puede definir como ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], donde p es el ranking verdadero (débil), ˆp es el ranking predicho, y 1[b] es la función indicadora condicionada a b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Tabla 1: Ejemplo y Modelos Supongamos que tenemos un espacio de hipótesis con solo dos funciones de hipótesis, h1 y h2, como se muestra en la Tabla 1. Estas dos hipótesis predicen un ranking para la consulta x sobre un corpus de ocho documentos. Tabla 2: Rendimiento de los Modelos de Juguete La Tabla 2 muestra las puntuaciones de MAP y ROCArea de h1 y h2. Aquí, un método de aprendizaje que optimiza para el Área bajo la curva ROC elegiría h2 ya que esto resulta en un puntaje de Área bajo la curva ROC más alto, pero esto produce un puntaje de MAP subóptimo. 2.2 MAP vs Precisión Usando un ejemplo muy similar, ahora demostramos cómo optimizar para la precisión podría resultar en un puntaje de MAP subóptimo. Los modelos que se optimizan para la precisión no están directamente preocupados por la clasificación. En cambio, aprenden un umbral tal que los documentos que obtienen una puntuación superior al umbral pueden ser clasificados como relevantes y los documentos que obtienen una puntuación inferior como no relevantes. Consideramos nuevamente un espacio de hipótesis con dos hipótesis. La Tabla 3 muestra las predicciones de las dos hipótesis en una única consulta x. Hipótesis MAP Mejor Precisión h1(q) 0.70 0.64 h2(q) 0.64 0.73 Tabla 4: Rendimiento de los Modelos de Juguete La Tabla 4 muestra los puntajes de MAP y mejor precisión de h1(q) y h2(q). La mejor precisión se refiere a la precisión más alta alcanzable en esa clasificación al considerar todos los umbrales posibles. Por ejemplo, con h1(q), un umbral entre los documentos 1 y 2 da 4 errores (documentos 6-9 clasificados incorrectamente como no relevantes), lo que resulta en una precisión de 0.64. De manera similar, con h2(q), un umbral entre los documentos 5 y 6 da 3 errores (los documentos 10-11 clasificados incorrectamente como relevantes, y el documento 1 como no relevante), lo que resulta en una precisión de 0.73. Un método de aprendizaje que optimiza la precisión elegiría h2 ya que esto resulta en un puntaje de precisión más alto, pero esto produce un puntaje de MAP subóptimo. 3. OPTIMIZANDO LA PRECISIÓN PROMEDIO Nos basamos en el enfoque utilizado por [13] para optimizar el Área bajo la Curva ROC. A diferencia de ROCArea, sin embargo, MAP no se descompone linealmente en los ejemplos y requiere un algoritmo sustancialmente extendido, el cual describimos en esta sección. Recuerda que la clasificación verdadera es una clasificación débil con dos valores de clasificación (relevante y no relevante). Que Cx y C¯x denoten el conjunto de documentos relevantes y no relevantes de C para la consulta x, respectivamente. Nos enfocamos en funciones que están parametrizadas por un vector de peso w, y por lo tanto deseamos encontrar w para minimizar el riesgo empírico, R∆ S (w) ≡ R∆ S (h(·; w)). Nuestro enfoque es aprender una función discriminante F: X × Y → sobre pares de entrada-salida. Dada la consulta x, podemos derivar una predicción encontrando la clasificación y que maximiza la función discriminante: h(x; w) = argmax y∈Y F(x, y; w). (1) Suponemos que F es lineal en alguna representación de características combinadas de entradas y salidas Ψ(x, y) ∈ RN, es decir, F(x, y; w) = wT Ψ(x, y). (2) La función de características combinadas que utilizamos es Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))], donde φ: X × C → N es una función de mapeo de características de un par consulta/documento a un punto en un espacio dimensional N. Representamos las clasificaciones como una matriz de ordenamientos por pares, Y ⊂ {−1, 0, +1}|C|×|C| . Para cualquier y ∈ Y, yij = +1 si di está clasificado por delante de dj, y yij = −1 si dj está clasificado por delante de di, y yij = 0 si di y dj tienen el mismo rango. Consideramos solo matrices que corresponden a clasificaciones válidas (es decir, que cumplen con la antisimetría y la transitividad). De manera intuitiva, Ψ es una suma de las diferencias vectoriales de todos los pares de documentos relevantes/no relevantes. Dado que asumimos que las clasificaciones predichas son clasificaciones completas, yij es o bien +1 o −1 (nunca 0). Dado un vector de pesos aprendido w, predecir un ranking (es decir, resolver la ecuación (1)) dado una consulta x se reduce a elegir cada yij para maximizar wT Ψ(x, y). Como también se discute en [13], esto se logra ordenando los documentos por wT φ(x, d) en orden descendente. Discutiremos más adelante las elecciones de φ que utilizamos para nuestros experimentos. 3.1 SVM Estructurales La formulación anterior es muy similar a aprender un modelo lineal directo mientras se entrena en la diferencia de pares de documentos relevantes/no relevantes. Muchos enfoques basados en SVM optimizan sobre estas diferencias en pares (por ejemplo, [5, 10, 13, 4]), aunque estos métodos no optimizan para el MAP durante el entrenamiento. Anteriormente, no estaba claro cómo incorporar funciones de pérdida multivariadas no lineales como la pérdida MAP directamente en problemas de optimización global como el entrenamiento de SVM. Ahora presentamos un método basado en SVM estructurales [19] para abordar este problema. Utilizamos la formulación del SVM estructural, presentada en el Problema de Optimización 1, para aprender un w ∈ RN. Problema de optimización 1. (SVM estructural) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) La función objetivo a minimizar (3) es un compromiso entre la complejidad del modelo, w 2 , y una relajación de pérdida de MAP mediante la pérdida de bisagra, P ξi. Como es habitual en el entrenamiento de SVM, C es igual a 2. Por ejemplo, una dimensión podría ser el número de veces que las palabras de la consulta aparecen en el documento. Algoritmo 1 Algoritmo de plano de corte para resolver OP 1 dentro de la tolerancia. 1: Entrada: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ para todo i = 1, . . . , n 3: repetir 4: para i = 1, . . . , n hacer 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: calcular ˆy = argmaxy∈Y H(y; w) 7: calcular ξi = max{0, maxy∈Wi H(y; w)} 8: si H(ˆy; w) > ξi + entonces 9: Wi ← Wi ∪ {ˆy} 10: w ← optimizar (3) sobre W = S i Wi 11: fin si 12: fin para 13: hasta que ningún Wi haya cambiado durante la iteración parámetro que controla este equilibrio y puede ajustarse para lograr un buen rendimiento en diferentes tareas de entrenamiento. Para cada (xi, yi) en el conjunto de entrenamiento, se añade un conjunto de restricciones de la forma en la ecuación (4) al problema de optimización. Ten en cuenta que wT Ψ(x, y) es exactamente nuestra función discriminante F(x, y; w) (ver ecuación (2)). Durante la predicción, nuestro modelo elige el ranking que maximiza el discriminante (1). Si el valor del discriminante para una clasificación incorrecta y es mayor que para la clasificación verdadera yi (por ejemplo, F(xi, y; w) > F(xi, yi; w)), entonces la variable de holgura correspondiente, ξi, debe ser al menos ∆(yi, y) para que se cumpla esa restricción. Por lo tanto, la suma de los márgenes, P ξi, acota superiormente la pérdida MAP. Esto se establece formalmente en la Proposición 1. Proposición 1. Sea ξ∗ (w) la solución óptima de las variables de holgura para OP 1 para un vector de peso dado w. Entonces 1 n Pn i=1 ξi es una cota superior del riesgo empírico R∆ S (w). (ver [19] para la prueba) La Proposición 1 muestra que OP 1 aprende una función de clasificación que optimiza una cota superior del error de MAP en el conjunto de entrenamiento. Desafortunadamente hay un problema: se requiere una restricción para cada posible resultado incorrecto y, y el número de resultados incorrectos posibles es exponencial en el tamaño de C. Afortunadamente, podemos emplear el Algoritmo 1 para resolver OP 1. El algoritmo 1 es un algoritmo de plano de corte, introduciendo iterativamente restricciones hasta que hayamos resuelto el problema original dentro de una tolerancia deseada [19]. El algoritmo comienza sin restricciones y encuentra de forma iterativa, para cada ejemplo (xi, yi), la salida ˆy asociada con la restricción más violada. Si la restricción correspondiente es violada por más de lo que introducimos ˆy en el conjunto de trabajo Wi de restricciones activas, por ejemplo i, y volvemos a resolver (3) usando el W actualizado. Se puede demostrar que el bucle externo del Algoritmo 1 está garantizado a detenerse dentro de un número polinomial de iteraciones para cualquier precisión deseada. Teorema 1. Sea ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y), ¯∆ = maxi maxy ∆(yi, y), y para cualquier > 0, el Algoritmo 1 termina después de agregar a lo sumo max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff restricciones al conjunto de trabajo W. (ver [19] para la prueba) Sin embargo, dentro del bucle interno de este algoritmo tenemos que calcular argmaxy∈Y H(y; w), donde H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), o equivalentemente, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), ya que wT Ψ(xi, yi) es constante con respecto a y. Aunque está estrechamente relacionado con el procedimiento de clasificación, esto tiene la complicación sustancial de que debemos lidiar con el término adicional ∆(yi, y). Sin la capacidad de encontrar eficientemente la restricción más violada (es decir, resolver argmaxy∈Y H(y, w)), el procedimiento de generación de restricciones no es viable. 3.2 Encontrar la restricción más violada utilizando OP 1 y optimizando la pérdida de ROCArea (∆roc), el problema de encontrar la restricción más violada, o resolver argmaxy∈Y H(y, w) (en adelante argmax H), se aborda en [13]. Resolver argmax H para ∆map es más difícil. Esto se debe principalmente a que ROCArea se descompone de manera ordenada en una suma de puntuaciones calculadas de forma independiente en cada ordenamiento relativo de un par de documentos relevantes/no relevantes. MAP, por otro lado, no se descompone de la misma manera que ROCArea. La principal contribución algorítmica de este artículo es un método eficiente para resolver argmax H para ∆map. Una propiedad útil de ∆map es que es invariante al intercambiar dos documentos con igual relevancia. Por ejemplo, si los documentos da y db son ambos relevantes, entonces intercambiar las posiciones de da y db en cualquier clasificación no afecta a ∆map. Por extensión, ∆map es invariante a cualquier permutación arbitraria de los documentos relevantes entre sí y de los documentos no relevantes entre sí. Sin embargo, esta reorganización afectará la puntuación del discriminante, wT Ψ(x, y). Esto nos lleva a la Observación 1. Observación 1. Considera clasificaciones que estén limitadas por fijar la relevancia en cada posición de la clasificación (por ejemplo, el tercer documento en la clasificación debe ser relevante). Cada clasificación que cumpla con el mismo conjunto de restricciones tendrá el mismo ∆map. Si los documentos relevantes están ordenados por wT φ(x, d) en orden descendente, y los documentos no relevantes también están ordenados de la misma manera por wT φ(x, d), entonces la intercalación de las dos listas ordenadas que cumpla con las restricciones maximizará H para ese conjunto de clasificaciones restringidas. La Observación 1 implica que en la clasificación que maximiza H, los documentos relevantes se ordenarán por wT φ(x, d), y los documentos no relevantes también se ordenarán de la misma manera. Al ordenar primero los documentos relevantes y no relevantes, el problema se simplifica a encontrar la intercalación óptima de dos listas ordenadas. Para el resto de nuestra discusión, asumimos que los documentos relevantes y no relevantes están ordenados por wT φ(x, d) en orden descendente. Para mayor comodidad, también nos referimos a los documentos relevantes como {dx 1 , . . . dx |Cx|} = Cx, y a los documentos no relevantes como {d¯x 1 , . . . d¯x |C¯x|} = C¯x. Definimos δj(i1, i2), con i1 < i2, como el cambio en H desde cuando el documento relevante de mayor rango clasificado después de d¯x j es dx i1 hasta que es dx i2. Para i2 = i1 + 1, tenemos δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5), donde si = wT φ(x, di). El primer término en (5) es el cambio en ∆map cuando el documento relevante i tiene j documentos no relevantes clasificados antes de él, en lugar de j-1. El segundo término es el cambio en la puntuación del discriminante, wT Ψ(x, y), cuando yij cambia de +1 a −1. . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . . Figura 1: Ejemplo para δj(i, i + 1). La Figura 1 proporciona un ejemplo conceptual para δj(i, i + 1). La clasificación inferior difiere de la superior solo cuando d¯x j sube un rango. La diferencia en el valor de H para estas dos clasificaciones es exactamente δj(i, i + 1). Para cualquier i1 < i2, podemos definir δj(i1, i2) como δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) o equivalentemente, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) . Deja que o1, . . . , o|C¯x| codifiquen las posiciones de los documentos no relevantes, donde dx oj es el documento relevante de mayor rango clasificado después del j-ésimo documento no relevante. Debido a la Observación 1, esta codificación identifica de forma única un ranking completo. Podemos recuperar la clasificación como yij = 8 >>>< >>>: 0 si i = j sign(si − sj) si di, dj relevancia igual signo(oj − i − 0.5) si di = dx i , dj = d¯x j signo(j − oi + 0.5) si di = d¯x i , dj = dx j. (7) Ahora podemos reformular H en una nueva función objetivo, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), donde ¯y es la verdadera clasificación (débil). Conceptualmente, H comienza con una clasificación perfecta ¯y y agrega el cambio en H cuando cada documento no relevante sucesivo sube en la clasificación. Luego podemos reformular el problema argmax H como argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) sujeto a o1 ≤ . . . ≤ o|C¯x|. (9) El Algoritmo 2 describe el algoritmo utilizado para resolver la ecuación (8). Conceptualmente, el Algoritmo 2 comienza con un ranking perfecto. Entonces, para cada documento no relevante sucesivo, el algoritmo modifica la solución deslizando ese documento hacia arriba en la clasificación para maximizar localmente H, manteniendo las posiciones de los otros documentos no relevantes constantes. 3.2.1 Prueba de Corrección El Algoritmo 2 es codicioso en el sentido de que encuentra la mejor posición de cada documento no relevante de forma independiente de los otros documentos no relevantes. En otras palabras, el algoritmo maximiza H para cada documento no relevante, d¯x j, Algoritmo 2 Encontrar la Restricción Más Violada (argmax H) para el Algoritmo 1 con ∆map 1: Entrada: w, Cx, C¯x 2: ordenar Cx y C¯x en orden descendente de wT φ(x, d) 3: sx i ← wT φ(x, dx i), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i), i = 1, . . . , |C¯x | 5: para j = 1, . . . , |C¯x | hacer 6: optj ← argmaxk δj(k, |Cx| + 1) 7: fin para 8: codificar ˆy de acuerdo con (7) 9: devolver ˆy sin considerar las posiciones de los otros documentos no relevantes, y así ignora las restricciones de (9). Para que la solución sea factible, el documento no relevante j-ésimo debe ser clasificado después de los primeros j-1 documentos no relevantes, satisfaciendo así opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. Si la solución es factible, entonces claramente resuelve (8). Por lo tanto, basta con demostrar que el Algoritmo 2 cumple con (10). Primero demostramos que δj(·, ·) es monótonamente decreciente en j. Lema 1. Para cualquier 1 ≤ i1 < i2 ≤ |Cx | + 1 y 1 ≤ j < |C¯x |, debe ser el caso que δj+1(i1, i2) ≤ δj(i1, i2). Prueba. Recuerde que tanto δj(i1, i2) como δj+1(i1, i2) son sumas de términos i2 − i1. Mostraremos que cada término en la suma de δj+1(i1, i2) no es mayor que el término correspondiente en δj(i1, i2), o δj+1(k, k + 1) ≤ δj(k, k + 1) para k = i1, . . . , i2 − 1. Cada término en δj(k, k +1) y δj+1(k, k +1) puede ser descompuesto aún más en dos partes (ver (5)). Mostraremos que cada parte de δj+1(k, k + 1) no es mayor que la parte correspondiente en δj(k, k + 1). En otras palabras, demostraremos que tanto j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) como −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) son verdaderos para los valores mencionados de j y k. Es fácil ver que (11) es verdadero observando que para cualquier par de enteros positivos 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1, y eligiendo a = j y b = j + k. La segunda desigualdad (12) se cumple porque el Algoritmo 2 primero ordena d¯x en orden descendente de s¯x, lo que implica s¯x j+1 ≤ s¯x j. Así vemos que cada término en δj+1 no es mayor que el término correspondiente en δj, lo cual completa la prueba. El resultado del Lema 1 conduce directamente a nuestro resultado principal de corrección: Teorema 2. En el Algoritmo 2, los valores calculados de optj satisfacen (10), lo que implica que la solución devuelta por el Algoritmo 2 es factible y, por lo tanto, óptima. Prueba. Demostraremos que optj ≤ optj+1 se cumple para cualquier 1 ≤ j < |C¯x|, implicando así (10). Dado que el Algoritmo 2 calcula optj como optj = argmax k δj(k, |Cx | + 1), (13), entonces por definición de δj (6), para cualquier 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0. Usando el Lema 1, sabemos que δj+1(i, optj) ≤ δj(i, optj) < 0, lo que implica que para cualquier 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0. Supongamos por contradicción que optj+1 < optj. Entonces δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), lo cual contradice (13). Por lo tanto, debe ser el caso que optj ≤ optj+1, lo cual completa la prueba. 3.2.2 Tiempo de ejecución El tiempo de ejecución del Algoritmo 2 se puede dividir en dos partes. La primera parte es la clasificación por wT φ(x, d), lo cual requiere un tiempo de O(n log n), donde n = |Cx | + |C¯x |. La segunda parte calcula cada optj, lo cual requiere un tiempo de O(|Cx| · |C¯x|). Aunque en el peor de los casos esto es O(n2), el número de documentos relevantes, |Cx|, suele ser muy pequeño (por ejemplo, constante con respecto a n), en cuyo caso el tiempo de ejecución para la segunda parte es simplemente O(n). Para la mayoría de los conjuntos de datos del mundo real, el Algoritmo 2 está dominado por la ordenación y tiene una complejidad O(n log n). El Algoritmo 1 está garantizado de detenerse en un número polinómico de iteraciones [19], y cada iteración ejecuta el Algoritmo 2. Prácticamente todos los modelos que funcionaron bien fueron entrenados en un tiempo razonable (generalmente menos de una hora). Una vez que el entrenamiento esté completo, hacer predicciones sobre la consulta x usando la hipótesis resultante h(x|w) solo requiere ordenar por wT φ(x, d). Desarrollamos nuestro software utilizando una interfaz de Python a SVMstruct, ya que el lenguaje Python simplificó en gran medida el proceso de codificación. Para mejorar el rendimiento, es recomendable utilizar la implementación estándar en C de SVMstruct. CONFIGURACIÓN DEL EXPERIMENTO El objetivo principal de nuestros experimentos es evaluar si la optimización directa de MAP conduce a un rendimiento de MAP mejorado en comparación con los métodos convencionales de SVM que optimizan una pérdida sustituta como la precisión o el área bajo la curva ROC. Evaluamos empíricamente nuestro método utilizando dos conjuntos de consultas de la TREC Web Track, uno de TREC 9 y otro de TREC 10 (temas 451-500 y 501-550), ambos de los cuales utilizaron el corpus WT10g. Para cada consulta, TREC proporciona las evaluaciones de relevancia de los documentos. Generamos nuestras características utilizando las puntuaciones de las funciones de recuperación existentes en estas consultas. Si bien nuestro método es agnóstico al significado de las características, elegimos utilizar funciones de recuperación existentes como una forma simple pero efectiva de adquirir características útiles. Por lo tanto, nuestros experimentos de estadísticas de conjuntos de datos básicos esencialmente prueban la capacidad de nuestros métodos para volver a clasificar los documentos altamente clasificados (por ejemplo, volver a combinar las puntuaciones de las funciones de recuperación) para mejorar el MAP. Comparamos nuestro método con las mejores funciones de recuperación entrenadas (en adelante, funciones base), así como con los métodos SVM propuestos anteriormente. Comparar con las mejores funciones base pone a prueba la capacidad de nuestros métodos para aprender una combinación útil. Comparar con métodos SVM anteriores nos permite probar si optimizar directamente para el MAP (en lugar de precisión o área bajo la curva ROC) logra una puntuación de MAP más alta en la práctica. El resto de esta sección describe las funciones base y el método de generación de características en detalle. 4.1 Elección de Funciones de Recuperación Elegimos dos conjuntos de funciones base para nuestros experimentos. Para el primer conjunto, generamos tres índices sobre el corpus WT10g utilizando Indri5. El primer índice fue generado utilizando la configuración predeterminada, el segundo utilizó Porter-stemming, y el último utilizó Porter-stemming y las palabras vacías predeterminadas de Indris. Para TREC 9 y TREC 10, utilizamos la parte de descripción de cada consulta y puntuamos los documentos utilizando cinco de los métodos de recuperación integrados en Indri, que son Similitud Coseno, TFIDF, Okapi, Modelo de Lenguaje con Prior de Dirichlet y Modelo de Lenguaje con Prior de Jelinek-Mercer. Todos los parámetros se mantuvieron en sus valores predeterminados. Calculamos las puntuaciones de estos cinco métodos de recuperación sobre los tres índices, dando un total de 15 funciones base. Para cada consulta, consideramos las puntuaciones de los documentos encontrados en la unión de los mejores 1000 documentos de cada función base. Para nuestro segundo conjunto de funciones base, utilizamos puntuaciones de las presentaciones de la pista web TREC 9 [8] y TREC 10 [9]. Utilizamos solo las presentaciones no manuales y no breves de ambos años. Para TREC 9 y TREC 10, hubo 53 y 18 envíos de este tipo, respectivamente. Una presentación típica contenía puntajes de sus 1000 documentos principales. b ca wT φ(x,d) f(d|x) Figura 2: Ejemplo de Agrupación de Características 4.2 Generación de Características Para generar ejemplos de entrada para nuestro método, se debe proporcionar una instancia concreta de φ. Para cada documento d puntuado por un conjunto de funciones de recuperación F en la consulta x, generamos las características como un vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf, donde f(d|x) denota la puntuación que la función de recuperación f asigna al documento d para la consulta x, y cada Kf es un conjunto de valores reales. Desde un nivel alto, estamos expresando la puntuación de cada función de recuperación utilizando |Kf | + 1 contenedores. Dado que estamos utilizando núcleos lineales, se puede pensar en el problema de aprendizaje como encontrar una buena combinación de piezas constantes de los puntajes de las funciones de recuperación. La Figura 2 muestra un ejemplo de nuestro método de mapeo de características. En este ejemplo tenemos una única característica F = {f}. Aquí, Kf = {a, b, c}, y el vector de pesos es w = wa, wb, wc. Para cualquier documento d y consulta x, tenemos wT φ(x, d) = 8 >>< >>: 0 si f(d|x) < a wa si a ≤ f(d|x) < b wa + wb si b ≤ f(d|x) < c wa + wb + wc si c ≤ f(d|x) . Esto se expresa cualitativamente en la Figura 2, donde wa y wb son positivos, y wc es negativo. Realizamos nuestros experimentos principales utilizando cuatro opciones de F: el conjunto de las funciones de recuperación de Indri mencionadas anteriormente para TREC 9 y TREC 10, y las presentaciones de la pista web para TREC 9 y TREC 10. Para cada F y cada función f ∈ F, elegimos 50 valores para Kf que estuvieran razonablemente espaciados y capturaran la región sensible de f. Utilizando las cuatro opciones de F, generamos cuatro conjuntos de datos para nuestros experimentos principales. La Tabla 5 contiene estadísticas de los conjuntos de datos generados. Hay muchas formas de generar características, y no estamos abogando por nuestro método sobre los demás. Esto fue simplemente un medio eficiente para normalizar las salidas de diferentes funciones y permitir un modelo más expresivo. EXPERIMENTOS Para cada conjunto de datos en la Tabla 5, realizamos 50 pruebas. Para cada prueba, entrenamos con 10 consultas seleccionadas al azar, y seleccionamos otras 5 consultas al azar para un conjunto de validación. Los modelos fueron entrenados utilizando una amplia gama de valores de C. El modelo que tuvo mejor rendimiento en el conjunto de validación fue seleccionado y probado en las 35 consultas restantes. Todas las consultas fueron seleccionadas para estar en los conjuntos de entrenamiento, validación y prueba la misma cantidad de veces. Utilizando esta configuración, realizamos los mismos experimentos mientras usábamos nuestro método (mapa SVM∆), un SVM optimizando para ROCArea (SVM∆ roc) [13], y un SVM de clasificación convencional (SVMacc) [20]. Todos los métodos de SVM utilizaron un kernel lineal. Informamos sobre el rendimiento promedio de todos los modelos en las 50 pruebas. 5.1 Comparación con Funciones Base Al analizar nuestros resultados, la primera pregunta a responder es, ¿puede SVM∆ map aprender un modelo que supere al mejor modelo base TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.290 - 0.287Mejor Func. 0.280 28/22 0.283 29/21 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 36/14 ** Tabla 7: Comparación con Envíos TREC TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288Mejor Func. 0.280 27/23 0.283 31/19 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 35/15 ** Tabla 8: Comparación con Funciones de Envíos TREC (sin el mejor) La Tabla 6 presenta la comparación del mapa SVM∆ con las mejores funciones base de Indri. Cada grupo de columnas contiene el rendimiento del MAP macro-promediado de SVM∆ map o una función base. Las columnas W/L muestran el número de consultas donde SVM∆ map logró un puntaje MAP más alto. Se realizaron pruebas de significancia utilizando la prueba de rango con signo de Wilcoxon de dos colas. Dos estrellas indican un nivel de significancia de 0.95. Todas las tablas que muestran nuestros resultados experimentales están estructuradas de manera idéntica. Aquí encontramos que SVM∆ mapea significativamente mejor que las mejores funciones base. La Tabla 7 muestra la comparación cuando se entrena con las presentaciones de TREC. Si bien logra una puntuación de MAP más alta que las mejores funciones base, la diferencia de rendimiento entre SVM∆ y las funciones base no es significativa. Dado que muchas de estas presentaciones utilizan funciones de puntuación cuidadosamente diseñadas para lograr un alto MAP, es posible que las presentaciones con mejor rendimiento utilicen técnicas que engloben las técnicas de las otras presentaciones. Como resultado, el mapa SVM∆ no sería capaz de aprender una hipótesis que pueda superar significativamente la mejor presentación. Por lo tanto, realizamos los mismos experimentos utilizando un conjunto de datos modificado en el que se eliminaron las características calculadas utilizando la mejor presentación. La tabla 8 muestra los resultados (ten en cuenta que aún estamos comparando con la mejor presentación, aunque no la estamos utilizando para el entrenamiento). Observa que si bien el rendimiento del SVM∆ map se degradó ligeramente, aún era comparable con el de la mejor presentación. 5.2 Comparación con Métodos SVM Anteriores La siguiente pregunta a responder es, ¿produce el SVM∆ map puntajes MAP más altos que los métodos SVM anteriores? Las tablas 9 y 10 presentan los resultados de SVM∆ map, SVM∆ roc y SVMacc cuando se entrenan con las funciones de recuperación de Indri y las presentaciones de TREC, respectivamente. La Tabla 11 contiene los resultados correspondientes cuando se entrena con las presentaciones de TREC sin la mejor presentación. Para empezar, nuestros resultados indican que SVMacc no fue competitivo con SVM∆ map y SVM∆ roc, y a veces tuvo un rendimiento notablemente inferior. Por lo tanto, probamos varios enfoques para mejorar el rendimiento de SVMacc. 5.2.1 Métodos alternativos de SVMacc Un problema que puede causar que SVMacc tenga un rendimiento deficiente es el desequilibrio severo entre documentos relevantes y no relevantes. La gran mayoría de los documentos no son relevantes. SVMacc2 aborda este problema asignando una penalización mayor a los errores de falsos negativos. Para cada conjunto de datos, la proporción de las penalizaciones por falsos negativos a falsos positivos es igual a la proporción entre el número de documentos no relevantes y relevantes en ese conjunto de datos. Las tablas 9, 10 y 11 indican que SVMacc2 sigue teniendo un rendimiento significativamente peor que SVM∆ map. Otro posible problema es que SVMacc intenta encontrar solo un umbral discriminatorio b que sea invariable a la consulta. Puede ser que diferentes consultas requieran diferentes valores de b. Tener el método de aprendizaje intentando encontrar un buen valor de b (cuando no existe) puede ser perjudicial. Tomamos dos enfoques para abordar este problema. El primer método, SVMacc3, convierte las puntuaciones de la función de recuperación en percentiles. Por ejemplo, para el documento d, la consulta q y la función de recuperación f, si la puntuación f(d|q) se encuentra en el 90% superior de las puntuaciones f(·|q) para la consulta q, entonces la puntuación convertida es f(d|q) = 0.9. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Las tablas 9, 10 y 11 muestran que el rendimiento de SVMacc3 tampoco fue competitivo con SVM∆ map. El segundo método, SVMacc4, normaliza las puntuaciones dadas por f para cada consulta. Por ejemplo, suponga para la consulta q que f produce puntuaciones en el rango de 0.2 a 0.7. Entonces, para el documento d, si f(d|q) = 0.6, la puntuación convertida sería f(d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Nuevamente, las Tablas 9, 10 y 11 muestran que SVMacc4 no fue competitivo con SVM∆ map 5.2.2 MAP vs ROCArea. SVM∆ roc tuvo un rendimiento mucho mejor que SVMacc en nuestros experimentos. Cuando se entrenó con las funciones de recuperación de Indri (ver Tabla 9), el rendimiento de SVM∆ roc fue ligeramente, aunque no significativamente, peor que el rendimiento de SVM∆ map. Sin embargo, la Tabla 10 muestra que el mapa SVM∆ superó significativamente al roc SVM∆ cuando se entrenó con las presentaciones de TREC. La tabla 11 muestra el rendimiento de los modelos cuando se entrenan con las presentaciones de TREC y se elimina la mejor presentación. El rendimiento de la mayoría de los modelos se degradó ligeramente, con SVM∆ map aún teniendo el mejor rendimiento. TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288 SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Tabla 11: Entrenado en TREC Subm. (sin Mejor) 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado un método SVM que optimiza directamente el MAP. Proporciona un enfoque basado en principios y evita heurísticas difíciles de controlar. Formulamos el problema de optimización y presentamos un algoritmo que encuentra la solución de manera demostrable en tiempo polinómico. Hemos demostrado empíricamente que nuestro método es generalmente superior o competitivo con los métodos convencionales de SVM. Nuestro nuevo método hace que sea conceptualmente tan fácil optimizar SVMs para MAP como anteriormente solo era posible para Precisión y Área bajo la curva ROC. El costo computacional para el entrenamiento es muy razonable en la práctica. Dado que otros métodos suelen requerir ajustar múltiples heurísticas, también esperamos entrenar menos modelos antes de encontrar uno que logre un buen rendimiento. El marco de aprendizaje utilizado por nuestro método es bastante general. Una extensión natural de este marco sería desarrollar métodos para optimizar otras medidas importantes de IR, como la Ganancia Acumulada Normalizada Descontada [2, 3, 4, 12] y la Reciprocidad Media de Rango. 7. AGRADECIMIENTOS Este trabajo fue financiado bajo el Premio NSF IIS-0412894, el Premio NSF CAREER 0237381 y un obsequio de Yahoo! Investigación. El tercer autor también fue parcialmente apoyado por una Beca de Investigación de Microsoft. 8. REFERENCIAS [1] B. T. Bartell, G. W. Cottrell y R. K. Belew. Combinación automática de múltiples sistemas de recuperación clasificados. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2005. [3] C. J. C. Burges, R. Ragno y Q. Lo. Aprendizaje para clasificar con funciones de costo no suaves. En Actas de la Conferencia Internacional sobre Avances en Sistemas de Información Neural (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang y H.-W. Hon. Adaptando el SVM de clasificación para la recuperación de documentos. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [5] B. Carterette y D. Petkova. Aprendiendo un ranking a partir de preferencias por pares. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew y A. Ksikes. Selección de conjunto de bibliotecas de modelos. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [7] J. Davis y M. Goadrich. La relación entre las curvas de precisión-recall y ROC. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2006. [8] D. Hawking. Resumen de la pista web TREC-9. En Actas de TREC-2000, 2000. [9] D. Hawking y N. Craswell. Resumen de la pista web TREC-2001. En Actas de TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel y K. Obermayer. Límites de rango de margen amplio para regresión ordinal. Avances en clasificadores de márgenes amplios, 2000. [11] A. Herschtal y B. Raskutti. Optimizando el área bajo la curva ROC utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [12] K. Jarvelin y J. Kekalainen. Métodos de evaluación para recuperar documentos altamente relevantes. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2000. [13] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), páginas 377-384, Nueva York, NY, EE. UU., 2005. ACM Press. [14] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), páginas 111-119, 2001. [15] Y. Lin, Y. Lee y G. Wahba. Máquinas de vectores de soporte para clasificación en situaciones no estándar. Aprendizaje automático, 46:191-202, 2002. [16] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [17] K. Morik, P. Brockhausen y T. Joachims. Combinando el aprendizaje estadístico con un enfoque basado en el conocimiento. En Actas de la Conferencia Internacional sobre Aprendizaje Automático, 1999. [18] S. Robertson. El principio de clasificación de probabilidad en la revista IR de documentación. Revista de Documentación, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims y Y. Altun. Métodos de margen amplio para variables de salida estructuradas e interdependientes. Revista de Investigación en Aprendizaje Automático (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik. Teoría del Aprendizaje Estadístico. Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz. \n\nWiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer y R. Wolniewicz. Optimizando el rendimiento del clasificador mediante la aproximación a la estadística de Wilcoxon-Mann-Witney. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2003. ",
            "candidates": [],
            "error": [
                [
                    "precisión media promedio",
                    "Precisión Promedio Media"
                ]
            ]
        },
        "optimal solution": {
            "translated_key": "solución óptima",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT Machine learning is commonly used to improve ranked retrieval systems.",
                "Due to computational difficulties, few learning techniques have been developed to directly optimize for mean average precision (MAP), despite its widespread use in evaluating such systems.",
                "Existing approaches optimizing MAP either do not find a globally <br>optimal solution</br>, or are computationally expensive.",
                "In contrast, we present a general SVM learning algorithm that efficiently finds a globally <br>optimal solution</br> to a straightforward relaxation of MAP.",
                "We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora (WT10g), comparing against SVMs optimized for accuracy and ROCArea.",
                "In most cases we show our method to produce statistically significant improvements in MAP scores.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval Models General Terms Algorithm, Theory, Experimentation 1.",
                "INTRODUCTION State of the art information retrieval systems commonly use machine learning techniques to learn ranking functions.",
                "However, most current approaches do not optimize for the evaluation measure most often used, namely Mean Average Precision (MAP).",
                "Instead, current algorithms tend to take one of two general approaches.",
                "The first approach is to learn a model that estimates the probability of a document being relevant given a query (e.g., [18, 14]).",
                "If solved effectively, the ranking with best MAP performance can easily be derived from the probabilities of relevance.",
                "However, achieving high MAP only requires finding a good ordering of the documents.",
                "As a result, finding good probabilities requires solving a more difficult problem than necessary, likely requiring more training data to achieve the same MAP performance.",
                "The second common approach is to learn a function that maximizes a surrogate measure.",
                "Performance measures optimized include accuracy [17, 15], ROCArea [1, 5, 10, 11, 13, 21] or modifications of ROCArea [4], and NDCG [2, 3].",
                "Learning a model to optimize for such measures might result in suboptimal MAP performance.",
                "In fact, although some previous systems have obtained good MAP performance, it is known that neither achieving optimal accuracy nor ROCArea can guarantee optimal MAP performance[7].",
                "In this paper, we present a general approach for learning ranking functions that maximize MAP performance.",
                "Specifically, we present an SVM algorithm that globally optimizes a hinge-loss relaxation of MAP.",
                "This approach simplifies the process of obtaining ranking functions with high MAP performance by avoiding additional intermediate steps and heuristics.",
                "The new algorithm also makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for accuracy and ROCArea.",
                "In contrast to recent work directly optimizing for MAP performance by Metzler & Croft [16] and Caruana et al. [6], our technique is computationally efficient while finding a globally <br>optimal solution</br>.",
                "Like [6, 16], our method learns a linear model, but is much more efficient in practice and, unlike [16], can handle many thousands of features.",
                "We now describe the algorithm in detail and provide proof of correctness.",
                "Following this, we provide an analysis of running time.",
                "We finish with empirical results from experiments on the TREC 9 and TREC 10 Web Track corpus.",
                "We have also developed a software package implementing our algorithm that is available for public use1 . 2.",
                "THE LEARNING PROBLEM Following the standard machine learning setup, our goal is to learn a function h : X → Y between an input space X (all possible queries) and output space Y (rankings over a corpus).",
                "In order to quantify the quality of a prediction, ˆy = h(x), we will consider a loss function ∆ : Y × Y → . ∆(y, ˆy) quantifies the penalty for making prediction ˆy if the correct output is y.",
                "The loss function allows us to incorporate specific performance measures, which we will exploit 1 http://svmrank.yisongyue.com for optimizing MAP.",
                "We restrict ourselves to the supervised learning scenario, where input/output pairs (x, y) are available for training and are assumed to come from some fixed distribution P(x, y).",
                "The goal is to find a function h such that the risk (i.e., expected loss), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), is minimized.",
                "Of course, P(x, y) is unknown.",
                "But given a finite set of training pairs, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, the performance of h on S can be measured by the empirical risk, R∆ S (h) = 1 n nX i=1 ∆(yi, h(xi)).",
                "In the case of learning a ranked retrieval function, X denotes a space of queries, and Y the space of (possibly weak) rankings over some corpus of documents C = {d1, . . . ,d|C|}.",
                "We can define average precision loss as ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), where rank(y) is a vector of the rank values of each document in C. For example, for a corpus of two documents, {d1, d2}, with d1 having higher rank than d2, rank(y ) = (1, 0).",
                "We assume true rankings have two rank values, where relevant documents have rank value 1 and non-relevant documents rank value 0.",
                "We further assume that all predicted rankings are complete rankings (no ties).",
                "Let p = rank(y) and ˆp = rank(ˆy).",
                "The average precision score is defined as MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, where rel = |{i : pi = 1}| is the number of relevant documents, and Prec@j is the percentage of relevant documents in the top j documents in predicted ranking ˆy.",
                "MAP is the mean of the average precision scores of a group of queries. 2.1 MAP vs ROCArea Most learning algorithms optimize for accuracy or ROCArea.",
                "While optimizing for these measures might achieve good MAP performance, we use two simple examples to show it can also be suboptimal in terms of MAP.",
                "ROCArea assigns equal penalty to each misordering of a relevant/non-relevant pair.",
                "In contrast, MAP assigns greater penalties to misorderings higher up in the predicted ranking.",
                "Using our notation, ROCArea can be defined as ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], where p is the true (weak) ranking, ˆp is the predicted ranking, and 1[b] is the indicator function conditioned on b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Table 1: Toy Example and Models Suppose we have a hypothesis space with only two hypothesis functions, h1 and h2, as shown in Table 1.",
                "These two hypotheses predict a ranking for query x over a corpus of eight documents.",
                "Hypothesis MAP ROCArea h1(x) 0.59 0.47 h2(x) 0.51 0.53 Table 2: Performance of Toy Models Table 2 shows the MAP and ROCArea scores of h1 and h2.",
                "Here, a learning method which optimizes for ROCArea would choose h2 since that results in a higher ROCArea score, but this yields a suboptimal MAP score. 2.2 MAP vs Accuracy Using a very similar example, we now demonstrate how optimizing for accuracy might result in suboptimal MAP.",
                "Models which optimize for accuracy are not directly concerned with the ranking.",
                "Instead, they learn a threshold such that documents scoring higher than the threshold can be classified as relevant and documents scoring lower as nonrelevant.",
                "Doc ID 1 2 3 4 5 6 7 8 9 10 11 p 1 0 0 0 0 1 1 1 1 0 0 rank(h1(x)) 11 10 9 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 9 10 11 Table 3: Toy Example and Models We consider again a hypothesis space with two hypotheses.",
                "Table 3 shows the predictions of the two hypotheses on a single query x. Hypothesis MAP Best Acc. h1(q) 0.70 0.64 h2(q) 0.64 0.73 Table 4: Performance of Toy Models Table 4 shows the MAP and best accuracy scores of h1(q) and h2(q).",
                "The best accuracy refers to the highest achievable accuracy on that ranking when considering all possible thresholds.",
                "For instance, with h1(q), a threshold between documents 1 and 2 gives 4 errors (documents 6-9 incorrectly classified as non-relevant), yielding an accuracy of 0.64.",
                "Similarly, with h2(q), a threshold between documents 5 and 6 gives 3 errors (documents 10-11 incorrectly classified as relevant, and document 1 as non-relevant), yielding an accuracy of 0.73.",
                "A learning method which optimizes for accuracy would choose h2 since that results in a higher accuracy score, but this yields a suboptimal MAP score. 3.",
                "OPTIMIZING AVERAGE PRECISION We build upon the approach used by [13] for optimizing ROCArea.",
                "Unlike ROCArea, however, MAP does not decompose linearly in the examples and requires a substantially extended algorithm, which we describe in this section.",
                "Recall that the true ranking is a weak ranking with two rank values (relevant and non-relevant).",
                "Let Cx and C¯x denote the set of relevant and non-relevant documents of C for query x, respectively.",
                "We focus on functions which are parametrized by a weight vector w, and thus wish to find w to minimize the empirical risk, R∆ S (w) ≡ R∆ S (h(·; w)).",
                "Our approach is to learn a discriminant function F : X × Y → over input-output pairs.",
                "Given query x, we can derive a prediction by finding the ranking y that maximizes the discriminant function: h(x; w) = argmax y∈Y F(x, y; w). (1) We assume F to be linear in some combined feature representation of inputs and outputs Ψ(x, y) ∈ RN , i.e., F(x, y; w) = wT Ψ(x, y). (2) The combined feature function we use is Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))] , where φ : X × C → N is a feature mapping function from a query/document pair to a point in N dimensional space2 .",
                "We represent rankings as a matrix of pairwise orderings, Y ⊂ {−1, 0, +1}|C|×|C| .",
                "For any y ∈ Y, yij = +1 if di is ranked ahead of dj, and yij = −1 if dj is ranked ahead of di, and yij = 0 if di and dj have equal rank.",
                "We consider only matrices which correspond to valid rankings (i.e, obeying antisymmetry and transitivity).",
                "Intuitively, Ψ is a summation over the vector differences of all relevant/non-relevant document pairings.",
                "Since we assume predicted rankings to be complete rankings, yij is either +1 or −1 (never 0).",
                "Given a learned weight vector w, predicting a ranking (i.e. solving equation (1)) given query x reduces to picking each yij to maximize wT Ψ(x, y).",
                "As is also discussed in [13], this is attained by sorting the documents by wT φ(x, d) in descending order.",
                "We will discuss later the choices of φ we used for our experiments. 3.1 Structural SVMs The above formulation is very similar to learning a straightforward linear model while training on the pairwise difference of relevant/non-relevant document pairings.",
                "Many SVM-based approaches optimize over these pairwise differences (e.g., [5, 10, 13, 4]), although these methods do not optimize for MAP during training.",
                "Previously, it was not clear how to incorporate non-linear multivariate loss functions such as MAP loss directly into global optimization problems such as SVM training.",
                "We now present a method based on structural SVMs [19] to address this problem.",
                "We use the structural SVM formulation, presented in Optimization Problem 1, to learn a w ∈ RN .",
                "Optimization Problem 1. (Structural SVM) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) The objective function to be minimized (3) is a tradeoff between model complexity, w 2 , and a hinge loss relaxation of MAP loss, P ξi.",
                "As is usual in SVM training, C is a 2 For example, one dimension might be the number of times the query words appear in the document.",
                "Algorithm 1 Cutting plane algorithm for solving OP 1 within tolerance . 1: Input: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ for all i = 1, . . . , n 3: repeat 4: for i = 1, . . . , n do 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: compute ˆy = argmaxy∈Y H(y; w) 7: compute ξi = max{0, maxy∈Wi H(y; w)} 8: if H(ˆy; w) > ξi + then 9: Wi ← Wi ∪ {ˆy} 10: w ← optimize (3) over W = S i Wi 11: end if 12: end for 13: until no Wi has changed during iteration parameter that controls this tradeoff and can be tuned to achieve good performance in different training tasks.",
                "For each (xi, yi) in the training set, a set of constraints of the form in equation (4) is added to the optimization problem.",
                "Note that wT Ψ(x, y) is exactly our discriminant function F(x, y; w) (see equation (2)).",
                "During prediction, our model chooses the ranking which maximizes the discriminant (1).",
                "If the discriminant value for an incorrect ranking y is greater than for the true ranking yi (e.g., F(xi, y; w) > F(xi, yi; w)), then corresponding slack variable, ξi, must be at least ∆(yi, y) for that constraint to be satisfied.",
                "Therefore, the sum of slacks, P ξi, upper bounds the MAP loss.",
                "This is stated formally in Proposition 1.",
                "Proposition 1.",
                "Let ξ∗ (w) be the <br>optimal solution</br> of the slack variables for OP 1 for a given weight vector w. Then 1 n Pn i=1 ξi is an upper bound on the empirical risk R∆ S (w). (see [19] for proof) Proposition 1 shows that OP 1 learns a ranking function that optimizes an upper bound on MAP error on the training set.",
                "Unfortunately there is a problem: a constraint is required for every possible wrong output y, and the number of possible wrong outputs is exponential in the size of C. Fortunately, we may employ Algorithm 1 to solve OP 1.",
                "Algorithm 1 is a cutting plane algorithm, iteratively introducing constraints until we have solved the original problem within a desired tolerance [19].",
                "The algorithm starts with no constraints, and iteratively finds for each example (xi, yi) the output ˆy associated with the most violated constraint.",
                "If the corresponding constraint is violated by more than we introduce ˆy into the working set Wi of active constraints for example i, and re-solve (3) using the updated W. It can be shown that Algorithm 1s outer loop is guaranteed to halt within a polynomial number of iterations for any desired precision .",
                "Theorem 1.",
                "Let ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y) , ¯∆ = maxi maxy ∆(yi, y), and for any > 0, Algorithm 1 terminates after adding at most max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff constraints to the working set W. (see [19] for proof) However, within the inner loop of this algorithm we have to compute argmaxy∈Y H(y; w), where H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), or equivalently, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), since wT Ψ(xi, yi) is constant with respect to y.",
                "Though closely related to the classification procedure, this has the substantial complication that we must contend with the additional ∆(yi, y) term.",
                "Without the ability to efficiently find the most violated constraint (i.e., solve argmaxy∈Y H(y, w)), the constraint generation procedure is not tractable. 3.2 Finding the Most Violated Constraint Using OP 1 and optimizing to ROCArea loss (∆roc), the problem of finding the most violated constraint, or solving argmaxy∈Y H(y, w) (henceforth argmax H), is addressed in [13].",
                "Solving argmax H for ∆map is more difficult.",
                "This is primarily because ROCArea decomposes nicely into a sum of scores computed independently on each relative ordering of a relevant/non-relevant document pair.",
                "MAP, on the other hand, does not decompose in the same way as ROCArea.",
                "The main algorithmic contribution of this paper is an efficient method for solving argmax H for ∆map.",
                "One useful property of ∆map is that it is invariant to swapping two documents with equal relevance.",
                "For example, if documents da and db are both relevant, then swapping the positions of da and db in any ranking does not affect ∆map.",
                "By extension, ∆map is invariant to any arbitrary permutation of the relevant documents amongst themselves and of the non-relevant documents amongst themselves.",
                "However, this reshuﬄing will affect the discriminant score, wT Ψ(x, y).",
                "This leads us to Observation 1.",
                "Observation 1.",
                "Consider rankings which are constrained by fixing the relevance at each position in the ranking (e.g., the 3rd document in the ranking must be relevant).",
                "Every ranking which satisfies the same set of constraints will have the same ∆map.",
                "If the relevant documents are sorted by wT φ(x, d) in descending order, and the non-relevant documents are likewise sorted by wT φ(x, d), then the interleaving of the two sorted lists which satisfies the constraints will maximize H for that constrained set of rankings.",
                "Observation 1 implies that in the ranking which maximizes H, the relevant documents will be sorted by wT φ(x, d), and the non-relevant documents will also be sorted likewise.",
                "By first sorting the relevant and non-relevant documents, the problem is simplified to finding the optimal interleaving of two sorted lists.",
                "For the rest of our discussion, we assume that the relevant documents and non-relevant documents are both sorted by descending wT φ(x, d).",
                "For convenience, we also refer to relevant documents as {dx 1 , . . . dx |Cx|} = Cx , and non-relevant documents as {d¯x 1 , . . . d¯x |C¯x|} = C¯x .",
                "We define δj(i1, i2), with i1 < i2, as the change in H from when the highest ranked relevant document ranked after d¯x j is dx i1 to when it is dx i2 .",
                "For i2 = i1 + 1, we have δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5) where si = wT φ(x, di).",
                "The first term in (5) is the change in ∆map when the ith relevant document has j non-relevant documents ranked before it, as opposed to j −1.",
                "The second term is the change in the discriminant score, wT Ψ(x, y), when yij changes from +1 to −1. . . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . .",
                "Figure 1: Example for δj(i, i + 1) Figure 1 gives a conceptual example for δj(i, i + 1).",
                "The bottom ranking differs from the top only where d¯x j slides up one rank.",
                "The difference in the value of H for these two rankings is exactly δj(i, i + 1).",
                "For any i1 < i2, we can then define δj(i1, i2) as δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) or equivalently, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) .",
                "Let o1, . . . , o|C¯x| encode the positions of the non-relevant documents, where dx oj is the highest ranked relevant document ranked after the jth non-relevant document.",
                "Due to Observation 1, this encoding uniquely identifies a complete ranking.",
                "We can recover the ranking as yij = 8 >>>< >>>: 0 if i = j sign(si − sj) if di, dj equal relevance sign(oj − i − 0.5) if di = dx i , dj = d¯x j sign(j − oi + 0.5) if di = d¯x i , dj = dx j . (7) We can now reformulate H into a new objective function, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), where ¯y is the true (weak) ranking.",
                "Conceptually H starts with a perfect ranking ¯y, and adds the change in H when each successive non-relevant document slides up the ranking.",
                "We can then reformulate the argmax H problem as argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) s.t. o1 ≤ . . . ≤ o|C¯x|. (9) Algorithm 2 describes the algorithm used to solve equation (8).",
                "Conceptually, Algorithm 2 starts with a perfect ranking.",
                "Then for each successive non-relevant document, the algorithm modifies the solution by sliding that document up the ranking to locally maximize H while keeping the positions of the other non-relevant documents constant. 3.2.1 Proof of Correctness Algorithm 2 is greedy in the sense that it finds the best position of each non-relevant document independently from the other non-relevant documents.",
                "In other words, the algorithm maximizes H for each non-relevant document, d¯x j , Algorithm 2 Finding the Most Violated Constraint (argmax H) for Algorithm 1 with ∆map 1: Input: w, Cx , C¯x 2: sort Cx and C¯x in descending order of wT φ(x, d) 3: sx i ← wT φ(x, dx i ), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i ), i = 1, . . . , |C¯x | 5: for j = 1, . . . , |C¯x | do 6: optj ← argmaxk δj(k, |Cx | + 1) 7: end for 8: encode ˆy according to (7) 9: return ˆy without considering the positions of the other non-relevant documents, and thus ignores the constraints of (9).",
                "In order for the solution to be feasible, the jth non-relevant document must be ranked after the first j − 1 non-relevant documents, thus satisfying opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. (10) If the solution is feasible, the it clearly solves (8).",
                "Therefore, it suffices to prove that Algorithm 2 satisfies (10).",
                "We first prove that δj(·, ·) is monotonically decreasing in j. Lemma 1.",
                "For any 1 ≤ i1 < i2 ≤ |Cx | + 1 and 1 ≤ j < |C¯x |, it must be the case that δj+1(i1, i2) ≤ δj(i1, i2).",
                "Proof.",
                "Recall from (6) that both δj(i1, i2) and δj+1(i1, i2) are summations of i2 − i1 terms.",
                "We will show that each term in the summation of δj+1(i1, i2) is no greater than the corresponding term in δj(i1, i2), or δj+1(k, k + 1) ≤ δj(k, k + 1) for k = i1, . . . , i2 − 1.",
                "Each term in δj(k, k +1) and δj+1(k, k +1) can be further decomposed into two parts (see (5)).",
                "We will show that each part of δj+1(k, k + 1) is no greater than the corresponding part in δj(k, k + 1).",
                "In other words, we will show that both j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) and −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) are true for the aforementioned values of j and k. It is easy to see that (11) is true by observing that for any two positive integers 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1 , and choosing a = j and b = j + k. The second inequality (12) holds because Algorithm 2 first sorts d¯x in descending order of s¯x , implying s¯x j+1 ≤ s¯x j .",
                "Thus we see that each term in δj+1 is no greater than the corresponding term in δj, which completes the proof.",
                "The result of Lemma 1 leads directly to our main correctness result: Theorem 2.",
                "In Algorithm 2, the computed values of optj satisfy (10), implying that the solution returned by Algorithm 2 is feasible and thus optimal.",
                "Proof.",
                "We will prove that optj ≤ optj+1 holds for any 1 ≤ j < |C¯x |, thus implying (10).",
                "Since Algorithm 2 computes optj as optj = argmax k δj(k, |Cx | + 1), (13) then by definition of δj (6), for any 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0.",
                "Using Lemma 1, we know that δj+1(i, optj) ≤ δj(i, optj) < 0, which implies that for any 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0.",
                "Suppose for contradiction that optj+1 < optj.",
                "Then δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), which contradicts (13).",
                "Therefore, it must be the case that optj ≤ optj+1, which completes the proof. 3.2.2 Running Time The running time of Algorithm 2 can be split into two parts.",
                "The first part is the sort by wT φ(x, d), which requires O(n log n) time, where n = |Cx | + |C¯x |.",
                "The second part computes each optj, which requires O(|Cx | · |C¯x |) time.",
                "Though in the worst case this is O(n2 ), the number of relevant documents, |Cx |, is often very small (e.g., constant with respect to n), in which case the running time for the second part is simply O(n).",
                "For most real-world datasets, Algorithm 2 is dominated by the sort and has complexity O(n log n).",
                "Algorithm 1 is guaranteed to halt in a polynomial number of iterations [19], and each iteration runs Algorithm 2.",
                "Virtually all well-performing models were trained in a reasonable amount of time (usually less than one hour).",
                "Once training is complete, making predictions on query x using the resulting hypothesis h(x|w) requires only sorting by wT φ(x, d).",
                "We developed our software using a Python interface3 to SVMstruct , since the Python language greatly simplified the coding process.",
                "To improve performance, it is advisable to use the standard C implementation4 of SVMstruct . 4.",
                "EXPERIMENT SETUP The main goal of our experiments is to evaluate whether directly optimizing MAP leads to improved MAP performance compared to conventional SVM methods that optimize a substitute loss such as accuracy or ROCArea.",
                "We empirically evaluate our method using two sets of TREC Web Track queries, one each from TREC 9 and TREC 10 (topics 451-500 and 501-550), both of which used the WT10g corpus.",
                "For each query, TREC provides the relevance judgments of the documents.",
                "We generated our features using the scores of existing retrieval functions on these queries.",
                "While our method is agnostic to the meaning of the features, we chose to use existing retrieval functions as a simple yet effective way of acquiring useful features.",
                "As such, our 3 http://www.cs.cornell.edu/~tomf/svmpython/ 4 http://svmlight.joachims.org/svm_struct.html Dataset Base Funcs Features TREC 9 Indri 15 750 TREC 10 Indri 15 750 TREC 9 Submissions 53 2650 TREC 10 Submissions 18 900 Table 5: Dataset Statistics experiments essentially test our methods ability to re-rank the highly ranked documents (e.g., re-combine the scores of the retrieval functions) to improve MAP.",
                "We compare our method against the best retrieval functions trained on (henceforth base functions), as well as against previously proposed SVM methods.",
                "Comparing with the best base functions tests our methods ability to learn a useful combination.",
                "Comparing with previous SVM methods allows us to test whether optimizing directly for MAP (as opposed to accuracy or ROCArea) achieves a higher MAP score in practice.",
                "The rest of this section describes the base functions and the feature generation method in detail. 4.1 Choosing Retrieval Functions We chose two sets of base functions for our experiments.",
                "For the first set, we generated three indices over the WT10g corpus using Indri5 .",
                "The first index was generated using default settings, the second used Porter-stemming, and the last used Porter-stemming and Indris default stopwords.",
                "For both TREC 9 and TREC 10, we used the description portion of each query and scored the documents using five of Indris built-in retrieval methods, which are Cosine Similarity, TFIDF, Okapi, Language Model with Dirichlet Prior, and Language Model with Jelinek-Mercer Prior.",
                "All parameters were kept as their defaults.",
                "We computed the scores of these five retrieval methods over the three indices, giving 15 base functions in total.",
                "For each query, we considered the scores of documents found in the union of the top 1000 documents of each base function.",
                "For our second set of base functions, we used scores from the TREC 9 [8] and TREC 10 [9] Web Track submissions.",
                "We used only the non-manual, non-short submissions from both years.",
                "For TREC 9 and TREC 10, there were 53 and 18 such submissions, respectively.",
                "A typical submission contained scores of its top 1000 documents. b ca wT φ(x,d) f(d|x) Figure 2: Example Feature Binning 4.2 Generating Features In order to generate input examples for our method, a concrete instantiation of φ must be provided.",
                "For each doc5 http://www.lemurproject.org TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236Best Func. 0.204 39/11 ** 0.181 37/13 ** 2nd Best 0.199 38/12 ** 0.174 43/7 ** 3rd Best 0.188 34/16 ** 0.174 38/12 ** Table 6: Comparison with Indri Functions ument d scored by a set of retrieval functions F on query x, we generate the features as a vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf , where f(d|x) denotes the score that retrieval function f assigns to document d for query x, and each Kf is a set of real values.",
                "From a high level, we are expressing the score of each retrieval function using |Kf | + 1 bins.",
                "Since we are using linear kernels, one can think of the learning problem as finding a good piecewise-constant combination of the scores of the retrieval functions.",
                "Figure 2 shows an example of our feature mapping method.",
                "In this example we have a single feature F = {f}.",
                "Here, Kf = {a, b, c}, and the weight vector is w = wa, wb, wc .",
                "For any document d and query x, we have wT φ(x, d) = 8 >>< >>: 0 if f(d|x) < a wa if a ≤ f(d|x) < b wa + wb if b ≤ f(d|x) < c wa + wb + wc if c ≤ f(d|x) .",
                "This is expressed qualitatively in Figure 2, where wa and wb are positive, and wc is negative.",
                "We ran our main experiments using four choices of F: the set of aforementioned Indri retrieval functions for TREC 9 and TREC 10, and the Web Track submissions for TREC 9 and TREC 10.",
                "For each F and each function f ∈ F, we chose 50 values for Kf which are reasonably spaced and capture the sensitive region of f. Using the four choices of F, we generated four datasets for our main experiments.",
                "Table 5 contains statistics of the generated datasets.",
                "There are many ways to generate features, and we are not advocating our method over others.",
                "This was simply an efficient means to normalize the outputs of different functions and allow for a more expressive model. 5.",
                "EXPERIMENTS For each dataset in Table 5, we performed 50 trials.",
                "For each trial, we train on 10 randomly selected queries, and select another 5 queries at random for a validation set.",
                "Models were trained using a wide range of C values.",
                "The model which performed best on the validation set was selected and tested on the remaining 35 queries.",
                "All queries were selected to be in the training, validation and test sets the same number of times.",
                "Using this setup, we performed the same experiments while using our method (SVM∆ map), an SVM optimizing for ROCArea (SVM∆ roc) [13], and a conventional classification SVM (SVMacc) [20].",
                "All SVM methods used a linear kernel.",
                "We reported the average performance of all models over the 50 trials. 5.1 Comparison with Base Functions In analyzing our results, the first question to answer is, can SVM∆ map learn a model which outperforms the best base TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287Best Func. 0.280 28/22 0.283 29/21 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 36/14 ** Table 7: Comparison with TREC Submissions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288Best Func. 0.280 27/23 0.283 31/19 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 35/15 ** Table 8: Comparison with TREC Subm. (w/o best) functions?",
                "Table 6 presents the comparison of SVM∆ map with the best Indri base functions.",
                "Each column group contains the macro-averaged MAP performance of SVM∆ map or a base function.",
                "The W/L columns show the number of queries where SVM∆ map achieved a higher MAP score.",
                "Significance tests were performed using the two-tailed Wilcoxon signed rank test.",
                "Two stars indicate a significance level of 0.95.",
                "All tables displaying our experimental results are structured identically.",
                "Here, we find that SVM∆ map significantly outperforms the best base functions.",
                "Table 7 shows the comparison when trained on TREC submissions.",
                "While achieving a higher MAP score than the best base functions, the performance difference between SVM∆ map the base functions is not significant.",
                "Given that many of these submissions use scoring functions which are carefully crafted to achieve high MAP, it is possible that the best performing submissions use techniques which subsume the techniques of the other submissions.",
                "As a result, SVM∆ map would not be able to learn a hypothesis which can significantly out-perform the best submission.",
                "Hence, we ran the same experiments using a modified dataset where the features computed using the best submission were removed.",
                "Table 8 shows the results (note that we are still comparing against the best submission though we are not using it for training).",
                "Notice that while the performance of SVM∆ map degraded slightly, the performance was still comparable with that of the best submission. 5.2 Comparison w/ Previous SVM Methods The next question to answer is, does SVM∆ map produce higher MAP scores than previous SVM methods?",
                "Tables 9 and 10 present the results of SVM∆ map, SVM∆ roc, and SVMacc when trained on the Indri retrieval functions and TREC submissions, respectively.",
                "Table 11 contains the corresponding results when trained on the TREC submissions without the best submission.",
                "To start with, our results indicate that SVMacc was not competitive with SVM∆ map and SVM∆ roc, and at times underperformed dramatically.",
                "As such, we tried several approaches to improve the performance of SVMacc. 5.2.1 Alternate SVMacc Methods One issue which may cause SVMacc to underperform is the severe imbalance between relevant and non-relevant docTREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236SVM∆ roc 0.237 29/21 0.234 24/26 SVMacc 0.147 47/3 ** 0.155 47/3 ** SVMacc2 0.219 39/11 ** 0.207 43/7 ** SVMacc3 0.113 49/1 ** 0.153 45/5 ** SVMacc4 0.155 48/2 ** 0.155 48/2 ** Table 9: Trained on Indri Functions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287SVM∆ roc 0.282 29/21 0.278 35/15 ** SVMacc 0.213 49/1 ** 0.222 49/1 ** SVMacc2 0.270 34/16 ** 0.261 42/8 ** SVMacc3 0.133 50/0 ** 0.182 46/4 ** SVMacc4 0.233 47/3 ** 0.238 46/4 ** Table 10: Trained on TREC Submissions uments.",
                "The vast majority of the documents are not relevant.",
                "SVMacc2 addresses this problem by assigning more penalty to false negative errors.",
                "For each dataset, the ratio of the false negative to false positive penalties is equal to the ratio of the number non-relevant and relevant documents in that dataset.",
                "Tables 9, 10 and 11 indicate that SVMacc2 still performs significantly worse than SVM∆ map.",
                "Another possible issue is that SVMacc attempts to find just one discriminating threshold b that is query-invariant.",
                "It may be that different queries require different values of b.",
                "Having the learning method trying to find a good b value (when one does not exist) may be detrimental.",
                "We took two approaches to address this issue.",
                "The first method, SVMacc3, converts the retrieval function scores into percentiles.",
                "For example, for document d, query q and retrieval function f, if the score f(d|q) is in the top 90% of the scores f(·|q) for query q, then the converted score is f (d|q) = 0.9.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Tables 9, 10 and 11 show that the performance of SVMacc3 was also not competitive with SVM∆ map.",
                "The second method, SVMacc4, normalizes the scores given by f for each query.",
                "For example, assume for query q that f outputs scores in the range 0.2 to 0.7.",
                "Then for document d, if f(d|q) = 0.6, the converted score would be f (d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Again, Tables 9, 10 and 11 show that SVMacc4 was not competitive with SVM∆ map 5.2.2 MAP vs ROCArea SVM∆ roc performed much better than SVMacc in our experiments.",
                "When trained on Indri retrieval functions (see Table 9), the performance of SVM∆ roc was slight, though not significantly, worse than the performances of SVM∆ map.",
                "However, Table 10 shows that SVM∆ map did significantly outperform SVM∆ roc when trained on the TREC submissions.",
                "Table 11 shows the performance of the models when trained on the TREC submissions with the best submission removed.",
                "The performance of most models degraded by a small amount, with SVM∆ map still having the best performance.",
                "TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Table 11: Trained on TREC Subm. (w/o Best) 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented an SVM method that directly optimizes MAP.",
                "It provides a principled approach and avoids difficult to control heuristics.",
                "We formulated the optimization problem and presented an algorithm which provably finds the solution in polynomial time.",
                "We have shown empirically that our method is generally superior to or competitive with conventional SVMs methods.",
                "Our new method makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for Accuracy and ROCArea.",
                "The computational cost for training is very reasonable in practice.",
                "Since other methods typically require tuning multiple heuristics, we also expect to train fewer models before finding one which achieves good performance.",
                "The learning framework used by our method is fairly general.",
                "A natural extension of this framework would be to develop methods to optimize for other important IR measures, such as Normalized Discounted Cumulative Gain [2, 3, 4, 12] and Mean Reciprocal Rank. 7.",
                "ACKNOWLEDGMENTS This work was funded under NSF Award IIS-0412894, NSF CAREER Award 0237381, and a gift from Yahoo!",
                "Research.",
                "The third author was also partly supported by a Microsoft Research Fellowship. 8.",
                "REFERENCES [1] B. T. Bartell, G. W. Cottrell, and R. K. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2005. [3] C. J. C. Burges, R. Ragno, and Q.",
                "Le.",
                "Learning to rank with non-smooth cost functions.",
                "In Proceedings of the International Conference on Advances in Neural Information Processing Systems (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y.",
                "Liu, H. Li, Y. Huang, and H.-W. Hon.",
                "Adapting ranking SVM to document retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [5] B. Carterette and D. Petkova.",
                "Learning a ranking from pairwise preferences.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew, and A. Ksikes.",
                "Ensemble selection from libraries of models.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [7] J. Davis and M. Goadrich.",
                "The relationship between precision-recall and ROC curves.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2006. [8] D. Hawking.",
                "Overview of the TREC-9 web track.",
                "In Proceedings of TREC-2000, 2000. [9] D. Hawking and N. Craswell.",
                "Overview of the TREC-2001 web track.",
                "In Proceedings of TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel, and K. Obermayer.",
                "Large margin rank boundaries for ordinal regression.",
                "Advances in large margin classifiers, 2000. [11] A. Herschtal and B. Raskutti.",
                "Optimising area under the ROC curve using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [12] K. Jarvelin and J. Kekalainen.",
                "Ir evaluation methods for retrieving highly relevant documents.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2000. [13] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proceedings of the International Conference on Machine Learning (ICML), pages 377-384, New York, NY, USA, 2005.",
                "ACM Press. [14] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 111-119, 2001. [15] Y. Lin, Y. Lee, and G. Wahba.",
                "Support vector machines for classification in nonstandard situations.",
                "Machine Learning, 46:191-202, 2002. [16] D. Metzler and W. B. Croft.",
                "A markov random field model for term dependencies.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 472-479, 2005. [17] K. Morik, P. Brockhausen, and T. Joachims.",
                "Combining statistical learning with a knowledge-based approach.",
                "In Proceedings of the International Conference on Machine Learning, 1999. [18] S. Robertson.",
                "The probability ranking principle in ir. journal of documentation.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.",
                "Large margin methods for structured and interdependent output variables.",
                "Journal of Machine Learning Research (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik.",
                "Statistical Learning Theory.",
                "Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz.",
                "Optimizing classifier performance via approximation to the Wilcoxon-Mann-Witney statistic.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2003."
            ],
            "original_annotated_samples": [
                "Existing approaches optimizing MAP either do not find a globally <br>optimal solution</br>, or are computationally expensive.",
                "In contrast, we present a general SVM learning algorithm that efficiently finds a globally <br>optimal solution</br> to a straightforward relaxation of MAP.",
                "In contrast to recent work directly optimizing for MAP performance by Metzler & Croft [16] and Caruana et al. [6], our technique is computationally efficient while finding a globally <br>optimal solution</br>.",
                "Let ξ∗ (w) be the <br>optimal solution</br> of the slack variables for OP 1 for a given weight vector w. Then 1 n Pn i=1 ξi is an upper bound on the empirical risk R∆ S (w). (see [19] for proof) Proposition 1 shows that OP 1 learns a ranking function that optimizes an upper bound on MAP error on the training set."
            ],
            "translated_annotated_samples": [
                "Los enfoques existentes que optimizan el MAP no encuentran <br>una solución óptima global</br> o son computacionalmente costosos.",
                "Por el contrario, presentamos un algoritmo de aprendizaje SVM general que encuentra de manera eficiente una <br>solución óptima</br> global para una relajación directa de MAP.",
                "A diferencia del trabajo reciente que optimiza directamente el rendimiento de MAP realizado por Metzler & Croft [16] y Caruana et al. [6], nuestra técnica es eficiente computacionalmente al encontrar una <br>solución óptima</br> a nivel global.",
                "Sea ξ∗ (w) la <br>solución óptima</br> de las variables de holgura para OP 1 para un vector de peso dado w. Entonces 1 n Pn i=1 ξi es una cota superior del riesgo empírico R∆ S (w). (ver [19] para la prueba) La Proposición 1 muestra que OP 1 aprende una función de clasificación que optimiza una cota superior del error de MAP en el conjunto de entrenamiento."
            ],
            "translated_text": "Un método de Vectores de Soporte para optimizar la Precisión Promedio Yisong Yue Universidad de Cornell Ithaca, NY, EE. UU. yyue@cs.cornell.edu Thomas Finley Universidad de Cornell Ithaca, NY, EE. UU. tomf@cs.cornell.edu Filip Radlinski Universidad de Cornell Ithaca, NY, EE. UU. filip@cs.cornell.edu Thorsten Joachims Universidad de Cornell Ithaca, NY, EE. UU. tj@cs.cornell.edu RESUMEN El aprendizaje automático se utiliza comúnmente para mejorar los sistemas de recuperación clasificados. Debido a dificultades computacionales, se han desarrollado pocas técnicas de aprendizaje para optimizar directamente la precisión media promedio (MAP), a pesar de su uso generalizado en la evaluación de dichos sistemas. Los enfoques existentes que optimizan el MAP no encuentran <br>una solución óptima global</br> o son computacionalmente costosos. Por el contrario, presentamos un algoritmo de aprendizaje SVM general que encuentra de manera eficiente una <br>solución óptima</br> global para una relajación directa de MAP. Evaluamos nuestro enfoque utilizando los corpus de la pista web TREC 9 y TREC 10 (WT10g), comparando con SVM optimizados para precisión y área bajo la curva ROC. En la mayoría de los casos mostramos nuestro método para producir mejoras estadísticamente significativas en las puntuaciones de MAP. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de Recuperación Términos Generales Algoritmo, Teoría, Experimentación 1. INTRODUCCIÓN Los sistemas de recuperación de información de última generación comúnmente utilizan técnicas de aprendizaje automático para aprender funciones de clasificación. Sin embargo, la mayoría de los enfoques actuales no están optimizados para la medida de evaluación más utilizada, es decir, la Precisión Promedio Media (MAP). En cambio, los algoritmos actuales tienden a seguir uno de dos enfoques generales. El primer enfoque es aprender un modelo que estime la probabilidad de que un documento sea relevante dado una consulta (por ejemplo, [18, 14]). Si se resuelve de manera efectiva, la clasificación con el mejor rendimiento de MAP puede derivarse fácilmente de las probabilidades de relevancia. Sin embargo, lograr un MAP alto solo requiere encontrar un buen ordenamiento de los documentos. Como resultado, encontrar buenas probabilidades requiere resolver un problema más difícil de lo necesario, probablemente necesitando más datos de entrenamiento para lograr el mismo rendimiento de MAP. El segundo enfoque común es aprender una función que maximice una medida sustituta. Las medidas de rendimiento optimizadas incluyen precisión [17, 15], área bajo la curva ROC [1, 5, 10, 11, 13, 21] o modificaciones del área bajo la curva ROC [4], y NDCG [2, 3]. Aprender un modelo para optimizar tales medidas podría resultar en un rendimiento de MAP subóptimo. De hecho, aunque algunos sistemas anteriores han obtenido un buen rendimiento de MAP, se sabe que ni lograr una precisión óptima ni un área bajo la curva ROC pueden garantizar un rendimiento de MAP óptimo[7]. En este artículo, presentamos un enfoque general para aprender funciones de clasificación que maximizan el rendimiento de MAP. Específicamente, presentamos un algoritmo SVM que optimiza globalmente una relajación de pérdida de bisagra de MAP. Este enfoque simplifica el proceso de obtener funciones de clasificación con un alto rendimiento de MAP al evitar pasos intermedios adicionales y heurísticas. El nuevo algoritmo también hace que sea conceptualmente tan fácil optimizar las SVM para MAP como anteriormente solo era posible para precisión y ROCArea. A diferencia del trabajo reciente que optimiza directamente el rendimiento de MAP realizado por Metzler & Croft [16] y Caruana et al. [6], nuestra técnica es eficiente computacionalmente al encontrar una <br>solución óptima</br> a nivel global. Al igual que [6, 16], nuestro método aprende un modelo lineal, pero es mucho más eficiente en la práctica y, a diferencia de [16], puede manejar miles de características. Ahora describimos el algoritmo en detalle y proporcionamos la prueba de corrección. A continuación, proporcionamos un análisis del tiempo de ejecución. Concluimos con los resultados empíricos de experimentos en el corpus de la pista web TREC 9 y TREC 10. También hemos desarrollado un paquete de software que implementa nuestro algoritmo y está disponible para uso público. EL PROBLEMA DEL APRENDIZAJE Siguiendo la configuración estándar del aprendizaje automático, nuestro objetivo es aprender una función h: X → Y entre un espacio de entrada X (todas las consultas posibles) y un espacio de salida Y (clasificaciones sobre un corpus). Para cuantificar la calidad de una predicción, ˆy = h(x), consideraremos una función de pérdida ∆ : Y × Y → . ∆(y, ˆy) cuantifica la penalización por hacer la predicción ˆy si la salida correcta es y. La función de pérdida nos permite incorporar medidas específicas de rendimiento, las cuales explotaremos en http://svmrank.yisongyue.com para optimizar el MAP. Nos restringimos al escenario de aprendizaje supervisado, donde pares de entrada/salida (x, y) están disponibles para el entrenamiento y se asume que provienen de alguna distribución fija P(x, y). El objetivo es encontrar una función h tal que el riesgo (es decir, la pérdida esperada), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), se minimice. Por supuesto, P(x, y) es desconocido. Pero dado un conjunto finito de pares de entrenamiento, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, el rendimiento de h en S puede medirse mediante el riesgo empírico, R∆ S (h) = 1 n ∑ i=1 n ∆(yi, h(xi)). En el caso de aprender una función de recuperación clasificada, X denota un espacio de consultas, y Y el espacio de clasificaciones (posiblemente débiles) sobre algún corpus de documentos C = {d1, . . . ,d|C|}. Podemos definir la pérdida de precisión promedio como ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), donde rank(y) es un vector de los valores de rango de cada documento en C. Por ejemplo, para un corpus de dos documentos, {d1, d2}, con d1 teniendo un rango más alto que d2, rank(y) = (1, 0). Suponemos que las clasificaciones verdaderas tienen dos valores de clasificación, donde los documentos relevantes tienen un valor de clasificación 1 y los documentos no relevantes tienen un valor de clasificación 0. Además, asumimos que todas las clasificaciones predichas son clasificaciones completas (sin empates). Sea p = rango(y) y ˆp = rango(ˆy). La puntuación de precisión promedio se define como MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, donde rel = |{i : pi = 1}| es el número de documentos relevantes, y Prec@j es el porcentaje de documentos relevantes en los primeros j documentos en la clasificación predicha ˆy. MAP es la media de las puntuaciones de precisión promedio de un grupo de consultas. La mayoría de los algoritmos de aprendizaje se optimizan para precisión o ROCArea. Si bien optimizar estas medidas podría lograr un buen rendimiento de MAP, usamos dos ejemplos simples para mostrar que también puede ser subóptimo en términos de MAP. ROCArea asigna una penalización igual a cada desordenamiento de un par relevante/no relevante. Por el contrario, MAP asigna mayores penalizaciones a los errores de ordenamiento más arriba en la clasificación predicha. Usando nuestra notación, el Área bajo la Curva ROC (ROCArea) se puede definir como ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], donde p es el ranking verdadero (débil), ˆp es el ranking predicho, y 1[b] es la función indicadora condicionada a b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Tabla 1: Ejemplo y Modelos Supongamos que tenemos un espacio de hipótesis con solo dos funciones de hipótesis, h1 y h2, como se muestra en la Tabla 1. Estas dos hipótesis predicen un ranking para la consulta x sobre un corpus de ocho documentos. Tabla 2: Rendimiento de los Modelos de Juguete La Tabla 2 muestra las puntuaciones de MAP y ROCArea de h1 y h2. Aquí, un método de aprendizaje que optimiza para el Área bajo la curva ROC elegiría h2 ya que esto resulta en un puntaje de Área bajo la curva ROC más alto, pero esto produce un puntaje de MAP subóptimo. 2.2 MAP vs Precisión Usando un ejemplo muy similar, ahora demostramos cómo optimizar para la precisión podría resultar en un puntaje de MAP subóptimo. Los modelos que se optimizan para la precisión no están directamente preocupados por la clasificación. En cambio, aprenden un umbral tal que los documentos que obtienen una puntuación superior al umbral pueden ser clasificados como relevantes y los documentos que obtienen una puntuación inferior como no relevantes. Consideramos nuevamente un espacio de hipótesis con dos hipótesis. La Tabla 3 muestra las predicciones de las dos hipótesis en una única consulta x. Hipótesis MAP Mejor Precisión h1(q) 0.70 0.64 h2(q) 0.64 0.73 Tabla 4: Rendimiento de los Modelos de Juguete La Tabla 4 muestra los puntajes de MAP y mejor precisión de h1(q) y h2(q). La mejor precisión se refiere a la precisión más alta alcanzable en esa clasificación al considerar todos los umbrales posibles. Por ejemplo, con h1(q), un umbral entre los documentos 1 y 2 da 4 errores (documentos 6-9 clasificados incorrectamente como no relevantes), lo que resulta en una precisión de 0.64. De manera similar, con h2(q), un umbral entre los documentos 5 y 6 da 3 errores (los documentos 10-11 clasificados incorrectamente como relevantes, y el documento 1 como no relevante), lo que resulta en una precisión de 0.73. Un método de aprendizaje que optimiza la precisión elegiría h2 ya que esto resulta en un puntaje de precisión más alto, pero esto produce un puntaje de MAP subóptimo. 3. OPTIMIZANDO LA PRECISIÓN PROMEDIO Nos basamos en el enfoque utilizado por [13] para optimizar el Área bajo la Curva ROC. A diferencia de ROCArea, sin embargo, MAP no se descompone linealmente en los ejemplos y requiere un algoritmo sustancialmente extendido, el cual describimos en esta sección. Recuerda que la clasificación verdadera es una clasificación débil con dos valores de clasificación (relevante y no relevante). Que Cx y C¯x denoten el conjunto de documentos relevantes y no relevantes de C para la consulta x, respectivamente. Nos enfocamos en funciones que están parametrizadas por un vector de peso w, y por lo tanto deseamos encontrar w para minimizar el riesgo empírico, R∆ S (w) ≡ R∆ S (h(·; w)). Nuestro enfoque es aprender una función discriminante F: X × Y → sobre pares de entrada-salida. Dada la consulta x, podemos derivar una predicción encontrando la clasificación y que maximiza la función discriminante: h(x; w) = argmax y∈Y F(x, y; w). (1) Suponemos que F es lineal en alguna representación de características combinadas de entradas y salidas Ψ(x, y) ∈ RN, es decir, F(x, y; w) = wT Ψ(x, y). (2) La función de características combinadas que utilizamos es Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))], donde φ: X × C → N es una función de mapeo de características de un par consulta/documento a un punto en un espacio dimensional N. Representamos las clasificaciones como una matriz de ordenamientos por pares, Y ⊂ {−1, 0, +1}|C|×|C| . Para cualquier y ∈ Y, yij = +1 si di está clasificado por delante de dj, y yij = −1 si dj está clasificado por delante de di, y yij = 0 si di y dj tienen el mismo rango. Consideramos solo matrices que corresponden a clasificaciones válidas (es decir, que cumplen con la antisimetría y la transitividad). De manera intuitiva, Ψ es una suma de las diferencias vectoriales de todos los pares de documentos relevantes/no relevantes. Dado que asumimos que las clasificaciones predichas son clasificaciones completas, yij es o bien +1 o −1 (nunca 0). Dado un vector de pesos aprendido w, predecir un ranking (es decir, resolver la ecuación (1)) dado una consulta x se reduce a elegir cada yij para maximizar wT Ψ(x, y). Como también se discute en [13], esto se logra ordenando los documentos por wT φ(x, d) en orden descendente. Discutiremos más adelante las elecciones de φ que utilizamos para nuestros experimentos. 3.1 SVM Estructurales La formulación anterior es muy similar a aprender un modelo lineal directo mientras se entrena en la diferencia de pares de documentos relevantes/no relevantes. Muchos enfoques basados en SVM optimizan sobre estas diferencias en pares (por ejemplo, [5, 10, 13, 4]), aunque estos métodos no optimizan para el MAP durante el entrenamiento. Anteriormente, no estaba claro cómo incorporar funciones de pérdida multivariadas no lineales como la pérdida MAP directamente en problemas de optimización global como el entrenamiento de SVM. Ahora presentamos un método basado en SVM estructurales [19] para abordar este problema. Utilizamos la formulación del SVM estructural, presentada en el Problema de Optimización 1, para aprender un w ∈ RN. Problema de optimización 1. (SVM estructural) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) La función objetivo a minimizar (3) es un compromiso entre la complejidad del modelo, w 2 , y una relajación de pérdida de MAP mediante la pérdida de bisagra, P ξi. Como es habitual en el entrenamiento de SVM, C es igual a 2. Por ejemplo, una dimensión podría ser el número de veces que las palabras de la consulta aparecen en el documento. Algoritmo 1 Algoritmo de plano de corte para resolver OP 1 dentro de la tolerancia. 1: Entrada: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ para todo i = 1, . . . , n 3: repetir 4: para i = 1, . . . , n hacer 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: calcular ˆy = argmaxy∈Y H(y; w) 7: calcular ξi = max{0, maxy∈Wi H(y; w)} 8: si H(ˆy; w) > ξi + entonces 9: Wi ← Wi ∪ {ˆy} 10: w ← optimizar (3) sobre W = S i Wi 11: fin si 12: fin para 13: hasta que ningún Wi haya cambiado durante la iteración parámetro que controla este equilibrio y puede ajustarse para lograr un buen rendimiento en diferentes tareas de entrenamiento. Para cada (xi, yi) en el conjunto de entrenamiento, se añade un conjunto de restricciones de la forma en la ecuación (4) al problema de optimización. Ten en cuenta que wT Ψ(x, y) es exactamente nuestra función discriminante F(x, y; w) (ver ecuación (2)). Durante la predicción, nuestro modelo elige el ranking que maximiza el discriminante (1). Si el valor del discriminante para una clasificación incorrecta y es mayor que para la clasificación verdadera yi (por ejemplo, F(xi, y; w) > F(xi, yi; w)), entonces la variable de holgura correspondiente, ξi, debe ser al menos ∆(yi, y) para que se cumpla esa restricción. Por lo tanto, la suma de los márgenes, P ξi, acota superiormente la pérdida MAP. Esto se establece formalmente en la Proposición 1. Proposición 1. Sea ξ∗ (w) la <br>solución óptima</br> de las variables de holgura para OP 1 para un vector de peso dado w. Entonces 1 n Pn i=1 ξi es una cota superior del riesgo empírico R∆ S (w). (ver [19] para la prueba) La Proposición 1 muestra que OP 1 aprende una función de clasificación que optimiza una cota superior del error de MAP en el conjunto de entrenamiento. Desafortunadamente hay un problema: se requiere una restricción para cada posible resultado incorrecto y, y el número de resultados incorrectos posibles es exponencial en el tamaño de C. Afortunadamente, podemos emplear el Algoritmo 1 para resolver OP 1. El algoritmo 1 es un algoritmo de plano de corte, introduciendo iterativamente restricciones hasta que hayamos resuelto el problema original dentro de una tolerancia deseada [19]. El algoritmo comienza sin restricciones y encuentra de forma iterativa, para cada ejemplo (xi, yi), la salida ˆy asociada con la restricción más violada. Si la restricción correspondiente es violada por más de lo que introducimos ˆy en el conjunto de trabajo Wi de restricciones activas, por ejemplo i, y volvemos a resolver (3) usando el W actualizado. Se puede demostrar que el bucle externo del Algoritmo 1 está garantizado a detenerse dentro de un número polinomial de iteraciones para cualquier precisión deseada. Teorema 1. Sea ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y), ¯∆ = maxi maxy ∆(yi, y), y para cualquier > 0, el Algoritmo 1 termina después de agregar a lo sumo max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff restricciones al conjunto de trabajo W. (ver [19] para la prueba) Sin embargo, dentro del bucle interno de este algoritmo tenemos que calcular argmaxy∈Y H(y; w), donde H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), o equivalentemente, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), ya que wT Ψ(xi, yi) es constante con respecto a y. Aunque está estrechamente relacionado con el procedimiento de clasificación, esto tiene la complicación sustancial de que debemos lidiar con el término adicional ∆(yi, y). Sin la capacidad de encontrar eficientemente la restricción más violada (es decir, resolver argmaxy∈Y H(y, w)), el procedimiento de generación de restricciones no es viable. 3.2 Encontrar la restricción más violada utilizando OP 1 y optimizando la pérdida de ROCArea (∆roc), el problema de encontrar la restricción más violada, o resolver argmaxy∈Y H(y, w) (en adelante argmax H), se aborda en [13]. Resolver argmax H para ∆map es más difícil. Esto se debe principalmente a que ROCArea se descompone de manera ordenada en una suma de puntuaciones calculadas de forma independiente en cada ordenamiento relativo de un par de documentos relevantes/no relevantes. MAP, por otro lado, no se descompone de la misma manera que ROCArea. La principal contribución algorítmica de este artículo es un método eficiente para resolver argmax H para ∆map. Una propiedad útil de ∆map es que es invariante al intercambiar dos documentos con igual relevancia. Por ejemplo, si los documentos da y db son ambos relevantes, entonces intercambiar las posiciones de da y db en cualquier clasificación no afecta a ∆map. Por extensión, ∆map es invariante a cualquier permutación arbitraria de los documentos relevantes entre sí y de los documentos no relevantes entre sí. Sin embargo, esta reorganización afectará la puntuación del discriminante, wT Ψ(x, y). Esto nos lleva a la Observación 1. Observación 1. Considera clasificaciones que estén limitadas por fijar la relevancia en cada posición de la clasificación (por ejemplo, el tercer documento en la clasificación debe ser relevante). Cada clasificación que cumpla con el mismo conjunto de restricciones tendrá el mismo ∆map. Si los documentos relevantes están ordenados por wT φ(x, d) en orden descendente, y los documentos no relevantes también están ordenados de la misma manera por wT φ(x, d), entonces la intercalación de las dos listas ordenadas que cumpla con las restricciones maximizará H para ese conjunto de clasificaciones restringidas. La Observación 1 implica que en la clasificación que maximiza H, los documentos relevantes se ordenarán por wT φ(x, d), y los documentos no relevantes también se ordenarán de la misma manera. Al ordenar primero los documentos relevantes y no relevantes, el problema se simplifica a encontrar la intercalación óptima de dos listas ordenadas. Para el resto de nuestra discusión, asumimos que los documentos relevantes y no relevantes están ordenados por wT φ(x, d) en orden descendente. Para mayor comodidad, también nos referimos a los documentos relevantes como {dx 1 , . . . dx |Cx|} = Cx, y a los documentos no relevantes como {d¯x 1 , . . . d¯x |C¯x|} = C¯x. Definimos δj(i1, i2), con i1 < i2, como el cambio en H desde cuando el documento relevante de mayor rango clasificado después de d¯x j es dx i1 hasta que es dx i2. Para i2 = i1 + 1, tenemos δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5), donde si = wT φ(x, di). El primer término en (5) es el cambio en ∆map cuando el documento relevante i tiene j documentos no relevantes clasificados antes de él, en lugar de j-1. El segundo término es el cambio en la puntuación del discriminante, wT Ψ(x, y), cuando yij cambia de +1 a −1. . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . . Figura 1: Ejemplo para δj(i, i + 1). La Figura 1 proporciona un ejemplo conceptual para δj(i, i + 1). La clasificación inferior difiere de la superior solo cuando d¯x j sube un rango. La diferencia en el valor de H para estas dos clasificaciones es exactamente δj(i, i + 1). Para cualquier i1 < i2, podemos definir δj(i1, i2) como δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) o equivalentemente, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) . Deja que o1, . . . , o|C¯x| codifiquen las posiciones de los documentos no relevantes, donde dx oj es el documento relevante de mayor rango clasificado después del j-ésimo documento no relevante. Debido a la Observación 1, esta codificación identifica de forma única un ranking completo. Podemos recuperar la clasificación como yij = 8 >>>< >>>: 0 si i = j sign(si − sj) si di, dj relevancia igual signo(oj − i − 0.5) si di = dx i , dj = d¯x j signo(j − oi + 0.5) si di = d¯x i , dj = dx j. (7) Ahora podemos reformular H en una nueva función objetivo, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), donde ¯y es la verdadera clasificación (débil). Conceptualmente, H comienza con una clasificación perfecta ¯y y agrega el cambio en H cuando cada documento no relevante sucesivo sube en la clasificación. Luego podemos reformular el problema argmax H como argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) sujeto a o1 ≤ . . . ≤ o|C¯x|. (9) El Algoritmo 2 describe el algoritmo utilizado para resolver la ecuación (8). Conceptualmente, el Algoritmo 2 comienza con un ranking perfecto. Entonces, para cada documento no relevante sucesivo, el algoritmo modifica la solución deslizando ese documento hacia arriba en la clasificación para maximizar localmente H, manteniendo las posiciones de los otros documentos no relevantes constantes. 3.2.1 Prueba de Corrección El Algoritmo 2 es codicioso en el sentido de que encuentra la mejor posición de cada documento no relevante de forma independiente de los otros documentos no relevantes. En otras palabras, el algoritmo maximiza H para cada documento no relevante, d¯x j, Algoritmo 2 Encontrar la Restricción Más Violada (argmax H) para el Algoritmo 1 con ∆map 1: Entrada: w, Cx, C¯x 2: ordenar Cx y C¯x en orden descendente de wT φ(x, d) 3: sx i ← wT φ(x, dx i), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i), i = 1, . . . , |C¯x | 5: para j = 1, . . . , |C¯x | hacer 6: optj ← argmaxk δj(k, |Cx| + 1) 7: fin para 8: codificar ˆy de acuerdo con (7) 9: devolver ˆy sin considerar las posiciones de los otros documentos no relevantes, y así ignora las restricciones de (9). Para que la solución sea factible, el documento no relevante j-ésimo debe ser clasificado después de los primeros j-1 documentos no relevantes, satisfaciendo así opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. Si la solución es factible, entonces claramente resuelve (8). Por lo tanto, basta con demostrar que el Algoritmo 2 cumple con (10). Primero demostramos que δj(·, ·) es monótonamente decreciente en j. Lema 1. Para cualquier 1 ≤ i1 < i2 ≤ |Cx | + 1 y 1 ≤ j < |C¯x |, debe ser el caso que δj+1(i1, i2) ≤ δj(i1, i2). Prueba. Recuerde que tanto δj(i1, i2) como δj+1(i1, i2) son sumas de términos i2 − i1. Mostraremos que cada término en la suma de δj+1(i1, i2) no es mayor que el término correspondiente en δj(i1, i2), o δj+1(k, k + 1) ≤ δj(k, k + 1) para k = i1, . . . , i2 − 1. Cada término en δj(k, k +1) y δj+1(k, k +1) puede ser descompuesto aún más en dos partes (ver (5)). Mostraremos que cada parte de δj+1(k, k + 1) no es mayor que la parte correspondiente en δj(k, k + 1). En otras palabras, demostraremos que tanto j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) como −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) son verdaderos para los valores mencionados de j y k. Es fácil ver que (11) es verdadero observando que para cualquier par de enteros positivos 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1, y eligiendo a = j y b = j + k. La segunda desigualdad (12) se cumple porque el Algoritmo 2 primero ordena d¯x en orden descendente de s¯x, lo que implica s¯x j+1 ≤ s¯x j. Así vemos que cada término en δj+1 no es mayor que el término correspondiente en δj, lo cual completa la prueba. El resultado del Lema 1 conduce directamente a nuestro resultado principal de corrección: Teorema 2. En el Algoritmo 2, los valores calculados de optj satisfacen (10), lo que implica que la solución devuelta por el Algoritmo 2 es factible y, por lo tanto, óptima. Prueba. Demostraremos que optj ≤ optj+1 se cumple para cualquier 1 ≤ j < |C¯x|, implicando así (10). Dado que el Algoritmo 2 calcula optj como optj = argmax k δj(k, |Cx | + 1), (13), entonces por definición de δj (6), para cualquier 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0. Usando el Lema 1, sabemos que δj+1(i, optj) ≤ δj(i, optj) < 0, lo que implica que para cualquier 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0. Supongamos por contradicción que optj+1 < optj. Entonces δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), lo cual contradice (13). Por lo tanto, debe ser el caso que optj ≤ optj+1, lo cual completa la prueba. 3.2.2 Tiempo de ejecución El tiempo de ejecución del Algoritmo 2 se puede dividir en dos partes. La primera parte es la clasificación por wT φ(x, d), lo cual requiere un tiempo de O(n log n), donde n = |Cx | + |C¯x |. La segunda parte calcula cada optj, lo cual requiere un tiempo de O(|Cx| · |C¯x|). Aunque en el peor de los casos esto es O(n2), el número de documentos relevantes, |Cx|, suele ser muy pequeño (por ejemplo, constante con respecto a n), en cuyo caso el tiempo de ejecución para la segunda parte es simplemente O(n). Para la mayoría de los conjuntos de datos del mundo real, el Algoritmo 2 está dominado por la ordenación y tiene una complejidad O(n log n). El Algoritmo 1 está garantizado de detenerse en un número polinómico de iteraciones [19], y cada iteración ejecuta el Algoritmo 2. Prácticamente todos los modelos que funcionaron bien fueron entrenados en un tiempo razonable (generalmente menos de una hora). Una vez que el entrenamiento esté completo, hacer predicciones sobre la consulta x usando la hipótesis resultante h(x|w) solo requiere ordenar por wT φ(x, d). Desarrollamos nuestro software utilizando una interfaz de Python a SVMstruct, ya que el lenguaje Python simplificó en gran medida el proceso de codificación. Para mejorar el rendimiento, es recomendable utilizar la implementación estándar en C de SVMstruct. CONFIGURACIÓN DEL EXPERIMENTO El objetivo principal de nuestros experimentos es evaluar si la optimización directa de MAP conduce a un rendimiento de MAP mejorado en comparación con los métodos convencionales de SVM que optimizan una pérdida sustituta como la precisión o el área bajo la curva ROC. Evaluamos empíricamente nuestro método utilizando dos conjuntos de consultas de la TREC Web Track, uno de TREC 9 y otro de TREC 10 (temas 451-500 y 501-550), ambos de los cuales utilizaron el corpus WT10g. Para cada consulta, TREC proporciona las evaluaciones de relevancia de los documentos. Generamos nuestras características utilizando las puntuaciones de las funciones de recuperación existentes en estas consultas. Si bien nuestro método es agnóstico al significado de las características, elegimos utilizar funciones de recuperación existentes como una forma simple pero efectiva de adquirir características útiles. Por lo tanto, nuestros experimentos de estadísticas de conjuntos de datos básicos esencialmente prueban la capacidad de nuestros métodos para volver a clasificar los documentos altamente clasificados (por ejemplo, volver a combinar las puntuaciones de las funciones de recuperación) para mejorar el MAP. Comparamos nuestro método con las mejores funciones de recuperación entrenadas (en adelante, funciones base), así como con los métodos SVM propuestos anteriormente. Comparar con las mejores funciones base pone a prueba la capacidad de nuestros métodos para aprender una combinación útil. Comparar con métodos SVM anteriores nos permite probar si optimizar directamente para el MAP (en lugar de precisión o área bajo la curva ROC) logra una puntuación de MAP más alta en la práctica. El resto de esta sección describe las funciones base y el método de generación de características en detalle. 4.1 Elección de Funciones de Recuperación Elegimos dos conjuntos de funciones base para nuestros experimentos. Para el primer conjunto, generamos tres índices sobre el corpus WT10g utilizando Indri5. El primer índice fue generado utilizando la configuración predeterminada, el segundo utilizó Porter-stemming, y el último utilizó Porter-stemming y las palabras vacías predeterminadas de Indris. Para TREC 9 y TREC 10, utilizamos la parte de descripción de cada consulta y puntuamos los documentos utilizando cinco de los métodos de recuperación integrados en Indri, que son Similitud Coseno, TFIDF, Okapi, Modelo de Lenguaje con Prior de Dirichlet y Modelo de Lenguaje con Prior de Jelinek-Mercer. Todos los parámetros se mantuvieron en sus valores predeterminados. Calculamos las puntuaciones de estos cinco métodos de recuperación sobre los tres índices, dando un total de 15 funciones base. Para cada consulta, consideramos las puntuaciones de los documentos encontrados en la unión de los mejores 1000 documentos de cada función base. Para nuestro segundo conjunto de funciones base, utilizamos puntuaciones de las presentaciones de la pista web TREC 9 [8] y TREC 10 [9]. Utilizamos solo las presentaciones no manuales y no breves de ambos años. Para TREC 9 y TREC 10, hubo 53 y 18 envíos de este tipo, respectivamente. Una presentación típica contenía puntajes de sus 1000 documentos principales. b ca wT φ(x,d) f(d|x) Figura 2: Ejemplo de Agrupación de Características 4.2 Generación de Características Para generar ejemplos de entrada para nuestro método, se debe proporcionar una instancia concreta de φ. Para cada documento d puntuado por un conjunto de funciones de recuperación F en la consulta x, generamos las características como un vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf, donde f(d|x) denota la puntuación que la función de recuperación f asigna al documento d para la consulta x, y cada Kf es un conjunto de valores reales. Desde un nivel alto, estamos expresando la puntuación de cada función de recuperación utilizando |Kf | + 1 contenedores. Dado que estamos utilizando núcleos lineales, se puede pensar en el problema de aprendizaje como encontrar una buena combinación de piezas constantes de los puntajes de las funciones de recuperación. La Figura 2 muestra un ejemplo de nuestro método de mapeo de características. En este ejemplo tenemos una única característica F = {f}. Aquí, Kf = {a, b, c}, y el vector de pesos es w = wa, wb, wc. Para cualquier documento d y consulta x, tenemos wT φ(x, d) = 8 >>< >>: 0 si f(d|x) < a wa si a ≤ f(d|x) < b wa + wb si b ≤ f(d|x) < c wa + wb + wc si c ≤ f(d|x) . Esto se expresa cualitativamente en la Figura 2, donde wa y wb son positivos, y wc es negativo. Realizamos nuestros experimentos principales utilizando cuatro opciones de F: el conjunto de las funciones de recuperación de Indri mencionadas anteriormente para TREC 9 y TREC 10, y las presentaciones de la pista web para TREC 9 y TREC 10. Para cada F y cada función f ∈ F, elegimos 50 valores para Kf que estuvieran razonablemente espaciados y capturaran la región sensible de f. Utilizando las cuatro opciones de F, generamos cuatro conjuntos de datos para nuestros experimentos principales. La Tabla 5 contiene estadísticas de los conjuntos de datos generados. Hay muchas formas de generar características, y no estamos abogando por nuestro método sobre los demás. Esto fue simplemente un medio eficiente para normalizar las salidas de diferentes funciones y permitir un modelo más expresivo. EXPERIMENTOS Para cada conjunto de datos en la Tabla 5, realizamos 50 pruebas. Para cada prueba, entrenamos con 10 consultas seleccionadas al azar, y seleccionamos otras 5 consultas al azar para un conjunto de validación. Los modelos fueron entrenados utilizando una amplia gama de valores de C. El modelo que tuvo mejor rendimiento en el conjunto de validación fue seleccionado y probado en las 35 consultas restantes. Todas las consultas fueron seleccionadas para estar en los conjuntos de entrenamiento, validación y prueba la misma cantidad de veces. Utilizando esta configuración, realizamos los mismos experimentos mientras usábamos nuestro método (mapa SVM∆), un SVM optimizando para ROCArea (SVM∆ roc) [13], y un SVM de clasificación convencional (SVMacc) [20]. Todos los métodos de SVM utilizaron un kernel lineal. Informamos sobre el rendimiento promedio de todos los modelos en las 50 pruebas. 5.1 Comparación con Funciones Base Al analizar nuestros resultados, la primera pregunta a responder es, ¿puede SVM∆ map aprender un modelo que supere al mejor modelo base TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.290 - 0.287Mejor Func. 0.280 28/22 0.283 29/21 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 36/14 ** Tabla 7: Comparación con Envíos TREC TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288Mejor Func. 0.280 27/23 0.283 31/19 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 35/15 ** Tabla 8: Comparación con Funciones de Envíos TREC (sin el mejor) La Tabla 6 presenta la comparación del mapa SVM∆ con las mejores funciones base de Indri. Cada grupo de columnas contiene el rendimiento del MAP macro-promediado de SVM∆ map o una función base. Las columnas W/L muestran el número de consultas donde SVM∆ map logró un puntaje MAP más alto. Se realizaron pruebas de significancia utilizando la prueba de rango con signo de Wilcoxon de dos colas. Dos estrellas indican un nivel de significancia de 0.95. Todas las tablas que muestran nuestros resultados experimentales están estructuradas de manera idéntica. Aquí encontramos que SVM∆ mapea significativamente mejor que las mejores funciones base. La Tabla 7 muestra la comparación cuando se entrena con las presentaciones de TREC. Si bien logra una puntuación de MAP más alta que las mejores funciones base, la diferencia de rendimiento entre SVM∆ y las funciones base no es significativa. Dado que muchas de estas presentaciones utilizan funciones de puntuación cuidadosamente diseñadas para lograr un alto MAP, es posible que las presentaciones con mejor rendimiento utilicen técnicas que engloben las técnicas de las otras presentaciones. Como resultado, el mapa SVM∆ no sería capaz de aprender una hipótesis que pueda superar significativamente la mejor presentación. Por lo tanto, realizamos los mismos experimentos utilizando un conjunto de datos modificado en el que se eliminaron las características calculadas utilizando la mejor presentación. La tabla 8 muestra los resultados (ten en cuenta que aún estamos comparando con la mejor presentación, aunque no la estamos utilizando para el entrenamiento). Observa que si bien el rendimiento del SVM∆ map se degradó ligeramente, aún era comparable con el de la mejor presentación. 5.2 Comparación con Métodos SVM Anteriores La siguiente pregunta a responder es, ¿produce el SVM∆ map puntajes MAP más altos que los métodos SVM anteriores? Las tablas 9 y 10 presentan los resultados de SVM∆ map, SVM∆ roc y SVMacc cuando se entrenan con las funciones de recuperación de Indri y las presentaciones de TREC, respectivamente. La Tabla 11 contiene los resultados correspondientes cuando se entrena con las presentaciones de TREC sin la mejor presentación. Para empezar, nuestros resultados indican que SVMacc no fue competitivo con SVM∆ map y SVM∆ roc, y a veces tuvo un rendimiento notablemente inferior. Por lo tanto, probamos varios enfoques para mejorar el rendimiento de SVMacc. 5.2.1 Métodos alternativos de SVMacc Un problema que puede causar que SVMacc tenga un rendimiento deficiente es el desequilibrio severo entre documentos relevantes y no relevantes. La gran mayoría de los documentos no son relevantes. SVMacc2 aborda este problema asignando una penalización mayor a los errores de falsos negativos. Para cada conjunto de datos, la proporción de las penalizaciones por falsos negativos a falsos positivos es igual a la proporción entre el número de documentos no relevantes y relevantes en ese conjunto de datos. Las tablas 9, 10 y 11 indican que SVMacc2 sigue teniendo un rendimiento significativamente peor que SVM∆ map. Otro posible problema es que SVMacc intenta encontrar solo un umbral discriminatorio b que sea invariable a la consulta. Puede ser que diferentes consultas requieran diferentes valores de b. Tener el método de aprendizaje intentando encontrar un buen valor de b (cuando no existe) puede ser perjudicial. Tomamos dos enfoques para abordar este problema. El primer método, SVMacc3, convierte las puntuaciones de la función de recuperación en percentiles. Por ejemplo, para el documento d, la consulta q y la función de recuperación f, si la puntuación f(d|q) se encuentra en el 90% superior de las puntuaciones f(·|q) para la consulta q, entonces la puntuación convertida es f(d|q) = 0.9. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Las tablas 9, 10 y 11 muestran que el rendimiento de SVMacc3 tampoco fue competitivo con SVM∆ map. El segundo método, SVMacc4, normaliza las puntuaciones dadas por f para cada consulta. Por ejemplo, suponga para la consulta q que f produce puntuaciones en el rango de 0.2 a 0.7. Entonces, para el documento d, si f(d|q) = 0.6, la puntuación convertida sería f(d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Nuevamente, las Tablas 9, 10 y 11 muestran que SVMacc4 no fue competitivo con SVM∆ map 5.2.2 MAP vs ROCArea. SVM∆ roc tuvo un rendimiento mucho mejor que SVMacc en nuestros experimentos. Cuando se entrenó con las funciones de recuperación de Indri (ver Tabla 9), el rendimiento de SVM∆ roc fue ligeramente, aunque no significativamente, peor que el rendimiento de SVM∆ map. Sin embargo, la Tabla 10 muestra que el mapa SVM∆ superó significativamente al roc SVM∆ cuando se entrenó con las presentaciones de TREC. La tabla 11 muestra el rendimiento de los modelos cuando se entrenan con las presentaciones de TREC y se elimina la mejor presentación. El rendimiento de la mayoría de los modelos se degradó ligeramente, con SVM∆ map aún teniendo el mejor rendimiento. TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288 SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Tabla 11: Entrenado en TREC Subm. (sin Mejor) 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado un método SVM que optimiza directamente el MAP. Proporciona un enfoque basado en principios y evita heurísticas difíciles de controlar. Formulamos el problema de optimización y presentamos un algoritmo que encuentra la solución de manera demostrable en tiempo polinómico. Hemos demostrado empíricamente que nuestro método es generalmente superior o competitivo con los métodos convencionales de SVM. Nuestro nuevo método hace que sea conceptualmente tan fácil optimizar SVMs para MAP como anteriormente solo era posible para Precisión y Área bajo la curva ROC. El costo computacional para el entrenamiento es muy razonable en la práctica. Dado que otros métodos suelen requerir ajustar múltiples heurísticas, también esperamos entrenar menos modelos antes de encontrar uno que logre un buen rendimiento. El marco de aprendizaje utilizado por nuestro método es bastante general. Una extensión natural de este marco sería desarrollar métodos para optimizar otras medidas importantes de IR, como la Ganancia Acumulada Normalizada Descontada [2, 3, 4, 12] y la Reciprocidad Media de Rango. 7. AGRADECIMIENTOS Este trabajo fue financiado bajo el Premio NSF IIS-0412894, el Premio NSF CAREER 0237381 y un obsequio de Yahoo! Investigación. El tercer autor también fue parcialmente apoyado por una Beca de Investigación de Microsoft. 8. REFERENCIAS [1] B. T. Bartell, G. W. Cottrell y R. K. Belew. Combinación automática de múltiples sistemas de recuperación clasificados. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2005. [3] C. J. C. Burges, R. Ragno y Q. Lo. Aprendizaje para clasificar con funciones de costo no suaves. En Actas de la Conferencia Internacional sobre Avances en Sistemas de Información Neural (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang y H.-W. Hon. Adaptando el SVM de clasificación para la recuperación de documentos. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [5] B. Carterette y D. Petkova. Aprendiendo un ranking a partir de preferencias por pares. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew y A. Ksikes. Selección de conjunto de bibliotecas de modelos. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [7] J. Davis y M. Goadrich. La relación entre las curvas de precisión-recall y ROC. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2006. [8] D. Hawking. Resumen de la pista web TREC-9. En Actas de TREC-2000, 2000. [9] D. Hawking y N. Craswell. Resumen de la pista web TREC-2001. En Actas de TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel y K. Obermayer. Límites de rango de margen amplio para regresión ordinal. Avances en clasificadores de márgenes amplios, 2000. [11] A. Herschtal y B. Raskutti. Optimizando el área bajo la curva ROC utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [12] K. Jarvelin y J. Kekalainen. Métodos de evaluación para recuperar documentos altamente relevantes. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2000. [13] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), páginas 377-384, Nueva York, NY, EE. UU., 2005. ACM Press. [14] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), páginas 111-119, 2001. [15] Y. Lin, Y. Lee y G. Wahba. Máquinas de vectores de soporte para clasificación en situaciones no estándar. Aprendizaje automático, 46:191-202, 2002. [16] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [17] K. Morik, P. Brockhausen y T. Joachims. Combinando el aprendizaje estadístico con un enfoque basado en el conocimiento. En Actas de la Conferencia Internacional sobre Aprendizaje Automático, 1999. [18] S. Robertson. El principio de clasificación de probabilidad en la revista IR de documentación. Revista de Documentación, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims y Y. Altun. Métodos de margen amplio para variables de salida estructuradas e interdependientes. Revista de Investigación en Aprendizaje Automático (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik. Teoría del Aprendizaje Estadístico. Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz. \n\nWiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer y R. Wolniewicz. Optimizando el rendimiento del clasificador mediante la aproximación a la estadística de Wilcoxon-Mann-Witney. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2003. ",
            "candidates": [],
            "error": [
                [
                    "una solución óptima global",
                    "solución óptima",
                    "solución óptima",
                    "solución óptima"
                ]
            ]
        },
        "relaxation of map": {
            "translated_key": "relajación de map",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT Machine learning is commonly used to improve ranked retrieval systems.",
                "Due to computational difficulties, few learning techniques have been developed to directly optimize for mean average precision (MAP), despite its widespread use in evaluating such systems.",
                "Existing approaches optimizing MAP either do not find a globally optimal solution, or are computationally expensive.",
                "In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward <br>relaxation of map</br>.",
                "We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora (WT10g), comparing against SVMs optimized for accuracy and ROCArea.",
                "In most cases we show our method to produce statistically significant improvements in MAP scores.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval Models General Terms Algorithm, Theory, Experimentation 1.",
                "INTRODUCTION State of the art information retrieval systems commonly use machine learning techniques to learn ranking functions.",
                "However, most current approaches do not optimize for the evaluation measure most often used, namely Mean Average Precision (MAP).",
                "Instead, current algorithms tend to take one of two general approaches.",
                "The first approach is to learn a model that estimates the probability of a document being relevant given a query (e.g., [18, 14]).",
                "If solved effectively, the ranking with best MAP performance can easily be derived from the probabilities of relevance.",
                "However, achieving high MAP only requires finding a good ordering of the documents.",
                "As a result, finding good probabilities requires solving a more difficult problem than necessary, likely requiring more training data to achieve the same MAP performance.",
                "The second common approach is to learn a function that maximizes a surrogate measure.",
                "Performance measures optimized include accuracy [17, 15], ROCArea [1, 5, 10, 11, 13, 21] or modifications of ROCArea [4], and NDCG [2, 3].",
                "Learning a model to optimize for such measures might result in suboptimal MAP performance.",
                "In fact, although some previous systems have obtained good MAP performance, it is known that neither achieving optimal accuracy nor ROCArea can guarantee optimal MAP performance[7].",
                "In this paper, we present a general approach for learning ranking functions that maximize MAP performance.",
                "Specifically, we present an SVM algorithm that globally optimizes a hinge-loss <br>relaxation of map</br>.",
                "This approach simplifies the process of obtaining ranking functions with high MAP performance by avoiding additional intermediate steps and heuristics.",
                "The new algorithm also makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for accuracy and ROCArea.",
                "In contrast to recent work directly optimizing for MAP performance by Metzler & Croft [16] and Caruana et al. [6], our technique is computationally efficient while finding a globally optimal solution.",
                "Like [6, 16], our method learns a linear model, but is much more efficient in practice and, unlike [16], can handle many thousands of features.",
                "We now describe the algorithm in detail and provide proof of correctness.",
                "Following this, we provide an analysis of running time.",
                "We finish with empirical results from experiments on the TREC 9 and TREC 10 Web Track corpus.",
                "We have also developed a software package implementing our algorithm that is available for public use1 . 2.",
                "THE LEARNING PROBLEM Following the standard machine learning setup, our goal is to learn a function h : X → Y between an input space X (all possible queries) and output space Y (rankings over a corpus).",
                "In order to quantify the quality of a prediction, ˆy = h(x), we will consider a loss function ∆ : Y × Y → . ∆(y, ˆy) quantifies the penalty for making prediction ˆy if the correct output is y.",
                "The loss function allows us to incorporate specific performance measures, which we will exploit 1 http://svmrank.yisongyue.com for optimizing MAP.",
                "We restrict ourselves to the supervised learning scenario, where input/output pairs (x, y) are available for training and are assumed to come from some fixed distribution P(x, y).",
                "The goal is to find a function h such that the risk (i.e., expected loss), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), is minimized.",
                "Of course, P(x, y) is unknown.",
                "But given a finite set of training pairs, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, the performance of h on S can be measured by the empirical risk, R∆ S (h) = 1 n nX i=1 ∆(yi, h(xi)).",
                "In the case of learning a ranked retrieval function, X denotes a space of queries, and Y the space of (possibly weak) rankings over some corpus of documents C = {d1, . . . ,d|C|}.",
                "We can define average precision loss as ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), where rank(y) is a vector of the rank values of each document in C. For example, for a corpus of two documents, {d1, d2}, with d1 having higher rank than d2, rank(y ) = (1, 0).",
                "We assume true rankings have two rank values, where relevant documents have rank value 1 and non-relevant documents rank value 0.",
                "We further assume that all predicted rankings are complete rankings (no ties).",
                "Let p = rank(y) and ˆp = rank(ˆy).",
                "The average precision score is defined as MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, where rel = |{i : pi = 1}| is the number of relevant documents, and Prec@j is the percentage of relevant documents in the top j documents in predicted ranking ˆy.",
                "MAP is the mean of the average precision scores of a group of queries. 2.1 MAP vs ROCArea Most learning algorithms optimize for accuracy or ROCArea.",
                "While optimizing for these measures might achieve good MAP performance, we use two simple examples to show it can also be suboptimal in terms of MAP.",
                "ROCArea assigns equal penalty to each misordering of a relevant/non-relevant pair.",
                "In contrast, MAP assigns greater penalties to misorderings higher up in the predicted ranking.",
                "Using our notation, ROCArea can be defined as ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], where p is the true (weak) ranking, ˆp is the predicted ranking, and 1[b] is the indicator function conditioned on b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Table 1: Toy Example and Models Suppose we have a hypothesis space with only two hypothesis functions, h1 and h2, as shown in Table 1.",
                "These two hypotheses predict a ranking for query x over a corpus of eight documents.",
                "Hypothesis MAP ROCArea h1(x) 0.59 0.47 h2(x) 0.51 0.53 Table 2: Performance of Toy Models Table 2 shows the MAP and ROCArea scores of h1 and h2.",
                "Here, a learning method which optimizes for ROCArea would choose h2 since that results in a higher ROCArea score, but this yields a suboptimal MAP score. 2.2 MAP vs Accuracy Using a very similar example, we now demonstrate how optimizing for accuracy might result in suboptimal MAP.",
                "Models which optimize for accuracy are not directly concerned with the ranking.",
                "Instead, they learn a threshold such that documents scoring higher than the threshold can be classified as relevant and documents scoring lower as nonrelevant.",
                "Doc ID 1 2 3 4 5 6 7 8 9 10 11 p 1 0 0 0 0 1 1 1 1 0 0 rank(h1(x)) 11 10 9 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 9 10 11 Table 3: Toy Example and Models We consider again a hypothesis space with two hypotheses.",
                "Table 3 shows the predictions of the two hypotheses on a single query x. Hypothesis MAP Best Acc. h1(q) 0.70 0.64 h2(q) 0.64 0.73 Table 4: Performance of Toy Models Table 4 shows the MAP and best accuracy scores of h1(q) and h2(q).",
                "The best accuracy refers to the highest achievable accuracy on that ranking when considering all possible thresholds.",
                "For instance, with h1(q), a threshold between documents 1 and 2 gives 4 errors (documents 6-9 incorrectly classified as non-relevant), yielding an accuracy of 0.64.",
                "Similarly, with h2(q), a threshold between documents 5 and 6 gives 3 errors (documents 10-11 incorrectly classified as relevant, and document 1 as non-relevant), yielding an accuracy of 0.73.",
                "A learning method which optimizes for accuracy would choose h2 since that results in a higher accuracy score, but this yields a suboptimal MAP score. 3.",
                "OPTIMIZING AVERAGE PRECISION We build upon the approach used by [13] for optimizing ROCArea.",
                "Unlike ROCArea, however, MAP does not decompose linearly in the examples and requires a substantially extended algorithm, which we describe in this section.",
                "Recall that the true ranking is a weak ranking with two rank values (relevant and non-relevant).",
                "Let Cx and C¯x denote the set of relevant and non-relevant documents of C for query x, respectively.",
                "We focus on functions which are parametrized by a weight vector w, and thus wish to find w to minimize the empirical risk, R∆ S (w) ≡ R∆ S (h(·; w)).",
                "Our approach is to learn a discriminant function F : X × Y → over input-output pairs.",
                "Given query x, we can derive a prediction by finding the ranking y that maximizes the discriminant function: h(x; w) = argmax y∈Y F(x, y; w). (1) We assume F to be linear in some combined feature representation of inputs and outputs Ψ(x, y) ∈ RN , i.e., F(x, y; w) = wT Ψ(x, y). (2) The combined feature function we use is Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))] , where φ : X × C → N is a feature mapping function from a query/document pair to a point in N dimensional space2 .",
                "We represent rankings as a matrix of pairwise orderings, Y ⊂ {−1, 0, +1}|C|×|C| .",
                "For any y ∈ Y, yij = +1 if di is ranked ahead of dj, and yij = −1 if dj is ranked ahead of di, and yij = 0 if di and dj have equal rank.",
                "We consider only matrices which correspond to valid rankings (i.e, obeying antisymmetry and transitivity).",
                "Intuitively, Ψ is a summation over the vector differences of all relevant/non-relevant document pairings.",
                "Since we assume predicted rankings to be complete rankings, yij is either +1 or −1 (never 0).",
                "Given a learned weight vector w, predicting a ranking (i.e. solving equation (1)) given query x reduces to picking each yij to maximize wT Ψ(x, y).",
                "As is also discussed in [13], this is attained by sorting the documents by wT φ(x, d) in descending order.",
                "We will discuss later the choices of φ we used for our experiments. 3.1 Structural SVMs The above formulation is very similar to learning a straightforward linear model while training on the pairwise difference of relevant/non-relevant document pairings.",
                "Many SVM-based approaches optimize over these pairwise differences (e.g., [5, 10, 13, 4]), although these methods do not optimize for MAP during training.",
                "Previously, it was not clear how to incorporate non-linear multivariate loss functions such as MAP loss directly into global optimization problems such as SVM training.",
                "We now present a method based on structural SVMs [19] to address this problem.",
                "We use the structural SVM formulation, presented in Optimization Problem 1, to learn a w ∈ RN .",
                "Optimization Problem 1. (Structural SVM) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) The objective function to be minimized (3) is a tradeoff between model complexity, w 2 , and a hinge loss <br>relaxation of map</br> loss, P ξi.",
                "As is usual in SVM training, C is a 2 For example, one dimension might be the number of times the query words appear in the document.",
                "Algorithm 1 Cutting plane algorithm for solving OP 1 within tolerance . 1: Input: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ for all i = 1, . . . , n 3: repeat 4: for i = 1, . . . , n do 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: compute ˆy = argmaxy∈Y H(y; w) 7: compute ξi = max{0, maxy∈Wi H(y; w)} 8: if H(ˆy; w) > ξi + then 9: Wi ← Wi ∪ {ˆy} 10: w ← optimize (3) over W = S i Wi 11: end if 12: end for 13: until no Wi has changed during iteration parameter that controls this tradeoff and can be tuned to achieve good performance in different training tasks.",
                "For each (xi, yi) in the training set, a set of constraints of the form in equation (4) is added to the optimization problem.",
                "Note that wT Ψ(x, y) is exactly our discriminant function F(x, y; w) (see equation (2)).",
                "During prediction, our model chooses the ranking which maximizes the discriminant (1).",
                "If the discriminant value for an incorrect ranking y is greater than for the true ranking yi (e.g., F(xi, y; w) > F(xi, yi; w)), then corresponding slack variable, ξi, must be at least ∆(yi, y) for that constraint to be satisfied.",
                "Therefore, the sum of slacks, P ξi, upper bounds the MAP loss.",
                "This is stated formally in Proposition 1.",
                "Proposition 1.",
                "Let ξ∗ (w) be the optimal solution of the slack variables for OP 1 for a given weight vector w. Then 1 n Pn i=1 ξi is an upper bound on the empirical risk R∆ S (w). (see [19] for proof) Proposition 1 shows that OP 1 learns a ranking function that optimizes an upper bound on MAP error on the training set.",
                "Unfortunately there is a problem: a constraint is required for every possible wrong output y, and the number of possible wrong outputs is exponential in the size of C. Fortunately, we may employ Algorithm 1 to solve OP 1.",
                "Algorithm 1 is a cutting plane algorithm, iteratively introducing constraints until we have solved the original problem within a desired tolerance [19].",
                "The algorithm starts with no constraints, and iteratively finds for each example (xi, yi) the output ˆy associated with the most violated constraint.",
                "If the corresponding constraint is violated by more than we introduce ˆy into the working set Wi of active constraints for example i, and re-solve (3) using the updated W. It can be shown that Algorithm 1s outer loop is guaranteed to halt within a polynomial number of iterations for any desired precision .",
                "Theorem 1.",
                "Let ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y) , ¯∆ = maxi maxy ∆(yi, y), and for any > 0, Algorithm 1 terminates after adding at most max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff constraints to the working set W. (see [19] for proof) However, within the inner loop of this algorithm we have to compute argmaxy∈Y H(y; w), where H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), or equivalently, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), since wT Ψ(xi, yi) is constant with respect to y.",
                "Though closely related to the classification procedure, this has the substantial complication that we must contend with the additional ∆(yi, y) term.",
                "Without the ability to efficiently find the most violated constraint (i.e., solve argmaxy∈Y H(y, w)), the constraint generation procedure is not tractable. 3.2 Finding the Most Violated Constraint Using OP 1 and optimizing to ROCArea loss (∆roc), the problem of finding the most violated constraint, or solving argmaxy∈Y H(y, w) (henceforth argmax H), is addressed in [13].",
                "Solving argmax H for ∆map is more difficult.",
                "This is primarily because ROCArea decomposes nicely into a sum of scores computed independently on each relative ordering of a relevant/non-relevant document pair.",
                "MAP, on the other hand, does not decompose in the same way as ROCArea.",
                "The main algorithmic contribution of this paper is an efficient method for solving argmax H for ∆map.",
                "One useful property of ∆map is that it is invariant to swapping two documents with equal relevance.",
                "For example, if documents da and db are both relevant, then swapping the positions of da and db in any ranking does not affect ∆map.",
                "By extension, ∆map is invariant to any arbitrary permutation of the relevant documents amongst themselves and of the non-relevant documents amongst themselves.",
                "However, this reshuﬄing will affect the discriminant score, wT Ψ(x, y).",
                "This leads us to Observation 1.",
                "Observation 1.",
                "Consider rankings which are constrained by fixing the relevance at each position in the ranking (e.g., the 3rd document in the ranking must be relevant).",
                "Every ranking which satisfies the same set of constraints will have the same ∆map.",
                "If the relevant documents are sorted by wT φ(x, d) in descending order, and the non-relevant documents are likewise sorted by wT φ(x, d), then the interleaving of the two sorted lists which satisfies the constraints will maximize H for that constrained set of rankings.",
                "Observation 1 implies that in the ranking which maximizes H, the relevant documents will be sorted by wT φ(x, d), and the non-relevant documents will also be sorted likewise.",
                "By first sorting the relevant and non-relevant documents, the problem is simplified to finding the optimal interleaving of two sorted lists.",
                "For the rest of our discussion, we assume that the relevant documents and non-relevant documents are both sorted by descending wT φ(x, d).",
                "For convenience, we also refer to relevant documents as {dx 1 , . . . dx |Cx|} = Cx , and non-relevant documents as {d¯x 1 , . . . d¯x |C¯x|} = C¯x .",
                "We define δj(i1, i2), with i1 < i2, as the change in H from when the highest ranked relevant document ranked after d¯x j is dx i1 to when it is dx i2 .",
                "For i2 = i1 + 1, we have δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5) where si = wT φ(x, di).",
                "The first term in (5) is the change in ∆map when the ith relevant document has j non-relevant documents ranked before it, as opposed to j −1.",
                "The second term is the change in the discriminant score, wT Ψ(x, y), when yij changes from +1 to −1. . . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . .",
                "Figure 1: Example for δj(i, i + 1) Figure 1 gives a conceptual example for δj(i, i + 1).",
                "The bottom ranking differs from the top only where d¯x j slides up one rank.",
                "The difference in the value of H for these two rankings is exactly δj(i, i + 1).",
                "For any i1 < i2, we can then define δj(i1, i2) as δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) or equivalently, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) .",
                "Let o1, . . . , o|C¯x| encode the positions of the non-relevant documents, where dx oj is the highest ranked relevant document ranked after the jth non-relevant document.",
                "Due to Observation 1, this encoding uniquely identifies a complete ranking.",
                "We can recover the ranking as yij = 8 >>>< >>>: 0 if i = j sign(si − sj) if di, dj equal relevance sign(oj − i − 0.5) if di = dx i , dj = d¯x j sign(j − oi + 0.5) if di = d¯x i , dj = dx j . (7) We can now reformulate H into a new objective function, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), where ¯y is the true (weak) ranking.",
                "Conceptually H starts with a perfect ranking ¯y, and adds the change in H when each successive non-relevant document slides up the ranking.",
                "We can then reformulate the argmax H problem as argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) s.t. o1 ≤ . . . ≤ o|C¯x|. (9) Algorithm 2 describes the algorithm used to solve equation (8).",
                "Conceptually, Algorithm 2 starts with a perfect ranking.",
                "Then for each successive non-relevant document, the algorithm modifies the solution by sliding that document up the ranking to locally maximize H while keeping the positions of the other non-relevant documents constant. 3.2.1 Proof of Correctness Algorithm 2 is greedy in the sense that it finds the best position of each non-relevant document independently from the other non-relevant documents.",
                "In other words, the algorithm maximizes H for each non-relevant document, d¯x j , Algorithm 2 Finding the Most Violated Constraint (argmax H) for Algorithm 1 with ∆map 1: Input: w, Cx , C¯x 2: sort Cx and C¯x in descending order of wT φ(x, d) 3: sx i ← wT φ(x, dx i ), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i ), i = 1, . . . , |C¯x | 5: for j = 1, . . . , |C¯x | do 6: optj ← argmaxk δj(k, |Cx | + 1) 7: end for 8: encode ˆy according to (7) 9: return ˆy without considering the positions of the other non-relevant documents, and thus ignores the constraints of (9).",
                "In order for the solution to be feasible, the jth non-relevant document must be ranked after the first j − 1 non-relevant documents, thus satisfying opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. (10) If the solution is feasible, the it clearly solves (8).",
                "Therefore, it suffices to prove that Algorithm 2 satisfies (10).",
                "We first prove that δj(·, ·) is monotonically decreasing in j. Lemma 1.",
                "For any 1 ≤ i1 < i2 ≤ |Cx | + 1 and 1 ≤ j < |C¯x |, it must be the case that δj+1(i1, i2) ≤ δj(i1, i2).",
                "Proof.",
                "Recall from (6) that both δj(i1, i2) and δj+1(i1, i2) are summations of i2 − i1 terms.",
                "We will show that each term in the summation of δj+1(i1, i2) is no greater than the corresponding term in δj(i1, i2), or δj+1(k, k + 1) ≤ δj(k, k + 1) for k = i1, . . . , i2 − 1.",
                "Each term in δj(k, k +1) and δj+1(k, k +1) can be further decomposed into two parts (see (5)).",
                "We will show that each part of δj+1(k, k + 1) is no greater than the corresponding part in δj(k, k + 1).",
                "In other words, we will show that both j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) and −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) are true for the aforementioned values of j and k. It is easy to see that (11) is true by observing that for any two positive integers 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1 , and choosing a = j and b = j + k. The second inequality (12) holds because Algorithm 2 first sorts d¯x in descending order of s¯x , implying s¯x j+1 ≤ s¯x j .",
                "Thus we see that each term in δj+1 is no greater than the corresponding term in δj, which completes the proof.",
                "The result of Lemma 1 leads directly to our main correctness result: Theorem 2.",
                "In Algorithm 2, the computed values of optj satisfy (10), implying that the solution returned by Algorithm 2 is feasible and thus optimal.",
                "Proof.",
                "We will prove that optj ≤ optj+1 holds for any 1 ≤ j < |C¯x |, thus implying (10).",
                "Since Algorithm 2 computes optj as optj = argmax k δj(k, |Cx | + 1), (13) then by definition of δj (6), for any 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0.",
                "Using Lemma 1, we know that δj+1(i, optj) ≤ δj(i, optj) < 0, which implies that for any 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0.",
                "Suppose for contradiction that optj+1 < optj.",
                "Then δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), which contradicts (13).",
                "Therefore, it must be the case that optj ≤ optj+1, which completes the proof. 3.2.2 Running Time The running time of Algorithm 2 can be split into two parts.",
                "The first part is the sort by wT φ(x, d), which requires O(n log n) time, where n = |Cx | + |C¯x |.",
                "The second part computes each optj, which requires O(|Cx | · |C¯x |) time.",
                "Though in the worst case this is O(n2 ), the number of relevant documents, |Cx |, is often very small (e.g., constant with respect to n), in which case the running time for the second part is simply O(n).",
                "For most real-world datasets, Algorithm 2 is dominated by the sort and has complexity O(n log n).",
                "Algorithm 1 is guaranteed to halt in a polynomial number of iterations [19], and each iteration runs Algorithm 2.",
                "Virtually all well-performing models were trained in a reasonable amount of time (usually less than one hour).",
                "Once training is complete, making predictions on query x using the resulting hypothesis h(x|w) requires only sorting by wT φ(x, d).",
                "We developed our software using a Python interface3 to SVMstruct , since the Python language greatly simplified the coding process.",
                "To improve performance, it is advisable to use the standard C implementation4 of SVMstruct . 4.",
                "EXPERIMENT SETUP The main goal of our experiments is to evaluate whether directly optimizing MAP leads to improved MAP performance compared to conventional SVM methods that optimize a substitute loss such as accuracy or ROCArea.",
                "We empirically evaluate our method using two sets of TREC Web Track queries, one each from TREC 9 and TREC 10 (topics 451-500 and 501-550), both of which used the WT10g corpus.",
                "For each query, TREC provides the relevance judgments of the documents.",
                "We generated our features using the scores of existing retrieval functions on these queries.",
                "While our method is agnostic to the meaning of the features, we chose to use existing retrieval functions as a simple yet effective way of acquiring useful features.",
                "As such, our 3 http://www.cs.cornell.edu/~tomf/svmpython/ 4 http://svmlight.joachims.org/svm_struct.html Dataset Base Funcs Features TREC 9 Indri 15 750 TREC 10 Indri 15 750 TREC 9 Submissions 53 2650 TREC 10 Submissions 18 900 Table 5: Dataset Statistics experiments essentially test our methods ability to re-rank the highly ranked documents (e.g., re-combine the scores of the retrieval functions) to improve MAP.",
                "We compare our method against the best retrieval functions trained on (henceforth base functions), as well as against previously proposed SVM methods.",
                "Comparing with the best base functions tests our methods ability to learn a useful combination.",
                "Comparing with previous SVM methods allows us to test whether optimizing directly for MAP (as opposed to accuracy or ROCArea) achieves a higher MAP score in practice.",
                "The rest of this section describes the base functions and the feature generation method in detail. 4.1 Choosing Retrieval Functions We chose two sets of base functions for our experiments.",
                "For the first set, we generated three indices over the WT10g corpus using Indri5 .",
                "The first index was generated using default settings, the second used Porter-stemming, and the last used Porter-stemming and Indris default stopwords.",
                "For both TREC 9 and TREC 10, we used the description portion of each query and scored the documents using five of Indris built-in retrieval methods, which are Cosine Similarity, TFIDF, Okapi, Language Model with Dirichlet Prior, and Language Model with Jelinek-Mercer Prior.",
                "All parameters were kept as their defaults.",
                "We computed the scores of these five retrieval methods over the three indices, giving 15 base functions in total.",
                "For each query, we considered the scores of documents found in the union of the top 1000 documents of each base function.",
                "For our second set of base functions, we used scores from the TREC 9 [8] and TREC 10 [9] Web Track submissions.",
                "We used only the non-manual, non-short submissions from both years.",
                "For TREC 9 and TREC 10, there were 53 and 18 such submissions, respectively.",
                "A typical submission contained scores of its top 1000 documents. b ca wT φ(x,d) f(d|x) Figure 2: Example Feature Binning 4.2 Generating Features In order to generate input examples for our method, a concrete instantiation of φ must be provided.",
                "For each doc5 http://www.lemurproject.org TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236Best Func. 0.204 39/11 ** 0.181 37/13 ** 2nd Best 0.199 38/12 ** 0.174 43/7 ** 3rd Best 0.188 34/16 ** 0.174 38/12 ** Table 6: Comparison with Indri Functions ument d scored by a set of retrieval functions F on query x, we generate the features as a vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf , where f(d|x) denotes the score that retrieval function f assigns to document d for query x, and each Kf is a set of real values.",
                "From a high level, we are expressing the score of each retrieval function using |Kf | + 1 bins.",
                "Since we are using linear kernels, one can think of the learning problem as finding a good piecewise-constant combination of the scores of the retrieval functions.",
                "Figure 2 shows an example of our feature mapping method.",
                "In this example we have a single feature F = {f}.",
                "Here, Kf = {a, b, c}, and the weight vector is w = wa, wb, wc .",
                "For any document d and query x, we have wT φ(x, d) = 8 >>< >>: 0 if f(d|x) < a wa if a ≤ f(d|x) < b wa + wb if b ≤ f(d|x) < c wa + wb + wc if c ≤ f(d|x) .",
                "This is expressed qualitatively in Figure 2, where wa and wb are positive, and wc is negative.",
                "We ran our main experiments using four choices of F: the set of aforementioned Indri retrieval functions for TREC 9 and TREC 10, and the Web Track submissions for TREC 9 and TREC 10.",
                "For each F and each function f ∈ F, we chose 50 values for Kf which are reasonably spaced and capture the sensitive region of f. Using the four choices of F, we generated four datasets for our main experiments.",
                "Table 5 contains statistics of the generated datasets.",
                "There are many ways to generate features, and we are not advocating our method over others.",
                "This was simply an efficient means to normalize the outputs of different functions and allow for a more expressive model. 5.",
                "EXPERIMENTS For each dataset in Table 5, we performed 50 trials.",
                "For each trial, we train on 10 randomly selected queries, and select another 5 queries at random for a validation set.",
                "Models were trained using a wide range of C values.",
                "The model which performed best on the validation set was selected and tested on the remaining 35 queries.",
                "All queries were selected to be in the training, validation and test sets the same number of times.",
                "Using this setup, we performed the same experiments while using our method (SVM∆ map), an SVM optimizing for ROCArea (SVM∆ roc) [13], and a conventional classification SVM (SVMacc) [20].",
                "All SVM methods used a linear kernel.",
                "We reported the average performance of all models over the 50 trials. 5.1 Comparison with Base Functions In analyzing our results, the first question to answer is, can SVM∆ map learn a model which outperforms the best base TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287Best Func. 0.280 28/22 0.283 29/21 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 36/14 ** Table 7: Comparison with TREC Submissions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288Best Func. 0.280 27/23 0.283 31/19 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 35/15 ** Table 8: Comparison with TREC Subm. (w/o best) functions?",
                "Table 6 presents the comparison of SVM∆ map with the best Indri base functions.",
                "Each column group contains the macro-averaged MAP performance of SVM∆ map or a base function.",
                "The W/L columns show the number of queries where SVM∆ map achieved a higher MAP score.",
                "Significance tests were performed using the two-tailed Wilcoxon signed rank test.",
                "Two stars indicate a significance level of 0.95.",
                "All tables displaying our experimental results are structured identically.",
                "Here, we find that SVM∆ map significantly outperforms the best base functions.",
                "Table 7 shows the comparison when trained on TREC submissions.",
                "While achieving a higher MAP score than the best base functions, the performance difference between SVM∆ map the base functions is not significant.",
                "Given that many of these submissions use scoring functions which are carefully crafted to achieve high MAP, it is possible that the best performing submissions use techniques which subsume the techniques of the other submissions.",
                "As a result, SVM∆ map would not be able to learn a hypothesis which can significantly out-perform the best submission.",
                "Hence, we ran the same experiments using a modified dataset where the features computed using the best submission were removed.",
                "Table 8 shows the results (note that we are still comparing against the best submission though we are not using it for training).",
                "Notice that while the performance of SVM∆ map degraded slightly, the performance was still comparable with that of the best submission. 5.2 Comparison w/ Previous SVM Methods The next question to answer is, does SVM∆ map produce higher MAP scores than previous SVM methods?",
                "Tables 9 and 10 present the results of SVM∆ map, SVM∆ roc, and SVMacc when trained on the Indri retrieval functions and TREC submissions, respectively.",
                "Table 11 contains the corresponding results when trained on the TREC submissions without the best submission.",
                "To start with, our results indicate that SVMacc was not competitive with SVM∆ map and SVM∆ roc, and at times underperformed dramatically.",
                "As such, we tried several approaches to improve the performance of SVMacc. 5.2.1 Alternate SVMacc Methods One issue which may cause SVMacc to underperform is the severe imbalance between relevant and non-relevant docTREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236SVM∆ roc 0.237 29/21 0.234 24/26 SVMacc 0.147 47/3 ** 0.155 47/3 ** SVMacc2 0.219 39/11 ** 0.207 43/7 ** SVMacc3 0.113 49/1 ** 0.153 45/5 ** SVMacc4 0.155 48/2 ** 0.155 48/2 ** Table 9: Trained on Indri Functions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287SVM∆ roc 0.282 29/21 0.278 35/15 ** SVMacc 0.213 49/1 ** 0.222 49/1 ** SVMacc2 0.270 34/16 ** 0.261 42/8 ** SVMacc3 0.133 50/0 ** 0.182 46/4 ** SVMacc4 0.233 47/3 ** 0.238 46/4 ** Table 10: Trained on TREC Submissions uments.",
                "The vast majority of the documents are not relevant.",
                "SVMacc2 addresses this problem by assigning more penalty to false negative errors.",
                "For each dataset, the ratio of the false negative to false positive penalties is equal to the ratio of the number non-relevant and relevant documents in that dataset.",
                "Tables 9, 10 and 11 indicate that SVMacc2 still performs significantly worse than SVM∆ map.",
                "Another possible issue is that SVMacc attempts to find just one discriminating threshold b that is query-invariant.",
                "It may be that different queries require different values of b.",
                "Having the learning method trying to find a good b value (when one does not exist) may be detrimental.",
                "We took two approaches to address this issue.",
                "The first method, SVMacc3, converts the retrieval function scores into percentiles.",
                "For example, for document d, query q and retrieval function f, if the score f(d|q) is in the top 90% of the scores f(·|q) for query q, then the converted score is f (d|q) = 0.9.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Tables 9, 10 and 11 show that the performance of SVMacc3 was also not competitive with SVM∆ map.",
                "The second method, SVMacc4, normalizes the scores given by f for each query.",
                "For example, assume for query q that f outputs scores in the range 0.2 to 0.7.",
                "Then for document d, if f(d|q) = 0.6, the converted score would be f (d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Again, Tables 9, 10 and 11 show that SVMacc4 was not competitive with SVM∆ map 5.2.2 MAP vs ROCArea SVM∆ roc performed much better than SVMacc in our experiments.",
                "When trained on Indri retrieval functions (see Table 9), the performance of SVM∆ roc was slight, though not significantly, worse than the performances of SVM∆ map.",
                "However, Table 10 shows that SVM∆ map did significantly outperform SVM∆ roc when trained on the TREC submissions.",
                "Table 11 shows the performance of the models when trained on the TREC submissions with the best submission removed.",
                "The performance of most models degraded by a small amount, with SVM∆ map still having the best performance.",
                "TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Table 11: Trained on TREC Subm. (w/o Best) 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented an SVM method that directly optimizes MAP.",
                "It provides a principled approach and avoids difficult to control heuristics.",
                "We formulated the optimization problem and presented an algorithm which provably finds the solution in polynomial time.",
                "We have shown empirically that our method is generally superior to or competitive with conventional SVMs methods.",
                "Our new method makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for Accuracy and ROCArea.",
                "The computational cost for training is very reasonable in practice.",
                "Since other methods typically require tuning multiple heuristics, we also expect to train fewer models before finding one which achieves good performance.",
                "The learning framework used by our method is fairly general.",
                "A natural extension of this framework would be to develop methods to optimize for other important IR measures, such as Normalized Discounted Cumulative Gain [2, 3, 4, 12] and Mean Reciprocal Rank. 7.",
                "ACKNOWLEDGMENTS This work was funded under NSF Award IIS-0412894, NSF CAREER Award 0237381, and a gift from Yahoo!",
                "Research.",
                "The third author was also partly supported by a Microsoft Research Fellowship. 8.",
                "REFERENCES [1] B. T. Bartell, G. W. Cottrell, and R. K. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2005. [3] C. J. C. Burges, R. Ragno, and Q.",
                "Le.",
                "Learning to rank with non-smooth cost functions.",
                "In Proceedings of the International Conference on Advances in Neural Information Processing Systems (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y.",
                "Liu, H. Li, Y. Huang, and H.-W. Hon.",
                "Adapting ranking SVM to document retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [5] B. Carterette and D. Petkova.",
                "Learning a ranking from pairwise preferences.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew, and A. Ksikes.",
                "Ensemble selection from libraries of models.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [7] J. Davis and M. Goadrich.",
                "The relationship between precision-recall and ROC curves.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2006. [8] D. Hawking.",
                "Overview of the TREC-9 web track.",
                "In Proceedings of TREC-2000, 2000. [9] D. Hawking and N. Craswell.",
                "Overview of the TREC-2001 web track.",
                "In Proceedings of TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel, and K. Obermayer.",
                "Large margin rank boundaries for ordinal regression.",
                "Advances in large margin classifiers, 2000. [11] A. Herschtal and B. Raskutti.",
                "Optimising area under the ROC curve using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [12] K. Jarvelin and J. Kekalainen.",
                "Ir evaluation methods for retrieving highly relevant documents.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2000. [13] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proceedings of the International Conference on Machine Learning (ICML), pages 377-384, New York, NY, USA, 2005.",
                "ACM Press. [14] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 111-119, 2001. [15] Y. Lin, Y. Lee, and G. Wahba.",
                "Support vector machines for classification in nonstandard situations.",
                "Machine Learning, 46:191-202, 2002. [16] D. Metzler and W. B. Croft.",
                "A markov random field model for term dependencies.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 472-479, 2005. [17] K. Morik, P. Brockhausen, and T. Joachims.",
                "Combining statistical learning with a knowledge-based approach.",
                "In Proceedings of the International Conference on Machine Learning, 1999. [18] S. Robertson.",
                "The probability ranking principle in ir. journal of documentation.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.",
                "Large margin methods for structured and interdependent output variables.",
                "Journal of Machine Learning Research (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik.",
                "Statistical Learning Theory.",
                "Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz.",
                "Optimizing classifier performance via approximation to the Wilcoxon-Mann-Witney statistic.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2003."
            ],
            "original_annotated_samples": [
                "In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward <br>relaxation of map</br>.",
                "Specifically, we present an SVM algorithm that globally optimizes a hinge-loss <br>relaxation of map</br>.",
                "Optimization Problem 1. (Structural SVM) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) The objective function to be minimized (3) is a tradeoff between model complexity, w 2 , and a hinge loss <br>relaxation of map</br> loss, P ξi."
            ],
            "translated_annotated_samples": [
                "Por el contrario, presentamos un algoritmo de aprendizaje SVM general que encuentra de manera eficiente una solución óptima global para una relajación directa de MAP.",
                "Específicamente, presentamos un algoritmo SVM que optimiza globalmente una <br>relajación de pérdida de bisagra</br> de MAP.",
                "Problema de optimización 1. (SVM estructural) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) La función objetivo a minimizar (3) es un compromiso entre la complejidad del modelo, w 2 , y una <br>relajación de pérdida de MAP</br> mediante la pérdida de bisagra, P ξi."
            ],
            "translated_text": "Un método de Vectores de Soporte para optimizar la Precisión Promedio Yisong Yue Universidad de Cornell Ithaca, NY, EE. UU. yyue@cs.cornell.edu Thomas Finley Universidad de Cornell Ithaca, NY, EE. UU. tomf@cs.cornell.edu Filip Radlinski Universidad de Cornell Ithaca, NY, EE. UU. filip@cs.cornell.edu Thorsten Joachims Universidad de Cornell Ithaca, NY, EE. UU. tj@cs.cornell.edu RESUMEN El aprendizaje automático se utiliza comúnmente para mejorar los sistemas de recuperación clasificados. Debido a dificultades computacionales, se han desarrollado pocas técnicas de aprendizaje para optimizar directamente la precisión media promedio (MAP), a pesar de su uso generalizado en la evaluación de dichos sistemas. Los enfoques existentes que optimizan el MAP no encuentran una solución óptima global o son computacionalmente costosos. Por el contrario, presentamos un algoritmo de aprendizaje SVM general que encuentra de manera eficiente una solución óptima global para una relajación directa de MAP. Evaluamos nuestro enfoque utilizando los corpus de la pista web TREC 9 y TREC 10 (WT10g), comparando con SVM optimizados para precisión y área bajo la curva ROC. En la mayoría de los casos mostramos nuestro método para producir mejoras estadísticamente significativas en las puntuaciones de MAP. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de Recuperación Términos Generales Algoritmo, Teoría, Experimentación 1. INTRODUCCIÓN Los sistemas de recuperación de información de última generación comúnmente utilizan técnicas de aprendizaje automático para aprender funciones de clasificación. Sin embargo, la mayoría de los enfoques actuales no están optimizados para la medida de evaluación más utilizada, es decir, la Precisión Promedio Media (MAP). En cambio, los algoritmos actuales tienden a seguir uno de dos enfoques generales. El primer enfoque es aprender un modelo que estime la probabilidad de que un documento sea relevante dado una consulta (por ejemplo, [18, 14]). Si se resuelve de manera efectiva, la clasificación con el mejor rendimiento de MAP puede derivarse fácilmente de las probabilidades de relevancia. Sin embargo, lograr un MAP alto solo requiere encontrar un buen ordenamiento de los documentos. Como resultado, encontrar buenas probabilidades requiere resolver un problema más difícil de lo necesario, probablemente necesitando más datos de entrenamiento para lograr el mismo rendimiento de MAP. El segundo enfoque común es aprender una función que maximice una medida sustituta. Las medidas de rendimiento optimizadas incluyen precisión [17, 15], área bajo la curva ROC [1, 5, 10, 11, 13, 21] o modificaciones del área bajo la curva ROC [4], y NDCG [2, 3]. Aprender un modelo para optimizar tales medidas podría resultar en un rendimiento de MAP subóptimo. De hecho, aunque algunos sistemas anteriores han obtenido un buen rendimiento de MAP, se sabe que ni lograr una precisión óptima ni un área bajo la curva ROC pueden garantizar un rendimiento de MAP óptimo[7]. En este artículo, presentamos un enfoque general para aprender funciones de clasificación que maximizan el rendimiento de MAP. Específicamente, presentamos un algoritmo SVM que optimiza globalmente una <br>relajación de pérdida de bisagra</br> de MAP. Este enfoque simplifica el proceso de obtener funciones de clasificación con un alto rendimiento de MAP al evitar pasos intermedios adicionales y heurísticas. El nuevo algoritmo también hace que sea conceptualmente tan fácil optimizar las SVM para MAP como anteriormente solo era posible para precisión y ROCArea. A diferencia del trabajo reciente que optimiza directamente el rendimiento de MAP realizado por Metzler & Croft [16] y Caruana et al. [6], nuestra técnica es eficiente computacionalmente al encontrar una solución óptima a nivel global. Al igual que [6, 16], nuestro método aprende un modelo lineal, pero es mucho más eficiente en la práctica y, a diferencia de [16], puede manejar miles de características. Ahora describimos el algoritmo en detalle y proporcionamos la prueba de corrección. A continuación, proporcionamos un análisis del tiempo de ejecución. Concluimos con los resultados empíricos de experimentos en el corpus de la pista web TREC 9 y TREC 10. También hemos desarrollado un paquete de software que implementa nuestro algoritmo y está disponible para uso público. EL PROBLEMA DEL APRENDIZAJE Siguiendo la configuración estándar del aprendizaje automático, nuestro objetivo es aprender una función h: X → Y entre un espacio de entrada X (todas las consultas posibles) y un espacio de salida Y (clasificaciones sobre un corpus). Para cuantificar la calidad de una predicción, ˆy = h(x), consideraremos una función de pérdida ∆ : Y × Y → . ∆(y, ˆy) cuantifica la penalización por hacer la predicción ˆy si la salida correcta es y. La función de pérdida nos permite incorporar medidas específicas de rendimiento, las cuales explotaremos en http://svmrank.yisongyue.com para optimizar el MAP. Nos restringimos al escenario de aprendizaje supervisado, donde pares de entrada/salida (x, y) están disponibles para el entrenamiento y se asume que provienen de alguna distribución fija P(x, y). El objetivo es encontrar una función h tal que el riesgo (es decir, la pérdida esperada), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), se minimice. Por supuesto, P(x, y) es desconocido. Pero dado un conjunto finito de pares de entrenamiento, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, el rendimiento de h en S puede medirse mediante el riesgo empírico, R∆ S (h) = 1 n ∑ i=1 n ∆(yi, h(xi)). En el caso de aprender una función de recuperación clasificada, X denota un espacio de consultas, y Y el espacio de clasificaciones (posiblemente débiles) sobre algún corpus de documentos C = {d1, . . . ,d|C|}. Podemos definir la pérdida de precisión promedio como ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), donde rank(y) es un vector de los valores de rango de cada documento en C. Por ejemplo, para un corpus de dos documentos, {d1, d2}, con d1 teniendo un rango más alto que d2, rank(y) = (1, 0). Suponemos que las clasificaciones verdaderas tienen dos valores de clasificación, donde los documentos relevantes tienen un valor de clasificación 1 y los documentos no relevantes tienen un valor de clasificación 0. Además, asumimos que todas las clasificaciones predichas son clasificaciones completas (sin empates). Sea p = rango(y) y ˆp = rango(ˆy). La puntuación de precisión promedio se define como MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, donde rel = |{i : pi = 1}| es el número de documentos relevantes, y Prec@j es el porcentaje de documentos relevantes en los primeros j documentos en la clasificación predicha ˆy. MAP es la media de las puntuaciones de precisión promedio de un grupo de consultas. La mayoría de los algoritmos de aprendizaje se optimizan para precisión o ROCArea. Si bien optimizar estas medidas podría lograr un buen rendimiento de MAP, usamos dos ejemplos simples para mostrar que también puede ser subóptimo en términos de MAP. ROCArea asigna una penalización igual a cada desordenamiento de un par relevante/no relevante. Por el contrario, MAP asigna mayores penalizaciones a los errores de ordenamiento más arriba en la clasificación predicha. Usando nuestra notación, el Área bajo la Curva ROC (ROCArea) se puede definir como ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], donde p es el ranking verdadero (débil), ˆp es el ranking predicho, y 1[b] es la función indicadora condicionada a b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Tabla 1: Ejemplo y Modelos Supongamos que tenemos un espacio de hipótesis con solo dos funciones de hipótesis, h1 y h2, como se muestra en la Tabla 1. Estas dos hipótesis predicen un ranking para la consulta x sobre un corpus de ocho documentos. Tabla 2: Rendimiento de los Modelos de Juguete La Tabla 2 muestra las puntuaciones de MAP y ROCArea de h1 y h2. Aquí, un método de aprendizaje que optimiza para el Área bajo la curva ROC elegiría h2 ya que esto resulta en un puntaje de Área bajo la curva ROC más alto, pero esto produce un puntaje de MAP subóptimo. 2.2 MAP vs Precisión Usando un ejemplo muy similar, ahora demostramos cómo optimizar para la precisión podría resultar en un puntaje de MAP subóptimo. Los modelos que se optimizan para la precisión no están directamente preocupados por la clasificación. En cambio, aprenden un umbral tal que los documentos que obtienen una puntuación superior al umbral pueden ser clasificados como relevantes y los documentos que obtienen una puntuación inferior como no relevantes. Consideramos nuevamente un espacio de hipótesis con dos hipótesis. La Tabla 3 muestra las predicciones de las dos hipótesis en una única consulta x. Hipótesis MAP Mejor Precisión h1(q) 0.70 0.64 h2(q) 0.64 0.73 Tabla 4: Rendimiento de los Modelos de Juguete La Tabla 4 muestra los puntajes de MAP y mejor precisión de h1(q) y h2(q). La mejor precisión se refiere a la precisión más alta alcanzable en esa clasificación al considerar todos los umbrales posibles. Por ejemplo, con h1(q), un umbral entre los documentos 1 y 2 da 4 errores (documentos 6-9 clasificados incorrectamente como no relevantes), lo que resulta en una precisión de 0.64. De manera similar, con h2(q), un umbral entre los documentos 5 y 6 da 3 errores (los documentos 10-11 clasificados incorrectamente como relevantes, y el documento 1 como no relevante), lo que resulta en una precisión de 0.73. Un método de aprendizaje que optimiza la precisión elegiría h2 ya que esto resulta en un puntaje de precisión más alto, pero esto produce un puntaje de MAP subóptimo. 3. OPTIMIZANDO LA PRECISIÓN PROMEDIO Nos basamos en el enfoque utilizado por [13] para optimizar el Área bajo la Curva ROC. A diferencia de ROCArea, sin embargo, MAP no se descompone linealmente en los ejemplos y requiere un algoritmo sustancialmente extendido, el cual describimos en esta sección. Recuerda que la clasificación verdadera es una clasificación débil con dos valores de clasificación (relevante y no relevante). Que Cx y C¯x denoten el conjunto de documentos relevantes y no relevantes de C para la consulta x, respectivamente. Nos enfocamos en funciones que están parametrizadas por un vector de peso w, y por lo tanto deseamos encontrar w para minimizar el riesgo empírico, R∆ S (w) ≡ R∆ S (h(·; w)). Nuestro enfoque es aprender una función discriminante F: X × Y → sobre pares de entrada-salida. Dada la consulta x, podemos derivar una predicción encontrando la clasificación y que maximiza la función discriminante: h(x; w) = argmax y∈Y F(x, y; w). (1) Suponemos que F es lineal en alguna representación de características combinadas de entradas y salidas Ψ(x, y) ∈ RN, es decir, F(x, y; w) = wT Ψ(x, y). (2) La función de características combinadas que utilizamos es Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))], donde φ: X × C → N es una función de mapeo de características de un par consulta/documento a un punto en un espacio dimensional N. Representamos las clasificaciones como una matriz de ordenamientos por pares, Y ⊂ {−1, 0, +1}|C|×|C| . Para cualquier y ∈ Y, yij = +1 si di está clasificado por delante de dj, y yij = −1 si dj está clasificado por delante de di, y yij = 0 si di y dj tienen el mismo rango. Consideramos solo matrices que corresponden a clasificaciones válidas (es decir, que cumplen con la antisimetría y la transitividad). De manera intuitiva, Ψ es una suma de las diferencias vectoriales de todos los pares de documentos relevantes/no relevantes. Dado que asumimos que las clasificaciones predichas son clasificaciones completas, yij es o bien +1 o −1 (nunca 0). Dado un vector de pesos aprendido w, predecir un ranking (es decir, resolver la ecuación (1)) dado una consulta x se reduce a elegir cada yij para maximizar wT Ψ(x, y). Como también se discute en [13], esto se logra ordenando los documentos por wT φ(x, d) en orden descendente. Discutiremos más adelante las elecciones de φ que utilizamos para nuestros experimentos. 3.1 SVM Estructurales La formulación anterior es muy similar a aprender un modelo lineal directo mientras se entrena en la diferencia de pares de documentos relevantes/no relevantes. Muchos enfoques basados en SVM optimizan sobre estas diferencias en pares (por ejemplo, [5, 10, 13, 4]), aunque estos métodos no optimizan para el MAP durante el entrenamiento. Anteriormente, no estaba claro cómo incorporar funciones de pérdida multivariadas no lineales como la pérdida MAP directamente en problemas de optimización global como el entrenamiento de SVM. Ahora presentamos un método basado en SVM estructurales [19] para abordar este problema. Utilizamos la formulación del SVM estructural, presentada en el Problema de Optimización 1, para aprender un w ∈ RN. Problema de optimización 1. (SVM estructural) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) La función objetivo a minimizar (3) es un compromiso entre la complejidad del modelo, w 2 , y una <br>relajación de pérdida de MAP</br> mediante la pérdida de bisagra, P ξi. Como es habitual en el entrenamiento de SVM, C es igual a 2. Por ejemplo, una dimensión podría ser el número de veces que las palabras de la consulta aparecen en el documento. Algoritmo 1 Algoritmo de plano de corte para resolver OP 1 dentro de la tolerancia. 1: Entrada: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ para todo i = 1, . . . , n 3: repetir 4: para i = 1, . . . , n hacer 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: calcular ˆy = argmaxy∈Y H(y; w) 7: calcular ξi = max{0, maxy∈Wi H(y; w)} 8: si H(ˆy; w) > ξi + entonces 9: Wi ← Wi ∪ {ˆy} 10: w ← optimizar (3) sobre W = S i Wi 11: fin si 12: fin para 13: hasta que ningún Wi haya cambiado durante la iteración parámetro que controla este equilibrio y puede ajustarse para lograr un buen rendimiento en diferentes tareas de entrenamiento. Para cada (xi, yi) en el conjunto de entrenamiento, se añade un conjunto de restricciones de la forma en la ecuación (4) al problema de optimización. Ten en cuenta que wT Ψ(x, y) es exactamente nuestra función discriminante F(x, y; w) (ver ecuación (2)). Durante la predicción, nuestro modelo elige el ranking que maximiza el discriminante (1). Si el valor del discriminante para una clasificación incorrecta y es mayor que para la clasificación verdadera yi (por ejemplo, F(xi, y; w) > F(xi, yi; w)), entonces la variable de holgura correspondiente, ξi, debe ser al menos ∆(yi, y) para que se cumpla esa restricción. Por lo tanto, la suma de los márgenes, P ξi, acota superiormente la pérdida MAP. Esto se establece formalmente en la Proposición 1. Proposición 1. Sea ξ∗ (w) la solución óptima de las variables de holgura para OP 1 para un vector de peso dado w. Entonces 1 n Pn i=1 ξi es una cota superior del riesgo empírico R∆ S (w). (ver [19] para la prueba) La Proposición 1 muestra que OP 1 aprende una función de clasificación que optimiza una cota superior del error de MAP en el conjunto de entrenamiento. Desafortunadamente hay un problema: se requiere una restricción para cada posible resultado incorrecto y, y el número de resultados incorrectos posibles es exponencial en el tamaño de C. Afortunadamente, podemos emplear el Algoritmo 1 para resolver OP 1. El algoritmo 1 es un algoritmo de plano de corte, introduciendo iterativamente restricciones hasta que hayamos resuelto el problema original dentro de una tolerancia deseada [19]. El algoritmo comienza sin restricciones y encuentra de forma iterativa, para cada ejemplo (xi, yi), la salida ˆy asociada con la restricción más violada. Si la restricción correspondiente es violada por más de lo que introducimos ˆy en el conjunto de trabajo Wi de restricciones activas, por ejemplo i, y volvemos a resolver (3) usando el W actualizado. Se puede demostrar que el bucle externo del Algoritmo 1 está garantizado a detenerse dentro de un número polinomial de iteraciones para cualquier precisión deseada. Teorema 1. Sea ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y), ¯∆ = maxi maxy ∆(yi, y), y para cualquier > 0, el Algoritmo 1 termina después de agregar a lo sumo max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff restricciones al conjunto de trabajo W. (ver [19] para la prueba) Sin embargo, dentro del bucle interno de este algoritmo tenemos que calcular argmaxy∈Y H(y; w), donde H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), o equivalentemente, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), ya que wT Ψ(xi, yi) es constante con respecto a y. Aunque está estrechamente relacionado con el procedimiento de clasificación, esto tiene la complicación sustancial de que debemos lidiar con el término adicional ∆(yi, y). Sin la capacidad de encontrar eficientemente la restricción más violada (es decir, resolver argmaxy∈Y H(y, w)), el procedimiento de generación de restricciones no es viable. 3.2 Encontrar la restricción más violada utilizando OP 1 y optimizando la pérdida de ROCArea (∆roc), el problema de encontrar la restricción más violada, o resolver argmaxy∈Y H(y, w) (en adelante argmax H), se aborda en [13]. Resolver argmax H para ∆map es más difícil. Esto se debe principalmente a que ROCArea se descompone de manera ordenada en una suma de puntuaciones calculadas de forma independiente en cada ordenamiento relativo de un par de documentos relevantes/no relevantes. MAP, por otro lado, no se descompone de la misma manera que ROCArea. La principal contribución algorítmica de este artículo es un método eficiente para resolver argmax H para ∆map. Una propiedad útil de ∆map es que es invariante al intercambiar dos documentos con igual relevancia. Por ejemplo, si los documentos da y db son ambos relevantes, entonces intercambiar las posiciones de da y db en cualquier clasificación no afecta a ∆map. Por extensión, ∆map es invariante a cualquier permutación arbitraria de los documentos relevantes entre sí y de los documentos no relevantes entre sí. Sin embargo, esta reorganización afectará la puntuación del discriminante, wT Ψ(x, y). Esto nos lleva a la Observación 1. Observación 1. Considera clasificaciones que estén limitadas por fijar la relevancia en cada posición de la clasificación (por ejemplo, el tercer documento en la clasificación debe ser relevante). Cada clasificación que cumpla con el mismo conjunto de restricciones tendrá el mismo ∆map. Si los documentos relevantes están ordenados por wT φ(x, d) en orden descendente, y los documentos no relevantes también están ordenados de la misma manera por wT φ(x, d), entonces la intercalación de las dos listas ordenadas que cumpla con las restricciones maximizará H para ese conjunto de clasificaciones restringidas. La Observación 1 implica que en la clasificación que maximiza H, los documentos relevantes se ordenarán por wT φ(x, d), y los documentos no relevantes también se ordenarán de la misma manera. Al ordenar primero los documentos relevantes y no relevantes, el problema se simplifica a encontrar la intercalación óptima de dos listas ordenadas. Para el resto de nuestra discusión, asumimos que los documentos relevantes y no relevantes están ordenados por wT φ(x, d) en orden descendente. Para mayor comodidad, también nos referimos a los documentos relevantes como {dx 1 , . . . dx |Cx|} = Cx, y a los documentos no relevantes como {d¯x 1 , . . . d¯x |C¯x|} = C¯x. Definimos δj(i1, i2), con i1 < i2, como el cambio en H desde cuando el documento relevante de mayor rango clasificado después de d¯x j es dx i1 hasta que es dx i2. Para i2 = i1 + 1, tenemos δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5), donde si = wT φ(x, di). El primer término en (5) es el cambio en ∆map cuando el documento relevante i tiene j documentos no relevantes clasificados antes de él, en lugar de j-1. El segundo término es el cambio en la puntuación del discriminante, wT Ψ(x, y), cuando yij cambia de +1 a −1. . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . . Figura 1: Ejemplo para δj(i, i + 1). La Figura 1 proporciona un ejemplo conceptual para δj(i, i + 1). La clasificación inferior difiere de la superior solo cuando d¯x j sube un rango. La diferencia en el valor de H para estas dos clasificaciones es exactamente δj(i, i + 1). Para cualquier i1 < i2, podemos definir δj(i1, i2) como δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) o equivalentemente, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) . Deja que o1, . . . , o|C¯x| codifiquen las posiciones de los documentos no relevantes, donde dx oj es el documento relevante de mayor rango clasificado después del j-ésimo documento no relevante. Debido a la Observación 1, esta codificación identifica de forma única un ranking completo. Podemos recuperar la clasificación como yij = 8 >>>< >>>: 0 si i = j sign(si − sj) si di, dj relevancia igual signo(oj − i − 0.5) si di = dx i , dj = d¯x j signo(j − oi + 0.5) si di = d¯x i , dj = dx j. (7) Ahora podemos reformular H en una nueva función objetivo, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), donde ¯y es la verdadera clasificación (débil). Conceptualmente, H comienza con una clasificación perfecta ¯y y agrega el cambio en H cuando cada documento no relevante sucesivo sube en la clasificación. Luego podemos reformular el problema argmax H como argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) sujeto a o1 ≤ . . . ≤ o|C¯x|. (9) El Algoritmo 2 describe el algoritmo utilizado para resolver la ecuación (8). Conceptualmente, el Algoritmo 2 comienza con un ranking perfecto. Entonces, para cada documento no relevante sucesivo, el algoritmo modifica la solución deslizando ese documento hacia arriba en la clasificación para maximizar localmente H, manteniendo las posiciones de los otros documentos no relevantes constantes. 3.2.1 Prueba de Corrección El Algoritmo 2 es codicioso en el sentido de que encuentra la mejor posición de cada documento no relevante de forma independiente de los otros documentos no relevantes. En otras palabras, el algoritmo maximiza H para cada documento no relevante, d¯x j, Algoritmo 2 Encontrar la Restricción Más Violada (argmax H) para el Algoritmo 1 con ∆map 1: Entrada: w, Cx, C¯x 2: ordenar Cx y C¯x en orden descendente de wT φ(x, d) 3: sx i ← wT φ(x, dx i), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i), i = 1, . . . , |C¯x | 5: para j = 1, . . . , |C¯x | hacer 6: optj ← argmaxk δj(k, |Cx| + 1) 7: fin para 8: codificar ˆy de acuerdo con (7) 9: devolver ˆy sin considerar las posiciones de los otros documentos no relevantes, y así ignora las restricciones de (9). Para que la solución sea factible, el documento no relevante j-ésimo debe ser clasificado después de los primeros j-1 documentos no relevantes, satisfaciendo así opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. Si la solución es factible, entonces claramente resuelve (8). Por lo tanto, basta con demostrar que el Algoritmo 2 cumple con (10). Primero demostramos que δj(·, ·) es monótonamente decreciente en j. Lema 1. Para cualquier 1 ≤ i1 < i2 ≤ |Cx | + 1 y 1 ≤ j < |C¯x |, debe ser el caso que δj+1(i1, i2) ≤ δj(i1, i2). Prueba. Recuerde que tanto δj(i1, i2) como δj+1(i1, i2) son sumas de términos i2 − i1. Mostraremos que cada término en la suma de δj+1(i1, i2) no es mayor que el término correspondiente en δj(i1, i2), o δj+1(k, k + 1) ≤ δj(k, k + 1) para k = i1, . . . , i2 − 1. Cada término en δj(k, k +1) y δj+1(k, k +1) puede ser descompuesto aún más en dos partes (ver (5)). Mostraremos que cada parte de δj+1(k, k + 1) no es mayor que la parte correspondiente en δj(k, k + 1). En otras palabras, demostraremos que tanto j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) como −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) son verdaderos para los valores mencionados de j y k. Es fácil ver que (11) es verdadero observando que para cualquier par de enteros positivos 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1, y eligiendo a = j y b = j + k. La segunda desigualdad (12) se cumple porque el Algoritmo 2 primero ordena d¯x en orden descendente de s¯x, lo que implica s¯x j+1 ≤ s¯x j. Así vemos que cada término en δj+1 no es mayor que el término correspondiente en δj, lo cual completa la prueba. El resultado del Lema 1 conduce directamente a nuestro resultado principal de corrección: Teorema 2. En el Algoritmo 2, los valores calculados de optj satisfacen (10), lo que implica que la solución devuelta por el Algoritmo 2 es factible y, por lo tanto, óptima. Prueba. Demostraremos que optj ≤ optj+1 se cumple para cualquier 1 ≤ j < |C¯x|, implicando así (10). Dado que el Algoritmo 2 calcula optj como optj = argmax k δj(k, |Cx | + 1), (13), entonces por definición de δj (6), para cualquier 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0. Usando el Lema 1, sabemos que δj+1(i, optj) ≤ δj(i, optj) < 0, lo que implica que para cualquier 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0. Supongamos por contradicción que optj+1 < optj. Entonces δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), lo cual contradice (13). Por lo tanto, debe ser el caso que optj ≤ optj+1, lo cual completa la prueba. 3.2.2 Tiempo de ejecución El tiempo de ejecución del Algoritmo 2 se puede dividir en dos partes. La primera parte es la clasificación por wT φ(x, d), lo cual requiere un tiempo de O(n log n), donde n = |Cx | + |C¯x |. La segunda parte calcula cada optj, lo cual requiere un tiempo de O(|Cx| · |C¯x|). Aunque en el peor de los casos esto es O(n2), el número de documentos relevantes, |Cx|, suele ser muy pequeño (por ejemplo, constante con respecto a n), en cuyo caso el tiempo de ejecución para la segunda parte es simplemente O(n). Para la mayoría de los conjuntos de datos del mundo real, el Algoritmo 2 está dominado por la ordenación y tiene una complejidad O(n log n). El Algoritmo 1 está garantizado de detenerse en un número polinómico de iteraciones [19], y cada iteración ejecuta el Algoritmo 2. Prácticamente todos los modelos que funcionaron bien fueron entrenados en un tiempo razonable (generalmente menos de una hora). Una vez que el entrenamiento esté completo, hacer predicciones sobre la consulta x usando la hipótesis resultante h(x|w) solo requiere ordenar por wT φ(x, d). Desarrollamos nuestro software utilizando una interfaz de Python a SVMstruct, ya que el lenguaje Python simplificó en gran medida el proceso de codificación. Para mejorar el rendimiento, es recomendable utilizar la implementación estándar en C de SVMstruct. CONFIGURACIÓN DEL EXPERIMENTO El objetivo principal de nuestros experimentos es evaluar si la optimización directa de MAP conduce a un rendimiento de MAP mejorado en comparación con los métodos convencionales de SVM que optimizan una pérdida sustituta como la precisión o el área bajo la curva ROC. Evaluamos empíricamente nuestro método utilizando dos conjuntos de consultas de la TREC Web Track, uno de TREC 9 y otro de TREC 10 (temas 451-500 y 501-550), ambos de los cuales utilizaron el corpus WT10g. Para cada consulta, TREC proporciona las evaluaciones de relevancia de los documentos. Generamos nuestras características utilizando las puntuaciones de las funciones de recuperación existentes en estas consultas. Si bien nuestro método es agnóstico al significado de las características, elegimos utilizar funciones de recuperación existentes como una forma simple pero efectiva de adquirir características útiles. Por lo tanto, nuestros experimentos de estadísticas de conjuntos de datos básicos esencialmente prueban la capacidad de nuestros métodos para volver a clasificar los documentos altamente clasificados (por ejemplo, volver a combinar las puntuaciones de las funciones de recuperación) para mejorar el MAP. Comparamos nuestro método con las mejores funciones de recuperación entrenadas (en adelante, funciones base), así como con los métodos SVM propuestos anteriormente. Comparar con las mejores funciones base pone a prueba la capacidad de nuestros métodos para aprender una combinación útil. Comparar con métodos SVM anteriores nos permite probar si optimizar directamente para el MAP (en lugar de precisión o área bajo la curva ROC) logra una puntuación de MAP más alta en la práctica. El resto de esta sección describe las funciones base y el método de generación de características en detalle. 4.1 Elección de Funciones de Recuperación Elegimos dos conjuntos de funciones base para nuestros experimentos. Para el primer conjunto, generamos tres índices sobre el corpus WT10g utilizando Indri5. El primer índice fue generado utilizando la configuración predeterminada, el segundo utilizó Porter-stemming, y el último utilizó Porter-stemming y las palabras vacías predeterminadas de Indris. Para TREC 9 y TREC 10, utilizamos la parte de descripción de cada consulta y puntuamos los documentos utilizando cinco de los métodos de recuperación integrados en Indri, que son Similitud Coseno, TFIDF, Okapi, Modelo de Lenguaje con Prior de Dirichlet y Modelo de Lenguaje con Prior de Jelinek-Mercer. Todos los parámetros se mantuvieron en sus valores predeterminados. Calculamos las puntuaciones de estos cinco métodos de recuperación sobre los tres índices, dando un total de 15 funciones base. Para cada consulta, consideramos las puntuaciones de los documentos encontrados en la unión de los mejores 1000 documentos de cada función base. Para nuestro segundo conjunto de funciones base, utilizamos puntuaciones de las presentaciones de la pista web TREC 9 [8] y TREC 10 [9]. Utilizamos solo las presentaciones no manuales y no breves de ambos años. Para TREC 9 y TREC 10, hubo 53 y 18 envíos de este tipo, respectivamente. Una presentación típica contenía puntajes de sus 1000 documentos principales. b ca wT φ(x,d) f(d|x) Figura 2: Ejemplo de Agrupación de Características 4.2 Generación de Características Para generar ejemplos de entrada para nuestro método, se debe proporcionar una instancia concreta de φ. Para cada documento d puntuado por un conjunto de funciones de recuperación F en la consulta x, generamos las características como un vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf, donde f(d|x) denota la puntuación que la función de recuperación f asigna al documento d para la consulta x, y cada Kf es un conjunto de valores reales. Desde un nivel alto, estamos expresando la puntuación de cada función de recuperación utilizando |Kf | + 1 contenedores. Dado que estamos utilizando núcleos lineales, se puede pensar en el problema de aprendizaje como encontrar una buena combinación de piezas constantes de los puntajes de las funciones de recuperación. La Figura 2 muestra un ejemplo de nuestro método de mapeo de características. En este ejemplo tenemos una única característica F = {f}. Aquí, Kf = {a, b, c}, y el vector de pesos es w = wa, wb, wc. Para cualquier documento d y consulta x, tenemos wT φ(x, d) = 8 >>< >>: 0 si f(d|x) < a wa si a ≤ f(d|x) < b wa + wb si b ≤ f(d|x) < c wa + wb + wc si c ≤ f(d|x) . Esto se expresa cualitativamente en la Figura 2, donde wa y wb son positivos, y wc es negativo. Realizamos nuestros experimentos principales utilizando cuatro opciones de F: el conjunto de las funciones de recuperación de Indri mencionadas anteriormente para TREC 9 y TREC 10, y las presentaciones de la pista web para TREC 9 y TREC 10. Para cada F y cada función f ∈ F, elegimos 50 valores para Kf que estuvieran razonablemente espaciados y capturaran la región sensible de f. Utilizando las cuatro opciones de F, generamos cuatro conjuntos de datos para nuestros experimentos principales. La Tabla 5 contiene estadísticas de los conjuntos de datos generados. Hay muchas formas de generar características, y no estamos abogando por nuestro método sobre los demás. Esto fue simplemente un medio eficiente para normalizar las salidas de diferentes funciones y permitir un modelo más expresivo. EXPERIMENTOS Para cada conjunto de datos en la Tabla 5, realizamos 50 pruebas. Para cada prueba, entrenamos con 10 consultas seleccionadas al azar, y seleccionamos otras 5 consultas al azar para un conjunto de validación. Los modelos fueron entrenados utilizando una amplia gama de valores de C. El modelo que tuvo mejor rendimiento en el conjunto de validación fue seleccionado y probado en las 35 consultas restantes. Todas las consultas fueron seleccionadas para estar en los conjuntos de entrenamiento, validación y prueba la misma cantidad de veces. Utilizando esta configuración, realizamos los mismos experimentos mientras usábamos nuestro método (mapa SVM∆), un SVM optimizando para ROCArea (SVM∆ roc) [13], y un SVM de clasificación convencional (SVMacc) [20]. Todos los métodos de SVM utilizaron un kernel lineal. Informamos sobre el rendimiento promedio de todos los modelos en las 50 pruebas. 5.1 Comparación con Funciones Base Al analizar nuestros resultados, la primera pregunta a responder es, ¿puede SVM∆ map aprender un modelo que supere al mejor modelo base TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.290 - 0.287Mejor Func. 0.280 28/22 0.283 29/21 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 36/14 ** Tabla 7: Comparación con Envíos TREC TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288Mejor Func. 0.280 27/23 0.283 31/19 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 35/15 ** Tabla 8: Comparación con Funciones de Envíos TREC (sin el mejor) La Tabla 6 presenta la comparación del mapa SVM∆ con las mejores funciones base de Indri. Cada grupo de columnas contiene el rendimiento del MAP macro-promediado de SVM∆ map o una función base. Las columnas W/L muestran el número de consultas donde SVM∆ map logró un puntaje MAP más alto. Se realizaron pruebas de significancia utilizando la prueba de rango con signo de Wilcoxon de dos colas. Dos estrellas indican un nivel de significancia de 0.95. Todas las tablas que muestran nuestros resultados experimentales están estructuradas de manera idéntica. Aquí encontramos que SVM∆ mapea significativamente mejor que las mejores funciones base. La Tabla 7 muestra la comparación cuando se entrena con las presentaciones de TREC. Si bien logra una puntuación de MAP más alta que las mejores funciones base, la diferencia de rendimiento entre SVM∆ y las funciones base no es significativa. Dado que muchas de estas presentaciones utilizan funciones de puntuación cuidadosamente diseñadas para lograr un alto MAP, es posible que las presentaciones con mejor rendimiento utilicen técnicas que engloben las técnicas de las otras presentaciones. Como resultado, el mapa SVM∆ no sería capaz de aprender una hipótesis que pueda superar significativamente la mejor presentación. Por lo tanto, realizamos los mismos experimentos utilizando un conjunto de datos modificado en el que se eliminaron las características calculadas utilizando la mejor presentación. La tabla 8 muestra los resultados (ten en cuenta que aún estamos comparando con la mejor presentación, aunque no la estamos utilizando para el entrenamiento). Observa que si bien el rendimiento del SVM∆ map se degradó ligeramente, aún era comparable con el de la mejor presentación. 5.2 Comparación con Métodos SVM Anteriores La siguiente pregunta a responder es, ¿produce el SVM∆ map puntajes MAP más altos que los métodos SVM anteriores? Las tablas 9 y 10 presentan los resultados de SVM∆ map, SVM∆ roc y SVMacc cuando se entrenan con las funciones de recuperación de Indri y las presentaciones de TREC, respectivamente. La Tabla 11 contiene los resultados correspondientes cuando se entrena con las presentaciones de TREC sin la mejor presentación. Para empezar, nuestros resultados indican que SVMacc no fue competitivo con SVM∆ map y SVM∆ roc, y a veces tuvo un rendimiento notablemente inferior. Por lo tanto, probamos varios enfoques para mejorar el rendimiento de SVMacc. 5.2.1 Métodos alternativos de SVMacc Un problema que puede causar que SVMacc tenga un rendimiento deficiente es el desequilibrio severo entre documentos relevantes y no relevantes. La gran mayoría de los documentos no son relevantes. SVMacc2 aborda este problema asignando una penalización mayor a los errores de falsos negativos. Para cada conjunto de datos, la proporción de las penalizaciones por falsos negativos a falsos positivos es igual a la proporción entre el número de documentos no relevantes y relevantes en ese conjunto de datos. Las tablas 9, 10 y 11 indican que SVMacc2 sigue teniendo un rendimiento significativamente peor que SVM∆ map. Otro posible problema es que SVMacc intenta encontrar solo un umbral discriminatorio b que sea invariable a la consulta. Puede ser que diferentes consultas requieran diferentes valores de b. Tener el método de aprendizaje intentando encontrar un buen valor de b (cuando no existe) puede ser perjudicial. Tomamos dos enfoques para abordar este problema. El primer método, SVMacc3, convierte las puntuaciones de la función de recuperación en percentiles. Por ejemplo, para el documento d, la consulta q y la función de recuperación f, si la puntuación f(d|q) se encuentra en el 90% superior de las puntuaciones f(·|q) para la consulta q, entonces la puntuación convertida es f(d|q) = 0.9. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Las tablas 9, 10 y 11 muestran que el rendimiento de SVMacc3 tampoco fue competitivo con SVM∆ map. El segundo método, SVMacc4, normaliza las puntuaciones dadas por f para cada consulta. Por ejemplo, suponga para la consulta q que f produce puntuaciones en el rango de 0.2 a 0.7. Entonces, para el documento d, si f(d|q) = 0.6, la puntuación convertida sería f(d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Nuevamente, las Tablas 9, 10 y 11 muestran que SVMacc4 no fue competitivo con SVM∆ map 5.2.2 MAP vs ROCArea. SVM∆ roc tuvo un rendimiento mucho mejor que SVMacc en nuestros experimentos. Cuando se entrenó con las funciones de recuperación de Indri (ver Tabla 9), el rendimiento de SVM∆ roc fue ligeramente, aunque no significativamente, peor que el rendimiento de SVM∆ map. Sin embargo, la Tabla 10 muestra que el mapa SVM∆ superó significativamente al roc SVM∆ cuando se entrenó con las presentaciones de TREC. La tabla 11 muestra el rendimiento de los modelos cuando se entrenan con las presentaciones de TREC y se elimina la mejor presentación. El rendimiento de la mayoría de los modelos se degradó ligeramente, con SVM∆ map aún teniendo el mejor rendimiento. TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288 SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Tabla 11: Entrenado en TREC Subm. (sin Mejor) 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado un método SVM que optimiza directamente el MAP. Proporciona un enfoque basado en principios y evita heurísticas difíciles de controlar. Formulamos el problema de optimización y presentamos un algoritmo que encuentra la solución de manera demostrable en tiempo polinómico. Hemos demostrado empíricamente que nuestro método es generalmente superior o competitivo con los métodos convencionales de SVM. Nuestro nuevo método hace que sea conceptualmente tan fácil optimizar SVMs para MAP como anteriormente solo era posible para Precisión y Área bajo la curva ROC. El costo computacional para el entrenamiento es muy razonable en la práctica. Dado que otros métodos suelen requerir ajustar múltiples heurísticas, también esperamos entrenar menos modelos antes de encontrar uno que logre un buen rendimiento. El marco de aprendizaje utilizado por nuestro método es bastante general. Una extensión natural de este marco sería desarrollar métodos para optimizar otras medidas importantes de IR, como la Ganancia Acumulada Normalizada Descontada [2, 3, 4, 12] y la Reciprocidad Media de Rango. 7. AGRADECIMIENTOS Este trabajo fue financiado bajo el Premio NSF IIS-0412894, el Premio NSF CAREER 0237381 y un obsequio de Yahoo! Investigación. El tercer autor también fue parcialmente apoyado por una Beca de Investigación de Microsoft. 8. REFERENCIAS [1] B. T. Bartell, G. W. Cottrell y R. K. Belew. Combinación automática de múltiples sistemas de recuperación clasificados. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2005. [3] C. J. C. Burges, R. Ragno y Q. Lo. Aprendizaje para clasificar con funciones de costo no suaves. En Actas de la Conferencia Internacional sobre Avances en Sistemas de Información Neural (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang y H.-W. Hon. Adaptando el SVM de clasificación para la recuperación de documentos. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [5] B. Carterette y D. Petkova. Aprendiendo un ranking a partir de preferencias por pares. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew y A. Ksikes. Selección de conjunto de bibliotecas de modelos. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [7] J. Davis y M. Goadrich. La relación entre las curvas de precisión-recall y ROC. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2006. [8] D. Hawking. Resumen de la pista web TREC-9. En Actas de TREC-2000, 2000. [9] D. Hawking y N. Craswell. Resumen de la pista web TREC-2001. En Actas de TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel y K. Obermayer. Límites de rango de margen amplio para regresión ordinal. Avances en clasificadores de márgenes amplios, 2000. [11] A. Herschtal y B. Raskutti. Optimizando el área bajo la curva ROC utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [12] K. Jarvelin y J. Kekalainen. Métodos de evaluación para recuperar documentos altamente relevantes. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2000. [13] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), páginas 377-384, Nueva York, NY, EE. UU., 2005. ACM Press. [14] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), páginas 111-119, 2001. [15] Y. Lin, Y. Lee y G. Wahba. Máquinas de vectores de soporte para clasificación en situaciones no estándar. Aprendizaje automático, 46:191-202, 2002. [16] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [17] K. Morik, P. Brockhausen y T. Joachims. Combinando el aprendizaje estadístico con un enfoque basado en el conocimiento. En Actas de la Conferencia Internacional sobre Aprendizaje Automático, 1999. [18] S. Robertson. El principio de clasificación de probabilidad en la revista IR de documentación. Revista de Documentación, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims y Y. Altun. Métodos de margen amplio para variables de salida estructuradas e interdependientes. Revista de Investigación en Aprendizaje Automático (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik. Teoría del Aprendizaje Estadístico. Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz. \n\nWiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer y R. Wolniewicz. Optimizando el rendimiento del clasificador mediante la aproximación a la estadística de Wilcoxon-Mann-Witney. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2003. ",
            "candidates": [],
            "error": [
                [
                    "relajación de pérdida de bisagra",
                    "relajación de pérdida de MAP"
                ]
            ]
        },
        "map relaxation": {
            "translated_key": "relajación del mapa",
            "is_in_text": false,
            "original_annotated_sentences": [
                "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT Machine learning is commonly used to improve ranked retrieval systems.",
                "Due to computational difficulties, few learning techniques have been developed to directly optimize for mean average precision (MAP), despite its widespread use in evaluating such systems.",
                "Existing approaches optimizing MAP either do not find a globally optimal solution, or are computationally expensive.",
                "In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of MAP.",
                "We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora (WT10g), comparing against SVMs optimized for accuracy and ROCArea.",
                "In most cases we show our method to produce statistically significant improvements in MAP scores.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval Models General Terms Algorithm, Theory, Experimentation 1.",
                "INTRODUCTION State of the art information retrieval systems commonly use machine learning techniques to learn ranking functions.",
                "However, most current approaches do not optimize for the evaluation measure most often used, namely Mean Average Precision (MAP).",
                "Instead, current algorithms tend to take one of two general approaches.",
                "The first approach is to learn a model that estimates the probability of a document being relevant given a query (e.g., [18, 14]).",
                "If solved effectively, the ranking with best MAP performance can easily be derived from the probabilities of relevance.",
                "However, achieving high MAP only requires finding a good ordering of the documents.",
                "As a result, finding good probabilities requires solving a more difficult problem than necessary, likely requiring more training data to achieve the same MAP performance.",
                "The second common approach is to learn a function that maximizes a surrogate measure.",
                "Performance measures optimized include accuracy [17, 15], ROCArea [1, 5, 10, 11, 13, 21] or modifications of ROCArea [4], and NDCG [2, 3].",
                "Learning a model to optimize for such measures might result in suboptimal MAP performance.",
                "In fact, although some previous systems have obtained good MAP performance, it is known that neither achieving optimal accuracy nor ROCArea can guarantee optimal MAP performance[7].",
                "In this paper, we present a general approach for learning ranking functions that maximize MAP performance.",
                "Specifically, we present an SVM algorithm that globally optimizes a hinge-loss relaxation of MAP.",
                "This approach simplifies the process of obtaining ranking functions with high MAP performance by avoiding additional intermediate steps and heuristics.",
                "The new algorithm also makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for accuracy and ROCArea.",
                "In contrast to recent work directly optimizing for MAP performance by Metzler & Croft [16] and Caruana et al. [6], our technique is computationally efficient while finding a globally optimal solution.",
                "Like [6, 16], our method learns a linear model, but is much more efficient in practice and, unlike [16], can handle many thousands of features.",
                "We now describe the algorithm in detail and provide proof of correctness.",
                "Following this, we provide an analysis of running time.",
                "We finish with empirical results from experiments on the TREC 9 and TREC 10 Web Track corpus.",
                "We have also developed a software package implementing our algorithm that is available for public use1 . 2.",
                "THE LEARNING PROBLEM Following the standard machine learning setup, our goal is to learn a function h : X → Y between an input space X (all possible queries) and output space Y (rankings over a corpus).",
                "In order to quantify the quality of a prediction, ˆy = h(x), we will consider a loss function ∆ : Y × Y → . ∆(y, ˆy) quantifies the penalty for making prediction ˆy if the correct output is y.",
                "The loss function allows us to incorporate specific performance measures, which we will exploit 1 http://svmrank.yisongyue.com for optimizing MAP.",
                "We restrict ourselves to the supervised learning scenario, where input/output pairs (x, y) are available for training and are assumed to come from some fixed distribution P(x, y).",
                "The goal is to find a function h such that the risk (i.e., expected loss), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), is minimized.",
                "Of course, P(x, y) is unknown.",
                "But given a finite set of training pairs, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, the performance of h on S can be measured by the empirical risk, R∆ S (h) = 1 n nX i=1 ∆(yi, h(xi)).",
                "In the case of learning a ranked retrieval function, X denotes a space of queries, and Y the space of (possibly weak) rankings over some corpus of documents C = {d1, . . . ,d|C|}.",
                "We can define average precision loss as ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), where rank(y) is a vector of the rank values of each document in C. For example, for a corpus of two documents, {d1, d2}, with d1 having higher rank than d2, rank(y ) = (1, 0).",
                "We assume true rankings have two rank values, where relevant documents have rank value 1 and non-relevant documents rank value 0.",
                "We further assume that all predicted rankings are complete rankings (no ties).",
                "Let p = rank(y) and ˆp = rank(ˆy).",
                "The average precision score is defined as MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, where rel = |{i : pi = 1}| is the number of relevant documents, and Prec@j is the percentage of relevant documents in the top j documents in predicted ranking ˆy.",
                "MAP is the mean of the average precision scores of a group of queries. 2.1 MAP vs ROCArea Most learning algorithms optimize for accuracy or ROCArea.",
                "While optimizing for these measures might achieve good MAP performance, we use two simple examples to show it can also be suboptimal in terms of MAP.",
                "ROCArea assigns equal penalty to each misordering of a relevant/non-relevant pair.",
                "In contrast, MAP assigns greater penalties to misorderings higher up in the predicted ranking.",
                "Using our notation, ROCArea can be defined as ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], where p is the true (weak) ranking, ˆp is the predicted ranking, and 1[b] is the indicator function conditioned on b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Table 1: Toy Example and Models Suppose we have a hypothesis space with only two hypothesis functions, h1 and h2, as shown in Table 1.",
                "These two hypotheses predict a ranking for query x over a corpus of eight documents.",
                "Hypothesis MAP ROCArea h1(x) 0.59 0.47 h2(x) 0.51 0.53 Table 2: Performance of Toy Models Table 2 shows the MAP and ROCArea scores of h1 and h2.",
                "Here, a learning method which optimizes for ROCArea would choose h2 since that results in a higher ROCArea score, but this yields a suboptimal MAP score. 2.2 MAP vs Accuracy Using a very similar example, we now demonstrate how optimizing for accuracy might result in suboptimal MAP.",
                "Models which optimize for accuracy are not directly concerned with the ranking.",
                "Instead, they learn a threshold such that documents scoring higher than the threshold can be classified as relevant and documents scoring lower as nonrelevant.",
                "Doc ID 1 2 3 4 5 6 7 8 9 10 11 p 1 0 0 0 0 1 1 1 1 0 0 rank(h1(x)) 11 10 9 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 9 10 11 Table 3: Toy Example and Models We consider again a hypothesis space with two hypotheses.",
                "Table 3 shows the predictions of the two hypotheses on a single query x. Hypothesis MAP Best Acc. h1(q) 0.70 0.64 h2(q) 0.64 0.73 Table 4: Performance of Toy Models Table 4 shows the MAP and best accuracy scores of h1(q) and h2(q).",
                "The best accuracy refers to the highest achievable accuracy on that ranking when considering all possible thresholds.",
                "For instance, with h1(q), a threshold between documents 1 and 2 gives 4 errors (documents 6-9 incorrectly classified as non-relevant), yielding an accuracy of 0.64.",
                "Similarly, with h2(q), a threshold between documents 5 and 6 gives 3 errors (documents 10-11 incorrectly classified as relevant, and document 1 as non-relevant), yielding an accuracy of 0.73.",
                "A learning method which optimizes for accuracy would choose h2 since that results in a higher accuracy score, but this yields a suboptimal MAP score. 3.",
                "OPTIMIZING AVERAGE PRECISION We build upon the approach used by [13] for optimizing ROCArea.",
                "Unlike ROCArea, however, MAP does not decompose linearly in the examples and requires a substantially extended algorithm, which we describe in this section.",
                "Recall that the true ranking is a weak ranking with two rank values (relevant and non-relevant).",
                "Let Cx and C¯x denote the set of relevant and non-relevant documents of C for query x, respectively.",
                "We focus on functions which are parametrized by a weight vector w, and thus wish to find w to minimize the empirical risk, R∆ S (w) ≡ R∆ S (h(·; w)).",
                "Our approach is to learn a discriminant function F : X × Y → over input-output pairs.",
                "Given query x, we can derive a prediction by finding the ranking y that maximizes the discriminant function: h(x; w) = argmax y∈Y F(x, y; w). (1) We assume F to be linear in some combined feature representation of inputs and outputs Ψ(x, y) ∈ RN , i.e., F(x, y; w) = wT Ψ(x, y). (2) The combined feature function we use is Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))] , where φ : X × C → N is a feature mapping function from a query/document pair to a point in N dimensional space2 .",
                "We represent rankings as a matrix of pairwise orderings, Y ⊂ {−1, 0, +1}|C|×|C| .",
                "For any y ∈ Y, yij = +1 if di is ranked ahead of dj, and yij = −1 if dj is ranked ahead of di, and yij = 0 if di and dj have equal rank.",
                "We consider only matrices which correspond to valid rankings (i.e, obeying antisymmetry and transitivity).",
                "Intuitively, Ψ is a summation over the vector differences of all relevant/non-relevant document pairings.",
                "Since we assume predicted rankings to be complete rankings, yij is either +1 or −1 (never 0).",
                "Given a learned weight vector w, predicting a ranking (i.e. solving equation (1)) given query x reduces to picking each yij to maximize wT Ψ(x, y).",
                "As is also discussed in [13], this is attained by sorting the documents by wT φ(x, d) in descending order.",
                "We will discuss later the choices of φ we used for our experiments. 3.1 Structural SVMs The above formulation is very similar to learning a straightforward linear model while training on the pairwise difference of relevant/non-relevant document pairings.",
                "Many SVM-based approaches optimize over these pairwise differences (e.g., [5, 10, 13, 4]), although these methods do not optimize for MAP during training.",
                "Previously, it was not clear how to incorporate non-linear multivariate loss functions such as MAP loss directly into global optimization problems such as SVM training.",
                "We now present a method based on structural SVMs [19] to address this problem.",
                "We use the structural SVM formulation, presented in Optimization Problem 1, to learn a w ∈ RN .",
                "Optimization Problem 1. (Structural SVM) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) The objective function to be minimized (3) is a tradeoff between model complexity, w 2 , and a hinge loss relaxation of MAP loss, P ξi.",
                "As is usual in SVM training, C is a 2 For example, one dimension might be the number of times the query words appear in the document.",
                "Algorithm 1 Cutting plane algorithm for solving OP 1 within tolerance . 1: Input: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ for all i = 1, . . . , n 3: repeat 4: for i = 1, . . . , n do 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: compute ˆy = argmaxy∈Y H(y; w) 7: compute ξi = max{0, maxy∈Wi H(y; w)} 8: if H(ˆy; w) > ξi + then 9: Wi ← Wi ∪ {ˆy} 10: w ← optimize (3) over W = S i Wi 11: end if 12: end for 13: until no Wi has changed during iteration parameter that controls this tradeoff and can be tuned to achieve good performance in different training tasks.",
                "For each (xi, yi) in the training set, a set of constraints of the form in equation (4) is added to the optimization problem.",
                "Note that wT Ψ(x, y) is exactly our discriminant function F(x, y; w) (see equation (2)).",
                "During prediction, our model chooses the ranking which maximizes the discriminant (1).",
                "If the discriminant value for an incorrect ranking y is greater than for the true ranking yi (e.g., F(xi, y; w) > F(xi, yi; w)), then corresponding slack variable, ξi, must be at least ∆(yi, y) for that constraint to be satisfied.",
                "Therefore, the sum of slacks, P ξi, upper bounds the MAP loss.",
                "This is stated formally in Proposition 1.",
                "Proposition 1.",
                "Let ξ∗ (w) be the optimal solution of the slack variables for OP 1 for a given weight vector w. Then 1 n Pn i=1 ξi is an upper bound on the empirical risk R∆ S (w). (see [19] for proof) Proposition 1 shows that OP 1 learns a ranking function that optimizes an upper bound on MAP error on the training set.",
                "Unfortunately there is a problem: a constraint is required for every possible wrong output y, and the number of possible wrong outputs is exponential in the size of C. Fortunately, we may employ Algorithm 1 to solve OP 1.",
                "Algorithm 1 is a cutting plane algorithm, iteratively introducing constraints until we have solved the original problem within a desired tolerance [19].",
                "The algorithm starts with no constraints, and iteratively finds for each example (xi, yi) the output ˆy associated with the most violated constraint.",
                "If the corresponding constraint is violated by more than we introduce ˆy into the working set Wi of active constraints for example i, and re-solve (3) using the updated W. It can be shown that Algorithm 1s outer loop is guaranteed to halt within a polynomial number of iterations for any desired precision .",
                "Theorem 1.",
                "Let ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y) , ¯∆ = maxi maxy ∆(yi, y), and for any > 0, Algorithm 1 terminates after adding at most max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff constraints to the working set W. (see [19] for proof) However, within the inner loop of this algorithm we have to compute argmaxy∈Y H(y; w), where H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), or equivalently, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), since wT Ψ(xi, yi) is constant with respect to y.",
                "Though closely related to the classification procedure, this has the substantial complication that we must contend with the additional ∆(yi, y) term.",
                "Without the ability to efficiently find the most violated constraint (i.e., solve argmaxy∈Y H(y, w)), the constraint generation procedure is not tractable. 3.2 Finding the Most Violated Constraint Using OP 1 and optimizing to ROCArea loss (∆roc), the problem of finding the most violated constraint, or solving argmaxy∈Y H(y, w) (henceforth argmax H), is addressed in [13].",
                "Solving argmax H for ∆map is more difficult.",
                "This is primarily because ROCArea decomposes nicely into a sum of scores computed independently on each relative ordering of a relevant/non-relevant document pair.",
                "MAP, on the other hand, does not decompose in the same way as ROCArea.",
                "The main algorithmic contribution of this paper is an efficient method for solving argmax H for ∆map.",
                "One useful property of ∆map is that it is invariant to swapping two documents with equal relevance.",
                "For example, if documents da and db are both relevant, then swapping the positions of da and db in any ranking does not affect ∆map.",
                "By extension, ∆map is invariant to any arbitrary permutation of the relevant documents amongst themselves and of the non-relevant documents amongst themselves.",
                "However, this reshuﬄing will affect the discriminant score, wT Ψ(x, y).",
                "This leads us to Observation 1.",
                "Observation 1.",
                "Consider rankings which are constrained by fixing the relevance at each position in the ranking (e.g., the 3rd document in the ranking must be relevant).",
                "Every ranking which satisfies the same set of constraints will have the same ∆map.",
                "If the relevant documents are sorted by wT φ(x, d) in descending order, and the non-relevant documents are likewise sorted by wT φ(x, d), then the interleaving of the two sorted lists which satisfies the constraints will maximize H for that constrained set of rankings.",
                "Observation 1 implies that in the ranking which maximizes H, the relevant documents will be sorted by wT φ(x, d), and the non-relevant documents will also be sorted likewise.",
                "By first sorting the relevant and non-relevant documents, the problem is simplified to finding the optimal interleaving of two sorted lists.",
                "For the rest of our discussion, we assume that the relevant documents and non-relevant documents are both sorted by descending wT φ(x, d).",
                "For convenience, we also refer to relevant documents as {dx 1 , . . . dx |Cx|} = Cx , and non-relevant documents as {d¯x 1 , . . . d¯x |C¯x|} = C¯x .",
                "We define δj(i1, i2), with i1 < i2, as the change in H from when the highest ranked relevant document ranked after d¯x j is dx i1 to when it is dx i2 .",
                "For i2 = i1 + 1, we have δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5) where si = wT φ(x, di).",
                "The first term in (5) is the change in ∆map when the ith relevant document has j non-relevant documents ranked before it, as opposed to j −1.",
                "The second term is the change in the discriminant score, wT Ψ(x, y), when yij changes from +1 to −1. . . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . .",
                "Figure 1: Example for δj(i, i + 1) Figure 1 gives a conceptual example for δj(i, i + 1).",
                "The bottom ranking differs from the top only where d¯x j slides up one rank.",
                "The difference in the value of H for these two rankings is exactly δj(i, i + 1).",
                "For any i1 < i2, we can then define δj(i1, i2) as δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) or equivalently, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) .",
                "Let o1, . . . , o|C¯x| encode the positions of the non-relevant documents, where dx oj is the highest ranked relevant document ranked after the jth non-relevant document.",
                "Due to Observation 1, this encoding uniquely identifies a complete ranking.",
                "We can recover the ranking as yij = 8 >>>< >>>: 0 if i = j sign(si − sj) if di, dj equal relevance sign(oj − i − 0.5) if di = dx i , dj = d¯x j sign(j − oi + 0.5) if di = d¯x i , dj = dx j . (7) We can now reformulate H into a new objective function, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), where ¯y is the true (weak) ranking.",
                "Conceptually H starts with a perfect ranking ¯y, and adds the change in H when each successive non-relevant document slides up the ranking.",
                "We can then reformulate the argmax H problem as argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) s.t. o1 ≤ . . . ≤ o|C¯x|. (9) Algorithm 2 describes the algorithm used to solve equation (8).",
                "Conceptually, Algorithm 2 starts with a perfect ranking.",
                "Then for each successive non-relevant document, the algorithm modifies the solution by sliding that document up the ranking to locally maximize H while keeping the positions of the other non-relevant documents constant. 3.2.1 Proof of Correctness Algorithm 2 is greedy in the sense that it finds the best position of each non-relevant document independently from the other non-relevant documents.",
                "In other words, the algorithm maximizes H for each non-relevant document, d¯x j , Algorithm 2 Finding the Most Violated Constraint (argmax H) for Algorithm 1 with ∆map 1: Input: w, Cx , C¯x 2: sort Cx and C¯x in descending order of wT φ(x, d) 3: sx i ← wT φ(x, dx i ), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i ), i = 1, . . . , |C¯x | 5: for j = 1, . . . , |C¯x | do 6: optj ← argmaxk δj(k, |Cx | + 1) 7: end for 8: encode ˆy according to (7) 9: return ˆy without considering the positions of the other non-relevant documents, and thus ignores the constraints of (9).",
                "In order for the solution to be feasible, the jth non-relevant document must be ranked after the first j − 1 non-relevant documents, thus satisfying opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. (10) If the solution is feasible, the it clearly solves (8).",
                "Therefore, it suffices to prove that Algorithm 2 satisfies (10).",
                "We first prove that δj(·, ·) is monotonically decreasing in j. Lemma 1.",
                "For any 1 ≤ i1 < i2 ≤ |Cx | + 1 and 1 ≤ j < |C¯x |, it must be the case that δj+1(i1, i2) ≤ δj(i1, i2).",
                "Proof.",
                "Recall from (6) that both δj(i1, i2) and δj+1(i1, i2) are summations of i2 − i1 terms.",
                "We will show that each term in the summation of δj+1(i1, i2) is no greater than the corresponding term in δj(i1, i2), or δj+1(k, k + 1) ≤ δj(k, k + 1) for k = i1, . . . , i2 − 1.",
                "Each term in δj(k, k +1) and δj+1(k, k +1) can be further decomposed into two parts (see (5)).",
                "We will show that each part of δj+1(k, k + 1) is no greater than the corresponding part in δj(k, k + 1).",
                "In other words, we will show that both j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) and −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) are true for the aforementioned values of j and k. It is easy to see that (11) is true by observing that for any two positive integers 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1 , and choosing a = j and b = j + k. The second inequality (12) holds because Algorithm 2 first sorts d¯x in descending order of s¯x , implying s¯x j+1 ≤ s¯x j .",
                "Thus we see that each term in δj+1 is no greater than the corresponding term in δj, which completes the proof.",
                "The result of Lemma 1 leads directly to our main correctness result: Theorem 2.",
                "In Algorithm 2, the computed values of optj satisfy (10), implying that the solution returned by Algorithm 2 is feasible and thus optimal.",
                "Proof.",
                "We will prove that optj ≤ optj+1 holds for any 1 ≤ j < |C¯x |, thus implying (10).",
                "Since Algorithm 2 computes optj as optj = argmax k δj(k, |Cx | + 1), (13) then by definition of δj (6), for any 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0.",
                "Using Lemma 1, we know that δj+1(i, optj) ≤ δj(i, optj) < 0, which implies that for any 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0.",
                "Suppose for contradiction that optj+1 < optj.",
                "Then δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), which contradicts (13).",
                "Therefore, it must be the case that optj ≤ optj+1, which completes the proof. 3.2.2 Running Time The running time of Algorithm 2 can be split into two parts.",
                "The first part is the sort by wT φ(x, d), which requires O(n log n) time, where n = |Cx | + |C¯x |.",
                "The second part computes each optj, which requires O(|Cx | · |C¯x |) time.",
                "Though in the worst case this is O(n2 ), the number of relevant documents, |Cx |, is often very small (e.g., constant with respect to n), in which case the running time for the second part is simply O(n).",
                "For most real-world datasets, Algorithm 2 is dominated by the sort and has complexity O(n log n).",
                "Algorithm 1 is guaranteed to halt in a polynomial number of iterations [19], and each iteration runs Algorithm 2.",
                "Virtually all well-performing models were trained in a reasonable amount of time (usually less than one hour).",
                "Once training is complete, making predictions on query x using the resulting hypothesis h(x|w) requires only sorting by wT φ(x, d).",
                "We developed our software using a Python interface3 to SVMstruct , since the Python language greatly simplified the coding process.",
                "To improve performance, it is advisable to use the standard C implementation4 of SVMstruct . 4.",
                "EXPERIMENT SETUP The main goal of our experiments is to evaluate whether directly optimizing MAP leads to improved MAP performance compared to conventional SVM methods that optimize a substitute loss such as accuracy or ROCArea.",
                "We empirically evaluate our method using two sets of TREC Web Track queries, one each from TREC 9 and TREC 10 (topics 451-500 and 501-550), both of which used the WT10g corpus.",
                "For each query, TREC provides the relevance judgments of the documents.",
                "We generated our features using the scores of existing retrieval functions on these queries.",
                "While our method is agnostic to the meaning of the features, we chose to use existing retrieval functions as a simple yet effective way of acquiring useful features.",
                "As such, our 3 http://www.cs.cornell.edu/~tomf/svmpython/ 4 http://svmlight.joachims.org/svm_struct.html Dataset Base Funcs Features TREC 9 Indri 15 750 TREC 10 Indri 15 750 TREC 9 Submissions 53 2650 TREC 10 Submissions 18 900 Table 5: Dataset Statistics experiments essentially test our methods ability to re-rank the highly ranked documents (e.g., re-combine the scores of the retrieval functions) to improve MAP.",
                "We compare our method against the best retrieval functions trained on (henceforth base functions), as well as against previously proposed SVM methods.",
                "Comparing with the best base functions tests our methods ability to learn a useful combination.",
                "Comparing with previous SVM methods allows us to test whether optimizing directly for MAP (as opposed to accuracy or ROCArea) achieves a higher MAP score in practice.",
                "The rest of this section describes the base functions and the feature generation method in detail. 4.1 Choosing Retrieval Functions We chose two sets of base functions for our experiments.",
                "For the first set, we generated three indices over the WT10g corpus using Indri5 .",
                "The first index was generated using default settings, the second used Porter-stemming, and the last used Porter-stemming and Indris default stopwords.",
                "For both TREC 9 and TREC 10, we used the description portion of each query and scored the documents using five of Indris built-in retrieval methods, which are Cosine Similarity, TFIDF, Okapi, Language Model with Dirichlet Prior, and Language Model with Jelinek-Mercer Prior.",
                "All parameters were kept as their defaults.",
                "We computed the scores of these five retrieval methods over the three indices, giving 15 base functions in total.",
                "For each query, we considered the scores of documents found in the union of the top 1000 documents of each base function.",
                "For our second set of base functions, we used scores from the TREC 9 [8] and TREC 10 [9] Web Track submissions.",
                "We used only the non-manual, non-short submissions from both years.",
                "For TREC 9 and TREC 10, there were 53 and 18 such submissions, respectively.",
                "A typical submission contained scores of its top 1000 documents. b ca wT φ(x,d) f(d|x) Figure 2: Example Feature Binning 4.2 Generating Features In order to generate input examples for our method, a concrete instantiation of φ must be provided.",
                "For each doc5 http://www.lemurproject.org TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236Best Func. 0.204 39/11 ** 0.181 37/13 ** 2nd Best 0.199 38/12 ** 0.174 43/7 ** 3rd Best 0.188 34/16 ** 0.174 38/12 ** Table 6: Comparison with Indri Functions ument d scored by a set of retrieval functions F on query x, we generate the features as a vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf , where f(d|x) denotes the score that retrieval function f assigns to document d for query x, and each Kf is a set of real values.",
                "From a high level, we are expressing the score of each retrieval function using |Kf | + 1 bins.",
                "Since we are using linear kernels, one can think of the learning problem as finding a good piecewise-constant combination of the scores of the retrieval functions.",
                "Figure 2 shows an example of our feature mapping method.",
                "In this example we have a single feature F = {f}.",
                "Here, Kf = {a, b, c}, and the weight vector is w = wa, wb, wc .",
                "For any document d and query x, we have wT φ(x, d) = 8 >>< >>: 0 if f(d|x) < a wa if a ≤ f(d|x) < b wa + wb if b ≤ f(d|x) < c wa + wb + wc if c ≤ f(d|x) .",
                "This is expressed qualitatively in Figure 2, where wa and wb are positive, and wc is negative.",
                "We ran our main experiments using four choices of F: the set of aforementioned Indri retrieval functions for TREC 9 and TREC 10, and the Web Track submissions for TREC 9 and TREC 10.",
                "For each F and each function f ∈ F, we chose 50 values for Kf which are reasonably spaced and capture the sensitive region of f. Using the four choices of F, we generated four datasets for our main experiments.",
                "Table 5 contains statistics of the generated datasets.",
                "There are many ways to generate features, and we are not advocating our method over others.",
                "This was simply an efficient means to normalize the outputs of different functions and allow for a more expressive model. 5.",
                "EXPERIMENTS For each dataset in Table 5, we performed 50 trials.",
                "For each trial, we train on 10 randomly selected queries, and select another 5 queries at random for a validation set.",
                "Models were trained using a wide range of C values.",
                "The model which performed best on the validation set was selected and tested on the remaining 35 queries.",
                "All queries were selected to be in the training, validation and test sets the same number of times.",
                "Using this setup, we performed the same experiments while using our method (SVM∆ map), an SVM optimizing for ROCArea (SVM∆ roc) [13], and a conventional classification SVM (SVMacc) [20].",
                "All SVM methods used a linear kernel.",
                "We reported the average performance of all models over the 50 trials. 5.1 Comparison with Base Functions In analyzing our results, the first question to answer is, can SVM∆ map learn a model which outperforms the best base TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287Best Func. 0.280 28/22 0.283 29/21 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 36/14 ** Table 7: Comparison with TREC Submissions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288Best Func. 0.280 27/23 0.283 31/19 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 35/15 ** Table 8: Comparison with TREC Subm. (w/o best) functions?",
                "Table 6 presents the comparison of SVM∆ map with the best Indri base functions.",
                "Each column group contains the macro-averaged MAP performance of SVM∆ map or a base function.",
                "The W/L columns show the number of queries where SVM∆ map achieved a higher MAP score.",
                "Significance tests were performed using the two-tailed Wilcoxon signed rank test.",
                "Two stars indicate a significance level of 0.95.",
                "All tables displaying our experimental results are structured identically.",
                "Here, we find that SVM∆ map significantly outperforms the best base functions.",
                "Table 7 shows the comparison when trained on TREC submissions.",
                "While achieving a higher MAP score than the best base functions, the performance difference between SVM∆ map the base functions is not significant.",
                "Given that many of these submissions use scoring functions which are carefully crafted to achieve high MAP, it is possible that the best performing submissions use techniques which subsume the techniques of the other submissions.",
                "As a result, SVM∆ map would not be able to learn a hypothesis which can significantly out-perform the best submission.",
                "Hence, we ran the same experiments using a modified dataset where the features computed using the best submission were removed.",
                "Table 8 shows the results (note that we are still comparing against the best submission though we are not using it for training).",
                "Notice that while the performance of SVM∆ map degraded slightly, the performance was still comparable with that of the best submission. 5.2 Comparison w/ Previous SVM Methods The next question to answer is, does SVM∆ map produce higher MAP scores than previous SVM methods?",
                "Tables 9 and 10 present the results of SVM∆ map, SVM∆ roc, and SVMacc when trained on the Indri retrieval functions and TREC submissions, respectively.",
                "Table 11 contains the corresponding results when trained on the TREC submissions without the best submission.",
                "To start with, our results indicate that SVMacc was not competitive with SVM∆ map and SVM∆ roc, and at times underperformed dramatically.",
                "As such, we tried several approaches to improve the performance of SVMacc. 5.2.1 Alternate SVMacc Methods One issue which may cause SVMacc to underperform is the severe imbalance between relevant and non-relevant docTREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236SVM∆ roc 0.237 29/21 0.234 24/26 SVMacc 0.147 47/3 ** 0.155 47/3 ** SVMacc2 0.219 39/11 ** 0.207 43/7 ** SVMacc3 0.113 49/1 ** 0.153 45/5 ** SVMacc4 0.155 48/2 ** 0.155 48/2 ** Table 9: Trained on Indri Functions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287SVM∆ roc 0.282 29/21 0.278 35/15 ** SVMacc 0.213 49/1 ** 0.222 49/1 ** SVMacc2 0.270 34/16 ** 0.261 42/8 ** SVMacc3 0.133 50/0 ** 0.182 46/4 ** SVMacc4 0.233 47/3 ** 0.238 46/4 ** Table 10: Trained on TREC Submissions uments.",
                "The vast majority of the documents are not relevant.",
                "SVMacc2 addresses this problem by assigning more penalty to false negative errors.",
                "For each dataset, the ratio of the false negative to false positive penalties is equal to the ratio of the number non-relevant and relevant documents in that dataset.",
                "Tables 9, 10 and 11 indicate that SVMacc2 still performs significantly worse than SVM∆ map.",
                "Another possible issue is that SVMacc attempts to find just one discriminating threshold b that is query-invariant.",
                "It may be that different queries require different values of b.",
                "Having the learning method trying to find a good b value (when one does not exist) may be detrimental.",
                "We took two approaches to address this issue.",
                "The first method, SVMacc3, converts the retrieval function scores into percentiles.",
                "For example, for document d, query q and retrieval function f, if the score f(d|q) is in the top 90% of the scores f(·|q) for query q, then the converted score is f (d|q) = 0.9.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Tables 9, 10 and 11 show that the performance of SVMacc3 was also not competitive with SVM∆ map.",
                "The second method, SVMacc4, normalizes the scores given by f for each query.",
                "For example, assume for query q that f outputs scores in the range 0.2 to 0.7.",
                "Then for document d, if f(d|q) = 0.6, the converted score would be f (d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Again, Tables 9, 10 and 11 show that SVMacc4 was not competitive with SVM∆ map 5.2.2 MAP vs ROCArea SVM∆ roc performed much better than SVMacc in our experiments.",
                "When trained on Indri retrieval functions (see Table 9), the performance of SVM∆ roc was slight, though not significantly, worse than the performances of SVM∆ map.",
                "However, Table 10 shows that SVM∆ map did significantly outperform SVM∆ roc when trained on the TREC submissions.",
                "Table 11 shows the performance of the models when trained on the TREC submissions with the best submission removed.",
                "The performance of most models degraded by a small amount, with SVM∆ map still having the best performance.",
                "TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Table 11: Trained on TREC Subm. (w/o Best) 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented an SVM method that directly optimizes MAP.",
                "It provides a principled approach and avoids difficult to control heuristics.",
                "We formulated the optimization problem and presented an algorithm which provably finds the solution in polynomial time.",
                "We have shown empirically that our method is generally superior to or competitive with conventional SVMs methods.",
                "Our new method makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for Accuracy and ROCArea.",
                "The computational cost for training is very reasonable in practice.",
                "Since other methods typically require tuning multiple heuristics, we also expect to train fewer models before finding one which achieves good performance.",
                "The learning framework used by our method is fairly general.",
                "A natural extension of this framework would be to develop methods to optimize for other important IR measures, such as Normalized Discounted Cumulative Gain [2, 3, 4, 12] and Mean Reciprocal Rank. 7.",
                "ACKNOWLEDGMENTS This work was funded under NSF Award IIS-0412894, NSF CAREER Award 0237381, and a gift from Yahoo!",
                "Research.",
                "The third author was also partly supported by a Microsoft Research Fellowship. 8.",
                "REFERENCES [1] B. T. Bartell, G. W. Cottrell, and R. K. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2005. [3] C. J. C. Burges, R. Ragno, and Q.",
                "Le.",
                "Learning to rank with non-smooth cost functions.",
                "In Proceedings of the International Conference on Advances in Neural Information Processing Systems (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y.",
                "Liu, H. Li, Y. Huang, and H.-W. Hon.",
                "Adapting ranking SVM to document retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [5] B. Carterette and D. Petkova.",
                "Learning a ranking from pairwise preferences.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew, and A. Ksikes.",
                "Ensemble selection from libraries of models.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [7] J. Davis and M. Goadrich.",
                "The relationship between precision-recall and ROC curves.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2006. [8] D. Hawking.",
                "Overview of the TREC-9 web track.",
                "In Proceedings of TREC-2000, 2000. [9] D. Hawking and N. Craswell.",
                "Overview of the TREC-2001 web track.",
                "In Proceedings of TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel, and K. Obermayer.",
                "Large margin rank boundaries for ordinal regression.",
                "Advances in large margin classifiers, 2000. [11] A. Herschtal and B. Raskutti.",
                "Optimising area under the ROC curve using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [12] K. Jarvelin and J. Kekalainen.",
                "Ir evaluation methods for retrieving highly relevant documents.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2000. [13] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proceedings of the International Conference on Machine Learning (ICML), pages 377-384, New York, NY, USA, 2005.",
                "ACM Press. [14] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 111-119, 2001. [15] Y. Lin, Y. Lee, and G. Wahba.",
                "Support vector machines for classification in nonstandard situations.",
                "Machine Learning, 46:191-202, 2002. [16] D. Metzler and W. B. Croft.",
                "A markov random field model for term dependencies.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 472-479, 2005. [17] K. Morik, P. Brockhausen, and T. Joachims.",
                "Combining statistical learning with a knowledge-based approach.",
                "In Proceedings of the International Conference on Machine Learning, 1999. [18] S. Robertson.",
                "The probability ranking principle in ir. journal of documentation.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.",
                "Large margin methods for structured and interdependent output variables.",
                "Journal of Machine Learning Research (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik.",
                "Statistical Learning Theory.",
                "Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz.",
                "Optimizing classifier performance via approximation to the Wilcoxon-Mann-Witney statistic.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2003."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "information retrieval system": {
            "translated_key": "sistemas de recuperación de información",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT Machine learning is commonly used to improve ranked retrieval systems.",
                "Due to computational difficulties, few learning techniques have been developed to directly optimize for mean average precision (MAP), despite its widespread use in evaluating such systems.",
                "Existing approaches optimizing MAP either do not find a globally optimal solution, or are computationally expensive.",
                "In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of MAP.",
                "We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora (WT10g), comparing against SVMs optimized for accuracy and ROCArea.",
                "In most cases we show our method to produce statistically significant improvements in MAP scores.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval Models General Terms Algorithm, Theory, Experimentation 1.",
                "INTRODUCTION State of the art <br>information retrieval system</br>s commonly use machine learning techniques to learn ranking functions.",
                "However, most current approaches do not optimize for the evaluation measure most often used, namely Mean Average Precision (MAP).",
                "Instead, current algorithms tend to take one of two general approaches.",
                "The first approach is to learn a model that estimates the probability of a document being relevant given a query (e.g., [18, 14]).",
                "If solved effectively, the ranking with best MAP performance can easily be derived from the probabilities of relevance.",
                "However, achieving high MAP only requires finding a good ordering of the documents.",
                "As a result, finding good probabilities requires solving a more difficult problem than necessary, likely requiring more training data to achieve the same MAP performance.",
                "The second common approach is to learn a function that maximizes a surrogate measure.",
                "Performance measures optimized include accuracy [17, 15], ROCArea [1, 5, 10, 11, 13, 21] or modifications of ROCArea [4], and NDCG [2, 3].",
                "Learning a model to optimize for such measures might result in suboptimal MAP performance.",
                "In fact, although some previous systems have obtained good MAP performance, it is known that neither achieving optimal accuracy nor ROCArea can guarantee optimal MAP performance[7].",
                "In this paper, we present a general approach for learning ranking functions that maximize MAP performance.",
                "Specifically, we present an SVM algorithm that globally optimizes a hinge-loss relaxation of MAP.",
                "This approach simplifies the process of obtaining ranking functions with high MAP performance by avoiding additional intermediate steps and heuristics.",
                "The new algorithm also makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for accuracy and ROCArea.",
                "In contrast to recent work directly optimizing for MAP performance by Metzler & Croft [16] and Caruana et al. [6], our technique is computationally efficient while finding a globally optimal solution.",
                "Like [6, 16], our method learns a linear model, but is much more efficient in practice and, unlike [16], can handle many thousands of features.",
                "We now describe the algorithm in detail and provide proof of correctness.",
                "Following this, we provide an analysis of running time.",
                "We finish with empirical results from experiments on the TREC 9 and TREC 10 Web Track corpus.",
                "We have also developed a software package implementing our algorithm that is available for public use1 . 2.",
                "THE LEARNING PROBLEM Following the standard machine learning setup, our goal is to learn a function h : X → Y between an input space X (all possible queries) and output space Y (rankings over a corpus).",
                "In order to quantify the quality of a prediction, ˆy = h(x), we will consider a loss function ∆ : Y × Y → . ∆(y, ˆy) quantifies the penalty for making prediction ˆy if the correct output is y.",
                "The loss function allows us to incorporate specific performance measures, which we will exploit 1 http://svmrank.yisongyue.com for optimizing MAP.",
                "We restrict ourselves to the supervised learning scenario, where input/output pairs (x, y) are available for training and are assumed to come from some fixed distribution P(x, y).",
                "The goal is to find a function h such that the risk (i.e., expected loss), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), is minimized.",
                "Of course, P(x, y) is unknown.",
                "But given a finite set of training pairs, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, the performance of h on S can be measured by the empirical risk, R∆ S (h) = 1 n nX i=1 ∆(yi, h(xi)).",
                "In the case of learning a ranked retrieval function, X denotes a space of queries, and Y the space of (possibly weak) rankings over some corpus of documents C = {d1, . . . ,d|C|}.",
                "We can define average precision loss as ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), where rank(y) is a vector of the rank values of each document in C. For example, for a corpus of two documents, {d1, d2}, with d1 having higher rank than d2, rank(y ) = (1, 0).",
                "We assume true rankings have two rank values, where relevant documents have rank value 1 and non-relevant documents rank value 0.",
                "We further assume that all predicted rankings are complete rankings (no ties).",
                "Let p = rank(y) and ˆp = rank(ˆy).",
                "The average precision score is defined as MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, where rel = |{i : pi = 1}| is the number of relevant documents, and Prec@j is the percentage of relevant documents in the top j documents in predicted ranking ˆy.",
                "MAP is the mean of the average precision scores of a group of queries. 2.1 MAP vs ROCArea Most learning algorithms optimize for accuracy or ROCArea.",
                "While optimizing for these measures might achieve good MAP performance, we use two simple examples to show it can also be suboptimal in terms of MAP.",
                "ROCArea assigns equal penalty to each misordering of a relevant/non-relevant pair.",
                "In contrast, MAP assigns greater penalties to misorderings higher up in the predicted ranking.",
                "Using our notation, ROCArea can be defined as ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], where p is the true (weak) ranking, ˆp is the predicted ranking, and 1[b] is the indicator function conditioned on b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Table 1: Toy Example and Models Suppose we have a hypothesis space with only two hypothesis functions, h1 and h2, as shown in Table 1.",
                "These two hypotheses predict a ranking for query x over a corpus of eight documents.",
                "Hypothesis MAP ROCArea h1(x) 0.59 0.47 h2(x) 0.51 0.53 Table 2: Performance of Toy Models Table 2 shows the MAP and ROCArea scores of h1 and h2.",
                "Here, a learning method which optimizes for ROCArea would choose h2 since that results in a higher ROCArea score, but this yields a suboptimal MAP score. 2.2 MAP vs Accuracy Using a very similar example, we now demonstrate how optimizing for accuracy might result in suboptimal MAP.",
                "Models which optimize for accuracy are not directly concerned with the ranking.",
                "Instead, they learn a threshold such that documents scoring higher than the threshold can be classified as relevant and documents scoring lower as nonrelevant.",
                "Doc ID 1 2 3 4 5 6 7 8 9 10 11 p 1 0 0 0 0 1 1 1 1 0 0 rank(h1(x)) 11 10 9 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 9 10 11 Table 3: Toy Example and Models We consider again a hypothesis space with two hypotheses.",
                "Table 3 shows the predictions of the two hypotheses on a single query x. Hypothesis MAP Best Acc. h1(q) 0.70 0.64 h2(q) 0.64 0.73 Table 4: Performance of Toy Models Table 4 shows the MAP and best accuracy scores of h1(q) and h2(q).",
                "The best accuracy refers to the highest achievable accuracy on that ranking when considering all possible thresholds.",
                "For instance, with h1(q), a threshold between documents 1 and 2 gives 4 errors (documents 6-9 incorrectly classified as non-relevant), yielding an accuracy of 0.64.",
                "Similarly, with h2(q), a threshold between documents 5 and 6 gives 3 errors (documents 10-11 incorrectly classified as relevant, and document 1 as non-relevant), yielding an accuracy of 0.73.",
                "A learning method which optimizes for accuracy would choose h2 since that results in a higher accuracy score, but this yields a suboptimal MAP score. 3.",
                "OPTIMIZING AVERAGE PRECISION We build upon the approach used by [13] for optimizing ROCArea.",
                "Unlike ROCArea, however, MAP does not decompose linearly in the examples and requires a substantially extended algorithm, which we describe in this section.",
                "Recall that the true ranking is a weak ranking with two rank values (relevant and non-relevant).",
                "Let Cx and C¯x denote the set of relevant and non-relevant documents of C for query x, respectively.",
                "We focus on functions which are parametrized by a weight vector w, and thus wish to find w to minimize the empirical risk, R∆ S (w) ≡ R∆ S (h(·; w)).",
                "Our approach is to learn a discriminant function F : X × Y → over input-output pairs.",
                "Given query x, we can derive a prediction by finding the ranking y that maximizes the discriminant function: h(x; w) = argmax y∈Y F(x, y; w). (1) We assume F to be linear in some combined feature representation of inputs and outputs Ψ(x, y) ∈ RN , i.e., F(x, y; w) = wT Ψ(x, y). (2) The combined feature function we use is Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))] , where φ : X × C → N is a feature mapping function from a query/document pair to a point in N dimensional space2 .",
                "We represent rankings as a matrix of pairwise orderings, Y ⊂ {−1, 0, +1}|C|×|C| .",
                "For any y ∈ Y, yij = +1 if di is ranked ahead of dj, and yij = −1 if dj is ranked ahead of di, and yij = 0 if di and dj have equal rank.",
                "We consider only matrices which correspond to valid rankings (i.e, obeying antisymmetry and transitivity).",
                "Intuitively, Ψ is a summation over the vector differences of all relevant/non-relevant document pairings.",
                "Since we assume predicted rankings to be complete rankings, yij is either +1 or −1 (never 0).",
                "Given a learned weight vector w, predicting a ranking (i.e. solving equation (1)) given query x reduces to picking each yij to maximize wT Ψ(x, y).",
                "As is also discussed in [13], this is attained by sorting the documents by wT φ(x, d) in descending order.",
                "We will discuss later the choices of φ we used for our experiments. 3.1 Structural SVMs The above formulation is very similar to learning a straightforward linear model while training on the pairwise difference of relevant/non-relevant document pairings.",
                "Many SVM-based approaches optimize over these pairwise differences (e.g., [5, 10, 13, 4]), although these methods do not optimize for MAP during training.",
                "Previously, it was not clear how to incorporate non-linear multivariate loss functions such as MAP loss directly into global optimization problems such as SVM training.",
                "We now present a method based on structural SVMs [19] to address this problem.",
                "We use the structural SVM formulation, presented in Optimization Problem 1, to learn a w ∈ RN .",
                "Optimization Problem 1. (Structural SVM) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) The objective function to be minimized (3) is a tradeoff between model complexity, w 2 , and a hinge loss relaxation of MAP loss, P ξi.",
                "As is usual in SVM training, C is a 2 For example, one dimension might be the number of times the query words appear in the document.",
                "Algorithm 1 Cutting plane algorithm for solving OP 1 within tolerance . 1: Input: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ for all i = 1, . . . , n 3: repeat 4: for i = 1, . . . , n do 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: compute ˆy = argmaxy∈Y H(y; w) 7: compute ξi = max{0, maxy∈Wi H(y; w)} 8: if H(ˆy; w) > ξi + then 9: Wi ← Wi ∪ {ˆy} 10: w ← optimize (3) over W = S i Wi 11: end if 12: end for 13: until no Wi has changed during iteration parameter that controls this tradeoff and can be tuned to achieve good performance in different training tasks.",
                "For each (xi, yi) in the training set, a set of constraints of the form in equation (4) is added to the optimization problem.",
                "Note that wT Ψ(x, y) is exactly our discriminant function F(x, y; w) (see equation (2)).",
                "During prediction, our model chooses the ranking which maximizes the discriminant (1).",
                "If the discriminant value for an incorrect ranking y is greater than for the true ranking yi (e.g., F(xi, y; w) > F(xi, yi; w)), then corresponding slack variable, ξi, must be at least ∆(yi, y) for that constraint to be satisfied.",
                "Therefore, the sum of slacks, P ξi, upper bounds the MAP loss.",
                "This is stated formally in Proposition 1.",
                "Proposition 1.",
                "Let ξ∗ (w) be the optimal solution of the slack variables for OP 1 for a given weight vector w. Then 1 n Pn i=1 ξi is an upper bound on the empirical risk R∆ S (w). (see [19] for proof) Proposition 1 shows that OP 1 learns a ranking function that optimizes an upper bound on MAP error on the training set.",
                "Unfortunately there is a problem: a constraint is required for every possible wrong output y, and the number of possible wrong outputs is exponential in the size of C. Fortunately, we may employ Algorithm 1 to solve OP 1.",
                "Algorithm 1 is a cutting plane algorithm, iteratively introducing constraints until we have solved the original problem within a desired tolerance [19].",
                "The algorithm starts with no constraints, and iteratively finds for each example (xi, yi) the output ˆy associated with the most violated constraint.",
                "If the corresponding constraint is violated by more than we introduce ˆy into the working set Wi of active constraints for example i, and re-solve (3) using the updated W. It can be shown that Algorithm 1s outer loop is guaranteed to halt within a polynomial number of iterations for any desired precision .",
                "Theorem 1.",
                "Let ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y) , ¯∆ = maxi maxy ∆(yi, y), and for any > 0, Algorithm 1 terminates after adding at most max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff constraints to the working set W. (see [19] for proof) However, within the inner loop of this algorithm we have to compute argmaxy∈Y H(y; w), where H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), or equivalently, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), since wT Ψ(xi, yi) is constant with respect to y.",
                "Though closely related to the classification procedure, this has the substantial complication that we must contend with the additional ∆(yi, y) term.",
                "Without the ability to efficiently find the most violated constraint (i.e., solve argmaxy∈Y H(y, w)), the constraint generation procedure is not tractable. 3.2 Finding the Most Violated Constraint Using OP 1 and optimizing to ROCArea loss (∆roc), the problem of finding the most violated constraint, or solving argmaxy∈Y H(y, w) (henceforth argmax H), is addressed in [13].",
                "Solving argmax H for ∆map is more difficult.",
                "This is primarily because ROCArea decomposes nicely into a sum of scores computed independently on each relative ordering of a relevant/non-relevant document pair.",
                "MAP, on the other hand, does not decompose in the same way as ROCArea.",
                "The main algorithmic contribution of this paper is an efficient method for solving argmax H for ∆map.",
                "One useful property of ∆map is that it is invariant to swapping two documents with equal relevance.",
                "For example, if documents da and db are both relevant, then swapping the positions of da and db in any ranking does not affect ∆map.",
                "By extension, ∆map is invariant to any arbitrary permutation of the relevant documents amongst themselves and of the non-relevant documents amongst themselves.",
                "However, this reshuﬄing will affect the discriminant score, wT Ψ(x, y).",
                "This leads us to Observation 1.",
                "Observation 1.",
                "Consider rankings which are constrained by fixing the relevance at each position in the ranking (e.g., the 3rd document in the ranking must be relevant).",
                "Every ranking which satisfies the same set of constraints will have the same ∆map.",
                "If the relevant documents are sorted by wT φ(x, d) in descending order, and the non-relevant documents are likewise sorted by wT φ(x, d), then the interleaving of the two sorted lists which satisfies the constraints will maximize H for that constrained set of rankings.",
                "Observation 1 implies that in the ranking which maximizes H, the relevant documents will be sorted by wT φ(x, d), and the non-relevant documents will also be sorted likewise.",
                "By first sorting the relevant and non-relevant documents, the problem is simplified to finding the optimal interleaving of two sorted lists.",
                "For the rest of our discussion, we assume that the relevant documents and non-relevant documents are both sorted by descending wT φ(x, d).",
                "For convenience, we also refer to relevant documents as {dx 1 , . . . dx |Cx|} = Cx , and non-relevant documents as {d¯x 1 , . . . d¯x |C¯x|} = C¯x .",
                "We define δj(i1, i2), with i1 < i2, as the change in H from when the highest ranked relevant document ranked after d¯x j is dx i1 to when it is dx i2 .",
                "For i2 = i1 + 1, we have δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5) where si = wT φ(x, di).",
                "The first term in (5) is the change in ∆map when the ith relevant document has j non-relevant documents ranked before it, as opposed to j −1.",
                "The second term is the change in the discriminant score, wT Ψ(x, y), when yij changes from +1 to −1. . . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . .",
                "Figure 1: Example for δj(i, i + 1) Figure 1 gives a conceptual example for δj(i, i + 1).",
                "The bottom ranking differs from the top only where d¯x j slides up one rank.",
                "The difference in the value of H for these two rankings is exactly δj(i, i + 1).",
                "For any i1 < i2, we can then define δj(i1, i2) as δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) or equivalently, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) .",
                "Let o1, . . . , o|C¯x| encode the positions of the non-relevant documents, where dx oj is the highest ranked relevant document ranked after the jth non-relevant document.",
                "Due to Observation 1, this encoding uniquely identifies a complete ranking.",
                "We can recover the ranking as yij = 8 >>>< >>>: 0 if i = j sign(si − sj) if di, dj equal relevance sign(oj − i − 0.5) if di = dx i , dj = d¯x j sign(j − oi + 0.5) if di = d¯x i , dj = dx j . (7) We can now reformulate H into a new objective function, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), where ¯y is the true (weak) ranking.",
                "Conceptually H starts with a perfect ranking ¯y, and adds the change in H when each successive non-relevant document slides up the ranking.",
                "We can then reformulate the argmax H problem as argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) s.t. o1 ≤ . . . ≤ o|C¯x|. (9) Algorithm 2 describes the algorithm used to solve equation (8).",
                "Conceptually, Algorithm 2 starts with a perfect ranking.",
                "Then for each successive non-relevant document, the algorithm modifies the solution by sliding that document up the ranking to locally maximize H while keeping the positions of the other non-relevant documents constant. 3.2.1 Proof of Correctness Algorithm 2 is greedy in the sense that it finds the best position of each non-relevant document independently from the other non-relevant documents.",
                "In other words, the algorithm maximizes H for each non-relevant document, d¯x j , Algorithm 2 Finding the Most Violated Constraint (argmax H) for Algorithm 1 with ∆map 1: Input: w, Cx , C¯x 2: sort Cx and C¯x in descending order of wT φ(x, d) 3: sx i ← wT φ(x, dx i ), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i ), i = 1, . . . , |C¯x | 5: for j = 1, . . . , |C¯x | do 6: optj ← argmaxk δj(k, |Cx | + 1) 7: end for 8: encode ˆy according to (7) 9: return ˆy without considering the positions of the other non-relevant documents, and thus ignores the constraints of (9).",
                "In order for the solution to be feasible, the jth non-relevant document must be ranked after the first j − 1 non-relevant documents, thus satisfying opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. (10) If the solution is feasible, the it clearly solves (8).",
                "Therefore, it suffices to prove that Algorithm 2 satisfies (10).",
                "We first prove that δj(·, ·) is monotonically decreasing in j. Lemma 1.",
                "For any 1 ≤ i1 < i2 ≤ |Cx | + 1 and 1 ≤ j < |C¯x |, it must be the case that δj+1(i1, i2) ≤ δj(i1, i2).",
                "Proof.",
                "Recall from (6) that both δj(i1, i2) and δj+1(i1, i2) are summations of i2 − i1 terms.",
                "We will show that each term in the summation of δj+1(i1, i2) is no greater than the corresponding term in δj(i1, i2), or δj+1(k, k + 1) ≤ δj(k, k + 1) for k = i1, . . . , i2 − 1.",
                "Each term in δj(k, k +1) and δj+1(k, k +1) can be further decomposed into two parts (see (5)).",
                "We will show that each part of δj+1(k, k + 1) is no greater than the corresponding part in δj(k, k + 1).",
                "In other words, we will show that both j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) and −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) are true for the aforementioned values of j and k. It is easy to see that (11) is true by observing that for any two positive integers 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1 , and choosing a = j and b = j + k. The second inequality (12) holds because Algorithm 2 first sorts d¯x in descending order of s¯x , implying s¯x j+1 ≤ s¯x j .",
                "Thus we see that each term in δj+1 is no greater than the corresponding term in δj, which completes the proof.",
                "The result of Lemma 1 leads directly to our main correctness result: Theorem 2.",
                "In Algorithm 2, the computed values of optj satisfy (10), implying that the solution returned by Algorithm 2 is feasible and thus optimal.",
                "Proof.",
                "We will prove that optj ≤ optj+1 holds for any 1 ≤ j < |C¯x |, thus implying (10).",
                "Since Algorithm 2 computes optj as optj = argmax k δj(k, |Cx | + 1), (13) then by definition of δj (6), for any 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0.",
                "Using Lemma 1, we know that δj+1(i, optj) ≤ δj(i, optj) < 0, which implies that for any 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0.",
                "Suppose for contradiction that optj+1 < optj.",
                "Then δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), which contradicts (13).",
                "Therefore, it must be the case that optj ≤ optj+1, which completes the proof. 3.2.2 Running Time The running time of Algorithm 2 can be split into two parts.",
                "The first part is the sort by wT φ(x, d), which requires O(n log n) time, where n = |Cx | + |C¯x |.",
                "The second part computes each optj, which requires O(|Cx | · |C¯x |) time.",
                "Though in the worst case this is O(n2 ), the number of relevant documents, |Cx |, is often very small (e.g., constant with respect to n), in which case the running time for the second part is simply O(n).",
                "For most real-world datasets, Algorithm 2 is dominated by the sort and has complexity O(n log n).",
                "Algorithm 1 is guaranteed to halt in a polynomial number of iterations [19], and each iteration runs Algorithm 2.",
                "Virtually all well-performing models were trained in a reasonable amount of time (usually less than one hour).",
                "Once training is complete, making predictions on query x using the resulting hypothesis h(x|w) requires only sorting by wT φ(x, d).",
                "We developed our software using a Python interface3 to SVMstruct , since the Python language greatly simplified the coding process.",
                "To improve performance, it is advisable to use the standard C implementation4 of SVMstruct . 4.",
                "EXPERIMENT SETUP The main goal of our experiments is to evaluate whether directly optimizing MAP leads to improved MAP performance compared to conventional SVM methods that optimize a substitute loss such as accuracy or ROCArea.",
                "We empirically evaluate our method using two sets of TREC Web Track queries, one each from TREC 9 and TREC 10 (topics 451-500 and 501-550), both of which used the WT10g corpus.",
                "For each query, TREC provides the relevance judgments of the documents.",
                "We generated our features using the scores of existing retrieval functions on these queries.",
                "While our method is agnostic to the meaning of the features, we chose to use existing retrieval functions as a simple yet effective way of acquiring useful features.",
                "As such, our 3 http://www.cs.cornell.edu/~tomf/svmpython/ 4 http://svmlight.joachims.org/svm_struct.html Dataset Base Funcs Features TREC 9 Indri 15 750 TREC 10 Indri 15 750 TREC 9 Submissions 53 2650 TREC 10 Submissions 18 900 Table 5: Dataset Statistics experiments essentially test our methods ability to re-rank the highly ranked documents (e.g., re-combine the scores of the retrieval functions) to improve MAP.",
                "We compare our method against the best retrieval functions trained on (henceforth base functions), as well as against previously proposed SVM methods.",
                "Comparing with the best base functions tests our methods ability to learn a useful combination.",
                "Comparing with previous SVM methods allows us to test whether optimizing directly for MAP (as opposed to accuracy or ROCArea) achieves a higher MAP score in practice.",
                "The rest of this section describes the base functions and the feature generation method in detail. 4.1 Choosing Retrieval Functions We chose two sets of base functions for our experiments.",
                "For the first set, we generated three indices over the WT10g corpus using Indri5 .",
                "The first index was generated using default settings, the second used Porter-stemming, and the last used Porter-stemming and Indris default stopwords.",
                "For both TREC 9 and TREC 10, we used the description portion of each query and scored the documents using five of Indris built-in retrieval methods, which are Cosine Similarity, TFIDF, Okapi, Language Model with Dirichlet Prior, and Language Model with Jelinek-Mercer Prior.",
                "All parameters were kept as their defaults.",
                "We computed the scores of these five retrieval methods over the three indices, giving 15 base functions in total.",
                "For each query, we considered the scores of documents found in the union of the top 1000 documents of each base function.",
                "For our second set of base functions, we used scores from the TREC 9 [8] and TREC 10 [9] Web Track submissions.",
                "We used only the non-manual, non-short submissions from both years.",
                "For TREC 9 and TREC 10, there were 53 and 18 such submissions, respectively.",
                "A typical submission contained scores of its top 1000 documents. b ca wT φ(x,d) f(d|x) Figure 2: Example Feature Binning 4.2 Generating Features In order to generate input examples for our method, a concrete instantiation of φ must be provided.",
                "For each doc5 http://www.lemurproject.org TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236Best Func. 0.204 39/11 ** 0.181 37/13 ** 2nd Best 0.199 38/12 ** 0.174 43/7 ** 3rd Best 0.188 34/16 ** 0.174 38/12 ** Table 6: Comparison with Indri Functions ument d scored by a set of retrieval functions F on query x, we generate the features as a vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf , where f(d|x) denotes the score that retrieval function f assigns to document d for query x, and each Kf is a set of real values.",
                "From a high level, we are expressing the score of each retrieval function using |Kf | + 1 bins.",
                "Since we are using linear kernels, one can think of the learning problem as finding a good piecewise-constant combination of the scores of the retrieval functions.",
                "Figure 2 shows an example of our feature mapping method.",
                "In this example we have a single feature F = {f}.",
                "Here, Kf = {a, b, c}, and the weight vector is w = wa, wb, wc .",
                "For any document d and query x, we have wT φ(x, d) = 8 >>< >>: 0 if f(d|x) < a wa if a ≤ f(d|x) < b wa + wb if b ≤ f(d|x) < c wa + wb + wc if c ≤ f(d|x) .",
                "This is expressed qualitatively in Figure 2, where wa and wb are positive, and wc is negative.",
                "We ran our main experiments using four choices of F: the set of aforementioned Indri retrieval functions for TREC 9 and TREC 10, and the Web Track submissions for TREC 9 and TREC 10.",
                "For each F and each function f ∈ F, we chose 50 values for Kf which are reasonably spaced and capture the sensitive region of f. Using the four choices of F, we generated four datasets for our main experiments.",
                "Table 5 contains statistics of the generated datasets.",
                "There are many ways to generate features, and we are not advocating our method over others.",
                "This was simply an efficient means to normalize the outputs of different functions and allow for a more expressive model. 5.",
                "EXPERIMENTS For each dataset in Table 5, we performed 50 trials.",
                "For each trial, we train on 10 randomly selected queries, and select another 5 queries at random for a validation set.",
                "Models were trained using a wide range of C values.",
                "The model which performed best on the validation set was selected and tested on the remaining 35 queries.",
                "All queries were selected to be in the training, validation and test sets the same number of times.",
                "Using this setup, we performed the same experiments while using our method (SVM∆ map), an SVM optimizing for ROCArea (SVM∆ roc) [13], and a conventional classification SVM (SVMacc) [20].",
                "All SVM methods used a linear kernel.",
                "We reported the average performance of all models over the 50 trials. 5.1 Comparison with Base Functions In analyzing our results, the first question to answer is, can SVM∆ map learn a model which outperforms the best base TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287Best Func. 0.280 28/22 0.283 29/21 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 36/14 ** Table 7: Comparison with TREC Submissions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288Best Func. 0.280 27/23 0.283 31/19 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 35/15 ** Table 8: Comparison with TREC Subm. (w/o best) functions?",
                "Table 6 presents the comparison of SVM∆ map with the best Indri base functions.",
                "Each column group contains the macro-averaged MAP performance of SVM∆ map or a base function.",
                "The W/L columns show the number of queries where SVM∆ map achieved a higher MAP score.",
                "Significance tests were performed using the two-tailed Wilcoxon signed rank test.",
                "Two stars indicate a significance level of 0.95.",
                "All tables displaying our experimental results are structured identically.",
                "Here, we find that SVM∆ map significantly outperforms the best base functions.",
                "Table 7 shows the comparison when trained on TREC submissions.",
                "While achieving a higher MAP score than the best base functions, the performance difference between SVM∆ map the base functions is not significant.",
                "Given that many of these submissions use scoring functions which are carefully crafted to achieve high MAP, it is possible that the best performing submissions use techniques which subsume the techniques of the other submissions.",
                "As a result, SVM∆ map would not be able to learn a hypothesis which can significantly out-perform the best submission.",
                "Hence, we ran the same experiments using a modified dataset where the features computed using the best submission were removed.",
                "Table 8 shows the results (note that we are still comparing against the best submission though we are not using it for training).",
                "Notice that while the performance of SVM∆ map degraded slightly, the performance was still comparable with that of the best submission. 5.2 Comparison w/ Previous SVM Methods The next question to answer is, does SVM∆ map produce higher MAP scores than previous SVM methods?",
                "Tables 9 and 10 present the results of SVM∆ map, SVM∆ roc, and SVMacc when trained on the Indri retrieval functions and TREC submissions, respectively.",
                "Table 11 contains the corresponding results when trained on the TREC submissions without the best submission.",
                "To start with, our results indicate that SVMacc was not competitive with SVM∆ map and SVM∆ roc, and at times underperformed dramatically.",
                "As such, we tried several approaches to improve the performance of SVMacc. 5.2.1 Alternate SVMacc Methods One issue which may cause SVMacc to underperform is the severe imbalance between relevant and non-relevant docTREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236SVM∆ roc 0.237 29/21 0.234 24/26 SVMacc 0.147 47/3 ** 0.155 47/3 ** SVMacc2 0.219 39/11 ** 0.207 43/7 ** SVMacc3 0.113 49/1 ** 0.153 45/5 ** SVMacc4 0.155 48/2 ** 0.155 48/2 ** Table 9: Trained on Indri Functions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287SVM∆ roc 0.282 29/21 0.278 35/15 ** SVMacc 0.213 49/1 ** 0.222 49/1 ** SVMacc2 0.270 34/16 ** 0.261 42/8 ** SVMacc3 0.133 50/0 ** 0.182 46/4 ** SVMacc4 0.233 47/3 ** 0.238 46/4 ** Table 10: Trained on TREC Submissions uments.",
                "The vast majority of the documents are not relevant.",
                "SVMacc2 addresses this problem by assigning more penalty to false negative errors.",
                "For each dataset, the ratio of the false negative to false positive penalties is equal to the ratio of the number non-relevant and relevant documents in that dataset.",
                "Tables 9, 10 and 11 indicate that SVMacc2 still performs significantly worse than SVM∆ map.",
                "Another possible issue is that SVMacc attempts to find just one discriminating threshold b that is query-invariant.",
                "It may be that different queries require different values of b.",
                "Having the learning method trying to find a good b value (when one does not exist) may be detrimental.",
                "We took two approaches to address this issue.",
                "The first method, SVMacc3, converts the retrieval function scores into percentiles.",
                "For example, for document d, query q and retrieval function f, if the score f(d|q) is in the top 90% of the scores f(·|q) for query q, then the converted score is f (d|q) = 0.9.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Tables 9, 10 and 11 show that the performance of SVMacc3 was also not competitive with SVM∆ map.",
                "The second method, SVMacc4, normalizes the scores given by f for each query.",
                "For example, assume for query q that f outputs scores in the range 0.2 to 0.7.",
                "Then for document d, if f(d|q) = 0.6, the converted score would be f (d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Again, Tables 9, 10 and 11 show that SVMacc4 was not competitive with SVM∆ map 5.2.2 MAP vs ROCArea SVM∆ roc performed much better than SVMacc in our experiments.",
                "When trained on Indri retrieval functions (see Table 9), the performance of SVM∆ roc was slight, though not significantly, worse than the performances of SVM∆ map.",
                "However, Table 10 shows that SVM∆ map did significantly outperform SVM∆ roc when trained on the TREC submissions.",
                "Table 11 shows the performance of the models when trained on the TREC submissions with the best submission removed.",
                "The performance of most models degraded by a small amount, with SVM∆ map still having the best performance.",
                "TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Table 11: Trained on TREC Subm. (w/o Best) 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented an SVM method that directly optimizes MAP.",
                "It provides a principled approach and avoids difficult to control heuristics.",
                "We formulated the optimization problem and presented an algorithm which provably finds the solution in polynomial time.",
                "We have shown empirically that our method is generally superior to or competitive with conventional SVMs methods.",
                "Our new method makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for Accuracy and ROCArea.",
                "The computational cost for training is very reasonable in practice.",
                "Since other methods typically require tuning multiple heuristics, we also expect to train fewer models before finding one which achieves good performance.",
                "The learning framework used by our method is fairly general.",
                "A natural extension of this framework would be to develop methods to optimize for other important IR measures, such as Normalized Discounted Cumulative Gain [2, 3, 4, 12] and Mean Reciprocal Rank. 7.",
                "ACKNOWLEDGMENTS This work was funded under NSF Award IIS-0412894, NSF CAREER Award 0237381, and a gift from Yahoo!",
                "Research.",
                "The third author was also partly supported by a Microsoft Research Fellowship. 8.",
                "REFERENCES [1] B. T. Bartell, G. W. Cottrell, and R. K. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2005. [3] C. J. C. Burges, R. Ragno, and Q.",
                "Le.",
                "Learning to rank with non-smooth cost functions.",
                "In Proceedings of the International Conference on Advances in Neural Information Processing Systems (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y.",
                "Liu, H. Li, Y. Huang, and H.-W. Hon.",
                "Adapting ranking SVM to document retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [5] B. Carterette and D. Petkova.",
                "Learning a ranking from pairwise preferences.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew, and A. Ksikes.",
                "Ensemble selection from libraries of models.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [7] J. Davis and M. Goadrich.",
                "The relationship between precision-recall and ROC curves.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2006. [8] D. Hawking.",
                "Overview of the TREC-9 web track.",
                "In Proceedings of TREC-2000, 2000. [9] D. Hawking and N. Craswell.",
                "Overview of the TREC-2001 web track.",
                "In Proceedings of TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel, and K. Obermayer.",
                "Large margin rank boundaries for ordinal regression.",
                "Advances in large margin classifiers, 2000. [11] A. Herschtal and B. Raskutti.",
                "Optimising area under the ROC curve using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [12] K. Jarvelin and J. Kekalainen.",
                "Ir evaluation methods for retrieving highly relevant documents.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2000. [13] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proceedings of the International Conference on Machine Learning (ICML), pages 377-384, New York, NY, USA, 2005.",
                "ACM Press. [14] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 111-119, 2001. [15] Y. Lin, Y. Lee, and G. Wahba.",
                "Support vector machines for classification in nonstandard situations.",
                "Machine Learning, 46:191-202, 2002. [16] D. Metzler and W. B. Croft.",
                "A markov random field model for term dependencies.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 472-479, 2005. [17] K. Morik, P. Brockhausen, and T. Joachims.",
                "Combining statistical learning with a knowledge-based approach.",
                "In Proceedings of the International Conference on Machine Learning, 1999. [18] S. Robertson.",
                "The probability ranking principle in ir. journal of documentation.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.",
                "Large margin methods for structured and interdependent output variables.",
                "Journal of Machine Learning Research (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik.",
                "Statistical Learning Theory.",
                "Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz.",
                "Optimizing classifier performance via approximation to the Wilcoxon-Mann-Witney statistic.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2003."
            ],
            "original_annotated_samples": [
                "INTRODUCTION State of the art <br>information retrieval system</br>s commonly use machine learning techniques to learn ranking functions."
            ],
            "translated_annotated_samples": [
                "INTRODUCCIÓN Los <br>sistemas de recuperación de información</br> de última generación comúnmente utilizan técnicas de aprendizaje automático para aprender funciones de clasificación."
            ],
            "translated_text": "Un método de Vectores de Soporte para optimizar la Precisión Promedio Yisong Yue Universidad de Cornell Ithaca, NY, EE. UU. yyue@cs.cornell.edu Thomas Finley Universidad de Cornell Ithaca, NY, EE. UU. tomf@cs.cornell.edu Filip Radlinski Universidad de Cornell Ithaca, NY, EE. UU. filip@cs.cornell.edu Thorsten Joachims Universidad de Cornell Ithaca, NY, EE. UU. tj@cs.cornell.edu RESUMEN El aprendizaje automático se utiliza comúnmente para mejorar los sistemas de recuperación clasificados. Debido a dificultades computacionales, se han desarrollado pocas técnicas de aprendizaje para optimizar directamente la precisión media promedio (MAP), a pesar de su uso generalizado en la evaluación de dichos sistemas. Los enfoques existentes que optimizan el MAP no encuentran una solución óptima global o son computacionalmente costosos. Por el contrario, presentamos un algoritmo de aprendizaje SVM general que encuentra de manera eficiente una solución óptima global para una relajación directa de MAP. Evaluamos nuestro enfoque utilizando los corpus de la pista web TREC 9 y TREC 10 (WT10g), comparando con SVM optimizados para precisión y área bajo la curva ROC. En la mayoría de los casos mostramos nuestro método para producir mejoras estadísticamente significativas en las puntuaciones de MAP. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de Recuperación Términos Generales Algoritmo, Teoría, Experimentación 1. INTRODUCCIÓN Los <br>sistemas de recuperación de información</br> de última generación comúnmente utilizan técnicas de aprendizaje automático para aprender funciones de clasificación. Sin embargo, la mayoría de los enfoques actuales no están optimizados para la medida de evaluación más utilizada, es decir, la Precisión Promedio Media (MAP). En cambio, los algoritmos actuales tienden a seguir uno de dos enfoques generales. El primer enfoque es aprender un modelo que estime la probabilidad de que un documento sea relevante dado una consulta (por ejemplo, [18, 14]). Si se resuelve de manera efectiva, la clasificación con el mejor rendimiento de MAP puede derivarse fácilmente de las probabilidades de relevancia. Sin embargo, lograr un MAP alto solo requiere encontrar un buen ordenamiento de los documentos. Como resultado, encontrar buenas probabilidades requiere resolver un problema más difícil de lo necesario, probablemente necesitando más datos de entrenamiento para lograr el mismo rendimiento de MAP. El segundo enfoque común es aprender una función que maximice una medida sustituta. Las medidas de rendimiento optimizadas incluyen precisión [17, 15], área bajo la curva ROC [1, 5, 10, 11, 13, 21] o modificaciones del área bajo la curva ROC [4], y NDCG [2, 3]. Aprender un modelo para optimizar tales medidas podría resultar en un rendimiento de MAP subóptimo. De hecho, aunque algunos sistemas anteriores han obtenido un buen rendimiento de MAP, se sabe que ni lograr una precisión óptima ni un área bajo la curva ROC pueden garantizar un rendimiento de MAP óptimo[7]. En este artículo, presentamos un enfoque general para aprender funciones de clasificación que maximizan el rendimiento de MAP. Específicamente, presentamos un algoritmo SVM que optimiza globalmente una relajación de pérdida de bisagra de MAP. Este enfoque simplifica el proceso de obtener funciones de clasificación con un alto rendimiento de MAP al evitar pasos intermedios adicionales y heurísticas. El nuevo algoritmo también hace que sea conceptualmente tan fácil optimizar las SVM para MAP como anteriormente solo era posible para precisión y ROCArea. A diferencia del trabajo reciente que optimiza directamente el rendimiento de MAP realizado por Metzler & Croft [16] y Caruana et al. [6], nuestra técnica es eficiente computacionalmente al encontrar una solución óptima a nivel global. Al igual que [6, 16], nuestro método aprende un modelo lineal, pero es mucho más eficiente en la práctica y, a diferencia de [16], puede manejar miles de características. Ahora describimos el algoritmo en detalle y proporcionamos la prueba de corrección. A continuación, proporcionamos un análisis del tiempo de ejecución. Concluimos con los resultados empíricos de experimentos en el corpus de la pista web TREC 9 y TREC 10. También hemos desarrollado un paquete de software que implementa nuestro algoritmo y está disponible para uso público. EL PROBLEMA DEL APRENDIZAJE Siguiendo la configuración estándar del aprendizaje automático, nuestro objetivo es aprender una función h: X → Y entre un espacio de entrada X (todas las consultas posibles) y un espacio de salida Y (clasificaciones sobre un corpus). Para cuantificar la calidad de una predicción, ˆy = h(x), consideraremos una función de pérdida ∆ : Y × Y → . ∆(y, ˆy) cuantifica la penalización por hacer la predicción ˆy si la salida correcta es y. La función de pérdida nos permite incorporar medidas específicas de rendimiento, las cuales explotaremos en http://svmrank.yisongyue.com para optimizar el MAP. Nos restringimos al escenario de aprendizaje supervisado, donde pares de entrada/salida (x, y) están disponibles para el entrenamiento y se asume que provienen de alguna distribución fija P(x, y). El objetivo es encontrar una función h tal que el riesgo (es decir, la pérdida esperada), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), se minimice. Por supuesto, P(x, y) es desconocido. Pero dado un conjunto finito de pares de entrenamiento, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, el rendimiento de h en S puede medirse mediante el riesgo empírico, R∆ S (h) = 1 n ∑ i=1 n ∆(yi, h(xi)). En el caso de aprender una función de recuperación clasificada, X denota un espacio de consultas, y Y el espacio de clasificaciones (posiblemente débiles) sobre algún corpus de documentos C = {d1, . . . ,d|C|}. Podemos definir la pérdida de precisión promedio como ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), donde rank(y) es un vector de los valores de rango de cada documento en C. Por ejemplo, para un corpus de dos documentos, {d1, d2}, con d1 teniendo un rango más alto que d2, rank(y) = (1, 0). Suponemos que las clasificaciones verdaderas tienen dos valores de clasificación, donde los documentos relevantes tienen un valor de clasificación 1 y los documentos no relevantes tienen un valor de clasificación 0. Además, asumimos que todas las clasificaciones predichas son clasificaciones completas (sin empates). Sea p = rango(y) y ˆp = rango(ˆy). La puntuación de precisión promedio se define como MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, donde rel = |{i : pi = 1}| es el número de documentos relevantes, y Prec@j es el porcentaje de documentos relevantes en los primeros j documentos en la clasificación predicha ˆy. MAP es la media de las puntuaciones de precisión promedio de un grupo de consultas. La mayoría de los algoritmos de aprendizaje se optimizan para precisión o ROCArea. Si bien optimizar estas medidas podría lograr un buen rendimiento de MAP, usamos dos ejemplos simples para mostrar que también puede ser subóptimo en términos de MAP. ROCArea asigna una penalización igual a cada desordenamiento de un par relevante/no relevante. Por el contrario, MAP asigna mayores penalizaciones a los errores de ordenamiento más arriba en la clasificación predicha. Usando nuestra notación, el Área bajo la Curva ROC (ROCArea) se puede definir como ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], donde p es el ranking verdadero (débil), ˆp es el ranking predicho, y 1[b] es la función indicadora condicionada a b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Tabla 1: Ejemplo y Modelos Supongamos que tenemos un espacio de hipótesis con solo dos funciones de hipótesis, h1 y h2, como se muestra en la Tabla 1. Estas dos hipótesis predicen un ranking para la consulta x sobre un corpus de ocho documentos. Tabla 2: Rendimiento de los Modelos de Juguete La Tabla 2 muestra las puntuaciones de MAP y ROCArea de h1 y h2. Aquí, un método de aprendizaje que optimiza para el Área bajo la curva ROC elegiría h2 ya que esto resulta en un puntaje de Área bajo la curva ROC más alto, pero esto produce un puntaje de MAP subóptimo. 2.2 MAP vs Precisión Usando un ejemplo muy similar, ahora demostramos cómo optimizar para la precisión podría resultar en un puntaje de MAP subóptimo. Los modelos que se optimizan para la precisión no están directamente preocupados por la clasificación. En cambio, aprenden un umbral tal que los documentos que obtienen una puntuación superior al umbral pueden ser clasificados como relevantes y los documentos que obtienen una puntuación inferior como no relevantes. Consideramos nuevamente un espacio de hipótesis con dos hipótesis. La Tabla 3 muestra las predicciones de las dos hipótesis en una única consulta x. Hipótesis MAP Mejor Precisión h1(q) 0.70 0.64 h2(q) 0.64 0.73 Tabla 4: Rendimiento de los Modelos de Juguete La Tabla 4 muestra los puntajes de MAP y mejor precisión de h1(q) y h2(q). La mejor precisión se refiere a la precisión más alta alcanzable en esa clasificación al considerar todos los umbrales posibles. Por ejemplo, con h1(q), un umbral entre los documentos 1 y 2 da 4 errores (documentos 6-9 clasificados incorrectamente como no relevantes), lo que resulta en una precisión de 0.64. De manera similar, con h2(q), un umbral entre los documentos 5 y 6 da 3 errores (los documentos 10-11 clasificados incorrectamente como relevantes, y el documento 1 como no relevante), lo que resulta en una precisión de 0.73. Un método de aprendizaje que optimiza la precisión elegiría h2 ya que esto resulta en un puntaje de precisión más alto, pero esto produce un puntaje de MAP subóptimo. 3. OPTIMIZANDO LA PRECISIÓN PROMEDIO Nos basamos en el enfoque utilizado por [13] para optimizar el Área bajo la Curva ROC. A diferencia de ROCArea, sin embargo, MAP no se descompone linealmente en los ejemplos y requiere un algoritmo sustancialmente extendido, el cual describimos en esta sección. Recuerda que la clasificación verdadera es una clasificación débil con dos valores de clasificación (relevante y no relevante). Que Cx y C¯x denoten el conjunto de documentos relevantes y no relevantes de C para la consulta x, respectivamente. Nos enfocamos en funciones que están parametrizadas por un vector de peso w, y por lo tanto deseamos encontrar w para minimizar el riesgo empírico, R∆ S (w) ≡ R∆ S (h(·; w)). Nuestro enfoque es aprender una función discriminante F: X × Y → sobre pares de entrada-salida. Dada la consulta x, podemos derivar una predicción encontrando la clasificación y que maximiza la función discriminante: h(x; w) = argmax y∈Y F(x, y; w). (1) Suponemos que F es lineal en alguna representación de características combinadas de entradas y salidas Ψ(x, y) ∈ RN, es decir, F(x, y; w) = wT Ψ(x, y). (2) La función de características combinadas que utilizamos es Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))], donde φ: X × C → N es una función de mapeo de características de un par consulta/documento a un punto en un espacio dimensional N. Representamos las clasificaciones como una matriz de ordenamientos por pares, Y ⊂ {−1, 0, +1}|C|×|C| . Para cualquier y ∈ Y, yij = +1 si di está clasificado por delante de dj, y yij = −1 si dj está clasificado por delante de di, y yij = 0 si di y dj tienen el mismo rango. Consideramos solo matrices que corresponden a clasificaciones válidas (es decir, que cumplen con la antisimetría y la transitividad). De manera intuitiva, Ψ es una suma de las diferencias vectoriales de todos los pares de documentos relevantes/no relevantes. Dado que asumimos que las clasificaciones predichas son clasificaciones completas, yij es o bien +1 o −1 (nunca 0). Dado un vector de pesos aprendido w, predecir un ranking (es decir, resolver la ecuación (1)) dado una consulta x se reduce a elegir cada yij para maximizar wT Ψ(x, y). Como también se discute en [13], esto se logra ordenando los documentos por wT φ(x, d) en orden descendente. Discutiremos más adelante las elecciones de φ que utilizamos para nuestros experimentos. 3.1 SVM Estructurales La formulación anterior es muy similar a aprender un modelo lineal directo mientras se entrena en la diferencia de pares de documentos relevantes/no relevantes. Muchos enfoques basados en SVM optimizan sobre estas diferencias en pares (por ejemplo, [5, 10, 13, 4]), aunque estos métodos no optimizan para el MAP durante el entrenamiento. Anteriormente, no estaba claro cómo incorporar funciones de pérdida multivariadas no lineales como la pérdida MAP directamente en problemas de optimización global como el entrenamiento de SVM. Ahora presentamos un método basado en SVM estructurales [19] para abordar este problema. Utilizamos la formulación del SVM estructural, presentada en el Problema de Optimización 1, para aprender un w ∈ RN. Problema de optimización 1. (SVM estructural) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) La función objetivo a minimizar (3) es un compromiso entre la complejidad del modelo, w 2 , y una relajación de pérdida de MAP mediante la pérdida de bisagra, P ξi. Como es habitual en el entrenamiento de SVM, C es igual a 2. Por ejemplo, una dimensión podría ser el número de veces que las palabras de la consulta aparecen en el documento. Algoritmo 1 Algoritmo de plano de corte para resolver OP 1 dentro de la tolerancia. 1: Entrada: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ para todo i = 1, . . . , n 3: repetir 4: para i = 1, . . . , n hacer 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: calcular ˆy = argmaxy∈Y H(y; w) 7: calcular ξi = max{0, maxy∈Wi H(y; w)} 8: si H(ˆy; w) > ξi + entonces 9: Wi ← Wi ∪ {ˆy} 10: w ← optimizar (3) sobre W = S i Wi 11: fin si 12: fin para 13: hasta que ningún Wi haya cambiado durante la iteración parámetro que controla este equilibrio y puede ajustarse para lograr un buen rendimiento en diferentes tareas de entrenamiento. Para cada (xi, yi) en el conjunto de entrenamiento, se añade un conjunto de restricciones de la forma en la ecuación (4) al problema de optimización. Ten en cuenta que wT Ψ(x, y) es exactamente nuestra función discriminante F(x, y; w) (ver ecuación (2)). Durante la predicción, nuestro modelo elige el ranking que maximiza el discriminante (1). Si el valor del discriminante para una clasificación incorrecta y es mayor que para la clasificación verdadera yi (por ejemplo, F(xi, y; w) > F(xi, yi; w)), entonces la variable de holgura correspondiente, ξi, debe ser al menos ∆(yi, y) para que se cumpla esa restricción. Por lo tanto, la suma de los márgenes, P ξi, acota superiormente la pérdida MAP. Esto se establece formalmente en la Proposición 1. Proposición 1. Sea ξ∗ (w) la solución óptima de las variables de holgura para OP 1 para un vector de peso dado w. Entonces 1 n Pn i=1 ξi es una cota superior del riesgo empírico R∆ S (w). (ver [19] para la prueba) La Proposición 1 muestra que OP 1 aprende una función de clasificación que optimiza una cota superior del error de MAP en el conjunto de entrenamiento. Desafortunadamente hay un problema: se requiere una restricción para cada posible resultado incorrecto y, y el número de resultados incorrectos posibles es exponencial en el tamaño de C. Afortunadamente, podemos emplear el Algoritmo 1 para resolver OP 1. El algoritmo 1 es un algoritmo de plano de corte, introduciendo iterativamente restricciones hasta que hayamos resuelto el problema original dentro de una tolerancia deseada [19]. El algoritmo comienza sin restricciones y encuentra de forma iterativa, para cada ejemplo (xi, yi), la salida ˆy asociada con la restricción más violada. Si la restricción correspondiente es violada por más de lo que introducimos ˆy en el conjunto de trabajo Wi de restricciones activas, por ejemplo i, y volvemos a resolver (3) usando el W actualizado. Se puede demostrar que el bucle externo del Algoritmo 1 está garantizado a detenerse dentro de un número polinomial de iteraciones para cualquier precisión deseada. Teorema 1. Sea ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y), ¯∆ = maxi maxy ∆(yi, y), y para cualquier > 0, el Algoritmo 1 termina después de agregar a lo sumo max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff restricciones al conjunto de trabajo W. (ver [19] para la prueba) Sin embargo, dentro del bucle interno de este algoritmo tenemos que calcular argmaxy∈Y H(y; w), donde H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), o equivalentemente, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), ya que wT Ψ(xi, yi) es constante con respecto a y. Aunque está estrechamente relacionado con el procedimiento de clasificación, esto tiene la complicación sustancial de que debemos lidiar con el término adicional ∆(yi, y). Sin la capacidad de encontrar eficientemente la restricción más violada (es decir, resolver argmaxy∈Y H(y, w)), el procedimiento de generación de restricciones no es viable. 3.2 Encontrar la restricción más violada utilizando OP 1 y optimizando la pérdida de ROCArea (∆roc), el problema de encontrar la restricción más violada, o resolver argmaxy∈Y H(y, w) (en adelante argmax H), se aborda en [13]. Resolver argmax H para ∆map es más difícil. Esto se debe principalmente a que ROCArea se descompone de manera ordenada en una suma de puntuaciones calculadas de forma independiente en cada ordenamiento relativo de un par de documentos relevantes/no relevantes. MAP, por otro lado, no se descompone de la misma manera que ROCArea. La principal contribución algorítmica de este artículo es un método eficiente para resolver argmax H para ∆map. Una propiedad útil de ∆map es que es invariante al intercambiar dos documentos con igual relevancia. Por ejemplo, si los documentos da y db son ambos relevantes, entonces intercambiar las posiciones de da y db en cualquier clasificación no afecta a ∆map. Por extensión, ∆map es invariante a cualquier permutación arbitraria de los documentos relevantes entre sí y de los documentos no relevantes entre sí. Sin embargo, esta reorganización afectará la puntuación del discriminante, wT Ψ(x, y). Esto nos lleva a la Observación 1. Observación 1. Considera clasificaciones que estén limitadas por fijar la relevancia en cada posición de la clasificación (por ejemplo, el tercer documento en la clasificación debe ser relevante). Cada clasificación que cumpla con el mismo conjunto de restricciones tendrá el mismo ∆map. Si los documentos relevantes están ordenados por wT φ(x, d) en orden descendente, y los documentos no relevantes también están ordenados de la misma manera por wT φ(x, d), entonces la intercalación de las dos listas ordenadas que cumpla con las restricciones maximizará H para ese conjunto de clasificaciones restringidas. La Observación 1 implica que en la clasificación que maximiza H, los documentos relevantes se ordenarán por wT φ(x, d), y los documentos no relevantes también se ordenarán de la misma manera. Al ordenar primero los documentos relevantes y no relevantes, el problema se simplifica a encontrar la intercalación óptima de dos listas ordenadas. Para el resto de nuestra discusión, asumimos que los documentos relevantes y no relevantes están ordenados por wT φ(x, d) en orden descendente. Para mayor comodidad, también nos referimos a los documentos relevantes como {dx 1 , . . . dx |Cx|} = Cx, y a los documentos no relevantes como {d¯x 1 , . . . d¯x |C¯x|} = C¯x. Definimos δj(i1, i2), con i1 < i2, como el cambio en H desde cuando el documento relevante de mayor rango clasificado después de d¯x j es dx i1 hasta que es dx i2. Para i2 = i1 + 1, tenemos δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5), donde si = wT φ(x, di). El primer término en (5) es el cambio en ∆map cuando el documento relevante i tiene j documentos no relevantes clasificados antes de él, en lugar de j-1. El segundo término es el cambio en la puntuación del discriminante, wT Ψ(x, y), cuando yij cambia de +1 a −1. . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . . Figura 1: Ejemplo para δj(i, i + 1). La Figura 1 proporciona un ejemplo conceptual para δj(i, i + 1). La clasificación inferior difiere de la superior solo cuando d¯x j sube un rango. La diferencia en el valor de H para estas dos clasificaciones es exactamente δj(i, i + 1). Para cualquier i1 < i2, podemos definir δj(i1, i2) como δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) o equivalentemente, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) . Deja que o1, . . . , o|C¯x| codifiquen las posiciones de los documentos no relevantes, donde dx oj es el documento relevante de mayor rango clasificado después del j-ésimo documento no relevante. Debido a la Observación 1, esta codificación identifica de forma única un ranking completo. Podemos recuperar la clasificación como yij = 8 >>>< >>>: 0 si i = j sign(si − sj) si di, dj relevancia igual signo(oj − i − 0.5) si di = dx i , dj = d¯x j signo(j − oi + 0.5) si di = d¯x i , dj = dx j. (7) Ahora podemos reformular H en una nueva función objetivo, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), donde ¯y es la verdadera clasificación (débil). Conceptualmente, H comienza con una clasificación perfecta ¯y y agrega el cambio en H cuando cada documento no relevante sucesivo sube en la clasificación. Luego podemos reformular el problema argmax H como argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) sujeto a o1 ≤ . . . ≤ o|C¯x|. (9) El Algoritmo 2 describe el algoritmo utilizado para resolver la ecuación (8). Conceptualmente, el Algoritmo 2 comienza con un ranking perfecto. Entonces, para cada documento no relevante sucesivo, el algoritmo modifica la solución deslizando ese documento hacia arriba en la clasificación para maximizar localmente H, manteniendo las posiciones de los otros documentos no relevantes constantes. 3.2.1 Prueba de Corrección El Algoritmo 2 es codicioso en el sentido de que encuentra la mejor posición de cada documento no relevante de forma independiente de los otros documentos no relevantes. En otras palabras, el algoritmo maximiza H para cada documento no relevante, d¯x j, Algoritmo 2 Encontrar la Restricción Más Violada (argmax H) para el Algoritmo 1 con ∆map 1: Entrada: w, Cx, C¯x 2: ordenar Cx y C¯x en orden descendente de wT φ(x, d) 3: sx i ← wT φ(x, dx i), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i), i = 1, . . . , |C¯x | 5: para j = 1, . . . , |C¯x | hacer 6: optj ← argmaxk δj(k, |Cx| + 1) 7: fin para 8: codificar ˆy de acuerdo con (7) 9: devolver ˆy sin considerar las posiciones de los otros documentos no relevantes, y así ignora las restricciones de (9). Para que la solución sea factible, el documento no relevante j-ésimo debe ser clasificado después de los primeros j-1 documentos no relevantes, satisfaciendo así opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. Si la solución es factible, entonces claramente resuelve (8). Por lo tanto, basta con demostrar que el Algoritmo 2 cumple con (10). Primero demostramos que δj(·, ·) es monótonamente decreciente en j. Lema 1. Para cualquier 1 ≤ i1 < i2 ≤ |Cx | + 1 y 1 ≤ j < |C¯x |, debe ser el caso que δj+1(i1, i2) ≤ δj(i1, i2). Prueba. Recuerde que tanto δj(i1, i2) como δj+1(i1, i2) son sumas de términos i2 − i1. Mostraremos que cada término en la suma de δj+1(i1, i2) no es mayor que el término correspondiente en δj(i1, i2), o δj+1(k, k + 1) ≤ δj(k, k + 1) para k = i1, . . . , i2 − 1. Cada término en δj(k, k +1) y δj+1(k, k +1) puede ser descompuesto aún más en dos partes (ver (5)). Mostraremos que cada parte de δj+1(k, k + 1) no es mayor que la parte correspondiente en δj(k, k + 1). En otras palabras, demostraremos que tanto j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) como −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) son verdaderos para los valores mencionados de j y k. Es fácil ver que (11) es verdadero observando que para cualquier par de enteros positivos 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1, y eligiendo a = j y b = j + k. La segunda desigualdad (12) se cumple porque el Algoritmo 2 primero ordena d¯x en orden descendente de s¯x, lo que implica s¯x j+1 ≤ s¯x j. Así vemos que cada término en δj+1 no es mayor que el término correspondiente en δj, lo cual completa la prueba. El resultado del Lema 1 conduce directamente a nuestro resultado principal de corrección: Teorema 2. En el Algoritmo 2, los valores calculados de optj satisfacen (10), lo que implica que la solución devuelta por el Algoritmo 2 es factible y, por lo tanto, óptima. Prueba. Demostraremos que optj ≤ optj+1 se cumple para cualquier 1 ≤ j < |C¯x|, implicando así (10). Dado que el Algoritmo 2 calcula optj como optj = argmax k δj(k, |Cx | + 1), (13), entonces por definición de δj (6), para cualquier 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0. Usando el Lema 1, sabemos que δj+1(i, optj) ≤ δj(i, optj) < 0, lo que implica que para cualquier 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0. Supongamos por contradicción que optj+1 < optj. Entonces δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), lo cual contradice (13). Por lo tanto, debe ser el caso que optj ≤ optj+1, lo cual completa la prueba. 3.2.2 Tiempo de ejecución El tiempo de ejecución del Algoritmo 2 se puede dividir en dos partes. La primera parte es la clasificación por wT φ(x, d), lo cual requiere un tiempo de O(n log n), donde n = |Cx | + |C¯x |. La segunda parte calcula cada optj, lo cual requiere un tiempo de O(|Cx| · |C¯x|). Aunque en el peor de los casos esto es O(n2), el número de documentos relevantes, |Cx|, suele ser muy pequeño (por ejemplo, constante con respecto a n), en cuyo caso el tiempo de ejecución para la segunda parte es simplemente O(n). Para la mayoría de los conjuntos de datos del mundo real, el Algoritmo 2 está dominado por la ordenación y tiene una complejidad O(n log n). El Algoritmo 1 está garantizado de detenerse en un número polinómico de iteraciones [19], y cada iteración ejecuta el Algoritmo 2. Prácticamente todos los modelos que funcionaron bien fueron entrenados en un tiempo razonable (generalmente menos de una hora). Una vez que el entrenamiento esté completo, hacer predicciones sobre la consulta x usando la hipótesis resultante h(x|w) solo requiere ordenar por wT φ(x, d). Desarrollamos nuestro software utilizando una interfaz de Python a SVMstruct, ya que el lenguaje Python simplificó en gran medida el proceso de codificación. Para mejorar el rendimiento, es recomendable utilizar la implementación estándar en C de SVMstruct. CONFIGURACIÓN DEL EXPERIMENTO El objetivo principal de nuestros experimentos es evaluar si la optimización directa de MAP conduce a un rendimiento de MAP mejorado en comparación con los métodos convencionales de SVM que optimizan una pérdida sustituta como la precisión o el área bajo la curva ROC. Evaluamos empíricamente nuestro método utilizando dos conjuntos de consultas de la TREC Web Track, uno de TREC 9 y otro de TREC 10 (temas 451-500 y 501-550), ambos de los cuales utilizaron el corpus WT10g. Para cada consulta, TREC proporciona las evaluaciones de relevancia de los documentos. Generamos nuestras características utilizando las puntuaciones de las funciones de recuperación existentes en estas consultas. Si bien nuestro método es agnóstico al significado de las características, elegimos utilizar funciones de recuperación existentes como una forma simple pero efectiva de adquirir características útiles. Por lo tanto, nuestros experimentos de estadísticas de conjuntos de datos básicos esencialmente prueban la capacidad de nuestros métodos para volver a clasificar los documentos altamente clasificados (por ejemplo, volver a combinar las puntuaciones de las funciones de recuperación) para mejorar el MAP. Comparamos nuestro método con las mejores funciones de recuperación entrenadas (en adelante, funciones base), así como con los métodos SVM propuestos anteriormente. Comparar con las mejores funciones base pone a prueba la capacidad de nuestros métodos para aprender una combinación útil. Comparar con métodos SVM anteriores nos permite probar si optimizar directamente para el MAP (en lugar de precisión o área bajo la curva ROC) logra una puntuación de MAP más alta en la práctica. El resto de esta sección describe las funciones base y el método de generación de características en detalle. 4.1 Elección de Funciones de Recuperación Elegimos dos conjuntos de funciones base para nuestros experimentos. Para el primer conjunto, generamos tres índices sobre el corpus WT10g utilizando Indri5. El primer índice fue generado utilizando la configuración predeterminada, el segundo utilizó Porter-stemming, y el último utilizó Porter-stemming y las palabras vacías predeterminadas de Indris. Para TREC 9 y TREC 10, utilizamos la parte de descripción de cada consulta y puntuamos los documentos utilizando cinco de los métodos de recuperación integrados en Indri, que son Similitud Coseno, TFIDF, Okapi, Modelo de Lenguaje con Prior de Dirichlet y Modelo de Lenguaje con Prior de Jelinek-Mercer. Todos los parámetros se mantuvieron en sus valores predeterminados. Calculamos las puntuaciones de estos cinco métodos de recuperación sobre los tres índices, dando un total de 15 funciones base. Para cada consulta, consideramos las puntuaciones de los documentos encontrados en la unión de los mejores 1000 documentos de cada función base. Para nuestro segundo conjunto de funciones base, utilizamos puntuaciones de las presentaciones de la pista web TREC 9 [8] y TREC 10 [9]. Utilizamos solo las presentaciones no manuales y no breves de ambos años. Para TREC 9 y TREC 10, hubo 53 y 18 envíos de este tipo, respectivamente. Una presentación típica contenía puntajes de sus 1000 documentos principales. b ca wT φ(x,d) f(d|x) Figura 2: Ejemplo de Agrupación de Características 4.2 Generación de Características Para generar ejemplos de entrada para nuestro método, se debe proporcionar una instancia concreta de φ. Para cada documento d puntuado por un conjunto de funciones de recuperación F en la consulta x, generamos las características como un vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf, donde f(d|x) denota la puntuación que la función de recuperación f asigna al documento d para la consulta x, y cada Kf es un conjunto de valores reales. Desde un nivel alto, estamos expresando la puntuación de cada función de recuperación utilizando |Kf | + 1 contenedores. Dado que estamos utilizando núcleos lineales, se puede pensar en el problema de aprendizaje como encontrar una buena combinación de piezas constantes de los puntajes de las funciones de recuperación. La Figura 2 muestra un ejemplo de nuestro método de mapeo de características. En este ejemplo tenemos una única característica F = {f}. Aquí, Kf = {a, b, c}, y el vector de pesos es w = wa, wb, wc. Para cualquier documento d y consulta x, tenemos wT φ(x, d) = 8 >>< >>: 0 si f(d|x) < a wa si a ≤ f(d|x) < b wa + wb si b ≤ f(d|x) < c wa + wb + wc si c ≤ f(d|x) . Esto se expresa cualitativamente en la Figura 2, donde wa y wb son positivos, y wc es negativo. Realizamos nuestros experimentos principales utilizando cuatro opciones de F: el conjunto de las funciones de recuperación de Indri mencionadas anteriormente para TREC 9 y TREC 10, y las presentaciones de la pista web para TREC 9 y TREC 10. Para cada F y cada función f ∈ F, elegimos 50 valores para Kf que estuvieran razonablemente espaciados y capturaran la región sensible de f. Utilizando las cuatro opciones de F, generamos cuatro conjuntos de datos para nuestros experimentos principales. La Tabla 5 contiene estadísticas de los conjuntos de datos generados. Hay muchas formas de generar características, y no estamos abogando por nuestro método sobre los demás. Esto fue simplemente un medio eficiente para normalizar las salidas de diferentes funciones y permitir un modelo más expresivo. EXPERIMENTOS Para cada conjunto de datos en la Tabla 5, realizamos 50 pruebas. Para cada prueba, entrenamos con 10 consultas seleccionadas al azar, y seleccionamos otras 5 consultas al azar para un conjunto de validación. Los modelos fueron entrenados utilizando una amplia gama de valores de C. El modelo que tuvo mejor rendimiento en el conjunto de validación fue seleccionado y probado en las 35 consultas restantes. Todas las consultas fueron seleccionadas para estar en los conjuntos de entrenamiento, validación y prueba la misma cantidad de veces. Utilizando esta configuración, realizamos los mismos experimentos mientras usábamos nuestro método (mapa SVM∆), un SVM optimizando para ROCArea (SVM∆ roc) [13], y un SVM de clasificación convencional (SVMacc) [20]. Todos los métodos de SVM utilizaron un kernel lineal. Informamos sobre el rendimiento promedio de todos los modelos en las 50 pruebas. 5.1 Comparación con Funciones Base Al analizar nuestros resultados, la primera pregunta a responder es, ¿puede SVM∆ map aprender un modelo que supere al mejor modelo base TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.290 - 0.287Mejor Func. 0.280 28/22 0.283 29/21 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 36/14 ** Tabla 7: Comparación con Envíos TREC TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288Mejor Func. 0.280 27/23 0.283 31/19 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 35/15 ** Tabla 8: Comparación con Funciones de Envíos TREC (sin el mejor) La Tabla 6 presenta la comparación del mapa SVM∆ con las mejores funciones base de Indri. Cada grupo de columnas contiene el rendimiento del MAP macro-promediado de SVM∆ map o una función base. Las columnas W/L muestran el número de consultas donde SVM∆ map logró un puntaje MAP más alto. Se realizaron pruebas de significancia utilizando la prueba de rango con signo de Wilcoxon de dos colas. Dos estrellas indican un nivel de significancia de 0.95. Todas las tablas que muestran nuestros resultados experimentales están estructuradas de manera idéntica. Aquí encontramos que SVM∆ mapea significativamente mejor que las mejores funciones base. La Tabla 7 muestra la comparación cuando se entrena con las presentaciones de TREC. Si bien logra una puntuación de MAP más alta que las mejores funciones base, la diferencia de rendimiento entre SVM∆ y las funciones base no es significativa. Dado que muchas de estas presentaciones utilizan funciones de puntuación cuidadosamente diseñadas para lograr un alto MAP, es posible que las presentaciones con mejor rendimiento utilicen técnicas que engloben las técnicas de las otras presentaciones. Como resultado, el mapa SVM∆ no sería capaz de aprender una hipótesis que pueda superar significativamente la mejor presentación. Por lo tanto, realizamos los mismos experimentos utilizando un conjunto de datos modificado en el que se eliminaron las características calculadas utilizando la mejor presentación. La tabla 8 muestra los resultados (ten en cuenta que aún estamos comparando con la mejor presentación, aunque no la estamos utilizando para el entrenamiento). Observa que si bien el rendimiento del SVM∆ map se degradó ligeramente, aún era comparable con el de la mejor presentación. 5.2 Comparación con Métodos SVM Anteriores La siguiente pregunta a responder es, ¿produce el SVM∆ map puntajes MAP más altos que los métodos SVM anteriores? Las tablas 9 y 10 presentan los resultados de SVM∆ map, SVM∆ roc y SVMacc cuando se entrenan con las funciones de recuperación de Indri y las presentaciones de TREC, respectivamente. La Tabla 11 contiene los resultados correspondientes cuando se entrena con las presentaciones de TREC sin la mejor presentación. Para empezar, nuestros resultados indican que SVMacc no fue competitivo con SVM∆ map y SVM∆ roc, y a veces tuvo un rendimiento notablemente inferior. Por lo tanto, probamos varios enfoques para mejorar el rendimiento de SVMacc. 5.2.1 Métodos alternativos de SVMacc Un problema que puede causar que SVMacc tenga un rendimiento deficiente es el desequilibrio severo entre documentos relevantes y no relevantes. La gran mayoría de los documentos no son relevantes. SVMacc2 aborda este problema asignando una penalización mayor a los errores de falsos negativos. Para cada conjunto de datos, la proporción de las penalizaciones por falsos negativos a falsos positivos es igual a la proporción entre el número de documentos no relevantes y relevantes en ese conjunto de datos. Las tablas 9, 10 y 11 indican que SVMacc2 sigue teniendo un rendimiento significativamente peor que SVM∆ map. Otro posible problema es que SVMacc intenta encontrar solo un umbral discriminatorio b que sea invariable a la consulta. Puede ser que diferentes consultas requieran diferentes valores de b. Tener el método de aprendizaje intentando encontrar un buen valor de b (cuando no existe) puede ser perjudicial. Tomamos dos enfoques para abordar este problema. El primer método, SVMacc3, convierte las puntuaciones de la función de recuperación en percentiles. Por ejemplo, para el documento d, la consulta q y la función de recuperación f, si la puntuación f(d|q) se encuentra en el 90% superior de las puntuaciones f(·|q) para la consulta q, entonces la puntuación convertida es f(d|q) = 0.9. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Las tablas 9, 10 y 11 muestran que el rendimiento de SVMacc3 tampoco fue competitivo con SVM∆ map. El segundo método, SVMacc4, normaliza las puntuaciones dadas por f para cada consulta. Por ejemplo, suponga para la consulta q que f produce puntuaciones en el rango de 0.2 a 0.7. Entonces, para el documento d, si f(d|q) = 0.6, la puntuación convertida sería f(d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Nuevamente, las Tablas 9, 10 y 11 muestran que SVMacc4 no fue competitivo con SVM∆ map 5.2.2 MAP vs ROCArea. SVM∆ roc tuvo un rendimiento mucho mejor que SVMacc en nuestros experimentos. Cuando se entrenó con las funciones de recuperación de Indri (ver Tabla 9), el rendimiento de SVM∆ roc fue ligeramente, aunque no significativamente, peor que el rendimiento de SVM∆ map. Sin embargo, la Tabla 10 muestra que el mapa SVM∆ superó significativamente al roc SVM∆ cuando se entrenó con las presentaciones de TREC. La tabla 11 muestra el rendimiento de los modelos cuando se entrenan con las presentaciones de TREC y se elimina la mejor presentación. El rendimiento de la mayoría de los modelos se degradó ligeramente, con SVM∆ map aún teniendo el mejor rendimiento. TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288 SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Tabla 11: Entrenado en TREC Subm. (sin Mejor) 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado un método SVM que optimiza directamente el MAP. Proporciona un enfoque basado en principios y evita heurísticas difíciles de controlar. Formulamos el problema de optimización y presentamos un algoritmo que encuentra la solución de manera demostrable en tiempo polinómico. Hemos demostrado empíricamente que nuestro método es generalmente superior o competitivo con los métodos convencionales de SVM. Nuestro nuevo método hace que sea conceptualmente tan fácil optimizar SVMs para MAP como anteriormente solo era posible para Precisión y Área bajo la curva ROC. El costo computacional para el entrenamiento es muy razonable en la práctica. Dado que otros métodos suelen requerir ajustar múltiples heurísticas, también esperamos entrenar menos modelos antes de encontrar uno que logre un buen rendimiento. El marco de aprendizaje utilizado por nuestro método es bastante general. Una extensión natural de este marco sería desarrollar métodos para optimizar otras medidas importantes de IR, como la Ganancia Acumulada Normalizada Descontada [2, 3, 4, 12] y la Reciprocidad Media de Rango. 7. AGRADECIMIENTOS Este trabajo fue financiado bajo el Premio NSF IIS-0412894, el Premio NSF CAREER 0237381 y un obsequio de Yahoo! Investigación. El tercer autor también fue parcialmente apoyado por una Beca de Investigación de Microsoft. 8. REFERENCIAS [1] B. T. Bartell, G. W. Cottrell y R. K. Belew. Combinación automática de múltiples sistemas de recuperación clasificados. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2005. [3] C. J. C. Burges, R. Ragno y Q. Lo. Aprendizaje para clasificar con funciones de costo no suaves. En Actas de la Conferencia Internacional sobre Avances en Sistemas de Información Neural (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang y H.-W. Hon. Adaptando el SVM de clasificación para la recuperación de documentos. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [5] B. Carterette y D. Petkova. Aprendiendo un ranking a partir de preferencias por pares. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew y A. Ksikes. Selección de conjunto de bibliotecas de modelos. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [7] J. Davis y M. Goadrich. La relación entre las curvas de precisión-recall y ROC. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2006. [8] D. Hawking. Resumen de la pista web TREC-9. En Actas de TREC-2000, 2000. [9] D. Hawking y N. Craswell. Resumen de la pista web TREC-2001. En Actas de TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel y K. Obermayer. Límites de rango de margen amplio para regresión ordinal. Avances en clasificadores de márgenes amplios, 2000. [11] A. Herschtal y B. Raskutti. Optimizando el área bajo la curva ROC utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [12] K. Jarvelin y J. Kekalainen. Métodos de evaluación para recuperar documentos altamente relevantes. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2000. [13] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), páginas 377-384, Nueva York, NY, EE. UU., 2005. ACM Press. [14] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), páginas 111-119, 2001. [15] Y. Lin, Y. Lee y G. Wahba. Máquinas de vectores de soporte para clasificación en situaciones no estándar. Aprendizaje automático, 46:191-202, 2002. [16] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [17] K. Morik, P. Brockhausen y T. Joachims. Combinando el aprendizaje estadístico con un enfoque basado en el conocimiento. En Actas de la Conferencia Internacional sobre Aprendizaje Automático, 1999. [18] S. Robertson. El principio de clasificación de probabilidad en la revista IR de documentación. Revista de Documentación, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims y Y. Altun. Métodos de margen amplio para variables de salida estructuradas e interdependientes. Revista de Investigación en Aprendizaje Automático (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik. Teoría del Aprendizaje Estadístico. Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz. \n\nWiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer y R. Wolniewicz. Optimizando el rendimiento del clasificador mediante la aproximación a la estadística de Wilcoxon-Mann-Witney. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2003. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "probability": {
            "translated_key": "probabilidad",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT Machine learning is commonly used to improve ranked retrieval systems.",
                "Due to computational difficulties, few learning techniques have been developed to directly optimize for mean average precision (MAP), despite its widespread use in evaluating such systems.",
                "Existing approaches optimizing MAP either do not find a globally optimal solution, or are computationally expensive.",
                "In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of MAP.",
                "We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora (WT10g), comparing against SVMs optimized for accuracy and ROCArea.",
                "In most cases we show our method to produce statistically significant improvements in MAP scores.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval Models General Terms Algorithm, Theory, Experimentation 1.",
                "INTRODUCTION State of the art information retrieval systems commonly use machine learning techniques to learn ranking functions.",
                "However, most current approaches do not optimize for the evaluation measure most often used, namely Mean Average Precision (MAP).",
                "Instead, current algorithms tend to take one of two general approaches.",
                "The first approach is to learn a model that estimates the <br>probability</br> of a document being relevant given a query (e.g., [18, 14]).",
                "If solved effectively, the ranking with best MAP performance can easily be derived from the probabilities of relevance.",
                "However, achieving high MAP only requires finding a good ordering of the documents.",
                "As a result, finding good probabilities requires solving a more difficult problem than necessary, likely requiring more training data to achieve the same MAP performance.",
                "The second common approach is to learn a function that maximizes a surrogate measure.",
                "Performance measures optimized include accuracy [17, 15], ROCArea [1, 5, 10, 11, 13, 21] or modifications of ROCArea [4], and NDCG [2, 3].",
                "Learning a model to optimize for such measures might result in suboptimal MAP performance.",
                "In fact, although some previous systems have obtained good MAP performance, it is known that neither achieving optimal accuracy nor ROCArea can guarantee optimal MAP performance[7].",
                "In this paper, we present a general approach for learning ranking functions that maximize MAP performance.",
                "Specifically, we present an SVM algorithm that globally optimizes a hinge-loss relaxation of MAP.",
                "This approach simplifies the process of obtaining ranking functions with high MAP performance by avoiding additional intermediate steps and heuristics.",
                "The new algorithm also makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for accuracy and ROCArea.",
                "In contrast to recent work directly optimizing for MAP performance by Metzler & Croft [16] and Caruana et al. [6], our technique is computationally efficient while finding a globally optimal solution.",
                "Like [6, 16], our method learns a linear model, but is much more efficient in practice and, unlike [16], can handle many thousands of features.",
                "We now describe the algorithm in detail and provide proof of correctness.",
                "Following this, we provide an analysis of running time.",
                "We finish with empirical results from experiments on the TREC 9 and TREC 10 Web Track corpus.",
                "We have also developed a software package implementing our algorithm that is available for public use1 . 2.",
                "THE LEARNING PROBLEM Following the standard machine learning setup, our goal is to learn a function h : X → Y between an input space X (all possible queries) and output space Y (rankings over a corpus).",
                "In order to quantify the quality of a prediction, ˆy = h(x), we will consider a loss function ∆ : Y × Y → . ∆(y, ˆy) quantifies the penalty for making prediction ˆy if the correct output is y.",
                "The loss function allows us to incorporate specific performance measures, which we will exploit 1 http://svmrank.yisongyue.com for optimizing MAP.",
                "We restrict ourselves to the supervised learning scenario, where input/output pairs (x, y) are available for training and are assumed to come from some fixed distribution P(x, y).",
                "The goal is to find a function h such that the risk (i.e., expected loss), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), is minimized.",
                "Of course, P(x, y) is unknown.",
                "But given a finite set of training pairs, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, the performance of h on S can be measured by the empirical risk, R∆ S (h) = 1 n nX i=1 ∆(yi, h(xi)).",
                "In the case of learning a ranked retrieval function, X denotes a space of queries, and Y the space of (possibly weak) rankings over some corpus of documents C = {d1, . . . ,d|C|}.",
                "We can define average precision loss as ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), where rank(y) is a vector of the rank values of each document in C. For example, for a corpus of two documents, {d1, d2}, with d1 having higher rank than d2, rank(y ) = (1, 0).",
                "We assume true rankings have two rank values, where relevant documents have rank value 1 and non-relevant documents rank value 0.",
                "We further assume that all predicted rankings are complete rankings (no ties).",
                "Let p = rank(y) and ˆp = rank(ˆy).",
                "The average precision score is defined as MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, where rel = |{i : pi = 1}| is the number of relevant documents, and Prec@j is the percentage of relevant documents in the top j documents in predicted ranking ˆy.",
                "MAP is the mean of the average precision scores of a group of queries. 2.1 MAP vs ROCArea Most learning algorithms optimize for accuracy or ROCArea.",
                "While optimizing for these measures might achieve good MAP performance, we use two simple examples to show it can also be suboptimal in terms of MAP.",
                "ROCArea assigns equal penalty to each misordering of a relevant/non-relevant pair.",
                "In contrast, MAP assigns greater penalties to misorderings higher up in the predicted ranking.",
                "Using our notation, ROCArea can be defined as ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], where p is the true (weak) ranking, ˆp is the predicted ranking, and 1[b] is the indicator function conditioned on b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Table 1: Toy Example and Models Suppose we have a hypothesis space with only two hypothesis functions, h1 and h2, as shown in Table 1.",
                "These two hypotheses predict a ranking for query x over a corpus of eight documents.",
                "Hypothesis MAP ROCArea h1(x) 0.59 0.47 h2(x) 0.51 0.53 Table 2: Performance of Toy Models Table 2 shows the MAP and ROCArea scores of h1 and h2.",
                "Here, a learning method which optimizes for ROCArea would choose h2 since that results in a higher ROCArea score, but this yields a suboptimal MAP score. 2.2 MAP vs Accuracy Using a very similar example, we now demonstrate how optimizing for accuracy might result in suboptimal MAP.",
                "Models which optimize for accuracy are not directly concerned with the ranking.",
                "Instead, they learn a threshold such that documents scoring higher than the threshold can be classified as relevant and documents scoring lower as nonrelevant.",
                "Doc ID 1 2 3 4 5 6 7 8 9 10 11 p 1 0 0 0 0 1 1 1 1 0 0 rank(h1(x)) 11 10 9 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 9 10 11 Table 3: Toy Example and Models We consider again a hypothesis space with two hypotheses.",
                "Table 3 shows the predictions of the two hypotheses on a single query x. Hypothesis MAP Best Acc. h1(q) 0.70 0.64 h2(q) 0.64 0.73 Table 4: Performance of Toy Models Table 4 shows the MAP and best accuracy scores of h1(q) and h2(q).",
                "The best accuracy refers to the highest achievable accuracy on that ranking when considering all possible thresholds.",
                "For instance, with h1(q), a threshold between documents 1 and 2 gives 4 errors (documents 6-9 incorrectly classified as non-relevant), yielding an accuracy of 0.64.",
                "Similarly, with h2(q), a threshold between documents 5 and 6 gives 3 errors (documents 10-11 incorrectly classified as relevant, and document 1 as non-relevant), yielding an accuracy of 0.73.",
                "A learning method which optimizes for accuracy would choose h2 since that results in a higher accuracy score, but this yields a suboptimal MAP score. 3.",
                "OPTIMIZING AVERAGE PRECISION We build upon the approach used by [13] for optimizing ROCArea.",
                "Unlike ROCArea, however, MAP does not decompose linearly in the examples and requires a substantially extended algorithm, which we describe in this section.",
                "Recall that the true ranking is a weak ranking with two rank values (relevant and non-relevant).",
                "Let Cx and C¯x denote the set of relevant and non-relevant documents of C for query x, respectively.",
                "We focus on functions which are parametrized by a weight vector w, and thus wish to find w to minimize the empirical risk, R∆ S (w) ≡ R∆ S (h(·; w)).",
                "Our approach is to learn a discriminant function F : X × Y → over input-output pairs.",
                "Given query x, we can derive a prediction by finding the ranking y that maximizes the discriminant function: h(x; w) = argmax y∈Y F(x, y; w). (1) We assume F to be linear in some combined feature representation of inputs and outputs Ψ(x, y) ∈ RN , i.e., F(x, y; w) = wT Ψ(x, y). (2) The combined feature function we use is Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))] , where φ : X × C → N is a feature mapping function from a query/document pair to a point in N dimensional space2 .",
                "We represent rankings as a matrix of pairwise orderings, Y ⊂ {−1, 0, +1}|C|×|C| .",
                "For any y ∈ Y, yij = +1 if di is ranked ahead of dj, and yij = −1 if dj is ranked ahead of di, and yij = 0 if di and dj have equal rank.",
                "We consider only matrices which correspond to valid rankings (i.e, obeying antisymmetry and transitivity).",
                "Intuitively, Ψ is a summation over the vector differences of all relevant/non-relevant document pairings.",
                "Since we assume predicted rankings to be complete rankings, yij is either +1 or −1 (never 0).",
                "Given a learned weight vector w, predicting a ranking (i.e. solving equation (1)) given query x reduces to picking each yij to maximize wT Ψ(x, y).",
                "As is also discussed in [13], this is attained by sorting the documents by wT φ(x, d) in descending order.",
                "We will discuss later the choices of φ we used for our experiments. 3.1 Structural SVMs The above formulation is very similar to learning a straightforward linear model while training on the pairwise difference of relevant/non-relevant document pairings.",
                "Many SVM-based approaches optimize over these pairwise differences (e.g., [5, 10, 13, 4]), although these methods do not optimize for MAP during training.",
                "Previously, it was not clear how to incorporate non-linear multivariate loss functions such as MAP loss directly into global optimization problems such as SVM training.",
                "We now present a method based on structural SVMs [19] to address this problem.",
                "We use the structural SVM formulation, presented in Optimization Problem 1, to learn a w ∈ RN .",
                "Optimization Problem 1. (Structural SVM) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) The objective function to be minimized (3) is a tradeoff between model complexity, w 2 , and a hinge loss relaxation of MAP loss, P ξi.",
                "As is usual in SVM training, C is a 2 For example, one dimension might be the number of times the query words appear in the document.",
                "Algorithm 1 Cutting plane algorithm for solving OP 1 within tolerance . 1: Input: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ for all i = 1, . . . , n 3: repeat 4: for i = 1, . . . , n do 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: compute ˆy = argmaxy∈Y H(y; w) 7: compute ξi = max{0, maxy∈Wi H(y; w)} 8: if H(ˆy; w) > ξi + then 9: Wi ← Wi ∪ {ˆy} 10: w ← optimize (3) over W = S i Wi 11: end if 12: end for 13: until no Wi has changed during iteration parameter that controls this tradeoff and can be tuned to achieve good performance in different training tasks.",
                "For each (xi, yi) in the training set, a set of constraints of the form in equation (4) is added to the optimization problem.",
                "Note that wT Ψ(x, y) is exactly our discriminant function F(x, y; w) (see equation (2)).",
                "During prediction, our model chooses the ranking which maximizes the discriminant (1).",
                "If the discriminant value for an incorrect ranking y is greater than for the true ranking yi (e.g., F(xi, y; w) > F(xi, yi; w)), then corresponding slack variable, ξi, must be at least ∆(yi, y) for that constraint to be satisfied.",
                "Therefore, the sum of slacks, P ξi, upper bounds the MAP loss.",
                "This is stated formally in Proposition 1.",
                "Proposition 1.",
                "Let ξ∗ (w) be the optimal solution of the slack variables for OP 1 for a given weight vector w. Then 1 n Pn i=1 ξi is an upper bound on the empirical risk R∆ S (w). (see [19] for proof) Proposition 1 shows that OP 1 learns a ranking function that optimizes an upper bound on MAP error on the training set.",
                "Unfortunately there is a problem: a constraint is required for every possible wrong output y, and the number of possible wrong outputs is exponential in the size of C. Fortunately, we may employ Algorithm 1 to solve OP 1.",
                "Algorithm 1 is a cutting plane algorithm, iteratively introducing constraints until we have solved the original problem within a desired tolerance [19].",
                "The algorithm starts with no constraints, and iteratively finds for each example (xi, yi) the output ˆy associated with the most violated constraint.",
                "If the corresponding constraint is violated by more than we introduce ˆy into the working set Wi of active constraints for example i, and re-solve (3) using the updated W. It can be shown that Algorithm 1s outer loop is guaranteed to halt within a polynomial number of iterations for any desired precision .",
                "Theorem 1.",
                "Let ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y) , ¯∆ = maxi maxy ∆(yi, y), and for any > 0, Algorithm 1 terminates after adding at most max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff constraints to the working set W. (see [19] for proof) However, within the inner loop of this algorithm we have to compute argmaxy∈Y H(y; w), where H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), or equivalently, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), since wT Ψ(xi, yi) is constant with respect to y.",
                "Though closely related to the classification procedure, this has the substantial complication that we must contend with the additional ∆(yi, y) term.",
                "Without the ability to efficiently find the most violated constraint (i.e., solve argmaxy∈Y H(y, w)), the constraint generation procedure is not tractable. 3.2 Finding the Most Violated Constraint Using OP 1 and optimizing to ROCArea loss (∆roc), the problem of finding the most violated constraint, or solving argmaxy∈Y H(y, w) (henceforth argmax H), is addressed in [13].",
                "Solving argmax H for ∆map is more difficult.",
                "This is primarily because ROCArea decomposes nicely into a sum of scores computed independently on each relative ordering of a relevant/non-relevant document pair.",
                "MAP, on the other hand, does not decompose in the same way as ROCArea.",
                "The main algorithmic contribution of this paper is an efficient method for solving argmax H for ∆map.",
                "One useful property of ∆map is that it is invariant to swapping two documents with equal relevance.",
                "For example, if documents da and db are both relevant, then swapping the positions of da and db in any ranking does not affect ∆map.",
                "By extension, ∆map is invariant to any arbitrary permutation of the relevant documents amongst themselves and of the non-relevant documents amongst themselves.",
                "However, this reshuﬄing will affect the discriminant score, wT Ψ(x, y).",
                "This leads us to Observation 1.",
                "Observation 1.",
                "Consider rankings which are constrained by fixing the relevance at each position in the ranking (e.g., the 3rd document in the ranking must be relevant).",
                "Every ranking which satisfies the same set of constraints will have the same ∆map.",
                "If the relevant documents are sorted by wT φ(x, d) in descending order, and the non-relevant documents are likewise sorted by wT φ(x, d), then the interleaving of the two sorted lists which satisfies the constraints will maximize H for that constrained set of rankings.",
                "Observation 1 implies that in the ranking which maximizes H, the relevant documents will be sorted by wT φ(x, d), and the non-relevant documents will also be sorted likewise.",
                "By first sorting the relevant and non-relevant documents, the problem is simplified to finding the optimal interleaving of two sorted lists.",
                "For the rest of our discussion, we assume that the relevant documents and non-relevant documents are both sorted by descending wT φ(x, d).",
                "For convenience, we also refer to relevant documents as {dx 1 , . . . dx |Cx|} = Cx , and non-relevant documents as {d¯x 1 , . . . d¯x |C¯x|} = C¯x .",
                "We define δj(i1, i2), with i1 < i2, as the change in H from when the highest ranked relevant document ranked after d¯x j is dx i1 to when it is dx i2 .",
                "For i2 = i1 + 1, we have δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5) where si = wT φ(x, di).",
                "The first term in (5) is the change in ∆map when the ith relevant document has j non-relevant documents ranked before it, as opposed to j −1.",
                "The second term is the change in the discriminant score, wT Ψ(x, y), when yij changes from +1 to −1. . . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . .",
                "Figure 1: Example for δj(i, i + 1) Figure 1 gives a conceptual example for δj(i, i + 1).",
                "The bottom ranking differs from the top only where d¯x j slides up one rank.",
                "The difference in the value of H for these two rankings is exactly δj(i, i + 1).",
                "For any i1 < i2, we can then define δj(i1, i2) as δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) or equivalently, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) .",
                "Let o1, . . . , o|C¯x| encode the positions of the non-relevant documents, where dx oj is the highest ranked relevant document ranked after the jth non-relevant document.",
                "Due to Observation 1, this encoding uniquely identifies a complete ranking.",
                "We can recover the ranking as yij = 8 >>>< >>>: 0 if i = j sign(si − sj) if di, dj equal relevance sign(oj − i − 0.5) if di = dx i , dj = d¯x j sign(j − oi + 0.5) if di = d¯x i , dj = dx j . (7) We can now reformulate H into a new objective function, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), where ¯y is the true (weak) ranking.",
                "Conceptually H starts with a perfect ranking ¯y, and adds the change in H when each successive non-relevant document slides up the ranking.",
                "We can then reformulate the argmax H problem as argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) s.t. o1 ≤ . . . ≤ o|C¯x|. (9) Algorithm 2 describes the algorithm used to solve equation (8).",
                "Conceptually, Algorithm 2 starts with a perfect ranking.",
                "Then for each successive non-relevant document, the algorithm modifies the solution by sliding that document up the ranking to locally maximize H while keeping the positions of the other non-relevant documents constant. 3.2.1 Proof of Correctness Algorithm 2 is greedy in the sense that it finds the best position of each non-relevant document independently from the other non-relevant documents.",
                "In other words, the algorithm maximizes H for each non-relevant document, d¯x j , Algorithm 2 Finding the Most Violated Constraint (argmax H) for Algorithm 1 with ∆map 1: Input: w, Cx , C¯x 2: sort Cx and C¯x in descending order of wT φ(x, d) 3: sx i ← wT φ(x, dx i ), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i ), i = 1, . . . , |C¯x | 5: for j = 1, . . . , |C¯x | do 6: optj ← argmaxk δj(k, |Cx | + 1) 7: end for 8: encode ˆy according to (7) 9: return ˆy without considering the positions of the other non-relevant documents, and thus ignores the constraints of (9).",
                "In order for the solution to be feasible, the jth non-relevant document must be ranked after the first j − 1 non-relevant documents, thus satisfying opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. (10) If the solution is feasible, the it clearly solves (8).",
                "Therefore, it suffices to prove that Algorithm 2 satisfies (10).",
                "We first prove that δj(·, ·) is monotonically decreasing in j. Lemma 1.",
                "For any 1 ≤ i1 < i2 ≤ |Cx | + 1 and 1 ≤ j < |C¯x |, it must be the case that δj+1(i1, i2) ≤ δj(i1, i2).",
                "Proof.",
                "Recall from (6) that both δj(i1, i2) and δj+1(i1, i2) are summations of i2 − i1 terms.",
                "We will show that each term in the summation of δj+1(i1, i2) is no greater than the corresponding term in δj(i1, i2), or δj+1(k, k + 1) ≤ δj(k, k + 1) for k = i1, . . . , i2 − 1.",
                "Each term in δj(k, k +1) and δj+1(k, k +1) can be further decomposed into two parts (see (5)).",
                "We will show that each part of δj+1(k, k + 1) is no greater than the corresponding part in δj(k, k + 1).",
                "In other words, we will show that both j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) and −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) are true for the aforementioned values of j and k. It is easy to see that (11) is true by observing that for any two positive integers 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1 , and choosing a = j and b = j + k. The second inequality (12) holds because Algorithm 2 first sorts d¯x in descending order of s¯x , implying s¯x j+1 ≤ s¯x j .",
                "Thus we see that each term in δj+1 is no greater than the corresponding term in δj, which completes the proof.",
                "The result of Lemma 1 leads directly to our main correctness result: Theorem 2.",
                "In Algorithm 2, the computed values of optj satisfy (10), implying that the solution returned by Algorithm 2 is feasible and thus optimal.",
                "Proof.",
                "We will prove that optj ≤ optj+1 holds for any 1 ≤ j < |C¯x |, thus implying (10).",
                "Since Algorithm 2 computes optj as optj = argmax k δj(k, |Cx | + 1), (13) then by definition of δj (6), for any 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0.",
                "Using Lemma 1, we know that δj+1(i, optj) ≤ δj(i, optj) < 0, which implies that for any 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0.",
                "Suppose for contradiction that optj+1 < optj.",
                "Then δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), which contradicts (13).",
                "Therefore, it must be the case that optj ≤ optj+1, which completes the proof. 3.2.2 Running Time The running time of Algorithm 2 can be split into two parts.",
                "The first part is the sort by wT φ(x, d), which requires O(n log n) time, where n = |Cx | + |C¯x |.",
                "The second part computes each optj, which requires O(|Cx | · |C¯x |) time.",
                "Though in the worst case this is O(n2 ), the number of relevant documents, |Cx |, is often very small (e.g., constant with respect to n), in which case the running time for the second part is simply O(n).",
                "For most real-world datasets, Algorithm 2 is dominated by the sort and has complexity O(n log n).",
                "Algorithm 1 is guaranteed to halt in a polynomial number of iterations [19], and each iteration runs Algorithm 2.",
                "Virtually all well-performing models were trained in a reasonable amount of time (usually less than one hour).",
                "Once training is complete, making predictions on query x using the resulting hypothesis h(x|w) requires only sorting by wT φ(x, d).",
                "We developed our software using a Python interface3 to SVMstruct , since the Python language greatly simplified the coding process.",
                "To improve performance, it is advisable to use the standard C implementation4 of SVMstruct . 4.",
                "EXPERIMENT SETUP The main goal of our experiments is to evaluate whether directly optimizing MAP leads to improved MAP performance compared to conventional SVM methods that optimize a substitute loss such as accuracy or ROCArea.",
                "We empirically evaluate our method using two sets of TREC Web Track queries, one each from TREC 9 and TREC 10 (topics 451-500 and 501-550), both of which used the WT10g corpus.",
                "For each query, TREC provides the relevance judgments of the documents.",
                "We generated our features using the scores of existing retrieval functions on these queries.",
                "While our method is agnostic to the meaning of the features, we chose to use existing retrieval functions as a simple yet effective way of acquiring useful features.",
                "As such, our 3 http://www.cs.cornell.edu/~tomf/svmpython/ 4 http://svmlight.joachims.org/svm_struct.html Dataset Base Funcs Features TREC 9 Indri 15 750 TREC 10 Indri 15 750 TREC 9 Submissions 53 2650 TREC 10 Submissions 18 900 Table 5: Dataset Statistics experiments essentially test our methods ability to re-rank the highly ranked documents (e.g., re-combine the scores of the retrieval functions) to improve MAP.",
                "We compare our method against the best retrieval functions trained on (henceforth base functions), as well as against previously proposed SVM methods.",
                "Comparing with the best base functions tests our methods ability to learn a useful combination.",
                "Comparing with previous SVM methods allows us to test whether optimizing directly for MAP (as opposed to accuracy or ROCArea) achieves a higher MAP score in practice.",
                "The rest of this section describes the base functions and the feature generation method in detail. 4.1 Choosing Retrieval Functions We chose two sets of base functions for our experiments.",
                "For the first set, we generated three indices over the WT10g corpus using Indri5 .",
                "The first index was generated using default settings, the second used Porter-stemming, and the last used Porter-stemming and Indris default stopwords.",
                "For both TREC 9 and TREC 10, we used the description portion of each query and scored the documents using five of Indris built-in retrieval methods, which are Cosine Similarity, TFIDF, Okapi, Language Model with Dirichlet Prior, and Language Model with Jelinek-Mercer Prior.",
                "All parameters were kept as their defaults.",
                "We computed the scores of these five retrieval methods over the three indices, giving 15 base functions in total.",
                "For each query, we considered the scores of documents found in the union of the top 1000 documents of each base function.",
                "For our second set of base functions, we used scores from the TREC 9 [8] and TREC 10 [9] Web Track submissions.",
                "We used only the non-manual, non-short submissions from both years.",
                "For TREC 9 and TREC 10, there were 53 and 18 such submissions, respectively.",
                "A typical submission contained scores of its top 1000 documents. b ca wT φ(x,d) f(d|x) Figure 2: Example Feature Binning 4.2 Generating Features In order to generate input examples for our method, a concrete instantiation of φ must be provided.",
                "For each doc5 http://www.lemurproject.org TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236Best Func. 0.204 39/11 ** 0.181 37/13 ** 2nd Best 0.199 38/12 ** 0.174 43/7 ** 3rd Best 0.188 34/16 ** 0.174 38/12 ** Table 6: Comparison with Indri Functions ument d scored by a set of retrieval functions F on query x, we generate the features as a vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf , where f(d|x) denotes the score that retrieval function f assigns to document d for query x, and each Kf is a set of real values.",
                "From a high level, we are expressing the score of each retrieval function using |Kf | + 1 bins.",
                "Since we are using linear kernels, one can think of the learning problem as finding a good piecewise-constant combination of the scores of the retrieval functions.",
                "Figure 2 shows an example of our feature mapping method.",
                "In this example we have a single feature F = {f}.",
                "Here, Kf = {a, b, c}, and the weight vector is w = wa, wb, wc .",
                "For any document d and query x, we have wT φ(x, d) = 8 >>< >>: 0 if f(d|x) < a wa if a ≤ f(d|x) < b wa + wb if b ≤ f(d|x) < c wa + wb + wc if c ≤ f(d|x) .",
                "This is expressed qualitatively in Figure 2, where wa and wb are positive, and wc is negative.",
                "We ran our main experiments using four choices of F: the set of aforementioned Indri retrieval functions for TREC 9 and TREC 10, and the Web Track submissions for TREC 9 and TREC 10.",
                "For each F and each function f ∈ F, we chose 50 values for Kf which are reasonably spaced and capture the sensitive region of f. Using the four choices of F, we generated four datasets for our main experiments.",
                "Table 5 contains statistics of the generated datasets.",
                "There are many ways to generate features, and we are not advocating our method over others.",
                "This was simply an efficient means to normalize the outputs of different functions and allow for a more expressive model. 5.",
                "EXPERIMENTS For each dataset in Table 5, we performed 50 trials.",
                "For each trial, we train on 10 randomly selected queries, and select another 5 queries at random for a validation set.",
                "Models were trained using a wide range of C values.",
                "The model which performed best on the validation set was selected and tested on the remaining 35 queries.",
                "All queries were selected to be in the training, validation and test sets the same number of times.",
                "Using this setup, we performed the same experiments while using our method (SVM∆ map), an SVM optimizing for ROCArea (SVM∆ roc) [13], and a conventional classification SVM (SVMacc) [20].",
                "All SVM methods used a linear kernel.",
                "We reported the average performance of all models over the 50 trials. 5.1 Comparison with Base Functions In analyzing our results, the first question to answer is, can SVM∆ map learn a model which outperforms the best base TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287Best Func. 0.280 28/22 0.283 29/21 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 36/14 ** Table 7: Comparison with TREC Submissions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288Best Func. 0.280 27/23 0.283 31/19 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 35/15 ** Table 8: Comparison with TREC Subm. (w/o best) functions?",
                "Table 6 presents the comparison of SVM∆ map with the best Indri base functions.",
                "Each column group contains the macro-averaged MAP performance of SVM∆ map or a base function.",
                "The W/L columns show the number of queries where SVM∆ map achieved a higher MAP score.",
                "Significance tests were performed using the two-tailed Wilcoxon signed rank test.",
                "Two stars indicate a significance level of 0.95.",
                "All tables displaying our experimental results are structured identically.",
                "Here, we find that SVM∆ map significantly outperforms the best base functions.",
                "Table 7 shows the comparison when trained on TREC submissions.",
                "While achieving a higher MAP score than the best base functions, the performance difference between SVM∆ map the base functions is not significant.",
                "Given that many of these submissions use scoring functions which are carefully crafted to achieve high MAP, it is possible that the best performing submissions use techniques which subsume the techniques of the other submissions.",
                "As a result, SVM∆ map would not be able to learn a hypothesis which can significantly out-perform the best submission.",
                "Hence, we ran the same experiments using a modified dataset where the features computed using the best submission were removed.",
                "Table 8 shows the results (note that we are still comparing against the best submission though we are not using it for training).",
                "Notice that while the performance of SVM∆ map degraded slightly, the performance was still comparable with that of the best submission. 5.2 Comparison w/ Previous SVM Methods The next question to answer is, does SVM∆ map produce higher MAP scores than previous SVM methods?",
                "Tables 9 and 10 present the results of SVM∆ map, SVM∆ roc, and SVMacc when trained on the Indri retrieval functions and TREC submissions, respectively.",
                "Table 11 contains the corresponding results when trained on the TREC submissions without the best submission.",
                "To start with, our results indicate that SVMacc was not competitive with SVM∆ map and SVM∆ roc, and at times underperformed dramatically.",
                "As such, we tried several approaches to improve the performance of SVMacc. 5.2.1 Alternate SVMacc Methods One issue which may cause SVMacc to underperform is the severe imbalance between relevant and non-relevant docTREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236SVM∆ roc 0.237 29/21 0.234 24/26 SVMacc 0.147 47/3 ** 0.155 47/3 ** SVMacc2 0.219 39/11 ** 0.207 43/7 ** SVMacc3 0.113 49/1 ** 0.153 45/5 ** SVMacc4 0.155 48/2 ** 0.155 48/2 ** Table 9: Trained on Indri Functions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287SVM∆ roc 0.282 29/21 0.278 35/15 ** SVMacc 0.213 49/1 ** 0.222 49/1 ** SVMacc2 0.270 34/16 ** 0.261 42/8 ** SVMacc3 0.133 50/0 ** 0.182 46/4 ** SVMacc4 0.233 47/3 ** 0.238 46/4 ** Table 10: Trained on TREC Submissions uments.",
                "The vast majority of the documents are not relevant.",
                "SVMacc2 addresses this problem by assigning more penalty to false negative errors.",
                "For each dataset, the ratio of the false negative to false positive penalties is equal to the ratio of the number non-relevant and relevant documents in that dataset.",
                "Tables 9, 10 and 11 indicate that SVMacc2 still performs significantly worse than SVM∆ map.",
                "Another possible issue is that SVMacc attempts to find just one discriminating threshold b that is query-invariant.",
                "It may be that different queries require different values of b.",
                "Having the learning method trying to find a good b value (when one does not exist) may be detrimental.",
                "We took two approaches to address this issue.",
                "The first method, SVMacc3, converts the retrieval function scores into percentiles.",
                "For example, for document d, query q and retrieval function f, if the score f(d|q) is in the top 90% of the scores f(·|q) for query q, then the converted score is f (d|q) = 0.9.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Tables 9, 10 and 11 show that the performance of SVMacc3 was also not competitive with SVM∆ map.",
                "The second method, SVMacc4, normalizes the scores given by f for each query.",
                "For example, assume for query q that f outputs scores in the range 0.2 to 0.7.",
                "Then for document d, if f(d|q) = 0.6, the converted score would be f (d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Again, Tables 9, 10 and 11 show that SVMacc4 was not competitive with SVM∆ map 5.2.2 MAP vs ROCArea SVM∆ roc performed much better than SVMacc in our experiments.",
                "When trained on Indri retrieval functions (see Table 9), the performance of SVM∆ roc was slight, though not significantly, worse than the performances of SVM∆ map.",
                "However, Table 10 shows that SVM∆ map did significantly outperform SVM∆ roc when trained on the TREC submissions.",
                "Table 11 shows the performance of the models when trained on the TREC submissions with the best submission removed.",
                "The performance of most models degraded by a small amount, with SVM∆ map still having the best performance.",
                "TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Table 11: Trained on TREC Subm. (w/o Best) 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented an SVM method that directly optimizes MAP.",
                "It provides a principled approach and avoids difficult to control heuristics.",
                "We formulated the optimization problem and presented an algorithm which provably finds the solution in polynomial time.",
                "We have shown empirically that our method is generally superior to or competitive with conventional SVMs methods.",
                "Our new method makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for Accuracy and ROCArea.",
                "The computational cost for training is very reasonable in practice.",
                "Since other methods typically require tuning multiple heuristics, we also expect to train fewer models before finding one which achieves good performance.",
                "The learning framework used by our method is fairly general.",
                "A natural extension of this framework would be to develop methods to optimize for other important IR measures, such as Normalized Discounted Cumulative Gain [2, 3, 4, 12] and Mean Reciprocal Rank. 7.",
                "ACKNOWLEDGMENTS This work was funded under NSF Award IIS-0412894, NSF CAREER Award 0237381, and a gift from Yahoo!",
                "Research.",
                "The third author was also partly supported by a Microsoft Research Fellowship. 8.",
                "REFERENCES [1] B. T. Bartell, G. W. Cottrell, and R. K. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2005. [3] C. J. C. Burges, R. Ragno, and Q.",
                "Le.",
                "Learning to rank with non-smooth cost functions.",
                "In Proceedings of the International Conference on Advances in Neural Information Processing Systems (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y.",
                "Liu, H. Li, Y. Huang, and H.-W. Hon.",
                "Adapting ranking SVM to document retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [5] B. Carterette and D. Petkova.",
                "Learning a ranking from pairwise preferences.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew, and A. Ksikes.",
                "Ensemble selection from libraries of models.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [7] J. Davis and M. Goadrich.",
                "The relationship between precision-recall and ROC curves.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2006. [8] D. Hawking.",
                "Overview of the TREC-9 web track.",
                "In Proceedings of TREC-2000, 2000. [9] D. Hawking and N. Craswell.",
                "Overview of the TREC-2001 web track.",
                "In Proceedings of TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel, and K. Obermayer.",
                "Large margin rank boundaries for ordinal regression.",
                "Advances in large margin classifiers, 2000. [11] A. Herschtal and B. Raskutti.",
                "Optimising area under the ROC curve using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [12] K. Jarvelin and J. Kekalainen.",
                "Ir evaluation methods for retrieving highly relevant documents.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2000. [13] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proceedings of the International Conference on Machine Learning (ICML), pages 377-384, New York, NY, USA, 2005.",
                "ACM Press. [14] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 111-119, 2001. [15] Y. Lin, Y. Lee, and G. Wahba.",
                "Support vector machines for classification in nonstandard situations.",
                "Machine Learning, 46:191-202, 2002. [16] D. Metzler and W. B. Croft.",
                "A markov random field model for term dependencies.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 472-479, 2005. [17] K. Morik, P. Brockhausen, and T. Joachims.",
                "Combining statistical learning with a knowledge-based approach.",
                "In Proceedings of the International Conference on Machine Learning, 1999. [18] S. Robertson.",
                "The <br>probability</br> ranking principle in ir. journal of documentation.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.",
                "Large margin methods for structured and interdependent output variables.",
                "Journal of Machine Learning Research (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik.",
                "Statistical Learning Theory.",
                "Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz.",
                "Optimizing classifier performance via approximation to the Wilcoxon-Mann-Witney statistic.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2003."
            ],
            "original_annotated_samples": [
                "The first approach is to learn a model that estimates the <br>probability</br> of a document being relevant given a query (e.g., [18, 14]).",
                "The <br>probability</br> ranking principle in ir. journal of documentation."
            ],
            "translated_annotated_samples": [
                "El primer enfoque es aprender un modelo que estime la <br>probabilidad</br> de que un documento sea relevante dado una consulta (por ejemplo, [18, 14]).",
                "El principio de clasificación de <br>probabilidad</br> en la revista IR de documentación."
            ],
            "translated_text": "Un método de Vectores de Soporte para optimizar la Precisión Promedio Yisong Yue Universidad de Cornell Ithaca, NY, EE. UU. yyue@cs.cornell.edu Thomas Finley Universidad de Cornell Ithaca, NY, EE. UU. tomf@cs.cornell.edu Filip Radlinski Universidad de Cornell Ithaca, NY, EE. UU. filip@cs.cornell.edu Thorsten Joachims Universidad de Cornell Ithaca, NY, EE. UU. tj@cs.cornell.edu RESUMEN El aprendizaje automático se utiliza comúnmente para mejorar los sistemas de recuperación clasificados. Debido a dificultades computacionales, se han desarrollado pocas técnicas de aprendizaje para optimizar directamente la precisión media promedio (MAP), a pesar de su uso generalizado en la evaluación de dichos sistemas. Los enfoques existentes que optimizan el MAP no encuentran una solución óptima global o son computacionalmente costosos. Por el contrario, presentamos un algoritmo de aprendizaje SVM general que encuentra de manera eficiente una solución óptima global para una relajación directa de MAP. Evaluamos nuestro enfoque utilizando los corpus de la pista web TREC 9 y TREC 10 (WT10g), comparando con SVM optimizados para precisión y área bajo la curva ROC. En la mayoría de los casos mostramos nuestro método para producir mejoras estadísticamente significativas en las puntuaciones de MAP. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de Recuperación Términos Generales Algoritmo, Teoría, Experimentación 1. INTRODUCCIÓN Los sistemas de recuperación de información de última generación comúnmente utilizan técnicas de aprendizaje automático para aprender funciones de clasificación. Sin embargo, la mayoría de los enfoques actuales no están optimizados para la medida de evaluación más utilizada, es decir, la Precisión Promedio Media (MAP). En cambio, los algoritmos actuales tienden a seguir uno de dos enfoques generales. El primer enfoque es aprender un modelo que estime la <br>probabilidad</br> de que un documento sea relevante dado una consulta (por ejemplo, [18, 14]). Si se resuelve de manera efectiva, la clasificación con el mejor rendimiento de MAP puede derivarse fácilmente de las probabilidades de relevancia. Sin embargo, lograr un MAP alto solo requiere encontrar un buen ordenamiento de los documentos. Como resultado, encontrar buenas probabilidades requiere resolver un problema más difícil de lo necesario, probablemente necesitando más datos de entrenamiento para lograr el mismo rendimiento de MAP. El segundo enfoque común es aprender una función que maximice una medida sustituta. Las medidas de rendimiento optimizadas incluyen precisión [17, 15], área bajo la curva ROC [1, 5, 10, 11, 13, 21] o modificaciones del área bajo la curva ROC [4], y NDCG [2, 3]. Aprender un modelo para optimizar tales medidas podría resultar en un rendimiento de MAP subóptimo. De hecho, aunque algunos sistemas anteriores han obtenido un buen rendimiento de MAP, se sabe que ni lograr una precisión óptima ni un área bajo la curva ROC pueden garantizar un rendimiento de MAP óptimo[7]. En este artículo, presentamos un enfoque general para aprender funciones de clasificación que maximizan el rendimiento de MAP. Específicamente, presentamos un algoritmo SVM que optimiza globalmente una relajación de pérdida de bisagra de MAP. Este enfoque simplifica el proceso de obtener funciones de clasificación con un alto rendimiento de MAP al evitar pasos intermedios adicionales y heurísticas. El nuevo algoritmo también hace que sea conceptualmente tan fácil optimizar las SVM para MAP como anteriormente solo era posible para precisión y ROCArea. A diferencia del trabajo reciente que optimiza directamente el rendimiento de MAP realizado por Metzler & Croft [16] y Caruana et al. [6], nuestra técnica es eficiente computacionalmente al encontrar una solución óptima a nivel global. Al igual que [6, 16], nuestro método aprende un modelo lineal, pero es mucho más eficiente en la práctica y, a diferencia de [16], puede manejar miles de características. Ahora describimos el algoritmo en detalle y proporcionamos la prueba de corrección. A continuación, proporcionamos un análisis del tiempo de ejecución. Concluimos con los resultados empíricos de experimentos en el corpus de la pista web TREC 9 y TREC 10. También hemos desarrollado un paquete de software que implementa nuestro algoritmo y está disponible para uso público. EL PROBLEMA DEL APRENDIZAJE Siguiendo la configuración estándar del aprendizaje automático, nuestro objetivo es aprender una función h: X → Y entre un espacio de entrada X (todas las consultas posibles) y un espacio de salida Y (clasificaciones sobre un corpus). Para cuantificar la calidad de una predicción, ˆy = h(x), consideraremos una función de pérdida ∆ : Y × Y → . ∆(y, ˆy) cuantifica la penalización por hacer la predicción ˆy si la salida correcta es y. La función de pérdida nos permite incorporar medidas específicas de rendimiento, las cuales explotaremos en http://svmrank.yisongyue.com para optimizar el MAP. Nos restringimos al escenario de aprendizaje supervisado, donde pares de entrada/salida (x, y) están disponibles para el entrenamiento y se asume que provienen de alguna distribución fija P(x, y). El objetivo es encontrar una función h tal que el riesgo (es decir, la pérdida esperada), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), se minimice. Por supuesto, P(x, y) es desconocido. Pero dado un conjunto finito de pares de entrenamiento, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, el rendimiento de h en S puede medirse mediante el riesgo empírico, R∆ S (h) = 1 n ∑ i=1 n ∆(yi, h(xi)). En el caso de aprender una función de recuperación clasificada, X denota un espacio de consultas, y Y el espacio de clasificaciones (posiblemente débiles) sobre algún corpus de documentos C = {d1, . . . ,d|C|}. Podemos definir la pérdida de precisión promedio como ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), donde rank(y) es un vector de los valores de rango de cada documento en C. Por ejemplo, para un corpus de dos documentos, {d1, d2}, con d1 teniendo un rango más alto que d2, rank(y) = (1, 0). Suponemos que las clasificaciones verdaderas tienen dos valores de clasificación, donde los documentos relevantes tienen un valor de clasificación 1 y los documentos no relevantes tienen un valor de clasificación 0. Además, asumimos que todas las clasificaciones predichas son clasificaciones completas (sin empates). Sea p = rango(y) y ˆp = rango(ˆy). La puntuación de precisión promedio se define como MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, donde rel = |{i : pi = 1}| es el número de documentos relevantes, y Prec@j es el porcentaje de documentos relevantes en los primeros j documentos en la clasificación predicha ˆy. MAP es la media de las puntuaciones de precisión promedio de un grupo de consultas. La mayoría de los algoritmos de aprendizaje se optimizan para precisión o ROCArea. Si bien optimizar estas medidas podría lograr un buen rendimiento de MAP, usamos dos ejemplos simples para mostrar que también puede ser subóptimo en términos de MAP. ROCArea asigna una penalización igual a cada desordenamiento de un par relevante/no relevante. Por el contrario, MAP asigna mayores penalizaciones a los errores de ordenamiento más arriba en la clasificación predicha. Usando nuestra notación, el Área bajo la Curva ROC (ROCArea) se puede definir como ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], donde p es el ranking verdadero (débil), ˆp es el ranking predicho, y 1[b] es la función indicadora condicionada a b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Tabla 1: Ejemplo y Modelos Supongamos que tenemos un espacio de hipótesis con solo dos funciones de hipótesis, h1 y h2, como se muestra en la Tabla 1. Estas dos hipótesis predicen un ranking para la consulta x sobre un corpus de ocho documentos. Tabla 2: Rendimiento de los Modelos de Juguete La Tabla 2 muestra las puntuaciones de MAP y ROCArea de h1 y h2. Aquí, un método de aprendizaje que optimiza para el Área bajo la curva ROC elegiría h2 ya que esto resulta en un puntaje de Área bajo la curva ROC más alto, pero esto produce un puntaje de MAP subóptimo. 2.2 MAP vs Precisión Usando un ejemplo muy similar, ahora demostramos cómo optimizar para la precisión podría resultar en un puntaje de MAP subóptimo. Los modelos que se optimizan para la precisión no están directamente preocupados por la clasificación. En cambio, aprenden un umbral tal que los documentos que obtienen una puntuación superior al umbral pueden ser clasificados como relevantes y los documentos que obtienen una puntuación inferior como no relevantes. Consideramos nuevamente un espacio de hipótesis con dos hipótesis. La Tabla 3 muestra las predicciones de las dos hipótesis en una única consulta x. Hipótesis MAP Mejor Precisión h1(q) 0.70 0.64 h2(q) 0.64 0.73 Tabla 4: Rendimiento de los Modelos de Juguete La Tabla 4 muestra los puntajes de MAP y mejor precisión de h1(q) y h2(q). La mejor precisión se refiere a la precisión más alta alcanzable en esa clasificación al considerar todos los umbrales posibles. Por ejemplo, con h1(q), un umbral entre los documentos 1 y 2 da 4 errores (documentos 6-9 clasificados incorrectamente como no relevantes), lo que resulta en una precisión de 0.64. De manera similar, con h2(q), un umbral entre los documentos 5 y 6 da 3 errores (los documentos 10-11 clasificados incorrectamente como relevantes, y el documento 1 como no relevante), lo que resulta en una precisión de 0.73. Un método de aprendizaje que optimiza la precisión elegiría h2 ya que esto resulta en un puntaje de precisión más alto, pero esto produce un puntaje de MAP subóptimo. 3. OPTIMIZANDO LA PRECISIÓN PROMEDIO Nos basamos en el enfoque utilizado por [13] para optimizar el Área bajo la Curva ROC. A diferencia de ROCArea, sin embargo, MAP no se descompone linealmente en los ejemplos y requiere un algoritmo sustancialmente extendido, el cual describimos en esta sección. Recuerda que la clasificación verdadera es una clasificación débil con dos valores de clasificación (relevante y no relevante). Que Cx y C¯x denoten el conjunto de documentos relevantes y no relevantes de C para la consulta x, respectivamente. Nos enfocamos en funciones que están parametrizadas por un vector de peso w, y por lo tanto deseamos encontrar w para minimizar el riesgo empírico, R∆ S (w) ≡ R∆ S (h(·; w)). Nuestro enfoque es aprender una función discriminante F: X × Y → sobre pares de entrada-salida. Dada la consulta x, podemos derivar una predicción encontrando la clasificación y que maximiza la función discriminante: h(x; w) = argmax y∈Y F(x, y; w). (1) Suponemos que F es lineal en alguna representación de características combinadas de entradas y salidas Ψ(x, y) ∈ RN, es decir, F(x, y; w) = wT Ψ(x, y). (2) La función de características combinadas que utilizamos es Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))], donde φ: X × C → N es una función de mapeo de características de un par consulta/documento a un punto en un espacio dimensional N. Representamos las clasificaciones como una matriz de ordenamientos por pares, Y ⊂ {−1, 0, +1}|C|×|C| . Para cualquier y ∈ Y, yij = +1 si di está clasificado por delante de dj, y yij = −1 si dj está clasificado por delante de di, y yij = 0 si di y dj tienen el mismo rango. Consideramos solo matrices que corresponden a clasificaciones válidas (es decir, que cumplen con la antisimetría y la transitividad). De manera intuitiva, Ψ es una suma de las diferencias vectoriales de todos los pares de documentos relevantes/no relevantes. Dado que asumimos que las clasificaciones predichas son clasificaciones completas, yij es o bien +1 o −1 (nunca 0). Dado un vector de pesos aprendido w, predecir un ranking (es decir, resolver la ecuación (1)) dado una consulta x se reduce a elegir cada yij para maximizar wT Ψ(x, y). Como también se discute en [13], esto se logra ordenando los documentos por wT φ(x, d) en orden descendente. Discutiremos más adelante las elecciones de φ que utilizamos para nuestros experimentos. 3.1 SVM Estructurales La formulación anterior es muy similar a aprender un modelo lineal directo mientras se entrena en la diferencia de pares de documentos relevantes/no relevantes. Muchos enfoques basados en SVM optimizan sobre estas diferencias en pares (por ejemplo, [5, 10, 13, 4]), aunque estos métodos no optimizan para el MAP durante el entrenamiento. Anteriormente, no estaba claro cómo incorporar funciones de pérdida multivariadas no lineales como la pérdida MAP directamente en problemas de optimización global como el entrenamiento de SVM. Ahora presentamos un método basado en SVM estructurales [19] para abordar este problema. Utilizamos la formulación del SVM estructural, presentada en el Problema de Optimización 1, para aprender un w ∈ RN. Problema de optimización 1. (SVM estructural) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) La función objetivo a minimizar (3) es un compromiso entre la complejidad del modelo, w 2 , y una relajación de pérdida de MAP mediante la pérdida de bisagra, P ξi. Como es habitual en el entrenamiento de SVM, C es igual a 2. Por ejemplo, una dimensión podría ser el número de veces que las palabras de la consulta aparecen en el documento. Algoritmo 1 Algoritmo de plano de corte para resolver OP 1 dentro de la tolerancia. 1: Entrada: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ para todo i = 1, . . . , n 3: repetir 4: para i = 1, . . . , n hacer 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: calcular ˆy = argmaxy∈Y H(y; w) 7: calcular ξi = max{0, maxy∈Wi H(y; w)} 8: si H(ˆy; w) > ξi + entonces 9: Wi ← Wi ∪ {ˆy} 10: w ← optimizar (3) sobre W = S i Wi 11: fin si 12: fin para 13: hasta que ningún Wi haya cambiado durante la iteración parámetro que controla este equilibrio y puede ajustarse para lograr un buen rendimiento en diferentes tareas de entrenamiento. Para cada (xi, yi) en el conjunto de entrenamiento, se añade un conjunto de restricciones de la forma en la ecuación (4) al problema de optimización. Ten en cuenta que wT Ψ(x, y) es exactamente nuestra función discriminante F(x, y; w) (ver ecuación (2)). Durante la predicción, nuestro modelo elige el ranking que maximiza el discriminante (1). Si el valor del discriminante para una clasificación incorrecta y es mayor que para la clasificación verdadera yi (por ejemplo, F(xi, y; w) > F(xi, yi; w)), entonces la variable de holgura correspondiente, ξi, debe ser al menos ∆(yi, y) para que se cumpla esa restricción. Por lo tanto, la suma de los márgenes, P ξi, acota superiormente la pérdida MAP. Esto se establece formalmente en la Proposición 1. Proposición 1. Sea ξ∗ (w) la solución óptima de las variables de holgura para OP 1 para un vector de peso dado w. Entonces 1 n Pn i=1 ξi es una cota superior del riesgo empírico R∆ S (w). (ver [19] para la prueba) La Proposición 1 muestra que OP 1 aprende una función de clasificación que optimiza una cota superior del error de MAP en el conjunto de entrenamiento. Desafortunadamente hay un problema: se requiere una restricción para cada posible resultado incorrecto y, y el número de resultados incorrectos posibles es exponencial en el tamaño de C. Afortunadamente, podemos emplear el Algoritmo 1 para resolver OP 1. El algoritmo 1 es un algoritmo de plano de corte, introduciendo iterativamente restricciones hasta que hayamos resuelto el problema original dentro de una tolerancia deseada [19]. El algoritmo comienza sin restricciones y encuentra de forma iterativa, para cada ejemplo (xi, yi), la salida ˆy asociada con la restricción más violada. Si la restricción correspondiente es violada por más de lo que introducimos ˆy en el conjunto de trabajo Wi de restricciones activas, por ejemplo i, y volvemos a resolver (3) usando el W actualizado. Se puede demostrar que el bucle externo del Algoritmo 1 está garantizado a detenerse dentro de un número polinomial de iteraciones para cualquier precisión deseada. Teorema 1. Sea ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y), ¯∆ = maxi maxy ∆(yi, y), y para cualquier > 0, el Algoritmo 1 termina después de agregar a lo sumo max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff restricciones al conjunto de trabajo W. (ver [19] para la prueba) Sin embargo, dentro del bucle interno de este algoritmo tenemos que calcular argmaxy∈Y H(y; w), donde H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), o equivalentemente, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), ya que wT Ψ(xi, yi) es constante con respecto a y. Aunque está estrechamente relacionado con el procedimiento de clasificación, esto tiene la complicación sustancial de que debemos lidiar con el término adicional ∆(yi, y). Sin la capacidad de encontrar eficientemente la restricción más violada (es decir, resolver argmaxy∈Y H(y, w)), el procedimiento de generación de restricciones no es viable. 3.2 Encontrar la restricción más violada utilizando OP 1 y optimizando la pérdida de ROCArea (∆roc), el problema de encontrar la restricción más violada, o resolver argmaxy∈Y H(y, w) (en adelante argmax H), se aborda en [13]. Resolver argmax H para ∆map es más difícil. Esto se debe principalmente a que ROCArea se descompone de manera ordenada en una suma de puntuaciones calculadas de forma independiente en cada ordenamiento relativo de un par de documentos relevantes/no relevantes. MAP, por otro lado, no se descompone de la misma manera que ROCArea. La principal contribución algorítmica de este artículo es un método eficiente para resolver argmax H para ∆map. Una propiedad útil de ∆map es que es invariante al intercambiar dos documentos con igual relevancia. Por ejemplo, si los documentos da y db son ambos relevantes, entonces intercambiar las posiciones de da y db en cualquier clasificación no afecta a ∆map. Por extensión, ∆map es invariante a cualquier permutación arbitraria de los documentos relevantes entre sí y de los documentos no relevantes entre sí. Sin embargo, esta reorganización afectará la puntuación del discriminante, wT Ψ(x, y). Esto nos lleva a la Observación 1. Observación 1. Considera clasificaciones que estén limitadas por fijar la relevancia en cada posición de la clasificación (por ejemplo, el tercer documento en la clasificación debe ser relevante). Cada clasificación que cumpla con el mismo conjunto de restricciones tendrá el mismo ∆map. Si los documentos relevantes están ordenados por wT φ(x, d) en orden descendente, y los documentos no relevantes también están ordenados de la misma manera por wT φ(x, d), entonces la intercalación de las dos listas ordenadas que cumpla con las restricciones maximizará H para ese conjunto de clasificaciones restringidas. La Observación 1 implica que en la clasificación que maximiza H, los documentos relevantes se ordenarán por wT φ(x, d), y los documentos no relevantes también se ordenarán de la misma manera. Al ordenar primero los documentos relevantes y no relevantes, el problema se simplifica a encontrar la intercalación óptima de dos listas ordenadas. Para el resto de nuestra discusión, asumimos que los documentos relevantes y no relevantes están ordenados por wT φ(x, d) en orden descendente. Para mayor comodidad, también nos referimos a los documentos relevantes como {dx 1 , . . . dx |Cx|} = Cx, y a los documentos no relevantes como {d¯x 1 , . . . d¯x |C¯x|} = C¯x. Definimos δj(i1, i2), con i1 < i2, como el cambio en H desde cuando el documento relevante de mayor rango clasificado después de d¯x j es dx i1 hasta que es dx i2. Para i2 = i1 + 1, tenemos δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5), donde si = wT φ(x, di). El primer término en (5) es el cambio en ∆map cuando el documento relevante i tiene j documentos no relevantes clasificados antes de él, en lugar de j-1. El segundo término es el cambio en la puntuación del discriminante, wT Ψ(x, y), cuando yij cambia de +1 a −1. . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . . Figura 1: Ejemplo para δj(i, i + 1). La Figura 1 proporciona un ejemplo conceptual para δj(i, i + 1). La clasificación inferior difiere de la superior solo cuando d¯x j sube un rango. La diferencia en el valor de H para estas dos clasificaciones es exactamente δj(i, i + 1). Para cualquier i1 < i2, podemos definir δj(i1, i2) como δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) o equivalentemente, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) . Deja que o1, . . . , o|C¯x| codifiquen las posiciones de los documentos no relevantes, donde dx oj es el documento relevante de mayor rango clasificado después del j-ésimo documento no relevante. Debido a la Observación 1, esta codificación identifica de forma única un ranking completo. Podemos recuperar la clasificación como yij = 8 >>>< >>>: 0 si i = j sign(si − sj) si di, dj relevancia igual signo(oj − i − 0.5) si di = dx i , dj = d¯x j signo(j − oi + 0.5) si di = d¯x i , dj = dx j. (7) Ahora podemos reformular H en una nueva función objetivo, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), donde ¯y es la verdadera clasificación (débil). Conceptualmente, H comienza con una clasificación perfecta ¯y y agrega el cambio en H cuando cada documento no relevante sucesivo sube en la clasificación. Luego podemos reformular el problema argmax H como argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) sujeto a o1 ≤ . . . ≤ o|C¯x|. (9) El Algoritmo 2 describe el algoritmo utilizado para resolver la ecuación (8). Conceptualmente, el Algoritmo 2 comienza con un ranking perfecto. Entonces, para cada documento no relevante sucesivo, el algoritmo modifica la solución deslizando ese documento hacia arriba en la clasificación para maximizar localmente H, manteniendo las posiciones de los otros documentos no relevantes constantes. 3.2.1 Prueba de Corrección El Algoritmo 2 es codicioso en el sentido de que encuentra la mejor posición de cada documento no relevante de forma independiente de los otros documentos no relevantes. En otras palabras, el algoritmo maximiza H para cada documento no relevante, d¯x j, Algoritmo 2 Encontrar la Restricción Más Violada (argmax H) para el Algoritmo 1 con ∆map 1: Entrada: w, Cx, C¯x 2: ordenar Cx y C¯x en orden descendente de wT φ(x, d) 3: sx i ← wT φ(x, dx i), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i), i = 1, . . . , |C¯x | 5: para j = 1, . . . , |C¯x | hacer 6: optj ← argmaxk δj(k, |Cx| + 1) 7: fin para 8: codificar ˆy de acuerdo con (7) 9: devolver ˆy sin considerar las posiciones de los otros documentos no relevantes, y así ignora las restricciones de (9). Para que la solución sea factible, el documento no relevante j-ésimo debe ser clasificado después de los primeros j-1 documentos no relevantes, satisfaciendo así opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. Si la solución es factible, entonces claramente resuelve (8). Por lo tanto, basta con demostrar que el Algoritmo 2 cumple con (10). Primero demostramos que δj(·, ·) es monótonamente decreciente en j. Lema 1. Para cualquier 1 ≤ i1 < i2 ≤ |Cx | + 1 y 1 ≤ j < |C¯x |, debe ser el caso que δj+1(i1, i2) ≤ δj(i1, i2). Prueba. Recuerde que tanto δj(i1, i2) como δj+1(i1, i2) son sumas de términos i2 − i1. Mostraremos que cada término en la suma de δj+1(i1, i2) no es mayor que el término correspondiente en δj(i1, i2), o δj+1(k, k + 1) ≤ δj(k, k + 1) para k = i1, . . . , i2 − 1. Cada término en δj(k, k +1) y δj+1(k, k +1) puede ser descompuesto aún más en dos partes (ver (5)). Mostraremos que cada parte de δj+1(k, k + 1) no es mayor que la parte correspondiente en δj(k, k + 1). En otras palabras, demostraremos que tanto j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) como −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) son verdaderos para los valores mencionados de j y k. Es fácil ver que (11) es verdadero observando que para cualquier par de enteros positivos 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1, y eligiendo a = j y b = j + k. La segunda desigualdad (12) se cumple porque el Algoritmo 2 primero ordena d¯x en orden descendente de s¯x, lo que implica s¯x j+1 ≤ s¯x j. Así vemos que cada término en δj+1 no es mayor que el término correspondiente en δj, lo cual completa la prueba. El resultado del Lema 1 conduce directamente a nuestro resultado principal de corrección: Teorema 2. En el Algoritmo 2, los valores calculados de optj satisfacen (10), lo que implica que la solución devuelta por el Algoritmo 2 es factible y, por lo tanto, óptima. Prueba. Demostraremos que optj ≤ optj+1 se cumple para cualquier 1 ≤ j < |C¯x|, implicando así (10). Dado que el Algoritmo 2 calcula optj como optj = argmax k δj(k, |Cx | + 1), (13), entonces por definición de δj (6), para cualquier 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0. Usando el Lema 1, sabemos que δj+1(i, optj) ≤ δj(i, optj) < 0, lo que implica que para cualquier 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0. Supongamos por contradicción que optj+1 < optj. Entonces δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), lo cual contradice (13). Por lo tanto, debe ser el caso que optj ≤ optj+1, lo cual completa la prueba. 3.2.2 Tiempo de ejecución El tiempo de ejecución del Algoritmo 2 se puede dividir en dos partes. La primera parte es la clasificación por wT φ(x, d), lo cual requiere un tiempo de O(n log n), donde n = |Cx | + |C¯x |. La segunda parte calcula cada optj, lo cual requiere un tiempo de O(|Cx| · |C¯x|). Aunque en el peor de los casos esto es O(n2), el número de documentos relevantes, |Cx|, suele ser muy pequeño (por ejemplo, constante con respecto a n), en cuyo caso el tiempo de ejecución para la segunda parte es simplemente O(n). Para la mayoría de los conjuntos de datos del mundo real, el Algoritmo 2 está dominado por la ordenación y tiene una complejidad O(n log n). El Algoritmo 1 está garantizado de detenerse en un número polinómico de iteraciones [19], y cada iteración ejecuta el Algoritmo 2. Prácticamente todos los modelos que funcionaron bien fueron entrenados en un tiempo razonable (generalmente menos de una hora). Una vez que el entrenamiento esté completo, hacer predicciones sobre la consulta x usando la hipótesis resultante h(x|w) solo requiere ordenar por wT φ(x, d). Desarrollamos nuestro software utilizando una interfaz de Python a SVMstruct, ya que el lenguaje Python simplificó en gran medida el proceso de codificación. Para mejorar el rendimiento, es recomendable utilizar la implementación estándar en C de SVMstruct. CONFIGURACIÓN DEL EXPERIMENTO El objetivo principal de nuestros experimentos es evaluar si la optimización directa de MAP conduce a un rendimiento de MAP mejorado en comparación con los métodos convencionales de SVM que optimizan una pérdida sustituta como la precisión o el área bajo la curva ROC. Evaluamos empíricamente nuestro método utilizando dos conjuntos de consultas de la TREC Web Track, uno de TREC 9 y otro de TREC 10 (temas 451-500 y 501-550), ambos de los cuales utilizaron el corpus WT10g. Para cada consulta, TREC proporciona las evaluaciones de relevancia de los documentos. Generamos nuestras características utilizando las puntuaciones de las funciones de recuperación existentes en estas consultas. Si bien nuestro método es agnóstico al significado de las características, elegimos utilizar funciones de recuperación existentes como una forma simple pero efectiva de adquirir características útiles. Por lo tanto, nuestros experimentos de estadísticas de conjuntos de datos básicos esencialmente prueban la capacidad de nuestros métodos para volver a clasificar los documentos altamente clasificados (por ejemplo, volver a combinar las puntuaciones de las funciones de recuperación) para mejorar el MAP. Comparamos nuestro método con las mejores funciones de recuperación entrenadas (en adelante, funciones base), así como con los métodos SVM propuestos anteriormente. Comparar con las mejores funciones base pone a prueba la capacidad de nuestros métodos para aprender una combinación útil. Comparar con métodos SVM anteriores nos permite probar si optimizar directamente para el MAP (en lugar de precisión o área bajo la curva ROC) logra una puntuación de MAP más alta en la práctica. El resto de esta sección describe las funciones base y el método de generación de características en detalle. 4.1 Elección de Funciones de Recuperación Elegimos dos conjuntos de funciones base para nuestros experimentos. Para el primer conjunto, generamos tres índices sobre el corpus WT10g utilizando Indri5. El primer índice fue generado utilizando la configuración predeterminada, el segundo utilizó Porter-stemming, y el último utilizó Porter-stemming y las palabras vacías predeterminadas de Indris. Para TREC 9 y TREC 10, utilizamos la parte de descripción de cada consulta y puntuamos los documentos utilizando cinco de los métodos de recuperación integrados en Indri, que son Similitud Coseno, TFIDF, Okapi, Modelo de Lenguaje con Prior de Dirichlet y Modelo de Lenguaje con Prior de Jelinek-Mercer. Todos los parámetros se mantuvieron en sus valores predeterminados. Calculamos las puntuaciones de estos cinco métodos de recuperación sobre los tres índices, dando un total de 15 funciones base. Para cada consulta, consideramos las puntuaciones de los documentos encontrados en la unión de los mejores 1000 documentos de cada función base. Para nuestro segundo conjunto de funciones base, utilizamos puntuaciones de las presentaciones de la pista web TREC 9 [8] y TREC 10 [9]. Utilizamos solo las presentaciones no manuales y no breves de ambos años. Para TREC 9 y TREC 10, hubo 53 y 18 envíos de este tipo, respectivamente. Una presentación típica contenía puntajes de sus 1000 documentos principales. b ca wT φ(x,d) f(d|x) Figura 2: Ejemplo de Agrupación de Características 4.2 Generación de Características Para generar ejemplos de entrada para nuestro método, se debe proporcionar una instancia concreta de φ. Para cada documento d puntuado por un conjunto de funciones de recuperación F en la consulta x, generamos las características como un vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf, donde f(d|x) denota la puntuación que la función de recuperación f asigna al documento d para la consulta x, y cada Kf es un conjunto de valores reales. Desde un nivel alto, estamos expresando la puntuación de cada función de recuperación utilizando |Kf | + 1 contenedores. Dado que estamos utilizando núcleos lineales, se puede pensar en el problema de aprendizaje como encontrar una buena combinación de piezas constantes de los puntajes de las funciones de recuperación. La Figura 2 muestra un ejemplo de nuestro método de mapeo de características. En este ejemplo tenemos una única característica F = {f}. Aquí, Kf = {a, b, c}, y el vector de pesos es w = wa, wb, wc. Para cualquier documento d y consulta x, tenemos wT φ(x, d) = 8 >>< >>: 0 si f(d|x) < a wa si a ≤ f(d|x) < b wa + wb si b ≤ f(d|x) < c wa + wb + wc si c ≤ f(d|x) . Esto se expresa cualitativamente en la Figura 2, donde wa y wb son positivos, y wc es negativo. Realizamos nuestros experimentos principales utilizando cuatro opciones de F: el conjunto de las funciones de recuperación de Indri mencionadas anteriormente para TREC 9 y TREC 10, y las presentaciones de la pista web para TREC 9 y TREC 10. Para cada F y cada función f ∈ F, elegimos 50 valores para Kf que estuvieran razonablemente espaciados y capturaran la región sensible de f. Utilizando las cuatro opciones de F, generamos cuatro conjuntos de datos para nuestros experimentos principales. La Tabla 5 contiene estadísticas de los conjuntos de datos generados. Hay muchas formas de generar características, y no estamos abogando por nuestro método sobre los demás. Esto fue simplemente un medio eficiente para normalizar las salidas de diferentes funciones y permitir un modelo más expresivo. EXPERIMENTOS Para cada conjunto de datos en la Tabla 5, realizamos 50 pruebas. Para cada prueba, entrenamos con 10 consultas seleccionadas al azar, y seleccionamos otras 5 consultas al azar para un conjunto de validación. Los modelos fueron entrenados utilizando una amplia gama de valores de C. El modelo que tuvo mejor rendimiento en el conjunto de validación fue seleccionado y probado en las 35 consultas restantes. Todas las consultas fueron seleccionadas para estar en los conjuntos de entrenamiento, validación y prueba la misma cantidad de veces. Utilizando esta configuración, realizamos los mismos experimentos mientras usábamos nuestro método (mapa SVM∆), un SVM optimizando para ROCArea (SVM∆ roc) [13], y un SVM de clasificación convencional (SVMacc) [20]. Todos los métodos de SVM utilizaron un kernel lineal. Informamos sobre el rendimiento promedio de todos los modelos en las 50 pruebas. 5.1 Comparación con Funciones Base Al analizar nuestros resultados, la primera pregunta a responder es, ¿puede SVM∆ map aprender un modelo que supere al mejor modelo base TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.290 - 0.287Mejor Func. 0.280 28/22 0.283 29/21 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 36/14 ** Tabla 7: Comparación con Envíos TREC TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288Mejor Func. 0.280 27/23 0.283 31/19 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 35/15 ** Tabla 8: Comparación con Funciones de Envíos TREC (sin el mejor) La Tabla 6 presenta la comparación del mapa SVM∆ con las mejores funciones base de Indri. Cada grupo de columnas contiene el rendimiento del MAP macro-promediado de SVM∆ map o una función base. Las columnas W/L muestran el número de consultas donde SVM∆ map logró un puntaje MAP más alto. Se realizaron pruebas de significancia utilizando la prueba de rango con signo de Wilcoxon de dos colas. Dos estrellas indican un nivel de significancia de 0.95. Todas las tablas que muestran nuestros resultados experimentales están estructuradas de manera idéntica. Aquí encontramos que SVM∆ mapea significativamente mejor que las mejores funciones base. La Tabla 7 muestra la comparación cuando se entrena con las presentaciones de TREC. Si bien logra una puntuación de MAP más alta que las mejores funciones base, la diferencia de rendimiento entre SVM∆ y las funciones base no es significativa. Dado que muchas de estas presentaciones utilizan funciones de puntuación cuidadosamente diseñadas para lograr un alto MAP, es posible que las presentaciones con mejor rendimiento utilicen técnicas que engloben las técnicas de las otras presentaciones. Como resultado, el mapa SVM∆ no sería capaz de aprender una hipótesis que pueda superar significativamente la mejor presentación. Por lo tanto, realizamos los mismos experimentos utilizando un conjunto de datos modificado en el que se eliminaron las características calculadas utilizando la mejor presentación. La tabla 8 muestra los resultados (ten en cuenta que aún estamos comparando con la mejor presentación, aunque no la estamos utilizando para el entrenamiento). Observa que si bien el rendimiento del SVM∆ map se degradó ligeramente, aún era comparable con el de la mejor presentación. 5.2 Comparación con Métodos SVM Anteriores La siguiente pregunta a responder es, ¿produce el SVM∆ map puntajes MAP más altos que los métodos SVM anteriores? Las tablas 9 y 10 presentan los resultados de SVM∆ map, SVM∆ roc y SVMacc cuando se entrenan con las funciones de recuperación de Indri y las presentaciones de TREC, respectivamente. La Tabla 11 contiene los resultados correspondientes cuando se entrena con las presentaciones de TREC sin la mejor presentación. Para empezar, nuestros resultados indican que SVMacc no fue competitivo con SVM∆ map y SVM∆ roc, y a veces tuvo un rendimiento notablemente inferior. Por lo tanto, probamos varios enfoques para mejorar el rendimiento de SVMacc. 5.2.1 Métodos alternativos de SVMacc Un problema que puede causar que SVMacc tenga un rendimiento deficiente es el desequilibrio severo entre documentos relevantes y no relevantes. La gran mayoría de los documentos no son relevantes. SVMacc2 aborda este problema asignando una penalización mayor a los errores de falsos negativos. Para cada conjunto de datos, la proporción de las penalizaciones por falsos negativos a falsos positivos es igual a la proporción entre el número de documentos no relevantes y relevantes en ese conjunto de datos. Las tablas 9, 10 y 11 indican que SVMacc2 sigue teniendo un rendimiento significativamente peor que SVM∆ map. Otro posible problema es que SVMacc intenta encontrar solo un umbral discriminatorio b que sea invariable a la consulta. Puede ser que diferentes consultas requieran diferentes valores de b. Tener el método de aprendizaje intentando encontrar un buen valor de b (cuando no existe) puede ser perjudicial. Tomamos dos enfoques para abordar este problema. El primer método, SVMacc3, convierte las puntuaciones de la función de recuperación en percentiles. Por ejemplo, para el documento d, la consulta q y la función de recuperación f, si la puntuación f(d|q) se encuentra en el 90% superior de las puntuaciones f(·|q) para la consulta q, entonces la puntuación convertida es f(d|q) = 0.9. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Las tablas 9, 10 y 11 muestran que el rendimiento de SVMacc3 tampoco fue competitivo con SVM∆ map. El segundo método, SVMacc4, normaliza las puntuaciones dadas por f para cada consulta. Por ejemplo, suponga para la consulta q que f produce puntuaciones en el rango de 0.2 a 0.7. Entonces, para el documento d, si f(d|q) = 0.6, la puntuación convertida sería f(d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Nuevamente, las Tablas 9, 10 y 11 muestran que SVMacc4 no fue competitivo con SVM∆ map 5.2.2 MAP vs ROCArea. SVM∆ roc tuvo un rendimiento mucho mejor que SVMacc en nuestros experimentos. Cuando se entrenó con las funciones de recuperación de Indri (ver Tabla 9), el rendimiento de SVM∆ roc fue ligeramente, aunque no significativamente, peor que el rendimiento de SVM∆ map. Sin embargo, la Tabla 10 muestra que el mapa SVM∆ superó significativamente al roc SVM∆ cuando se entrenó con las presentaciones de TREC. La tabla 11 muestra el rendimiento de los modelos cuando se entrenan con las presentaciones de TREC y se elimina la mejor presentación. El rendimiento de la mayoría de los modelos se degradó ligeramente, con SVM∆ map aún teniendo el mejor rendimiento. TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288 SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Tabla 11: Entrenado en TREC Subm. (sin Mejor) 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado un método SVM que optimiza directamente el MAP. Proporciona un enfoque basado en principios y evita heurísticas difíciles de controlar. Formulamos el problema de optimización y presentamos un algoritmo que encuentra la solución de manera demostrable en tiempo polinómico. Hemos demostrado empíricamente que nuestro método es generalmente superior o competitivo con los métodos convencionales de SVM. Nuestro nuevo método hace que sea conceptualmente tan fácil optimizar SVMs para MAP como anteriormente solo era posible para Precisión y Área bajo la curva ROC. El costo computacional para el entrenamiento es muy razonable en la práctica. Dado que otros métodos suelen requerir ajustar múltiples heurísticas, también esperamos entrenar menos modelos antes de encontrar uno que logre un buen rendimiento. El marco de aprendizaje utilizado por nuestro método es bastante general. Una extensión natural de este marco sería desarrollar métodos para optimizar otras medidas importantes de IR, como la Ganancia Acumulada Normalizada Descontada [2, 3, 4, 12] y la Reciprocidad Media de Rango. 7. AGRADECIMIENTOS Este trabajo fue financiado bajo el Premio NSF IIS-0412894, el Premio NSF CAREER 0237381 y un obsequio de Yahoo! Investigación. El tercer autor también fue parcialmente apoyado por una Beca de Investigación de Microsoft. 8. REFERENCIAS [1] B. T. Bartell, G. W. Cottrell y R. K. Belew. Combinación automática de múltiples sistemas de recuperación clasificados. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2005. [3] C. J. C. Burges, R. Ragno y Q. Lo. Aprendizaje para clasificar con funciones de costo no suaves. En Actas de la Conferencia Internacional sobre Avances en Sistemas de Información Neural (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang y H.-W. Hon. Adaptando el SVM de clasificación para la recuperación de documentos. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [5] B. Carterette y D. Petkova. Aprendiendo un ranking a partir de preferencias por pares. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew y A. Ksikes. Selección de conjunto de bibliotecas de modelos. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [7] J. Davis y M. Goadrich. La relación entre las curvas de precisión-recall y ROC. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2006. [8] D. Hawking. Resumen de la pista web TREC-9. En Actas de TREC-2000, 2000. [9] D. Hawking y N. Craswell. Resumen de la pista web TREC-2001. En Actas de TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel y K. Obermayer. Límites de rango de margen amplio para regresión ordinal. Avances en clasificadores de márgenes amplios, 2000. [11] A. Herschtal y B. Raskutti. Optimizando el área bajo la curva ROC utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [12] K. Jarvelin y J. Kekalainen. Métodos de evaluación para recuperar documentos altamente relevantes. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2000. [13] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), páginas 377-384, Nueva York, NY, EE. UU., 2005. ACM Press. [14] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), páginas 111-119, 2001. [15] Y. Lin, Y. Lee y G. Wahba. Máquinas de vectores de soporte para clasificación en situaciones no estándar. Aprendizaje automático, 46:191-202, 2002. [16] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [17] K. Morik, P. Brockhausen y T. Joachims. Combinando el aprendizaje estadístico con un enfoque basado en el conocimiento. En Actas de la Conferencia Internacional sobre Aprendizaje Automático, 1999. [18] S. Robertson. El principio de clasificación de <br>probabilidad</br> en la revista IR de documentación. Revista de Documentación, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims y Y. Altun. Métodos de margen amplio para variables de salida estructuradas e interdependientes. Revista de Investigación en Aprendizaje Automático (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik. Teoría del Aprendizaje Estadístico. Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz. \n\nWiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer y R. Wolniewicz. Optimizando el rendimiento del clasificador mediante la aproximación a la estadística de Wilcoxon-Mann-Witney. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2003. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "surrogate measure": {
            "translated_key": "medida sustituta",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT Machine learning is commonly used to improve ranked retrieval systems.",
                "Due to computational difficulties, few learning techniques have been developed to directly optimize for mean average precision (MAP), despite its widespread use in evaluating such systems.",
                "Existing approaches optimizing MAP either do not find a globally optimal solution, or are computationally expensive.",
                "In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of MAP.",
                "We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora (WT10g), comparing against SVMs optimized for accuracy and ROCArea.",
                "In most cases we show our method to produce statistically significant improvements in MAP scores.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval Models General Terms Algorithm, Theory, Experimentation 1.",
                "INTRODUCTION State of the art information retrieval systems commonly use machine learning techniques to learn ranking functions.",
                "However, most current approaches do not optimize for the evaluation measure most often used, namely Mean Average Precision (MAP).",
                "Instead, current algorithms tend to take one of two general approaches.",
                "The first approach is to learn a model that estimates the probability of a document being relevant given a query (e.g., [18, 14]).",
                "If solved effectively, the ranking with best MAP performance can easily be derived from the probabilities of relevance.",
                "However, achieving high MAP only requires finding a good ordering of the documents.",
                "As a result, finding good probabilities requires solving a more difficult problem than necessary, likely requiring more training data to achieve the same MAP performance.",
                "The second common approach is to learn a function that maximizes a <br>surrogate measure</br>.",
                "Performance measures optimized include accuracy [17, 15], ROCArea [1, 5, 10, 11, 13, 21] or modifications of ROCArea [4], and NDCG [2, 3].",
                "Learning a model to optimize for such measures might result in suboptimal MAP performance.",
                "In fact, although some previous systems have obtained good MAP performance, it is known that neither achieving optimal accuracy nor ROCArea can guarantee optimal MAP performance[7].",
                "In this paper, we present a general approach for learning ranking functions that maximize MAP performance.",
                "Specifically, we present an SVM algorithm that globally optimizes a hinge-loss relaxation of MAP.",
                "This approach simplifies the process of obtaining ranking functions with high MAP performance by avoiding additional intermediate steps and heuristics.",
                "The new algorithm also makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for accuracy and ROCArea.",
                "In contrast to recent work directly optimizing for MAP performance by Metzler & Croft [16] and Caruana et al. [6], our technique is computationally efficient while finding a globally optimal solution.",
                "Like [6, 16], our method learns a linear model, but is much more efficient in practice and, unlike [16], can handle many thousands of features.",
                "We now describe the algorithm in detail and provide proof of correctness.",
                "Following this, we provide an analysis of running time.",
                "We finish with empirical results from experiments on the TREC 9 and TREC 10 Web Track corpus.",
                "We have also developed a software package implementing our algorithm that is available for public use1 . 2.",
                "THE LEARNING PROBLEM Following the standard machine learning setup, our goal is to learn a function h : X → Y between an input space X (all possible queries) and output space Y (rankings over a corpus).",
                "In order to quantify the quality of a prediction, ˆy = h(x), we will consider a loss function ∆ : Y × Y → . ∆(y, ˆy) quantifies the penalty for making prediction ˆy if the correct output is y.",
                "The loss function allows us to incorporate specific performance measures, which we will exploit 1 http://svmrank.yisongyue.com for optimizing MAP.",
                "We restrict ourselves to the supervised learning scenario, where input/output pairs (x, y) are available for training and are assumed to come from some fixed distribution P(x, y).",
                "The goal is to find a function h such that the risk (i.e., expected loss), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), is minimized.",
                "Of course, P(x, y) is unknown.",
                "But given a finite set of training pairs, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, the performance of h on S can be measured by the empirical risk, R∆ S (h) = 1 n nX i=1 ∆(yi, h(xi)).",
                "In the case of learning a ranked retrieval function, X denotes a space of queries, and Y the space of (possibly weak) rankings over some corpus of documents C = {d1, . . . ,d|C|}.",
                "We can define average precision loss as ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), where rank(y) is a vector of the rank values of each document in C. For example, for a corpus of two documents, {d1, d2}, with d1 having higher rank than d2, rank(y ) = (1, 0).",
                "We assume true rankings have two rank values, where relevant documents have rank value 1 and non-relevant documents rank value 0.",
                "We further assume that all predicted rankings are complete rankings (no ties).",
                "Let p = rank(y) and ˆp = rank(ˆy).",
                "The average precision score is defined as MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, where rel = |{i : pi = 1}| is the number of relevant documents, and Prec@j is the percentage of relevant documents in the top j documents in predicted ranking ˆy.",
                "MAP is the mean of the average precision scores of a group of queries. 2.1 MAP vs ROCArea Most learning algorithms optimize for accuracy or ROCArea.",
                "While optimizing for these measures might achieve good MAP performance, we use two simple examples to show it can also be suboptimal in terms of MAP.",
                "ROCArea assigns equal penalty to each misordering of a relevant/non-relevant pair.",
                "In contrast, MAP assigns greater penalties to misorderings higher up in the predicted ranking.",
                "Using our notation, ROCArea can be defined as ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], where p is the true (weak) ranking, ˆp is the predicted ranking, and 1[b] is the indicator function conditioned on b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Table 1: Toy Example and Models Suppose we have a hypothesis space with only two hypothesis functions, h1 and h2, as shown in Table 1.",
                "These two hypotheses predict a ranking for query x over a corpus of eight documents.",
                "Hypothesis MAP ROCArea h1(x) 0.59 0.47 h2(x) 0.51 0.53 Table 2: Performance of Toy Models Table 2 shows the MAP and ROCArea scores of h1 and h2.",
                "Here, a learning method which optimizes for ROCArea would choose h2 since that results in a higher ROCArea score, but this yields a suboptimal MAP score. 2.2 MAP vs Accuracy Using a very similar example, we now demonstrate how optimizing for accuracy might result in suboptimal MAP.",
                "Models which optimize for accuracy are not directly concerned with the ranking.",
                "Instead, they learn a threshold such that documents scoring higher than the threshold can be classified as relevant and documents scoring lower as nonrelevant.",
                "Doc ID 1 2 3 4 5 6 7 8 9 10 11 p 1 0 0 0 0 1 1 1 1 0 0 rank(h1(x)) 11 10 9 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 9 10 11 Table 3: Toy Example and Models We consider again a hypothesis space with two hypotheses.",
                "Table 3 shows the predictions of the two hypotheses on a single query x. Hypothesis MAP Best Acc. h1(q) 0.70 0.64 h2(q) 0.64 0.73 Table 4: Performance of Toy Models Table 4 shows the MAP and best accuracy scores of h1(q) and h2(q).",
                "The best accuracy refers to the highest achievable accuracy on that ranking when considering all possible thresholds.",
                "For instance, with h1(q), a threshold between documents 1 and 2 gives 4 errors (documents 6-9 incorrectly classified as non-relevant), yielding an accuracy of 0.64.",
                "Similarly, with h2(q), a threshold between documents 5 and 6 gives 3 errors (documents 10-11 incorrectly classified as relevant, and document 1 as non-relevant), yielding an accuracy of 0.73.",
                "A learning method which optimizes for accuracy would choose h2 since that results in a higher accuracy score, but this yields a suboptimal MAP score. 3.",
                "OPTIMIZING AVERAGE PRECISION We build upon the approach used by [13] for optimizing ROCArea.",
                "Unlike ROCArea, however, MAP does not decompose linearly in the examples and requires a substantially extended algorithm, which we describe in this section.",
                "Recall that the true ranking is a weak ranking with two rank values (relevant and non-relevant).",
                "Let Cx and C¯x denote the set of relevant and non-relevant documents of C for query x, respectively.",
                "We focus on functions which are parametrized by a weight vector w, and thus wish to find w to minimize the empirical risk, R∆ S (w) ≡ R∆ S (h(·; w)).",
                "Our approach is to learn a discriminant function F : X × Y → over input-output pairs.",
                "Given query x, we can derive a prediction by finding the ranking y that maximizes the discriminant function: h(x; w) = argmax y∈Y F(x, y; w). (1) We assume F to be linear in some combined feature representation of inputs and outputs Ψ(x, y) ∈ RN , i.e., F(x, y; w) = wT Ψ(x, y). (2) The combined feature function we use is Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))] , where φ : X × C → N is a feature mapping function from a query/document pair to a point in N dimensional space2 .",
                "We represent rankings as a matrix of pairwise orderings, Y ⊂ {−1, 0, +1}|C|×|C| .",
                "For any y ∈ Y, yij = +1 if di is ranked ahead of dj, and yij = −1 if dj is ranked ahead of di, and yij = 0 if di and dj have equal rank.",
                "We consider only matrices which correspond to valid rankings (i.e, obeying antisymmetry and transitivity).",
                "Intuitively, Ψ is a summation over the vector differences of all relevant/non-relevant document pairings.",
                "Since we assume predicted rankings to be complete rankings, yij is either +1 or −1 (never 0).",
                "Given a learned weight vector w, predicting a ranking (i.e. solving equation (1)) given query x reduces to picking each yij to maximize wT Ψ(x, y).",
                "As is also discussed in [13], this is attained by sorting the documents by wT φ(x, d) in descending order.",
                "We will discuss later the choices of φ we used for our experiments. 3.1 Structural SVMs The above formulation is very similar to learning a straightforward linear model while training on the pairwise difference of relevant/non-relevant document pairings.",
                "Many SVM-based approaches optimize over these pairwise differences (e.g., [5, 10, 13, 4]), although these methods do not optimize for MAP during training.",
                "Previously, it was not clear how to incorporate non-linear multivariate loss functions such as MAP loss directly into global optimization problems such as SVM training.",
                "We now present a method based on structural SVMs [19] to address this problem.",
                "We use the structural SVM formulation, presented in Optimization Problem 1, to learn a w ∈ RN .",
                "Optimization Problem 1. (Structural SVM) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) The objective function to be minimized (3) is a tradeoff between model complexity, w 2 , and a hinge loss relaxation of MAP loss, P ξi.",
                "As is usual in SVM training, C is a 2 For example, one dimension might be the number of times the query words appear in the document.",
                "Algorithm 1 Cutting plane algorithm for solving OP 1 within tolerance . 1: Input: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ for all i = 1, . . . , n 3: repeat 4: for i = 1, . . . , n do 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: compute ˆy = argmaxy∈Y H(y; w) 7: compute ξi = max{0, maxy∈Wi H(y; w)} 8: if H(ˆy; w) > ξi + then 9: Wi ← Wi ∪ {ˆy} 10: w ← optimize (3) over W = S i Wi 11: end if 12: end for 13: until no Wi has changed during iteration parameter that controls this tradeoff and can be tuned to achieve good performance in different training tasks.",
                "For each (xi, yi) in the training set, a set of constraints of the form in equation (4) is added to the optimization problem.",
                "Note that wT Ψ(x, y) is exactly our discriminant function F(x, y; w) (see equation (2)).",
                "During prediction, our model chooses the ranking which maximizes the discriminant (1).",
                "If the discriminant value for an incorrect ranking y is greater than for the true ranking yi (e.g., F(xi, y; w) > F(xi, yi; w)), then corresponding slack variable, ξi, must be at least ∆(yi, y) for that constraint to be satisfied.",
                "Therefore, the sum of slacks, P ξi, upper bounds the MAP loss.",
                "This is stated formally in Proposition 1.",
                "Proposition 1.",
                "Let ξ∗ (w) be the optimal solution of the slack variables for OP 1 for a given weight vector w. Then 1 n Pn i=1 ξi is an upper bound on the empirical risk R∆ S (w). (see [19] for proof) Proposition 1 shows that OP 1 learns a ranking function that optimizes an upper bound on MAP error on the training set.",
                "Unfortunately there is a problem: a constraint is required for every possible wrong output y, and the number of possible wrong outputs is exponential in the size of C. Fortunately, we may employ Algorithm 1 to solve OP 1.",
                "Algorithm 1 is a cutting plane algorithm, iteratively introducing constraints until we have solved the original problem within a desired tolerance [19].",
                "The algorithm starts with no constraints, and iteratively finds for each example (xi, yi) the output ˆy associated with the most violated constraint.",
                "If the corresponding constraint is violated by more than we introduce ˆy into the working set Wi of active constraints for example i, and re-solve (3) using the updated W. It can be shown that Algorithm 1s outer loop is guaranteed to halt within a polynomial number of iterations for any desired precision .",
                "Theorem 1.",
                "Let ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y) , ¯∆ = maxi maxy ∆(yi, y), and for any > 0, Algorithm 1 terminates after adding at most max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff constraints to the working set W. (see [19] for proof) However, within the inner loop of this algorithm we have to compute argmaxy∈Y H(y; w), where H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), or equivalently, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), since wT Ψ(xi, yi) is constant with respect to y.",
                "Though closely related to the classification procedure, this has the substantial complication that we must contend with the additional ∆(yi, y) term.",
                "Without the ability to efficiently find the most violated constraint (i.e., solve argmaxy∈Y H(y, w)), the constraint generation procedure is not tractable. 3.2 Finding the Most Violated Constraint Using OP 1 and optimizing to ROCArea loss (∆roc), the problem of finding the most violated constraint, or solving argmaxy∈Y H(y, w) (henceforth argmax H), is addressed in [13].",
                "Solving argmax H for ∆map is more difficult.",
                "This is primarily because ROCArea decomposes nicely into a sum of scores computed independently on each relative ordering of a relevant/non-relevant document pair.",
                "MAP, on the other hand, does not decompose in the same way as ROCArea.",
                "The main algorithmic contribution of this paper is an efficient method for solving argmax H for ∆map.",
                "One useful property of ∆map is that it is invariant to swapping two documents with equal relevance.",
                "For example, if documents da and db are both relevant, then swapping the positions of da and db in any ranking does not affect ∆map.",
                "By extension, ∆map is invariant to any arbitrary permutation of the relevant documents amongst themselves and of the non-relevant documents amongst themselves.",
                "However, this reshuﬄing will affect the discriminant score, wT Ψ(x, y).",
                "This leads us to Observation 1.",
                "Observation 1.",
                "Consider rankings which are constrained by fixing the relevance at each position in the ranking (e.g., the 3rd document in the ranking must be relevant).",
                "Every ranking which satisfies the same set of constraints will have the same ∆map.",
                "If the relevant documents are sorted by wT φ(x, d) in descending order, and the non-relevant documents are likewise sorted by wT φ(x, d), then the interleaving of the two sorted lists which satisfies the constraints will maximize H for that constrained set of rankings.",
                "Observation 1 implies that in the ranking which maximizes H, the relevant documents will be sorted by wT φ(x, d), and the non-relevant documents will also be sorted likewise.",
                "By first sorting the relevant and non-relevant documents, the problem is simplified to finding the optimal interleaving of two sorted lists.",
                "For the rest of our discussion, we assume that the relevant documents and non-relevant documents are both sorted by descending wT φ(x, d).",
                "For convenience, we also refer to relevant documents as {dx 1 , . . . dx |Cx|} = Cx , and non-relevant documents as {d¯x 1 , . . . d¯x |C¯x|} = C¯x .",
                "We define δj(i1, i2), with i1 < i2, as the change in H from when the highest ranked relevant document ranked after d¯x j is dx i1 to when it is dx i2 .",
                "For i2 = i1 + 1, we have δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5) where si = wT φ(x, di).",
                "The first term in (5) is the change in ∆map when the ith relevant document has j non-relevant documents ranked before it, as opposed to j −1.",
                "The second term is the change in the discriminant score, wT Ψ(x, y), when yij changes from +1 to −1. . . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . .",
                "Figure 1: Example for δj(i, i + 1) Figure 1 gives a conceptual example for δj(i, i + 1).",
                "The bottom ranking differs from the top only where d¯x j slides up one rank.",
                "The difference in the value of H for these two rankings is exactly δj(i, i + 1).",
                "For any i1 < i2, we can then define δj(i1, i2) as δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) or equivalently, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) .",
                "Let o1, . . . , o|C¯x| encode the positions of the non-relevant documents, where dx oj is the highest ranked relevant document ranked after the jth non-relevant document.",
                "Due to Observation 1, this encoding uniquely identifies a complete ranking.",
                "We can recover the ranking as yij = 8 >>>< >>>: 0 if i = j sign(si − sj) if di, dj equal relevance sign(oj − i − 0.5) if di = dx i , dj = d¯x j sign(j − oi + 0.5) if di = d¯x i , dj = dx j . (7) We can now reformulate H into a new objective function, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), where ¯y is the true (weak) ranking.",
                "Conceptually H starts with a perfect ranking ¯y, and adds the change in H when each successive non-relevant document slides up the ranking.",
                "We can then reformulate the argmax H problem as argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) s.t. o1 ≤ . . . ≤ o|C¯x|. (9) Algorithm 2 describes the algorithm used to solve equation (8).",
                "Conceptually, Algorithm 2 starts with a perfect ranking.",
                "Then for each successive non-relevant document, the algorithm modifies the solution by sliding that document up the ranking to locally maximize H while keeping the positions of the other non-relevant documents constant. 3.2.1 Proof of Correctness Algorithm 2 is greedy in the sense that it finds the best position of each non-relevant document independently from the other non-relevant documents.",
                "In other words, the algorithm maximizes H for each non-relevant document, d¯x j , Algorithm 2 Finding the Most Violated Constraint (argmax H) for Algorithm 1 with ∆map 1: Input: w, Cx , C¯x 2: sort Cx and C¯x in descending order of wT φ(x, d) 3: sx i ← wT φ(x, dx i ), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i ), i = 1, . . . , |C¯x | 5: for j = 1, . . . , |C¯x | do 6: optj ← argmaxk δj(k, |Cx | + 1) 7: end for 8: encode ˆy according to (7) 9: return ˆy without considering the positions of the other non-relevant documents, and thus ignores the constraints of (9).",
                "In order for the solution to be feasible, the jth non-relevant document must be ranked after the first j − 1 non-relevant documents, thus satisfying opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. (10) If the solution is feasible, the it clearly solves (8).",
                "Therefore, it suffices to prove that Algorithm 2 satisfies (10).",
                "We first prove that δj(·, ·) is monotonically decreasing in j. Lemma 1.",
                "For any 1 ≤ i1 < i2 ≤ |Cx | + 1 and 1 ≤ j < |C¯x |, it must be the case that δj+1(i1, i2) ≤ δj(i1, i2).",
                "Proof.",
                "Recall from (6) that both δj(i1, i2) and δj+1(i1, i2) are summations of i2 − i1 terms.",
                "We will show that each term in the summation of δj+1(i1, i2) is no greater than the corresponding term in δj(i1, i2), or δj+1(k, k + 1) ≤ δj(k, k + 1) for k = i1, . . . , i2 − 1.",
                "Each term in δj(k, k +1) and δj+1(k, k +1) can be further decomposed into two parts (see (5)).",
                "We will show that each part of δj+1(k, k + 1) is no greater than the corresponding part in δj(k, k + 1).",
                "In other words, we will show that both j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) and −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) are true for the aforementioned values of j and k. It is easy to see that (11) is true by observing that for any two positive integers 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1 , and choosing a = j and b = j + k. The second inequality (12) holds because Algorithm 2 first sorts d¯x in descending order of s¯x , implying s¯x j+1 ≤ s¯x j .",
                "Thus we see that each term in δj+1 is no greater than the corresponding term in δj, which completes the proof.",
                "The result of Lemma 1 leads directly to our main correctness result: Theorem 2.",
                "In Algorithm 2, the computed values of optj satisfy (10), implying that the solution returned by Algorithm 2 is feasible and thus optimal.",
                "Proof.",
                "We will prove that optj ≤ optj+1 holds for any 1 ≤ j < |C¯x |, thus implying (10).",
                "Since Algorithm 2 computes optj as optj = argmax k δj(k, |Cx | + 1), (13) then by definition of δj (6), for any 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0.",
                "Using Lemma 1, we know that δj+1(i, optj) ≤ δj(i, optj) < 0, which implies that for any 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0.",
                "Suppose for contradiction that optj+1 < optj.",
                "Then δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), which contradicts (13).",
                "Therefore, it must be the case that optj ≤ optj+1, which completes the proof. 3.2.2 Running Time The running time of Algorithm 2 can be split into two parts.",
                "The first part is the sort by wT φ(x, d), which requires O(n log n) time, where n = |Cx | + |C¯x |.",
                "The second part computes each optj, which requires O(|Cx | · |C¯x |) time.",
                "Though in the worst case this is O(n2 ), the number of relevant documents, |Cx |, is often very small (e.g., constant with respect to n), in which case the running time for the second part is simply O(n).",
                "For most real-world datasets, Algorithm 2 is dominated by the sort and has complexity O(n log n).",
                "Algorithm 1 is guaranteed to halt in a polynomial number of iterations [19], and each iteration runs Algorithm 2.",
                "Virtually all well-performing models were trained in a reasonable amount of time (usually less than one hour).",
                "Once training is complete, making predictions on query x using the resulting hypothesis h(x|w) requires only sorting by wT φ(x, d).",
                "We developed our software using a Python interface3 to SVMstruct , since the Python language greatly simplified the coding process.",
                "To improve performance, it is advisable to use the standard C implementation4 of SVMstruct . 4.",
                "EXPERIMENT SETUP The main goal of our experiments is to evaluate whether directly optimizing MAP leads to improved MAP performance compared to conventional SVM methods that optimize a substitute loss such as accuracy or ROCArea.",
                "We empirically evaluate our method using two sets of TREC Web Track queries, one each from TREC 9 and TREC 10 (topics 451-500 and 501-550), both of which used the WT10g corpus.",
                "For each query, TREC provides the relevance judgments of the documents.",
                "We generated our features using the scores of existing retrieval functions on these queries.",
                "While our method is agnostic to the meaning of the features, we chose to use existing retrieval functions as a simple yet effective way of acquiring useful features.",
                "As such, our 3 http://www.cs.cornell.edu/~tomf/svmpython/ 4 http://svmlight.joachims.org/svm_struct.html Dataset Base Funcs Features TREC 9 Indri 15 750 TREC 10 Indri 15 750 TREC 9 Submissions 53 2650 TREC 10 Submissions 18 900 Table 5: Dataset Statistics experiments essentially test our methods ability to re-rank the highly ranked documents (e.g., re-combine the scores of the retrieval functions) to improve MAP.",
                "We compare our method against the best retrieval functions trained on (henceforth base functions), as well as against previously proposed SVM methods.",
                "Comparing with the best base functions tests our methods ability to learn a useful combination.",
                "Comparing with previous SVM methods allows us to test whether optimizing directly for MAP (as opposed to accuracy or ROCArea) achieves a higher MAP score in practice.",
                "The rest of this section describes the base functions and the feature generation method in detail. 4.1 Choosing Retrieval Functions We chose two sets of base functions for our experiments.",
                "For the first set, we generated three indices over the WT10g corpus using Indri5 .",
                "The first index was generated using default settings, the second used Porter-stemming, and the last used Porter-stemming and Indris default stopwords.",
                "For both TREC 9 and TREC 10, we used the description portion of each query and scored the documents using five of Indris built-in retrieval methods, which are Cosine Similarity, TFIDF, Okapi, Language Model with Dirichlet Prior, and Language Model with Jelinek-Mercer Prior.",
                "All parameters were kept as their defaults.",
                "We computed the scores of these five retrieval methods over the three indices, giving 15 base functions in total.",
                "For each query, we considered the scores of documents found in the union of the top 1000 documents of each base function.",
                "For our second set of base functions, we used scores from the TREC 9 [8] and TREC 10 [9] Web Track submissions.",
                "We used only the non-manual, non-short submissions from both years.",
                "For TREC 9 and TREC 10, there were 53 and 18 such submissions, respectively.",
                "A typical submission contained scores of its top 1000 documents. b ca wT φ(x,d) f(d|x) Figure 2: Example Feature Binning 4.2 Generating Features In order to generate input examples for our method, a concrete instantiation of φ must be provided.",
                "For each doc5 http://www.lemurproject.org TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236Best Func. 0.204 39/11 ** 0.181 37/13 ** 2nd Best 0.199 38/12 ** 0.174 43/7 ** 3rd Best 0.188 34/16 ** 0.174 38/12 ** Table 6: Comparison with Indri Functions ument d scored by a set of retrieval functions F on query x, we generate the features as a vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf , where f(d|x) denotes the score that retrieval function f assigns to document d for query x, and each Kf is a set of real values.",
                "From a high level, we are expressing the score of each retrieval function using |Kf | + 1 bins.",
                "Since we are using linear kernels, one can think of the learning problem as finding a good piecewise-constant combination of the scores of the retrieval functions.",
                "Figure 2 shows an example of our feature mapping method.",
                "In this example we have a single feature F = {f}.",
                "Here, Kf = {a, b, c}, and the weight vector is w = wa, wb, wc .",
                "For any document d and query x, we have wT φ(x, d) = 8 >>< >>: 0 if f(d|x) < a wa if a ≤ f(d|x) < b wa + wb if b ≤ f(d|x) < c wa + wb + wc if c ≤ f(d|x) .",
                "This is expressed qualitatively in Figure 2, where wa and wb are positive, and wc is negative.",
                "We ran our main experiments using four choices of F: the set of aforementioned Indri retrieval functions for TREC 9 and TREC 10, and the Web Track submissions for TREC 9 and TREC 10.",
                "For each F and each function f ∈ F, we chose 50 values for Kf which are reasonably spaced and capture the sensitive region of f. Using the four choices of F, we generated four datasets for our main experiments.",
                "Table 5 contains statistics of the generated datasets.",
                "There are many ways to generate features, and we are not advocating our method over others.",
                "This was simply an efficient means to normalize the outputs of different functions and allow for a more expressive model. 5.",
                "EXPERIMENTS For each dataset in Table 5, we performed 50 trials.",
                "For each trial, we train on 10 randomly selected queries, and select another 5 queries at random for a validation set.",
                "Models were trained using a wide range of C values.",
                "The model which performed best on the validation set was selected and tested on the remaining 35 queries.",
                "All queries were selected to be in the training, validation and test sets the same number of times.",
                "Using this setup, we performed the same experiments while using our method (SVM∆ map), an SVM optimizing for ROCArea (SVM∆ roc) [13], and a conventional classification SVM (SVMacc) [20].",
                "All SVM methods used a linear kernel.",
                "We reported the average performance of all models over the 50 trials. 5.1 Comparison with Base Functions In analyzing our results, the first question to answer is, can SVM∆ map learn a model which outperforms the best base TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287Best Func. 0.280 28/22 0.283 29/21 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 36/14 ** Table 7: Comparison with TREC Submissions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288Best Func. 0.280 27/23 0.283 31/19 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 35/15 ** Table 8: Comparison with TREC Subm. (w/o best) functions?",
                "Table 6 presents the comparison of SVM∆ map with the best Indri base functions.",
                "Each column group contains the macro-averaged MAP performance of SVM∆ map or a base function.",
                "The W/L columns show the number of queries where SVM∆ map achieved a higher MAP score.",
                "Significance tests were performed using the two-tailed Wilcoxon signed rank test.",
                "Two stars indicate a significance level of 0.95.",
                "All tables displaying our experimental results are structured identically.",
                "Here, we find that SVM∆ map significantly outperforms the best base functions.",
                "Table 7 shows the comparison when trained on TREC submissions.",
                "While achieving a higher MAP score than the best base functions, the performance difference between SVM∆ map the base functions is not significant.",
                "Given that many of these submissions use scoring functions which are carefully crafted to achieve high MAP, it is possible that the best performing submissions use techniques which subsume the techniques of the other submissions.",
                "As a result, SVM∆ map would not be able to learn a hypothesis which can significantly out-perform the best submission.",
                "Hence, we ran the same experiments using a modified dataset where the features computed using the best submission were removed.",
                "Table 8 shows the results (note that we are still comparing against the best submission though we are not using it for training).",
                "Notice that while the performance of SVM∆ map degraded slightly, the performance was still comparable with that of the best submission. 5.2 Comparison w/ Previous SVM Methods The next question to answer is, does SVM∆ map produce higher MAP scores than previous SVM methods?",
                "Tables 9 and 10 present the results of SVM∆ map, SVM∆ roc, and SVMacc when trained on the Indri retrieval functions and TREC submissions, respectively.",
                "Table 11 contains the corresponding results when trained on the TREC submissions without the best submission.",
                "To start with, our results indicate that SVMacc was not competitive with SVM∆ map and SVM∆ roc, and at times underperformed dramatically.",
                "As such, we tried several approaches to improve the performance of SVMacc. 5.2.1 Alternate SVMacc Methods One issue which may cause SVMacc to underperform is the severe imbalance between relevant and non-relevant docTREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236SVM∆ roc 0.237 29/21 0.234 24/26 SVMacc 0.147 47/3 ** 0.155 47/3 ** SVMacc2 0.219 39/11 ** 0.207 43/7 ** SVMacc3 0.113 49/1 ** 0.153 45/5 ** SVMacc4 0.155 48/2 ** 0.155 48/2 ** Table 9: Trained on Indri Functions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287SVM∆ roc 0.282 29/21 0.278 35/15 ** SVMacc 0.213 49/1 ** 0.222 49/1 ** SVMacc2 0.270 34/16 ** 0.261 42/8 ** SVMacc3 0.133 50/0 ** 0.182 46/4 ** SVMacc4 0.233 47/3 ** 0.238 46/4 ** Table 10: Trained on TREC Submissions uments.",
                "The vast majority of the documents are not relevant.",
                "SVMacc2 addresses this problem by assigning more penalty to false negative errors.",
                "For each dataset, the ratio of the false negative to false positive penalties is equal to the ratio of the number non-relevant and relevant documents in that dataset.",
                "Tables 9, 10 and 11 indicate that SVMacc2 still performs significantly worse than SVM∆ map.",
                "Another possible issue is that SVMacc attempts to find just one discriminating threshold b that is query-invariant.",
                "It may be that different queries require different values of b.",
                "Having the learning method trying to find a good b value (when one does not exist) may be detrimental.",
                "We took two approaches to address this issue.",
                "The first method, SVMacc3, converts the retrieval function scores into percentiles.",
                "For example, for document d, query q and retrieval function f, if the score f(d|q) is in the top 90% of the scores f(·|q) for query q, then the converted score is f (d|q) = 0.9.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Tables 9, 10 and 11 show that the performance of SVMacc3 was also not competitive with SVM∆ map.",
                "The second method, SVMacc4, normalizes the scores given by f for each query.",
                "For example, assume for query q that f outputs scores in the range 0.2 to 0.7.",
                "Then for document d, if f(d|q) = 0.6, the converted score would be f (d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Again, Tables 9, 10 and 11 show that SVMacc4 was not competitive with SVM∆ map 5.2.2 MAP vs ROCArea SVM∆ roc performed much better than SVMacc in our experiments.",
                "When trained on Indri retrieval functions (see Table 9), the performance of SVM∆ roc was slight, though not significantly, worse than the performances of SVM∆ map.",
                "However, Table 10 shows that SVM∆ map did significantly outperform SVM∆ roc when trained on the TREC submissions.",
                "Table 11 shows the performance of the models when trained on the TREC submissions with the best submission removed.",
                "The performance of most models degraded by a small amount, with SVM∆ map still having the best performance.",
                "TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Table 11: Trained on TREC Subm. (w/o Best) 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented an SVM method that directly optimizes MAP.",
                "It provides a principled approach and avoids difficult to control heuristics.",
                "We formulated the optimization problem and presented an algorithm which provably finds the solution in polynomial time.",
                "We have shown empirically that our method is generally superior to or competitive with conventional SVMs methods.",
                "Our new method makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for Accuracy and ROCArea.",
                "The computational cost for training is very reasonable in practice.",
                "Since other methods typically require tuning multiple heuristics, we also expect to train fewer models before finding one which achieves good performance.",
                "The learning framework used by our method is fairly general.",
                "A natural extension of this framework would be to develop methods to optimize for other important IR measures, such as Normalized Discounted Cumulative Gain [2, 3, 4, 12] and Mean Reciprocal Rank. 7.",
                "ACKNOWLEDGMENTS This work was funded under NSF Award IIS-0412894, NSF CAREER Award 0237381, and a gift from Yahoo!",
                "Research.",
                "The third author was also partly supported by a Microsoft Research Fellowship. 8.",
                "REFERENCES [1] B. T. Bartell, G. W. Cottrell, and R. K. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2005. [3] C. J. C. Burges, R. Ragno, and Q.",
                "Le.",
                "Learning to rank with non-smooth cost functions.",
                "In Proceedings of the International Conference on Advances in Neural Information Processing Systems (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y.",
                "Liu, H. Li, Y. Huang, and H.-W. Hon.",
                "Adapting ranking SVM to document retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [5] B. Carterette and D. Petkova.",
                "Learning a ranking from pairwise preferences.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew, and A. Ksikes.",
                "Ensemble selection from libraries of models.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [7] J. Davis and M. Goadrich.",
                "The relationship between precision-recall and ROC curves.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2006. [8] D. Hawking.",
                "Overview of the TREC-9 web track.",
                "In Proceedings of TREC-2000, 2000. [9] D. Hawking and N. Craswell.",
                "Overview of the TREC-2001 web track.",
                "In Proceedings of TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel, and K. Obermayer.",
                "Large margin rank boundaries for ordinal regression.",
                "Advances in large margin classifiers, 2000. [11] A. Herschtal and B. Raskutti.",
                "Optimising area under the ROC curve using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [12] K. Jarvelin and J. Kekalainen.",
                "Ir evaluation methods for retrieving highly relevant documents.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2000. [13] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proceedings of the International Conference on Machine Learning (ICML), pages 377-384, New York, NY, USA, 2005.",
                "ACM Press. [14] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 111-119, 2001. [15] Y. Lin, Y. Lee, and G. Wahba.",
                "Support vector machines for classification in nonstandard situations.",
                "Machine Learning, 46:191-202, 2002. [16] D. Metzler and W. B. Croft.",
                "A markov random field model for term dependencies.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 472-479, 2005. [17] K. Morik, P. Brockhausen, and T. Joachims.",
                "Combining statistical learning with a knowledge-based approach.",
                "In Proceedings of the International Conference on Machine Learning, 1999. [18] S. Robertson.",
                "The probability ranking principle in ir. journal of documentation.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.",
                "Large margin methods for structured and interdependent output variables.",
                "Journal of Machine Learning Research (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik.",
                "Statistical Learning Theory.",
                "Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz.",
                "Optimizing classifier performance via approximation to the Wilcoxon-Mann-Witney statistic.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2003."
            ],
            "original_annotated_samples": [
                "The second common approach is to learn a function that maximizes a <br>surrogate measure</br>."
            ],
            "translated_annotated_samples": [
                "El segundo enfoque común es aprender una función que maximice una <br>medida sustituta</br>."
            ],
            "translated_text": "Un método de Vectores de Soporte para optimizar la Precisión Promedio Yisong Yue Universidad de Cornell Ithaca, NY, EE. UU. yyue@cs.cornell.edu Thomas Finley Universidad de Cornell Ithaca, NY, EE. UU. tomf@cs.cornell.edu Filip Radlinski Universidad de Cornell Ithaca, NY, EE. UU. filip@cs.cornell.edu Thorsten Joachims Universidad de Cornell Ithaca, NY, EE. UU. tj@cs.cornell.edu RESUMEN El aprendizaje automático se utiliza comúnmente para mejorar los sistemas de recuperación clasificados. Debido a dificultades computacionales, se han desarrollado pocas técnicas de aprendizaje para optimizar directamente la precisión media promedio (MAP), a pesar de su uso generalizado en la evaluación de dichos sistemas. Los enfoques existentes que optimizan el MAP no encuentran una solución óptima global o son computacionalmente costosos. Por el contrario, presentamos un algoritmo de aprendizaje SVM general que encuentra de manera eficiente una solución óptima global para una relajación directa de MAP. Evaluamos nuestro enfoque utilizando los corpus de la pista web TREC 9 y TREC 10 (WT10g), comparando con SVM optimizados para precisión y área bajo la curva ROC. En la mayoría de los casos mostramos nuestro método para producir mejoras estadísticamente significativas en las puntuaciones de MAP. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de Recuperación Términos Generales Algoritmo, Teoría, Experimentación 1. INTRODUCCIÓN Los sistemas de recuperación de información de última generación comúnmente utilizan técnicas de aprendizaje automático para aprender funciones de clasificación. Sin embargo, la mayoría de los enfoques actuales no están optimizados para la medida de evaluación más utilizada, es decir, la Precisión Promedio Media (MAP). En cambio, los algoritmos actuales tienden a seguir uno de dos enfoques generales. El primer enfoque es aprender un modelo que estime la probabilidad de que un documento sea relevante dado una consulta (por ejemplo, [18, 14]). Si se resuelve de manera efectiva, la clasificación con el mejor rendimiento de MAP puede derivarse fácilmente de las probabilidades de relevancia. Sin embargo, lograr un MAP alto solo requiere encontrar un buen ordenamiento de los documentos. Como resultado, encontrar buenas probabilidades requiere resolver un problema más difícil de lo necesario, probablemente necesitando más datos de entrenamiento para lograr el mismo rendimiento de MAP. El segundo enfoque común es aprender una función que maximice una <br>medida sustituta</br>. Las medidas de rendimiento optimizadas incluyen precisión [17, 15], área bajo la curva ROC [1, 5, 10, 11, 13, 21] o modificaciones del área bajo la curva ROC [4], y NDCG [2, 3]. Aprender un modelo para optimizar tales medidas podría resultar en un rendimiento de MAP subóptimo. De hecho, aunque algunos sistemas anteriores han obtenido un buen rendimiento de MAP, se sabe que ni lograr una precisión óptima ni un área bajo la curva ROC pueden garantizar un rendimiento de MAP óptimo[7]. En este artículo, presentamos un enfoque general para aprender funciones de clasificación que maximizan el rendimiento de MAP. Específicamente, presentamos un algoritmo SVM que optimiza globalmente una relajación de pérdida de bisagra de MAP. Este enfoque simplifica el proceso de obtener funciones de clasificación con un alto rendimiento de MAP al evitar pasos intermedios adicionales y heurísticas. El nuevo algoritmo también hace que sea conceptualmente tan fácil optimizar las SVM para MAP como anteriormente solo era posible para precisión y ROCArea. A diferencia del trabajo reciente que optimiza directamente el rendimiento de MAP realizado por Metzler & Croft [16] y Caruana et al. [6], nuestra técnica es eficiente computacionalmente al encontrar una solución óptima a nivel global. Al igual que [6, 16], nuestro método aprende un modelo lineal, pero es mucho más eficiente en la práctica y, a diferencia de [16], puede manejar miles de características. Ahora describimos el algoritmo en detalle y proporcionamos la prueba de corrección. A continuación, proporcionamos un análisis del tiempo de ejecución. Concluimos con los resultados empíricos de experimentos en el corpus de la pista web TREC 9 y TREC 10. También hemos desarrollado un paquete de software que implementa nuestro algoritmo y está disponible para uso público. EL PROBLEMA DEL APRENDIZAJE Siguiendo la configuración estándar del aprendizaje automático, nuestro objetivo es aprender una función h: X → Y entre un espacio de entrada X (todas las consultas posibles) y un espacio de salida Y (clasificaciones sobre un corpus). Para cuantificar la calidad de una predicción, ˆy = h(x), consideraremos una función de pérdida ∆ : Y × Y → . ∆(y, ˆy) cuantifica la penalización por hacer la predicción ˆy si la salida correcta es y. La función de pérdida nos permite incorporar medidas específicas de rendimiento, las cuales explotaremos en http://svmrank.yisongyue.com para optimizar el MAP. Nos restringimos al escenario de aprendizaje supervisado, donde pares de entrada/salida (x, y) están disponibles para el entrenamiento y se asume que provienen de alguna distribución fija P(x, y). El objetivo es encontrar una función h tal que el riesgo (es decir, la pérdida esperada), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), se minimice. Por supuesto, P(x, y) es desconocido. Pero dado un conjunto finito de pares de entrenamiento, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, el rendimiento de h en S puede medirse mediante el riesgo empírico, R∆ S (h) = 1 n ∑ i=1 n ∆(yi, h(xi)). En el caso de aprender una función de recuperación clasificada, X denota un espacio de consultas, y Y el espacio de clasificaciones (posiblemente débiles) sobre algún corpus de documentos C = {d1, . . . ,d|C|}. Podemos definir la pérdida de precisión promedio como ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), donde rank(y) es un vector de los valores de rango de cada documento en C. Por ejemplo, para un corpus de dos documentos, {d1, d2}, con d1 teniendo un rango más alto que d2, rank(y) = (1, 0). Suponemos que las clasificaciones verdaderas tienen dos valores de clasificación, donde los documentos relevantes tienen un valor de clasificación 1 y los documentos no relevantes tienen un valor de clasificación 0. Además, asumimos que todas las clasificaciones predichas son clasificaciones completas (sin empates). Sea p = rango(y) y ˆp = rango(ˆy). La puntuación de precisión promedio se define como MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, donde rel = |{i : pi = 1}| es el número de documentos relevantes, y Prec@j es el porcentaje de documentos relevantes en los primeros j documentos en la clasificación predicha ˆy. MAP es la media de las puntuaciones de precisión promedio de un grupo de consultas. La mayoría de los algoritmos de aprendizaje se optimizan para precisión o ROCArea. Si bien optimizar estas medidas podría lograr un buen rendimiento de MAP, usamos dos ejemplos simples para mostrar que también puede ser subóptimo en términos de MAP. ROCArea asigna una penalización igual a cada desordenamiento de un par relevante/no relevante. Por el contrario, MAP asigna mayores penalizaciones a los errores de ordenamiento más arriba en la clasificación predicha. Usando nuestra notación, el Área bajo la Curva ROC (ROCArea) se puede definir como ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], donde p es el ranking verdadero (débil), ˆp es el ranking predicho, y 1[b] es la función indicadora condicionada a b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Tabla 1: Ejemplo y Modelos Supongamos que tenemos un espacio de hipótesis con solo dos funciones de hipótesis, h1 y h2, como se muestra en la Tabla 1. Estas dos hipótesis predicen un ranking para la consulta x sobre un corpus de ocho documentos. Tabla 2: Rendimiento de los Modelos de Juguete La Tabla 2 muestra las puntuaciones de MAP y ROCArea de h1 y h2. Aquí, un método de aprendizaje que optimiza para el Área bajo la curva ROC elegiría h2 ya que esto resulta en un puntaje de Área bajo la curva ROC más alto, pero esto produce un puntaje de MAP subóptimo. 2.2 MAP vs Precisión Usando un ejemplo muy similar, ahora demostramos cómo optimizar para la precisión podría resultar en un puntaje de MAP subóptimo. Los modelos que se optimizan para la precisión no están directamente preocupados por la clasificación. En cambio, aprenden un umbral tal que los documentos que obtienen una puntuación superior al umbral pueden ser clasificados como relevantes y los documentos que obtienen una puntuación inferior como no relevantes. Consideramos nuevamente un espacio de hipótesis con dos hipótesis. La Tabla 3 muestra las predicciones de las dos hipótesis en una única consulta x. Hipótesis MAP Mejor Precisión h1(q) 0.70 0.64 h2(q) 0.64 0.73 Tabla 4: Rendimiento de los Modelos de Juguete La Tabla 4 muestra los puntajes de MAP y mejor precisión de h1(q) y h2(q). La mejor precisión se refiere a la precisión más alta alcanzable en esa clasificación al considerar todos los umbrales posibles. Por ejemplo, con h1(q), un umbral entre los documentos 1 y 2 da 4 errores (documentos 6-9 clasificados incorrectamente como no relevantes), lo que resulta en una precisión de 0.64. De manera similar, con h2(q), un umbral entre los documentos 5 y 6 da 3 errores (los documentos 10-11 clasificados incorrectamente como relevantes, y el documento 1 como no relevante), lo que resulta en una precisión de 0.73. Un método de aprendizaje que optimiza la precisión elegiría h2 ya que esto resulta en un puntaje de precisión más alto, pero esto produce un puntaje de MAP subóptimo. 3. OPTIMIZANDO LA PRECISIÓN PROMEDIO Nos basamos en el enfoque utilizado por [13] para optimizar el Área bajo la Curva ROC. A diferencia de ROCArea, sin embargo, MAP no se descompone linealmente en los ejemplos y requiere un algoritmo sustancialmente extendido, el cual describimos en esta sección. Recuerda que la clasificación verdadera es una clasificación débil con dos valores de clasificación (relevante y no relevante). Que Cx y C¯x denoten el conjunto de documentos relevantes y no relevantes de C para la consulta x, respectivamente. Nos enfocamos en funciones que están parametrizadas por un vector de peso w, y por lo tanto deseamos encontrar w para minimizar el riesgo empírico, R∆ S (w) ≡ R∆ S (h(·; w)). Nuestro enfoque es aprender una función discriminante F: X × Y → sobre pares de entrada-salida. Dada la consulta x, podemos derivar una predicción encontrando la clasificación y que maximiza la función discriminante: h(x; w) = argmax y∈Y F(x, y; w). (1) Suponemos que F es lineal en alguna representación de características combinadas de entradas y salidas Ψ(x, y) ∈ RN, es decir, F(x, y; w) = wT Ψ(x, y). (2) La función de características combinadas que utilizamos es Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))], donde φ: X × C → N es una función de mapeo de características de un par consulta/documento a un punto en un espacio dimensional N. Representamos las clasificaciones como una matriz de ordenamientos por pares, Y ⊂ {−1, 0, +1}|C|×|C| . Para cualquier y ∈ Y, yij = +1 si di está clasificado por delante de dj, y yij = −1 si dj está clasificado por delante de di, y yij = 0 si di y dj tienen el mismo rango. Consideramos solo matrices que corresponden a clasificaciones válidas (es decir, que cumplen con la antisimetría y la transitividad). De manera intuitiva, Ψ es una suma de las diferencias vectoriales de todos los pares de documentos relevantes/no relevantes. Dado que asumimos que las clasificaciones predichas son clasificaciones completas, yij es o bien +1 o −1 (nunca 0). Dado un vector de pesos aprendido w, predecir un ranking (es decir, resolver la ecuación (1)) dado una consulta x se reduce a elegir cada yij para maximizar wT Ψ(x, y). Como también se discute en [13], esto se logra ordenando los documentos por wT φ(x, d) en orden descendente. Discutiremos más adelante las elecciones de φ que utilizamos para nuestros experimentos. 3.1 SVM Estructurales La formulación anterior es muy similar a aprender un modelo lineal directo mientras se entrena en la diferencia de pares de documentos relevantes/no relevantes. Muchos enfoques basados en SVM optimizan sobre estas diferencias en pares (por ejemplo, [5, 10, 13, 4]), aunque estos métodos no optimizan para el MAP durante el entrenamiento. Anteriormente, no estaba claro cómo incorporar funciones de pérdida multivariadas no lineales como la pérdida MAP directamente en problemas de optimización global como el entrenamiento de SVM. Ahora presentamos un método basado en SVM estructurales [19] para abordar este problema. Utilizamos la formulación del SVM estructural, presentada en el Problema de Optimización 1, para aprender un w ∈ RN. Problema de optimización 1. (SVM estructural) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) La función objetivo a minimizar (3) es un compromiso entre la complejidad del modelo, w 2 , y una relajación de pérdida de MAP mediante la pérdida de bisagra, P ξi. Como es habitual en el entrenamiento de SVM, C es igual a 2. Por ejemplo, una dimensión podría ser el número de veces que las palabras de la consulta aparecen en el documento. Algoritmo 1 Algoritmo de plano de corte para resolver OP 1 dentro de la tolerancia. 1: Entrada: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ para todo i = 1, . . . , n 3: repetir 4: para i = 1, . . . , n hacer 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: calcular ˆy = argmaxy∈Y H(y; w) 7: calcular ξi = max{0, maxy∈Wi H(y; w)} 8: si H(ˆy; w) > ξi + entonces 9: Wi ← Wi ∪ {ˆy} 10: w ← optimizar (3) sobre W = S i Wi 11: fin si 12: fin para 13: hasta que ningún Wi haya cambiado durante la iteración parámetro que controla este equilibrio y puede ajustarse para lograr un buen rendimiento en diferentes tareas de entrenamiento. Para cada (xi, yi) en el conjunto de entrenamiento, se añade un conjunto de restricciones de la forma en la ecuación (4) al problema de optimización. Ten en cuenta que wT Ψ(x, y) es exactamente nuestra función discriminante F(x, y; w) (ver ecuación (2)). Durante la predicción, nuestro modelo elige el ranking que maximiza el discriminante (1). Si el valor del discriminante para una clasificación incorrecta y es mayor que para la clasificación verdadera yi (por ejemplo, F(xi, y; w) > F(xi, yi; w)), entonces la variable de holgura correspondiente, ξi, debe ser al menos ∆(yi, y) para que se cumpla esa restricción. Por lo tanto, la suma de los márgenes, P ξi, acota superiormente la pérdida MAP. Esto se establece formalmente en la Proposición 1. Proposición 1. Sea ξ∗ (w) la solución óptima de las variables de holgura para OP 1 para un vector de peso dado w. Entonces 1 n Pn i=1 ξi es una cota superior del riesgo empírico R∆ S (w). (ver [19] para la prueba) La Proposición 1 muestra que OP 1 aprende una función de clasificación que optimiza una cota superior del error de MAP en el conjunto de entrenamiento. Desafortunadamente hay un problema: se requiere una restricción para cada posible resultado incorrecto y, y el número de resultados incorrectos posibles es exponencial en el tamaño de C. Afortunadamente, podemos emplear el Algoritmo 1 para resolver OP 1. El algoritmo 1 es un algoritmo de plano de corte, introduciendo iterativamente restricciones hasta que hayamos resuelto el problema original dentro de una tolerancia deseada [19]. El algoritmo comienza sin restricciones y encuentra de forma iterativa, para cada ejemplo (xi, yi), la salida ˆy asociada con la restricción más violada. Si la restricción correspondiente es violada por más de lo que introducimos ˆy en el conjunto de trabajo Wi de restricciones activas, por ejemplo i, y volvemos a resolver (3) usando el W actualizado. Se puede demostrar que el bucle externo del Algoritmo 1 está garantizado a detenerse dentro de un número polinomial de iteraciones para cualquier precisión deseada. Teorema 1. Sea ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y), ¯∆ = maxi maxy ∆(yi, y), y para cualquier > 0, el Algoritmo 1 termina después de agregar a lo sumo max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff restricciones al conjunto de trabajo W. (ver [19] para la prueba) Sin embargo, dentro del bucle interno de este algoritmo tenemos que calcular argmaxy∈Y H(y; w), donde H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), o equivalentemente, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), ya que wT Ψ(xi, yi) es constante con respecto a y. Aunque está estrechamente relacionado con el procedimiento de clasificación, esto tiene la complicación sustancial de que debemos lidiar con el término adicional ∆(yi, y). Sin la capacidad de encontrar eficientemente la restricción más violada (es decir, resolver argmaxy∈Y H(y, w)), el procedimiento de generación de restricciones no es viable. 3.2 Encontrar la restricción más violada utilizando OP 1 y optimizando la pérdida de ROCArea (∆roc), el problema de encontrar la restricción más violada, o resolver argmaxy∈Y H(y, w) (en adelante argmax H), se aborda en [13]. Resolver argmax H para ∆map es más difícil. Esto se debe principalmente a que ROCArea se descompone de manera ordenada en una suma de puntuaciones calculadas de forma independiente en cada ordenamiento relativo de un par de documentos relevantes/no relevantes. MAP, por otro lado, no se descompone de la misma manera que ROCArea. La principal contribución algorítmica de este artículo es un método eficiente para resolver argmax H para ∆map. Una propiedad útil de ∆map es que es invariante al intercambiar dos documentos con igual relevancia. Por ejemplo, si los documentos da y db son ambos relevantes, entonces intercambiar las posiciones de da y db en cualquier clasificación no afecta a ∆map. Por extensión, ∆map es invariante a cualquier permutación arbitraria de los documentos relevantes entre sí y de los documentos no relevantes entre sí. Sin embargo, esta reorganización afectará la puntuación del discriminante, wT Ψ(x, y). Esto nos lleva a la Observación 1. Observación 1. Considera clasificaciones que estén limitadas por fijar la relevancia en cada posición de la clasificación (por ejemplo, el tercer documento en la clasificación debe ser relevante). Cada clasificación que cumpla con el mismo conjunto de restricciones tendrá el mismo ∆map. Si los documentos relevantes están ordenados por wT φ(x, d) en orden descendente, y los documentos no relevantes también están ordenados de la misma manera por wT φ(x, d), entonces la intercalación de las dos listas ordenadas que cumpla con las restricciones maximizará H para ese conjunto de clasificaciones restringidas. La Observación 1 implica que en la clasificación que maximiza H, los documentos relevantes se ordenarán por wT φ(x, d), y los documentos no relevantes también se ordenarán de la misma manera. Al ordenar primero los documentos relevantes y no relevantes, el problema se simplifica a encontrar la intercalación óptima de dos listas ordenadas. Para el resto de nuestra discusión, asumimos que los documentos relevantes y no relevantes están ordenados por wT φ(x, d) en orden descendente. Para mayor comodidad, también nos referimos a los documentos relevantes como {dx 1 , . . . dx |Cx|} = Cx, y a los documentos no relevantes como {d¯x 1 , . . . d¯x |C¯x|} = C¯x. Definimos δj(i1, i2), con i1 < i2, como el cambio en H desde cuando el documento relevante de mayor rango clasificado después de d¯x j es dx i1 hasta que es dx i2. Para i2 = i1 + 1, tenemos δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5), donde si = wT φ(x, di). El primer término en (5) es el cambio en ∆map cuando el documento relevante i tiene j documentos no relevantes clasificados antes de él, en lugar de j-1. El segundo término es el cambio en la puntuación del discriminante, wT Ψ(x, y), cuando yij cambia de +1 a −1. . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . . Figura 1: Ejemplo para δj(i, i + 1). La Figura 1 proporciona un ejemplo conceptual para δj(i, i + 1). La clasificación inferior difiere de la superior solo cuando d¯x j sube un rango. La diferencia en el valor de H para estas dos clasificaciones es exactamente δj(i, i + 1). Para cualquier i1 < i2, podemos definir δj(i1, i2) como δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) o equivalentemente, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) . Deja que o1, . . . , o|C¯x| codifiquen las posiciones de los documentos no relevantes, donde dx oj es el documento relevante de mayor rango clasificado después del j-ésimo documento no relevante. Debido a la Observación 1, esta codificación identifica de forma única un ranking completo. Podemos recuperar la clasificación como yij = 8 >>>< >>>: 0 si i = j sign(si − sj) si di, dj relevancia igual signo(oj − i − 0.5) si di = dx i , dj = d¯x j signo(j − oi + 0.5) si di = d¯x i , dj = dx j. (7) Ahora podemos reformular H en una nueva función objetivo, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), donde ¯y es la verdadera clasificación (débil). Conceptualmente, H comienza con una clasificación perfecta ¯y y agrega el cambio en H cuando cada documento no relevante sucesivo sube en la clasificación. Luego podemos reformular el problema argmax H como argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) sujeto a o1 ≤ . . . ≤ o|C¯x|. (9) El Algoritmo 2 describe el algoritmo utilizado para resolver la ecuación (8). Conceptualmente, el Algoritmo 2 comienza con un ranking perfecto. Entonces, para cada documento no relevante sucesivo, el algoritmo modifica la solución deslizando ese documento hacia arriba en la clasificación para maximizar localmente H, manteniendo las posiciones de los otros documentos no relevantes constantes. 3.2.1 Prueba de Corrección El Algoritmo 2 es codicioso en el sentido de que encuentra la mejor posición de cada documento no relevante de forma independiente de los otros documentos no relevantes. En otras palabras, el algoritmo maximiza H para cada documento no relevante, d¯x j, Algoritmo 2 Encontrar la Restricción Más Violada (argmax H) para el Algoritmo 1 con ∆map 1: Entrada: w, Cx, C¯x 2: ordenar Cx y C¯x en orden descendente de wT φ(x, d) 3: sx i ← wT φ(x, dx i), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i), i = 1, . . . , |C¯x | 5: para j = 1, . . . , |C¯x | hacer 6: optj ← argmaxk δj(k, |Cx| + 1) 7: fin para 8: codificar ˆy de acuerdo con (7) 9: devolver ˆy sin considerar las posiciones de los otros documentos no relevantes, y así ignora las restricciones de (9). Para que la solución sea factible, el documento no relevante j-ésimo debe ser clasificado después de los primeros j-1 documentos no relevantes, satisfaciendo así opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. Si la solución es factible, entonces claramente resuelve (8). Por lo tanto, basta con demostrar que el Algoritmo 2 cumple con (10). Primero demostramos que δj(·, ·) es monótonamente decreciente en j. Lema 1. Para cualquier 1 ≤ i1 < i2 ≤ |Cx | + 1 y 1 ≤ j < |C¯x |, debe ser el caso que δj+1(i1, i2) ≤ δj(i1, i2). Prueba. Recuerde que tanto δj(i1, i2) como δj+1(i1, i2) son sumas de términos i2 − i1. Mostraremos que cada término en la suma de δj+1(i1, i2) no es mayor que el término correspondiente en δj(i1, i2), o δj+1(k, k + 1) ≤ δj(k, k + 1) para k = i1, . . . , i2 − 1. Cada término en δj(k, k +1) y δj+1(k, k +1) puede ser descompuesto aún más en dos partes (ver (5)). Mostraremos que cada parte de δj+1(k, k + 1) no es mayor que la parte correspondiente en δj(k, k + 1). En otras palabras, demostraremos que tanto j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) como −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) son verdaderos para los valores mencionados de j y k. Es fácil ver que (11) es verdadero observando que para cualquier par de enteros positivos 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1, y eligiendo a = j y b = j + k. La segunda desigualdad (12) se cumple porque el Algoritmo 2 primero ordena d¯x en orden descendente de s¯x, lo que implica s¯x j+1 ≤ s¯x j. Así vemos que cada término en δj+1 no es mayor que el término correspondiente en δj, lo cual completa la prueba. El resultado del Lema 1 conduce directamente a nuestro resultado principal de corrección: Teorema 2. En el Algoritmo 2, los valores calculados de optj satisfacen (10), lo que implica que la solución devuelta por el Algoritmo 2 es factible y, por lo tanto, óptima. Prueba. Demostraremos que optj ≤ optj+1 se cumple para cualquier 1 ≤ j < |C¯x|, implicando así (10). Dado que el Algoritmo 2 calcula optj como optj = argmax k δj(k, |Cx | + 1), (13), entonces por definición de δj (6), para cualquier 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0. Usando el Lema 1, sabemos que δj+1(i, optj) ≤ δj(i, optj) < 0, lo que implica que para cualquier 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0. Supongamos por contradicción que optj+1 < optj. Entonces δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), lo cual contradice (13). Por lo tanto, debe ser el caso que optj ≤ optj+1, lo cual completa la prueba. 3.2.2 Tiempo de ejecución El tiempo de ejecución del Algoritmo 2 se puede dividir en dos partes. La primera parte es la clasificación por wT φ(x, d), lo cual requiere un tiempo de O(n log n), donde n = |Cx | + |C¯x |. La segunda parte calcula cada optj, lo cual requiere un tiempo de O(|Cx| · |C¯x|). Aunque en el peor de los casos esto es O(n2), el número de documentos relevantes, |Cx|, suele ser muy pequeño (por ejemplo, constante con respecto a n), en cuyo caso el tiempo de ejecución para la segunda parte es simplemente O(n). Para la mayoría de los conjuntos de datos del mundo real, el Algoritmo 2 está dominado por la ordenación y tiene una complejidad O(n log n). El Algoritmo 1 está garantizado de detenerse en un número polinómico de iteraciones [19], y cada iteración ejecuta el Algoritmo 2. Prácticamente todos los modelos que funcionaron bien fueron entrenados en un tiempo razonable (generalmente menos de una hora). Una vez que el entrenamiento esté completo, hacer predicciones sobre la consulta x usando la hipótesis resultante h(x|w) solo requiere ordenar por wT φ(x, d). Desarrollamos nuestro software utilizando una interfaz de Python a SVMstruct, ya que el lenguaje Python simplificó en gran medida el proceso de codificación. Para mejorar el rendimiento, es recomendable utilizar la implementación estándar en C de SVMstruct. CONFIGURACIÓN DEL EXPERIMENTO El objetivo principal de nuestros experimentos es evaluar si la optimización directa de MAP conduce a un rendimiento de MAP mejorado en comparación con los métodos convencionales de SVM que optimizan una pérdida sustituta como la precisión o el área bajo la curva ROC. Evaluamos empíricamente nuestro método utilizando dos conjuntos de consultas de la TREC Web Track, uno de TREC 9 y otro de TREC 10 (temas 451-500 y 501-550), ambos de los cuales utilizaron el corpus WT10g. Para cada consulta, TREC proporciona las evaluaciones de relevancia de los documentos. Generamos nuestras características utilizando las puntuaciones de las funciones de recuperación existentes en estas consultas. Si bien nuestro método es agnóstico al significado de las características, elegimos utilizar funciones de recuperación existentes como una forma simple pero efectiva de adquirir características útiles. Por lo tanto, nuestros experimentos de estadísticas de conjuntos de datos básicos esencialmente prueban la capacidad de nuestros métodos para volver a clasificar los documentos altamente clasificados (por ejemplo, volver a combinar las puntuaciones de las funciones de recuperación) para mejorar el MAP. Comparamos nuestro método con las mejores funciones de recuperación entrenadas (en adelante, funciones base), así como con los métodos SVM propuestos anteriormente. Comparar con las mejores funciones base pone a prueba la capacidad de nuestros métodos para aprender una combinación útil. Comparar con métodos SVM anteriores nos permite probar si optimizar directamente para el MAP (en lugar de precisión o área bajo la curva ROC) logra una puntuación de MAP más alta en la práctica. El resto de esta sección describe las funciones base y el método de generación de características en detalle. 4.1 Elección de Funciones de Recuperación Elegimos dos conjuntos de funciones base para nuestros experimentos. Para el primer conjunto, generamos tres índices sobre el corpus WT10g utilizando Indri5. El primer índice fue generado utilizando la configuración predeterminada, el segundo utilizó Porter-stemming, y el último utilizó Porter-stemming y las palabras vacías predeterminadas de Indris. Para TREC 9 y TREC 10, utilizamos la parte de descripción de cada consulta y puntuamos los documentos utilizando cinco de los métodos de recuperación integrados en Indri, que son Similitud Coseno, TFIDF, Okapi, Modelo de Lenguaje con Prior de Dirichlet y Modelo de Lenguaje con Prior de Jelinek-Mercer. Todos los parámetros se mantuvieron en sus valores predeterminados. Calculamos las puntuaciones de estos cinco métodos de recuperación sobre los tres índices, dando un total de 15 funciones base. Para cada consulta, consideramos las puntuaciones de los documentos encontrados en la unión de los mejores 1000 documentos de cada función base. Para nuestro segundo conjunto de funciones base, utilizamos puntuaciones de las presentaciones de la pista web TREC 9 [8] y TREC 10 [9]. Utilizamos solo las presentaciones no manuales y no breves de ambos años. Para TREC 9 y TREC 10, hubo 53 y 18 envíos de este tipo, respectivamente. Una presentación típica contenía puntajes de sus 1000 documentos principales. b ca wT φ(x,d) f(d|x) Figura 2: Ejemplo de Agrupación de Características 4.2 Generación de Características Para generar ejemplos de entrada para nuestro método, se debe proporcionar una instancia concreta de φ. Para cada documento d puntuado por un conjunto de funciones de recuperación F en la consulta x, generamos las características como un vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf, donde f(d|x) denota la puntuación que la función de recuperación f asigna al documento d para la consulta x, y cada Kf es un conjunto de valores reales. Desde un nivel alto, estamos expresando la puntuación de cada función de recuperación utilizando |Kf | + 1 contenedores. Dado que estamos utilizando núcleos lineales, se puede pensar en el problema de aprendizaje como encontrar una buena combinación de piezas constantes de los puntajes de las funciones de recuperación. La Figura 2 muestra un ejemplo de nuestro método de mapeo de características. En este ejemplo tenemos una única característica F = {f}. Aquí, Kf = {a, b, c}, y el vector de pesos es w = wa, wb, wc. Para cualquier documento d y consulta x, tenemos wT φ(x, d) = 8 >>< >>: 0 si f(d|x) < a wa si a ≤ f(d|x) < b wa + wb si b ≤ f(d|x) < c wa + wb + wc si c ≤ f(d|x) . Esto se expresa cualitativamente en la Figura 2, donde wa y wb son positivos, y wc es negativo. Realizamos nuestros experimentos principales utilizando cuatro opciones de F: el conjunto de las funciones de recuperación de Indri mencionadas anteriormente para TREC 9 y TREC 10, y las presentaciones de la pista web para TREC 9 y TREC 10. Para cada F y cada función f ∈ F, elegimos 50 valores para Kf que estuvieran razonablemente espaciados y capturaran la región sensible de f. Utilizando las cuatro opciones de F, generamos cuatro conjuntos de datos para nuestros experimentos principales. La Tabla 5 contiene estadísticas de los conjuntos de datos generados. Hay muchas formas de generar características, y no estamos abogando por nuestro método sobre los demás. Esto fue simplemente un medio eficiente para normalizar las salidas de diferentes funciones y permitir un modelo más expresivo. EXPERIMENTOS Para cada conjunto de datos en la Tabla 5, realizamos 50 pruebas. Para cada prueba, entrenamos con 10 consultas seleccionadas al azar, y seleccionamos otras 5 consultas al azar para un conjunto de validación. Los modelos fueron entrenados utilizando una amplia gama de valores de C. El modelo que tuvo mejor rendimiento en el conjunto de validación fue seleccionado y probado en las 35 consultas restantes. Todas las consultas fueron seleccionadas para estar en los conjuntos de entrenamiento, validación y prueba la misma cantidad de veces. Utilizando esta configuración, realizamos los mismos experimentos mientras usábamos nuestro método (mapa SVM∆), un SVM optimizando para ROCArea (SVM∆ roc) [13], y un SVM de clasificación convencional (SVMacc) [20]. Todos los métodos de SVM utilizaron un kernel lineal. Informamos sobre el rendimiento promedio de todos los modelos en las 50 pruebas. 5.1 Comparación con Funciones Base Al analizar nuestros resultados, la primera pregunta a responder es, ¿puede SVM∆ map aprender un modelo que supere al mejor modelo base TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.290 - 0.287Mejor Func. 0.280 28/22 0.283 29/21 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 36/14 ** Tabla 7: Comparación con Envíos TREC TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288Mejor Func. 0.280 27/23 0.283 31/19 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 35/15 ** Tabla 8: Comparación con Funciones de Envíos TREC (sin el mejor) La Tabla 6 presenta la comparación del mapa SVM∆ con las mejores funciones base de Indri. Cada grupo de columnas contiene el rendimiento del MAP macro-promediado de SVM∆ map o una función base. Las columnas W/L muestran el número de consultas donde SVM∆ map logró un puntaje MAP más alto. Se realizaron pruebas de significancia utilizando la prueba de rango con signo de Wilcoxon de dos colas. Dos estrellas indican un nivel de significancia de 0.95. Todas las tablas que muestran nuestros resultados experimentales están estructuradas de manera idéntica. Aquí encontramos que SVM∆ mapea significativamente mejor que las mejores funciones base. La Tabla 7 muestra la comparación cuando se entrena con las presentaciones de TREC. Si bien logra una puntuación de MAP más alta que las mejores funciones base, la diferencia de rendimiento entre SVM∆ y las funciones base no es significativa. Dado que muchas de estas presentaciones utilizan funciones de puntuación cuidadosamente diseñadas para lograr un alto MAP, es posible que las presentaciones con mejor rendimiento utilicen técnicas que engloben las técnicas de las otras presentaciones. Como resultado, el mapa SVM∆ no sería capaz de aprender una hipótesis que pueda superar significativamente la mejor presentación. Por lo tanto, realizamos los mismos experimentos utilizando un conjunto de datos modificado en el que se eliminaron las características calculadas utilizando la mejor presentación. La tabla 8 muestra los resultados (ten en cuenta que aún estamos comparando con la mejor presentación, aunque no la estamos utilizando para el entrenamiento). Observa que si bien el rendimiento del SVM∆ map se degradó ligeramente, aún era comparable con el de la mejor presentación. 5.2 Comparación con Métodos SVM Anteriores La siguiente pregunta a responder es, ¿produce el SVM∆ map puntajes MAP más altos que los métodos SVM anteriores? Las tablas 9 y 10 presentan los resultados de SVM∆ map, SVM∆ roc y SVMacc cuando se entrenan con las funciones de recuperación de Indri y las presentaciones de TREC, respectivamente. La Tabla 11 contiene los resultados correspondientes cuando se entrena con las presentaciones de TREC sin la mejor presentación. Para empezar, nuestros resultados indican que SVMacc no fue competitivo con SVM∆ map y SVM∆ roc, y a veces tuvo un rendimiento notablemente inferior. Por lo tanto, probamos varios enfoques para mejorar el rendimiento de SVMacc. 5.2.1 Métodos alternativos de SVMacc Un problema que puede causar que SVMacc tenga un rendimiento deficiente es el desequilibrio severo entre documentos relevantes y no relevantes. La gran mayoría de los documentos no son relevantes. SVMacc2 aborda este problema asignando una penalización mayor a los errores de falsos negativos. Para cada conjunto de datos, la proporción de las penalizaciones por falsos negativos a falsos positivos es igual a la proporción entre el número de documentos no relevantes y relevantes en ese conjunto de datos. Las tablas 9, 10 y 11 indican que SVMacc2 sigue teniendo un rendimiento significativamente peor que SVM∆ map. Otro posible problema es que SVMacc intenta encontrar solo un umbral discriminatorio b que sea invariable a la consulta. Puede ser que diferentes consultas requieran diferentes valores de b. Tener el método de aprendizaje intentando encontrar un buen valor de b (cuando no existe) puede ser perjudicial. Tomamos dos enfoques para abordar este problema. El primer método, SVMacc3, convierte las puntuaciones de la función de recuperación en percentiles. Por ejemplo, para el documento d, la consulta q y la función de recuperación f, si la puntuación f(d|q) se encuentra en el 90% superior de las puntuaciones f(·|q) para la consulta q, entonces la puntuación convertida es f(d|q) = 0.9. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Las tablas 9, 10 y 11 muestran que el rendimiento de SVMacc3 tampoco fue competitivo con SVM∆ map. El segundo método, SVMacc4, normaliza las puntuaciones dadas por f para cada consulta. Por ejemplo, suponga para la consulta q que f produce puntuaciones en el rango de 0.2 a 0.7. Entonces, para el documento d, si f(d|q) = 0.6, la puntuación convertida sería f(d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Nuevamente, las Tablas 9, 10 y 11 muestran que SVMacc4 no fue competitivo con SVM∆ map 5.2.2 MAP vs ROCArea. SVM∆ roc tuvo un rendimiento mucho mejor que SVMacc en nuestros experimentos. Cuando se entrenó con las funciones de recuperación de Indri (ver Tabla 9), el rendimiento de SVM∆ roc fue ligeramente, aunque no significativamente, peor que el rendimiento de SVM∆ map. Sin embargo, la Tabla 10 muestra que el mapa SVM∆ superó significativamente al roc SVM∆ cuando se entrenó con las presentaciones de TREC. La tabla 11 muestra el rendimiento de los modelos cuando se entrenan con las presentaciones de TREC y se elimina la mejor presentación. El rendimiento de la mayoría de los modelos se degradó ligeramente, con SVM∆ map aún teniendo el mejor rendimiento. TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288 SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Tabla 11: Entrenado en TREC Subm. (sin Mejor) 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado un método SVM que optimiza directamente el MAP. Proporciona un enfoque basado en principios y evita heurísticas difíciles de controlar. Formulamos el problema de optimización y presentamos un algoritmo que encuentra la solución de manera demostrable en tiempo polinómico. Hemos demostrado empíricamente que nuestro método es generalmente superior o competitivo con los métodos convencionales de SVM. Nuestro nuevo método hace que sea conceptualmente tan fácil optimizar SVMs para MAP como anteriormente solo era posible para Precisión y Área bajo la curva ROC. El costo computacional para el entrenamiento es muy razonable en la práctica. Dado que otros métodos suelen requerir ajustar múltiples heurísticas, también esperamos entrenar menos modelos antes de encontrar uno que logre un buen rendimiento. El marco de aprendizaje utilizado por nuestro método es bastante general. Una extensión natural de este marco sería desarrollar métodos para optimizar otras medidas importantes de IR, como la Ganancia Acumulada Normalizada Descontada [2, 3, 4, 12] y la Reciprocidad Media de Rango. 7. AGRADECIMIENTOS Este trabajo fue financiado bajo el Premio NSF IIS-0412894, el Premio NSF CAREER 0237381 y un obsequio de Yahoo! Investigación. El tercer autor también fue parcialmente apoyado por una Beca de Investigación de Microsoft. 8. REFERENCIAS [1] B. T. Bartell, G. W. Cottrell y R. K. Belew. Combinación automática de múltiples sistemas de recuperación clasificados. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2005. [3] C. J. C. Burges, R. Ragno y Q. Lo. Aprendizaje para clasificar con funciones de costo no suaves. En Actas de la Conferencia Internacional sobre Avances en Sistemas de Información Neural (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang y H.-W. Hon. Adaptando el SVM de clasificación para la recuperación de documentos. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [5] B. Carterette y D. Petkova. Aprendiendo un ranking a partir de preferencias por pares. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew y A. Ksikes. Selección de conjunto de bibliotecas de modelos. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [7] J. Davis y M. Goadrich. La relación entre las curvas de precisión-recall y ROC. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2006. [8] D. Hawking. Resumen de la pista web TREC-9. En Actas de TREC-2000, 2000. [9] D. Hawking y N. Craswell. Resumen de la pista web TREC-2001. En Actas de TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel y K. Obermayer. Límites de rango de margen amplio para regresión ordinal. Avances en clasificadores de márgenes amplios, 2000. [11] A. Herschtal y B. Raskutti. Optimizando el área bajo la curva ROC utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [12] K. Jarvelin y J. Kekalainen. Métodos de evaluación para recuperar documentos altamente relevantes. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2000. [13] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), páginas 377-384, Nueva York, NY, EE. UU., 2005. ACM Press. [14] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), páginas 111-119, 2001. [15] Y. Lin, Y. Lee y G. Wahba. Máquinas de vectores de soporte para clasificación en situaciones no estándar. Aprendizaje automático, 46:191-202, 2002. [16] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [17] K. Morik, P. Brockhausen y T. Joachims. Combinando el aprendizaje estadístico con un enfoque basado en el conocimiento. En Actas de la Conferencia Internacional sobre Aprendizaje Automático, 1999. [18] S. Robertson. El principio de clasificación de probabilidad en la revista IR de documentación. Revista de Documentación, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims y Y. Altun. Métodos de margen amplio para variables de salida estructuradas e interdependientes. Revista de Investigación en Aprendizaje Automático (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik. Teoría del Aprendizaje Estadístico. Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz. \n\nWiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer y R. Wolniewicz. Optimizando el rendimiento del clasificador mediante la aproximación a la estadística de Wilcoxon-Mann-Witney. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2003. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "loss function": {
            "translated_key": "función de pérdida",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT Machine learning is commonly used to improve ranked retrieval systems.",
                "Due to computational difficulties, few learning techniques have been developed to directly optimize for mean average precision (MAP), despite its widespread use in evaluating such systems.",
                "Existing approaches optimizing MAP either do not find a globally optimal solution, or are computationally expensive.",
                "In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of MAP.",
                "We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora (WT10g), comparing against SVMs optimized for accuracy and ROCArea.",
                "In most cases we show our method to produce statistically significant improvements in MAP scores.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval Models General Terms Algorithm, Theory, Experimentation 1.",
                "INTRODUCTION State of the art information retrieval systems commonly use machine learning techniques to learn ranking functions.",
                "However, most current approaches do not optimize for the evaluation measure most often used, namely Mean Average Precision (MAP).",
                "Instead, current algorithms tend to take one of two general approaches.",
                "The first approach is to learn a model that estimates the probability of a document being relevant given a query (e.g., [18, 14]).",
                "If solved effectively, the ranking with best MAP performance can easily be derived from the probabilities of relevance.",
                "However, achieving high MAP only requires finding a good ordering of the documents.",
                "As a result, finding good probabilities requires solving a more difficult problem than necessary, likely requiring more training data to achieve the same MAP performance.",
                "The second common approach is to learn a function that maximizes a surrogate measure.",
                "Performance measures optimized include accuracy [17, 15], ROCArea [1, 5, 10, 11, 13, 21] or modifications of ROCArea [4], and NDCG [2, 3].",
                "Learning a model to optimize for such measures might result in suboptimal MAP performance.",
                "In fact, although some previous systems have obtained good MAP performance, it is known that neither achieving optimal accuracy nor ROCArea can guarantee optimal MAP performance[7].",
                "In this paper, we present a general approach for learning ranking functions that maximize MAP performance.",
                "Specifically, we present an SVM algorithm that globally optimizes a hinge-loss relaxation of MAP.",
                "This approach simplifies the process of obtaining ranking functions with high MAP performance by avoiding additional intermediate steps and heuristics.",
                "The new algorithm also makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for accuracy and ROCArea.",
                "In contrast to recent work directly optimizing for MAP performance by Metzler & Croft [16] and Caruana et al. [6], our technique is computationally efficient while finding a globally optimal solution.",
                "Like [6, 16], our method learns a linear model, but is much more efficient in practice and, unlike [16], can handle many thousands of features.",
                "We now describe the algorithm in detail and provide proof of correctness.",
                "Following this, we provide an analysis of running time.",
                "We finish with empirical results from experiments on the TREC 9 and TREC 10 Web Track corpus.",
                "We have also developed a software package implementing our algorithm that is available for public use1 . 2.",
                "THE LEARNING PROBLEM Following the standard machine learning setup, our goal is to learn a function h : X → Y between an input space X (all possible queries) and output space Y (rankings over a corpus).",
                "In order to quantify the quality of a prediction, ˆy = h(x), we will consider a <br>loss function</br> ∆ : Y × Y → . ∆(y, ˆy) quantifies the penalty for making prediction ˆy if the correct output is y.",
                "The <br>loss function</br> allows us to incorporate specific performance measures, which we will exploit 1 http://svmrank.yisongyue.com for optimizing MAP.",
                "We restrict ourselves to the supervised learning scenario, where input/output pairs (x, y) are available for training and are assumed to come from some fixed distribution P(x, y).",
                "The goal is to find a function h such that the risk (i.e., expected loss), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), is minimized.",
                "Of course, P(x, y) is unknown.",
                "But given a finite set of training pairs, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, the performance of h on S can be measured by the empirical risk, R∆ S (h) = 1 n nX i=1 ∆(yi, h(xi)).",
                "In the case of learning a ranked retrieval function, X denotes a space of queries, and Y the space of (possibly weak) rankings over some corpus of documents C = {d1, . . . ,d|C|}.",
                "We can define average precision loss as ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), where rank(y) is a vector of the rank values of each document in C. For example, for a corpus of two documents, {d1, d2}, with d1 having higher rank than d2, rank(y ) = (1, 0).",
                "We assume true rankings have two rank values, where relevant documents have rank value 1 and non-relevant documents rank value 0.",
                "We further assume that all predicted rankings are complete rankings (no ties).",
                "Let p = rank(y) and ˆp = rank(ˆy).",
                "The average precision score is defined as MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, where rel = |{i : pi = 1}| is the number of relevant documents, and Prec@j is the percentage of relevant documents in the top j documents in predicted ranking ˆy.",
                "MAP is the mean of the average precision scores of a group of queries. 2.1 MAP vs ROCArea Most learning algorithms optimize for accuracy or ROCArea.",
                "While optimizing for these measures might achieve good MAP performance, we use two simple examples to show it can also be suboptimal in terms of MAP.",
                "ROCArea assigns equal penalty to each misordering of a relevant/non-relevant pair.",
                "In contrast, MAP assigns greater penalties to misorderings higher up in the predicted ranking.",
                "Using our notation, ROCArea can be defined as ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], where p is the true (weak) ranking, ˆp is the predicted ranking, and 1[b] is the indicator function conditioned on b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Table 1: Toy Example and Models Suppose we have a hypothesis space with only two hypothesis functions, h1 and h2, as shown in Table 1.",
                "These two hypotheses predict a ranking for query x over a corpus of eight documents.",
                "Hypothesis MAP ROCArea h1(x) 0.59 0.47 h2(x) 0.51 0.53 Table 2: Performance of Toy Models Table 2 shows the MAP and ROCArea scores of h1 and h2.",
                "Here, a learning method which optimizes for ROCArea would choose h2 since that results in a higher ROCArea score, but this yields a suboptimal MAP score. 2.2 MAP vs Accuracy Using a very similar example, we now demonstrate how optimizing for accuracy might result in suboptimal MAP.",
                "Models which optimize for accuracy are not directly concerned with the ranking.",
                "Instead, they learn a threshold such that documents scoring higher than the threshold can be classified as relevant and documents scoring lower as nonrelevant.",
                "Doc ID 1 2 3 4 5 6 7 8 9 10 11 p 1 0 0 0 0 1 1 1 1 0 0 rank(h1(x)) 11 10 9 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 9 10 11 Table 3: Toy Example and Models We consider again a hypothesis space with two hypotheses.",
                "Table 3 shows the predictions of the two hypotheses on a single query x. Hypothesis MAP Best Acc. h1(q) 0.70 0.64 h2(q) 0.64 0.73 Table 4: Performance of Toy Models Table 4 shows the MAP and best accuracy scores of h1(q) and h2(q).",
                "The best accuracy refers to the highest achievable accuracy on that ranking when considering all possible thresholds.",
                "For instance, with h1(q), a threshold between documents 1 and 2 gives 4 errors (documents 6-9 incorrectly classified as non-relevant), yielding an accuracy of 0.64.",
                "Similarly, with h2(q), a threshold between documents 5 and 6 gives 3 errors (documents 10-11 incorrectly classified as relevant, and document 1 as non-relevant), yielding an accuracy of 0.73.",
                "A learning method which optimizes for accuracy would choose h2 since that results in a higher accuracy score, but this yields a suboptimal MAP score. 3.",
                "OPTIMIZING AVERAGE PRECISION We build upon the approach used by [13] for optimizing ROCArea.",
                "Unlike ROCArea, however, MAP does not decompose linearly in the examples and requires a substantially extended algorithm, which we describe in this section.",
                "Recall that the true ranking is a weak ranking with two rank values (relevant and non-relevant).",
                "Let Cx and C¯x denote the set of relevant and non-relevant documents of C for query x, respectively.",
                "We focus on functions which are parametrized by a weight vector w, and thus wish to find w to minimize the empirical risk, R∆ S (w) ≡ R∆ S (h(·; w)).",
                "Our approach is to learn a discriminant function F : X × Y → over input-output pairs.",
                "Given query x, we can derive a prediction by finding the ranking y that maximizes the discriminant function: h(x; w) = argmax y∈Y F(x, y; w). (1) We assume F to be linear in some combined feature representation of inputs and outputs Ψ(x, y) ∈ RN , i.e., F(x, y; w) = wT Ψ(x, y). (2) The combined feature function we use is Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))] , where φ : X × C → N is a feature mapping function from a query/document pair to a point in N dimensional space2 .",
                "We represent rankings as a matrix of pairwise orderings, Y ⊂ {−1, 0, +1}|C|×|C| .",
                "For any y ∈ Y, yij = +1 if di is ranked ahead of dj, and yij = −1 if dj is ranked ahead of di, and yij = 0 if di and dj have equal rank.",
                "We consider only matrices which correspond to valid rankings (i.e, obeying antisymmetry and transitivity).",
                "Intuitively, Ψ is a summation over the vector differences of all relevant/non-relevant document pairings.",
                "Since we assume predicted rankings to be complete rankings, yij is either +1 or −1 (never 0).",
                "Given a learned weight vector w, predicting a ranking (i.e. solving equation (1)) given query x reduces to picking each yij to maximize wT Ψ(x, y).",
                "As is also discussed in [13], this is attained by sorting the documents by wT φ(x, d) in descending order.",
                "We will discuss later the choices of φ we used for our experiments. 3.1 Structural SVMs The above formulation is very similar to learning a straightforward linear model while training on the pairwise difference of relevant/non-relevant document pairings.",
                "Many SVM-based approaches optimize over these pairwise differences (e.g., [5, 10, 13, 4]), although these methods do not optimize for MAP during training.",
                "Previously, it was not clear how to incorporate non-linear multivariate loss functions such as MAP loss directly into global optimization problems such as SVM training.",
                "We now present a method based on structural SVMs [19] to address this problem.",
                "We use the structural SVM formulation, presented in Optimization Problem 1, to learn a w ∈ RN .",
                "Optimization Problem 1. (Structural SVM) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) The objective function to be minimized (3) is a tradeoff between model complexity, w 2 , and a hinge loss relaxation of MAP loss, P ξi.",
                "As is usual in SVM training, C is a 2 For example, one dimension might be the number of times the query words appear in the document.",
                "Algorithm 1 Cutting plane algorithm for solving OP 1 within tolerance . 1: Input: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ for all i = 1, . . . , n 3: repeat 4: for i = 1, . . . , n do 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: compute ˆy = argmaxy∈Y H(y; w) 7: compute ξi = max{0, maxy∈Wi H(y; w)} 8: if H(ˆy; w) > ξi + then 9: Wi ← Wi ∪ {ˆy} 10: w ← optimize (3) over W = S i Wi 11: end if 12: end for 13: until no Wi has changed during iteration parameter that controls this tradeoff and can be tuned to achieve good performance in different training tasks.",
                "For each (xi, yi) in the training set, a set of constraints of the form in equation (4) is added to the optimization problem.",
                "Note that wT Ψ(x, y) is exactly our discriminant function F(x, y; w) (see equation (2)).",
                "During prediction, our model chooses the ranking which maximizes the discriminant (1).",
                "If the discriminant value for an incorrect ranking y is greater than for the true ranking yi (e.g., F(xi, y; w) > F(xi, yi; w)), then corresponding slack variable, ξi, must be at least ∆(yi, y) for that constraint to be satisfied.",
                "Therefore, the sum of slacks, P ξi, upper bounds the MAP loss.",
                "This is stated formally in Proposition 1.",
                "Proposition 1.",
                "Let ξ∗ (w) be the optimal solution of the slack variables for OP 1 for a given weight vector w. Then 1 n Pn i=1 ξi is an upper bound on the empirical risk R∆ S (w). (see [19] for proof) Proposition 1 shows that OP 1 learns a ranking function that optimizes an upper bound on MAP error on the training set.",
                "Unfortunately there is a problem: a constraint is required for every possible wrong output y, and the number of possible wrong outputs is exponential in the size of C. Fortunately, we may employ Algorithm 1 to solve OP 1.",
                "Algorithm 1 is a cutting plane algorithm, iteratively introducing constraints until we have solved the original problem within a desired tolerance [19].",
                "The algorithm starts with no constraints, and iteratively finds for each example (xi, yi) the output ˆy associated with the most violated constraint.",
                "If the corresponding constraint is violated by more than we introduce ˆy into the working set Wi of active constraints for example i, and re-solve (3) using the updated W. It can be shown that Algorithm 1s outer loop is guaranteed to halt within a polynomial number of iterations for any desired precision .",
                "Theorem 1.",
                "Let ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y) , ¯∆ = maxi maxy ∆(yi, y), and for any > 0, Algorithm 1 terminates after adding at most max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff constraints to the working set W. (see [19] for proof) However, within the inner loop of this algorithm we have to compute argmaxy∈Y H(y; w), where H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), or equivalently, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), since wT Ψ(xi, yi) is constant with respect to y.",
                "Though closely related to the classification procedure, this has the substantial complication that we must contend with the additional ∆(yi, y) term.",
                "Without the ability to efficiently find the most violated constraint (i.e., solve argmaxy∈Y H(y, w)), the constraint generation procedure is not tractable. 3.2 Finding the Most Violated Constraint Using OP 1 and optimizing to ROCArea loss (∆roc), the problem of finding the most violated constraint, or solving argmaxy∈Y H(y, w) (henceforth argmax H), is addressed in [13].",
                "Solving argmax H for ∆map is more difficult.",
                "This is primarily because ROCArea decomposes nicely into a sum of scores computed independently on each relative ordering of a relevant/non-relevant document pair.",
                "MAP, on the other hand, does not decompose in the same way as ROCArea.",
                "The main algorithmic contribution of this paper is an efficient method for solving argmax H for ∆map.",
                "One useful property of ∆map is that it is invariant to swapping two documents with equal relevance.",
                "For example, if documents da and db are both relevant, then swapping the positions of da and db in any ranking does not affect ∆map.",
                "By extension, ∆map is invariant to any arbitrary permutation of the relevant documents amongst themselves and of the non-relevant documents amongst themselves.",
                "However, this reshuﬄing will affect the discriminant score, wT Ψ(x, y).",
                "This leads us to Observation 1.",
                "Observation 1.",
                "Consider rankings which are constrained by fixing the relevance at each position in the ranking (e.g., the 3rd document in the ranking must be relevant).",
                "Every ranking which satisfies the same set of constraints will have the same ∆map.",
                "If the relevant documents are sorted by wT φ(x, d) in descending order, and the non-relevant documents are likewise sorted by wT φ(x, d), then the interleaving of the two sorted lists which satisfies the constraints will maximize H for that constrained set of rankings.",
                "Observation 1 implies that in the ranking which maximizes H, the relevant documents will be sorted by wT φ(x, d), and the non-relevant documents will also be sorted likewise.",
                "By first sorting the relevant and non-relevant documents, the problem is simplified to finding the optimal interleaving of two sorted lists.",
                "For the rest of our discussion, we assume that the relevant documents and non-relevant documents are both sorted by descending wT φ(x, d).",
                "For convenience, we also refer to relevant documents as {dx 1 , . . . dx |Cx|} = Cx , and non-relevant documents as {d¯x 1 , . . . d¯x |C¯x|} = C¯x .",
                "We define δj(i1, i2), with i1 < i2, as the change in H from when the highest ranked relevant document ranked after d¯x j is dx i1 to when it is dx i2 .",
                "For i2 = i1 + 1, we have δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5) where si = wT φ(x, di).",
                "The first term in (5) is the change in ∆map when the ith relevant document has j non-relevant documents ranked before it, as opposed to j −1.",
                "The second term is the change in the discriminant score, wT Ψ(x, y), when yij changes from +1 to −1. . . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . .",
                "Figure 1: Example for δj(i, i + 1) Figure 1 gives a conceptual example for δj(i, i + 1).",
                "The bottom ranking differs from the top only where d¯x j slides up one rank.",
                "The difference in the value of H for these two rankings is exactly δj(i, i + 1).",
                "For any i1 < i2, we can then define δj(i1, i2) as δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) or equivalently, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) .",
                "Let o1, . . . , o|C¯x| encode the positions of the non-relevant documents, where dx oj is the highest ranked relevant document ranked after the jth non-relevant document.",
                "Due to Observation 1, this encoding uniquely identifies a complete ranking.",
                "We can recover the ranking as yij = 8 >>>< >>>: 0 if i = j sign(si − sj) if di, dj equal relevance sign(oj − i − 0.5) if di = dx i , dj = d¯x j sign(j − oi + 0.5) if di = d¯x i , dj = dx j . (7) We can now reformulate H into a new objective function, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), where ¯y is the true (weak) ranking.",
                "Conceptually H starts with a perfect ranking ¯y, and adds the change in H when each successive non-relevant document slides up the ranking.",
                "We can then reformulate the argmax H problem as argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) s.t. o1 ≤ . . . ≤ o|C¯x|. (9) Algorithm 2 describes the algorithm used to solve equation (8).",
                "Conceptually, Algorithm 2 starts with a perfect ranking.",
                "Then for each successive non-relevant document, the algorithm modifies the solution by sliding that document up the ranking to locally maximize H while keeping the positions of the other non-relevant documents constant. 3.2.1 Proof of Correctness Algorithm 2 is greedy in the sense that it finds the best position of each non-relevant document independently from the other non-relevant documents.",
                "In other words, the algorithm maximizes H for each non-relevant document, d¯x j , Algorithm 2 Finding the Most Violated Constraint (argmax H) for Algorithm 1 with ∆map 1: Input: w, Cx , C¯x 2: sort Cx and C¯x in descending order of wT φ(x, d) 3: sx i ← wT φ(x, dx i ), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i ), i = 1, . . . , |C¯x | 5: for j = 1, . . . , |C¯x | do 6: optj ← argmaxk δj(k, |Cx | + 1) 7: end for 8: encode ˆy according to (7) 9: return ˆy without considering the positions of the other non-relevant documents, and thus ignores the constraints of (9).",
                "In order for the solution to be feasible, the jth non-relevant document must be ranked after the first j − 1 non-relevant documents, thus satisfying opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. (10) If the solution is feasible, the it clearly solves (8).",
                "Therefore, it suffices to prove that Algorithm 2 satisfies (10).",
                "We first prove that δj(·, ·) is monotonically decreasing in j. Lemma 1.",
                "For any 1 ≤ i1 < i2 ≤ |Cx | + 1 and 1 ≤ j < |C¯x |, it must be the case that δj+1(i1, i2) ≤ δj(i1, i2).",
                "Proof.",
                "Recall from (6) that both δj(i1, i2) and δj+1(i1, i2) are summations of i2 − i1 terms.",
                "We will show that each term in the summation of δj+1(i1, i2) is no greater than the corresponding term in δj(i1, i2), or δj+1(k, k + 1) ≤ δj(k, k + 1) for k = i1, . . . , i2 − 1.",
                "Each term in δj(k, k +1) and δj+1(k, k +1) can be further decomposed into two parts (see (5)).",
                "We will show that each part of δj+1(k, k + 1) is no greater than the corresponding part in δj(k, k + 1).",
                "In other words, we will show that both j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) and −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) are true for the aforementioned values of j and k. It is easy to see that (11) is true by observing that for any two positive integers 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1 , and choosing a = j and b = j + k. The second inequality (12) holds because Algorithm 2 first sorts d¯x in descending order of s¯x , implying s¯x j+1 ≤ s¯x j .",
                "Thus we see that each term in δj+1 is no greater than the corresponding term in δj, which completes the proof.",
                "The result of Lemma 1 leads directly to our main correctness result: Theorem 2.",
                "In Algorithm 2, the computed values of optj satisfy (10), implying that the solution returned by Algorithm 2 is feasible and thus optimal.",
                "Proof.",
                "We will prove that optj ≤ optj+1 holds for any 1 ≤ j < |C¯x |, thus implying (10).",
                "Since Algorithm 2 computes optj as optj = argmax k δj(k, |Cx | + 1), (13) then by definition of δj (6), for any 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0.",
                "Using Lemma 1, we know that δj+1(i, optj) ≤ δj(i, optj) < 0, which implies that for any 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0.",
                "Suppose for contradiction that optj+1 < optj.",
                "Then δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), which contradicts (13).",
                "Therefore, it must be the case that optj ≤ optj+1, which completes the proof. 3.2.2 Running Time The running time of Algorithm 2 can be split into two parts.",
                "The first part is the sort by wT φ(x, d), which requires O(n log n) time, where n = |Cx | + |C¯x |.",
                "The second part computes each optj, which requires O(|Cx | · |C¯x |) time.",
                "Though in the worst case this is O(n2 ), the number of relevant documents, |Cx |, is often very small (e.g., constant with respect to n), in which case the running time for the second part is simply O(n).",
                "For most real-world datasets, Algorithm 2 is dominated by the sort and has complexity O(n log n).",
                "Algorithm 1 is guaranteed to halt in a polynomial number of iterations [19], and each iteration runs Algorithm 2.",
                "Virtually all well-performing models were trained in a reasonable amount of time (usually less than one hour).",
                "Once training is complete, making predictions on query x using the resulting hypothesis h(x|w) requires only sorting by wT φ(x, d).",
                "We developed our software using a Python interface3 to SVMstruct , since the Python language greatly simplified the coding process.",
                "To improve performance, it is advisable to use the standard C implementation4 of SVMstruct . 4.",
                "EXPERIMENT SETUP The main goal of our experiments is to evaluate whether directly optimizing MAP leads to improved MAP performance compared to conventional SVM methods that optimize a substitute loss such as accuracy or ROCArea.",
                "We empirically evaluate our method using two sets of TREC Web Track queries, one each from TREC 9 and TREC 10 (topics 451-500 and 501-550), both of which used the WT10g corpus.",
                "For each query, TREC provides the relevance judgments of the documents.",
                "We generated our features using the scores of existing retrieval functions on these queries.",
                "While our method is agnostic to the meaning of the features, we chose to use existing retrieval functions as a simple yet effective way of acquiring useful features.",
                "As such, our 3 http://www.cs.cornell.edu/~tomf/svmpython/ 4 http://svmlight.joachims.org/svm_struct.html Dataset Base Funcs Features TREC 9 Indri 15 750 TREC 10 Indri 15 750 TREC 9 Submissions 53 2650 TREC 10 Submissions 18 900 Table 5: Dataset Statistics experiments essentially test our methods ability to re-rank the highly ranked documents (e.g., re-combine the scores of the retrieval functions) to improve MAP.",
                "We compare our method against the best retrieval functions trained on (henceforth base functions), as well as against previously proposed SVM methods.",
                "Comparing with the best base functions tests our methods ability to learn a useful combination.",
                "Comparing with previous SVM methods allows us to test whether optimizing directly for MAP (as opposed to accuracy or ROCArea) achieves a higher MAP score in practice.",
                "The rest of this section describes the base functions and the feature generation method in detail. 4.1 Choosing Retrieval Functions We chose two sets of base functions for our experiments.",
                "For the first set, we generated three indices over the WT10g corpus using Indri5 .",
                "The first index was generated using default settings, the second used Porter-stemming, and the last used Porter-stemming and Indris default stopwords.",
                "For both TREC 9 and TREC 10, we used the description portion of each query and scored the documents using five of Indris built-in retrieval methods, which are Cosine Similarity, TFIDF, Okapi, Language Model with Dirichlet Prior, and Language Model with Jelinek-Mercer Prior.",
                "All parameters were kept as their defaults.",
                "We computed the scores of these five retrieval methods over the three indices, giving 15 base functions in total.",
                "For each query, we considered the scores of documents found in the union of the top 1000 documents of each base function.",
                "For our second set of base functions, we used scores from the TREC 9 [8] and TREC 10 [9] Web Track submissions.",
                "We used only the non-manual, non-short submissions from both years.",
                "For TREC 9 and TREC 10, there were 53 and 18 such submissions, respectively.",
                "A typical submission contained scores of its top 1000 documents. b ca wT φ(x,d) f(d|x) Figure 2: Example Feature Binning 4.2 Generating Features In order to generate input examples for our method, a concrete instantiation of φ must be provided.",
                "For each doc5 http://www.lemurproject.org TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236Best Func. 0.204 39/11 ** 0.181 37/13 ** 2nd Best 0.199 38/12 ** 0.174 43/7 ** 3rd Best 0.188 34/16 ** 0.174 38/12 ** Table 6: Comparison with Indri Functions ument d scored by a set of retrieval functions F on query x, we generate the features as a vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf , where f(d|x) denotes the score that retrieval function f assigns to document d for query x, and each Kf is a set of real values.",
                "From a high level, we are expressing the score of each retrieval function using |Kf | + 1 bins.",
                "Since we are using linear kernels, one can think of the learning problem as finding a good piecewise-constant combination of the scores of the retrieval functions.",
                "Figure 2 shows an example of our feature mapping method.",
                "In this example we have a single feature F = {f}.",
                "Here, Kf = {a, b, c}, and the weight vector is w = wa, wb, wc .",
                "For any document d and query x, we have wT φ(x, d) = 8 >>< >>: 0 if f(d|x) < a wa if a ≤ f(d|x) < b wa + wb if b ≤ f(d|x) < c wa + wb + wc if c ≤ f(d|x) .",
                "This is expressed qualitatively in Figure 2, where wa and wb are positive, and wc is negative.",
                "We ran our main experiments using four choices of F: the set of aforementioned Indri retrieval functions for TREC 9 and TREC 10, and the Web Track submissions for TREC 9 and TREC 10.",
                "For each F and each function f ∈ F, we chose 50 values for Kf which are reasonably spaced and capture the sensitive region of f. Using the four choices of F, we generated four datasets for our main experiments.",
                "Table 5 contains statistics of the generated datasets.",
                "There are many ways to generate features, and we are not advocating our method over others.",
                "This was simply an efficient means to normalize the outputs of different functions and allow for a more expressive model. 5.",
                "EXPERIMENTS For each dataset in Table 5, we performed 50 trials.",
                "For each trial, we train on 10 randomly selected queries, and select another 5 queries at random for a validation set.",
                "Models were trained using a wide range of C values.",
                "The model which performed best on the validation set was selected and tested on the remaining 35 queries.",
                "All queries were selected to be in the training, validation and test sets the same number of times.",
                "Using this setup, we performed the same experiments while using our method (SVM∆ map), an SVM optimizing for ROCArea (SVM∆ roc) [13], and a conventional classification SVM (SVMacc) [20].",
                "All SVM methods used a linear kernel.",
                "We reported the average performance of all models over the 50 trials. 5.1 Comparison with Base Functions In analyzing our results, the first question to answer is, can SVM∆ map learn a model which outperforms the best base TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287Best Func. 0.280 28/22 0.283 29/21 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 36/14 ** Table 7: Comparison with TREC Submissions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288Best Func. 0.280 27/23 0.283 31/19 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 35/15 ** Table 8: Comparison with TREC Subm. (w/o best) functions?",
                "Table 6 presents the comparison of SVM∆ map with the best Indri base functions.",
                "Each column group contains the macro-averaged MAP performance of SVM∆ map or a base function.",
                "The W/L columns show the number of queries where SVM∆ map achieved a higher MAP score.",
                "Significance tests were performed using the two-tailed Wilcoxon signed rank test.",
                "Two stars indicate a significance level of 0.95.",
                "All tables displaying our experimental results are structured identically.",
                "Here, we find that SVM∆ map significantly outperforms the best base functions.",
                "Table 7 shows the comparison when trained on TREC submissions.",
                "While achieving a higher MAP score than the best base functions, the performance difference between SVM∆ map the base functions is not significant.",
                "Given that many of these submissions use scoring functions which are carefully crafted to achieve high MAP, it is possible that the best performing submissions use techniques which subsume the techniques of the other submissions.",
                "As a result, SVM∆ map would not be able to learn a hypothesis which can significantly out-perform the best submission.",
                "Hence, we ran the same experiments using a modified dataset where the features computed using the best submission were removed.",
                "Table 8 shows the results (note that we are still comparing against the best submission though we are not using it for training).",
                "Notice that while the performance of SVM∆ map degraded slightly, the performance was still comparable with that of the best submission. 5.2 Comparison w/ Previous SVM Methods The next question to answer is, does SVM∆ map produce higher MAP scores than previous SVM methods?",
                "Tables 9 and 10 present the results of SVM∆ map, SVM∆ roc, and SVMacc when trained on the Indri retrieval functions and TREC submissions, respectively.",
                "Table 11 contains the corresponding results when trained on the TREC submissions without the best submission.",
                "To start with, our results indicate that SVMacc was not competitive with SVM∆ map and SVM∆ roc, and at times underperformed dramatically.",
                "As such, we tried several approaches to improve the performance of SVMacc. 5.2.1 Alternate SVMacc Methods One issue which may cause SVMacc to underperform is the severe imbalance between relevant and non-relevant docTREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236SVM∆ roc 0.237 29/21 0.234 24/26 SVMacc 0.147 47/3 ** 0.155 47/3 ** SVMacc2 0.219 39/11 ** 0.207 43/7 ** SVMacc3 0.113 49/1 ** 0.153 45/5 ** SVMacc4 0.155 48/2 ** 0.155 48/2 ** Table 9: Trained on Indri Functions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287SVM∆ roc 0.282 29/21 0.278 35/15 ** SVMacc 0.213 49/1 ** 0.222 49/1 ** SVMacc2 0.270 34/16 ** 0.261 42/8 ** SVMacc3 0.133 50/0 ** 0.182 46/4 ** SVMacc4 0.233 47/3 ** 0.238 46/4 ** Table 10: Trained on TREC Submissions uments.",
                "The vast majority of the documents are not relevant.",
                "SVMacc2 addresses this problem by assigning more penalty to false negative errors.",
                "For each dataset, the ratio of the false negative to false positive penalties is equal to the ratio of the number non-relevant and relevant documents in that dataset.",
                "Tables 9, 10 and 11 indicate that SVMacc2 still performs significantly worse than SVM∆ map.",
                "Another possible issue is that SVMacc attempts to find just one discriminating threshold b that is query-invariant.",
                "It may be that different queries require different values of b.",
                "Having the learning method trying to find a good b value (when one does not exist) may be detrimental.",
                "We took two approaches to address this issue.",
                "The first method, SVMacc3, converts the retrieval function scores into percentiles.",
                "For example, for document d, query q and retrieval function f, if the score f(d|q) is in the top 90% of the scores f(·|q) for query q, then the converted score is f (d|q) = 0.9.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Tables 9, 10 and 11 show that the performance of SVMacc3 was also not competitive with SVM∆ map.",
                "The second method, SVMacc4, normalizes the scores given by f for each query.",
                "For example, assume for query q that f outputs scores in the range 0.2 to 0.7.",
                "Then for document d, if f(d|q) = 0.6, the converted score would be f (d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Again, Tables 9, 10 and 11 show that SVMacc4 was not competitive with SVM∆ map 5.2.2 MAP vs ROCArea SVM∆ roc performed much better than SVMacc in our experiments.",
                "When trained on Indri retrieval functions (see Table 9), the performance of SVM∆ roc was slight, though not significantly, worse than the performances of SVM∆ map.",
                "However, Table 10 shows that SVM∆ map did significantly outperform SVM∆ roc when trained on the TREC submissions.",
                "Table 11 shows the performance of the models when trained on the TREC submissions with the best submission removed.",
                "The performance of most models degraded by a small amount, with SVM∆ map still having the best performance.",
                "TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Table 11: Trained on TREC Subm. (w/o Best) 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented an SVM method that directly optimizes MAP.",
                "It provides a principled approach and avoids difficult to control heuristics.",
                "We formulated the optimization problem and presented an algorithm which provably finds the solution in polynomial time.",
                "We have shown empirically that our method is generally superior to or competitive with conventional SVMs methods.",
                "Our new method makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for Accuracy and ROCArea.",
                "The computational cost for training is very reasonable in practice.",
                "Since other methods typically require tuning multiple heuristics, we also expect to train fewer models before finding one which achieves good performance.",
                "The learning framework used by our method is fairly general.",
                "A natural extension of this framework would be to develop methods to optimize for other important IR measures, such as Normalized Discounted Cumulative Gain [2, 3, 4, 12] and Mean Reciprocal Rank. 7.",
                "ACKNOWLEDGMENTS This work was funded under NSF Award IIS-0412894, NSF CAREER Award 0237381, and a gift from Yahoo!",
                "Research.",
                "The third author was also partly supported by a Microsoft Research Fellowship. 8.",
                "REFERENCES [1] B. T. Bartell, G. W. Cottrell, and R. K. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2005. [3] C. J. C. Burges, R. Ragno, and Q.",
                "Le.",
                "Learning to rank with non-smooth cost functions.",
                "In Proceedings of the International Conference on Advances in Neural Information Processing Systems (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y.",
                "Liu, H. Li, Y. Huang, and H.-W. Hon.",
                "Adapting ranking SVM to document retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [5] B. Carterette and D. Petkova.",
                "Learning a ranking from pairwise preferences.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew, and A. Ksikes.",
                "Ensemble selection from libraries of models.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [7] J. Davis and M. Goadrich.",
                "The relationship between precision-recall and ROC curves.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2006. [8] D. Hawking.",
                "Overview of the TREC-9 web track.",
                "In Proceedings of TREC-2000, 2000. [9] D. Hawking and N. Craswell.",
                "Overview of the TREC-2001 web track.",
                "In Proceedings of TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel, and K. Obermayer.",
                "Large margin rank boundaries for ordinal regression.",
                "Advances in large margin classifiers, 2000. [11] A. Herschtal and B. Raskutti.",
                "Optimising area under the ROC curve using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [12] K. Jarvelin and J. Kekalainen.",
                "Ir evaluation methods for retrieving highly relevant documents.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2000. [13] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proceedings of the International Conference on Machine Learning (ICML), pages 377-384, New York, NY, USA, 2005.",
                "ACM Press. [14] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 111-119, 2001. [15] Y. Lin, Y. Lee, and G. Wahba.",
                "Support vector machines for classification in nonstandard situations.",
                "Machine Learning, 46:191-202, 2002. [16] D. Metzler and W. B. Croft.",
                "A markov random field model for term dependencies.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 472-479, 2005. [17] K. Morik, P. Brockhausen, and T. Joachims.",
                "Combining statistical learning with a knowledge-based approach.",
                "In Proceedings of the International Conference on Machine Learning, 1999. [18] S. Robertson.",
                "The probability ranking principle in ir. journal of documentation.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.",
                "Large margin methods for structured and interdependent output variables.",
                "Journal of Machine Learning Research (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik.",
                "Statistical Learning Theory.",
                "Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz.",
                "Optimizing classifier performance via approximation to the Wilcoxon-Mann-Witney statistic.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2003."
            ],
            "original_annotated_samples": [
                "In order to quantify the quality of a prediction, ˆy = h(x), we will consider a <br>loss function</br> ∆ : Y × Y → . ∆(y, ˆy) quantifies the penalty for making prediction ˆy if the correct output is y.",
                "The <br>loss function</br> allows us to incorporate specific performance measures, which we will exploit 1 http://svmrank.yisongyue.com for optimizing MAP."
            ],
            "translated_annotated_samples": [
                "Para cuantificar la calidad de una predicción, ˆy = h(x), consideraremos una <br>función de pérdida</br> ∆ : Y × Y → . ∆(y, ˆy) cuantifica la penalización por hacer la predicción ˆy si la salida correcta es y.",
                "La <br>función de pérdida</br> nos permite incorporar medidas específicas de rendimiento, las cuales explotaremos en http://svmrank.yisongyue.com para optimizar el MAP."
            ],
            "translated_text": "Un método de Vectores de Soporte para optimizar la Precisión Promedio Yisong Yue Universidad de Cornell Ithaca, NY, EE. UU. yyue@cs.cornell.edu Thomas Finley Universidad de Cornell Ithaca, NY, EE. UU. tomf@cs.cornell.edu Filip Radlinski Universidad de Cornell Ithaca, NY, EE. UU. filip@cs.cornell.edu Thorsten Joachims Universidad de Cornell Ithaca, NY, EE. UU. tj@cs.cornell.edu RESUMEN El aprendizaje automático se utiliza comúnmente para mejorar los sistemas de recuperación clasificados. Debido a dificultades computacionales, se han desarrollado pocas técnicas de aprendizaje para optimizar directamente la precisión media promedio (MAP), a pesar de su uso generalizado en la evaluación de dichos sistemas. Los enfoques existentes que optimizan el MAP no encuentran una solución óptima global o son computacionalmente costosos. Por el contrario, presentamos un algoritmo de aprendizaje SVM general que encuentra de manera eficiente una solución óptima global para una relajación directa de MAP. Evaluamos nuestro enfoque utilizando los corpus de la pista web TREC 9 y TREC 10 (WT10g), comparando con SVM optimizados para precisión y área bajo la curva ROC. En la mayoría de los casos mostramos nuestro método para producir mejoras estadísticamente significativas en las puntuaciones de MAP. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de Recuperación Términos Generales Algoritmo, Teoría, Experimentación 1. INTRODUCCIÓN Los sistemas de recuperación de información de última generación comúnmente utilizan técnicas de aprendizaje automático para aprender funciones de clasificación. Sin embargo, la mayoría de los enfoques actuales no están optimizados para la medida de evaluación más utilizada, es decir, la Precisión Promedio Media (MAP). En cambio, los algoritmos actuales tienden a seguir uno de dos enfoques generales. El primer enfoque es aprender un modelo que estime la probabilidad de que un documento sea relevante dado una consulta (por ejemplo, [18, 14]). Si se resuelve de manera efectiva, la clasificación con el mejor rendimiento de MAP puede derivarse fácilmente de las probabilidades de relevancia. Sin embargo, lograr un MAP alto solo requiere encontrar un buen ordenamiento de los documentos. Como resultado, encontrar buenas probabilidades requiere resolver un problema más difícil de lo necesario, probablemente necesitando más datos de entrenamiento para lograr el mismo rendimiento de MAP. El segundo enfoque común es aprender una función que maximice una medida sustituta. Las medidas de rendimiento optimizadas incluyen precisión [17, 15], área bajo la curva ROC [1, 5, 10, 11, 13, 21] o modificaciones del área bajo la curva ROC [4], y NDCG [2, 3]. Aprender un modelo para optimizar tales medidas podría resultar en un rendimiento de MAP subóptimo. De hecho, aunque algunos sistemas anteriores han obtenido un buen rendimiento de MAP, se sabe que ni lograr una precisión óptima ni un área bajo la curva ROC pueden garantizar un rendimiento de MAP óptimo[7]. En este artículo, presentamos un enfoque general para aprender funciones de clasificación que maximizan el rendimiento de MAP. Específicamente, presentamos un algoritmo SVM que optimiza globalmente una relajación de pérdida de bisagra de MAP. Este enfoque simplifica el proceso de obtener funciones de clasificación con un alto rendimiento de MAP al evitar pasos intermedios adicionales y heurísticas. El nuevo algoritmo también hace que sea conceptualmente tan fácil optimizar las SVM para MAP como anteriormente solo era posible para precisión y ROCArea. A diferencia del trabajo reciente que optimiza directamente el rendimiento de MAP realizado por Metzler & Croft [16] y Caruana et al. [6], nuestra técnica es eficiente computacionalmente al encontrar una solución óptima a nivel global. Al igual que [6, 16], nuestro método aprende un modelo lineal, pero es mucho más eficiente en la práctica y, a diferencia de [16], puede manejar miles de características. Ahora describimos el algoritmo en detalle y proporcionamos la prueba de corrección. A continuación, proporcionamos un análisis del tiempo de ejecución. Concluimos con los resultados empíricos de experimentos en el corpus de la pista web TREC 9 y TREC 10. También hemos desarrollado un paquete de software que implementa nuestro algoritmo y está disponible para uso público. EL PROBLEMA DEL APRENDIZAJE Siguiendo la configuración estándar del aprendizaje automático, nuestro objetivo es aprender una función h: X → Y entre un espacio de entrada X (todas las consultas posibles) y un espacio de salida Y (clasificaciones sobre un corpus). Para cuantificar la calidad de una predicción, ˆy = h(x), consideraremos una <br>función de pérdida</br> ∆ : Y × Y → . ∆(y, ˆy) cuantifica la penalización por hacer la predicción ˆy si la salida correcta es y. La <br>función de pérdida</br> nos permite incorporar medidas específicas de rendimiento, las cuales explotaremos en http://svmrank.yisongyue.com para optimizar el MAP. Nos restringimos al escenario de aprendizaje supervisado, donde pares de entrada/salida (x, y) están disponibles para el entrenamiento y se asume que provienen de alguna distribución fija P(x, y). El objetivo es encontrar una función h tal que el riesgo (es decir, la pérdida esperada), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), se minimice. Por supuesto, P(x, y) es desconocido. Pero dado un conjunto finito de pares de entrenamiento, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, el rendimiento de h en S puede medirse mediante el riesgo empírico, R∆ S (h) = 1 n ∑ i=1 n ∆(yi, h(xi)). En el caso de aprender una función de recuperación clasificada, X denota un espacio de consultas, y Y el espacio de clasificaciones (posiblemente débiles) sobre algún corpus de documentos C = {d1, . . . ,d|C|}. Podemos definir la pérdida de precisión promedio como ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), donde rank(y) es un vector de los valores de rango de cada documento en C. Por ejemplo, para un corpus de dos documentos, {d1, d2}, con d1 teniendo un rango más alto que d2, rank(y) = (1, 0). Suponemos que las clasificaciones verdaderas tienen dos valores de clasificación, donde los documentos relevantes tienen un valor de clasificación 1 y los documentos no relevantes tienen un valor de clasificación 0. Además, asumimos que todas las clasificaciones predichas son clasificaciones completas (sin empates). Sea p = rango(y) y ˆp = rango(ˆy). La puntuación de precisión promedio se define como MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, donde rel = |{i : pi = 1}| es el número de documentos relevantes, y Prec@j es el porcentaje de documentos relevantes en los primeros j documentos en la clasificación predicha ˆy. MAP es la media de las puntuaciones de precisión promedio de un grupo de consultas. La mayoría de los algoritmos de aprendizaje se optimizan para precisión o ROCArea. Si bien optimizar estas medidas podría lograr un buen rendimiento de MAP, usamos dos ejemplos simples para mostrar que también puede ser subóptimo en términos de MAP. ROCArea asigna una penalización igual a cada desordenamiento de un par relevante/no relevante. Por el contrario, MAP asigna mayores penalizaciones a los errores de ordenamiento más arriba en la clasificación predicha. Usando nuestra notación, el Área bajo la Curva ROC (ROCArea) se puede definir como ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], donde p es el ranking verdadero (débil), ˆp es el ranking predicho, y 1[b] es la función indicadora condicionada a b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Tabla 1: Ejemplo y Modelos Supongamos que tenemos un espacio de hipótesis con solo dos funciones de hipótesis, h1 y h2, como se muestra en la Tabla 1. Estas dos hipótesis predicen un ranking para la consulta x sobre un corpus de ocho documentos. Tabla 2: Rendimiento de los Modelos de Juguete La Tabla 2 muestra las puntuaciones de MAP y ROCArea de h1 y h2. Aquí, un método de aprendizaje que optimiza para el Área bajo la curva ROC elegiría h2 ya que esto resulta en un puntaje de Área bajo la curva ROC más alto, pero esto produce un puntaje de MAP subóptimo. 2.2 MAP vs Precisión Usando un ejemplo muy similar, ahora demostramos cómo optimizar para la precisión podría resultar en un puntaje de MAP subóptimo. Los modelos que se optimizan para la precisión no están directamente preocupados por la clasificación. En cambio, aprenden un umbral tal que los documentos que obtienen una puntuación superior al umbral pueden ser clasificados como relevantes y los documentos que obtienen una puntuación inferior como no relevantes. Consideramos nuevamente un espacio de hipótesis con dos hipótesis. La Tabla 3 muestra las predicciones de las dos hipótesis en una única consulta x. Hipótesis MAP Mejor Precisión h1(q) 0.70 0.64 h2(q) 0.64 0.73 Tabla 4: Rendimiento de los Modelos de Juguete La Tabla 4 muestra los puntajes de MAP y mejor precisión de h1(q) y h2(q). La mejor precisión se refiere a la precisión más alta alcanzable en esa clasificación al considerar todos los umbrales posibles. Por ejemplo, con h1(q), un umbral entre los documentos 1 y 2 da 4 errores (documentos 6-9 clasificados incorrectamente como no relevantes), lo que resulta en una precisión de 0.64. De manera similar, con h2(q), un umbral entre los documentos 5 y 6 da 3 errores (los documentos 10-11 clasificados incorrectamente como relevantes, y el documento 1 como no relevante), lo que resulta en una precisión de 0.73. Un método de aprendizaje que optimiza la precisión elegiría h2 ya que esto resulta en un puntaje de precisión más alto, pero esto produce un puntaje de MAP subóptimo. 3. OPTIMIZANDO LA PRECISIÓN PROMEDIO Nos basamos en el enfoque utilizado por [13] para optimizar el Área bajo la Curva ROC. A diferencia de ROCArea, sin embargo, MAP no se descompone linealmente en los ejemplos y requiere un algoritmo sustancialmente extendido, el cual describimos en esta sección. Recuerda que la clasificación verdadera es una clasificación débil con dos valores de clasificación (relevante y no relevante). Que Cx y C¯x denoten el conjunto de documentos relevantes y no relevantes de C para la consulta x, respectivamente. Nos enfocamos en funciones que están parametrizadas por un vector de peso w, y por lo tanto deseamos encontrar w para minimizar el riesgo empírico, R∆ S (w) ≡ R∆ S (h(·; w)). Nuestro enfoque es aprender una función discriminante F: X × Y → sobre pares de entrada-salida. Dada la consulta x, podemos derivar una predicción encontrando la clasificación y que maximiza la función discriminante: h(x; w) = argmax y∈Y F(x, y; w). (1) Suponemos que F es lineal en alguna representación de características combinadas de entradas y salidas Ψ(x, y) ∈ RN, es decir, F(x, y; w) = wT Ψ(x, y). (2) La función de características combinadas que utilizamos es Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))], donde φ: X × C → N es una función de mapeo de características de un par consulta/documento a un punto en un espacio dimensional N. Representamos las clasificaciones como una matriz de ordenamientos por pares, Y ⊂ {−1, 0, +1}|C|×|C| . Para cualquier y ∈ Y, yij = +1 si di está clasificado por delante de dj, y yij = −1 si dj está clasificado por delante de di, y yij = 0 si di y dj tienen el mismo rango. Consideramos solo matrices que corresponden a clasificaciones válidas (es decir, que cumplen con la antisimetría y la transitividad). De manera intuitiva, Ψ es una suma de las diferencias vectoriales de todos los pares de documentos relevantes/no relevantes. Dado que asumimos que las clasificaciones predichas son clasificaciones completas, yij es o bien +1 o −1 (nunca 0). Dado un vector de pesos aprendido w, predecir un ranking (es decir, resolver la ecuación (1)) dado una consulta x se reduce a elegir cada yij para maximizar wT Ψ(x, y). Como también se discute en [13], esto se logra ordenando los documentos por wT φ(x, d) en orden descendente. Discutiremos más adelante las elecciones de φ que utilizamos para nuestros experimentos. 3.1 SVM Estructurales La formulación anterior es muy similar a aprender un modelo lineal directo mientras se entrena en la diferencia de pares de documentos relevantes/no relevantes. Muchos enfoques basados en SVM optimizan sobre estas diferencias en pares (por ejemplo, [5, 10, 13, 4]), aunque estos métodos no optimizan para el MAP durante el entrenamiento. Anteriormente, no estaba claro cómo incorporar funciones de pérdida multivariadas no lineales como la pérdida MAP directamente en problemas de optimización global como el entrenamiento de SVM. Ahora presentamos un método basado en SVM estructurales [19] para abordar este problema. Utilizamos la formulación del SVM estructural, presentada en el Problema de Optimización 1, para aprender un w ∈ RN. Problema de optimización 1. (SVM estructural) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) La función objetivo a minimizar (3) es un compromiso entre la complejidad del modelo, w 2 , y una relajación de pérdida de MAP mediante la pérdida de bisagra, P ξi. Como es habitual en el entrenamiento de SVM, C es igual a 2. Por ejemplo, una dimensión podría ser el número de veces que las palabras de la consulta aparecen en el documento. Algoritmo 1 Algoritmo de plano de corte para resolver OP 1 dentro de la tolerancia. 1: Entrada: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ para todo i = 1, . . . , n 3: repetir 4: para i = 1, . . . , n hacer 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: calcular ˆy = argmaxy∈Y H(y; w) 7: calcular ξi = max{0, maxy∈Wi H(y; w)} 8: si H(ˆy; w) > ξi + entonces 9: Wi ← Wi ∪ {ˆy} 10: w ← optimizar (3) sobre W = S i Wi 11: fin si 12: fin para 13: hasta que ningún Wi haya cambiado durante la iteración parámetro que controla este equilibrio y puede ajustarse para lograr un buen rendimiento en diferentes tareas de entrenamiento. Para cada (xi, yi) en el conjunto de entrenamiento, se añade un conjunto de restricciones de la forma en la ecuación (4) al problema de optimización. Ten en cuenta que wT Ψ(x, y) es exactamente nuestra función discriminante F(x, y; w) (ver ecuación (2)). Durante la predicción, nuestro modelo elige el ranking que maximiza el discriminante (1). Si el valor del discriminante para una clasificación incorrecta y es mayor que para la clasificación verdadera yi (por ejemplo, F(xi, y; w) > F(xi, yi; w)), entonces la variable de holgura correspondiente, ξi, debe ser al menos ∆(yi, y) para que se cumpla esa restricción. Por lo tanto, la suma de los márgenes, P ξi, acota superiormente la pérdida MAP. Esto se establece formalmente en la Proposición 1. Proposición 1. Sea ξ∗ (w) la solución óptima de las variables de holgura para OP 1 para un vector de peso dado w. Entonces 1 n Pn i=1 ξi es una cota superior del riesgo empírico R∆ S (w). (ver [19] para la prueba) La Proposición 1 muestra que OP 1 aprende una función de clasificación que optimiza una cota superior del error de MAP en el conjunto de entrenamiento. Desafortunadamente hay un problema: se requiere una restricción para cada posible resultado incorrecto y, y el número de resultados incorrectos posibles es exponencial en el tamaño de C. Afortunadamente, podemos emplear el Algoritmo 1 para resolver OP 1. El algoritmo 1 es un algoritmo de plano de corte, introduciendo iterativamente restricciones hasta que hayamos resuelto el problema original dentro de una tolerancia deseada [19]. El algoritmo comienza sin restricciones y encuentra de forma iterativa, para cada ejemplo (xi, yi), la salida ˆy asociada con la restricción más violada. Si la restricción correspondiente es violada por más de lo que introducimos ˆy en el conjunto de trabajo Wi de restricciones activas, por ejemplo i, y volvemos a resolver (3) usando el W actualizado. Se puede demostrar que el bucle externo del Algoritmo 1 está garantizado a detenerse dentro de un número polinomial de iteraciones para cualquier precisión deseada. Teorema 1. Sea ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y), ¯∆ = maxi maxy ∆(yi, y), y para cualquier > 0, el Algoritmo 1 termina después de agregar a lo sumo max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff restricciones al conjunto de trabajo W. (ver [19] para la prueba) Sin embargo, dentro del bucle interno de este algoritmo tenemos que calcular argmaxy∈Y H(y; w), donde H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), o equivalentemente, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), ya que wT Ψ(xi, yi) es constante con respecto a y. Aunque está estrechamente relacionado con el procedimiento de clasificación, esto tiene la complicación sustancial de que debemos lidiar con el término adicional ∆(yi, y). Sin la capacidad de encontrar eficientemente la restricción más violada (es decir, resolver argmaxy∈Y H(y, w)), el procedimiento de generación de restricciones no es viable. 3.2 Encontrar la restricción más violada utilizando OP 1 y optimizando la pérdida de ROCArea (∆roc), el problema de encontrar la restricción más violada, o resolver argmaxy∈Y H(y, w) (en adelante argmax H), se aborda en [13]. Resolver argmax H para ∆map es más difícil. Esto se debe principalmente a que ROCArea se descompone de manera ordenada en una suma de puntuaciones calculadas de forma independiente en cada ordenamiento relativo de un par de documentos relevantes/no relevantes. MAP, por otro lado, no se descompone de la misma manera que ROCArea. La principal contribución algorítmica de este artículo es un método eficiente para resolver argmax H para ∆map. Una propiedad útil de ∆map es que es invariante al intercambiar dos documentos con igual relevancia. Por ejemplo, si los documentos da y db son ambos relevantes, entonces intercambiar las posiciones de da y db en cualquier clasificación no afecta a ∆map. Por extensión, ∆map es invariante a cualquier permutación arbitraria de los documentos relevantes entre sí y de los documentos no relevantes entre sí. Sin embargo, esta reorganización afectará la puntuación del discriminante, wT Ψ(x, y). Esto nos lleva a la Observación 1. Observación 1. Considera clasificaciones que estén limitadas por fijar la relevancia en cada posición de la clasificación (por ejemplo, el tercer documento en la clasificación debe ser relevante). Cada clasificación que cumpla con el mismo conjunto de restricciones tendrá el mismo ∆map. Si los documentos relevantes están ordenados por wT φ(x, d) en orden descendente, y los documentos no relevantes también están ordenados de la misma manera por wT φ(x, d), entonces la intercalación de las dos listas ordenadas que cumpla con las restricciones maximizará H para ese conjunto de clasificaciones restringidas. La Observación 1 implica que en la clasificación que maximiza H, los documentos relevantes se ordenarán por wT φ(x, d), y los documentos no relevantes también se ordenarán de la misma manera. Al ordenar primero los documentos relevantes y no relevantes, el problema se simplifica a encontrar la intercalación óptima de dos listas ordenadas. Para el resto de nuestra discusión, asumimos que los documentos relevantes y no relevantes están ordenados por wT φ(x, d) en orden descendente. Para mayor comodidad, también nos referimos a los documentos relevantes como {dx 1 , . . . dx |Cx|} = Cx, y a los documentos no relevantes como {d¯x 1 , . . . d¯x |C¯x|} = C¯x. Definimos δj(i1, i2), con i1 < i2, como el cambio en H desde cuando el documento relevante de mayor rango clasificado después de d¯x j es dx i1 hasta que es dx i2. Para i2 = i1 + 1, tenemos δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5), donde si = wT φ(x, di). El primer término en (5) es el cambio en ∆map cuando el documento relevante i tiene j documentos no relevantes clasificados antes de él, en lugar de j-1. El segundo término es el cambio en la puntuación del discriminante, wT Ψ(x, y), cuando yij cambia de +1 a −1. . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . . Figura 1: Ejemplo para δj(i, i + 1). La Figura 1 proporciona un ejemplo conceptual para δj(i, i + 1). La clasificación inferior difiere de la superior solo cuando d¯x j sube un rango. La diferencia en el valor de H para estas dos clasificaciones es exactamente δj(i, i + 1). Para cualquier i1 < i2, podemos definir δj(i1, i2) como δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) o equivalentemente, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) . Deja que o1, . . . , o|C¯x| codifiquen las posiciones de los documentos no relevantes, donde dx oj es el documento relevante de mayor rango clasificado después del j-ésimo documento no relevante. Debido a la Observación 1, esta codificación identifica de forma única un ranking completo. Podemos recuperar la clasificación como yij = 8 >>>< >>>: 0 si i = j sign(si − sj) si di, dj relevancia igual signo(oj − i − 0.5) si di = dx i , dj = d¯x j signo(j − oi + 0.5) si di = d¯x i , dj = dx j. (7) Ahora podemos reformular H en una nueva función objetivo, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), donde ¯y es la verdadera clasificación (débil). Conceptualmente, H comienza con una clasificación perfecta ¯y y agrega el cambio en H cuando cada documento no relevante sucesivo sube en la clasificación. Luego podemos reformular el problema argmax H como argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) sujeto a o1 ≤ . . . ≤ o|C¯x|. (9) El Algoritmo 2 describe el algoritmo utilizado para resolver la ecuación (8). Conceptualmente, el Algoritmo 2 comienza con un ranking perfecto. Entonces, para cada documento no relevante sucesivo, el algoritmo modifica la solución deslizando ese documento hacia arriba en la clasificación para maximizar localmente H, manteniendo las posiciones de los otros documentos no relevantes constantes. 3.2.1 Prueba de Corrección El Algoritmo 2 es codicioso en el sentido de que encuentra la mejor posición de cada documento no relevante de forma independiente de los otros documentos no relevantes. En otras palabras, el algoritmo maximiza H para cada documento no relevante, d¯x j, Algoritmo 2 Encontrar la Restricción Más Violada (argmax H) para el Algoritmo 1 con ∆map 1: Entrada: w, Cx, C¯x 2: ordenar Cx y C¯x en orden descendente de wT φ(x, d) 3: sx i ← wT φ(x, dx i), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i), i = 1, . . . , |C¯x | 5: para j = 1, . . . , |C¯x | hacer 6: optj ← argmaxk δj(k, |Cx| + 1) 7: fin para 8: codificar ˆy de acuerdo con (7) 9: devolver ˆy sin considerar las posiciones de los otros documentos no relevantes, y así ignora las restricciones de (9). Para que la solución sea factible, el documento no relevante j-ésimo debe ser clasificado después de los primeros j-1 documentos no relevantes, satisfaciendo así opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. Si la solución es factible, entonces claramente resuelve (8). Por lo tanto, basta con demostrar que el Algoritmo 2 cumple con (10). Primero demostramos que δj(·, ·) es monótonamente decreciente en j. Lema 1. Para cualquier 1 ≤ i1 < i2 ≤ |Cx | + 1 y 1 ≤ j < |C¯x |, debe ser el caso que δj+1(i1, i2) ≤ δj(i1, i2). Prueba. Recuerde que tanto δj(i1, i2) como δj+1(i1, i2) son sumas de términos i2 − i1. Mostraremos que cada término en la suma de δj+1(i1, i2) no es mayor que el término correspondiente en δj(i1, i2), o δj+1(k, k + 1) ≤ δj(k, k + 1) para k = i1, . . . , i2 − 1. Cada término en δj(k, k +1) y δj+1(k, k +1) puede ser descompuesto aún más en dos partes (ver (5)). Mostraremos que cada parte de δj+1(k, k + 1) no es mayor que la parte correspondiente en δj(k, k + 1). En otras palabras, demostraremos que tanto j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) como −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) son verdaderos para los valores mencionados de j y k. Es fácil ver que (11) es verdadero observando que para cualquier par de enteros positivos 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1, y eligiendo a = j y b = j + k. La segunda desigualdad (12) se cumple porque el Algoritmo 2 primero ordena d¯x en orden descendente de s¯x, lo que implica s¯x j+1 ≤ s¯x j. Así vemos que cada término en δj+1 no es mayor que el término correspondiente en δj, lo cual completa la prueba. El resultado del Lema 1 conduce directamente a nuestro resultado principal de corrección: Teorema 2. En el Algoritmo 2, los valores calculados de optj satisfacen (10), lo que implica que la solución devuelta por el Algoritmo 2 es factible y, por lo tanto, óptima. Prueba. Demostraremos que optj ≤ optj+1 se cumple para cualquier 1 ≤ j < |C¯x|, implicando así (10). Dado que el Algoritmo 2 calcula optj como optj = argmax k δj(k, |Cx | + 1), (13), entonces por definición de δj (6), para cualquier 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0. Usando el Lema 1, sabemos que δj+1(i, optj) ≤ δj(i, optj) < 0, lo que implica que para cualquier 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0. Supongamos por contradicción que optj+1 < optj. Entonces δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), lo cual contradice (13). Por lo tanto, debe ser el caso que optj ≤ optj+1, lo cual completa la prueba. 3.2.2 Tiempo de ejecución El tiempo de ejecución del Algoritmo 2 se puede dividir en dos partes. La primera parte es la clasificación por wT φ(x, d), lo cual requiere un tiempo de O(n log n), donde n = |Cx | + |C¯x |. La segunda parte calcula cada optj, lo cual requiere un tiempo de O(|Cx| · |C¯x|). Aunque en el peor de los casos esto es O(n2), el número de documentos relevantes, |Cx|, suele ser muy pequeño (por ejemplo, constante con respecto a n), en cuyo caso el tiempo de ejecución para la segunda parte es simplemente O(n). Para la mayoría de los conjuntos de datos del mundo real, el Algoritmo 2 está dominado por la ordenación y tiene una complejidad O(n log n). El Algoritmo 1 está garantizado de detenerse en un número polinómico de iteraciones [19], y cada iteración ejecuta el Algoritmo 2. Prácticamente todos los modelos que funcionaron bien fueron entrenados en un tiempo razonable (generalmente menos de una hora). Una vez que el entrenamiento esté completo, hacer predicciones sobre la consulta x usando la hipótesis resultante h(x|w) solo requiere ordenar por wT φ(x, d). Desarrollamos nuestro software utilizando una interfaz de Python a SVMstruct, ya que el lenguaje Python simplificó en gran medida el proceso de codificación. Para mejorar el rendimiento, es recomendable utilizar la implementación estándar en C de SVMstruct. CONFIGURACIÓN DEL EXPERIMENTO El objetivo principal de nuestros experimentos es evaluar si la optimización directa de MAP conduce a un rendimiento de MAP mejorado en comparación con los métodos convencionales de SVM que optimizan una pérdida sustituta como la precisión o el área bajo la curva ROC. Evaluamos empíricamente nuestro método utilizando dos conjuntos de consultas de la TREC Web Track, uno de TREC 9 y otro de TREC 10 (temas 451-500 y 501-550), ambos de los cuales utilizaron el corpus WT10g. Para cada consulta, TREC proporciona las evaluaciones de relevancia de los documentos. Generamos nuestras características utilizando las puntuaciones de las funciones de recuperación existentes en estas consultas. Si bien nuestro método es agnóstico al significado de las características, elegimos utilizar funciones de recuperación existentes como una forma simple pero efectiva de adquirir características útiles. Por lo tanto, nuestros experimentos de estadísticas de conjuntos de datos básicos esencialmente prueban la capacidad de nuestros métodos para volver a clasificar los documentos altamente clasificados (por ejemplo, volver a combinar las puntuaciones de las funciones de recuperación) para mejorar el MAP. Comparamos nuestro método con las mejores funciones de recuperación entrenadas (en adelante, funciones base), así como con los métodos SVM propuestos anteriormente. Comparar con las mejores funciones base pone a prueba la capacidad de nuestros métodos para aprender una combinación útil. Comparar con métodos SVM anteriores nos permite probar si optimizar directamente para el MAP (en lugar de precisión o área bajo la curva ROC) logra una puntuación de MAP más alta en la práctica. El resto de esta sección describe las funciones base y el método de generación de características en detalle. 4.1 Elección de Funciones de Recuperación Elegimos dos conjuntos de funciones base para nuestros experimentos. Para el primer conjunto, generamos tres índices sobre el corpus WT10g utilizando Indri5. El primer índice fue generado utilizando la configuración predeterminada, el segundo utilizó Porter-stemming, y el último utilizó Porter-stemming y las palabras vacías predeterminadas de Indris. Para TREC 9 y TREC 10, utilizamos la parte de descripción de cada consulta y puntuamos los documentos utilizando cinco de los métodos de recuperación integrados en Indri, que son Similitud Coseno, TFIDF, Okapi, Modelo de Lenguaje con Prior de Dirichlet y Modelo de Lenguaje con Prior de Jelinek-Mercer. Todos los parámetros se mantuvieron en sus valores predeterminados. Calculamos las puntuaciones de estos cinco métodos de recuperación sobre los tres índices, dando un total de 15 funciones base. Para cada consulta, consideramos las puntuaciones de los documentos encontrados en la unión de los mejores 1000 documentos de cada función base. Para nuestro segundo conjunto de funciones base, utilizamos puntuaciones de las presentaciones de la pista web TREC 9 [8] y TREC 10 [9]. Utilizamos solo las presentaciones no manuales y no breves de ambos años. Para TREC 9 y TREC 10, hubo 53 y 18 envíos de este tipo, respectivamente. Una presentación típica contenía puntajes de sus 1000 documentos principales. b ca wT φ(x,d) f(d|x) Figura 2: Ejemplo de Agrupación de Características 4.2 Generación de Características Para generar ejemplos de entrada para nuestro método, se debe proporcionar una instancia concreta de φ. Para cada documento d puntuado por un conjunto de funciones de recuperación F en la consulta x, generamos las características como un vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf, donde f(d|x) denota la puntuación que la función de recuperación f asigna al documento d para la consulta x, y cada Kf es un conjunto de valores reales. Desde un nivel alto, estamos expresando la puntuación de cada función de recuperación utilizando |Kf | + 1 contenedores. Dado que estamos utilizando núcleos lineales, se puede pensar en el problema de aprendizaje como encontrar una buena combinación de piezas constantes de los puntajes de las funciones de recuperación. La Figura 2 muestra un ejemplo de nuestro método de mapeo de características. En este ejemplo tenemos una única característica F = {f}. Aquí, Kf = {a, b, c}, y el vector de pesos es w = wa, wb, wc. Para cualquier documento d y consulta x, tenemos wT φ(x, d) = 8 >>< >>: 0 si f(d|x) < a wa si a ≤ f(d|x) < b wa + wb si b ≤ f(d|x) < c wa + wb + wc si c ≤ f(d|x) . Esto se expresa cualitativamente en la Figura 2, donde wa y wb son positivos, y wc es negativo. Realizamos nuestros experimentos principales utilizando cuatro opciones de F: el conjunto de las funciones de recuperación de Indri mencionadas anteriormente para TREC 9 y TREC 10, y las presentaciones de la pista web para TREC 9 y TREC 10. Para cada F y cada función f ∈ F, elegimos 50 valores para Kf que estuvieran razonablemente espaciados y capturaran la región sensible de f. Utilizando las cuatro opciones de F, generamos cuatro conjuntos de datos para nuestros experimentos principales. La Tabla 5 contiene estadísticas de los conjuntos de datos generados. Hay muchas formas de generar características, y no estamos abogando por nuestro método sobre los demás. Esto fue simplemente un medio eficiente para normalizar las salidas de diferentes funciones y permitir un modelo más expresivo. EXPERIMENTOS Para cada conjunto de datos en la Tabla 5, realizamos 50 pruebas. Para cada prueba, entrenamos con 10 consultas seleccionadas al azar, y seleccionamos otras 5 consultas al azar para un conjunto de validación. Los modelos fueron entrenados utilizando una amplia gama de valores de C. El modelo que tuvo mejor rendimiento en el conjunto de validación fue seleccionado y probado en las 35 consultas restantes. Todas las consultas fueron seleccionadas para estar en los conjuntos de entrenamiento, validación y prueba la misma cantidad de veces. Utilizando esta configuración, realizamos los mismos experimentos mientras usábamos nuestro método (mapa SVM∆), un SVM optimizando para ROCArea (SVM∆ roc) [13], y un SVM de clasificación convencional (SVMacc) [20]. Todos los métodos de SVM utilizaron un kernel lineal. Informamos sobre el rendimiento promedio de todos los modelos en las 50 pruebas. 5.1 Comparación con Funciones Base Al analizar nuestros resultados, la primera pregunta a responder es, ¿puede SVM∆ map aprender un modelo que supere al mejor modelo base TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.290 - 0.287Mejor Func. 0.280 28/22 0.283 29/21 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 36/14 ** Tabla 7: Comparación con Envíos TREC TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288Mejor Func. 0.280 27/23 0.283 31/19 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 35/15 ** Tabla 8: Comparación con Funciones de Envíos TREC (sin el mejor) La Tabla 6 presenta la comparación del mapa SVM∆ con las mejores funciones base de Indri. Cada grupo de columnas contiene el rendimiento del MAP macro-promediado de SVM∆ map o una función base. Las columnas W/L muestran el número de consultas donde SVM∆ map logró un puntaje MAP más alto. Se realizaron pruebas de significancia utilizando la prueba de rango con signo de Wilcoxon de dos colas. Dos estrellas indican un nivel de significancia de 0.95. Todas las tablas que muestran nuestros resultados experimentales están estructuradas de manera idéntica. Aquí encontramos que SVM∆ mapea significativamente mejor que las mejores funciones base. La Tabla 7 muestra la comparación cuando se entrena con las presentaciones de TREC. Si bien logra una puntuación de MAP más alta que las mejores funciones base, la diferencia de rendimiento entre SVM∆ y las funciones base no es significativa. Dado que muchas de estas presentaciones utilizan funciones de puntuación cuidadosamente diseñadas para lograr un alto MAP, es posible que las presentaciones con mejor rendimiento utilicen técnicas que engloben las técnicas de las otras presentaciones. Como resultado, el mapa SVM∆ no sería capaz de aprender una hipótesis que pueda superar significativamente la mejor presentación. Por lo tanto, realizamos los mismos experimentos utilizando un conjunto de datos modificado en el que se eliminaron las características calculadas utilizando la mejor presentación. La tabla 8 muestra los resultados (ten en cuenta que aún estamos comparando con la mejor presentación, aunque no la estamos utilizando para el entrenamiento). Observa que si bien el rendimiento del SVM∆ map se degradó ligeramente, aún era comparable con el de la mejor presentación. 5.2 Comparación con Métodos SVM Anteriores La siguiente pregunta a responder es, ¿produce el SVM∆ map puntajes MAP más altos que los métodos SVM anteriores? Las tablas 9 y 10 presentan los resultados de SVM∆ map, SVM∆ roc y SVMacc cuando se entrenan con las funciones de recuperación de Indri y las presentaciones de TREC, respectivamente. La Tabla 11 contiene los resultados correspondientes cuando se entrena con las presentaciones de TREC sin la mejor presentación. Para empezar, nuestros resultados indican que SVMacc no fue competitivo con SVM∆ map y SVM∆ roc, y a veces tuvo un rendimiento notablemente inferior. Por lo tanto, probamos varios enfoques para mejorar el rendimiento de SVMacc. 5.2.1 Métodos alternativos de SVMacc Un problema que puede causar que SVMacc tenga un rendimiento deficiente es el desequilibrio severo entre documentos relevantes y no relevantes. La gran mayoría de los documentos no son relevantes. SVMacc2 aborda este problema asignando una penalización mayor a los errores de falsos negativos. Para cada conjunto de datos, la proporción de las penalizaciones por falsos negativos a falsos positivos es igual a la proporción entre el número de documentos no relevantes y relevantes en ese conjunto de datos. Las tablas 9, 10 y 11 indican que SVMacc2 sigue teniendo un rendimiento significativamente peor que SVM∆ map. Otro posible problema es que SVMacc intenta encontrar solo un umbral discriminatorio b que sea invariable a la consulta. Puede ser que diferentes consultas requieran diferentes valores de b. Tener el método de aprendizaje intentando encontrar un buen valor de b (cuando no existe) puede ser perjudicial. Tomamos dos enfoques para abordar este problema. El primer método, SVMacc3, convierte las puntuaciones de la función de recuperación en percentiles. Por ejemplo, para el documento d, la consulta q y la función de recuperación f, si la puntuación f(d|q) se encuentra en el 90% superior de las puntuaciones f(·|q) para la consulta q, entonces la puntuación convertida es f(d|q) = 0.9. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Las tablas 9, 10 y 11 muestran que el rendimiento de SVMacc3 tampoco fue competitivo con SVM∆ map. El segundo método, SVMacc4, normaliza las puntuaciones dadas por f para cada consulta. Por ejemplo, suponga para la consulta q que f produce puntuaciones en el rango de 0.2 a 0.7. Entonces, para el documento d, si f(d|q) = 0.6, la puntuación convertida sería f(d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Nuevamente, las Tablas 9, 10 y 11 muestran que SVMacc4 no fue competitivo con SVM∆ map 5.2.2 MAP vs ROCArea. SVM∆ roc tuvo un rendimiento mucho mejor que SVMacc en nuestros experimentos. Cuando se entrenó con las funciones de recuperación de Indri (ver Tabla 9), el rendimiento de SVM∆ roc fue ligeramente, aunque no significativamente, peor que el rendimiento de SVM∆ map. Sin embargo, la Tabla 10 muestra que el mapa SVM∆ superó significativamente al roc SVM∆ cuando se entrenó con las presentaciones de TREC. La tabla 11 muestra el rendimiento de los modelos cuando se entrenan con las presentaciones de TREC y se elimina la mejor presentación. El rendimiento de la mayoría de los modelos se degradó ligeramente, con SVM∆ map aún teniendo el mejor rendimiento. TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288 SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Tabla 11: Entrenado en TREC Subm. (sin Mejor) 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado un método SVM que optimiza directamente el MAP. Proporciona un enfoque basado en principios y evita heurísticas difíciles de controlar. Formulamos el problema de optimización y presentamos un algoritmo que encuentra la solución de manera demostrable en tiempo polinómico. Hemos demostrado empíricamente que nuestro método es generalmente superior o competitivo con los métodos convencionales de SVM. Nuestro nuevo método hace que sea conceptualmente tan fácil optimizar SVMs para MAP como anteriormente solo era posible para Precisión y Área bajo la curva ROC. El costo computacional para el entrenamiento es muy razonable en la práctica. Dado que otros métodos suelen requerir ajustar múltiples heurísticas, también esperamos entrenar menos modelos antes de encontrar uno que logre un buen rendimiento. El marco de aprendizaje utilizado por nuestro método es bastante general. Una extensión natural de este marco sería desarrollar métodos para optimizar otras medidas importantes de IR, como la Ganancia Acumulada Normalizada Descontada [2, 3, 4, 12] y la Reciprocidad Media de Rango. 7. AGRADECIMIENTOS Este trabajo fue financiado bajo el Premio NSF IIS-0412894, el Premio NSF CAREER 0237381 y un obsequio de Yahoo! Investigación. El tercer autor también fue parcialmente apoyado por una Beca de Investigación de Microsoft. 8. REFERENCIAS [1] B. T. Bartell, G. W. Cottrell y R. K. Belew. Combinación automática de múltiples sistemas de recuperación clasificados. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2005. [3] C. J. C. Burges, R. Ragno y Q. Lo. Aprendizaje para clasificar con funciones de costo no suaves. En Actas de la Conferencia Internacional sobre Avances en Sistemas de Información Neural (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang y H.-W. Hon. Adaptando el SVM de clasificación para la recuperación de documentos. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [5] B. Carterette y D. Petkova. Aprendiendo un ranking a partir de preferencias por pares. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew y A. Ksikes. Selección de conjunto de bibliotecas de modelos. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [7] J. Davis y M. Goadrich. La relación entre las curvas de precisión-recall y ROC. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2006. [8] D. Hawking. Resumen de la pista web TREC-9. En Actas de TREC-2000, 2000. [9] D. Hawking y N. Craswell. Resumen de la pista web TREC-2001. En Actas de TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel y K. Obermayer. Límites de rango de margen amplio para regresión ordinal. Avances en clasificadores de márgenes amplios, 2000. [11] A. Herschtal y B. Raskutti. Optimizando el área bajo la curva ROC utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [12] K. Jarvelin y J. Kekalainen. Métodos de evaluación para recuperar documentos altamente relevantes. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2000. [13] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), páginas 377-384, Nueva York, NY, EE. UU., 2005. ACM Press. [14] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), páginas 111-119, 2001. [15] Y. Lin, Y. Lee y G. Wahba. Máquinas de vectores de soporte para clasificación en situaciones no estándar. Aprendizaje automático, 46:191-202, 2002. [16] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [17] K. Morik, P. Brockhausen y T. Joachims. Combinando el aprendizaje estadístico con un enfoque basado en el conocimiento. En Actas de la Conferencia Internacional sobre Aprendizaje Automático, 1999. [18] S. Robertson. El principio de clasificación de probabilidad en la revista IR de documentación. Revista de Documentación, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims y Y. Altun. Métodos de margen amplio para variables de salida estructuradas e interdependientes. Revista de Investigación en Aprendizaje Automático (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik. Teoría del Aprendizaje Estadístico. Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz. \n\nWiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer y R. Wolniewicz. Optimizando el rendimiento del clasificador mediante la aproximación a la estadística de Wilcoxon-Mann-Witney. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2003. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "supervised learning": {
            "translated_key": "aprendizaje supervisado",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT Machine learning is commonly used to improve ranked retrieval systems.",
                "Due to computational difficulties, few learning techniques have been developed to directly optimize for mean average precision (MAP), despite its widespread use in evaluating such systems.",
                "Existing approaches optimizing MAP either do not find a globally optimal solution, or are computationally expensive.",
                "In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of MAP.",
                "We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora (WT10g), comparing against SVMs optimized for accuracy and ROCArea.",
                "In most cases we show our method to produce statistically significant improvements in MAP scores.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval Models General Terms Algorithm, Theory, Experimentation 1.",
                "INTRODUCTION State of the art information retrieval systems commonly use machine learning techniques to learn ranking functions.",
                "However, most current approaches do not optimize for the evaluation measure most often used, namely Mean Average Precision (MAP).",
                "Instead, current algorithms tend to take one of two general approaches.",
                "The first approach is to learn a model that estimates the probability of a document being relevant given a query (e.g., [18, 14]).",
                "If solved effectively, the ranking with best MAP performance can easily be derived from the probabilities of relevance.",
                "However, achieving high MAP only requires finding a good ordering of the documents.",
                "As a result, finding good probabilities requires solving a more difficult problem than necessary, likely requiring more training data to achieve the same MAP performance.",
                "The second common approach is to learn a function that maximizes a surrogate measure.",
                "Performance measures optimized include accuracy [17, 15], ROCArea [1, 5, 10, 11, 13, 21] or modifications of ROCArea [4], and NDCG [2, 3].",
                "Learning a model to optimize for such measures might result in suboptimal MAP performance.",
                "In fact, although some previous systems have obtained good MAP performance, it is known that neither achieving optimal accuracy nor ROCArea can guarantee optimal MAP performance[7].",
                "In this paper, we present a general approach for learning ranking functions that maximize MAP performance.",
                "Specifically, we present an SVM algorithm that globally optimizes a hinge-loss relaxation of MAP.",
                "This approach simplifies the process of obtaining ranking functions with high MAP performance by avoiding additional intermediate steps and heuristics.",
                "The new algorithm also makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for accuracy and ROCArea.",
                "In contrast to recent work directly optimizing for MAP performance by Metzler & Croft [16] and Caruana et al. [6], our technique is computationally efficient while finding a globally optimal solution.",
                "Like [6, 16], our method learns a linear model, but is much more efficient in practice and, unlike [16], can handle many thousands of features.",
                "We now describe the algorithm in detail and provide proof of correctness.",
                "Following this, we provide an analysis of running time.",
                "We finish with empirical results from experiments on the TREC 9 and TREC 10 Web Track corpus.",
                "We have also developed a software package implementing our algorithm that is available for public use1 . 2.",
                "THE LEARNING PROBLEM Following the standard machine learning setup, our goal is to learn a function h : X → Y between an input space X (all possible queries) and output space Y (rankings over a corpus).",
                "In order to quantify the quality of a prediction, ˆy = h(x), we will consider a loss function ∆ : Y × Y → . ∆(y, ˆy) quantifies the penalty for making prediction ˆy if the correct output is y.",
                "The loss function allows us to incorporate specific performance measures, which we will exploit 1 http://svmrank.yisongyue.com for optimizing MAP.",
                "We restrict ourselves to the <br>supervised learning</br> scenario, where input/output pairs (x, y) are available for training and are assumed to come from some fixed distribution P(x, y).",
                "The goal is to find a function h such that the risk (i.e., expected loss), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), is minimized.",
                "Of course, P(x, y) is unknown.",
                "But given a finite set of training pairs, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, the performance of h on S can be measured by the empirical risk, R∆ S (h) = 1 n nX i=1 ∆(yi, h(xi)).",
                "In the case of learning a ranked retrieval function, X denotes a space of queries, and Y the space of (possibly weak) rankings over some corpus of documents C = {d1, . . . ,d|C|}.",
                "We can define average precision loss as ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), where rank(y) is a vector of the rank values of each document in C. For example, for a corpus of two documents, {d1, d2}, with d1 having higher rank than d2, rank(y ) = (1, 0).",
                "We assume true rankings have two rank values, where relevant documents have rank value 1 and non-relevant documents rank value 0.",
                "We further assume that all predicted rankings are complete rankings (no ties).",
                "Let p = rank(y) and ˆp = rank(ˆy).",
                "The average precision score is defined as MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, where rel = |{i : pi = 1}| is the number of relevant documents, and Prec@j is the percentage of relevant documents in the top j documents in predicted ranking ˆy.",
                "MAP is the mean of the average precision scores of a group of queries. 2.1 MAP vs ROCArea Most learning algorithms optimize for accuracy or ROCArea.",
                "While optimizing for these measures might achieve good MAP performance, we use two simple examples to show it can also be suboptimal in terms of MAP.",
                "ROCArea assigns equal penalty to each misordering of a relevant/non-relevant pair.",
                "In contrast, MAP assigns greater penalties to misorderings higher up in the predicted ranking.",
                "Using our notation, ROCArea can be defined as ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], where p is the true (weak) ranking, ˆp is the predicted ranking, and 1[b] is the indicator function conditioned on b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Table 1: Toy Example and Models Suppose we have a hypothesis space with only two hypothesis functions, h1 and h2, as shown in Table 1.",
                "These two hypotheses predict a ranking for query x over a corpus of eight documents.",
                "Hypothesis MAP ROCArea h1(x) 0.59 0.47 h2(x) 0.51 0.53 Table 2: Performance of Toy Models Table 2 shows the MAP and ROCArea scores of h1 and h2.",
                "Here, a learning method which optimizes for ROCArea would choose h2 since that results in a higher ROCArea score, but this yields a suboptimal MAP score. 2.2 MAP vs Accuracy Using a very similar example, we now demonstrate how optimizing for accuracy might result in suboptimal MAP.",
                "Models which optimize for accuracy are not directly concerned with the ranking.",
                "Instead, they learn a threshold such that documents scoring higher than the threshold can be classified as relevant and documents scoring lower as nonrelevant.",
                "Doc ID 1 2 3 4 5 6 7 8 9 10 11 p 1 0 0 0 0 1 1 1 1 0 0 rank(h1(x)) 11 10 9 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 9 10 11 Table 3: Toy Example and Models We consider again a hypothesis space with two hypotheses.",
                "Table 3 shows the predictions of the two hypotheses on a single query x. Hypothesis MAP Best Acc. h1(q) 0.70 0.64 h2(q) 0.64 0.73 Table 4: Performance of Toy Models Table 4 shows the MAP and best accuracy scores of h1(q) and h2(q).",
                "The best accuracy refers to the highest achievable accuracy on that ranking when considering all possible thresholds.",
                "For instance, with h1(q), a threshold between documents 1 and 2 gives 4 errors (documents 6-9 incorrectly classified as non-relevant), yielding an accuracy of 0.64.",
                "Similarly, with h2(q), a threshold between documents 5 and 6 gives 3 errors (documents 10-11 incorrectly classified as relevant, and document 1 as non-relevant), yielding an accuracy of 0.73.",
                "A learning method which optimizes for accuracy would choose h2 since that results in a higher accuracy score, but this yields a suboptimal MAP score. 3.",
                "OPTIMIZING AVERAGE PRECISION We build upon the approach used by [13] for optimizing ROCArea.",
                "Unlike ROCArea, however, MAP does not decompose linearly in the examples and requires a substantially extended algorithm, which we describe in this section.",
                "Recall that the true ranking is a weak ranking with two rank values (relevant and non-relevant).",
                "Let Cx and C¯x denote the set of relevant and non-relevant documents of C for query x, respectively.",
                "We focus on functions which are parametrized by a weight vector w, and thus wish to find w to minimize the empirical risk, R∆ S (w) ≡ R∆ S (h(·; w)).",
                "Our approach is to learn a discriminant function F : X × Y → over input-output pairs.",
                "Given query x, we can derive a prediction by finding the ranking y that maximizes the discriminant function: h(x; w) = argmax y∈Y F(x, y; w). (1) We assume F to be linear in some combined feature representation of inputs and outputs Ψ(x, y) ∈ RN , i.e., F(x, y; w) = wT Ψ(x, y). (2) The combined feature function we use is Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))] , where φ : X × C → N is a feature mapping function from a query/document pair to a point in N dimensional space2 .",
                "We represent rankings as a matrix of pairwise orderings, Y ⊂ {−1, 0, +1}|C|×|C| .",
                "For any y ∈ Y, yij = +1 if di is ranked ahead of dj, and yij = −1 if dj is ranked ahead of di, and yij = 0 if di and dj have equal rank.",
                "We consider only matrices which correspond to valid rankings (i.e, obeying antisymmetry and transitivity).",
                "Intuitively, Ψ is a summation over the vector differences of all relevant/non-relevant document pairings.",
                "Since we assume predicted rankings to be complete rankings, yij is either +1 or −1 (never 0).",
                "Given a learned weight vector w, predicting a ranking (i.e. solving equation (1)) given query x reduces to picking each yij to maximize wT Ψ(x, y).",
                "As is also discussed in [13], this is attained by sorting the documents by wT φ(x, d) in descending order.",
                "We will discuss later the choices of φ we used for our experiments. 3.1 Structural SVMs The above formulation is very similar to learning a straightforward linear model while training on the pairwise difference of relevant/non-relevant document pairings.",
                "Many SVM-based approaches optimize over these pairwise differences (e.g., [5, 10, 13, 4]), although these methods do not optimize for MAP during training.",
                "Previously, it was not clear how to incorporate non-linear multivariate loss functions such as MAP loss directly into global optimization problems such as SVM training.",
                "We now present a method based on structural SVMs [19] to address this problem.",
                "We use the structural SVM formulation, presented in Optimization Problem 1, to learn a w ∈ RN .",
                "Optimization Problem 1. (Structural SVM) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) The objective function to be minimized (3) is a tradeoff between model complexity, w 2 , and a hinge loss relaxation of MAP loss, P ξi.",
                "As is usual in SVM training, C is a 2 For example, one dimension might be the number of times the query words appear in the document.",
                "Algorithm 1 Cutting plane algorithm for solving OP 1 within tolerance . 1: Input: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ for all i = 1, . . . , n 3: repeat 4: for i = 1, . . . , n do 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: compute ˆy = argmaxy∈Y H(y; w) 7: compute ξi = max{0, maxy∈Wi H(y; w)} 8: if H(ˆy; w) > ξi + then 9: Wi ← Wi ∪ {ˆy} 10: w ← optimize (3) over W = S i Wi 11: end if 12: end for 13: until no Wi has changed during iteration parameter that controls this tradeoff and can be tuned to achieve good performance in different training tasks.",
                "For each (xi, yi) in the training set, a set of constraints of the form in equation (4) is added to the optimization problem.",
                "Note that wT Ψ(x, y) is exactly our discriminant function F(x, y; w) (see equation (2)).",
                "During prediction, our model chooses the ranking which maximizes the discriminant (1).",
                "If the discriminant value for an incorrect ranking y is greater than for the true ranking yi (e.g., F(xi, y; w) > F(xi, yi; w)), then corresponding slack variable, ξi, must be at least ∆(yi, y) for that constraint to be satisfied.",
                "Therefore, the sum of slacks, P ξi, upper bounds the MAP loss.",
                "This is stated formally in Proposition 1.",
                "Proposition 1.",
                "Let ξ∗ (w) be the optimal solution of the slack variables for OP 1 for a given weight vector w. Then 1 n Pn i=1 ξi is an upper bound on the empirical risk R∆ S (w). (see [19] for proof) Proposition 1 shows that OP 1 learns a ranking function that optimizes an upper bound on MAP error on the training set.",
                "Unfortunately there is a problem: a constraint is required for every possible wrong output y, and the number of possible wrong outputs is exponential in the size of C. Fortunately, we may employ Algorithm 1 to solve OP 1.",
                "Algorithm 1 is a cutting plane algorithm, iteratively introducing constraints until we have solved the original problem within a desired tolerance [19].",
                "The algorithm starts with no constraints, and iteratively finds for each example (xi, yi) the output ˆy associated with the most violated constraint.",
                "If the corresponding constraint is violated by more than we introduce ˆy into the working set Wi of active constraints for example i, and re-solve (3) using the updated W. It can be shown that Algorithm 1s outer loop is guaranteed to halt within a polynomial number of iterations for any desired precision .",
                "Theorem 1.",
                "Let ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y) , ¯∆ = maxi maxy ∆(yi, y), and for any > 0, Algorithm 1 terminates after adding at most max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff constraints to the working set W. (see [19] for proof) However, within the inner loop of this algorithm we have to compute argmaxy∈Y H(y; w), where H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), or equivalently, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), since wT Ψ(xi, yi) is constant with respect to y.",
                "Though closely related to the classification procedure, this has the substantial complication that we must contend with the additional ∆(yi, y) term.",
                "Without the ability to efficiently find the most violated constraint (i.e., solve argmaxy∈Y H(y, w)), the constraint generation procedure is not tractable. 3.2 Finding the Most Violated Constraint Using OP 1 and optimizing to ROCArea loss (∆roc), the problem of finding the most violated constraint, or solving argmaxy∈Y H(y, w) (henceforth argmax H), is addressed in [13].",
                "Solving argmax H for ∆map is more difficult.",
                "This is primarily because ROCArea decomposes nicely into a sum of scores computed independently on each relative ordering of a relevant/non-relevant document pair.",
                "MAP, on the other hand, does not decompose in the same way as ROCArea.",
                "The main algorithmic contribution of this paper is an efficient method for solving argmax H for ∆map.",
                "One useful property of ∆map is that it is invariant to swapping two documents with equal relevance.",
                "For example, if documents da and db are both relevant, then swapping the positions of da and db in any ranking does not affect ∆map.",
                "By extension, ∆map is invariant to any arbitrary permutation of the relevant documents amongst themselves and of the non-relevant documents amongst themselves.",
                "However, this reshuﬄing will affect the discriminant score, wT Ψ(x, y).",
                "This leads us to Observation 1.",
                "Observation 1.",
                "Consider rankings which are constrained by fixing the relevance at each position in the ranking (e.g., the 3rd document in the ranking must be relevant).",
                "Every ranking which satisfies the same set of constraints will have the same ∆map.",
                "If the relevant documents are sorted by wT φ(x, d) in descending order, and the non-relevant documents are likewise sorted by wT φ(x, d), then the interleaving of the two sorted lists which satisfies the constraints will maximize H for that constrained set of rankings.",
                "Observation 1 implies that in the ranking which maximizes H, the relevant documents will be sorted by wT φ(x, d), and the non-relevant documents will also be sorted likewise.",
                "By first sorting the relevant and non-relevant documents, the problem is simplified to finding the optimal interleaving of two sorted lists.",
                "For the rest of our discussion, we assume that the relevant documents and non-relevant documents are both sorted by descending wT φ(x, d).",
                "For convenience, we also refer to relevant documents as {dx 1 , . . . dx |Cx|} = Cx , and non-relevant documents as {d¯x 1 , . . . d¯x |C¯x|} = C¯x .",
                "We define δj(i1, i2), with i1 < i2, as the change in H from when the highest ranked relevant document ranked after d¯x j is dx i1 to when it is dx i2 .",
                "For i2 = i1 + 1, we have δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5) where si = wT φ(x, di).",
                "The first term in (5) is the change in ∆map when the ith relevant document has j non-relevant documents ranked before it, as opposed to j −1.",
                "The second term is the change in the discriminant score, wT Ψ(x, y), when yij changes from +1 to −1. . . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . .",
                "Figure 1: Example for δj(i, i + 1) Figure 1 gives a conceptual example for δj(i, i + 1).",
                "The bottom ranking differs from the top only where d¯x j slides up one rank.",
                "The difference in the value of H for these two rankings is exactly δj(i, i + 1).",
                "For any i1 < i2, we can then define δj(i1, i2) as δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) or equivalently, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) .",
                "Let o1, . . . , o|C¯x| encode the positions of the non-relevant documents, where dx oj is the highest ranked relevant document ranked after the jth non-relevant document.",
                "Due to Observation 1, this encoding uniquely identifies a complete ranking.",
                "We can recover the ranking as yij = 8 >>>< >>>: 0 if i = j sign(si − sj) if di, dj equal relevance sign(oj − i − 0.5) if di = dx i , dj = d¯x j sign(j − oi + 0.5) if di = d¯x i , dj = dx j . (7) We can now reformulate H into a new objective function, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), where ¯y is the true (weak) ranking.",
                "Conceptually H starts with a perfect ranking ¯y, and adds the change in H when each successive non-relevant document slides up the ranking.",
                "We can then reformulate the argmax H problem as argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) s.t. o1 ≤ . . . ≤ o|C¯x|. (9) Algorithm 2 describes the algorithm used to solve equation (8).",
                "Conceptually, Algorithm 2 starts with a perfect ranking.",
                "Then for each successive non-relevant document, the algorithm modifies the solution by sliding that document up the ranking to locally maximize H while keeping the positions of the other non-relevant documents constant. 3.2.1 Proof of Correctness Algorithm 2 is greedy in the sense that it finds the best position of each non-relevant document independently from the other non-relevant documents.",
                "In other words, the algorithm maximizes H for each non-relevant document, d¯x j , Algorithm 2 Finding the Most Violated Constraint (argmax H) for Algorithm 1 with ∆map 1: Input: w, Cx , C¯x 2: sort Cx and C¯x in descending order of wT φ(x, d) 3: sx i ← wT φ(x, dx i ), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i ), i = 1, . . . , |C¯x | 5: for j = 1, . . . , |C¯x | do 6: optj ← argmaxk δj(k, |Cx | + 1) 7: end for 8: encode ˆy according to (7) 9: return ˆy without considering the positions of the other non-relevant documents, and thus ignores the constraints of (9).",
                "In order for the solution to be feasible, the jth non-relevant document must be ranked after the first j − 1 non-relevant documents, thus satisfying opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. (10) If the solution is feasible, the it clearly solves (8).",
                "Therefore, it suffices to prove that Algorithm 2 satisfies (10).",
                "We first prove that δj(·, ·) is monotonically decreasing in j. Lemma 1.",
                "For any 1 ≤ i1 < i2 ≤ |Cx | + 1 and 1 ≤ j < |C¯x |, it must be the case that δj+1(i1, i2) ≤ δj(i1, i2).",
                "Proof.",
                "Recall from (6) that both δj(i1, i2) and δj+1(i1, i2) are summations of i2 − i1 terms.",
                "We will show that each term in the summation of δj+1(i1, i2) is no greater than the corresponding term in δj(i1, i2), or δj+1(k, k + 1) ≤ δj(k, k + 1) for k = i1, . . . , i2 − 1.",
                "Each term in δj(k, k +1) and δj+1(k, k +1) can be further decomposed into two parts (see (5)).",
                "We will show that each part of δj+1(k, k + 1) is no greater than the corresponding part in δj(k, k + 1).",
                "In other words, we will show that both j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) and −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) are true for the aforementioned values of j and k. It is easy to see that (11) is true by observing that for any two positive integers 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1 , and choosing a = j and b = j + k. The second inequality (12) holds because Algorithm 2 first sorts d¯x in descending order of s¯x , implying s¯x j+1 ≤ s¯x j .",
                "Thus we see that each term in δj+1 is no greater than the corresponding term in δj, which completes the proof.",
                "The result of Lemma 1 leads directly to our main correctness result: Theorem 2.",
                "In Algorithm 2, the computed values of optj satisfy (10), implying that the solution returned by Algorithm 2 is feasible and thus optimal.",
                "Proof.",
                "We will prove that optj ≤ optj+1 holds for any 1 ≤ j < |C¯x |, thus implying (10).",
                "Since Algorithm 2 computes optj as optj = argmax k δj(k, |Cx | + 1), (13) then by definition of δj (6), for any 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0.",
                "Using Lemma 1, we know that δj+1(i, optj) ≤ δj(i, optj) < 0, which implies that for any 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0.",
                "Suppose for contradiction that optj+1 < optj.",
                "Then δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), which contradicts (13).",
                "Therefore, it must be the case that optj ≤ optj+1, which completes the proof. 3.2.2 Running Time The running time of Algorithm 2 can be split into two parts.",
                "The first part is the sort by wT φ(x, d), which requires O(n log n) time, where n = |Cx | + |C¯x |.",
                "The second part computes each optj, which requires O(|Cx | · |C¯x |) time.",
                "Though in the worst case this is O(n2 ), the number of relevant documents, |Cx |, is often very small (e.g., constant with respect to n), in which case the running time for the second part is simply O(n).",
                "For most real-world datasets, Algorithm 2 is dominated by the sort and has complexity O(n log n).",
                "Algorithm 1 is guaranteed to halt in a polynomial number of iterations [19], and each iteration runs Algorithm 2.",
                "Virtually all well-performing models were trained in a reasonable amount of time (usually less than one hour).",
                "Once training is complete, making predictions on query x using the resulting hypothesis h(x|w) requires only sorting by wT φ(x, d).",
                "We developed our software using a Python interface3 to SVMstruct , since the Python language greatly simplified the coding process.",
                "To improve performance, it is advisable to use the standard C implementation4 of SVMstruct . 4.",
                "EXPERIMENT SETUP The main goal of our experiments is to evaluate whether directly optimizing MAP leads to improved MAP performance compared to conventional SVM methods that optimize a substitute loss such as accuracy or ROCArea.",
                "We empirically evaluate our method using two sets of TREC Web Track queries, one each from TREC 9 and TREC 10 (topics 451-500 and 501-550), both of which used the WT10g corpus.",
                "For each query, TREC provides the relevance judgments of the documents.",
                "We generated our features using the scores of existing retrieval functions on these queries.",
                "While our method is agnostic to the meaning of the features, we chose to use existing retrieval functions as a simple yet effective way of acquiring useful features.",
                "As such, our 3 http://www.cs.cornell.edu/~tomf/svmpython/ 4 http://svmlight.joachims.org/svm_struct.html Dataset Base Funcs Features TREC 9 Indri 15 750 TREC 10 Indri 15 750 TREC 9 Submissions 53 2650 TREC 10 Submissions 18 900 Table 5: Dataset Statistics experiments essentially test our methods ability to re-rank the highly ranked documents (e.g., re-combine the scores of the retrieval functions) to improve MAP.",
                "We compare our method against the best retrieval functions trained on (henceforth base functions), as well as against previously proposed SVM methods.",
                "Comparing with the best base functions tests our methods ability to learn a useful combination.",
                "Comparing with previous SVM methods allows us to test whether optimizing directly for MAP (as opposed to accuracy or ROCArea) achieves a higher MAP score in practice.",
                "The rest of this section describes the base functions and the feature generation method in detail. 4.1 Choosing Retrieval Functions We chose two sets of base functions for our experiments.",
                "For the first set, we generated three indices over the WT10g corpus using Indri5 .",
                "The first index was generated using default settings, the second used Porter-stemming, and the last used Porter-stemming and Indris default stopwords.",
                "For both TREC 9 and TREC 10, we used the description portion of each query and scored the documents using five of Indris built-in retrieval methods, which are Cosine Similarity, TFIDF, Okapi, Language Model with Dirichlet Prior, and Language Model with Jelinek-Mercer Prior.",
                "All parameters were kept as their defaults.",
                "We computed the scores of these five retrieval methods over the three indices, giving 15 base functions in total.",
                "For each query, we considered the scores of documents found in the union of the top 1000 documents of each base function.",
                "For our second set of base functions, we used scores from the TREC 9 [8] and TREC 10 [9] Web Track submissions.",
                "We used only the non-manual, non-short submissions from both years.",
                "For TREC 9 and TREC 10, there were 53 and 18 such submissions, respectively.",
                "A typical submission contained scores of its top 1000 documents. b ca wT φ(x,d) f(d|x) Figure 2: Example Feature Binning 4.2 Generating Features In order to generate input examples for our method, a concrete instantiation of φ must be provided.",
                "For each doc5 http://www.lemurproject.org TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236Best Func. 0.204 39/11 ** 0.181 37/13 ** 2nd Best 0.199 38/12 ** 0.174 43/7 ** 3rd Best 0.188 34/16 ** 0.174 38/12 ** Table 6: Comparison with Indri Functions ument d scored by a set of retrieval functions F on query x, we generate the features as a vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf , where f(d|x) denotes the score that retrieval function f assigns to document d for query x, and each Kf is a set of real values.",
                "From a high level, we are expressing the score of each retrieval function using |Kf | + 1 bins.",
                "Since we are using linear kernels, one can think of the learning problem as finding a good piecewise-constant combination of the scores of the retrieval functions.",
                "Figure 2 shows an example of our feature mapping method.",
                "In this example we have a single feature F = {f}.",
                "Here, Kf = {a, b, c}, and the weight vector is w = wa, wb, wc .",
                "For any document d and query x, we have wT φ(x, d) = 8 >>< >>: 0 if f(d|x) < a wa if a ≤ f(d|x) < b wa + wb if b ≤ f(d|x) < c wa + wb + wc if c ≤ f(d|x) .",
                "This is expressed qualitatively in Figure 2, where wa and wb are positive, and wc is negative.",
                "We ran our main experiments using four choices of F: the set of aforementioned Indri retrieval functions for TREC 9 and TREC 10, and the Web Track submissions for TREC 9 and TREC 10.",
                "For each F and each function f ∈ F, we chose 50 values for Kf which are reasonably spaced and capture the sensitive region of f. Using the four choices of F, we generated four datasets for our main experiments.",
                "Table 5 contains statistics of the generated datasets.",
                "There are many ways to generate features, and we are not advocating our method over others.",
                "This was simply an efficient means to normalize the outputs of different functions and allow for a more expressive model. 5.",
                "EXPERIMENTS For each dataset in Table 5, we performed 50 trials.",
                "For each trial, we train on 10 randomly selected queries, and select another 5 queries at random for a validation set.",
                "Models were trained using a wide range of C values.",
                "The model which performed best on the validation set was selected and tested on the remaining 35 queries.",
                "All queries were selected to be in the training, validation and test sets the same number of times.",
                "Using this setup, we performed the same experiments while using our method (SVM∆ map), an SVM optimizing for ROCArea (SVM∆ roc) [13], and a conventional classification SVM (SVMacc) [20].",
                "All SVM methods used a linear kernel.",
                "We reported the average performance of all models over the 50 trials. 5.1 Comparison with Base Functions In analyzing our results, the first question to answer is, can SVM∆ map learn a model which outperforms the best base TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287Best Func. 0.280 28/22 0.283 29/21 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 36/14 ** Table 7: Comparison with TREC Submissions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288Best Func. 0.280 27/23 0.283 31/19 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 35/15 ** Table 8: Comparison with TREC Subm. (w/o best) functions?",
                "Table 6 presents the comparison of SVM∆ map with the best Indri base functions.",
                "Each column group contains the macro-averaged MAP performance of SVM∆ map or a base function.",
                "The W/L columns show the number of queries where SVM∆ map achieved a higher MAP score.",
                "Significance tests were performed using the two-tailed Wilcoxon signed rank test.",
                "Two stars indicate a significance level of 0.95.",
                "All tables displaying our experimental results are structured identically.",
                "Here, we find that SVM∆ map significantly outperforms the best base functions.",
                "Table 7 shows the comparison when trained on TREC submissions.",
                "While achieving a higher MAP score than the best base functions, the performance difference between SVM∆ map the base functions is not significant.",
                "Given that many of these submissions use scoring functions which are carefully crafted to achieve high MAP, it is possible that the best performing submissions use techniques which subsume the techniques of the other submissions.",
                "As a result, SVM∆ map would not be able to learn a hypothesis which can significantly out-perform the best submission.",
                "Hence, we ran the same experiments using a modified dataset where the features computed using the best submission were removed.",
                "Table 8 shows the results (note that we are still comparing against the best submission though we are not using it for training).",
                "Notice that while the performance of SVM∆ map degraded slightly, the performance was still comparable with that of the best submission. 5.2 Comparison w/ Previous SVM Methods The next question to answer is, does SVM∆ map produce higher MAP scores than previous SVM methods?",
                "Tables 9 and 10 present the results of SVM∆ map, SVM∆ roc, and SVMacc when trained on the Indri retrieval functions and TREC submissions, respectively.",
                "Table 11 contains the corresponding results when trained on the TREC submissions without the best submission.",
                "To start with, our results indicate that SVMacc was not competitive with SVM∆ map and SVM∆ roc, and at times underperformed dramatically.",
                "As such, we tried several approaches to improve the performance of SVMacc. 5.2.1 Alternate SVMacc Methods One issue which may cause SVMacc to underperform is the severe imbalance between relevant and non-relevant docTREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236SVM∆ roc 0.237 29/21 0.234 24/26 SVMacc 0.147 47/3 ** 0.155 47/3 ** SVMacc2 0.219 39/11 ** 0.207 43/7 ** SVMacc3 0.113 49/1 ** 0.153 45/5 ** SVMacc4 0.155 48/2 ** 0.155 48/2 ** Table 9: Trained on Indri Functions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287SVM∆ roc 0.282 29/21 0.278 35/15 ** SVMacc 0.213 49/1 ** 0.222 49/1 ** SVMacc2 0.270 34/16 ** 0.261 42/8 ** SVMacc3 0.133 50/0 ** 0.182 46/4 ** SVMacc4 0.233 47/3 ** 0.238 46/4 ** Table 10: Trained on TREC Submissions uments.",
                "The vast majority of the documents are not relevant.",
                "SVMacc2 addresses this problem by assigning more penalty to false negative errors.",
                "For each dataset, the ratio of the false negative to false positive penalties is equal to the ratio of the number non-relevant and relevant documents in that dataset.",
                "Tables 9, 10 and 11 indicate that SVMacc2 still performs significantly worse than SVM∆ map.",
                "Another possible issue is that SVMacc attempts to find just one discriminating threshold b that is query-invariant.",
                "It may be that different queries require different values of b.",
                "Having the learning method trying to find a good b value (when one does not exist) may be detrimental.",
                "We took two approaches to address this issue.",
                "The first method, SVMacc3, converts the retrieval function scores into percentiles.",
                "For example, for document d, query q and retrieval function f, if the score f(d|q) is in the top 90% of the scores f(·|q) for query q, then the converted score is f (d|q) = 0.9.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Tables 9, 10 and 11 show that the performance of SVMacc3 was also not competitive with SVM∆ map.",
                "The second method, SVMacc4, normalizes the scores given by f for each query.",
                "For example, assume for query q that f outputs scores in the range 0.2 to 0.7.",
                "Then for document d, if f(d|q) = 0.6, the converted score would be f (d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Again, Tables 9, 10 and 11 show that SVMacc4 was not competitive with SVM∆ map 5.2.2 MAP vs ROCArea SVM∆ roc performed much better than SVMacc in our experiments.",
                "When trained on Indri retrieval functions (see Table 9), the performance of SVM∆ roc was slight, though not significantly, worse than the performances of SVM∆ map.",
                "However, Table 10 shows that SVM∆ map did significantly outperform SVM∆ roc when trained on the TREC submissions.",
                "Table 11 shows the performance of the models when trained on the TREC submissions with the best submission removed.",
                "The performance of most models degraded by a small amount, with SVM∆ map still having the best performance.",
                "TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Table 11: Trained on TREC Subm. (w/o Best) 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented an SVM method that directly optimizes MAP.",
                "It provides a principled approach and avoids difficult to control heuristics.",
                "We formulated the optimization problem and presented an algorithm which provably finds the solution in polynomial time.",
                "We have shown empirically that our method is generally superior to or competitive with conventional SVMs methods.",
                "Our new method makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for Accuracy and ROCArea.",
                "The computational cost for training is very reasonable in practice.",
                "Since other methods typically require tuning multiple heuristics, we also expect to train fewer models before finding one which achieves good performance.",
                "The learning framework used by our method is fairly general.",
                "A natural extension of this framework would be to develop methods to optimize for other important IR measures, such as Normalized Discounted Cumulative Gain [2, 3, 4, 12] and Mean Reciprocal Rank. 7.",
                "ACKNOWLEDGMENTS This work was funded under NSF Award IIS-0412894, NSF CAREER Award 0237381, and a gift from Yahoo!",
                "Research.",
                "The third author was also partly supported by a Microsoft Research Fellowship. 8.",
                "REFERENCES [1] B. T. Bartell, G. W. Cottrell, and R. K. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2005. [3] C. J. C. Burges, R. Ragno, and Q.",
                "Le.",
                "Learning to rank with non-smooth cost functions.",
                "In Proceedings of the International Conference on Advances in Neural Information Processing Systems (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y.",
                "Liu, H. Li, Y. Huang, and H.-W. Hon.",
                "Adapting ranking SVM to document retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [5] B. Carterette and D. Petkova.",
                "Learning a ranking from pairwise preferences.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew, and A. Ksikes.",
                "Ensemble selection from libraries of models.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [7] J. Davis and M. Goadrich.",
                "The relationship between precision-recall and ROC curves.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2006. [8] D. Hawking.",
                "Overview of the TREC-9 web track.",
                "In Proceedings of TREC-2000, 2000. [9] D. Hawking and N. Craswell.",
                "Overview of the TREC-2001 web track.",
                "In Proceedings of TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel, and K. Obermayer.",
                "Large margin rank boundaries for ordinal regression.",
                "Advances in large margin classifiers, 2000. [11] A. Herschtal and B. Raskutti.",
                "Optimising area under the ROC curve using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [12] K. Jarvelin and J. Kekalainen.",
                "Ir evaluation methods for retrieving highly relevant documents.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2000. [13] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proceedings of the International Conference on Machine Learning (ICML), pages 377-384, New York, NY, USA, 2005.",
                "ACM Press. [14] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 111-119, 2001. [15] Y. Lin, Y. Lee, and G. Wahba.",
                "Support vector machines for classification in nonstandard situations.",
                "Machine Learning, 46:191-202, 2002. [16] D. Metzler and W. B. Croft.",
                "A markov random field model for term dependencies.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 472-479, 2005. [17] K. Morik, P. Brockhausen, and T. Joachims.",
                "Combining statistical learning with a knowledge-based approach.",
                "In Proceedings of the International Conference on Machine Learning, 1999. [18] S. Robertson.",
                "The probability ranking principle in ir. journal of documentation.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.",
                "Large margin methods for structured and interdependent output variables.",
                "Journal of Machine Learning Research (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik.",
                "Statistical Learning Theory.",
                "Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz.",
                "Optimizing classifier performance via approximation to the Wilcoxon-Mann-Witney statistic.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2003."
            ],
            "original_annotated_samples": [
                "We restrict ourselves to the <br>supervised learning</br> scenario, where input/output pairs (x, y) are available for training and are assumed to come from some fixed distribution P(x, y)."
            ],
            "translated_annotated_samples": [
                "Nos restringimos al escenario de <br>aprendizaje supervisado</br>, donde pares de entrada/salida (x, y) están disponibles para el entrenamiento y se asume que provienen de alguna distribución fija P(x, y)."
            ],
            "translated_text": "Un método de Vectores de Soporte para optimizar la Precisión Promedio Yisong Yue Universidad de Cornell Ithaca, NY, EE. UU. yyue@cs.cornell.edu Thomas Finley Universidad de Cornell Ithaca, NY, EE. UU. tomf@cs.cornell.edu Filip Radlinski Universidad de Cornell Ithaca, NY, EE. UU. filip@cs.cornell.edu Thorsten Joachims Universidad de Cornell Ithaca, NY, EE. UU. tj@cs.cornell.edu RESUMEN El aprendizaje automático se utiliza comúnmente para mejorar los sistemas de recuperación clasificados. Debido a dificultades computacionales, se han desarrollado pocas técnicas de aprendizaje para optimizar directamente la precisión media promedio (MAP), a pesar de su uso generalizado en la evaluación de dichos sistemas. Los enfoques existentes que optimizan el MAP no encuentran una solución óptima global o son computacionalmente costosos. Por el contrario, presentamos un algoritmo de aprendizaje SVM general que encuentra de manera eficiente una solución óptima global para una relajación directa de MAP. Evaluamos nuestro enfoque utilizando los corpus de la pista web TREC 9 y TREC 10 (WT10g), comparando con SVM optimizados para precisión y área bajo la curva ROC. En la mayoría de los casos mostramos nuestro método para producir mejoras estadísticamente significativas en las puntuaciones de MAP. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de Recuperación Términos Generales Algoritmo, Teoría, Experimentación 1. INTRODUCCIÓN Los sistemas de recuperación de información de última generación comúnmente utilizan técnicas de aprendizaje automático para aprender funciones de clasificación. Sin embargo, la mayoría de los enfoques actuales no están optimizados para la medida de evaluación más utilizada, es decir, la Precisión Promedio Media (MAP). En cambio, los algoritmos actuales tienden a seguir uno de dos enfoques generales. El primer enfoque es aprender un modelo que estime la probabilidad de que un documento sea relevante dado una consulta (por ejemplo, [18, 14]). Si se resuelve de manera efectiva, la clasificación con el mejor rendimiento de MAP puede derivarse fácilmente de las probabilidades de relevancia. Sin embargo, lograr un MAP alto solo requiere encontrar un buen ordenamiento de los documentos. Como resultado, encontrar buenas probabilidades requiere resolver un problema más difícil de lo necesario, probablemente necesitando más datos de entrenamiento para lograr el mismo rendimiento de MAP. El segundo enfoque común es aprender una función que maximice una medida sustituta. Las medidas de rendimiento optimizadas incluyen precisión [17, 15], área bajo la curva ROC [1, 5, 10, 11, 13, 21] o modificaciones del área bajo la curva ROC [4], y NDCG [2, 3]. Aprender un modelo para optimizar tales medidas podría resultar en un rendimiento de MAP subóptimo. De hecho, aunque algunos sistemas anteriores han obtenido un buen rendimiento de MAP, se sabe que ni lograr una precisión óptima ni un área bajo la curva ROC pueden garantizar un rendimiento de MAP óptimo[7]. En este artículo, presentamos un enfoque general para aprender funciones de clasificación que maximizan el rendimiento de MAP. Específicamente, presentamos un algoritmo SVM que optimiza globalmente una relajación de pérdida de bisagra de MAP. Este enfoque simplifica el proceso de obtener funciones de clasificación con un alto rendimiento de MAP al evitar pasos intermedios adicionales y heurísticas. El nuevo algoritmo también hace que sea conceptualmente tan fácil optimizar las SVM para MAP como anteriormente solo era posible para precisión y ROCArea. A diferencia del trabajo reciente que optimiza directamente el rendimiento de MAP realizado por Metzler & Croft [16] y Caruana et al. [6], nuestra técnica es eficiente computacionalmente al encontrar una solución óptima a nivel global. Al igual que [6, 16], nuestro método aprende un modelo lineal, pero es mucho más eficiente en la práctica y, a diferencia de [16], puede manejar miles de características. Ahora describimos el algoritmo en detalle y proporcionamos la prueba de corrección. A continuación, proporcionamos un análisis del tiempo de ejecución. Concluimos con los resultados empíricos de experimentos en el corpus de la pista web TREC 9 y TREC 10. También hemos desarrollado un paquete de software que implementa nuestro algoritmo y está disponible para uso público. EL PROBLEMA DEL APRENDIZAJE Siguiendo la configuración estándar del aprendizaje automático, nuestro objetivo es aprender una función h: X → Y entre un espacio de entrada X (todas las consultas posibles) y un espacio de salida Y (clasificaciones sobre un corpus). Para cuantificar la calidad de una predicción, ˆy = h(x), consideraremos una función de pérdida ∆ : Y × Y → . ∆(y, ˆy) cuantifica la penalización por hacer la predicción ˆy si la salida correcta es y. La función de pérdida nos permite incorporar medidas específicas de rendimiento, las cuales explotaremos en http://svmrank.yisongyue.com para optimizar el MAP. Nos restringimos al escenario de <br>aprendizaje supervisado</br>, donde pares de entrada/salida (x, y) están disponibles para el entrenamiento y se asume que provienen de alguna distribución fija P(x, y). El objetivo es encontrar una función h tal que el riesgo (es decir, la pérdida esperada), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), se minimice. Por supuesto, P(x, y) es desconocido. Pero dado un conjunto finito de pares de entrenamiento, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, el rendimiento de h en S puede medirse mediante el riesgo empírico, R∆ S (h) = 1 n ∑ i=1 n ∆(yi, h(xi)). En el caso de aprender una función de recuperación clasificada, X denota un espacio de consultas, y Y el espacio de clasificaciones (posiblemente débiles) sobre algún corpus de documentos C = {d1, . . . ,d|C|}. Podemos definir la pérdida de precisión promedio como ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), donde rank(y) es un vector de los valores de rango de cada documento en C. Por ejemplo, para un corpus de dos documentos, {d1, d2}, con d1 teniendo un rango más alto que d2, rank(y) = (1, 0). Suponemos que las clasificaciones verdaderas tienen dos valores de clasificación, donde los documentos relevantes tienen un valor de clasificación 1 y los documentos no relevantes tienen un valor de clasificación 0. Además, asumimos que todas las clasificaciones predichas son clasificaciones completas (sin empates). Sea p = rango(y) y ˆp = rango(ˆy). La puntuación de precisión promedio se define como MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, donde rel = |{i : pi = 1}| es el número de documentos relevantes, y Prec@j es el porcentaje de documentos relevantes en los primeros j documentos en la clasificación predicha ˆy. MAP es la media de las puntuaciones de precisión promedio de un grupo de consultas. La mayoría de los algoritmos de aprendizaje se optimizan para precisión o ROCArea. Si bien optimizar estas medidas podría lograr un buen rendimiento de MAP, usamos dos ejemplos simples para mostrar que también puede ser subóptimo en términos de MAP. ROCArea asigna una penalización igual a cada desordenamiento de un par relevante/no relevante. Por el contrario, MAP asigna mayores penalizaciones a los errores de ordenamiento más arriba en la clasificación predicha. Usando nuestra notación, el Área bajo la Curva ROC (ROCArea) se puede definir como ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], donde p es el ranking verdadero (débil), ˆp es el ranking predicho, y 1[b] es la función indicadora condicionada a b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Tabla 1: Ejemplo y Modelos Supongamos que tenemos un espacio de hipótesis con solo dos funciones de hipótesis, h1 y h2, como se muestra en la Tabla 1. Estas dos hipótesis predicen un ranking para la consulta x sobre un corpus de ocho documentos. Tabla 2: Rendimiento de los Modelos de Juguete La Tabla 2 muestra las puntuaciones de MAP y ROCArea de h1 y h2. Aquí, un método de aprendizaje que optimiza para el Área bajo la curva ROC elegiría h2 ya que esto resulta en un puntaje de Área bajo la curva ROC más alto, pero esto produce un puntaje de MAP subóptimo. 2.2 MAP vs Precisión Usando un ejemplo muy similar, ahora demostramos cómo optimizar para la precisión podría resultar en un puntaje de MAP subóptimo. Los modelos que se optimizan para la precisión no están directamente preocupados por la clasificación. En cambio, aprenden un umbral tal que los documentos que obtienen una puntuación superior al umbral pueden ser clasificados como relevantes y los documentos que obtienen una puntuación inferior como no relevantes. Consideramos nuevamente un espacio de hipótesis con dos hipótesis. La Tabla 3 muestra las predicciones de las dos hipótesis en una única consulta x. Hipótesis MAP Mejor Precisión h1(q) 0.70 0.64 h2(q) 0.64 0.73 Tabla 4: Rendimiento de los Modelos de Juguete La Tabla 4 muestra los puntajes de MAP y mejor precisión de h1(q) y h2(q). La mejor precisión se refiere a la precisión más alta alcanzable en esa clasificación al considerar todos los umbrales posibles. Por ejemplo, con h1(q), un umbral entre los documentos 1 y 2 da 4 errores (documentos 6-9 clasificados incorrectamente como no relevantes), lo que resulta en una precisión de 0.64. De manera similar, con h2(q), un umbral entre los documentos 5 y 6 da 3 errores (los documentos 10-11 clasificados incorrectamente como relevantes, y el documento 1 como no relevante), lo que resulta en una precisión de 0.73. Un método de aprendizaje que optimiza la precisión elegiría h2 ya que esto resulta en un puntaje de precisión más alto, pero esto produce un puntaje de MAP subóptimo. 3. OPTIMIZANDO LA PRECISIÓN PROMEDIO Nos basamos en el enfoque utilizado por [13] para optimizar el Área bajo la Curva ROC. A diferencia de ROCArea, sin embargo, MAP no se descompone linealmente en los ejemplos y requiere un algoritmo sustancialmente extendido, el cual describimos en esta sección. Recuerda que la clasificación verdadera es una clasificación débil con dos valores de clasificación (relevante y no relevante). Que Cx y C¯x denoten el conjunto de documentos relevantes y no relevantes de C para la consulta x, respectivamente. Nos enfocamos en funciones que están parametrizadas por un vector de peso w, y por lo tanto deseamos encontrar w para minimizar el riesgo empírico, R∆ S (w) ≡ R∆ S (h(·; w)). Nuestro enfoque es aprender una función discriminante F: X × Y → sobre pares de entrada-salida. Dada la consulta x, podemos derivar una predicción encontrando la clasificación y que maximiza la función discriminante: h(x; w) = argmax y∈Y F(x, y; w). (1) Suponemos que F es lineal en alguna representación de características combinadas de entradas y salidas Ψ(x, y) ∈ RN, es decir, F(x, y; w) = wT Ψ(x, y). (2) La función de características combinadas que utilizamos es Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))], donde φ: X × C → N es una función de mapeo de características de un par consulta/documento a un punto en un espacio dimensional N. Representamos las clasificaciones como una matriz de ordenamientos por pares, Y ⊂ {−1, 0, +1}|C|×|C| . Para cualquier y ∈ Y, yij = +1 si di está clasificado por delante de dj, y yij = −1 si dj está clasificado por delante de di, y yij = 0 si di y dj tienen el mismo rango. Consideramos solo matrices que corresponden a clasificaciones válidas (es decir, que cumplen con la antisimetría y la transitividad). De manera intuitiva, Ψ es una suma de las diferencias vectoriales de todos los pares de documentos relevantes/no relevantes. Dado que asumimos que las clasificaciones predichas son clasificaciones completas, yij es o bien +1 o −1 (nunca 0). Dado un vector de pesos aprendido w, predecir un ranking (es decir, resolver la ecuación (1)) dado una consulta x se reduce a elegir cada yij para maximizar wT Ψ(x, y). Como también se discute en [13], esto se logra ordenando los documentos por wT φ(x, d) en orden descendente. Discutiremos más adelante las elecciones de φ que utilizamos para nuestros experimentos. 3.1 SVM Estructurales La formulación anterior es muy similar a aprender un modelo lineal directo mientras se entrena en la diferencia de pares de documentos relevantes/no relevantes. Muchos enfoques basados en SVM optimizan sobre estas diferencias en pares (por ejemplo, [5, 10, 13, 4]), aunque estos métodos no optimizan para el MAP durante el entrenamiento. Anteriormente, no estaba claro cómo incorporar funciones de pérdida multivariadas no lineales como la pérdida MAP directamente en problemas de optimización global como el entrenamiento de SVM. Ahora presentamos un método basado en SVM estructurales [19] para abordar este problema. Utilizamos la formulación del SVM estructural, presentada en el Problema de Optimización 1, para aprender un w ∈ RN. Problema de optimización 1. (SVM estructural) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) La función objetivo a minimizar (3) es un compromiso entre la complejidad del modelo, w 2 , y una relajación de pérdida de MAP mediante la pérdida de bisagra, P ξi. Como es habitual en el entrenamiento de SVM, C es igual a 2. Por ejemplo, una dimensión podría ser el número de veces que las palabras de la consulta aparecen en el documento. Algoritmo 1 Algoritmo de plano de corte para resolver OP 1 dentro de la tolerancia. 1: Entrada: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ para todo i = 1, . . . , n 3: repetir 4: para i = 1, . . . , n hacer 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: calcular ˆy = argmaxy∈Y H(y; w) 7: calcular ξi = max{0, maxy∈Wi H(y; w)} 8: si H(ˆy; w) > ξi + entonces 9: Wi ← Wi ∪ {ˆy} 10: w ← optimizar (3) sobre W = S i Wi 11: fin si 12: fin para 13: hasta que ningún Wi haya cambiado durante la iteración parámetro que controla este equilibrio y puede ajustarse para lograr un buen rendimiento en diferentes tareas de entrenamiento. Para cada (xi, yi) en el conjunto de entrenamiento, se añade un conjunto de restricciones de la forma en la ecuación (4) al problema de optimización. Ten en cuenta que wT Ψ(x, y) es exactamente nuestra función discriminante F(x, y; w) (ver ecuación (2)). Durante la predicción, nuestro modelo elige el ranking que maximiza el discriminante (1). Si el valor del discriminante para una clasificación incorrecta y es mayor que para la clasificación verdadera yi (por ejemplo, F(xi, y; w) > F(xi, yi; w)), entonces la variable de holgura correspondiente, ξi, debe ser al menos ∆(yi, y) para que se cumpla esa restricción. Por lo tanto, la suma de los márgenes, P ξi, acota superiormente la pérdida MAP. Esto se establece formalmente en la Proposición 1. Proposición 1. Sea ξ∗ (w) la solución óptima de las variables de holgura para OP 1 para un vector de peso dado w. Entonces 1 n Pn i=1 ξi es una cota superior del riesgo empírico R∆ S (w). (ver [19] para la prueba) La Proposición 1 muestra que OP 1 aprende una función de clasificación que optimiza una cota superior del error de MAP en el conjunto de entrenamiento. Desafortunadamente hay un problema: se requiere una restricción para cada posible resultado incorrecto y, y el número de resultados incorrectos posibles es exponencial en el tamaño de C. Afortunadamente, podemos emplear el Algoritmo 1 para resolver OP 1. El algoritmo 1 es un algoritmo de plano de corte, introduciendo iterativamente restricciones hasta que hayamos resuelto el problema original dentro de una tolerancia deseada [19]. El algoritmo comienza sin restricciones y encuentra de forma iterativa, para cada ejemplo (xi, yi), la salida ˆy asociada con la restricción más violada. Si la restricción correspondiente es violada por más de lo que introducimos ˆy en el conjunto de trabajo Wi de restricciones activas, por ejemplo i, y volvemos a resolver (3) usando el W actualizado. Se puede demostrar que el bucle externo del Algoritmo 1 está garantizado a detenerse dentro de un número polinomial de iteraciones para cualquier precisión deseada. Teorema 1. Sea ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y), ¯∆ = maxi maxy ∆(yi, y), y para cualquier > 0, el Algoritmo 1 termina después de agregar a lo sumo max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff restricciones al conjunto de trabajo W. (ver [19] para la prueba) Sin embargo, dentro del bucle interno de este algoritmo tenemos que calcular argmaxy∈Y H(y; w), donde H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), o equivalentemente, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), ya que wT Ψ(xi, yi) es constante con respecto a y. Aunque está estrechamente relacionado con el procedimiento de clasificación, esto tiene la complicación sustancial de que debemos lidiar con el término adicional ∆(yi, y). Sin la capacidad de encontrar eficientemente la restricción más violada (es decir, resolver argmaxy∈Y H(y, w)), el procedimiento de generación de restricciones no es viable. 3.2 Encontrar la restricción más violada utilizando OP 1 y optimizando la pérdida de ROCArea (∆roc), el problema de encontrar la restricción más violada, o resolver argmaxy∈Y H(y, w) (en adelante argmax H), se aborda en [13]. Resolver argmax H para ∆map es más difícil. Esto se debe principalmente a que ROCArea se descompone de manera ordenada en una suma de puntuaciones calculadas de forma independiente en cada ordenamiento relativo de un par de documentos relevantes/no relevantes. MAP, por otro lado, no se descompone de la misma manera que ROCArea. La principal contribución algorítmica de este artículo es un método eficiente para resolver argmax H para ∆map. Una propiedad útil de ∆map es que es invariante al intercambiar dos documentos con igual relevancia. Por ejemplo, si los documentos da y db son ambos relevantes, entonces intercambiar las posiciones de da y db en cualquier clasificación no afecta a ∆map. Por extensión, ∆map es invariante a cualquier permutación arbitraria de los documentos relevantes entre sí y de los documentos no relevantes entre sí. Sin embargo, esta reorganización afectará la puntuación del discriminante, wT Ψ(x, y). Esto nos lleva a la Observación 1. Observación 1. Considera clasificaciones que estén limitadas por fijar la relevancia en cada posición de la clasificación (por ejemplo, el tercer documento en la clasificación debe ser relevante). Cada clasificación que cumpla con el mismo conjunto de restricciones tendrá el mismo ∆map. Si los documentos relevantes están ordenados por wT φ(x, d) en orden descendente, y los documentos no relevantes también están ordenados de la misma manera por wT φ(x, d), entonces la intercalación de las dos listas ordenadas que cumpla con las restricciones maximizará H para ese conjunto de clasificaciones restringidas. La Observación 1 implica que en la clasificación que maximiza H, los documentos relevantes se ordenarán por wT φ(x, d), y los documentos no relevantes también se ordenarán de la misma manera. Al ordenar primero los documentos relevantes y no relevantes, el problema se simplifica a encontrar la intercalación óptima de dos listas ordenadas. Para el resto de nuestra discusión, asumimos que los documentos relevantes y no relevantes están ordenados por wT φ(x, d) en orden descendente. Para mayor comodidad, también nos referimos a los documentos relevantes como {dx 1 , . . . dx |Cx|} = Cx, y a los documentos no relevantes como {d¯x 1 , . . . d¯x |C¯x|} = C¯x. Definimos δj(i1, i2), con i1 < i2, como el cambio en H desde cuando el documento relevante de mayor rango clasificado después de d¯x j es dx i1 hasta que es dx i2. Para i2 = i1 + 1, tenemos δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5), donde si = wT φ(x, di). El primer término en (5) es el cambio en ∆map cuando el documento relevante i tiene j documentos no relevantes clasificados antes de él, en lugar de j-1. El segundo término es el cambio en la puntuación del discriminante, wT Ψ(x, y), cuando yij cambia de +1 a −1. . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . . Figura 1: Ejemplo para δj(i, i + 1). La Figura 1 proporciona un ejemplo conceptual para δj(i, i + 1). La clasificación inferior difiere de la superior solo cuando d¯x j sube un rango. La diferencia en el valor de H para estas dos clasificaciones es exactamente δj(i, i + 1). Para cualquier i1 < i2, podemos definir δj(i1, i2) como δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) o equivalentemente, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) . Deja que o1, . . . , o|C¯x| codifiquen las posiciones de los documentos no relevantes, donde dx oj es el documento relevante de mayor rango clasificado después del j-ésimo documento no relevante. Debido a la Observación 1, esta codificación identifica de forma única un ranking completo. Podemos recuperar la clasificación como yij = 8 >>>< >>>: 0 si i = j sign(si − sj) si di, dj relevancia igual signo(oj − i − 0.5) si di = dx i , dj = d¯x j signo(j − oi + 0.5) si di = d¯x i , dj = dx j. (7) Ahora podemos reformular H en una nueva función objetivo, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), donde ¯y es la verdadera clasificación (débil). Conceptualmente, H comienza con una clasificación perfecta ¯y y agrega el cambio en H cuando cada documento no relevante sucesivo sube en la clasificación. Luego podemos reformular el problema argmax H como argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) sujeto a o1 ≤ . . . ≤ o|C¯x|. (9) El Algoritmo 2 describe el algoritmo utilizado para resolver la ecuación (8). Conceptualmente, el Algoritmo 2 comienza con un ranking perfecto. Entonces, para cada documento no relevante sucesivo, el algoritmo modifica la solución deslizando ese documento hacia arriba en la clasificación para maximizar localmente H, manteniendo las posiciones de los otros documentos no relevantes constantes. 3.2.1 Prueba de Corrección El Algoritmo 2 es codicioso en el sentido de que encuentra la mejor posición de cada documento no relevante de forma independiente de los otros documentos no relevantes. En otras palabras, el algoritmo maximiza H para cada documento no relevante, d¯x j, Algoritmo 2 Encontrar la Restricción Más Violada (argmax H) para el Algoritmo 1 con ∆map 1: Entrada: w, Cx, C¯x 2: ordenar Cx y C¯x en orden descendente de wT φ(x, d) 3: sx i ← wT φ(x, dx i), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i), i = 1, . . . , |C¯x | 5: para j = 1, . . . , |C¯x | hacer 6: optj ← argmaxk δj(k, |Cx| + 1) 7: fin para 8: codificar ˆy de acuerdo con (7) 9: devolver ˆy sin considerar las posiciones de los otros documentos no relevantes, y así ignora las restricciones de (9). Para que la solución sea factible, el documento no relevante j-ésimo debe ser clasificado después de los primeros j-1 documentos no relevantes, satisfaciendo así opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. Si la solución es factible, entonces claramente resuelve (8). Por lo tanto, basta con demostrar que el Algoritmo 2 cumple con (10). Primero demostramos que δj(·, ·) es monótonamente decreciente en j. Lema 1. Para cualquier 1 ≤ i1 < i2 ≤ |Cx | + 1 y 1 ≤ j < |C¯x |, debe ser el caso que δj+1(i1, i2) ≤ δj(i1, i2). Prueba. Recuerde que tanto δj(i1, i2) como δj+1(i1, i2) son sumas de términos i2 − i1. Mostraremos que cada término en la suma de δj+1(i1, i2) no es mayor que el término correspondiente en δj(i1, i2), o δj+1(k, k + 1) ≤ δj(k, k + 1) para k = i1, . . . , i2 − 1. Cada término en δj(k, k +1) y δj+1(k, k +1) puede ser descompuesto aún más en dos partes (ver (5)). Mostraremos que cada parte de δj+1(k, k + 1) no es mayor que la parte correspondiente en δj(k, k + 1). En otras palabras, demostraremos que tanto j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) como −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) son verdaderos para los valores mencionados de j y k. Es fácil ver que (11) es verdadero observando que para cualquier par de enteros positivos 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1, y eligiendo a = j y b = j + k. La segunda desigualdad (12) se cumple porque el Algoritmo 2 primero ordena d¯x en orden descendente de s¯x, lo que implica s¯x j+1 ≤ s¯x j. Así vemos que cada término en δj+1 no es mayor que el término correspondiente en δj, lo cual completa la prueba. El resultado del Lema 1 conduce directamente a nuestro resultado principal de corrección: Teorema 2. En el Algoritmo 2, los valores calculados de optj satisfacen (10), lo que implica que la solución devuelta por el Algoritmo 2 es factible y, por lo tanto, óptima. Prueba. Demostraremos que optj ≤ optj+1 se cumple para cualquier 1 ≤ j < |C¯x|, implicando así (10). Dado que el Algoritmo 2 calcula optj como optj = argmax k δj(k, |Cx | + 1), (13), entonces por definición de δj (6), para cualquier 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0. Usando el Lema 1, sabemos que δj+1(i, optj) ≤ δj(i, optj) < 0, lo que implica que para cualquier 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0. Supongamos por contradicción que optj+1 < optj. Entonces δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), lo cual contradice (13). Por lo tanto, debe ser el caso que optj ≤ optj+1, lo cual completa la prueba. 3.2.2 Tiempo de ejecución El tiempo de ejecución del Algoritmo 2 se puede dividir en dos partes. La primera parte es la clasificación por wT φ(x, d), lo cual requiere un tiempo de O(n log n), donde n = |Cx | + |C¯x |. La segunda parte calcula cada optj, lo cual requiere un tiempo de O(|Cx| · |C¯x|). Aunque en el peor de los casos esto es O(n2), el número de documentos relevantes, |Cx|, suele ser muy pequeño (por ejemplo, constante con respecto a n), en cuyo caso el tiempo de ejecución para la segunda parte es simplemente O(n). Para la mayoría de los conjuntos de datos del mundo real, el Algoritmo 2 está dominado por la ordenación y tiene una complejidad O(n log n). El Algoritmo 1 está garantizado de detenerse en un número polinómico de iteraciones [19], y cada iteración ejecuta el Algoritmo 2. Prácticamente todos los modelos que funcionaron bien fueron entrenados en un tiempo razonable (generalmente menos de una hora). Una vez que el entrenamiento esté completo, hacer predicciones sobre la consulta x usando la hipótesis resultante h(x|w) solo requiere ordenar por wT φ(x, d). Desarrollamos nuestro software utilizando una interfaz de Python a SVMstruct, ya que el lenguaje Python simplificó en gran medida el proceso de codificación. Para mejorar el rendimiento, es recomendable utilizar la implementación estándar en C de SVMstruct. CONFIGURACIÓN DEL EXPERIMENTO El objetivo principal de nuestros experimentos es evaluar si la optimización directa de MAP conduce a un rendimiento de MAP mejorado en comparación con los métodos convencionales de SVM que optimizan una pérdida sustituta como la precisión o el área bajo la curva ROC. Evaluamos empíricamente nuestro método utilizando dos conjuntos de consultas de la TREC Web Track, uno de TREC 9 y otro de TREC 10 (temas 451-500 y 501-550), ambos de los cuales utilizaron el corpus WT10g. Para cada consulta, TREC proporciona las evaluaciones de relevancia de los documentos. Generamos nuestras características utilizando las puntuaciones de las funciones de recuperación existentes en estas consultas. Si bien nuestro método es agnóstico al significado de las características, elegimos utilizar funciones de recuperación existentes como una forma simple pero efectiva de adquirir características útiles. Por lo tanto, nuestros experimentos de estadísticas de conjuntos de datos básicos esencialmente prueban la capacidad de nuestros métodos para volver a clasificar los documentos altamente clasificados (por ejemplo, volver a combinar las puntuaciones de las funciones de recuperación) para mejorar el MAP. Comparamos nuestro método con las mejores funciones de recuperación entrenadas (en adelante, funciones base), así como con los métodos SVM propuestos anteriormente. Comparar con las mejores funciones base pone a prueba la capacidad de nuestros métodos para aprender una combinación útil. Comparar con métodos SVM anteriores nos permite probar si optimizar directamente para el MAP (en lugar de precisión o área bajo la curva ROC) logra una puntuación de MAP más alta en la práctica. El resto de esta sección describe las funciones base y el método de generación de características en detalle. 4.1 Elección de Funciones de Recuperación Elegimos dos conjuntos de funciones base para nuestros experimentos. Para el primer conjunto, generamos tres índices sobre el corpus WT10g utilizando Indri5. El primer índice fue generado utilizando la configuración predeterminada, el segundo utilizó Porter-stemming, y el último utilizó Porter-stemming y las palabras vacías predeterminadas de Indris. Para TREC 9 y TREC 10, utilizamos la parte de descripción de cada consulta y puntuamos los documentos utilizando cinco de los métodos de recuperación integrados en Indri, que son Similitud Coseno, TFIDF, Okapi, Modelo de Lenguaje con Prior de Dirichlet y Modelo de Lenguaje con Prior de Jelinek-Mercer. Todos los parámetros se mantuvieron en sus valores predeterminados. Calculamos las puntuaciones de estos cinco métodos de recuperación sobre los tres índices, dando un total de 15 funciones base. Para cada consulta, consideramos las puntuaciones de los documentos encontrados en la unión de los mejores 1000 documentos de cada función base. Para nuestro segundo conjunto de funciones base, utilizamos puntuaciones de las presentaciones de la pista web TREC 9 [8] y TREC 10 [9]. Utilizamos solo las presentaciones no manuales y no breves de ambos años. Para TREC 9 y TREC 10, hubo 53 y 18 envíos de este tipo, respectivamente. Una presentación típica contenía puntajes de sus 1000 documentos principales. b ca wT φ(x,d) f(d|x) Figura 2: Ejemplo de Agrupación de Características 4.2 Generación de Características Para generar ejemplos de entrada para nuestro método, se debe proporcionar una instancia concreta de φ. Para cada documento d puntuado por un conjunto de funciones de recuperación F en la consulta x, generamos las características como un vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf, donde f(d|x) denota la puntuación que la función de recuperación f asigna al documento d para la consulta x, y cada Kf es un conjunto de valores reales. Desde un nivel alto, estamos expresando la puntuación de cada función de recuperación utilizando |Kf | + 1 contenedores. Dado que estamos utilizando núcleos lineales, se puede pensar en el problema de aprendizaje como encontrar una buena combinación de piezas constantes de los puntajes de las funciones de recuperación. La Figura 2 muestra un ejemplo de nuestro método de mapeo de características. En este ejemplo tenemos una única característica F = {f}. Aquí, Kf = {a, b, c}, y el vector de pesos es w = wa, wb, wc. Para cualquier documento d y consulta x, tenemos wT φ(x, d) = 8 >>< >>: 0 si f(d|x) < a wa si a ≤ f(d|x) < b wa + wb si b ≤ f(d|x) < c wa + wb + wc si c ≤ f(d|x) . Esto se expresa cualitativamente en la Figura 2, donde wa y wb son positivos, y wc es negativo. Realizamos nuestros experimentos principales utilizando cuatro opciones de F: el conjunto de las funciones de recuperación de Indri mencionadas anteriormente para TREC 9 y TREC 10, y las presentaciones de la pista web para TREC 9 y TREC 10. Para cada F y cada función f ∈ F, elegimos 50 valores para Kf que estuvieran razonablemente espaciados y capturaran la región sensible de f. Utilizando las cuatro opciones de F, generamos cuatro conjuntos de datos para nuestros experimentos principales. La Tabla 5 contiene estadísticas de los conjuntos de datos generados. Hay muchas formas de generar características, y no estamos abogando por nuestro método sobre los demás. Esto fue simplemente un medio eficiente para normalizar las salidas de diferentes funciones y permitir un modelo más expresivo. EXPERIMENTOS Para cada conjunto de datos en la Tabla 5, realizamos 50 pruebas. Para cada prueba, entrenamos con 10 consultas seleccionadas al azar, y seleccionamos otras 5 consultas al azar para un conjunto de validación. Los modelos fueron entrenados utilizando una amplia gama de valores de C. El modelo que tuvo mejor rendimiento en el conjunto de validación fue seleccionado y probado en las 35 consultas restantes. Todas las consultas fueron seleccionadas para estar en los conjuntos de entrenamiento, validación y prueba la misma cantidad de veces. Utilizando esta configuración, realizamos los mismos experimentos mientras usábamos nuestro método (mapa SVM∆), un SVM optimizando para ROCArea (SVM∆ roc) [13], y un SVM de clasificación convencional (SVMacc) [20]. Todos los métodos de SVM utilizaron un kernel lineal. Informamos sobre el rendimiento promedio de todos los modelos en las 50 pruebas. 5.1 Comparación con Funciones Base Al analizar nuestros resultados, la primera pregunta a responder es, ¿puede SVM∆ map aprender un modelo que supere al mejor modelo base TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.290 - 0.287Mejor Func. 0.280 28/22 0.283 29/21 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 36/14 ** Tabla 7: Comparación con Envíos TREC TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288Mejor Func. 0.280 27/23 0.283 31/19 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 35/15 ** Tabla 8: Comparación con Funciones de Envíos TREC (sin el mejor) La Tabla 6 presenta la comparación del mapa SVM∆ con las mejores funciones base de Indri. Cada grupo de columnas contiene el rendimiento del MAP macro-promediado de SVM∆ map o una función base. Las columnas W/L muestran el número de consultas donde SVM∆ map logró un puntaje MAP más alto. Se realizaron pruebas de significancia utilizando la prueba de rango con signo de Wilcoxon de dos colas. Dos estrellas indican un nivel de significancia de 0.95. Todas las tablas que muestran nuestros resultados experimentales están estructuradas de manera idéntica. Aquí encontramos que SVM∆ mapea significativamente mejor que las mejores funciones base. La Tabla 7 muestra la comparación cuando se entrena con las presentaciones de TREC. Si bien logra una puntuación de MAP más alta que las mejores funciones base, la diferencia de rendimiento entre SVM∆ y las funciones base no es significativa. Dado que muchas de estas presentaciones utilizan funciones de puntuación cuidadosamente diseñadas para lograr un alto MAP, es posible que las presentaciones con mejor rendimiento utilicen técnicas que engloben las técnicas de las otras presentaciones. Como resultado, el mapa SVM∆ no sería capaz de aprender una hipótesis que pueda superar significativamente la mejor presentación. Por lo tanto, realizamos los mismos experimentos utilizando un conjunto de datos modificado en el que se eliminaron las características calculadas utilizando la mejor presentación. La tabla 8 muestra los resultados (ten en cuenta que aún estamos comparando con la mejor presentación, aunque no la estamos utilizando para el entrenamiento). Observa que si bien el rendimiento del SVM∆ map se degradó ligeramente, aún era comparable con el de la mejor presentación. 5.2 Comparación con Métodos SVM Anteriores La siguiente pregunta a responder es, ¿produce el SVM∆ map puntajes MAP más altos que los métodos SVM anteriores? Las tablas 9 y 10 presentan los resultados de SVM∆ map, SVM∆ roc y SVMacc cuando se entrenan con las funciones de recuperación de Indri y las presentaciones de TREC, respectivamente. La Tabla 11 contiene los resultados correspondientes cuando se entrena con las presentaciones de TREC sin la mejor presentación. Para empezar, nuestros resultados indican que SVMacc no fue competitivo con SVM∆ map y SVM∆ roc, y a veces tuvo un rendimiento notablemente inferior. Por lo tanto, probamos varios enfoques para mejorar el rendimiento de SVMacc. 5.2.1 Métodos alternativos de SVMacc Un problema que puede causar que SVMacc tenga un rendimiento deficiente es el desequilibrio severo entre documentos relevantes y no relevantes. La gran mayoría de los documentos no son relevantes. SVMacc2 aborda este problema asignando una penalización mayor a los errores de falsos negativos. Para cada conjunto de datos, la proporción de las penalizaciones por falsos negativos a falsos positivos es igual a la proporción entre el número de documentos no relevantes y relevantes en ese conjunto de datos. Las tablas 9, 10 y 11 indican que SVMacc2 sigue teniendo un rendimiento significativamente peor que SVM∆ map. Otro posible problema es que SVMacc intenta encontrar solo un umbral discriminatorio b que sea invariable a la consulta. Puede ser que diferentes consultas requieran diferentes valores de b. Tener el método de aprendizaje intentando encontrar un buen valor de b (cuando no existe) puede ser perjudicial. Tomamos dos enfoques para abordar este problema. El primer método, SVMacc3, convierte las puntuaciones de la función de recuperación en percentiles. Por ejemplo, para el documento d, la consulta q y la función de recuperación f, si la puntuación f(d|q) se encuentra en el 90% superior de las puntuaciones f(·|q) para la consulta q, entonces la puntuación convertida es f(d|q) = 0.9. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Las tablas 9, 10 y 11 muestran que el rendimiento de SVMacc3 tampoco fue competitivo con SVM∆ map. El segundo método, SVMacc4, normaliza las puntuaciones dadas por f para cada consulta. Por ejemplo, suponga para la consulta q que f produce puntuaciones en el rango de 0.2 a 0.7. Entonces, para el documento d, si f(d|q) = 0.6, la puntuación convertida sería f(d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Nuevamente, las Tablas 9, 10 y 11 muestran que SVMacc4 no fue competitivo con SVM∆ map 5.2.2 MAP vs ROCArea. SVM∆ roc tuvo un rendimiento mucho mejor que SVMacc en nuestros experimentos. Cuando se entrenó con las funciones de recuperación de Indri (ver Tabla 9), el rendimiento de SVM∆ roc fue ligeramente, aunque no significativamente, peor que el rendimiento de SVM∆ map. Sin embargo, la Tabla 10 muestra que el mapa SVM∆ superó significativamente al roc SVM∆ cuando se entrenó con las presentaciones de TREC. La tabla 11 muestra el rendimiento de los modelos cuando se entrenan con las presentaciones de TREC y se elimina la mejor presentación. El rendimiento de la mayoría de los modelos se degradó ligeramente, con SVM∆ map aún teniendo el mejor rendimiento. TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288 SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Tabla 11: Entrenado en TREC Subm. (sin Mejor) 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado un método SVM que optimiza directamente el MAP. Proporciona un enfoque basado en principios y evita heurísticas difíciles de controlar. Formulamos el problema de optimización y presentamos un algoritmo que encuentra la solución de manera demostrable en tiempo polinómico. Hemos demostrado empíricamente que nuestro método es generalmente superior o competitivo con los métodos convencionales de SVM. Nuestro nuevo método hace que sea conceptualmente tan fácil optimizar SVMs para MAP como anteriormente solo era posible para Precisión y Área bajo la curva ROC. El costo computacional para el entrenamiento es muy razonable en la práctica. Dado que otros métodos suelen requerir ajustar múltiples heurísticas, también esperamos entrenar menos modelos antes de encontrar uno que logre un buen rendimiento. El marco de aprendizaje utilizado por nuestro método es bastante general. Una extensión natural de este marco sería desarrollar métodos para optimizar otras medidas importantes de IR, como la Ganancia Acumulada Normalizada Descontada [2, 3, 4, 12] y la Reciprocidad Media de Rango. 7. AGRADECIMIENTOS Este trabajo fue financiado bajo el Premio NSF IIS-0412894, el Premio NSF CAREER 0237381 y un obsequio de Yahoo! Investigación. El tercer autor también fue parcialmente apoyado por una Beca de Investigación de Microsoft. 8. REFERENCIAS [1] B. T. Bartell, G. W. Cottrell y R. K. Belew. Combinación automática de múltiples sistemas de recuperación clasificados. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2005. [3] C. J. C. Burges, R. Ragno y Q. Lo. Aprendizaje para clasificar con funciones de costo no suaves. En Actas de la Conferencia Internacional sobre Avances en Sistemas de Información Neural (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang y H.-W. Hon. Adaptando el SVM de clasificación para la recuperación de documentos. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [5] B. Carterette y D. Petkova. Aprendiendo un ranking a partir de preferencias por pares. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew y A. Ksikes. Selección de conjunto de bibliotecas de modelos. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [7] J. Davis y M. Goadrich. La relación entre las curvas de precisión-recall y ROC. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2006. [8] D. Hawking. Resumen de la pista web TREC-9. En Actas de TREC-2000, 2000. [9] D. Hawking y N. Craswell. Resumen de la pista web TREC-2001. En Actas de TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel y K. Obermayer. Límites de rango de margen amplio para regresión ordinal. Avances en clasificadores de márgenes amplios, 2000. [11] A. Herschtal y B. Raskutti. Optimizando el área bajo la curva ROC utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [12] K. Jarvelin y J. Kekalainen. Métodos de evaluación para recuperar documentos altamente relevantes. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2000. [13] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), páginas 377-384, Nueva York, NY, EE. UU., 2005. ACM Press. [14] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), páginas 111-119, 2001. [15] Y. Lin, Y. Lee y G. Wahba. Máquinas de vectores de soporte para clasificación en situaciones no estándar. Aprendizaje automático, 46:191-202, 2002. [16] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [17] K. Morik, P. Brockhausen y T. Joachims. Combinando el aprendizaje estadístico con un enfoque basado en el conocimiento. En Actas de la Conferencia Internacional sobre Aprendizaje Automático, 1999. [18] S. Robertson. El principio de clasificación de probabilidad en la revista IR de documentación. Revista de Documentación, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims y Y. Altun. Métodos de margen amplio para variables de salida estructuradas e interdependientes. Revista de Investigación en Aprendizaje Automático (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik. Teoría del Aprendizaje Estadístico. Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz. \n\nWiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer y R. Wolniewicz. Optimizando el rendimiento del clasificador mediante la aproximación a la estadística de Wilcoxon-Mann-Witney. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2003. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "machine learn for information retrieval": {
            "translated_key": "aprendizaje automático para la recuperación de información",
            "is_in_text": false,
            "original_annotated_sentences": [
                "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT Machine learning is commonly used to improve ranked retrieval systems.",
                "Due to computational difficulties, few learning techniques have been developed to directly optimize for mean average precision (MAP), despite its widespread use in evaluating such systems.",
                "Existing approaches optimizing MAP either do not find a globally optimal solution, or are computationally expensive.",
                "In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of MAP.",
                "We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora (WT10g), comparing against SVMs optimized for accuracy and ROCArea.",
                "In most cases we show our method to produce statistically significant improvements in MAP scores.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval Models General Terms Algorithm, Theory, Experimentation 1.",
                "INTRODUCTION State of the art information retrieval systems commonly use machine learning techniques to learn ranking functions.",
                "However, most current approaches do not optimize for the evaluation measure most often used, namely Mean Average Precision (MAP).",
                "Instead, current algorithms tend to take one of two general approaches.",
                "The first approach is to learn a model that estimates the probability of a document being relevant given a query (e.g., [18, 14]).",
                "If solved effectively, the ranking with best MAP performance can easily be derived from the probabilities of relevance.",
                "However, achieving high MAP only requires finding a good ordering of the documents.",
                "As a result, finding good probabilities requires solving a more difficult problem than necessary, likely requiring more training data to achieve the same MAP performance.",
                "The second common approach is to learn a function that maximizes a surrogate measure.",
                "Performance measures optimized include accuracy [17, 15], ROCArea [1, 5, 10, 11, 13, 21] or modifications of ROCArea [4], and NDCG [2, 3].",
                "Learning a model to optimize for such measures might result in suboptimal MAP performance.",
                "In fact, although some previous systems have obtained good MAP performance, it is known that neither achieving optimal accuracy nor ROCArea can guarantee optimal MAP performance[7].",
                "In this paper, we present a general approach for learning ranking functions that maximize MAP performance.",
                "Specifically, we present an SVM algorithm that globally optimizes a hinge-loss relaxation of MAP.",
                "This approach simplifies the process of obtaining ranking functions with high MAP performance by avoiding additional intermediate steps and heuristics.",
                "The new algorithm also makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for accuracy and ROCArea.",
                "In contrast to recent work directly optimizing for MAP performance by Metzler & Croft [16] and Caruana et al. [6], our technique is computationally efficient while finding a globally optimal solution.",
                "Like [6, 16], our method learns a linear model, but is much more efficient in practice and, unlike [16], can handle many thousands of features.",
                "We now describe the algorithm in detail and provide proof of correctness.",
                "Following this, we provide an analysis of running time.",
                "We finish with empirical results from experiments on the TREC 9 and TREC 10 Web Track corpus.",
                "We have also developed a software package implementing our algorithm that is available for public use1 . 2.",
                "THE LEARNING PROBLEM Following the standard machine learning setup, our goal is to learn a function h : X → Y between an input space X (all possible queries) and output space Y (rankings over a corpus).",
                "In order to quantify the quality of a prediction, ˆy = h(x), we will consider a loss function ∆ : Y × Y → . ∆(y, ˆy) quantifies the penalty for making prediction ˆy if the correct output is y.",
                "The loss function allows us to incorporate specific performance measures, which we will exploit 1 http://svmrank.yisongyue.com for optimizing MAP.",
                "We restrict ourselves to the supervised learning scenario, where input/output pairs (x, y) are available for training and are assumed to come from some fixed distribution P(x, y).",
                "The goal is to find a function h such that the risk (i.e., expected loss), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), is minimized.",
                "Of course, P(x, y) is unknown.",
                "But given a finite set of training pairs, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, the performance of h on S can be measured by the empirical risk, R∆ S (h) = 1 n nX i=1 ∆(yi, h(xi)).",
                "In the case of learning a ranked retrieval function, X denotes a space of queries, and Y the space of (possibly weak) rankings over some corpus of documents C = {d1, . . . ,d|C|}.",
                "We can define average precision loss as ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), where rank(y) is a vector of the rank values of each document in C. For example, for a corpus of two documents, {d1, d2}, with d1 having higher rank than d2, rank(y ) = (1, 0).",
                "We assume true rankings have two rank values, where relevant documents have rank value 1 and non-relevant documents rank value 0.",
                "We further assume that all predicted rankings are complete rankings (no ties).",
                "Let p = rank(y) and ˆp = rank(ˆy).",
                "The average precision score is defined as MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, where rel = |{i : pi = 1}| is the number of relevant documents, and Prec@j is the percentage of relevant documents in the top j documents in predicted ranking ˆy.",
                "MAP is the mean of the average precision scores of a group of queries. 2.1 MAP vs ROCArea Most learning algorithms optimize for accuracy or ROCArea.",
                "While optimizing for these measures might achieve good MAP performance, we use two simple examples to show it can also be suboptimal in terms of MAP.",
                "ROCArea assigns equal penalty to each misordering of a relevant/non-relevant pair.",
                "In contrast, MAP assigns greater penalties to misorderings higher up in the predicted ranking.",
                "Using our notation, ROCArea can be defined as ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], where p is the true (weak) ranking, ˆp is the predicted ranking, and 1[b] is the indicator function conditioned on b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Table 1: Toy Example and Models Suppose we have a hypothesis space with only two hypothesis functions, h1 and h2, as shown in Table 1.",
                "These two hypotheses predict a ranking for query x over a corpus of eight documents.",
                "Hypothesis MAP ROCArea h1(x) 0.59 0.47 h2(x) 0.51 0.53 Table 2: Performance of Toy Models Table 2 shows the MAP and ROCArea scores of h1 and h2.",
                "Here, a learning method which optimizes for ROCArea would choose h2 since that results in a higher ROCArea score, but this yields a suboptimal MAP score. 2.2 MAP vs Accuracy Using a very similar example, we now demonstrate how optimizing for accuracy might result in suboptimal MAP.",
                "Models which optimize for accuracy are not directly concerned with the ranking.",
                "Instead, they learn a threshold such that documents scoring higher than the threshold can be classified as relevant and documents scoring lower as nonrelevant.",
                "Doc ID 1 2 3 4 5 6 7 8 9 10 11 p 1 0 0 0 0 1 1 1 1 0 0 rank(h1(x)) 11 10 9 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 9 10 11 Table 3: Toy Example and Models We consider again a hypothesis space with two hypotheses.",
                "Table 3 shows the predictions of the two hypotheses on a single query x. Hypothesis MAP Best Acc. h1(q) 0.70 0.64 h2(q) 0.64 0.73 Table 4: Performance of Toy Models Table 4 shows the MAP and best accuracy scores of h1(q) and h2(q).",
                "The best accuracy refers to the highest achievable accuracy on that ranking when considering all possible thresholds.",
                "For instance, with h1(q), a threshold between documents 1 and 2 gives 4 errors (documents 6-9 incorrectly classified as non-relevant), yielding an accuracy of 0.64.",
                "Similarly, with h2(q), a threshold between documents 5 and 6 gives 3 errors (documents 10-11 incorrectly classified as relevant, and document 1 as non-relevant), yielding an accuracy of 0.73.",
                "A learning method which optimizes for accuracy would choose h2 since that results in a higher accuracy score, but this yields a suboptimal MAP score. 3.",
                "OPTIMIZING AVERAGE PRECISION We build upon the approach used by [13] for optimizing ROCArea.",
                "Unlike ROCArea, however, MAP does not decompose linearly in the examples and requires a substantially extended algorithm, which we describe in this section.",
                "Recall that the true ranking is a weak ranking with two rank values (relevant and non-relevant).",
                "Let Cx and C¯x denote the set of relevant and non-relevant documents of C for query x, respectively.",
                "We focus on functions which are parametrized by a weight vector w, and thus wish to find w to minimize the empirical risk, R∆ S (w) ≡ R∆ S (h(·; w)).",
                "Our approach is to learn a discriminant function F : X × Y → over input-output pairs.",
                "Given query x, we can derive a prediction by finding the ranking y that maximizes the discriminant function: h(x; w) = argmax y∈Y F(x, y; w). (1) We assume F to be linear in some combined feature representation of inputs and outputs Ψ(x, y) ∈ RN , i.e., F(x, y; w) = wT Ψ(x, y). (2) The combined feature function we use is Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))] , where φ : X × C → N is a feature mapping function from a query/document pair to a point in N dimensional space2 .",
                "We represent rankings as a matrix of pairwise orderings, Y ⊂ {−1, 0, +1}|C|×|C| .",
                "For any y ∈ Y, yij = +1 if di is ranked ahead of dj, and yij = −1 if dj is ranked ahead of di, and yij = 0 if di and dj have equal rank.",
                "We consider only matrices which correspond to valid rankings (i.e, obeying antisymmetry and transitivity).",
                "Intuitively, Ψ is a summation over the vector differences of all relevant/non-relevant document pairings.",
                "Since we assume predicted rankings to be complete rankings, yij is either +1 or −1 (never 0).",
                "Given a learned weight vector w, predicting a ranking (i.e. solving equation (1)) given query x reduces to picking each yij to maximize wT Ψ(x, y).",
                "As is also discussed in [13], this is attained by sorting the documents by wT φ(x, d) in descending order.",
                "We will discuss later the choices of φ we used for our experiments. 3.1 Structural SVMs The above formulation is very similar to learning a straightforward linear model while training on the pairwise difference of relevant/non-relevant document pairings.",
                "Many SVM-based approaches optimize over these pairwise differences (e.g., [5, 10, 13, 4]), although these methods do not optimize for MAP during training.",
                "Previously, it was not clear how to incorporate non-linear multivariate loss functions such as MAP loss directly into global optimization problems such as SVM training.",
                "We now present a method based on structural SVMs [19] to address this problem.",
                "We use the structural SVM formulation, presented in Optimization Problem 1, to learn a w ∈ RN .",
                "Optimization Problem 1. (Structural SVM) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) The objective function to be minimized (3) is a tradeoff between model complexity, w 2 , and a hinge loss relaxation of MAP loss, P ξi.",
                "As is usual in SVM training, C is a 2 For example, one dimension might be the number of times the query words appear in the document.",
                "Algorithm 1 Cutting plane algorithm for solving OP 1 within tolerance . 1: Input: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ for all i = 1, . . . , n 3: repeat 4: for i = 1, . . . , n do 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: compute ˆy = argmaxy∈Y H(y; w) 7: compute ξi = max{0, maxy∈Wi H(y; w)} 8: if H(ˆy; w) > ξi + then 9: Wi ← Wi ∪ {ˆy} 10: w ← optimize (3) over W = S i Wi 11: end if 12: end for 13: until no Wi has changed during iteration parameter that controls this tradeoff and can be tuned to achieve good performance in different training tasks.",
                "For each (xi, yi) in the training set, a set of constraints of the form in equation (4) is added to the optimization problem.",
                "Note that wT Ψ(x, y) is exactly our discriminant function F(x, y; w) (see equation (2)).",
                "During prediction, our model chooses the ranking which maximizes the discriminant (1).",
                "If the discriminant value for an incorrect ranking y is greater than for the true ranking yi (e.g., F(xi, y; w) > F(xi, yi; w)), then corresponding slack variable, ξi, must be at least ∆(yi, y) for that constraint to be satisfied.",
                "Therefore, the sum of slacks, P ξi, upper bounds the MAP loss.",
                "This is stated formally in Proposition 1.",
                "Proposition 1.",
                "Let ξ∗ (w) be the optimal solution of the slack variables for OP 1 for a given weight vector w. Then 1 n Pn i=1 ξi is an upper bound on the empirical risk R∆ S (w). (see [19] for proof) Proposition 1 shows that OP 1 learns a ranking function that optimizes an upper bound on MAP error on the training set.",
                "Unfortunately there is a problem: a constraint is required for every possible wrong output y, and the number of possible wrong outputs is exponential in the size of C. Fortunately, we may employ Algorithm 1 to solve OP 1.",
                "Algorithm 1 is a cutting plane algorithm, iteratively introducing constraints until we have solved the original problem within a desired tolerance [19].",
                "The algorithm starts with no constraints, and iteratively finds for each example (xi, yi) the output ˆy associated with the most violated constraint.",
                "If the corresponding constraint is violated by more than we introduce ˆy into the working set Wi of active constraints for example i, and re-solve (3) using the updated W. It can be shown that Algorithm 1s outer loop is guaranteed to halt within a polynomial number of iterations for any desired precision .",
                "Theorem 1.",
                "Let ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y) , ¯∆ = maxi maxy ∆(yi, y), and for any > 0, Algorithm 1 terminates after adding at most max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff constraints to the working set W. (see [19] for proof) However, within the inner loop of this algorithm we have to compute argmaxy∈Y H(y; w), where H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), or equivalently, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), since wT Ψ(xi, yi) is constant with respect to y.",
                "Though closely related to the classification procedure, this has the substantial complication that we must contend with the additional ∆(yi, y) term.",
                "Without the ability to efficiently find the most violated constraint (i.e., solve argmaxy∈Y H(y, w)), the constraint generation procedure is not tractable. 3.2 Finding the Most Violated Constraint Using OP 1 and optimizing to ROCArea loss (∆roc), the problem of finding the most violated constraint, or solving argmaxy∈Y H(y, w) (henceforth argmax H), is addressed in [13].",
                "Solving argmax H for ∆map is more difficult.",
                "This is primarily because ROCArea decomposes nicely into a sum of scores computed independently on each relative ordering of a relevant/non-relevant document pair.",
                "MAP, on the other hand, does not decompose in the same way as ROCArea.",
                "The main algorithmic contribution of this paper is an efficient method for solving argmax H for ∆map.",
                "One useful property of ∆map is that it is invariant to swapping two documents with equal relevance.",
                "For example, if documents da and db are both relevant, then swapping the positions of da and db in any ranking does not affect ∆map.",
                "By extension, ∆map is invariant to any arbitrary permutation of the relevant documents amongst themselves and of the non-relevant documents amongst themselves.",
                "However, this reshuﬄing will affect the discriminant score, wT Ψ(x, y).",
                "This leads us to Observation 1.",
                "Observation 1.",
                "Consider rankings which are constrained by fixing the relevance at each position in the ranking (e.g., the 3rd document in the ranking must be relevant).",
                "Every ranking which satisfies the same set of constraints will have the same ∆map.",
                "If the relevant documents are sorted by wT φ(x, d) in descending order, and the non-relevant documents are likewise sorted by wT φ(x, d), then the interleaving of the two sorted lists which satisfies the constraints will maximize H for that constrained set of rankings.",
                "Observation 1 implies that in the ranking which maximizes H, the relevant documents will be sorted by wT φ(x, d), and the non-relevant documents will also be sorted likewise.",
                "By first sorting the relevant and non-relevant documents, the problem is simplified to finding the optimal interleaving of two sorted lists.",
                "For the rest of our discussion, we assume that the relevant documents and non-relevant documents are both sorted by descending wT φ(x, d).",
                "For convenience, we also refer to relevant documents as {dx 1 , . . . dx |Cx|} = Cx , and non-relevant documents as {d¯x 1 , . . . d¯x |C¯x|} = C¯x .",
                "We define δj(i1, i2), with i1 < i2, as the change in H from when the highest ranked relevant document ranked after d¯x j is dx i1 to when it is dx i2 .",
                "For i2 = i1 + 1, we have δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5) where si = wT φ(x, di).",
                "The first term in (5) is the change in ∆map when the ith relevant document has j non-relevant documents ranked before it, as opposed to j −1.",
                "The second term is the change in the discriminant score, wT Ψ(x, y), when yij changes from +1 to −1. . . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . .",
                "Figure 1: Example for δj(i, i + 1) Figure 1 gives a conceptual example for δj(i, i + 1).",
                "The bottom ranking differs from the top only where d¯x j slides up one rank.",
                "The difference in the value of H for these two rankings is exactly δj(i, i + 1).",
                "For any i1 < i2, we can then define δj(i1, i2) as δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) or equivalently, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) .",
                "Let o1, . . . , o|C¯x| encode the positions of the non-relevant documents, where dx oj is the highest ranked relevant document ranked after the jth non-relevant document.",
                "Due to Observation 1, this encoding uniquely identifies a complete ranking.",
                "We can recover the ranking as yij = 8 >>>< >>>: 0 if i = j sign(si − sj) if di, dj equal relevance sign(oj − i − 0.5) if di = dx i , dj = d¯x j sign(j − oi + 0.5) if di = d¯x i , dj = dx j . (7) We can now reformulate H into a new objective function, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), where ¯y is the true (weak) ranking.",
                "Conceptually H starts with a perfect ranking ¯y, and adds the change in H when each successive non-relevant document slides up the ranking.",
                "We can then reformulate the argmax H problem as argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) s.t. o1 ≤ . . . ≤ o|C¯x|. (9) Algorithm 2 describes the algorithm used to solve equation (8).",
                "Conceptually, Algorithm 2 starts with a perfect ranking.",
                "Then for each successive non-relevant document, the algorithm modifies the solution by sliding that document up the ranking to locally maximize H while keeping the positions of the other non-relevant documents constant. 3.2.1 Proof of Correctness Algorithm 2 is greedy in the sense that it finds the best position of each non-relevant document independently from the other non-relevant documents.",
                "In other words, the algorithm maximizes H for each non-relevant document, d¯x j , Algorithm 2 Finding the Most Violated Constraint (argmax H) for Algorithm 1 with ∆map 1: Input: w, Cx , C¯x 2: sort Cx and C¯x in descending order of wT φ(x, d) 3: sx i ← wT φ(x, dx i ), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i ), i = 1, . . . , |C¯x | 5: for j = 1, . . . , |C¯x | do 6: optj ← argmaxk δj(k, |Cx | + 1) 7: end for 8: encode ˆy according to (7) 9: return ˆy without considering the positions of the other non-relevant documents, and thus ignores the constraints of (9).",
                "In order for the solution to be feasible, the jth non-relevant document must be ranked after the first j − 1 non-relevant documents, thus satisfying opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. (10) If the solution is feasible, the it clearly solves (8).",
                "Therefore, it suffices to prove that Algorithm 2 satisfies (10).",
                "We first prove that δj(·, ·) is monotonically decreasing in j. Lemma 1.",
                "For any 1 ≤ i1 < i2 ≤ |Cx | + 1 and 1 ≤ j < |C¯x |, it must be the case that δj+1(i1, i2) ≤ δj(i1, i2).",
                "Proof.",
                "Recall from (6) that both δj(i1, i2) and δj+1(i1, i2) are summations of i2 − i1 terms.",
                "We will show that each term in the summation of δj+1(i1, i2) is no greater than the corresponding term in δj(i1, i2), or δj+1(k, k + 1) ≤ δj(k, k + 1) for k = i1, . . . , i2 − 1.",
                "Each term in δj(k, k +1) and δj+1(k, k +1) can be further decomposed into two parts (see (5)).",
                "We will show that each part of δj+1(k, k + 1) is no greater than the corresponding part in δj(k, k + 1).",
                "In other words, we will show that both j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) and −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) are true for the aforementioned values of j and k. It is easy to see that (11) is true by observing that for any two positive integers 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1 , and choosing a = j and b = j + k. The second inequality (12) holds because Algorithm 2 first sorts d¯x in descending order of s¯x , implying s¯x j+1 ≤ s¯x j .",
                "Thus we see that each term in δj+1 is no greater than the corresponding term in δj, which completes the proof.",
                "The result of Lemma 1 leads directly to our main correctness result: Theorem 2.",
                "In Algorithm 2, the computed values of optj satisfy (10), implying that the solution returned by Algorithm 2 is feasible and thus optimal.",
                "Proof.",
                "We will prove that optj ≤ optj+1 holds for any 1 ≤ j < |C¯x |, thus implying (10).",
                "Since Algorithm 2 computes optj as optj = argmax k δj(k, |Cx | + 1), (13) then by definition of δj (6), for any 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0.",
                "Using Lemma 1, we know that δj+1(i, optj) ≤ δj(i, optj) < 0, which implies that for any 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0.",
                "Suppose for contradiction that optj+1 < optj.",
                "Then δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), which contradicts (13).",
                "Therefore, it must be the case that optj ≤ optj+1, which completes the proof. 3.2.2 Running Time The running time of Algorithm 2 can be split into two parts.",
                "The first part is the sort by wT φ(x, d), which requires O(n log n) time, where n = |Cx | + |C¯x |.",
                "The second part computes each optj, which requires O(|Cx | · |C¯x |) time.",
                "Though in the worst case this is O(n2 ), the number of relevant documents, |Cx |, is often very small (e.g., constant with respect to n), in which case the running time for the second part is simply O(n).",
                "For most real-world datasets, Algorithm 2 is dominated by the sort and has complexity O(n log n).",
                "Algorithm 1 is guaranteed to halt in a polynomial number of iterations [19], and each iteration runs Algorithm 2.",
                "Virtually all well-performing models were trained in a reasonable amount of time (usually less than one hour).",
                "Once training is complete, making predictions on query x using the resulting hypothesis h(x|w) requires only sorting by wT φ(x, d).",
                "We developed our software using a Python interface3 to SVMstruct , since the Python language greatly simplified the coding process.",
                "To improve performance, it is advisable to use the standard C implementation4 of SVMstruct . 4.",
                "EXPERIMENT SETUP The main goal of our experiments is to evaluate whether directly optimizing MAP leads to improved MAP performance compared to conventional SVM methods that optimize a substitute loss such as accuracy or ROCArea.",
                "We empirically evaluate our method using two sets of TREC Web Track queries, one each from TREC 9 and TREC 10 (topics 451-500 and 501-550), both of which used the WT10g corpus.",
                "For each query, TREC provides the relevance judgments of the documents.",
                "We generated our features using the scores of existing retrieval functions on these queries.",
                "While our method is agnostic to the meaning of the features, we chose to use existing retrieval functions as a simple yet effective way of acquiring useful features.",
                "As such, our 3 http://www.cs.cornell.edu/~tomf/svmpython/ 4 http://svmlight.joachims.org/svm_struct.html Dataset Base Funcs Features TREC 9 Indri 15 750 TREC 10 Indri 15 750 TREC 9 Submissions 53 2650 TREC 10 Submissions 18 900 Table 5: Dataset Statistics experiments essentially test our methods ability to re-rank the highly ranked documents (e.g., re-combine the scores of the retrieval functions) to improve MAP.",
                "We compare our method against the best retrieval functions trained on (henceforth base functions), as well as against previously proposed SVM methods.",
                "Comparing with the best base functions tests our methods ability to learn a useful combination.",
                "Comparing with previous SVM methods allows us to test whether optimizing directly for MAP (as opposed to accuracy or ROCArea) achieves a higher MAP score in practice.",
                "The rest of this section describes the base functions and the feature generation method in detail. 4.1 Choosing Retrieval Functions We chose two sets of base functions for our experiments.",
                "For the first set, we generated three indices over the WT10g corpus using Indri5 .",
                "The first index was generated using default settings, the second used Porter-stemming, and the last used Porter-stemming and Indris default stopwords.",
                "For both TREC 9 and TREC 10, we used the description portion of each query and scored the documents using five of Indris built-in retrieval methods, which are Cosine Similarity, TFIDF, Okapi, Language Model with Dirichlet Prior, and Language Model with Jelinek-Mercer Prior.",
                "All parameters were kept as their defaults.",
                "We computed the scores of these five retrieval methods over the three indices, giving 15 base functions in total.",
                "For each query, we considered the scores of documents found in the union of the top 1000 documents of each base function.",
                "For our second set of base functions, we used scores from the TREC 9 [8] and TREC 10 [9] Web Track submissions.",
                "We used only the non-manual, non-short submissions from both years.",
                "For TREC 9 and TREC 10, there were 53 and 18 such submissions, respectively.",
                "A typical submission contained scores of its top 1000 documents. b ca wT φ(x,d) f(d|x) Figure 2: Example Feature Binning 4.2 Generating Features In order to generate input examples for our method, a concrete instantiation of φ must be provided.",
                "For each doc5 http://www.lemurproject.org TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236Best Func. 0.204 39/11 ** 0.181 37/13 ** 2nd Best 0.199 38/12 ** 0.174 43/7 ** 3rd Best 0.188 34/16 ** 0.174 38/12 ** Table 6: Comparison with Indri Functions ument d scored by a set of retrieval functions F on query x, we generate the features as a vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf , where f(d|x) denotes the score that retrieval function f assigns to document d for query x, and each Kf is a set of real values.",
                "From a high level, we are expressing the score of each retrieval function using |Kf | + 1 bins.",
                "Since we are using linear kernels, one can think of the learning problem as finding a good piecewise-constant combination of the scores of the retrieval functions.",
                "Figure 2 shows an example of our feature mapping method.",
                "In this example we have a single feature F = {f}.",
                "Here, Kf = {a, b, c}, and the weight vector is w = wa, wb, wc .",
                "For any document d and query x, we have wT φ(x, d) = 8 >>< >>: 0 if f(d|x) < a wa if a ≤ f(d|x) < b wa + wb if b ≤ f(d|x) < c wa + wb + wc if c ≤ f(d|x) .",
                "This is expressed qualitatively in Figure 2, where wa and wb are positive, and wc is negative.",
                "We ran our main experiments using four choices of F: the set of aforementioned Indri retrieval functions for TREC 9 and TREC 10, and the Web Track submissions for TREC 9 and TREC 10.",
                "For each F and each function f ∈ F, we chose 50 values for Kf which are reasonably spaced and capture the sensitive region of f. Using the four choices of F, we generated four datasets for our main experiments.",
                "Table 5 contains statistics of the generated datasets.",
                "There are many ways to generate features, and we are not advocating our method over others.",
                "This was simply an efficient means to normalize the outputs of different functions and allow for a more expressive model. 5.",
                "EXPERIMENTS For each dataset in Table 5, we performed 50 trials.",
                "For each trial, we train on 10 randomly selected queries, and select another 5 queries at random for a validation set.",
                "Models were trained using a wide range of C values.",
                "The model which performed best on the validation set was selected and tested on the remaining 35 queries.",
                "All queries were selected to be in the training, validation and test sets the same number of times.",
                "Using this setup, we performed the same experiments while using our method (SVM∆ map), an SVM optimizing for ROCArea (SVM∆ roc) [13], and a conventional classification SVM (SVMacc) [20].",
                "All SVM methods used a linear kernel.",
                "We reported the average performance of all models over the 50 trials. 5.1 Comparison with Base Functions In analyzing our results, the first question to answer is, can SVM∆ map learn a model which outperforms the best base TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287Best Func. 0.280 28/22 0.283 29/21 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 36/14 ** Table 7: Comparison with TREC Submissions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288Best Func. 0.280 27/23 0.283 31/19 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 35/15 ** Table 8: Comparison with TREC Subm. (w/o best) functions?",
                "Table 6 presents the comparison of SVM∆ map with the best Indri base functions.",
                "Each column group contains the macro-averaged MAP performance of SVM∆ map or a base function.",
                "The W/L columns show the number of queries where SVM∆ map achieved a higher MAP score.",
                "Significance tests were performed using the two-tailed Wilcoxon signed rank test.",
                "Two stars indicate a significance level of 0.95.",
                "All tables displaying our experimental results are structured identically.",
                "Here, we find that SVM∆ map significantly outperforms the best base functions.",
                "Table 7 shows the comparison when trained on TREC submissions.",
                "While achieving a higher MAP score than the best base functions, the performance difference between SVM∆ map the base functions is not significant.",
                "Given that many of these submissions use scoring functions which are carefully crafted to achieve high MAP, it is possible that the best performing submissions use techniques which subsume the techniques of the other submissions.",
                "As a result, SVM∆ map would not be able to learn a hypothesis which can significantly out-perform the best submission.",
                "Hence, we ran the same experiments using a modified dataset where the features computed using the best submission were removed.",
                "Table 8 shows the results (note that we are still comparing against the best submission though we are not using it for training).",
                "Notice that while the performance of SVM∆ map degraded slightly, the performance was still comparable with that of the best submission. 5.2 Comparison w/ Previous SVM Methods The next question to answer is, does SVM∆ map produce higher MAP scores than previous SVM methods?",
                "Tables 9 and 10 present the results of SVM∆ map, SVM∆ roc, and SVMacc when trained on the Indri retrieval functions and TREC submissions, respectively.",
                "Table 11 contains the corresponding results when trained on the TREC submissions without the best submission.",
                "To start with, our results indicate that SVMacc was not competitive with SVM∆ map and SVM∆ roc, and at times underperformed dramatically.",
                "As such, we tried several approaches to improve the performance of SVMacc. 5.2.1 Alternate SVMacc Methods One issue which may cause SVMacc to underperform is the severe imbalance between relevant and non-relevant docTREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236SVM∆ roc 0.237 29/21 0.234 24/26 SVMacc 0.147 47/3 ** 0.155 47/3 ** SVMacc2 0.219 39/11 ** 0.207 43/7 ** SVMacc3 0.113 49/1 ** 0.153 45/5 ** SVMacc4 0.155 48/2 ** 0.155 48/2 ** Table 9: Trained on Indri Functions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287SVM∆ roc 0.282 29/21 0.278 35/15 ** SVMacc 0.213 49/1 ** 0.222 49/1 ** SVMacc2 0.270 34/16 ** 0.261 42/8 ** SVMacc3 0.133 50/0 ** 0.182 46/4 ** SVMacc4 0.233 47/3 ** 0.238 46/4 ** Table 10: Trained on TREC Submissions uments.",
                "The vast majority of the documents are not relevant.",
                "SVMacc2 addresses this problem by assigning more penalty to false negative errors.",
                "For each dataset, the ratio of the false negative to false positive penalties is equal to the ratio of the number non-relevant and relevant documents in that dataset.",
                "Tables 9, 10 and 11 indicate that SVMacc2 still performs significantly worse than SVM∆ map.",
                "Another possible issue is that SVMacc attempts to find just one discriminating threshold b that is query-invariant.",
                "It may be that different queries require different values of b.",
                "Having the learning method trying to find a good b value (when one does not exist) may be detrimental.",
                "We took two approaches to address this issue.",
                "The first method, SVMacc3, converts the retrieval function scores into percentiles.",
                "For example, for document d, query q and retrieval function f, if the score f(d|q) is in the top 90% of the scores f(·|q) for query q, then the converted score is f (d|q) = 0.9.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Tables 9, 10 and 11 show that the performance of SVMacc3 was also not competitive with SVM∆ map.",
                "The second method, SVMacc4, normalizes the scores given by f for each query.",
                "For example, assume for query q that f outputs scores in the range 0.2 to 0.7.",
                "Then for document d, if f(d|q) = 0.6, the converted score would be f (d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Again, Tables 9, 10 and 11 show that SVMacc4 was not competitive with SVM∆ map 5.2.2 MAP vs ROCArea SVM∆ roc performed much better than SVMacc in our experiments.",
                "When trained on Indri retrieval functions (see Table 9), the performance of SVM∆ roc was slight, though not significantly, worse than the performances of SVM∆ map.",
                "However, Table 10 shows that SVM∆ map did significantly outperform SVM∆ roc when trained on the TREC submissions.",
                "Table 11 shows the performance of the models when trained on the TREC submissions with the best submission removed.",
                "The performance of most models degraded by a small amount, with SVM∆ map still having the best performance.",
                "TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Table 11: Trained on TREC Subm. (w/o Best) 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented an SVM method that directly optimizes MAP.",
                "It provides a principled approach and avoids difficult to control heuristics.",
                "We formulated the optimization problem and presented an algorithm which provably finds the solution in polynomial time.",
                "We have shown empirically that our method is generally superior to or competitive with conventional SVMs methods.",
                "Our new method makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for Accuracy and ROCArea.",
                "The computational cost for training is very reasonable in practice.",
                "Since other methods typically require tuning multiple heuristics, we also expect to train fewer models before finding one which achieves good performance.",
                "The learning framework used by our method is fairly general.",
                "A natural extension of this framework would be to develop methods to optimize for other important IR measures, such as Normalized Discounted Cumulative Gain [2, 3, 4, 12] and Mean Reciprocal Rank. 7.",
                "ACKNOWLEDGMENTS This work was funded under NSF Award IIS-0412894, NSF CAREER Award 0237381, and a gift from Yahoo!",
                "Research.",
                "The third author was also partly supported by a Microsoft Research Fellowship. 8.",
                "REFERENCES [1] B. T. Bartell, G. W. Cottrell, and R. K. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2005. [3] C. J. C. Burges, R. Ragno, and Q.",
                "Le.",
                "Learning to rank with non-smooth cost functions.",
                "In Proceedings of the International Conference on Advances in Neural Information Processing Systems (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y.",
                "Liu, H. Li, Y. Huang, and H.-W. Hon.",
                "Adapting ranking SVM to document retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [5] B. Carterette and D. Petkova.",
                "Learning a ranking from pairwise preferences.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew, and A. Ksikes.",
                "Ensemble selection from libraries of models.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [7] J. Davis and M. Goadrich.",
                "The relationship between precision-recall and ROC curves.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2006. [8] D. Hawking.",
                "Overview of the TREC-9 web track.",
                "In Proceedings of TREC-2000, 2000. [9] D. Hawking and N. Craswell.",
                "Overview of the TREC-2001 web track.",
                "In Proceedings of TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel, and K. Obermayer.",
                "Large margin rank boundaries for ordinal regression.",
                "Advances in large margin classifiers, 2000. [11] A. Herschtal and B. Raskutti.",
                "Optimising area under the ROC curve using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [12] K. Jarvelin and J. Kekalainen.",
                "Ir evaluation methods for retrieving highly relevant documents.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2000. [13] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proceedings of the International Conference on Machine Learning (ICML), pages 377-384, New York, NY, USA, 2005.",
                "ACM Press. [14] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 111-119, 2001. [15] Y. Lin, Y. Lee, and G. Wahba.",
                "Support vector machines for classification in nonstandard situations.",
                "Machine Learning, 46:191-202, 2002. [16] D. Metzler and W. B. Croft.",
                "A markov random field model for term dependencies.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 472-479, 2005. [17] K. Morik, P. Brockhausen, and T. Joachims.",
                "Combining statistical learning with a knowledge-based approach.",
                "In Proceedings of the International Conference on Machine Learning, 1999. [18] S. Robertson.",
                "The probability ranking principle in ir. journal of documentation.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.",
                "Large margin methods for structured and interdependent output variables.",
                "Journal of Machine Learning Research (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik.",
                "Statistical Learning Theory.",
                "Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz.",
                "Optimizing classifier performance via approximation to the Wilcoxon-Mann-Witney statistic.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2003."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "support vector machine": {
            "translated_key": "máquina de vectores de soporte",
            "is_in_text": false,
            "original_annotated_sentences": [
                "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT Machine learning is commonly used to improve ranked retrieval systems.",
                "Due to computational difficulties, few learning techniques have been developed to directly optimize for mean average precision (MAP), despite its widespread use in evaluating such systems.",
                "Existing approaches optimizing MAP either do not find a globally optimal solution, or are computationally expensive.",
                "In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of MAP.",
                "We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora (WT10g), comparing against SVMs optimized for accuracy and ROCArea.",
                "In most cases we show our method to produce statistically significant improvements in MAP scores.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval Models General Terms Algorithm, Theory, Experimentation 1.",
                "INTRODUCTION State of the art information retrieval systems commonly use machine learning techniques to learn ranking functions.",
                "However, most current approaches do not optimize for the evaluation measure most often used, namely Mean Average Precision (MAP).",
                "Instead, current algorithms tend to take one of two general approaches.",
                "The first approach is to learn a model that estimates the probability of a document being relevant given a query (e.g., [18, 14]).",
                "If solved effectively, the ranking with best MAP performance can easily be derived from the probabilities of relevance.",
                "However, achieving high MAP only requires finding a good ordering of the documents.",
                "As a result, finding good probabilities requires solving a more difficult problem than necessary, likely requiring more training data to achieve the same MAP performance.",
                "The second common approach is to learn a function that maximizes a surrogate measure.",
                "Performance measures optimized include accuracy [17, 15], ROCArea [1, 5, 10, 11, 13, 21] or modifications of ROCArea [4], and NDCG [2, 3].",
                "Learning a model to optimize for such measures might result in suboptimal MAP performance.",
                "In fact, although some previous systems have obtained good MAP performance, it is known that neither achieving optimal accuracy nor ROCArea can guarantee optimal MAP performance[7].",
                "In this paper, we present a general approach for learning ranking functions that maximize MAP performance.",
                "Specifically, we present an SVM algorithm that globally optimizes a hinge-loss relaxation of MAP.",
                "This approach simplifies the process of obtaining ranking functions with high MAP performance by avoiding additional intermediate steps and heuristics.",
                "The new algorithm also makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for accuracy and ROCArea.",
                "In contrast to recent work directly optimizing for MAP performance by Metzler & Croft [16] and Caruana et al. [6], our technique is computationally efficient while finding a globally optimal solution.",
                "Like [6, 16], our method learns a linear model, but is much more efficient in practice and, unlike [16], can handle many thousands of features.",
                "We now describe the algorithm in detail and provide proof of correctness.",
                "Following this, we provide an analysis of running time.",
                "We finish with empirical results from experiments on the TREC 9 and TREC 10 Web Track corpus.",
                "We have also developed a software package implementing our algorithm that is available for public use1 . 2.",
                "THE LEARNING PROBLEM Following the standard machine learning setup, our goal is to learn a function h : X → Y between an input space X (all possible queries) and output space Y (rankings over a corpus).",
                "In order to quantify the quality of a prediction, ˆy = h(x), we will consider a loss function ∆ : Y × Y → . ∆(y, ˆy) quantifies the penalty for making prediction ˆy if the correct output is y.",
                "The loss function allows us to incorporate specific performance measures, which we will exploit 1 http://svmrank.yisongyue.com for optimizing MAP.",
                "We restrict ourselves to the supervised learning scenario, where input/output pairs (x, y) are available for training and are assumed to come from some fixed distribution P(x, y).",
                "The goal is to find a function h such that the risk (i.e., expected loss), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), is minimized.",
                "Of course, P(x, y) is unknown.",
                "But given a finite set of training pairs, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, the performance of h on S can be measured by the empirical risk, R∆ S (h) = 1 n nX i=1 ∆(yi, h(xi)).",
                "In the case of learning a ranked retrieval function, X denotes a space of queries, and Y the space of (possibly weak) rankings over some corpus of documents C = {d1, . . . ,d|C|}.",
                "We can define average precision loss as ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), where rank(y) is a vector of the rank values of each document in C. For example, for a corpus of two documents, {d1, d2}, with d1 having higher rank than d2, rank(y ) = (1, 0).",
                "We assume true rankings have two rank values, where relevant documents have rank value 1 and non-relevant documents rank value 0.",
                "We further assume that all predicted rankings are complete rankings (no ties).",
                "Let p = rank(y) and ˆp = rank(ˆy).",
                "The average precision score is defined as MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, where rel = |{i : pi = 1}| is the number of relevant documents, and Prec@j is the percentage of relevant documents in the top j documents in predicted ranking ˆy.",
                "MAP is the mean of the average precision scores of a group of queries. 2.1 MAP vs ROCArea Most learning algorithms optimize for accuracy or ROCArea.",
                "While optimizing for these measures might achieve good MAP performance, we use two simple examples to show it can also be suboptimal in terms of MAP.",
                "ROCArea assigns equal penalty to each misordering of a relevant/non-relevant pair.",
                "In contrast, MAP assigns greater penalties to misorderings higher up in the predicted ranking.",
                "Using our notation, ROCArea can be defined as ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], where p is the true (weak) ranking, ˆp is the predicted ranking, and 1[b] is the indicator function conditioned on b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Table 1: Toy Example and Models Suppose we have a hypothesis space with only two hypothesis functions, h1 and h2, as shown in Table 1.",
                "These two hypotheses predict a ranking for query x over a corpus of eight documents.",
                "Hypothesis MAP ROCArea h1(x) 0.59 0.47 h2(x) 0.51 0.53 Table 2: Performance of Toy Models Table 2 shows the MAP and ROCArea scores of h1 and h2.",
                "Here, a learning method which optimizes for ROCArea would choose h2 since that results in a higher ROCArea score, but this yields a suboptimal MAP score. 2.2 MAP vs Accuracy Using a very similar example, we now demonstrate how optimizing for accuracy might result in suboptimal MAP.",
                "Models which optimize for accuracy are not directly concerned with the ranking.",
                "Instead, they learn a threshold such that documents scoring higher than the threshold can be classified as relevant and documents scoring lower as nonrelevant.",
                "Doc ID 1 2 3 4 5 6 7 8 9 10 11 p 1 0 0 0 0 1 1 1 1 0 0 rank(h1(x)) 11 10 9 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 9 10 11 Table 3: Toy Example and Models We consider again a hypothesis space with two hypotheses.",
                "Table 3 shows the predictions of the two hypotheses on a single query x. Hypothesis MAP Best Acc. h1(q) 0.70 0.64 h2(q) 0.64 0.73 Table 4: Performance of Toy Models Table 4 shows the MAP and best accuracy scores of h1(q) and h2(q).",
                "The best accuracy refers to the highest achievable accuracy on that ranking when considering all possible thresholds.",
                "For instance, with h1(q), a threshold between documents 1 and 2 gives 4 errors (documents 6-9 incorrectly classified as non-relevant), yielding an accuracy of 0.64.",
                "Similarly, with h2(q), a threshold between documents 5 and 6 gives 3 errors (documents 10-11 incorrectly classified as relevant, and document 1 as non-relevant), yielding an accuracy of 0.73.",
                "A learning method which optimizes for accuracy would choose h2 since that results in a higher accuracy score, but this yields a suboptimal MAP score. 3.",
                "OPTIMIZING AVERAGE PRECISION We build upon the approach used by [13] for optimizing ROCArea.",
                "Unlike ROCArea, however, MAP does not decompose linearly in the examples and requires a substantially extended algorithm, which we describe in this section.",
                "Recall that the true ranking is a weak ranking with two rank values (relevant and non-relevant).",
                "Let Cx and C¯x denote the set of relevant and non-relevant documents of C for query x, respectively.",
                "We focus on functions which are parametrized by a weight vector w, and thus wish to find w to minimize the empirical risk, R∆ S (w) ≡ R∆ S (h(·; w)).",
                "Our approach is to learn a discriminant function F : X × Y → over input-output pairs.",
                "Given query x, we can derive a prediction by finding the ranking y that maximizes the discriminant function: h(x; w) = argmax y∈Y F(x, y; w). (1) We assume F to be linear in some combined feature representation of inputs and outputs Ψ(x, y) ∈ RN , i.e., F(x, y; w) = wT Ψ(x, y). (2) The combined feature function we use is Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))] , where φ : X × C → N is a feature mapping function from a query/document pair to a point in N dimensional space2 .",
                "We represent rankings as a matrix of pairwise orderings, Y ⊂ {−1, 0, +1}|C|×|C| .",
                "For any y ∈ Y, yij = +1 if di is ranked ahead of dj, and yij = −1 if dj is ranked ahead of di, and yij = 0 if di and dj have equal rank.",
                "We consider only matrices which correspond to valid rankings (i.e, obeying antisymmetry and transitivity).",
                "Intuitively, Ψ is a summation over the vector differences of all relevant/non-relevant document pairings.",
                "Since we assume predicted rankings to be complete rankings, yij is either +1 or −1 (never 0).",
                "Given a learned weight vector w, predicting a ranking (i.e. solving equation (1)) given query x reduces to picking each yij to maximize wT Ψ(x, y).",
                "As is also discussed in [13], this is attained by sorting the documents by wT φ(x, d) in descending order.",
                "We will discuss later the choices of φ we used for our experiments. 3.1 Structural SVMs The above formulation is very similar to learning a straightforward linear model while training on the pairwise difference of relevant/non-relevant document pairings.",
                "Many SVM-based approaches optimize over these pairwise differences (e.g., [5, 10, 13, 4]), although these methods do not optimize for MAP during training.",
                "Previously, it was not clear how to incorporate non-linear multivariate loss functions such as MAP loss directly into global optimization problems such as SVM training.",
                "We now present a method based on structural SVMs [19] to address this problem.",
                "We use the structural SVM formulation, presented in Optimization Problem 1, to learn a w ∈ RN .",
                "Optimization Problem 1. (Structural SVM) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) The objective function to be minimized (3) is a tradeoff between model complexity, w 2 , and a hinge loss relaxation of MAP loss, P ξi.",
                "As is usual in SVM training, C is a 2 For example, one dimension might be the number of times the query words appear in the document.",
                "Algorithm 1 Cutting plane algorithm for solving OP 1 within tolerance . 1: Input: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ for all i = 1, . . . , n 3: repeat 4: for i = 1, . . . , n do 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: compute ˆy = argmaxy∈Y H(y; w) 7: compute ξi = max{0, maxy∈Wi H(y; w)} 8: if H(ˆy; w) > ξi + then 9: Wi ← Wi ∪ {ˆy} 10: w ← optimize (3) over W = S i Wi 11: end if 12: end for 13: until no Wi has changed during iteration parameter that controls this tradeoff and can be tuned to achieve good performance in different training tasks.",
                "For each (xi, yi) in the training set, a set of constraints of the form in equation (4) is added to the optimization problem.",
                "Note that wT Ψ(x, y) is exactly our discriminant function F(x, y; w) (see equation (2)).",
                "During prediction, our model chooses the ranking which maximizes the discriminant (1).",
                "If the discriminant value for an incorrect ranking y is greater than for the true ranking yi (e.g., F(xi, y; w) > F(xi, yi; w)), then corresponding slack variable, ξi, must be at least ∆(yi, y) for that constraint to be satisfied.",
                "Therefore, the sum of slacks, P ξi, upper bounds the MAP loss.",
                "This is stated formally in Proposition 1.",
                "Proposition 1.",
                "Let ξ∗ (w) be the optimal solution of the slack variables for OP 1 for a given weight vector w. Then 1 n Pn i=1 ξi is an upper bound on the empirical risk R∆ S (w). (see [19] for proof) Proposition 1 shows that OP 1 learns a ranking function that optimizes an upper bound on MAP error on the training set.",
                "Unfortunately there is a problem: a constraint is required for every possible wrong output y, and the number of possible wrong outputs is exponential in the size of C. Fortunately, we may employ Algorithm 1 to solve OP 1.",
                "Algorithm 1 is a cutting plane algorithm, iteratively introducing constraints until we have solved the original problem within a desired tolerance [19].",
                "The algorithm starts with no constraints, and iteratively finds for each example (xi, yi) the output ˆy associated with the most violated constraint.",
                "If the corresponding constraint is violated by more than we introduce ˆy into the working set Wi of active constraints for example i, and re-solve (3) using the updated W. It can be shown that Algorithm 1s outer loop is guaranteed to halt within a polynomial number of iterations for any desired precision .",
                "Theorem 1.",
                "Let ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y) , ¯∆ = maxi maxy ∆(yi, y), and for any > 0, Algorithm 1 terminates after adding at most max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff constraints to the working set W. (see [19] for proof) However, within the inner loop of this algorithm we have to compute argmaxy∈Y H(y; w), where H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), or equivalently, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), since wT Ψ(xi, yi) is constant with respect to y.",
                "Though closely related to the classification procedure, this has the substantial complication that we must contend with the additional ∆(yi, y) term.",
                "Without the ability to efficiently find the most violated constraint (i.e., solve argmaxy∈Y H(y, w)), the constraint generation procedure is not tractable. 3.2 Finding the Most Violated Constraint Using OP 1 and optimizing to ROCArea loss (∆roc), the problem of finding the most violated constraint, or solving argmaxy∈Y H(y, w) (henceforth argmax H), is addressed in [13].",
                "Solving argmax H for ∆map is more difficult.",
                "This is primarily because ROCArea decomposes nicely into a sum of scores computed independently on each relative ordering of a relevant/non-relevant document pair.",
                "MAP, on the other hand, does not decompose in the same way as ROCArea.",
                "The main algorithmic contribution of this paper is an efficient method for solving argmax H for ∆map.",
                "One useful property of ∆map is that it is invariant to swapping two documents with equal relevance.",
                "For example, if documents da and db are both relevant, then swapping the positions of da and db in any ranking does not affect ∆map.",
                "By extension, ∆map is invariant to any arbitrary permutation of the relevant documents amongst themselves and of the non-relevant documents amongst themselves.",
                "However, this reshuﬄing will affect the discriminant score, wT Ψ(x, y).",
                "This leads us to Observation 1.",
                "Observation 1.",
                "Consider rankings which are constrained by fixing the relevance at each position in the ranking (e.g., the 3rd document in the ranking must be relevant).",
                "Every ranking which satisfies the same set of constraints will have the same ∆map.",
                "If the relevant documents are sorted by wT φ(x, d) in descending order, and the non-relevant documents are likewise sorted by wT φ(x, d), then the interleaving of the two sorted lists which satisfies the constraints will maximize H for that constrained set of rankings.",
                "Observation 1 implies that in the ranking which maximizes H, the relevant documents will be sorted by wT φ(x, d), and the non-relevant documents will also be sorted likewise.",
                "By first sorting the relevant and non-relevant documents, the problem is simplified to finding the optimal interleaving of two sorted lists.",
                "For the rest of our discussion, we assume that the relevant documents and non-relevant documents are both sorted by descending wT φ(x, d).",
                "For convenience, we also refer to relevant documents as {dx 1 , . . . dx |Cx|} = Cx , and non-relevant documents as {d¯x 1 , . . . d¯x |C¯x|} = C¯x .",
                "We define δj(i1, i2), with i1 < i2, as the change in H from when the highest ranked relevant document ranked after d¯x j is dx i1 to when it is dx i2 .",
                "For i2 = i1 + 1, we have δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5) where si = wT φ(x, di).",
                "The first term in (5) is the change in ∆map when the ith relevant document has j non-relevant documents ranked before it, as opposed to j −1.",
                "The second term is the change in the discriminant score, wT Ψ(x, y), when yij changes from +1 to −1. . . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . .",
                "Figure 1: Example for δj(i, i + 1) Figure 1 gives a conceptual example for δj(i, i + 1).",
                "The bottom ranking differs from the top only where d¯x j slides up one rank.",
                "The difference in the value of H for these two rankings is exactly δj(i, i + 1).",
                "For any i1 < i2, we can then define δj(i1, i2) as δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) or equivalently, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) .",
                "Let o1, . . . , o|C¯x| encode the positions of the non-relevant documents, where dx oj is the highest ranked relevant document ranked after the jth non-relevant document.",
                "Due to Observation 1, this encoding uniquely identifies a complete ranking.",
                "We can recover the ranking as yij = 8 >>>< >>>: 0 if i = j sign(si − sj) if di, dj equal relevance sign(oj − i − 0.5) if di = dx i , dj = d¯x j sign(j − oi + 0.5) if di = d¯x i , dj = dx j . (7) We can now reformulate H into a new objective function, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), where ¯y is the true (weak) ranking.",
                "Conceptually H starts with a perfect ranking ¯y, and adds the change in H when each successive non-relevant document slides up the ranking.",
                "We can then reformulate the argmax H problem as argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) s.t. o1 ≤ . . . ≤ o|C¯x|. (9) Algorithm 2 describes the algorithm used to solve equation (8).",
                "Conceptually, Algorithm 2 starts with a perfect ranking.",
                "Then for each successive non-relevant document, the algorithm modifies the solution by sliding that document up the ranking to locally maximize H while keeping the positions of the other non-relevant documents constant. 3.2.1 Proof of Correctness Algorithm 2 is greedy in the sense that it finds the best position of each non-relevant document independently from the other non-relevant documents.",
                "In other words, the algorithm maximizes H for each non-relevant document, d¯x j , Algorithm 2 Finding the Most Violated Constraint (argmax H) for Algorithm 1 with ∆map 1: Input: w, Cx , C¯x 2: sort Cx and C¯x in descending order of wT φ(x, d) 3: sx i ← wT φ(x, dx i ), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i ), i = 1, . . . , |C¯x | 5: for j = 1, . . . , |C¯x | do 6: optj ← argmaxk δj(k, |Cx | + 1) 7: end for 8: encode ˆy according to (7) 9: return ˆy without considering the positions of the other non-relevant documents, and thus ignores the constraints of (9).",
                "In order for the solution to be feasible, the jth non-relevant document must be ranked after the first j − 1 non-relevant documents, thus satisfying opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. (10) If the solution is feasible, the it clearly solves (8).",
                "Therefore, it suffices to prove that Algorithm 2 satisfies (10).",
                "We first prove that δj(·, ·) is monotonically decreasing in j. Lemma 1.",
                "For any 1 ≤ i1 < i2 ≤ |Cx | + 1 and 1 ≤ j < |C¯x |, it must be the case that δj+1(i1, i2) ≤ δj(i1, i2).",
                "Proof.",
                "Recall from (6) that both δj(i1, i2) and δj+1(i1, i2) are summations of i2 − i1 terms.",
                "We will show that each term in the summation of δj+1(i1, i2) is no greater than the corresponding term in δj(i1, i2), or δj+1(k, k + 1) ≤ δj(k, k + 1) for k = i1, . . . , i2 − 1.",
                "Each term in δj(k, k +1) and δj+1(k, k +1) can be further decomposed into two parts (see (5)).",
                "We will show that each part of δj+1(k, k + 1) is no greater than the corresponding part in δj(k, k + 1).",
                "In other words, we will show that both j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) and −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) are true for the aforementioned values of j and k. It is easy to see that (11) is true by observing that for any two positive integers 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1 , and choosing a = j and b = j + k. The second inequality (12) holds because Algorithm 2 first sorts d¯x in descending order of s¯x , implying s¯x j+1 ≤ s¯x j .",
                "Thus we see that each term in δj+1 is no greater than the corresponding term in δj, which completes the proof.",
                "The result of Lemma 1 leads directly to our main correctness result: Theorem 2.",
                "In Algorithm 2, the computed values of optj satisfy (10), implying that the solution returned by Algorithm 2 is feasible and thus optimal.",
                "Proof.",
                "We will prove that optj ≤ optj+1 holds for any 1 ≤ j < |C¯x |, thus implying (10).",
                "Since Algorithm 2 computes optj as optj = argmax k δj(k, |Cx | + 1), (13) then by definition of δj (6), for any 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0.",
                "Using Lemma 1, we know that δj+1(i, optj) ≤ δj(i, optj) < 0, which implies that for any 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0.",
                "Suppose for contradiction that optj+1 < optj.",
                "Then δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), which contradicts (13).",
                "Therefore, it must be the case that optj ≤ optj+1, which completes the proof. 3.2.2 Running Time The running time of Algorithm 2 can be split into two parts.",
                "The first part is the sort by wT φ(x, d), which requires O(n log n) time, where n = |Cx | + |C¯x |.",
                "The second part computes each optj, which requires O(|Cx | · |C¯x |) time.",
                "Though in the worst case this is O(n2 ), the number of relevant documents, |Cx |, is often very small (e.g., constant with respect to n), in which case the running time for the second part is simply O(n).",
                "For most real-world datasets, Algorithm 2 is dominated by the sort and has complexity O(n log n).",
                "Algorithm 1 is guaranteed to halt in a polynomial number of iterations [19], and each iteration runs Algorithm 2.",
                "Virtually all well-performing models were trained in a reasonable amount of time (usually less than one hour).",
                "Once training is complete, making predictions on query x using the resulting hypothesis h(x|w) requires only sorting by wT φ(x, d).",
                "We developed our software using a Python interface3 to SVMstruct , since the Python language greatly simplified the coding process.",
                "To improve performance, it is advisable to use the standard C implementation4 of SVMstruct . 4.",
                "EXPERIMENT SETUP The main goal of our experiments is to evaluate whether directly optimizing MAP leads to improved MAP performance compared to conventional SVM methods that optimize a substitute loss such as accuracy or ROCArea.",
                "We empirically evaluate our method using two sets of TREC Web Track queries, one each from TREC 9 and TREC 10 (topics 451-500 and 501-550), both of which used the WT10g corpus.",
                "For each query, TREC provides the relevance judgments of the documents.",
                "We generated our features using the scores of existing retrieval functions on these queries.",
                "While our method is agnostic to the meaning of the features, we chose to use existing retrieval functions as a simple yet effective way of acquiring useful features.",
                "As such, our 3 http://www.cs.cornell.edu/~tomf/svmpython/ 4 http://svmlight.joachims.org/svm_struct.html Dataset Base Funcs Features TREC 9 Indri 15 750 TREC 10 Indri 15 750 TREC 9 Submissions 53 2650 TREC 10 Submissions 18 900 Table 5: Dataset Statistics experiments essentially test our methods ability to re-rank the highly ranked documents (e.g., re-combine the scores of the retrieval functions) to improve MAP.",
                "We compare our method against the best retrieval functions trained on (henceforth base functions), as well as against previously proposed SVM methods.",
                "Comparing with the best base functions tests our methods ability to learn a useful combination.",
                "Comparing with previous SVM methods allows us to test whether optimizing directly for MAP (as opposed to accuracy or ROCArea) achieves a higher MAP score in practice.",
                "The rest of this section describes the base functions and the feature generation method in detail. 4.1 Choosing Retrieval Functions We chose two sets of base functions for our experiments.",
                "For the first set, we generated three indices over the WT10g corpus using Indri5 .",
                "The first index was generated using default settings, the second used Porter-stemming, and the last used Porter-stemming and Indris default stopwords.",
                "For both TREC 9 and TREC 10, we used the description portion of each query and scored the documents using five of Indris built-in retrieval methods, which are Cosine Similarity, TFIDF, Okapi, Language Model with Dirichlet Prior, and Language Model with Jelinek-Mercer Prior.",
                "All parameters were kept as their defaults.",
                "We computed the scores of these five retrieval methods over the three indices, giving 15 base functions in total.",
                "For each query, we considered the scores of documents found in the union of the top 1000 documents of each base function.",
                "For our second set of base functions, we used scores from the TREC 9 [8] and TREC 10 [9] Web Track submissions.",
                "We used only the non-manual, non-short submissions from both years.",
                "For TREC 9 and TREC 10, there were 53 and 18 such submissions, respectively.",
                "A typical submission contained scores of its top 1000 documents. b ca wT φ(x,d) f(d|x) Figure 2: Example Feature Binning 4.2 Generating Features In order to generate input examples for our method, a concrete instantiation of φ must be provided.",
                "For each doc5 http://www.lemurproject.org TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236Best Func. 0.204 39/11 ** 0.181 37/13 ** 2nd Best 0.199 38/12 ** 0.174 43/7 ** 3rd Best 0.188 34/16 ** 0.174 38/12 ** Table 6: Comparison with Indri Functions ument d scored by a set of retrieval functions F on query x, we generate the features as a vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf , where f(d|x) denotes the score that retrieval function f assigns to document d for query x, and each Kf is a set of real values.",
                "From a high level, we are expressing the score of each retrieval function using |Kf | + 1 bins.",
                "Since we are using linear kernels, one can think of the learning problem as finding a good piecewise-constant combination of the scores of the retrieval functions.",
                "Figure 2 shows an example of our feature mapping method.",
                "In this example we have a single feature F = {f}.",
                "Here, Kf = {a, b, c}, and the weight vector is w = wa, wb, wc .",
                "For any document d and query x, we have wT φ(x, d) = 8 >>< >>: 0 if f(d|x) < a wa if a ≤ f(d|x) < b wa + wb if b ≤ f(d|x) < c wa + wb + wc if c ≤ f(d|x) .",
                "This is expressed qualitatively in Figure 2, where wa and wb are positive, and wc is negative.",
                "We ran our main experiments using four choices of F: the set of aforementioned Indri retrieval functions for TREC 9 and TREC 10, and the Web Track submissions for TREC 9 and TREC 10.",
                "For each F and each function f ∈ F, we chose 50 values for Kf which are reasonably spaced and capture the sensitive region of f. Using the four choices of F, we generated four datasets for our main experiments.",
                "Table 5 contains statistics of the generated datasets.",
                "There are many ways to generate features, and we are not advocating our method over others.",
                "This was simply an efficient means to normalize the outputs of different functions and allow for a more expressive model. 5.",
                "EXPERIMENTS For each dataset in Table 5, we performed 50 trials.",
                "For each trial, we train on 10 randomly selected queries, and select another 5 queries at random for a validation set.",
                "Models were trained using a wide range of C values.",
                "The model which performed best on the validation set was selected and tested on the remaining 35 queries.",
                "All queries were selected to be in the training, validation and test sets the same number of times.",
                "Using this setup, we performed the same experiments while using our method (SVM∆ map), an SVM optimizing for ROCArea (SVM∆ roc) [13], and a conventional classification SVM (SVMacc) [20].",
                "All SVM methods used a linear kernel.",
                "We reported the average performance of all models over the 50 trials. 5.1 Comparison with Base Functions In analyzing our results, the first question to answer is, can SVM∆ map learn a model which outperforms the best base TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287Best Func. 0.280 28/22 0.283 29/21 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 36/14 ** Table 7: Comparison with TREC Submissions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288Best Func. 0.280 27/23 0.283 31/19 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 35/15 ** Table 8: Comparison with TREC Subm. (w/o best) functions?",
                "Table 6 presents the comparison of SVM∆ map with the best Indri base functions.",
                "Each column group contains the macro-averaged MAP performance of SVM∆ map or a base function.",
                "The W/L columns show the number of queries where SVM∆ map achieved a higher MAP score.",
                "Significance tests were performed using the two-tailed Wilcoxon signed rank test.",
                "Two stars indicate a significance level of 0.95.",
                "All tables displaying our experimental results are structured identically.",
                "Here, we find that SVM∆ map significantly outperforms the best base functions.",
                "Table 7 shows the comparison when trained on TREC submissions.",
                "While achieving a higher MAP score than the best base functions, the performance difference between SVM∆ map the base functions is not significant.",
                "Given that many of these submissions use scoring functions which are carefully crafted to achieve high MAP, it is possible that the best performing submissions use techniques which subsume the techniques of the other submissions.",
                "As a result, SVM∆ map would not be able to learn a hypothesis which can significantly out-perform the best submission.",
                "Hence, we ran the same experiments using a modified dataset where the features computed using the best submission were removed.",
                "Table 8 shows the results (note that we are still comparing against the best submission though we are not using it for training).",
                "Notice that while the performance of SVM∆ map degraded slightly, the performance was still comparable with that of the best submission. 5.2 Comparison w/ Previous SVM Methods The next question to answer is, does SVM∆ map produce higher MAP scores than previous SVM methods?",
                "Tables 9 and 10 present the results of SVM∆ map, SVM∆ roc, and SVMacc when trained on the Indri retrieval functions and TREC submissions, respectively.",
                "Table 11 contains the corresponding results when trained on the TREC submissions without the best submission.",
                "To start with, our results indicate that SVMacc was not competitive with SVM∆ map and SVM∆ roc, and at times underperformed dramatically.",
                "As such, we tried several approaches to improve the performance of SVMacc. 5.2.1 Alternate SVMacc Methods One issue which may cause SVMacc to underperform is the severe imbalance between relevant and non-relevant docTREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236SVM∆ roc 0.237 29/21 0.234 24/26 SVMacc 0.147 47/3 ** 0.155 47/3 ** SVMacc2 0.219 39/11 ** 0.207 43/7 ** SVMacc3 0.113 49/1 ** 0.153 45/5 ** SVMacc4 0.155 48/2 ** 0.155 48/2 ** Table 9: Trained on Indri Functions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287SVM∆ roc 0.282 29/21 0.278 35/15 ** SVMacc 0.213 49/1 ** 0.222 49/1 ** SVMacc2 0.270 34/16 ** 0.261 42/8 ** SVMacc3 0.133 50/0 ** 0.182 46/4 ** SVMacc4 0.233 47/3 ** 0.238 46/4 ** Table 10: Trained on TREC Submissions uments.",
                "The vast majority of the documents are not relevant.",
                "SVMacc2 addresses this problem by assigning more penalty to false negative errors.",
                "For each dataset, the ratio of the false negative to false positive penalties is equal to the ratio of the number non-relevant and relevant documents in that dataset.",
                "Tables 9, 10 and 11 indicate that SVMacc2 still performs significantly worse than SVM∆ map.",
                "Another possible issue is that SVMacc attempts to find just one discriminating threshold b that is query-invariant.",
                "It may be that different queries require different values of b.",
                "Having the learning method trying to find a good b value (when one does not exist) may be detrimental.",
                "We took two approaches to address this issue.",
                "The first method, SVMacc3, converts the retrieval function scores into percentiles.",
                "For example, for document d, query q and retrieval function f, if the score f(d|q) is in the top 90% of the scores f(·|q) for query q, then the converted score is f (d|q) = 0.9.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Tables 9, 10 and 11 show that the performance of SVMacc3 was also not competitive with SVM∆ map.",
                "The second method, SVMacc4, normalizes the scores given by f for each query.",
                "For example, assume for query q that f outputs scores in the range 0.2 to 0.7.",
                "Then for document d, if f(d|q) = 0.6, the converted score would be f (d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Again, Tables 9, 10 and 11 show that SVMacc4 was not competitive with SVM∆ map 5.2.2 MAP vs ROCArea SVM∆ roc performed much better than SVMacc in our experiments.",
                "When trained on Indri retrieval functions (see Table 9), the performance of SVM∆ roc was slight, though not significantly, worse than the performances of SVM∆ map.",
                "However, Table 10 shows that SVM∆ map did significantly outperform SVM∆ roc when trained on the TREC submissions.",
                "Table 11 shows the performance of the models when trained on the TREC submissions with the best submission removed.",
                "The performance of most models degraded by a small amount, with SVM∆ map still having the best performance.",
                "TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Table 11: Trained on TREC Subm. (w/o Best) 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented an SVM method that directly optimizes MAP.",
                "It provides a principled approach and avoids difficult to control heuristics.",
                "We formulated the optimization problem and presented an algorithm which provably finds the solution in polynomial time.",
                "We have shown empirically that our method is generally superior to or competitive with conventional SVMs methods.",
                "Our new method makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for Accuracy and ROCArea.",
                "The computational cost for training is very reasonable in practice.",
                "Since other methods typically require tuning multiple heuristics, we also expect to train fewer models before finding one which achieves good performance.",
                "The learning framework used by our method is fairly general.",
                "A natural extension of this framework would be to develop methods to optimize for other important IR measures, such as Normalized Discounted Cumulative Gain [2, 3, 4, 12] and Mean Reciprocal Rank. 7.",
                "ACKNOWLEDGMENTS This work was funded under NSF Award IIS-0412894, NSF CAREER Award 0237381, and a gift from Yahoo!",
                "Research.",
                "The third author was also partly supported by a Microsoft Research Fellowship. 8.",
                "REFERENCES [1] B. T. Bartell, G. W. Cottrell, and R. K. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2005. [3] C. J. C. Burges, R. Ragno, and Q.",
                "Le.",
                "Learning to rank with non-smooth cost functions.",
                "In Proceedings of the International Conference on Advances in Neural Information Processing Systems (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y.",
                "Liu, H. Li, Y. Huang, and H.-W. Hon.",
                "Adapting ranking SVM to document retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [5] B. Carterette and D. Petkova.",
                "Learning a ranking from pairwise preferences.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew, and A. Ksikes.",
                "Ensemble selection from libraries of models.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [7] J. Davis and M. Goadrich.",
                "The relationship between precision-recall and ROC curves.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2006. [8] D. Hawking.",
                "Overview of the TREC-9 web track.",
                "In Proceedings of TREC-2000, 2000. [9] D. Hawking and N. Craswell.",
                "Overview of the TREC-2001 web track.",
                "In Proceedings of TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel, and K. Obermayer.",
                "Large margin rank boundaries for ordinal regression.",
                "Advances in large margin classifiers, 2000. [11] A. Herschtal and B. Raskutti.",
                "Optimising area under the ROC curve using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [12] K. Jarvelin and J. Kekalainen.",
                "Ir evaluation methods for retrieving highly relevant documents.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2000. [13] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proceedings of the International Conference on Machine Learning (ICML), pages 377-384, New York, NY, USA, 2005.",
                "ACM Press. [14] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 111-119, 2001. [15] Y. Lin, Y. Lee, and G. Wahba.",
                "Support vector machines for classification in nonstandard situations.",
                "Machine Learning, 46:191-202, 2002. [16] D. Metzler and W. B. Croft.",
                "A markov random field model for term dependencies.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 472-479, 2005. [17] K. Morik, P. Brockhausen, and T. Joachims.",
                "Combining statistical learning with a knowledge-based approach.",
                "In Proceedings of the International Conference on Machine Learning, 1999. [18] S. Robertson.",
                "The probability ranking principle in ir. journal of documentation.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.",
                "Large margin methods for structured and interdependent output variables.",
                "Journal of Machine Learning Research (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik.",
                "Statistical Learning Theory.",
                "Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz.",
                "Optimizing classifier performance via approximation to the Wilcoxon-Mann-Witney statistic.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2003."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "rank": {
            "translated_key": "rango",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Support Vector Method for Optimizing Average Precision Yisong Yue Cornell University Ithaca, NY, USA yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, USA tomf@cs.cornell.edu Filip Radlinski Cornell University Ithaca, NY, USA filip@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, USA tj@cs.cornell.edu ABSTRACT Machine learning is commonly used to improve ranked retrieval systems.",
                "Due to computational difficulties, few learning techniques have been developed to directly optimize for mean average precision (MAP), despite its widespread use in evaluating such systems.",
                "Existing approaches optimizing MAP either do not find a globally optimal solution, or are computationally expensive.",
                "In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of MAP.",
                "We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora (WT10g), comparing against SVMs optimized for accuracy and ROCArea.",
                "In most cases we show our method to produce statistically significant improvements in MAP scores.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval Models General Terms Algorithm, Theory, Experimentation 1.",
                "INTRODUCTION State of the art information retrieval systems commonly use machine learning techniques to learn ranking functions.",
                "However, most current approaches do not optimize for the evaluation measure most often used, namely Mean Average Precision (MAP).",
                "Instead, current algorithms tend to take one of two general approaches.",
                "The first approach is to learn a model that estimates the probability of a document being relevant given a query (e.g., [18, 14]).",
                "If solved effectively, the ranking with best MAP performance can easily be derived from the probabilities of relevance.",
                "However, achieving high MAP only requires finding a good ordering of the documents.",
                "As a result, finding good probabilities requires solving a more difficult problem than necessary, likely requiring more training data to achieve the same MAP performance.",
                "The second common approach is to learn a function that maximizes a surrogate measure.",
                "Performance measures optimized include accuracy [17, 15], ROCArea [1, 5, 10, 11, 13, 21] or modifications of ROCArea [4], and NDCG [2, 3].",
                "Learning a model to optimize for such measures might result in suboptimal MAP performance.",
                "In fact, although some previous systems have obtained good MAP performance, it is known that neither achieving optimal accuracy nor ROCArea can guarantee optimal MAP performance[7].",
                "In this paper, we present a general approach for learning ranking functions that maximize MAP performance.",
                "Specifically, we present an SVM algorithm that globally optimizes a hinge-loss relaxation of MAP.",
                "This approach simplifies the process of obtaining ranking functions with high MAP performance by avoiding additional intermediate steps and heuristics.",
                "The new algorithm also makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for accuracy and ROCArea.",
                "In contrast to recent work directly optimizing for MAP performance by Metzler & Croft [16] and Caruana et al. [6], our technique is computationally efficient while finding a globally optimal solution.",
                "Like [6, 16], our method learns a linear model, but is much more efficient in practice and, unlike [16], can handle many thousands of features.",
                "We now describe the algorithm in detail and provide proof of correctness.",
                "Following this, we provide an analysis of running time.",
                "We finish with empirical results from experiments on the TREC 9 and TREC 10 Web Track corpus.",
                "We have also developed a software package implementing our algorithm that is available for public use1 . 2.",
                "THE LEARNING PROBLEM Following the standard machine learning setup, our goal is to learn a function h : X → Y between an input space X (all possible queries) and output space Y (rankings over a corpus).",
                "In order to quantify the quality of a prediction, ˆy = h(x), we will consider a loss function ∆ : Y × Y → . ∆(y, ˆy) quantifies the penalty for making prediction ˆy if the correct output is y.",
                "The loss function allows us to incorporate specific performance measures, which we will exploit 1 http://svmrank.yisongyue.com for optimizing MAP.",
                "We restrict ourselves to the supervised learning scenario, where input/output pairs (x, y) are available for training and are assumed to come from some fixed distribution P(x, y).",
                "The goal is to find a function h such that the risk (i.e., expected loss), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), is minimized.",
                "Of course, P(x, y) is unknown.",
                "But given a finite set of training pairs, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, the performance of h on S can be measured by the empirical risk, R∆ S (h) = 1 n nX i=1 ∆(yi, h(xi)).",
                "In the case of learning a ranked retrieval function, X denotes a space of queries, and Y the space of (possibly weak) rankings over some corpus of documents C = {d1, . . . ,d|C|}.",
                "We can define average precision loss as ∆map(y, ˆy) = 1 − MAP(<br>rank</br>(y), <br>rank</br>(ˆy)), where rank(y) is a vector of the rank values of each document in C. For example, for a corpus of two documents, {d1, d2}, with d1 having higher rank than d2, rank(y ) = (1, 0).",
                "We assume true rankings have two <br>rank</br> values, where relevant documents have <br>rank</br> value 1 and non-relevant documents rank value 0.",
                "We further assume that all predicted rankings are complete rankings (no ties).",
                "Let p = <br>rank</br>(y) and ˆp = <br>rank</br>(ˆy).",
                "The average precision score is defined as MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, where rel = |{i : pi = 1}| is the number of relevant documents, and Prec@j is the percentage of relevant documents in the top j documents in predicted ranking ˆy.",
                "MAP is the mean of the average precision scores of a group of queries. 2.1 MAP vs ROCArea Most learning algorithms optimize for accuracy or ROCArea.",
                "While optimizing for these measures might achieve good MAP performance, we use two simple examples to show it can also be suboptimal in terms of MAP.",
                "ROCArea assigns equal penalty to each misordering of a relevant/non-relevant pair.",
                "In contrast, MAP assigns greater penalties to misorderings higher up in the predicted ranking.",
                "Using our notation, ROCArea can be defined as ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], where p is the true (weak) ranking, ˆp is the predicted ranking, and 1[b] is the indicator function conditioned on b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 <br>rank</br>(h1(x)) 8 7 6 5 4 3 2 1 <br>rank</br>(h2(x)) 1 2 3 4 5 6 7 8 Table 1: Toy Example and Models Suppose we have a hypothesis space with only two hypothesis functions, h1 and h2, as shown in Table 1.",
                "These two hypotheses predict a ranking for query x over a corpus of eight documents.",
                "Hypothesis MAP ROCArea h1(x) 0.59 0.47 h2(x) 0.51 0.53 Table 2: Performance of Toy Models Table 2 shows the MAP and ROCArea scores of h1 and h2.",
                "Here, a learning method which optimizes for ROCArea would choose h2 since that results in a higher ROCArea score, but this yields a suboptimal MAP score. 2.2 MAP vs Accuracy Using a very similar example, we now demonstrate how optimizing for accuracy might result in suboptimal MAP.",
                "Models which optimize for accuracy are not directly concerned with the ranking.",
                "Instead, they learn a threshold such that documents scoring higher than the threshold can be classified as relevant and documents scoring lower as nonrelevant.",
                "Doc ID 1 2 3 4 5 6 7 8 9 10 11 p 1 0 0 0 0 1 1 1 1 0 0 <br>rank</br>(h1(x)) 11 10 9 8 7 6 5 4 3 2 1 <br>rank</br>(h2(x)) 1 2 3 4 5 6 7 8 9 10 11 Table 3: Toy Example and Models We consider again a hypothesis space with two hypotheses.",
                "Table 3 shows the predictions of the two hypotheses on a single query x. Hypothesis MAP Best Acc. h1(q) 0.70 0.64 h2(q) 0.64 0.73 Table 4: Performance of Toy Models Table 4 shows the MAP and best accuracy scores of h1(q) and h2(q).",
                "The best accuracy refers to the highest achievable accuracy on that ranking when considering all possible thresholds.",
                "For instance, with h1(q), a threshold between documents 1 and 2 gives 4 errors (documents 6-9 incorrectly classified as non-relevant), yielding an accuracy of 0.64.",
                "Similarly, with h2(q), a threshold between documents 5 and 6 gives 3 errors (documents 10-11 incorrectly classified as relevant, and document 1 as non-relevant), yielding an accuracy of 0.73.",
                "A learning method which optimizes for accuracy would choose h2 since that results in a higher accuracy score, but this yields a suboptimal MAP score. 3.",
                "OPTIMIZING AVERAGE PRECISION We build upon the approach used by [13] for optimizing ROCArea.",
                "Unlike ROCArea, however, MAP does not decompose linearly in the examples and requires a substantially extended algorithm, which we describe in this section.",
                "Recall that the true ranking is a weak ranking with two <br>rank</br> values (relevant and non-relevant).",
                "Let Cx and C¯x denote the set of relevant and non-relevant documents of C for query x, respectively.",
                "We focus on functions which are parametrized by a weight vector w, and thus wish to find w to minimize the empirical risk, R∆ S (w) ≡ R∆ S (h(·; w)).",
                "Our approach is to learn a discriminant function F : X × Y → over input-output pairs.",
                "Given query x, we can derive a prediction by finding the ranking y that maximizes the discriminant function: h(x; w) = argmax y∈Y F(x, y; w). (1) We assume F to be linear in some combined feature representation of inputs and outputs Ψ(x, y) ∈ RN , i.e., F(x, y; w) = wT Ψ(x, y). (2) The combined feature function we use is Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))] , where φ : X × C → N is a feature mapping function from a query/document pair to a point in N dimensional space2 .",
                "We represent rankings as a matrix of pairwise orderings, Y ⊂ {−1, 0, +1}|C|×|C| .",
                "For any y ∈ Y, yij = +1 if di is ranked ahead of dj, and yij = −1 if dj is ranked ahead of di, and yij = 0 if di and dj have equal <br>rank</br>.",
                "We consider only matrices which correspond to valid rankings (i.e, obeying antisymmetry and transitivity).",
                "Intuitively, Ψ is a summation over the vector differences of all relevant/non-relevant document pairings.",
                "Since we assume predicted rankings to be complete rankings, yij is either +1 or −1 (never 0).",
                "Given a learned weight vector w, predicting a ranking (i.e. solving equation (1)) given query x reduces to picking each yij to maximize wT Ψ(x, y).",
                "As is also discussed in [13], this is attained by sorting the documents by wT φ(x, d) in descending order.",
                "We will discuss later the choices of φ we used for our experiments. 3.1 Structural SVMs The above formulation is very similar to learning a straightforward linear model while training on the pairwise difference of relevant/non-relevant document pairings.",
                "Many SVM-based approaches optimize over these pairwise differences (e.g., [5, 10, 13, 4]), although these methods do not optimize for MAP during training.",
                "Previously, it was not clear how to incorporate non-linear multivariate loss functions such as MAP loss directly into global optimization problems such as SVM training.",
                "We now present a method based on structural SVMs [19] to address this problem.",
                "We use the structural SVM formulation, presented in Optimization Problem 1, to learn a w ∈ RN .",
                "Optimization Problem 1. (Structural SVM) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \\ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) The objective function to be minimized (3) is a tradeoff between model complexity, w 2 , and a hinge loss relaxation of MAP loss, P ξi.",
                "As is usual in SVM training, C is a 2 For example, one dimension might be the number of times the query words appear in the document.",
                "Algorithm 1 Cutting plane algorithm for solving OP 1 within tolerance . 1: Input: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ for all i = 1, . . . , n 3: repeat 4: for i = 1, . . . , n do 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: compute ˆy = argmaxy∈Y H(y; w) 7: compute ξi = max{0, maxy∈Wi H(y; w)} 8: if H(ˆy; w) > ξi + then 9: Wi ← Wi ∪ {ˆy} 10: w ← optimize (3) over W = S i Wi 11: end if 12: end for 13: until no Wi has changed during iteration parameter that controls this tradeoff and can be tuned to achieve good performance in different training tasks.",
                "For each (xi, yi) in the training set, a set of constraints of the form in equation (4) is added to the optimization problem.",
                "Note that wT Ψ(x, y) is exactly our discriminant function F(x, y; w) (see equation (2)).",
                "During prediction, our model chooses the ranking which maximizes the discriminant (1).",
                "If the discriminant value for an incorrect ranking y is greater than for the true ranking yi (e.g., F(xi, y; w) > F(xi, yi; w)), then corresponding slack variable, ξi, must be at least ∆(yi, y) for that constraint to be satisfied.",
                "Therefore, the sum of slacks, P ξi, upper bounds the MAP loss.",
                "This is stated formally in Proposition 1.",
                "Proposition 1.",
                "Let ξ∗ (w) be the optimal solution of the slack variables for OP 1 for a given weight vector w. Then 1 n Pn i=1 ξi is an upper bound on the empirical risk R∆ S (w). (see [19] for proof) Proposition 1 shows that OP 1 learns a ranking function that optimizes an upper bound on MAP error on the training set.",
                "Unfortunately there is a problem: a constraint is required for every possible wrong output y, and the number of possible wrong outputs is exponential in the size of C. Fortunately, we may employ Algorithm 1 to solve OP 1.",
                "Algorithm 1 is a cutting plane algorithm, iteratively introducing constraints until we have solved the original problem within a desired tolerance [19].",
                "The algorithm starts with no constraints, and iteratively finds for each example (xi, yi) the output ˆy associated with the most violated constraint.",
                "If the corresponding constraint is violated by more than we introduce ˆy into the working set Wi of active constraints for example i, and re-solve (3) using the updated W. It can be shown that Algorithm 1s outer loop is guaranteed to halt within a polynomial number of iterations for any desired precision .",
                "Theorem 1.",
                "Let ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y) , ¯∆ = maxi maxy ∆(yi, y), and for any > 0, Algorithm 1 terminates after adding at most max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff constraints to the working set W. (see [19] for proof) However, within the inner loop of this algorithm we have to compute argmaxy∈Y H(y; w), where H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), or equivalently, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), since wT Ψ(xi, yi) is constant with respect to y.",
                "Though closely related to the classification procedure, this has the substantial complication that we must contend with the additional ∆(yi, y) term.",
                "Without the ability to efficiently find the most violated constraint (i.e., solve argmaxy∈Y H(y, w)), the constraint generation procedure is not tractable. 3.2 Finding the Most Violated Constraint Using OP 1 and optimizing to ROCArea loss (∆roc), the problem of finding the most violated constraint, or solving argmaxy∈Y H(y, w) (henceforth argmax H), is addressed in [13].",
                "Solving argmax H for ∆map is more difficult.",
                "This is primarily because ROCArea decomposes nicely into a sum of scores computed independently on each relative ordering of a relevant/non-relevant document pair.",
                "MAP, on the other hand, does not decompose in the same way as ROCArea.",
                "The main algorithmic contribution of this paper is an efficient method for solving argmax H for ∆map.",
                "One useful property of ∆map is that it is invariant to swapping two documents with equal relevance.",
                "For example, if documents da and db are both relevant, then swapping the positions of da and db in any ranking does not affect ∆map.",
                "By extension, ∆map is invariant to any arbitrary permutation of the relevant documents amongst themselves and of the non-relevant documents amongst themselves.",
                "However, this reshuﬄing will affect the discriminant score, wT Ψ(x, y).",
                "This leads us to Observation 1.",
                "Observation 1.",
                "Consider rankings which are constrained by fixing the relevance at each position in the ranking (e.g., the 3rd document in the ranking must be relevant).",
                "Every ranking which satisfies the same set of constraints will have the same ∆map.",
                "If the relevant documents are sorted by wT φ(x, d) in descending order, and the non-relevant documents are likewise sorted by wT φ(x, d), then the interleaving of the two sorted lists which satisfies the constraints will maximize H for that constrained set of rankings.",
                "Observation 1 implies that in the ranking which maximizes H, the relevant documents will be sorted by wT φ(x, d), and the non-relevant documents will also be sorted likewise.",
                "By first sorting the relevant and non-relevant documents, the problem is simplified to finding the optimal interleaving of two sorted lists.",
                "For the rest of our discussion, we assume that the relevant documents and non-relevant documents are both sorted by descending wT φ(x, d).",
                "For convenience, we also refer to relevant documents as {dx 1 , . . . dx |Cx|} = Cx , and non-relevant documents as {d¯x 1 , . . . d¯x |C¯x|} = C¯x .",
                "We define δj(i1, i2), with i1 < i2, as the change in H from when the highest ranked relevant document ranked after d¯x j is dx i1 to when it is dx i2 .",
                "For i2 = i1 + 1, we have δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5) where si = wT φ(x, di).",
                "The first term in (5) is the change in ∆map when the ith relevant document has j non-relevant documents ranked before it, as opposed to j −1.",
                "The second term is the change in the discriminant score, wT Ψ(x, y), when yij changes from +1 to −1. . . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . .",
                "Figure 1: Example for δj(i, i + 1) Figure 1 gives a conceptual example for δj(i, i + 1).",
                "The bottom ranking differs from the top only where d¯x j slides up one <br>rank</br>.",
                "The difference in the value of H for these two rankings is exactly δj(i, i + 1).",
                "For any i1 < i2, we can then define δj(i1, i2) as δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) or equivalently, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) .",
                "Let o1, . . . , o|C¯x| encode the positions of the non-relevant documents, where dx oj is the highest ranked relevant document ranked after the jth non-relevant document.",
                "Due to Observation 1, this encoding uniquely identifies a complete ranking.",
                "We can recover the ranking as yij = 8 >>>< >>>: 0 if i = j sign(si − sj) if di, dj equal relevance sign(oj − i − 0.5) if di = dx i , dj = d¯x j sign(j − oi + 0.5) if di = d¯x i , dj = dx j . (7) We can now reformulate H into a new objective function, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), where ¯y is the true (weak) ranking.",
                "Conceptually H starts with a perfect ranking ¯y, and adds the change in H when each successive non-relevant document slides up the ranking.",
                "We can then reformulate the argmax H problem as argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) s.t. o1 ≤ . . . ≤ o|C¯x|. (9) Algorithm 2 describes the algorithm used to solve equation (8).",
                "Conceptually, Algorithm 2 starts with a perfect ranking.",
                "Then for each successive non-relevant document, the algorithm modifies the solution by sliding that document up the ranking to locally maximize H while keeping the positions of the other non-relevant documents constant. 3.2.1 Proof of Correctness Algorithm 2 is greedy in the sense that it finds the best position of each non-relevant document independently from the other non-relevant documents.",
                "In other words, the algorithm maximizes H for each non-relevant document, d¯x j , Algorithm 2 Finding the Most Violated Constraint (argmax H) for Algorithm 1 with ∆map 1: Input: w, Cx , C¯x 2: sort Cx and C¯x in descending order of wT φ(x, d) 3: sx i ← wT φ(x, dx i ), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i ), i = 1, . . . , |C¯x | 5: for j = 1, . . . , |C¯x | do 6: optj ← argmaxk δj(k, |Cx | + 1) 7: end for 8: encode ˆy according to (7) 9: return ˆy without considering the positions of the other non-relevant documents, and thus ignores the constraints of (9).",
                "In order for the solution to be feasible, the jth non-relevant document must be ranked after the first j − 1 non-relevant documents, thus satisfying opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. (10) If the solution is feasible, the it clearly solves (8).",
                "Therefore, it suffices to prove that Algorithm 2 satisfies (10).",
                "We first prove that δj(·, ·) is monotonically decreasing in j. Lemma 1.",
                "For any 1 ≤ i1 < i2 ≤ |Cx | + 1 and 1 ≤ j < |C¯x |, it must be the case that δj+1(i1, i2) ≤ δj(i1, i2).",
                "Proof.",
                "Recall from (6) that both δj(i1, i2) and δj+1(i1, i2) are summations of i2 − i1 terms.",
                "We will show that each term in the summation of δj+1(i1, i2) is no greater than the corresponding term in δj(i1, i2), or δj+1(k, k + 1) ≤ δj(k, k + 1) for k = i1, . . . , i2 − 1.",
                "Each term in δj(k, k +1) and δj+1(k, k +1) can be further decomposed into two parts (see (5)).",
                "We will show that each part of δj+1(k, k + 1) is no greater than the corresponding part in δj(k, k + 1).",
                "In other words, we will show that both j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) and −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) are true for the aforementioned values of j and k. It is easy to see that (11) is true by observing that for any two positive integers 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1 , and choosing a = j and b = j + k. The second inequality (12) holds because Algorithm 2 first sorts d¯x in descending order of s¯x , implying s¯x j+1 ≤ s¯x j .",
                "Thus we see that each term in δj+1 is no greater than the corresponding term in δj, which completes the proof.",
                "The result of Lemma 1 leads directly to our main correctness result: Theorem 2.",
                "In Algorithm 2, the computed values of optj satisfy (10), implying that the solution returned by Algorithm 2 is feasible and thus optimal.",
                "Proof.",
                "We will prove that optj ≤ optj+1 holds for any 1 ≤ j < |C¯x |, thus implying (10).",
                "Since Algorithm 2 computes optj as optj = argmax k δj(k, |Cx | + 1), (13) then by definition of δj (6), for any 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0.",
                "Using Lemma 1, we know that δj+1(i, optj) ≤ δj(i, optj) < 0, which implies that for any 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0.",
                "Suppose for contradiction that optj+1 < optj.",
                "Then δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), which contradicts (13).",
                "Therefore, it must be the case that optj ≤ optj+1, which completes the proof. 3.2.2 Running Time The running time of Algorithm 2 can be split into two parts.",
                "The first part is the sort by wT φ(x, d), which requires O(n log n) time, where n = |Cx | + |C¯x |.",
                "The second part computes each optj, which requires O(|Cx | · |C¯x |) time.",
                "Though in the worst case this is O(n2 ), the number of relevant documents, |Cx |, is often very small (e.g., constant with respect to n), in which case the running time for the second part is simply O(n).",
                "For most real-world datasets, Algorithm 2 is dominated by the sort and has complexity O(n log n).",
                "Algorithm 1 is guaranteed to halt in a polynomial number of iterations [19], and each iteration runs Algorithm 2.",
                "Virtually all well-performing models were trained in a reasonable amount of time (usually less than one hour).",
                "Once training is complete, making predictions on query x using the resulting hypothesis h(x|w) requires only sorting by wT φ(x, d).",
                "We developed our software using a Python interface3 to SVMstruct , since the Python language greatly simplified the coding process.",
                "To improve performance, it is advisable to use the standard C implementation4 of SVMstruct . 4.",
                "EXPERIMENT SETUP The main goal of our experiments is to evaluate whether directly optimizing MAP leads to improved MAP performance compared to conventional SVM methods that optimize a substitute loss such as accuracy or ROCArea.",
                "We empirically evaluate our method using two sets of TREC Web Track queries, one each from TREC 9 and TREC 10 (topics 451-500 and 501-550), both of which used the WT10g corpus.",
                "For each query, TREC provides the relevance judgments of the documents.",
                "We generated our features using the scores of existing retrieval functions on these queries.",
                "While our method is agnostic to the meaning of the features, we chose to use existing retrieval functions as a simple yet effective way of acquiring useful features.",
                "As such, our 3 http://www.cs.cornell.edu/~tomf/svmpython/ 4 http://svmlight.joachims.org/svm_struct.html Dataset Base Funcs Features TREC 9 Indri 15 750 TREC 10 Indri 15 750 TREC 9 Submissions 53 2650 TREC 10 Submissions 18 900 Table 5: Dataset Statistics experiments essentially test our methods ability to re-<br>rank</br> the highly ranked documents (e.g., re-combine the scores of the retrieval functions) to improve MAP.",
                "We compare our method against the best retrieval functions trained on (henceforth base functions), as well as against previously proposed SVM methods.",
                "Comparing with the best base functions tests our methods ability to learn a useful combination.",
                "Comparing with previous SVM methods allows us to test whether optimizing directly for MAP (as opposed to accuracy or ROCArea) achieves a higher MAP score in practice.",
                "The rest of this section describes the base functions and the feature generation method in detail. 4.1 Choosing Retrieval Functions We chose two sets of base functions for our experiments.",
                "For the first set, we generated three indices over the WT10g corpus using Indri5 .",
                "The first index was generated using default settings, the second used Porter-stemming, and the last used Porter-stemming and Indris default stopwords.",
                "For both TREC 9 and TREC 10, we used the description portion of each query and scored the documents using five of Indris built-in retrieval methods, which are Cosine Similarity, TFIDF, Okapi, Language Model with Dirichlet Prior, and Language Model with Jelinek-Mercer Prior.",
                "All parameters were kept as their defaults.",
                "We computed the scores of these five retrieval methods over the three indices, giving 15 base functions in total.",
                "For each query, we considered the scores of documents found in the union of the top 1000 documents of each base function.",
                "For our second set of base functions, we used scores from the TREC 9 [8] and TREC 10 [9] Web Track submissions.",
                "We used only the non-manual, non-short submissions from both years.",
                "For TREC 9 and TREC 10, there were 53 and 18 such submissions, respectively.",
                "A typical submission contained scores of its top 1000 documents. b ca wT φ(x,d) f(d|x) Figure 2: Example Feature Binning 4.2 Generating Features In order to generate input examples for our method, a concrete instantiation of φ must be provided.",
                "For each doc5 http://www.lemurproject.org TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236Best Func. 0.204 39/11 ** 0.181 37/13 ** 2nd Best 0.199 38/12 ** 0.174 43/7 ** 3rd Best 0.188 34/16 ** 0.174 38/12 ** Table 6: Comparison with Indri Functions ument d scored by a set of retrieval functions F on query x, we generate the features as a vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf , where f(d|x) denotes the score that retrieval function f assigns to document d for query x, and each Kf is a set of real values.",
                "From a high level, we are expressing the score of each retrieval function using |Kf | + 1 bins.",
                "Since we are using linear kernels, one can think of the learning problem as finding a good piecewise-constant combination of the scores of the retrieval functions.",
                "Figure 2 shows an example of our feature mapping method.",
                "In this example we have a single feature F = {f}.",
                "Here, Kf = {a, b, c}, and the weight vector is w = wa, wb, wc .",
                "For any document d and query x, we have wT φ(x, d) = 8 >>< >>: 0 if f(d|x) < a wa if a ≤ f(d|x) < b wa + wb if b ≤ f(d|x) < c wa + wb + wc if c ≤ f(d|x) .",
                "This is expressed qualitatively in Figure 2, where wa and wb are positive, and wc is negative.",
                "We ran our main experiments using four choices of F: the set of aforementioned Indri retrieval functions for TREC 9 and TREC 10, and the Web Track submissions for TREC 9 and TREC 10.",
                "For each F and each function f ∈ F, we chose 50 values for Kf which are reasonably spaced and capture the sensitive region of f. Using the four choices of F, we generated four datasets for our main experiments.",
                "Table 5 contains statistics of the generated datasets.",
                "There are many ways to generate features, and we are not advocating our method over others.",
                "This was simply an efficient means to normalize the outputs of different functions and allow for a more expressive model. 5.",
                "EXPERIMENTS For each dataset in Table 5, we performed 50 trials.",
                "For each trial, we train on 10 randomly selected queries, and select another 5 queries at random for a validation set.",
                "Models were trained using a wide range of C values.",
                "The model which performed best on the validation set was selected and tested on the remaining 35 queries.",
                "All queries were selected to be in the training, validation and test sets the same number of times.",
                "Using this setup, we performed the same experiments while using our method (SVM∆ map), an SVM optimizing for ROCArea (SVM∆ roc) [13], and a conventional classification SVM (SVMacc) [20].",
                "All SVM methods used a linear kernel.",
                "We reported the average performance of all models over the 50 trials. 5.1 Comparison with Base Functions In analyzing our results, the first question to answer is, can SVM∆ map learn a model which outperforms the best base TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287Best Func. 0.280 28/22 0.283 29/21 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 36/14 ** Table 7: Comparison with TREC Submissions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288Best Func. 0.280 27/23 0.283 31/19 2nd Best 0.269 30/20 0.251 36/14 ** 3rd Best 0.266 30/20 0.233 35/15 ** Table 8: Comparison with TREC Subm. (w/o best) functions?",
                "Table 6 presents the comparison of SVM∆ map with the best Indri base functions.",
                "Each column group contains the macro-averaged MAP performance of SVM∆ map or a base function.",
                "The W/L columns show the number of queries where SVM∆ map achieved a higher MAP score.",
                "Significance tests were performed using the two-tailed Wilcoxon signed <br>rank</br> test.",
                "Two stars indicate a significance level of 0.95.",
                "All tables displaying our experimental results are structured identically.",
                "Here, we find that SVM∆ map significantly outperforms the best base functions.",
                "Table 7 shows the comparison when trained on TREC submissions.",
                "While achieving a higher MAP score than the best base functions, the performance difference between SVM∆ map the base functions is not significant.",
                "Given that many of these submissions use scoring functions which are carefully crafted to achieve high MAP, it is possible that the best performing submissions use techniques which subsume the techniques of the other submissions.",
                "As a result, SVM∆ map would not be able to learn a hypothesis which can significantly out-perform the best submission.",
                "Hence, we ran the same experiments using a modified dataset where the features computed using the best submission were removed.",
                "Table 8 shows the results (note that we are still comparing against the best submission though we are not using it for training).",
                "Notice that while the performance of SVM∆ map degraded slightly, the performance was still comparable with that of the best submission. 5.2 Comparison w/ Previous SVM Methods The next question to answer is, does SVM∆ map produce higher MAP scores than previous SVM methods?",
                "Tables 9 and 10 present the results of SVM∆ map, SVM∆ roc, and SVMacc when trained on the Indri retrieval functions and TREC submissions, respectively.",
                "Table 11 contains the corresponding results when trained on the TREC submissions without the best submission.",
                "To start with, our results indicate that SVMacc was not competitive with SVM∆ map and SVM∆ roc, and at times underperformed dramatically.",
                "As such, we tried several approaches to improve the performance of SVMacc. 5.2.1 Alternate SVMacc Methods One issue which may cause SVMacc to underperform is the severe imbalance between relevant and non-relevant docTREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.242 - 0.236SVM∆ roc 0.237 29/21 0.234 24/26 SVMacc 0.147 47/3 ** 0.155 47/3 ** SVMacc2 0.219 39/11 ** 0.207 43/7 ** SVMacc3 0.113 49/1 ** 0.153 45/5 ** SVMacc4 0.155 48/2 ** 0.155 48/2 ** Table 9: Trained on Indri Functions TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.290 - 0.287SVM∆ roc 0.282 29/21 0.278 35/15 ** SVMacc 0.213 49/1 ** 0.222 49/1 ** SVMacc2 0.270 34/16 ** 0.261 42/8 ** SVMacc3 0.133 50/0 ** 0.182 46/4 ** SVMacc4 0.233 47/3 ** 0.238 46/4 ** Table 10: Trained on TREC Submissions uments.",
                "The vast majority of the documents are not relevant.",
                "SVMacc2 addresses this problem by assigning more penalty to false negative errors.",
                "For each dataset, the ratio of the false negative to false positive penalties is equal to the ratio of the number non-relevant and relevant documents in that dataset.",
                "Tables 9, 10 and 11 indicate that SVMacc2 still performs significantly worse than SVM∆ map.",
                "Another possible issue is that SVMacc attempts to find just one discriminating threshold b that is query-invariant.",
                "It may be that different queries require different values of b.",
                "Having the learning method trying to find a good b value (when one does not exist) may be detrimental.",
                "We took two approaches to address this issue.",
                "The first method, SVMacc3, converts the retrieval function scores into percentiles.",
                "For example, for document d, query q and retrieval function f, if the score f(d|q) is in the top 90% of the scores f(·|q) for query q, then the converted score is f (d|q) = 0.9.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Tables 9, 10 and 11 show that the performance of SVMacc3 was also not competitive with SVM∆ map.",
                "The second method, SVMacc4, normalizes the scores given by f for each query.",
                "For example, assume for query q that f outputs scores in the range 0.2 to 0.7.",
                "Then for document d, if f(d|q) = 0.6, the converted score would be f (d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8.",
                "Each Kf contains 50 evenly spaced values between 0 and 1.",
                "Again, Tables 9, 10 and 11 show that SVMacc4 was not competitive with SVM∆ map 5.2.2 MAP vs ROCArea SVM∆ roc performed much better than SVMacc in our experiments.",
                "When trained on Indri retrieval functions (see Table 9), the performance of SVM∆ roc was slight, though not significantly, worse than the performances of SVM∆ map.",
                "However, Table 10 shows that SVM∆ map did significantly outperform SVM∆ roc when trained on the TREC submissions.",
                "Table 11 shows the performance of the models when trained on the TREC submissions with the best submission removed.",
                "The performance of most models degraded by a small amount, with SVM∆ map still having the best performance.",
                "TREC 9 TREC 10 Model MAP W/L MAP W/L SVM∆ map 0.284 - 0.288SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Table 11: Trained on TREC Subm. (w/o Best) 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented an SVM method that directly optimizes MAP.",
                "It provides a principled approach and avoids difficult to control heuristics.",
                "We formulated the optimization problem and presented an algorithm which provably finds the solution in polynomial time.",
                "We have shown empirically that our method is generally superior to or competitive with conventional SVMs methods.",
                "Our new method makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for Accuracy and ROCArea.",
                "The computational cost for training is very reasonable in practice.",
                "Since other methods typically require tuning multiple heuristics, we also expect to train fewer models before finding one which achieves good performance.",
                "The learning framework used by our method is fairly general.",
                "A natural extension of this framework would be to develop methods to optimize for other important IR measures, such as Normalized Discounted Cumulative Gain [2, 3, 4, 12] and Mean Reciprocal <br>rank</br>. 7.",
                "ACKNOWLEDGMENTS This work was funded under NSF Award IIS-0412894, NSF CAREER Award 0237381, and a gift from Yahoo!",
                "Research.",
                "The third author was also partly supported by a Microsoft Research Fellowship. 8.",
                "REFERENCES [1] B. T. Bartell, G. W. Cottrell, and R. K. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to <br>rank</br> using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2005. [3] C. J. C. Burges, R. Ragno, and Q.",
                "Le.",
                "Learning to <br>rank</br> with non-smooth cost functions.",
                "In Proceedings of the International Conference on Advances in Neural Information Processing Systems (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y.",
                "Liu, H. Li, Y. Huang, and H.-W. Hon.",
                "Adapting ranking SVM to document retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [5] B. Carterette and D. Petkova.",
                "Learning a ranking from pairwise preferences.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew, and A. Ksikes.",
                "Ensemble selection from libraries of models.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [7] J. Davis and M. Goadrich.",
                "The relationship between precision-recall and ROC curves.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2006. [8] D. Hawking.",
                "Overview of the TREC-9 web track.",
                "In Proceedings of TREC-2000, 2000. [9] D. Hawking and N. Craswell.",
                "Overview of the TREC-2001 web track.",
                "In Proceedings of TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel, and K. Obermayer.",
                "Large margin <br>rank</br> boundaries for ordinal regression.",
                "Advances in large margin classifiers, 2000. [11] A. Herschtal and B. Raskutti.",
                "Optimising area under the ROC curve using gradient descent.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2004. [12] K. Jarvelin and J. Kekalainen.",
                "Ir evaluation methods for retrieving highly relevant documents.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), 2000. [13] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proceedings of the International Conference on Machine Learning (ICML), pages 377-384, New York, NY, USA, 2005.",
                "ACM Press. [14] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of the ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 111-119, 2001. [15] Y. Lin, Y. Lee, and G. Wahba.",
                "Support vector machines for classification in nonstandard situations.",
                "Machine Learning, 46:191-202, 2002. [16] D. Metzler and W. B. Croft.",
                "A markov random field model for term dependencies.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 472-479, 2005. [17] K. Morik, P. Brockhausen, and T. Joachims.",
                "Combining statistical learning with a knowledge-based approach.",
                "In Proceedings of the International Conference on Machine Learning, 1999. [18] S. Robertson.",
                "The probability ranking principle in ir. journal of documentation.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.",
                "Large margin methods for structured and interdependent output variables.",
                "Journal of Machine Learning Research (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik.",
                "Statistical Learning Theory.",
                "Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz.",
                "Optimizing classifier performance via approximation to the Wilcoxon-Mann-Witney statistic.",
                "In Proceedings of the International Conference on Machine Learning (ICML), 2003."
            ],
            "original_annotated_samples": [
                "We can define average precision loss as ∆map(y, ˆy) = 1 − MAP(<br>rank</br>(y), <br>rank</br>(ˆy)), where rank(y) is a vector of the rank values of each document in C. For example, for a corpus of two documents, {d1, d2}, with d1 having higher rank than d2, rank(y ) = (1, 0).",
                "We assume true rankings have two <br>rank</br> values, where relevant documents have <br>rank</br> value 1 and non-relevant documents rank value 0.",
                "Let p = <br>rank</br>(y) and ˆp = <br>rank</br>(ˆy).",
                "Using our notation, ROCArea can be defined as ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], where p is the true (weak) ranking, ˆp is the predicted ranking, and 1[b] is the indicator function conditioned on b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 <br>rank</br>(h1(x)) 8 7 6 5 4 3 2 1 <br>rank</br>(h2(x)) 1 2 3 4 5 6 7 8 Table 1: Toy Example and Models Suppose we have a hypothesis space with only two hypothesis functions, h1 and h2, as shown in Table 1.",
                "Doc ID 1 2 3 4 5 6 7 8 9 10 11 p 1 0 0 0 0 1 1 1 1 0 0 <br>rank</br>(h1(x)) 11 10 9 8 7 6 5 4 3 2 1 <br>rank</br>(h2(x)) 1 2 3 4 5 6 7 8 9 10 11 Table 3: Toy Example and Models We consider again a hypothesis space with two hypotheses."
            ],
            "translated_annotated_samples": [
                "Podemos definir la pérdida de precisión promedio como ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), donde rank(y) es un vector de los valores de <br>rango</br> de cada documento en C. Por ejemplo, para un corpus de dos documentos, {d1, d2}, con d1 teniendo un <br>rango</br> más alto que d2, rank(y) = (1, 0).",
                "Suponemos que las clasificaciones verdaderas tienen dos valores de clasificación, donde los documentos relevantes tienen un <br>valor de clasificación</br> 1 y los documentos no relevantes tienen un <br>valor de clasificación</br> 0.",
                "Sea p = <br>rango</br>(y) y ˆp = <br>rango</br>(ˆy).",
                "Usando nuestra notación, el Área bajo la Curva ROC (ROCArea) se puede definir como ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], donde p es el ranking verdadero (débil), ˆp es el ranking predicho, y 1[b] es la función indicadora condicionada a b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Tabla 1: Ejemplo y Modelos Supongamos que tenemos un espacio de hipótesis con solo dos funciones de hipótesis, h1 y h2, como se muestra en la Tabla 1.",
                "Consideramos nuevamente un espacio de <br>hipótesis</br> con dos <br>hipótesis</br>."
            ],
            "translated_text": "Un método de Vectores de Soporte para optimizar la Precisión Promedio Yisong Yue Universidad de Cornell Ithaca, NY, EE. UU. yyue@cs.cornell.edu Thomas Finley Universidad de Cornell Ithaca, NY, EE. UU. tomf@cs.cornell.edu Filip Radlinski Universidad de Cornell Ithaca, NY, EE. UU. filip@cs.cornell.edu Thorsten Joachims Universidad de Cornell Ithaca, NY, EE. UU. tj@cs.cornell.edu RESUMEN El aprendizaje automático se utiliza comúnmente para mejorar los sistemas de recuperación clasificados. Debido a dificultades computacionales, se han desarrollado pocas técnicas de aprendizaje para optimizar directamente la precisión media promedio (MAP), a pesar de su uso generalizado en la evaluación de dichos sistemas. Los enfoques existentes que optimizan el MAP no encuentran una solución óptima global o son computacionalmente costosos. Por el contrario, presentamos un algoritmo de aprendizaje SVM general que encuentra de manera eficiente una solución óptima global para una relajación directa de MAP. Evaluamos nuestro enfoque utilizando los corpus de la pista web TREC 9 y TREC 10 (WT10g), comparando con SVM optimizados para precisión y área bajo la curva ROC. En la mayoría de los casos mostramos nuestro método para producir mejoras estadísticamente significativas en las puntuaciones de MAP. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de Recuperación Términos Generales Algoritmo, Teoría, Experimentación 1. INTRODUCCIÓN Los sistemas de recuperación de información de última generación comúnmente utilizan técnicas de aprendizaje automático para aprender funciones de clasificación. Sin embargo, la mayoría de los enfoques actuales no están optimizados para la medida de evaluación más utilizada, es decir, la Precisión Promedio Media (MAP). En cambio, los algoritmos actuales tienden a seguir uno de dos enfoques generales. El primer enfoque es aprender un modelo que estime la probabilidad de que un documento sea relevante dado una consulta (por ejemplo, [18, 14]). Si se resuelve de manera efectiva, la clasificación con el mejor rendimiento de MAP puede derivarse fácilmente de las probabilidades de relevancia. Sin embargo, lograr un MAP alto solo requiere encontrar un buen ordenamiento de los documentos. Como resultado, encontrar buenas probabilidades requiere resolver un problema más difícil de lo necesario, probablemente necesitando más datos de entrenamiento para lograr el mismo rendimiento de MAP. El segundo enfoque común es aprender una función que maximice una medida sustituta. Las medidas de rendimiento optimizadas incluyen precisión [17, 15], área bajo la curva ROC [1, 5, 10, 11, 13, 21] o modificaciones del área bajo la curva ROC [4], y NDCG [2, 3]. Aprender un modelo para optimizar tales medidas podría resultar en un rendimiento de MAP subóptimo. De hecho, aunque algunos sistemas anteriores han obtenido un buen rendimiento de MAP, se sabe que ni lograr una precisión óptima ni un área bajo la curva ROC pueden garantizar un rendimiento de MAP óptimo[7]. En este artículo, presentamos un enfoque general para aprender funciones de clasificación que maximizan el rendimiento de MAP. Específicamente, presentamos un algoritmo SVM que optimiza globalmente una relajación de pérdida de bisagra de MAP. Este enfoque simplifica el proceso de obtener funciones de clasificación con un alto rendimiento de MAP al evitar pasos intermedios adicionales y heurísticas. El nuevo algoritmo también hace que sea conceptualmente tan fácil optimizar las SVM para MAP como anteriormente solo era posible para precisión y ROCArea. A diferencia del trabajo reciente que optimiza directamente el rendimiento de MAP realizado por Metzler & Croft [16] y Caruana et al. [6], nuestra técnica es eficiente computacionalmente al encontrar una solución óptima a nivel global. Al igual que [6, 16], nuestro método aprende un modelo lineal, pero es mucho más eficiente en la práctica y, a diferencia de [16], puede manejar miles de características. Ahora describimos el algoritmo en detalle y proporcionamos la prueba de corrección. A continuación, proporcionamos un análisis del tiempo de ejecución. Concluimos con los resultados empíricos de experimentos en el corpus de la pista web TREC 9 y TREC 10. También hemos desarrollado un paquete de software que implementa nuestro algoritmo y está disponible para uso público. EL PROBLEMA DEL APRENDIZAJE Siguiendo la configuración estándar del aprendizaje automático, nuestro objetivo es aprender una función h: X → Y entre un espacio de entrada X (todas las consultas posibles) y un espacio de salida Y (clasificaciones sobre un corpus). Para cuantificar la calidad de una predicción, ˆy = h(x), consideraremos una función de pérdida ∆ : Y × Y → . ∆(y, ˆy) cuantifica la penalización por hacer la predicción ˆy si la salida correcta es y. La función de pérdida nos permite incorporar medidas específicas de rendimiento, las cuales explotaremos en http://svmrank.yisongyue.com para optimizar el MAP. Nos restringimos al escenario de aprendizaje supervisado, donde pares de entrada/salida (x, y) están disponibles para el entrenamiento y se asume que provienen de alguna distribución fija P(x, y). El objetivo es encontrar una función h tal que el riesgo (es decir, la pérdida esperada), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), se minimice. Por supuesto, P(x, y) es desconocido. Pero dado un conjunto finito de pares de entrenamiento, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, el rendimiento de h en S puede medirse mediante el riesgo empírico, R∆ S (h) = 1 n ∑ i=1 n ∆(yi, h(xi)). En el caso de aprender una función de recuperación clasificada, X denota un espacio de consultas, y Y el espacio de clasificaciones (posiblemente débiles) sobre algún corpus de documentos C = {d1, . . . ,d|C|}. Podemos definir la pérdida de precisión promedio como ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), donde rank(y) es un vector de los valores de <br>rango</br> de cada documento en C. Por ejemplo, para un corpus de dos documentos, {d1, d2}, con d1 teniendo un <br>rango</br> más alto que d2, rank(y) = (1, 0). Suponemos que las clasificaciones verdaderas tienen dos valores de clasificación, donde los documentos relevantes tienen un <br>valor de clasificación</br> 1 y los documentos no relevantes tienen un <br>valor de clasificación</br> 0. Además, asumimos que todas las clasificaciones predichas son clasificaciones completas (sin empates). Sea p = <br>rango</br>(y) y ˆp = <br>rango</br>(ˆy). La puntuación de precisión promedio se define como MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, donde rel = |{i : pi = 1}| es el número de documentos relevantes, y Prec@j es el porcentaje de documentos relevantes en los primeros j documentos en la clasificación predicha ˆy. MAP es la media de las puntuaciones de precisión promedio de un grupo de consultas. La mayoría de los algoritmos de aprendizaje se optimizan para precisión o ROCArea. Si bien optimizar estas medidas podría lograr un buen rendimiento de MAP, usamos dos ejemplos simples para mostrar que también puede ser subóptimo en términos de MAP. ROCArea asigna una penalización igual a cada desordenamiento de un par relevante/no relevante. Por el contrario, MAP asigna mayores penalizaciones a los errores de ordenamiento más arriba en la clasificación predicha. Usando nuestra notación, el Área bajo la Curva ROC (ROCArea) se puede definir como ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], donde p es el ranking verdadero (débil), ˆp es el ranking predicho, y 1[b] es la función indicadora condicionada a b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Tabla 1: Ejemplo y Modelos Supongamos que tenemos un espacio de hipótesis con solo dos funciones de hipótesis, h1 y h2, como se muestra en la Tabla 1. Estas dos hipótesis predicen un ranking para la consulta x sobre un corpus de ocho documentos. Tabla 2: Rendimiento de los Modelos de Juguete La Tabla 2 muestra las puntuaciones de MAP y ROCArea de h1 y h2. Aquí, un método de aprendizaje que optimiza para el Área bajo la curva ROC elegiría h2 ya que esto resulta en un puntaje de Área bajo la curva ROC más alto, pero esto produce un puntaje de MAP subóptimo. 2.2 MAP vs Precisión Usando un ejemplo muy similar, ahora demostramos cómo optimizar para la precisión podría resultar en un puntaje de MAP subóptimo. Los modelos que se optimizan para la precisión no están directamente preocupados por la clasificación. En cambio, aprenden un umbral tal que los documentos que obtienen una puntuación superior al umbral pueden ser clasificados como relevantes y los documentos que obtienen una puntuación inferior como no relevantes. Consideramos nuevamente un espacio de <br>hipótesis</br> con dos <br>hipótesis</br>. ",
            "candidates": [],
            "error": [
                [
                    "rango",
                    "rango",
                    "valor de clasificación",
                    "valor de clasificación",
                    "rango",
                    "rango",
                    "hipótesis",
                    "hipótesis"
                ]
            ]
        }
    }
}