{
    "id": "H-88",
    "original_text": "Controlling Overlap in Content-Oriented XML Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of XML documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents. This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents. The test collection developed by the INitiative for the Evaluation of XML Retrieval (INEX) forms the basis for the evaluation. Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1. INTRODUCTION The representation of documents in XML provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances. In response to a user query, an XML information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components. This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in XML. Figure 1 provides an example of a journal article encoded in XML, illustrating many of the important characteristics of XML documents. Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words. Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate. Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs. Each of these characteristics affects the design of an XML IR system, and each leads to fundamental problems that must be solved in an successful system. Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper. The article of figure 1 may be viewed as an XML tree, as illustrated in figure 2. Formally, a collection of XML documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes. For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example XML tree. of x. Since an element may be represented by the node at its root, the output of an XML IR system may be viewed as a ranked list of the top-m nodes. The direct application of a standard relevance ranking technique to a set of XML elements can produce a result in which the top ranks are dominated by many structurally related elements. A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article. For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms. If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content. One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it. Unfortunately, this approach destroys some of the possible benefits of XML IR. For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts. In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements. Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6]. This paper presents a method for controlling overlap. Starting with an initial element ranking, a re-ranking algorithm adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant. For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced. The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20]. Extending that approach, the re-ranking algorithm varies weights dynamically as elements are processed. The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a baseline retrieval method is presented in section 4. This baseline method represents a reasonable adaptation of standard IR technology to XML. Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point. A re-ranking algorithm implementing this strategy is presented in section 6 and evaluated in section 7. Section 8 discusses an extended version of the algorithm. 2. BACKGROUND This section provides a general overview of XML information retrieval and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction. Much research in the area of XML retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1]. Here, we take a content oriented IR perceptive, focusing on XML documents that primarily contain natural language data and queries that are primarily expressed in natural language. We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need. Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional information retrieval applications the standard unit of retrieval is taken to be the document. Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages. When applying standard relevance ranking techniques in the context of XML IR, a natural approach is to treat each element as a separate document, with term statistics available for each [16]. In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole. If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article. It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an XML IR system might potentially retrieve any element, many elements may not be appropriate as retrieval results. This is usually the case when elements contain very little text [10]. For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself. Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user. An effective XML IR system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18]. Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (INEX) has encouraged research into XML information retrieval technology [7,8]. INEX is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself. Over 50 groups participated in INEX 2004, and the conference has become as influential in the area of XML IR as TREC is in other IR areas. The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by INEX. Overlap causes considerable problems with retrieval evaluation, and the INEX organizers and participants have wrestled with these problems since the beginning. While substantial progress has been made, these problem are still not completely solved. Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of INEX retrieval evaluation and discuss both current and proposed evaluation metrics. Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3. INEX 2004 Space limitations prevent the inclusion of more than a brief summary of INEX 2004 tasks and evaluation methodology. For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, INEX 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002. Each document is encoded in XML using a common DTD, with the document of figures 1 and 2 providing one example. At INEX 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics. The two tasks differed in the types of topics they used. For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection. For this task, the IR system is required to select the elements to be returned. For the other task, the contentand-structure or CAS task, the topics are written in an XML query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy. Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description. In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants. Each topic includes a short keyword query, which is executed over the collection by each participating group on their own XML IR system. Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since XML IR is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient. Instead, the INEX organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic. A four-point scale is used in both dimensions. Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant. Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at INEX 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values. One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others. This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant. Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity. Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity. This paper reports results of this metric using all three of these quantization functions. Since this metric was first introduced at INEX 2002, it is generally referred as the inex-2002 metric. The inex-2002 metric does not penalize overlap. In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank. To address this problem, Kazai et al. [11] propose an XML cumulated gain metric, which compares the cumulated gain [9] of a ranked list to an ideal gain vector. This ideal gain vector is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path. Thus, the XCG metric rewards retrieval runs that avoid overlap. While XCG was not used officially at INEX 2004, a version of it is likely to be used in the future. At INEX 2003, yet another metric was introduced to ameliorate the perceived limitations of the inex-2002 metric. This inex-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them. Two versions were created, one that considered only component size and another that considered both size and overlap. While the inex-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4. BASELINE RETRIEVAL METHOD This section provides an overview of baseline XML information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3]. This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the XML information retrieval task. The MultiText system performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity. To support retrieval from XML and other structured document types, the system provides generalized queries of the form: rank X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms. For our INEX 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections. Prior to INEX 2004, the INEX collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names. Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received. Automating this selection process is planned as future work. For INEX 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer. For example, keyword field of topic 166 +tree edit distance + XML -image became the four-term query $tree $edit $distance $xml where the $ operator within a quoted string stems the term that follows it. Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞. Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(inex-2002) k1 strict generalized sog Figure 3: Impact of k1 on inex-2002 mean average precision with b = 0.75 (INEX 2003 CO topics). Prior to INEX 2004, the INEX 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section. For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article. These statistics are used for ranking all element types. Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length. The use of article statistics for all element types might be questioned. This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned. The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics. Nonetheless, we plan to examine this issue again in the future. In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose. Prior to INEX 2004, we trained the MultiText system using the INEX 2003 queries. As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system. The results were surprising. Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions. In our experience, optimal values for k1 are typically in the range 0.0 to 2.0. In this case, large values are required for good performance. Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization. Similar improvements are seen under the generalized and sog quantizations. In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4). After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our INEX 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5. CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements. At a conceptual level, re-ranking proceeds as follows: 1. Report the highest ranking element. 2. Adjust the scores of the unreported elements. 3. Repeat steps 1 and 2 until m elements are reported. One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements. For example, assume a paragraph with score p is reported in step 1. In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score. In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion. That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages. A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two. Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness. Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body. In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body. Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported. The next section presents and analysis a simple re-ranking algorithm that follows this strategy. The algorithm is evaluated experimentally in section 7. One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears. In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6. RE-RANKING ALGORITHM The re-ranking algorithm operates over XML trees, such as the one appearing in figure 2. Input to the algorithm is a list of n elements ranked according to their initial BM25 scores. During the initial ranking the XML tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |. Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores. An element is represented by the node x ∈ N at its root. Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - term frequency vector x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses. The vector x.f contains term frequency information corresponding to each term in the query. The vector x.g is initially zero and is updated by the algorithm as elements are reported. The score field contains the current BM25 score for the element, which will change as the values in x.g change. The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g. Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the re-ranking algorithm, nodes are stored in priority queues, ordered by decreasing score. Each priority queue PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue. The core of the re-ranking algorithm is presented in figure 5. The algorithm takes as input the priority queue S containing the initial ranking, and produces the top-m reranked nodes in the priority queue F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration. At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a priority queue S, containing XML nodes ranked by their initial scores, and returns its results in priority queue F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes. The tree traversal routines, Up and Down are given in figure 6. The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2. The Down routine performs a similar operation on each descendant. However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the time complexity of the algorithm, first note that a node may be an argument to Down at most once. Thereafter, the reported flag of its parent is true. During each call to Down a node may be moved from S to F, requiring O(log n) time. Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the time complexity of the loop over lines 2-15. During each iteration of this loop, a node and each of its ancestors are removed from a priority queue and then added back into a priority queue. Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time. Combining these observations produces an overall time complexity of O((n + mh) log n). In practice, re-ranking an INEX result set requires less than 200ms on a three-year-old desktop PC. 7. EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper. Nonetheless, when taken together they provide insight into the behaviour of the re-ranking algorithm. The INEX evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the inex-2002 and inex-2003 metrics. Values for the XCG metrics were computed using software supplied by its inventors [11]. Figure 7 plots the three variants of inex-2002 MAP metric together with the XCG metric. Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on inex-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0. Recalling that the XCG metric is designed to penalize overlap, while the inex-2002 metric ignores overlap, the conflict between the metrics is obvious. The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at INEX 2004 [8,12]. Figure 8 plots values of the inex-2003 MAP metric for two quantizations, with and without consideration of overlap. Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8. EXTENDED ALGORITHM One limitation of the re-ranking algorithm is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements. An obvious extension is to use different weights in these two cases. Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element. For example, a paragraph may form part of a reported section and then form part of a reported article. Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight. Motivated by these observations, the re-ranking algorithm may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times. Note that an upper bound on M is h, the maximum height of any XML tree in the collection. However, in practice M is likely to be relatively small (perhaps 3 or 4). Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights. One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument. When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down. The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors. The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall time complexity of O((nM + mh) log n). Since M ≤ h and m ≤ n, the time complexity is also O(nh log n). 9. CONCLUDING DISCUSSION When generating retrieval results over an XML collection, some overlap in the results should be tolerated, and may be beneficial. For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship. The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance. Other approaches may also help to control overlap. For example, when XML retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them. While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster. At Waterloo, we continue to develop and test our ideas for INEX 2005. In particular, we are investigating methods for learning the α and βj weights. We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10. ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation. In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11. REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava. Holistic twig joins: Optimal XML pattern matching. In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y. Mass, and A. Soffer. Searching XML documents via XML fragments. In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker. MultiText experiments for INEX 2004. In INEX 2004 Workshop Proceedings, 2004. Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas. Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit. In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu. A comprehensive XQuery to SQL translation using dynamic interval encoding. In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann. XIRQL: A query language for information retrieval in XML documents. In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors. Initiative for the Evaluation of XML Retrieval. Proceedings of the Second Workshop (INEX 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors. Initiative for the Evaluation of XML Retrieval. Proceedings of the Third Workshop (INEX 2004), Dagstuhl, Germany, December 2004. Published as Advances in XML Information Retrieval, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen. Cumulated gain-based evaluation of IR techniques. ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson. Length normalization in XML retrieval. In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries. The overlap problem in content-oriented XML retrieval evaluation. In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries. Reliability tests for the XCG and inex-2002 metrics. In INEX 2004 Workshop Proceedings, 2004. Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto. TRIX 2004 - Struggling with the overlap. In INEX 2004 Workshop Proceedings, 2004. Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu. Configurable indexing and ranking for XML information retrieval. In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 88-95, Sheffield, UK, July 2004. [15] Y. Mass and M. Mandelbrod. Retrieving the most relevant XML components. In INEX 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y. Mass and M. Mandelbrod. Component ranking and automatic query refinement for XML retrieval. In INEX 2004 Workshop Proceedings, 2004. Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan. Hierarchical language models for XML component retrieval. In INEX 2004 Workshop Proceedings, 2004. Published in LNCS 3493 [8]. [18] J. Pehcevski, J. A. Thom, and A. Vercoustre. Hybrid XML retrieval re-visited. In INEX 2004 Workshop Proceedings, 2004. Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas. Providing consistent and exhaustive relevance assessments for XML retrieval evaluation. In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor. Simple BM25 extension to multiple weighted fields. In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu. Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track. In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson. NEXI, now and next. In INEX 2004 Workshop Proceedings, 2004. Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari. An algebra for structured queries in bayesian networks. In INEX 2004 Workshop Proceedings, 2004. Published in LNCS 3493 [8].",
    "original_translation": "Controlando la superposición en la recuperación XML orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca RESUMEN La aplicación directa de técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos XML a menudo produce un conjunto de resultados en el que los primeros puestos están dominados por un gran número de elementos tomados de un pequeño número de documentos altamente relevantes. Este documento presenta y evalúa un algoritmo que vuelve a clasificar este conjunto de resultados, con el objetivo de minimizar el contenido redundante mientras se preservan los beneficios de la recuperación de elementos, incluido el beneficio de identificar componentes centrados en el tema contenidos en documentos relevantes. La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la Recuperación XML (INEX) constituye la base para la evaluación. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Búsqueda y Recuperación de Información Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. La representación de documentos en XML brinda una oportunidad para que los sistemas de recuperación de información aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias. En respuesta a una consulta de usuario, un sistema de recuperación de información XML podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes. Esta facilidad es de particular beneficio cuando una colección contiene documentos muy largos, como manuales de productos o libros, donde el usuario debe ser dirigido a las partes más relevantes de estos documentos. La Figura 1 proporciona un ejemplo de un artículo de revista codificado en XML, ilustrando muchas de las características importantes de los documentos XML. Las etiquetas indican el inicio y el final de cada elemento, con elementos que varían ampliamente en tamaño, desde una palabra hasta miles de palabras. Algunos elementos, como párrafos y secciones, pueden presentarse razonablemente al usuario como resultados de búsqueda, pero otros no son apropiados. Los elementos se superponen entre sí: los artículos contienen secciones, las secciones contienen subsecciones y las subsecciones contienen párrafos. Cada una de estas características afecta el diseño de un sistema de IR XML, y cada una conlleva problemas fundamentales que deben resolverse en un sistema exitoso. La mayoría de estos problemas fundamentales pueden resolverse mediante la cuidadosa adaptación de técnicas estándar de IR, pero los problemas causados por la superposición son únicos en esta área [4,11] y constituyen el enfoque principal de este artículo. El artículo de la figura 1 puede ser visto como un árbol XML, como se ilustra en la figura 2. Formalmente, una colección de documentos XML puede ser representada como un bosque de árboles ordenados y enraizados, que consiste en un conjunto de nodos N y un conjunto de aristas dirigidas E que conectan estos nodos. Para cada nodo x ∈ N, la notación x.parent se refiere al nodo padre de x, si existe, y la notación x.children se refiere al conjunto de nodos hijos de x. Dado que un elemento puede estar representado por el nodo en su raíz, la salida de un sistema de IR XML puede ser vista como una lista clasificada de los m nodos principales. La aplicación directa de una técnica estándar de clasificación de relevancia a un conjunto de elementos XML puede producir un resultado en el que los primeros puestos están dominados por muchos elementos estructuralmente relacionados. Una sección con una puntuación alta probablemente contenga varios párrafos con una puntuación alta y esté contenida en un artículo con una puntuación alta. Por ejemplo, muchos de los elementos en la figura 2 recibirían una puntuación alta en los algoritmos de compresión de índices de texto de consulta de palabras clave. Si cada uno de estos elementos se presenta a un usuario como un resultado individual y separado, puede perder mucho tiempo revisando y rechazando contenido redundante. Una posible solución es informar solo el elemento de mayor puntuación a lo largo de un camino dado en el árbol, y eliminar de los rangos inferiores cualquier elemento que lo contenga o esté contenido en él. Desafortunadamente, este enfoque destruye algunos de los posibles beneficios de XML IR. Por ejemplo, un elemento externo puede contener una cantidad sustancial de información que no aparece en un elemento interno, pero el elemento interno puede estar fuertemente enfocado en el tema de la consulta y proporcionar un breve resumen de los conceptos clave. En tales casos, es razonable informar sobre elementos que contienen, o están contenidos en, elementos de rango superior. Incluso cuando un libro entero es relevante, un usuario aún puede desear que se destaquen los párrafos más importantes, para guiar su lectura y ahorrar tiempo [6]. Este documento presenta un método para controlar la superposición. A partir de una clasificación inicial de elementos, un algoritmo de re-clasificación ajusta las puntuaciones de los elementos de menor clasificación que contienen, o están contenidos dentro de, elementos de mayor clasificación, reflejando el hecho de que esta información puede ser ahora redundante. Por ejemplo, una vez que un elemento que representa una sección aparece en la clasificación, las puntuaciones de los párrafos que contiene y del artículo que lo contiene se reducen. La inspiración para esta estrategia proviene parcialmente del trabajo reciente sobre la recuperación de documentos estructurados, donde los términos que aparecen en diferentes campos, como el título y el cuerpo, reciben diferentes pesos [20]. Extendiendo ese enfoque, el algoritmo de reordenamiento varía los pesos dinámicamente a medida que se procesan los elementos. El resto del documento está organizado de la siguiente manera: Después de una discusión sobre el trabajo de antecedentes y la metodología de evaluación, se presenta un método de recuperación de referencia en la sección 4. Este método de referencia representa una adaptación razonable de la tecnología estándar de IR al XML. La sección 5 luego describe una estrategia para controlar la superposición, utilizando el método de línea base como punto de partida. Un algoritmo de reordenamiento que implementa esta estrategia se presenta en la sección 6 y se evalúa en la sección 7. La sección 8 discute una versión extendida del algoritmo. 2. ANTECEDENTES Esta sección proporciona una visión general de la recuperación de información XML y discute trabajos relacionados, con énfasis en los problemas fundamentales mencionados en la introducción. Mucha investigación en el área de recuperación de XML lo ve desde una perspectiva de base de datos tradicional, preocupándose por problemas como la implementación de lenguajes de consulta estructurados [5] y el procesamiento de joins [1]. Aquí adoptamos una perspectiva de IR orientada al contenido, centrándonos en documentos XML que contienen principalmente datos en lenguaje natural y consultas que están principalmente expresadas en lenguaje natural. Suponemos que estas consultas indican únicamente la naturaleza del contenido deseado, no su estructura, y que el papel del sistema de RI es determinar qué elementos satisfacen mejor la necesidad de información subyacente. Otra investigación en IR ha considerado consultas mixtas, en las que se especifican tanto requisitos de contenido como estructurales [2,6,14,17,23]. 2.1 Estadísticas de Términos y Documentos En las aplicaciones tradicionales de recuperación de información, la unidad estándar de recuperación se considera que es el documento. Dependiendo de la aplicación, este término podría interpretarse para abarcar muchos objetos diferentes, incluyendo páginas web, artículos de periódico y mensajes de correo electrónico. Al aplicar técnicas estándar de clasificación de relevancia en el contexto de la RI XML, un enfoque natural es tratar cada elemento como un documento separado, con estadísticas de términos disponibles para cada uno [16]. Además, la mayoría de las técnicas de clasificación requieren estadísticas globales (por ejemplo, frecuencia inversa de documentos) calculadas sobre la colección en su totalidad. Si consideramos que esta colección incluye todos los elementos que podrían ser devueltos por el sistema, una ocurrencia específica de un término puede aparecer en varios documentos diferentes, quizás en elementos que representan un párrafo, una subsección, una sección y un artículo. No es apropiado calcular la frecuencia inversa de documentos bajo la suposición de que el término está contenido en todos estos elementos, ya que el número de elementos que contienen un término depende completamente del arreglo estructural de los documentos [13,23]. 2.2 Elementos Recuperables Si bien un sistema de recuperación de información XML podría potencialmente recuperar cualquier elemento, muchos elementos pueden no ser apropiados como resultados de recuperación. Esto suele ser el caso cuando los elementos contienen muy poco texto [10]. Por ejemplo, un título de sección que contenga solo los términos de búsqueda puede recibir una puntuación alta de un algoritmo de clasificación, pero por sí solo tendría un valor limitado para un usuario, quien podría preferir la sección real en sí misma. Otros elementos pueden reflejar la estructura física de los documentos, en lugar de la estructura lógica, lo cual puede tener poco o ningún significado para un usuario. Un sistema de recuperación de información XML efectivo debe devolver solo aquellos elementos que tengan suficiente contenido para ser utilizables y puedan funcionar como objetos independientes [15,18]. Componentes estándar de documentos como párrafos, secciones, subsecciones y resúmenes generalmente cumplen con estos requisitos; los títulos, frases en cursiva y campos de metadatos individuales a menudo no lo hacen. 2.3 Metodología de Evaluación En los últimos tres años, la Iniciativa para la Evaluación de la Recuperación de Información XML (INEX) ha fomentado la investigación en tecnología de recuperación de información XML [7,8]. INEX es una serie de conferencias experimentales, similar a TREC, en la que grupos de diferentes instituciones completan una o más tareas experimentales utilizando sus propias herramientas y sistemas, y comparan sus resultados en la propia conferencia. Más de 50 grupos participaron en INEX 2004, y la conferencia se ha convertido en tan influyente en el área de la RI XML como lo es TREC en otras áreas de la RI. La investigación descrita en este artículo, al igual que gran parte del trabajo relacionado que cita, depende de las colecciones de pruebas desarrolladas por INEX. La superposición causa problemas considerables en la evaluación de la recuperación, y los organizadores y participantes de INEX han luchado con estos problemas desde el principio. Aunque se ha logrado un progreso sustancial, estos problemas aún no están completamente resueltos. Kazai et al. [11] proporcionan una exposición detallada del problema de superposición en el contexto de la evaluación de recuperación de INEX y discuten tanto las métricas de evaluación actuales como las propuestas. Muchas de estas métricas se aplican para evaluar los experimentos reportados en este artículo, y se describen brevemente en la siguiente sección. 3. Las limitaciones de espacio impiden incluir más que un breve resumen de las tareas y metodología de evaluación de INEX 2004. Para obtener información detallada, se deben consultar las actas de la conferencia en sí [8]. 3.1 Tareas Para las principales tareas experimentales, a los participantes de INEX 2004 se les proporcionó una colección de 12,107 artículos tomados de las revistas y publicaciones de la IEEE Computer Societies entre 1995 y 2002. Cada documento está codificado en XML utilizando una DTD común, siendo el documento de las figuras 1 y 2 un ejemplo. En INEX 2004, las dos principales tareas experimentales fueron ambas tareas de recuperación ad hoc, investigando el rendimiento de sistemas que buscan en una colección estática utilizando temas previamente no vistos. Las dos tareas diferían en los tipos de temas que utilizaban. Para una tarea, la tarea de solo contenido o CO, los temas consisten en declaraciones cortas en lenguaje natural sin hacer referencia directa a la estructura de los documentos en la colección. Para esta tarea, se requiere que el sistema de IR seleccione los elementos a devolver. Para la otra tarea, la tarea de contenido y estructura o CAS, los temas están escritos en un lenguaje de consulta XML [22] y contienen referencias explícitas a la estructura del documento, que el sistema de IR debe intentar satisfacer. Dado que el trabajo descrito en este documento se enfoca en la tarea de solo contenido, donde el sistema de IR no recibe orientación sobre los elementos a devolver, la tarea de CAS se ignora en el resto de nuestra descripción. En 2004, los organizadores de la conferencia seleccionaron 40 nuevos temas de CO de las contribuciones proporcionadas por los participantes de la conferencia. Cada tema incluye una breve consulta de palabras clave, la cual es ejecutada sobre la colección por cada grupo participante en su propio sistema de IR XML. Cada grupo podría presentar hasta tres ejecuciones experimentales que consistieran en los primeros m = 1500 elementos para cada tema. 3.2 Evaluación de Relevancia Dado que la RI XML se preocupa por localizar aquellos elementos que proporcionan una cobertura completa de un tema mientras contienen la menor cantidad de información irrelevante posible, los juicios simples de relevante vs. no relevante no son suficientes. En cambio, los organizadores de INEX adoptaron dos dimensiones para la evaluación de relevancia: la dimensión de exhaustividad refleja el grado en que un elemento abarca el tema, y la dimensión de especificidad refleja el grado en que un elemento se enfoca en el tema. Se utiliza una escala de cuatro puntos en ambas dimensiones. Por lo tanto, un elemento (3,3) es altamente exhaustivo y altamente específico, un elemento (1,3) es marginalmente exhaustivo y altamente específico, y un elemento (0,0) no es relevante. Información adicional sobre la metodología de evaluación se puede encontrar en Piwowarski y Lalmas [19], quienes proporcionan una justificación detallada. 3.3 Métricas de Evaluación La métrica de evaluación principal utilizada en INEX 2004 es una versión de la precisión promedio media (MAP), ajustada por diversas funciones de cuantificación para dar diferentes pesos a diferentes elementos, dependiendo de sus valores de exhaustividad y especificidad. Una variante, la función de cuantización estricta asigna un peso de 1 a los elementos (3,3) y un peso de 0 a todos los demás. Esta variante es esencialmente el valor MAP familiar, con elementos (3,3) tratados como relevantes y todos los demás elementos tratados como no relevantes. Otras funciones de cuantización están diseñadas para otorgar crédito parcial a elementos que son aproximaciones cercanas, debido a la falta de exhaustividad y/o especificidad. Tanto la función de cuantificación generalizada como la función de generalización orientada a la especificidad (sog) acreditan elementos según su grado de relevancia [11], siendo que la segunda función pone mayor énfasis en la especificidad. Este documento informa los resultados de esta métrica utilizando las tres funciones de cuantización. Desde que esta métrica fue introducida por primera vez en INEX 2002, generalmente se le conoce como la métrica inex-2002. La métrica inex-2002 no penaliza la superposición. En particular, tanto las funciones de cuantificación generalizadas como las de sog otorgan crédito parcial a un casi acierto incluso cuando se informa un elemento (3,3) que se superpone a él en un rango más alto. Para abordar este problema, Kazai et al. [11] proponen una métrica de ganancia acumulada XML, que compara la ganancia acumulada [9] de una lista clasificada con un vector de ganancia ideal. Este vector de ganancia ideal se construye a partir de las valoraciones de relevancia al eliminar la superposición y retener solo el mejor elemento a lo largo de un camino dado. Por lo tanto, la métrica XCG recompensa las ejecuciones de recuperación que evitan la superposición. Aunque XCG no se utilizó oficialmente en INEX 2004, es probable que se utilice una versión de él en el futuro. En INEX 2003, se introdujo otra métrica para mejorar las limitaciones percibidas de la métrica inex-2002. Este métrico inex-2003 extiende las definiciones de precisión y exhaustividad para considerar tanto el tamaño de los componentes informados como la superposición entre ellos. Se crearon dos versiones, una que consideraba solo el tamaño de los componentes y otra que consideraba tanto el tamaño como la superposición. Si bien la métrica inex-2003 presenta anomalías no deseadas [11] y no se utilizó en 2004, se informan valores en la sección de evaluación para proporcionar un instrumento adicional para investigar la superposición. 4. MÉTODO DE RECUPERACIÓN DE BASELINE Esta sección proporciona una descripción general del método de recuperación de información XML de base actualmente utilizado en el sistema MultiText IR, desarrollado por el Grupo de Recuperación de Información de la Universidad de Waterloo [3]. Este método de recuperación resulta de la adaptación y ajuste de la medida Okapi BM25 [21] a la tarea de recuperación de información en XML. El sistema MultiText tuvo un desempeño respetable en INEX 2004, ubicándose entre los diez primeros en todas las funciones de cuantización, y ocupando el primer lugar cuando la función de cuantización enfatizaba la exhaustividad. Para admitir la recuperación de XML y otros tipos de documentos estructurados, el sistema proporciona consultas generalizadas de la forma: clasificar X por Y donde X es una subconsulta que especifica un conjunto de elementos de documentos a clasificar y Y es un vector de subconsultas que especifican términos de recuperación individuales. Para nuestras ejecuciones de INEX 2004, la subconsulta X especificó una lista de elementos recuperables como aquellos con nombres de etiquetas de la siguiente manera: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt. Esta lista incluye entradas bibliográficas (bb) y leyendas de figuras (fig) así como párrafos, secciones y subsecciones. Antes de INEX 2004, la colección de INEX y las evaluaciones de relevancia de INEX 2003 fueron analizadas manualmente para seleccionar estos nombres de etiquetas. Los nombres de las etiquetas fueron seleccionados en base a su frecuencia en la colección, el tamaño promedio de sus elementos asociados y el número relativo de juicios de relevancia positiva que recibieron. Automatizar este proceso de selección está planeado como trabajo futuro. Para INEX 2004, el vector término Y se derivó del tema dividiendo frases en palabras individuales, eliminando palabras vacías y términos negativos (aquellos que comienzan con -), y aplicando un stemmer. Por ejemplo, el campo de palabra clave del tema 166 +distancia de edición de árbol + XML -imagen se convirtió en la consulta de cuatro términos $árbol $edición $distancia $xml donde el operador $ dentro de una cadena entre comillas deriva el término que le sigue. Nuestra implementación de Okapi BM25 se deriva de la fórmula de Robertson et al. [21] al establecer los parámetros k2 = 0 y k3 = ∞. Dado un conjunto de términos Q, a un elemento x se le asigna la puntuación t∈Q w(1) qt (k1 + 1)xt K + xt (1) donde w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = número de documentos en el corpus Dt = número de documentos que contienen t qt = frecuencia con la que t ocurre en el tema xt = frecuencia con la que t ocurre en x K = k1((1 − b) + b · lx/lavg) lx = longitud de x lavg = longitud promedio del documento 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 PrecisiónPromedio(inex-2002) k1 estricto generalizado sog Figura 3: Impacto de k1 en la precisión promedio de inex-2002 con b = 0.75 (temas CO de INEX 2003). Antes de INEX 2004, los temas y juicios de INEX 2003 se utilizaron para ajustar los parámetros b y k1, y el impacto de este ajuste se discute más adelante en esta sección. Para los propósitos de calcular estadísticas a nivel de documento (D, Dt y lavg), un documento se define como un artículo. Estas estadísticas se utilizan para clasificar todos los tipos de elementos. Siguiendo la sugerencia de Kamps et al. [10], los resultados de recuperación se filtran para eliminar elementos muy cortos, aquellos con menos de 25 palabras de longitud. El uso de estadísticas de artículos para todos los tipos de elementos podría ser cuestionado. Este enfoque puede justificarse al considerar la colección como un conjunto de artículos que se pueden buscar utilizando técnicas estándar orientadas a documentos, donde solo se devuelven artículos. El puntaje calculado para un elemento es esencialmente el puntaje que recibiría si se agregara a la colección como un nuevo documento, ignorando los ajustes menores necesarios para las estadísticas a nivel de documento. Sin embargo, planeamos examinar este tema nuevamente en el futuro. En nuestra experiencia, el rendimiento de BM25 suele beneficiarse al ajustar los parámetros b y k1 a la colección, siempre que haya consultas de entrenamiento disponibles con este propósito. Antes de INEX 2004, entrenamos el sistema MultiText utilizando las consultas de INEX 2003. Como punto de partida, utilizamos los valores b = 0.75 y k1 = 1.2, que funcionan bien en colecciones TREC adhoc y se utilizan como valores predeterminados en nuestro sistema. Los resultados fueron sorprendentes. La Figura 3 muestra el resultado de variar k1 con b = 0.75 en los valores de MAP bajo tres funciones de cuantización. En nuestra experiencia, los valores óptimos para k1 suelen estar en el rango de 0.0 a 2.0. En este caso, se requieren valores grandes para un buen rendimiento. Entre k1 = 1.0 y k1 = 6.0, el MAP aumenta en más del 15% bajo la cuantización estricta. Se observan mejoras similares bajo las cuantizaciones generalizada y SOG. Por el contrario, nuestro valor predeterminado de b = 0.75 funciona bien bajo todas las funciones de cuantificación (figura 4). Después de ajustar una amplia gama de valores bajo varias funciones de cuantización, seleccionamos los valores de k = 10.0 y b = 0.80 para nuestros experimentos de INEX 2004, y estos valores se utilizan para los experimentos reportados en la sección 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 PrecisiónPromedioMedia (inex-2002) b estricto generalizado sog Figura 4: Impacto de b en la precisión promedio media de inex-2002 con k1 = 10 (temas CO de INEX 2003). 5. CONTROL DE SUPERPOSICIÓN Comenzando con una clasificación de elementos generada por el método de referencia descrito en la sección anterior, los elementos se vuelven a clasificar para controlar la superposición ajustando de forma iterativa las puntuaciones de aquellos elementos que contienen o están contenidos en elementos de clasificación más alta. A nivel conceptual, la reorganización procede de la siguiente manera: 1. Informe el elemento de rango más alto. Ajustar las puntuaciones de los elementos no reportados. 3. Repetir los pasos 1 y 2 hasta que se informen m elementos. Un enfoque para ajustar las puntuaciones de los elementos no informados en el paso 2 podría basarse en las puntuaciones Okapi BM25 de los elementos involucrados. Por ejemplo, supongamos que se informa un párrafo con una puntuación p en el paso 1. En el paso 2, la sección que contiene el párrafo podría tener su puntuación s reducida en una cantidad α · p para reflejar la contribución reducida que el párrafo debería hacer a la puntuación de las secciones. En un contexto relacionado, Robertson et al. [20] argumentan en contra de la combinación lineal de las puntuaciones de Okapi de esta manera. Ese trabajo considera el problema de asignar diferentes pesos a diferentes campos de documentos, como el título y el cuerpo asociados con páginas web. Un enfoque común para este problema puntúa el título y el cuerpo por separado y genera una puntuación final como una combinación lineal de ambos. Robertson et al. discuten las deficiencias teóricas en este enfoque y demuestran experimentalmente que puede perjudicar realmente la efectividad de la recuperación. En cambio, aplican los pesos a nivel de frecuencia de términos, donde la aparición de un término de consulta t en el título contribuye más al puntaje que una aparición en el cuerpo. En la ecuación 1, xt se convierte en α0 · yt + α1 · zt, donde yt es el número de veces que t aparece en el título y zt es el número de veces que t aparece en el cuerpo. Al traducir este enfoque a nuestro contexto, la contribución de los términos que aparecen en los elementos se reduce dinámicamente a medida que se informan. La siguiente sección presenta y analiza un algoritmo de reordenamiento simple que sigue esta estrategia. El algoritmo se evalúa experimentalmente en la sección 7. Una limitación del algoritmo es que la contribución de los términos que aparecen en los elementos informados se reduce por el mismo factor independientemente del número de elementos informados en los que aparezca. En la sección 8, el algoritmo se extiende para aplicar pesos crecientes, disminuyendo la puntuación, cuando un término aparece en más de un elemento informado. 6. ALGORITMO DE REORDENAMIENTO El algoritmo de reordenamiento opera sobre árboles XML, como el que aparece en la figura 2. La entrada al algoritmo es una lista de n elementos clasificados según sus puntuaciones iniciales de BM25. Durante la clasificación inicial, el árbol XML se reconstruye dinámicamente para incluir solo aquellos nodos con puntuaciones BM25 distintas de cero, por lo que n puede ser considerablemente menor que |N|. La salida del algoritmo es una lista de los primeros m elementos, clasificados según sus puntajes ajustados. Un elemento está representado por el nodo x ∈ N en su raíz. Asociados con este nodo se encuentran campos que almacenan la longitud del elemento, las frecuencias de términos y otra información requerida por el algoritmo de re-ranking, de la siguiente manera: x.f - vector de frecuencia de términos x.g - ajustes de frecuencia de términos x.l - longitud del elemento x.score - puntaje actual de Okapi BM25 x.reported - bandera booleana, inicialmente falsa x.children - conjunto de nodos hijos x.parent - nodo padre, si existe Estos campos se llenan durante el proceso de clasificación inicial y se actualizan a medida que avanza el algoritmo. El vector x.f contiene información de frecuencia de términos correspondiente a cada término en la consulta. El vector x.g es inicialmente cero y se actualiza por el algoritmo a medida que se informan elementos. El campo de puntuación contiene la puntuación BM25 actual para el elemento, la cual cambiará a medida que cambien los valores en x.g. El puntaje se calcula utilizando la ecuación 1, con el valor xt para cada término determinado por una combinación de los valores en x.f y x.g. Dado un término t ∈ Q, sea ft el componente de x.f correspondiente a t, y sea gt el componente de x.g correspondiente a t, entonces: xt = ft − α · gt (2) Para el procesamiento por el algoritmo de reordenamiento, los nodos se almacenan en colas de prioridad, ordenadas por puntaje decreciente. Cada cola de prioridad PQ admite tres operaciones: PQ.front() - devuelve el nodo con la puntuación más alta, PQ.add(x) - agrega el nodo x a la cola, PQ.remove(x) - elimina el nodo x de la cola. Cuando se implementan utilizando estructuras de datos estándar, la operación front requiere tiempo O(1), y las otras operaciones requieren tiempo O(log n), donde n es el tamaño de la cola. El núcleo del algoritmo de reordenamiento se presenta en la figura 5. El algoritmo toma como entrada la cola de prioridad S que contiene la clasificación inicial, y produce los primeros m nodos reordenados en la cola de prioridad F. Después de inicializar F como vacío en la línea 1, el algoritmo recorre m veces las líneas 215, transfiriendo al menos un nodo de S a F durante cada iteración. Al inicio de cada iteración, el nodo no reportado al frente de S tiene el mayor puntaje ajustado, y se elimina y se agrega a F. El algoritmo luego recorre el 1 F ← ∅ 2 para i ← 1 a m hacer 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 para cada y ∈ x.children hacer 9 Abajo (y) 10 fin hacer 11 12 si x no es un nodo raíz entonces 13 Arriba (x, x.parent) 14 fin si 15 fin hacer Figura 5: Algoritmo de Re-Ranking - Como entrada, el algoritmo toma una cola de prioridad S, que contiene nodos XML clasificados por sus puntajes iniciales, y devuelve sus resultados en la cola de prioridad F, clasificados por puntajes ajustados. 1 Arriba(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recalcular y.score 5 S.add(y) 6 si y no es un nodo raíz entonces 7 Arriba (x, y.parent) 8 fin si 9 10 Abajo(x) ≡ 11 si no x.reported entonces 12 S.remove(x) 14 x.g ← x.f 15 recalcular x.score 16 si x.score > 0 entonces 17 F.add(x) 18 fin si 19 x.reported ← true 20 para cada y ∈ x.children hacer 21 Abajo (y) 22 fin hacer 23 fin si Figura 6: Rutinas de recorrido de árbol llamadas por el algoritmo de re-ranking. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 PrecisiónPromedioMedia (inex-2002) GananciaAcumuladaXML(XCG) alfa MAP (estricto) MAP (generalizado) MAP (sog) XCG (sog2) Figura 7: Impacto de α en XCG y MAP inex-2002 (temas CO de INEX 2004; conjunto de evaluación I). nodos ancestros (líneas 8-10) y descendientes (líneas 12-14) ajustando los puntajes de estos nodos. Las rutinas de recorrido de árboles, Arriba y Abajo, se muestran en la figura 6. El procedimiento Up elimina cada nodo ancestro de S, ajusta sus valores de frecuencia de término, recalcula su puntuación y lo vuelve a agregar a S. El ajuste de los valores de frecuencia de término (línea 3) agrega a y.g solo las ocurrencias de términos no reportadas previamente en x. El recalculo de la puntuación en la línea 4 utiliza las ecuaciones 1 y 2. La rutina Down realiza una operación similar en cada descendiente. Sin embargo, dado que el contenido de cada descendiente está completamente contenido en un elemento informado, su puntuación final puede ser calculada, y se elimina de S y se agrega a F. Para determinar la complejidad temporal del algoritmo, primero observe que un nodo puede ser un argumento de Down como máximo una vez. Posteriormente, la bandera reportada de su padre es verdadera. Durante cada llamada a Down, un nodo puede ser movido de S a F, lo que requiere un tiempo O(log n). Por lo tanto, el tiempo total para todas las llamadas a Down es O(n log n), y podemos ignorar temporalmente las líneas 8-10 de la figura 5 al considerar la complejidad temporal del bucle sobre las líneas 2-15. Durante cada iteración de este bucle, se elimina un nodo y cada uno de sus ancestros de una cola de prioridad y luego se vuelven a agregar a la cola de prioridad. Dado que un nodo puede tener como máximo h ancestros, donde h es la altura máxima de cualquier árbol en la colección, cada una de las m iteraciones requiere un tiempo de O(h log n). La combinación de estas observaciones produce una complejidad temporal general de O((n + mh) log n). En la práctica, volver a clasificar un conjunto de resultados de INEX requiere menos de 200 ms en una PC de escritorio de tres años de antigüedad. EVALUACIÓN Ninguna de las métricas descritas en la sección 3.3 se ajusta adecuadamente a la perspectiva de superposición defendida por este documento. Sin embargo, cuando se toman en conjunto, proporcionan información sobre el comportamiento del algoritmo de reordenamiento. Los paquetes de evaluación de INEX (inex_eval e inex_eval_ng) se utilizaron para calcular los valores de las métricas inex-2002 e inex-2003. Los valores de las métricas XCG fueron calculados utilizando el software proporcionado por sus inventores [11]. La Figura 7 representa juntas las tres variantes de la métrica MAP inex-2002 junto con la métrica XCG. Los valores para estas métricas 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Precisión Media Promedio (inex-2003) alfa estricto, superposición no considerada estricto, superposición considerada generalizado, superposición no considerada generalizado, superposición considerada Figura 8: Impacto de α en MAP inex-2003 (temas CO de INEX 2004; conjunto de evaluación I). se trazan para valores de α entre 0.0 y 1.0. Recordando que la métrica XCG está diseñada para penalizar la superposición, mientras que la métrica inex-2002 ignora la superposición, el conflicto entre las métricas es evidente. Los valores de MAP en un extremo (α = 0.0) y el valor de XCG en el otro extremo (α = 1.0) representan un rendimiento de recuperación comparable a los mejores sistemas en INEX 2004 [8,12]. La Figura 8 muestra los valores de la métrica MAP inex-2003 para dos cuantificaciones, con y sin consideración de la superposición. Una vez más, el conflicto es evidente, con la influencia de α considerablemente disminuida cuando se considera la superposición. 8. ALGORITMO EXTENDIDO Una limitación del algoritmo de reordenamiento es que se utiliza un único peso α para ajustar las puntuaciones tanto de los ancestros como de los descendientes de los elementos informados. Una extensión obvia es usar diferentes pesos en estos dos casos. Además, se utiliza el mismo peso independientemente de cuántas veces un elemento esté contenido en un elemento informado. Por ejemplo, un párrafo puede formar parte de una sección reportada y luego formar parte de un artículo reportado. Dado que el usuario puede haber visto este párrafo dos veces, su puntuación debería ser reducida aún más aumentando el valor del peso. Motivado por estas observaciones, el algoritmo de reordenamiento puede ser extendido con una serie de pesos 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0, donde βj es el peso aplicado a un nodo que ha sido descendiente de un nodo reportado j veces. Ten en cuenta que un límite superior en M es h, la altura máxima de cualquier árbol XML en la colección. Sin embargo, en la práctica es probable que M sea relativamente pequeño (quizás 3 o 4). La Figura 9 presenta reemplazos para las rutinas de Subir y Bajar de la Figura 6, incorporando esta serie de pesas. Se requiere un campo adicional en cada nodo, de la siguiente manera: x.j - conteo descendente El valor de x.j se establece inicialmente en cero en todos los nodos y se incrementa cada vez que se llama a Down con x como su argumento. Al calcular la puntuación del nodo, el valor de x.j selecciona 1 Up(x, y) ≡ 2 si no y.reported entonces 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recalcular y.score 6 S.add(y) 8 si y no es un nodo raíz entonces 9 Up (x, y.padre) 10 fin si 11 fin si 12 13 Down(x) ≡ 14 si x.j < M entonces 15 x.j ← x.j + 1 16 si no x.reported entonces 17 S.remove(x) 18 recalcular x.score 19 S.add(x) 20 fin si 21 para cada y ∈ x.hijos hacer 22 Down (y) 23 fin hacer 24 fin si Figura 9: Rutinas extendidas de recorrido de árbol. el peso a aplicar al nodo ajustando el valor de xt en la ecuación 1, de la siguiente manera: xt = βx.j · (ft − α · gt) (3) donde ft y gt son los componentes de x.f y x.g correspondientes al término t. Se requieren algunos cambios adicionales para extender Up y Down. La rutina Up devuelve inmediatamente (línea 2) si su argumento ya ha sido reportado, ya que las frecuencias de términos ya han sido ajustadas en sus ancestros. El procedimiento Down no informa su argumento, sino que vuelve a calcular su puntuación y la agrega de nuevo a S. Un nodo no puede ser un argumento de Down más de M +1 veces, lo que a su vez implica una complejidad temporal total de O((nM + mh) log n). Dado que M ≤ h y m ≤ n, la complejidad temporal también es O(nh log n). DISCUSIÓN CONCLUSIVA Al generar resultados de recuperación en una colección de XML, se debe tolerar cierta superposición en los resultados, lo cual puede ser beneficioso. Por ejemplo, cuando un elemento altamente exhaustivo y bastante específico (3,2) contiene un elemento mucho más pequeño (2,3), ambos deben ser informados al usuario, y los algoritmos de recuperación y las métricas de evaluación deben respetar esta relación. El algoritmo presentado en este documento controla la superposición ponderando los términos que aparecen en los elementos informados para reflejar su menor importancia. Otros enfoques también pueden ayudar a controlar la superposición. Por ejemplo, cuando se presentan los resultados de recuperación de XML a los usuarios, puede ser deseable agrupar elementos relacionados estructuralmente juntos, ilustrando visualmente las relaciones entre ellos. Si bien este estilo de interfaz de usuario puede ayudar a un usuario a lidiar con la superposición, la estrategia presentada en este documento sigue siendo aplicable, al determinar los mejores elementos para incluir en cada grupo. En Waterloo, seguimos desarrollando y probando nuestras ideas para INEX 2005. En particular, estamos investigando métodos para aprender los pesos α y βj. También estamos reevaluando nuestro enfoque en las estadísticas de documentos y examinando ajustes apropiados al parámetro k1 a medida que cambian los pesos de los términos [20]. 10. AGRADECIMIENTOS Gracias a Gabriella Kazai y Arjen de Vries por proporcionar una versión temprana de su software para calcular la métrica XCG, y gracias a Phil Tilker y Stefan B¨uttcher por su ayuda con la evaluación experimental. En parte, la financiación para este proyecto fue proporcionada por IBM Canadá a través del Instituto Nacional de Investigación de Software. 11. REFERENCIAS [1] N. Bruno, N. Koudas y D. Srivastava. Uniones de ramas holísticas: Coincidencia óptima de patrones XML. En Actas de la Conferencia Internacional ACM SIGMOD 2002 sobre la Gestión de Datos, páginas 310-321, Madison, Wisconsin, junio de 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y. Masa y A. Soffer. Buscando documentos XML a través de fragmentos XML. En Actas de la 26ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 151-158, Toronto, Canadá, 2003. [3] C. L. A. Clarke y P. L. Tilker. Experimentos MultiText para INEX 2004. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai y M. Lalmas. Tolerancia a la irrelevancia: Una evaluación orientada al esfuerzo del usuario de sistemas de recuperación sin unidad de recuperación predefinida. En las Actas de la Conferencia RIAO 2004, páginas 463-473, Aviñón, Francia, abril de 2004. [5] D. DeHaan, D. Toman, M. P. Consens y M. T. ¨Ozsu. Una traducción exhaustiva de XQuery a SQL utilizando codificación dinámica de intervalos. En Actas de la Conferencia Internacional ACM SIGMOD 2003 sobre la Gestión de Datos, San Diego, junio de 2003. [6] N. Fuhr y K. Großjohann. XIRQL: Un lenguaje de consulta para la recuperación de información en documentos XML. En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 172-180, Nueva Orleans, septiembre de 2001. [7] N. Fuhr, M. Lalmas y S. Malik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Segundo Taller (INEX 2003), Dagstuhl, Alemania, diciembre de 2003. [8] N. Fuhr, M. Lalmas, S. Malik y Zoltán Szlávik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Tercer Taller (INEX 2004), Dagstuhl, Alemania, diciembre de 2004. Publicado como Avances en la Recuperación de Información XML, Notas de Conferencia en Ciencias de la Computación, volumen 3493, Springer, 2005. [9] K. J¨avelin y J. Kek¨al¨ainen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, y B. Sigurbjörnsson. Normalización de longitud en la recuperación de XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 80-87, Sheffield, Reino Unido, julio de 2004. [11] G. Kazai, M. Lalmas y A. P. de Vries. El problema de superposición en la evaluación de la recuperación de XML orientada al contenido. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 72-79, Sheffield, Reino Unido, julio de 2004. [12] G. Kazai, M. Lalmas y A. P. de Vries. Pruebas de confiabilidad para las métricas XCG e inex-2002. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola y T. Aalto. TRIX 2004 - Luchando con la superposición. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [14] S. Liu, Q. Zou y W. W. Chu. Indexación y clasificación configurables para la recuperación de información en XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 88-95, Sheffield, Reino Unido, julio de 2004. [15] Y. Masa y M. Mandelbrot. Recuperando los componentes XML más relevantes. En las Actas del Taller INEX 2003, Dagstuhl, Alemania, diciembre de 2003. [16] Y. Masa y M. Mandelbrot. Clasificación de componentes y refinamiento automático de consultas para la recuperación de XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [17] P. Ogilvie y J. Callan. Modelos de lenguaje jerárquicos para la recuperación de componentes XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [18] J. Pehcevski, J. A. Thom y A. Vercoustre. Recuperación híbrida de XML revisitada. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [19] B. Piwowarski y M. Lalmas. Proporcionando evaluaciones de relevancia consistentes y exhaustivas para la evaluación de recuperación de XML. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 361-370, Washington, DC, noviembre de 2004. [20] S. Robertson, H. Zaragoza y M. Taylor. Extensión simple de BM25 a múltiples campos ponderados. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 42-50, Washington, DC, noviembre de 2004. [21] S. E. Robertson, S. Walker y M. Beaulieu. Okapi en TREC-7: Búsqueda automática, filtrado, VLC y pista interactiva. En Actas de la Séptima Conferencia de Recuperación de Texto, Gaithersburg, MD, noviembre de 1998. [22] A. Trotman y B. Sigurbjörnsson. NEXI, ahora y después. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski y P. Gallinari. Un álgebra para consultas estructuradas en redes bayesianas. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8].",
    "original_sentences": [
        "Controlling Overlap in Content-Oriented XML Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of XML documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
        "This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents.",
        "The test collection developed by the INitiative for the Evaluation of XML Retrieval (INEX) forms the basis for the evaluation.",
        "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1.",
        "INTRODUCTION The representation of documents in XML provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
        "In response to a user query, an XML information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
        "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in XML.",
        "Figure 1 provides an example of a journal article encoded in XML, illustrating many of the important characteristics of XML documents.",
        "Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words.",
        "Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate.",
        "Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs.",
        "Each of these characteristics affects the design of an XML IR system, and each leads to fundamental problems that must be solved in an successful system.",
        "Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper.",
        "The article of figure 1 may be viewed as an XML tree, as illustrated in figure 2.",
        "Formally, a collection of XML documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes.",
        "For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example XML tree. of x.",
        "Since an element may be represented by the node at its root, the output of an XML IR system may be viewed as a ranked list of the top-m nodes.",
        "The direct application of a standard relevance ranking technique to a set of XML elements can produce a result in which the top ranks are dominated by many structurally related elements.",
        "A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article.",
        "For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms.",
        "If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content.",
        "One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it.",
        "Unfortunately, this approach destroys some of the possible benefits of XML IR.",
        "For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts.",
        "In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements.",
        "Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6].",
        "This paper presents a method for controlling overlap.",
        "Starting with an initial element ranking, a re-ranking algorithm adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
        "For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced.",
        "The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20].",
        "Extending that approach, the re-ranking algorithm varies weights dynamically as elements are processed.",
        "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a baseline retrieval method is presented in section 4.",
        "This baseline method represents a reasonable adaptation of standard IR technology to XML.",
        "Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point.",
        "A re-ranking algorithm implementing this strategy is presented in section 6 and evaluated in section 7.",
        "Section 8 discusses an extended version of the algorithm. 2.",
        "BACKGROUND This section provides a general overview of XML information retrieval and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
        "Much research in the area of XML retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1].",
        "Here, we take a content oriented IR perceptive, focusing on XML documents that primarily contain natural language data and queries that are primarily expressed in natural language.",
        "We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need.",
        "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional information retrieval applications the standard unit of retrieval is taken to be the document.",
        "Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages.",
        "When applying standard relevance ranking techniques in the context of XML IR, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
        "In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole.",
        "If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article.",
        "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an XML IR system might potentially retrieve any element, many elements may not be appropriate as retrieval results.",
        "This is usually the case when elements contain very little text [10].",
        "For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself.",
        "Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user.",
        "An effective XML IR system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18].",
        "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (INEX) has encouraged research into XML information retrieval technology [7,8].",
        "INEX is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
        "Over 50 groups participated in INEX 2004, and the conference has become as influential in the area of XML IR as TREC is in other IR areas.",
        "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by INEX.",
        "Overlap causes considerable problems with retrieval evaluation, and the INEX organizers and participants have wrestled with these problems since the beginning.",
        "While substantial progress has been made, these problem are still not completely solved.",
        "Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of INEX retrieval evaluation and discuss both current and proposed evaluation metrics.",
        "Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3.",
        "INEX 2004 Space limitations prevent the inclusion of more than a brief summary of INEX 2004 tasks and evaluation methodology.",
        "For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, INEX 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002.",
        "Each document is encoded in XML using a common DTD, with the document of figures 1 and 2 providing one example.",
        "At INEX 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics.",
        "The two tasks differed in the types of topics they used.",
        "For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection.",
        "For this task, the IR system is required to select the elements to be returned.",
        "For the other task, the contentand-structure or CAS task, the topics are written in an XML query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy.",
        "Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description.",
        "In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants.",
        "Each topic includes a short keyword query, which is executed over the collection by each participating group on their own XML IR system.",
        "Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since XML IR is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient.",
        "Instead, the INEX organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic.",
        "A four-point scale is used in both dimensions.",
        "Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant.",
        "Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at INEX 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values.",
        "One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others.",
        "This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant.",
        "Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity.",
        "Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity.",
        "This paper reports results of this metric using all three of these quantization functions.",
        "Since this metric was first introduced at INEX 2002, it is generally referred as the inex-2002 metric.",
        "The inex-2002 metric does not penalize overlap.",
        "In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank.",
        "To address this problem, Kazai et al. [11] propose an XML cumulated gain metric, which compares the cumulated gain [9] of a ranked list to an ideal gain vector.",
        "This ideal gain vector is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path.",
        "Thus, the XCG metric rewards retrieval runs that avoid overlap.",
        "While XCG was not used officially at INEX 2004, a version of it is likely to be used in the future.",
        "At INEX 2003, yet another metric was introduced to ameliorate the perceived limitations of the inex-2002 metric.",
        "This inex-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them.",
        "Two versions were created, one that considered only component size and another that considered both size and overlap.",
        "While the inex-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4.",
        "BASELINE RETRIEVAL METHOD This section provides an overview of baseline XML information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3].",
        "This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the XML information retrieval task.",
        "The MultiText system performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
        "To support retrieval from XML and other structured document types, the system provides generalized queries of the form: rank X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms.",
        "For our INEX 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections.",
        "Prior to INEX 2004, the INEX collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names.",
        "Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received.",
        "Automating this selection process is planned as future work.",
        "For INEX 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.",
        "For example, keyword field of topic 166 +tree edit distance + XML -image became the four-term query $tree $edit $distance $xml where the $ operator within a quoted string stems the term that follows it.",
        "Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞.",
        "Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(inex-2002) k1 strict generalized sog Figure 3: Impact of k1 on inex-2002 mean average precision with b = 0.75 (INEX 2003 CO topics).",
        "Prior to INEX 2004, the INEX 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.",
        "For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article.",
        "These statistics are used for ranking all element types.",
        "Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length.",
        "The use of article statistics for all element types might be questioned.",
        "This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.",
        "The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics.",
        "Nonetheless, we plan to examine this issue again in the future.",
        "In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose.",
        "Prior to INEX 2004, we trained the MultiText system using the INEX 2003 queries.",
        "As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system.",
        "The results were surprising.",
        "Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions.",
        "In our experience, optimal values for k1 are typically in the range 0.0 to 2.0.",
        "In this case, large values are required for good performance.",
        "Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization.",
        "Similar improvements are seen under the generalized and sog quantizations.",
        "In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).",
        "After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our INEX 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5.",
        "CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements.",
        "At a conceptual level, re-ranking proceeds as follows: 1.",
        "Report the highest ranking element. 2.",
        "Adjust the scores of the unreported elements. 3.",
        "Repeat steps 1 and 2 until m elements are reported.",
        "One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements.",
        "For example, assume a paragraph with score p is reported in step 1.",
        "In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score.",
        "In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion.",
        "That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages.",
        "A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two.",
        "Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness.",
        "Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body.",
        "In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body.",
        "Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported.",
        "The next section presents and analysis a simple re-ranking algorithm that follows this strategy.",
        "The algorithm is evaluated experimentally in section 7.",
        "One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears.",
        "In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6.",
        "RE-RANKING ALGORITHM The re-ranking algorithm operates over XML trees, such as the one appearing in figure 2.",
        "Input to the algorithm is a list of n elements ranked according to their initial BM25 scores.",
        "During the initial ranking the XML tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |.",
        "Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores.",
        "An element is represented by the node x ∈ N at its root.",
        "Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - term frequency vector x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses.",
        "The vector x.f contains term frequency information corresponding to each term in the query.",
        "The vector x.g is initially zero and is updated by the algorithm as elements are reported.",
        "The score field contains the current BM25 score for the element, which will change as the values in x.g change.",
        "The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g.",
        "Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the re-ranking algorithm, nodes are stored in priority queues, ordered by decreasing score.",
        "Each priority queue PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
        "The core of the re-ranking algorithm is presented in figure 5.",
        "The algorithm takes as input the priority queue S containing the initial ranking, and produces the top-m reranked nodes in the priority queue F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
        "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a priority queue S, containing XML nodes ranked by their initial scores, and returns its results in priority queue F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
        "The tree traversal routines, Up and Down are given in figure 6.",
        "The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2.",
        "The Down routine performs a similar operation on each descendant.",
        "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the time complexity of the algorithm, first note that a node may be an argument to Down at most once.",
        "Thereafter, the reported flag of its parent is true.",
        "During each call to Down a node may be moved from S to F, requiring O(log n) time.",
        "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the time complexity of the loop over lines 2-15.",
        "During each iteration of this loop, a node and each of its ancestors are removed from a priority queue and then added back into a priority queue.",
        "Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time.",
        "Combining these observations produces an overall time complexity of O((n + mh) log n).",
        "In practice, re-ranking an INEX result set requires less than 200ms on a three-year-old desktop PC. 7.",
        "EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper.",
        "Nonetheless, when taken together they provide insight into the behaviour of the re-ranking algorithm.",
        "The INEX evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the inex-2002 and inex-2003 metrics.",
        "Values for the XCG metrics were computed using software supplied by its inventors [11].",
        "Figure 7 plots the three variants of inex-2002 MAP metric together with the XCG metric.",
        "Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on inex-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0.",
        "Recalling that the XCG metric is designed to penalize overlap, while the inex-2002 metric ignores overlap, the conflict between the metrics is obvious.",
        "The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at INEX 2004 [8,12].",
        "Figure 8 plots values of the inex-2003 MAP metric for two quantizations, with and without consideration of overlap.",
        "Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8.",
        "EXTENDED ALGORITHM One limitation of the re-ranking algorithm is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements.",
        "An obvious extension is to use different weights in these two cases.",
        "Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element.",
        "For example, a paragraph may form part of a reported section and then form part of a reported article.",
        "Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight.",
        "Motivated by these observations, the re-ranking algorithm may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times.",
        "Note that an upper bound on M is h, the maximum height of any XML tree in the collection.",
        "However, in practice M is likely to be relatively small (perhaps 3 or 4).",
        "Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights.",
        "One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument.",
        "When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down.",
        "The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors.",
        "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall time complexity of O((nM + mh) log n).",
        "Since M ≤ h and m ≤ n, the time complexity is also O(nh log n). 9.",
        "CONCLUDING DISCUSSION When generating retrieval results over an XML collection, some overlap in the results should be tolerated, and may be beneficial.",
        "For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship.",
        "The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance.",
        "Other approaches may also help to control overlap.",
        "For example, when XML retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them.",
        "While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster.",
        "At Waterloo, we continue to develop and test our ideas for INEX 2005.",
        "In particular, we are investigating methods for learning the α and βj weights.",
        "We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10.",
        "ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation.",
        "In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11.",
        "REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava.",
        "Holistic twig joins: Optimal XML pattern matching.",
        "In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
        "Mass, and A. Soffer.",
        "Searching XML documents via XML fragments.",
        "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker.",
        "MultiText experiments for INEX 2004.",
        "In INEX 2004 Workshop Proceedings, 2004.",
        "Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas.",
        "Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit.",
        "In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu.",
        "A comprehensive XQuery to SQL translation using dynamic interval encoding.",
        "In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann.",
        "XIRQL: A query language for information retrieval in XML documents.",
        "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors.",
        "Initiative for the Evaluation of XML Retrieval.",
        "Proceedings of the Second Workshop (INEX 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors.",
        "Initiative for the Evaluation of XML Retrieval.",
        "Proceedings of the Third Workshop (INEX 2004), Dagstuhl, Germany, December 2004.",
        "Published as Advances in XML Information Retrieval, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen.",
        "Cumulated gain-based evaluation of IR techniques.",
        "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson.",
        "Length normalization in XML retrieval.",
        "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries.",
        "The overlap problem in content-oriented XML retrieval evaluation.",
        "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries.",
        "Reliability tests for the XCG and inex-2002 metrics.",
        "In INEX 2004 Workshop Proceedings, 2004.",
        "Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto.",
        "TRIX 2004 - Struggling with the overlap.",
        "In INEX 2004 Workshop Proceedings, 2004.",
        "Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu.",
        "Configurable indexing and ranking for XML information retrieval.",
        "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 88-95, Sheffield, UK, July 2004. [15] Y.",
        "Mass and M. Mandelbrod.",
        "Retrieving the most relevant XML components.",
        "In INEX 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y.",
        "Mass and M. Mandelbrod.",
        "Component ranking and automatic query refinement for XML retrieval.",
        "In INEX 2004 Workshop Proceedings, 2004.",
        "Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan.",
        "Hierarchical language models for XML component retrieval.",
        "In INEX 2004 Workshop Proceedings, 2004.",
        "Published in LNCS 3493 [8]. [18] J. Pehcevski, J.",
        "A. Thom, and A. Vercoustre.",
        "Hybrid XML retrieval re-visited.",
        "In INEX 2004 Workshop Proceedings, 2004.",
        "Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas.",
        "Providing consistent and exhaustive relevance assessments for XML retrieval evaluation.",
        "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor.",
        "Simple BM25 extension to multiple weighted fields.",
        "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu.",
        "Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track.",
        "In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson.",
        "NEXI, now and next.",
        "In INEX 2004 Workshop Proceedings, 2004.",
        "Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari.",
        "An algebra for structured queries in bayesian networks.",
        "In INEX 2004 Workshop Proceedings, 2004.",
        "Published in LNCS 3493 [8]."
    ],
    "translated_text_sentences": [
        "Controlando la superposición en la recuperación XML orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca RESUMEN La aplicación directa de técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos XML a menudo produce un conjunto de resultados en el que los primeros puestos están dominados por un gran número de elementos tomados de un pequeño número de documentos altamente relevantes.",
        "Este documento presenta y evalúa un algoritmo que vuelve a clasificar este conjunto de resultados, con el objetivo de minimizar el contenido redundante mientras se preservan los beneficios de la recuperación de elementos, incluido el beneficio de identificar componentes centrados en el tema contenidos en documentos relevantes.",
        "La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la Recuperación XML (INEX) constituye la base para la evaluación.",
        "Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Búsqueda y Recuperación de Información Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1.",
        "La representación de documentos en XML brinda una oportunidad para que los sistemas de recuperación de información aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias.",
        "En respuesta a una consulta de usuario, un sistema de recuperación de información XML podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes.",
        "Esta facilidad es de particular beneficio cuando una colección contiene documentos muy largos, como manuales de productos o libros, donde el usuario debe ser dirigido a las partes más relevantes de estos documentos.",
        "La Figura 1 proporciona un ejemplo de un artículo de revista codificado en XML, ilustrando muchas de las características importantes de los documentos XML.",
        "Las etiquetas indican el inicio y el final de cada elemento, con elementos que varían ampliamente en tamaño, desde una palabra hasta miles de palabras.",
        "Algunos elementos, como párrafos y secciones, pueden presentarse razonablemente al usuario como resultados de búsqueda, pero otros no son apropiados.",
        "Los elementos se superponen entre sí: los artículos contienen secciones, las secciones contienen subsecciones y las subsecciones contienen párrafos.",
        "Cada una de estas características afecta el diseño de un sistema de IR XML, y cada una conlleva problemas fundamentales que deben resolverse en un sistema exitoso.",
        "La mayoría de estos problemas fundamentales pueden resolverse mediante la cuidadosa adaptación de técnicas estándar de IR, pero los problemas causados por la superposición son únicos en esta área [4,11] y constituyen el enfoque principal de este artículo.",
        "El artículo de la figura 1 puede ser visto como un árbol XML, como se ilustra en la figura 2.",
        "Formalmente, una colección de documentos XML puede ser representada como un bosque de árboles ordenados y enraizados, que consiste en un conjunto de nodos N y un conjunto de aristas dirigidas E que conectan estos nodos.",
        "Para cada nodo x ∈ N, la notación x.parent se refiere al nodo padre de x, si existe, y la notación x.children se refiere al conjunto de nodos hijos de x.",
        "Dado que un elemento puede estar representado por el nodo en su raíz, la salida de un sistema de IR XML puede ser vista como una lista clasificada de los m nodos principales.",
        "La aplicación directa de una técnica estándar de clasificación de relevancia a un conjunto de elementos XML puede producir un resultado en el que los primeros puestos están dominados por muchos elementos estructuralmente relacionados.",
        "Una sección con una puntuación alta probablemente contenga varios párrafos con una puntuación alta y esté contenida en un artículo con una puntuación alta.",
        "Por ejemplo, muchos de los elementos en la figura 2 recibirían una puntuación alta en los algoritmos de compresión de índices de texto de consulta de palabras clave.",
        "Si cada uno de estos elementos se presenta a un usuario como un resultado individual y separado, puede perder mucho tiempo revisando y rechazando contenido redundante.",
        "Una posible solución es informar solo el elemento de mayor puntuación a lo largo de un camino dado en el árbol, y eliminar de los rangos inferiores cualquier elemento que lo contenga o esté contenido en él.",
        "Desafortunadamente, este enfoque destruye algunos de los posibles beneficios de XML IR.",
        "Por ejemplo, un elemento externo puede contener una cantidad sustancial de información que no aparece en un elemento interno, pero el elemento interno puede estar fuertemente enfocado en el tema de la consulta y proporcionar un breve resumen de los conceptos clave.",
        "En tales casos, es razonable informar sobre elementos que contienen, o están contenidos en, elementos de rango superior.",
        "Incluso cuando un libro entero es relevante, un usuario aún puede desear que se destaquen los párrafos más importantes, para guiar su lectura y ahorrar tiempo [6].",
        "Este documento presenta un método para controlar la superposición.",
        "A partir de una clasificación inicial de elementos, un algoritmo de re-clasificación ajusta las puntuaciones de los elementos de menor clasificación que contienen, o están contenidos dentro de, elementos de mayor clasificación, reflejando el hecho de que esta información puede ser ahora redundante.",
        "Por ejemplo, una vez que un elemento que representa una sección aparece en la clasificación, las puntuaciones de los párrafos que contiene y del artículo que lo contiene se reducen.",
        "La inspiración para esta estrategia proviene parcialmente del trabajo reciente sobre la recuperación de documentos estructurados, donde los términos que aparecen en diferentes campos, como el título y el cuerpo, reciben diferentes pesos [20].",
        "Extendiendo ese enfoque, el algoritmo de reordenamiento varía los pesos dinámicamente a medida que se procesan los elementos.",
        "El resto del documento está organizado de la siguiente manera: Después de una discusión sobre el trabajo de antecedentes y la metodología de evaluación, se presenta un método de recuperación de referencia en la sección 4.",
        "Este método de referencia representa una adaptación razonable de la tecnología estándar de IR al XML.",
        "La sección 5 luego describe una estrategia para controlar la superposición, utilizando el método de línea base como punto de partida.",
        "Un algoritmo de reordenamiento que implementa esta estrategia se presenta en la sección 6 y se evalúa en la sección 7.",
        "La sección 8 discute una versión extendida del algoritmo. 2.",
        "ANTECEDENTES Esta sección proporciona una visión general de la recuperación de información XML y discute trabajos relacionados, con énfasis en los problemas fundamentales mencionados en la introducción.",
        "Mucha investigación en el área de recuperación de XML lo ve desde una perspectiva de base de datos tradicional, preocupándose por problemas como la implementación de lenguajes de consulta estructurados [5] y el procesamiento de joins [1].",
        "Aquí adoptamos una perspectiva de IR orientada al contenido, centrándonos en documentos XML que contienen principalmente datos en lenguaje natural y consultas que están principalmente expresadas en lenguaje natural.",
        "Suponemos que estas consultas indican únicamente la naturaleza del contenido deseado, no su estructura, y que el papel del sistema de RI es determinar qué elementos satisfacen mejor la necesidad de información subyacente.",
        "Otra investigación en IR ha considerado consultas mixtas, en las que se especifican tanto requisitos de contenido como estructurales [2,6,14,17,23]. 2.1 Estadísticas de Términos y Documentos En las aplicaciones tradicionales de recuperación de información, la unidad estándar de recuperación se considera que es el documento.",
        "Dependiendo de la aplicación, este término podría interpretarse para abarcar muchos objetos diferentes, incluyendo páginas web, artículos de periódico y mensajes de correo electrónico.",
        "Al aplicar técnicas estándar de clasificación de relevancia en el contexto de la RI XML, un enfoque natural es tratar cada elemento como un documento separado, con estadísticas de términos disponibles para cada uno [16].",
        "Además, la mayoría de las técnicas de clasificación requieren estadísticas globales (por ejemplo, frecuencia inversa de documentos) calculadas sobre la colección en su totalidad.",
        "Si consideramos que esta colección incluye todos los elementos que podrían ser devueltos por el sistema, una ocurrencia específica de un término puede aparecer en varios documentos diferentes, quizás en elementos que representan un párrafo, una subsección, una sección y un artículo.",
        "No es apropiado calcular la frecuencia inversa de documentos bajo la suposición de que el término está contenido en todos estos elementos, ya que el número de elementos que contienen un término depende completamente del arreglo estructural de los documentos [13,23]. 2.2 Elementos Recuperables Si bien un sistema de recuperación de información XML podría potencialmente recuperar cualquier elemento, muchos elementos pueden no ser apropiados como resultados de recuperación.",
        "Esto suele ser el caso cuando los elementos contienen muy poco texto [10].",
        "Por ejemplo, un título de sección que contenga solo los términos de búsqueda puede recibir una puntuación alta de un algoritmo de clasificación, pero por sí solo tendría un valor limitado para un usuario, quien podría preferir la sección real en sí misma.",
        "Otros elementos pueden reflejar la estructura física de los documentos, en lugar de la estructura lógica, lo cual puede tener poco o ningún significado para un usuario.",
        "Un sistema de recuperación de información XML efectivo debe devolver solo aquellos elementos que tengan suficiente contenido para ser utilizables y puedan funcionar como objetos independientes [15,18].",
        "Componentes estándar de documentos como párrafos, secciones, subsecciones y resúmenes generalmente cumplen con estos requisitos; los títulos, frases en cursiva y campos de metadatos individuales a menudo no lo hacen. 2.3 Metodología de Evaluación En los últimos tres años, la Iniciativa para la Evaluación de la Recuperación de Información XML (INEX) ha fomentado la investigación en tecnología de recuperación de información XML [7,8].",
        "INEX es una serie de conferencias experimentales, similar a TREC, en la que grupos de diferentes instituciones completan una o más tareas experimentales utilizando sus propias herramientas y sistemas, y comparan sus resultados en la propia conferencia.",
        "Más de 50 grupos participaron en INEX 2004, y la conferencia se ha convertido en tan influyente en el área de la RI XML como lo es TREC en otras áreas de la RI.",
        "La investigación descrita en este artículo, al igual que gran parte del trabajo relacionado que cita, depende de las colecciones de pruebas desarrolladas por INEX.",
        "La superposición causa problemas considerables en la evaluación de la recuperación, y los organizadores y participantes de INEX han luchado con estos problemas desde el principio.",
        "Aunque se ha logrado un progreso sustancial, estos problemas aún no están completamente resueltos.",
        "Kazai et al. [11] proporcionan una exposición detallada del problema de superposición en el contexto de la evaluación de recuperación de INEX y discuten tanto las métricas de evaluación actuales como las propuestas.",
        "Muchas de estas métricas se aplican para evaluar los experimentos reportados en este artículo, y se describen brevemente en la siguiente sección. 3.",
        "Las limitaciones de espacio impiden incluir más que un breve resumen de las tareas y metodología de evaluación de INEX 2004.",
        "Para obtener información detallada, se deben consultar las actas de la conferencia en sí [8]. 3.1 Tareas Para las principales tareas experimentales, a los participantes de INEX 2004 se les proporcionó una colección de 12,107 artículos tomados de las revistas y publicaciones de la IEEE Computer Societies entre 1995 y 2002.",
        "Cada documento está codificado en XML utilizando una DTD común, siendo el documento de las figuras 1 y 2 un ejemplo.",
        "En INEX 2004, las dos principales tareas experimentales fueron ambas tareas de recuperación ad hoc, investigando el rendimiento de sistemas que buscan en una colección estática utilizando temas previamente no vistos.",
        "Las dos tareas diferían en los tipos de temas que utilizaban.",
        "Para una tarea, la tarea de solo contenido o CO, los temas consisten en declaraciones cortas en lenguaje natural sin hacer referencia directa a la estructura de los documentos en la colección.",
        "Para esta tarea, se requiere que el sistema de IR seleccione los elementos a devolver.",
        "Para la otra tarea, la tarea de contenido y estructura o CAS, los temas están escritos en un lenguaje de consulta XML [22] y contienen referencias explícitas a la estructura del documento, que el sistema de IR debe intentar satisfacer.",
        "Dado que el trabajo descrito en este documento se enfoca en la tarea de solo contenido, donde el sistema de IR no recibe orientación sobre los elementos a devolver, la tarea de CAS se ignora en el resto de nuestra descripción.",
        "En 2004, los organizadores de la conferencia seleccionaron 40 nuevos temas de CO de las contribuciones proporcionadas por los participantes de la conferencia.",
        "Cada tema incluye una breve consulta de palabras clave, la cual es ejecutada sobre la colección por cada grupo participante en su propio sistema de IR XML.",
        "Cada grupo podría presentar hasta tres ejecuciones experimentales que consistieran en los primeros m = 1500 elementos para cada tema. 3.2 Evaluación de Relevancia Dado que la RI XML se preocupa por localizar aquellos elementos que proporcionan una cobertura completa de un tema mientras contienen la menor cantidad de información irrelevante posible, los juicios simples de relevante vs. no relevante no son suficientes.",
        "En cambio, los organizadores de INEX adoptaron dos dimensiones para la evaluación de relevancia: la dimensión de exhaustividad refleja el grado en que un elemento abarca el tema, y la dimensión de especificidad refleja el grado en que un elemento se enfoca en el tema.",
        "Se utiliza una escala de cuatro puntos en ambas dimensiones.",
        "Por lo tanto, un elemento (3,3) es altamente exhaustivo y altamente específico, un elemento (1,3) es marginalmente exhaustivo y altamente específico, y un elemento (0,0) no es relevante.",
        "Información adicional sobre la metodología de evaluación se puede encontrar en Piwowarski y Lalmas [19], quienes proporcionan una justificación detallada. 3.3 Métricas de Evaluación La métrica de evaluación principal utilizada en INEX 2004 es una versión de la precisión promedio media (MAP), ajustada por diversas funciones de cuantificación para dar diferentes pesos a diferentes elementos, dependiendo de sus valores de exhaustividad y especificidad.",
        "Una variante, la función de cuantización estricta asigna un peso de 1 a los elementos (3,3) y un peso de 0 a todos los demás.",
        "Esta variante es esencialmente el valor MAP familiar, con elementos (3,3) tratados como relevantes y todos los demás elementos tratados como no relevantes.",
        "Otras funciones de cuantización están diseñadas para otorgar crédito parcial a elementos que son aproximaciones cercanas, debido a la falta de exhaustividad y/o especificidad.",
        "Tanto la función de cuantificación generalizada como la función de generalización orientada a la especificidad (sog) acreditan elementos según su grado de relevancia [11], siendo que la segunda función pone mayor énfasis en la especificidad.",
        "Este documento informa los resultados de esta métrica utilizando las tres funciones de cuantización.",
        "Desde que esta métrica fue introducida por primera vez en INEX 2002, generalmente se le conoce como la métrica inex-2002.",
        "La métrica inex-2002 no penaliza la superposición.",
        "En particular, tanto las funciones de cuantificación generalizadas como las de sog otorgan crédito parcial a un casi acierto incluso cuando se informa un elemento (3,3) que se superpone a él en un rango más alto.",
        "Para abordar este problema, Kazai et al. [11] proponen una métrica de ganancia acumulada XML, que compara la ganancia acumulada [9] de una lista clasificada con un vector de ganancia ideal.",
        "Este vector de ganancia ideal se construye a partir de las valoraciones de relevancia al eliminar la superposición y retener solo el mejor elemento a lo largo de un camino dado.",
        "Por lo tanto, la métrica XCG recompensa las ejecuciones de recuperación que evitan la superposición.",
        "Aunque XCG no se utilizó oficialmente en INEX 2004, es probable que se utilice una versión de él en el futuro.",
        "En INEX 2003, se introdujo otra métrica para mejorar las limitaciones percibidas de la métrica inex-2002.",
        "Este métrico inex-2003 extiende las definiciones de precisión y exhaustividad para considerar tanto el tamaño de los componentes informados como la superposición entre ellos.",
        "Se crearon dos versiones, una que consideraba solo el tamaño de los componentes y otra que consideraba tanto el tamaño como la superposición.",
        "Si bien la métrica inex-2003 presenta anomalías no deseadas [11] y no se utilizó en 2004, se informan valores en la sección de evaluación para proporcionar un instrumento adicional para investigar la superposición. 4.",
        "MÉTODO DE RECUPERACIÓN DE BASELINE Esta sección proporciona una descripción general del método de recuperación de información XML de base actualmente utilizado en el sistema MultiText IR, desarrollado por el Grupo de Recuperación de Información de la Universidad de Waterloo [3].",
        "Este método de recuperación resulta de la adaptación y ajuste de la medida Okapi BM25 [21] a la tarea de recuperación de información en XML.",
        "El sistema MultiText tuvo un desempeño respetable en INEX 2004, ubicándose entre los diez primeros en todas las funciones de cuantización, y ocupando el primer lugar cuando la función de cuantización enfatizaba la exhaustividad.",
        "Para admitir la recuperación de XML y otros tipos de documentos estructurados, el sistema proporciona consultas generalizadas de la forma: clasificar X por Y donde X es una subconsulta que especifica un conjunto de elementos de documentos a clasificar y Y es un vector de subconsultas que especifican términos de recuperación individuales.",
        "Para nuestras ejecuciones de INEX 2004, la subconsulta X especificó una lista de elementos recuperables como aquellos con nombres de etiquetas de la siguiente manera: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt. Esta lista incluye entradas bibliográficas (bb) y leyendas de figuras (fig) así como párrafos, secciones y subsecciones.",
        "Antes de INEX 2004, la colección de INEX y las evaluaciones de relevancia de INEX 2003 fueron analizadas manualmente para seleccionar estos nombres de etiquetas.",
        "Los nombres de las etiquetas fueron seleccionados en base a su frecuencia en la colección, el tamaño promedio de sus elementos asociados y el número relativo de juicios de relevancia positiva que recibieron.",
        "Automatizar este proceso de selección está planeado como trabajo futuro.",
        "Para INEX 2004, el vector término Y se derivó del tema dividiendo frases en palabras individuales, eliminando palabras vacías y términos negativos (aquellos que comienzan con -), y aplicando un stemmer.",
        "Por ejemplo, el campo de palabra clave del tema 166 +distancia de edición de árbol + XML -imagen se convirtió en la consulta de cuatro términos $árbol $edición $distancia $xml donde el operador $ dentro de una cadena entre comillas deriva el término que le sigue.",
        "Nuestra implementación de Okapi BM25 se deriva de la fórmula de Robertson et al. [21] al establecer los parámetros k2 = 0 y k3 = ∞.",
        "Dado un conjunto de términos Q, a un elemento x se le asigna la puntuación t∈Q w(1) qt (k1 + 1)xt K + xt (1) donde w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = número de documentos en el corpus Dt = número de documentos que contienen t qt = frecuencia con la que t ocurre en el tema xt = frecuencia con la que t ocurre en x K = k1((1 − b) + b · lx/lavg) lx = longitud de x lavg = longitud promedio del documento 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 PrecisiónPromedio(inex-2002) k1 estricto generalizado sog Figura 3: Impacto de k1 en la precisión promedio de inex-2002 con b = 0.75 (temas CO de INEX 2003).",
        "Antes de INEX 2004, los temas y juicios de INEX 2003 se utilizaron para ajustar los parámetros b y k1, y el impacto de este ajuste se discute más adelante en esta sección.",
        "Para los propósitos de calcular estadísticas a nivel de documento (D, Dt y lavg), un documento se define como un artículo.",
        "Estas estadísticas se utilizan para clasificar todos los tipos de elementos.",
        "Siguiendo la sugerencia de Kamps et al. [10], los resultados de recuperación se filtran para eliminar elementos muy cortos, aquellos con menos de 25 palabras de longitud.",
        "El uso de estadísticas de artículos para todos los tipos de elementos podría ser cuestionado.",
        "Este enfoque puede justificarse al considerar la colección como un conjunto de artículos que se pueden buscar utilizando técnicas estándar orientadas a documentos, donde solo se devuelven artículos.",
        "El puntaje calculado para un elemento es esencialmente el puntaje que recibiría si se agregara a la colección como un nuevo documento, ignorando los ajustes menores necesarios para las estadísticas a nivel de documento.",
        "Sin embargo, planeamos examinar este tema nuevamente en el futuro.",
        "En nuestra experiencia, el rendimiento de BM25 suele beneficiarse al ajustar los parámetros b y k1 a la colección, siempre que haya consultas de entrenamiento disponibles con este propósito.",
        "Antes de INEX 2004, entrenamos el sistema MultiText utilizando las consultas de INEX 2003.",
        "Como punto de partida, utilizamos los valores b = 0.75 y k1 = 1.2, que funcionan bien en colecciones TREC adhoc y se utilizan como valores predeterminados en nuestro sistema.",
        "Los resultados fueron sorprendentes.",
        "La Figura 3 muestra el resultado de variar k1 con b = 0.75 en los valores de MAP bajo tres funciones de cuantización.",
        "En nuestra experiencia, los valores óptimos para k1 suelen estar en el rango de 0.0 a 2.0.",
        "En este caso, se requieren valores grandes para un buen rendimiento.",
        "Entre k1 = 1.0 y k1 = 6.0, el MAP aumenta en más del 15% bajo la cuantización estricta.",
        "Se observan mejoras similares bajo las cuantizaciones generalizada y SOG.",
        "Por el contrario, nuestro valor predeterminado de b = 0.75 funciona bien bajo todas las funciones de cuantificación (figura 4).",
        "Después de ajustar una amplia gama de valores bajo varias funciones de cuantización, seleccionamos los valores de k = 10.0 y b = 0.80 para nuestros experimentos de INEX 2004, y estos valores se utilizan para los experimentos reportados en la sección 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 PrecisiónPromedioMedia (inex-2002) b estricto generalizado sog Figura 4: Impacto de b en la precisión promedio media de inex-2002 con k1 = 10 (temas CO de INEX 2003). 5.",
        "CONTROL DE SUPERPOSICIÓN Comenzando con una clasificación de elementos generada por el método de referencia descrito en la sección anterior, los elementos se vuelven a clasificar para controlar la superposición ajustando de forma iterativa las puntuaciones de aquellos elementos que contienen o están contenidos en elementos de clasificación más alta.",
        "A nivel conceptual, la reorganización procede de la siguiente manera: 1.",
        "Informe el elemento de rango más alto.",
        "Ajustar las puntuaciones de los elementos no reportados. 3.",
        "Repetir los pasos 1 y 2 hasta que se informen m elementos.",
        "Un enfoque para ajustar las puntuaciones de los elementos no informados en el paso 2 podría basarse en las puntuaciones Okapi BM25 de los elementos involucrados.",
        "Por ejemplo, supongamos que se informa un párrafo con una puntuación p en el paso 1.",
        "En el paso 2, la sección que contiene el párrafo podría tener su puntuación s reducida en una cantidad α · p para reflejar la contribución reducida que el párrafo debería hacer a la puntuación de las secciones.",
        "En un contexto relacionado, Robertson et al. [20] argumentan en contra de la combinación lineal de las puntuaciones de Okapi de esta manera.",
        "Ese trabajo considera el problema de asignar diferentes pesos a diferentes campos de documentos, como el título y el cuerpo asociados con páginas web.",
        "Un enfoque común para este problema puntúa el título y el cuerpo por separado y genera una puntuación final como una combinación lineal de ambos.",
        "Robertson et al. discuten las deficiencias teóricas en este enfoque y demuestran experimentalmente que puede perjudicar realmente la efectividad de la recuperación.",
        "En cambio, aplican los pesos a nivel de frecuencia de términos, donde la aparición de un término de consulta t en el título contribuye más al puntaje que una aparición en el cuerpo.",
        "En la ecuación 1, xt se convierte en α0 · yt + α1 · zt, donde yt es el número de veces que t aparece en el título y zt es el número de veces que t aparece en el cuerpo.",
        "Al traducir este enfoque a nuestro contexto, la contribución de los términos que aparecen en los elementos se reduce dinámicamente a medida que se informan.",
        "La siguiente sección presenta y analiza un algoritmo de reordenamiento simple que sigue esta estrategia.",
        "El algoritmo se evalúa experimentalmente en la sección 7.",
        "Una limitación del algoritmo es que la contribución de los términos que aparecen en los elementos informados se reduce por el mismo factor independientemente del número de elementos informados en los que aparezca.",
        "En la sección 8, el algoritmo se extiende para aplicar pesos crecientes, disminuyendo la puntuación, cuando un término aparece en más de un elemento informado. 6.",
        "ALGORITMO DE REORDENAMIENTO El algoritmo de reordenamiento opera sobre árboles XML, como el que aparece en la figura 2.",
        "La entrada al algoritmo es una lista de n elementos clasificados según sus puntuaciones iniciales de BM25.",
        "Durante la clasificación inicial, el árbol XML se reconstruye dinámicamente para incluir solo aquellos nodos con puntuaciones BM25 distintas de cero, por lo que n puede ser considerablemente menor que |N|.",
        "La salida del algoritmo es una lista de los primeros m elementos, clasificados según sus puntajes ajustados.",
        "Un elemento está representado por el nodo x ∈ N en su raíz.",
        "Asociados con este nodo se encuentran campos que almacenan la longitud del elemento, las frecuencias de términos y otra información requerida por el algoritmo de re-ranking, de la siguiente manera: x.f - vector de frecuencia de términos x.g - ajustes de frecuencia de términos x.l - longitud del elemento x.score - puntaje actual de Okapi BM25 x.reported - bandera booleana, inicialmente falsa x.children - conjunto de nodos hijos x.parent - nodo padre, si existe Estos campos se llenan durante el proceso de clasificación inicial y se actualizan a medida que avanza el algoritmo.",
        "El vector x.f contiene información de frecuencia de términos correspondiente a cada término en la consulta.",
        "El vector x.g es inicialmente cero y se actualiza por el algoritmo a medida que se informan elementos.",
        "El campo de puntuación contiene la puntuación BM25 actual para el elemento, la cual cambiará a medida que cambien los valores en x.g.",
        "El puntaje se calcula utilizando la ecuación 1, con el valor xt para cada término determinado por una combinación de los valores en x.f y x.g.",
        "Dado un término t ∈ Q, sea ft el componente de x.f correspondiente a t, y sea gt el componente de x.g correspondiente a t, entonces: xt = ft − α · gt (2) Para el procesamiento por el algoritmo de reordenamiento, los nodos se almacenan en colas de prioridad, ordenadas por puntaje decreciente.",
        "Cada cola de prioridad PQ admite tres operaciones: PQ.front() - devuelve el nodo con la puntuación más alta, PQ.add(x) - agrega el nodo x a la cola, PQ.remove(x) - elimina el nodo x de la cola. Cuando se implementan utilizando estructuras de datos estándar, la operación front requiere tiempo O(1), y las otras operaciones requieren tiempo O(log n), donde n es el tamaño de la cola.",
        "El núcleo del algoritmo de reordenamiento se presenta en la figura 5.",
        "El algoritmo toma como entrada la cola de prioridad S que contiene la clasificación inicial, y produce los primeros m nodos reordenados en la cola de prioridad F. Después de inicializar F como vacío en la línea 1, el algoritmo recorre m veces las líneas 215, transfiriendo al menos un nodo de S a F durante cada iteración.",
        "Al inicio de cada iteración, el nodo no reportado al frente de S tiene el mayor puntaje ajustado, y se elimina y se agrega a F. El algoritmo luego recorre el 1 F ← ∅ 2 para i ← 1 a m hacer 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 para cada y ∈ x.children hacer 9 Abajo (y) 10 fin hacer 11 12 si x no es un nodo raíz entonces 13 Arriba (x, x.parent) 14 fin si 15 fin hacer Figura 5: Algoritmo de Re-Ranking - Como entrada, el algoritmo toma una cola de prioridad S, que contiene nodos XML clasificados por sus puntajes iniciales, y devuelve sus resultados en la cola de prioridad F, clasificados por puntajes ajustados. 1 Arriba(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recalcular y.score 5 S.add(y) 6 si y no es un nodo raíz entonces 7 Arriba (x, y.parent) 8 fin si 9 10 Abajo(x) ≡ 11 si no x.reported entonces 12 S.remove(x) 14 x.g ← x.f 15 recalcular x.score 16 si x.score > 0 entonces 17 F.add(x) 18 fin si 19 x.reported ← true 20 para cada y ∈ x.children hacer 21 Abajo (y) 22 fin hacer 23 fin si Figura 6: Rutinas de recorrido de árbol llamadas por el algoritmo de re-ranking. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 PrecisiónPromedioMedia (inex-2002) GananciaAcumuladaXML(XCG) alfa MAP (estricto) MAP (generalizado) MAP (sog) XCG (sog2) Figura 7: Impacto de α en XCG y MAP inex-2002 (temas CO de INEX 2004; conjunto de evaluación I). nodos ancestros (líneas 8-10) y descendientes (líneas 12-14) ajustando los puntajes de estos nodos.",
        "Las rutinas de recorrido de árboles, Arriba y Abajo, se muestran en la figura 6.",
        "El procedimiento Up elimina cada nodo ancestro de S, ajusta sus valores de frecuencia de término, recalcula su puntuación y lo vuelve a agregar a S. El ajuste de los valores de frecuencia de término (línea 3) agrega a y.g solo las ocurrencias de términos no reportadas previamente en x. El recalculo de la puntuación en la línea 4 utiliza las ecuaciones 1 y 2.",
        "La rutina Down realiza una operación similar en cada descendiente.",
        "Sin embargo, dado que el contenido de cada descendiente está completamente contenido en un elemento informado, su puntuación final puede ser calculada, y se elimina de S y se agrega a F. Para determinar la complejidad temporal del algoritmo, primero observe que un nodo puede ser un argumento de Down como máximo una vez.",
        "Posteriormente, la bandera reportada de su padre es verdadera.",
        "Durante cada llamada a Down, un nodo puede ser movido de S a F, lo que requiere un tiempo O(log n).",
        "Por lo tanto, el tiempo total para todas las llamadas a Down es O(n log n), y podemos ignorar temporalmente las líneas 8-10 de la figura 5 al considerar la complejidad temporal del bucle sobre las líneas 2-15.",
        "Durante cada iteración de este bucle, se elimina un nodo y cada uno de sus ancestros de una cola de prioridad y luego se vuelven a agregar a la cola de prioridad.",
        "Dado que un nodo puede tener como máximo h ancestros, donde h es la altura máxima de cualquier árbol en la colección, cada una de las m iteraciones requiere un tiempo de O(h log n).",
        "La combinación de estas observaciones produce una complejidad temporal general de O((n + mh) log n).",
        "En la práctica, volver a clasificar un conjunto de resultados de INEX requiere menos de 200 ms en una PC de escritorio de tres años de antigüedad.",
        "EVALUACIÓN Ninguna de las métricas descritas en la sección 3.3 se ajusta adecuadamente a la perspectiva de superposición defendida por este documento.",
        "Sin embargo, cuando se toman en conjunto, proporcionan información sobre el comportamiento del algoritmo de reordenamiento.",
        "Los paquetes de evaluación de INEX (inex_eval e inex_eval_ng) se utilizaron para calcular los valores de las métricas inex-2002 e inex-2003.",
        "Los valores de las métricas XCG fueron calculados utilizando el software proporcionado por sus inventores [11].",
        "La Figura 7 representa juntas las tres variantes de la métrica MAP inex-2002 junto con la métrica XCG.",
        "Los valores para estas métricas 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Precisión Media Promedio (inex-2003) alfa estricto, superposición no considerada estricto, superposición considerada generalizado, superposición no considerada generalizado, superposición considerada Figura 8: Impacto de α en MAP inex-2003 (temas CO de INEX 2004; conjunto de evaluación I). se trazan para valores de α entre 0.0 y 1.0.",
        "Recordando que la métrica XCG está diseñada para penalizar la superposición, mientras que la métrica inex-2002 ignora la superposición, el conflicto entre las métricas es evidente.",
        "Los valores de MAP en un extremo (α = 0.0) y el valor de XCG en el otro extremo (α = 1.0) representan un rendimiento de recuperación comparable a los mejores sistemas en INEX 2004 [8,12].",
        "La Figura 8 muestra los valores de la métrica MAP inex-2003 para dos cuantificaciones, con y sin consideración de la superposición.",
        "Una vez más, el conflicto es evidente, con la influencia de α considerablemente disminuida cuando se considera la superposición. 8.",
        "ALGORITMO EXTENDIDO Una limitación del algoritmo de reordenamiento es que se utiliza un único peso α para ajustar las puntuaciones tanto de los ancestros como de los descendientes de los elementos informados.",
        "Una extensión obvia es usar diferentes pesos en estos dos casos.",
        "Además, se utiliza el mismo peso independientemente de cuántas veces un elemento esté contenido en un elemento informado.",
        "Por ejemplo, un párrafo puede formar parte de una sección reportada y luego formar parte de un artículo reportado.",
        "Dado que el usuario puede haber visto este párrafo dos veces, su puntuación debería ser reducida aún más aumentando el valor del peso.",
        "Motivado por estas observaciones, el algoritmo de reordenamiento puede ser extendido con una serie de pesos 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0, donde βj es el peso aplicado a un nodo que ha sido descendiente de un nodo reportado j veces.",
        "Ten en cuenta que un límite superior en M es h, la altura máxima de cualquier árbol XML en la colección.",
        "Sin embargo, en la práctica es probable que M sea relativamente pequeño (quizás 3 o 4).",
        "La Figura 9 presenta reemplazos para las rutinas de Subir y Bajar de la Figura 6, incorporando esta serie de pesas.",
        "Se requiere un campo adicional en cada nodo, de la siguiente manera: x.j - conteo descendente El valor de x.j se establece inicialmente en cero en todos los nodos y se incrementa cada vez que se llama a Down con x como su argumento.",
        "Al calcular la puntuación del nodo, el valor de x.j selecciona 1 Up(x, y) ≡ 2 si no y.reported entonces 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recalcular y.score 6 S.add(y) 8 si y no es un nodo raíz entonces 9 Up (x, y.padre) 10 fin si 11 fin si 12 13 Down(x) ≡ 14 si x.j < M entonces 15 x.j ← x.j + 1 16 si no x.reported entonces 17 S.remove(x) 18 recalcular x.score 19 S.add(x) 20 fin si 21 para cada y ∈ x.hijos hacer 22 Down (y) 23 fin hacer 24 fin si Figura 9: Rutinas extendidas de recorrido de árbol. el peso a aplicar al nodo ajustando el valor de xt en la ecuación 1, de la siguiente manera: xt = βx.j · (ft − α · gt) (3) donde ft y gt son los componentes de x.f y x.g correspondientes al término t. Se requieren algunos cambios adicionales para extender Up y Down.",
        "La rutina Up devuelve inmediatamente (línea 2) si su argumento ya ha sido reportado, ya que las frecuencias de términos ya han sido ajustadas en sus ancestros.",
        "El procedimiento Down no informa su argumento, sino que vuelve a calcular su puntuación y la agrega de nuevo a S. Un nodo no puede ser un argumento de Down más de M +1 veces, lo que a su vez implica una complejidad temporal total de O((nM + mh) log n).",
        "Dado que M ≤ h y m ≤ n, la complejidad temporal también es O(nh log n).",
        "DISCUSIÓN CONCLUSIVA Al generar resultados de recuperación en una colección de XML, se debe tolerar cierta superposición en los resultados, lo cual puede ser beneficioso.",
        "Por ejemplo, cuando un elemento altamente exhaustivo y bastante específico (3,2) contiene un elemento mucho más pequeño (2,3), ambos deben ser informados al usuario, y los algoritmos de recuperación y las métricas de evaluación deben respetar esta relación.",
        "El algoritmo presentado en este documento controla la superposición ponderando los términos que aparecen en los elementos informados para reflejar su menor importancia.",
        "Otros enfoques también pueden ayudar a controlar la superposición.",
        "Por ejemplo, cuando se presentan los resultados de recuperación de XML a los usuarios, puede ser deseable agrupar elementos relacionados estructuralmente juntos, ilustrando visualmente las relaciones entre ellos.",
        "Si bien este estilo de interfaz de usuario puede ayudar a un usuario a lidiar con la superposición, la estrategia presentada en este documento sigue siendo aplicable, al determinar los mejores elementos para incluir en cada grupo.",
        "En Waterloo, seguimos desarrollando y probando nuestras ideas para INEX 2005.",
        "En particular, estamos investigando métodos para aprender los pesos α y βj.",
        "También estamos reevaluando nuestro enfoque en las estadísticas de documentos y examinando ajustes apropiados al parámetro k1 a medida que cambian los pesos de los términos [20]. 10.",
        "AGRADECIMIENTOS Gracias a Gabriella Kazai y Arjen de Vries por proporcionar una versión temprana de su software para calcular la métrica XCG, y gracias a Phil Tilker y Stefan B¨uttcher por su ayuda con la evaluación experimental.",
        "En parte, la financiación para este proyecto fue proporcionada por IBM Canadá a través del Instituto Nacional de Investigación de Software. 11.",
        "REFERENCIAS [1] N. Bruno, N. Koudas y D. Srivastava.",
        "Uniones de ramas holísticas: Coincidencia óptima de patrones XML.",
        "En Actas de la Conferencia Internacional ACM SIGMOD 2002 sobre la Gestión de Datos, páginas 310-321, Madison, Wisconsin, junio de 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
        "Masa y A. Soffer.",
        "Buscando documentos XML a través de fragmentos XML.",
        "En Actas de la 26ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 151-158, Toronto, Canadá, 2003. [3] C. L. A. Clarke y P. L. Tilker.",
        "Experimentos MultiText para INEX 2004.",
        "En Actas del Taller INEX 2004, 2004.",
        "Publicado en LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai y M. Lalmas.",
        "Tolerancia a la irrelevancia: Una evaluación orientada al esfuerzo del usuario de sistemas de recuperación sin unidad de recuperación predefinida.",
        "En las Actas de la Conferencia RIAO 2004, páginas 463-473, Aviñón, Francia, abril de 2004. [5] D. DeHaan, D. Toman, M. P. Consens y M. T. ¨Ozsu.",
        "Una traducción exhaustiva de XQuery a SQL utilizando codificación dinámica de intervalos.",
        "En Actas de la Conferencia Internacional ACM SIGMOD 2003 sobre la Gestión de Datos, San Diego, junio de 2003. [6] N. Fuhr y K. Großjohann.",
        "XIRQL: Un lenguaje de consulta para la recuperación de información en documentos XML.",
        "En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 172-180, Nueva Orleans, septiembre de 2001. [7] N. Fuhr, M. Lalmas y S. Malik, editores.",
        "Iniciativa para la Evaluación de la Recuperación de XML.",
        "Actas del Segundo Taller (INEX 2003), Dagstuhl, Alemania, diciembre de 2003. [8] N. Fuhr, M. Lalmas, S. Malik y Zoltán Szlávik, editores.",
        "Iniciativa para la Evaluación de la Recuperación de XML.",
        "Actas del Tercer Taller (INEX 2004), Dagstuhl, Alemania, diciembre de 2004.",
        "Publicado como Avances en la Recuperación de Información XML, Notas de Conferencia en Ciencias de la Computación, volumen 3493, Springer, 2005. [9] K. J¨avelin y J. Kek¨al¨ainen.",
        "Evaluación basada en la ganancia acumulada de técnicas de recuperación de información.",
        "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, y B. Sigurbjörnsson.",
        "Normalización de longitud en la recuperación de XML.",
        "En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 80-87, Sheffield, Reino Unido, julio de 2004. [11] G. Kazai, M. Lalmas y A. P. de Vries.",
        "El problema de superposición en la evaluación de la recuperación de XML orientada al contenido.",
        "En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 72-79, Sheffield, Reino Unido, julio de 2004. [12] G. Kazai, M. Lalmas y A. P. de Vries.",
        "Pruebas de confiabilidad para las métricas XCG e inex-2002.",
        "En Actas del Taller INEX 2004, 2004.",
        "Publicado en LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola y T. Aalto.",
        "TRIX 2004 - Luchando con la superposición.",
        "En Actas del Taller INEX 2004, 2004.",
        "Publicado en LNCS 3493 [8]. [14] S. Liu, Q. Zou y W. W. Chu.",
        "Indexación y clasificación configurables para la recuperación de información en XML.",
        "En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 88-95, Sheffield, Reino Unido, julio de 2004. [15] Y.",
        "Masa y M. Mandelbrot.",
        "Recuperando los componentes XML más relevantes.",
        "En las Actas del Taller INEX 2003, Dagstuhl, Alemania, diciembre de 2003. [16] Y.",
        "Masa y M. Mandelbrot.",
        "Clasificación de componentes y refinamiento automático de consultas para la recuperación de XML.",
        "En Actas del Taller INEX 2004, 2004.",
        "Publicado en LNCS 3493 [8]. [17] P. Ogilvie y J. Callan.",
        "Modelos de lenguaje jerárquicos para la recuperación de componentes XML.",
        "En Actas del Taller INEX 2004, 2004.",
        "Publicado en LNCS 3493 [8]. [18] J. Pehcevski, J.",
        "A. Thom y A. Vercoustre.",
        "Recuperación híbrida de XML revisitada.",
        "En Actas del Taller INEX 2004, 2004.",
        "Publicado en LNCS 3493 [8]. [19] B. Piwowarski y M. Lalmas.",
        "Proporcionando evaluaciones de relevancia consistentes y exhaustivas para la evaluación de recuperación de XML.",
        "En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 361-370, Washington, DC, noviembre de 2004. [20] S. Robertson, H. Zaragoza y M. Taylor.",
        "Extensión simple de BM25 a múltiples campos ponderados.",
        "En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 42-50, Washington, DC, noviembre de 2004. [21] S. E. Robertson, S. Walker y M. Beaulieu.",
        "Okapi en TREC-7: Búsqueda automática, filtrado, VLC y pista interactiva.",
        "En Actas de la Séptima Conferencia de Recuperación de Texto, Gaithersburg, MD, noviembre de 1998. [22] A. Trotman y B. Sigurbjörnsson.",
        "NEXI, ahora y después.",
        "En Actas del Taller INEX 2004, 2004.",
        "Publicado en LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski y P. Gallinari.",
        "Un álgebra para consultas estructuradas en redes bayesianas.",
        "En Actas del Taller INEX 2004, 2004.",
        "Publicado en LNCS 3493 [8]."
    ],
    "error_count": 2,
    "keys": {
        "information retrieval": {
            "translated_key": "recuperación de información",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Controlling Overlap in Content-Oriented XML Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of XML documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
                "This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents.",
                "The test collection developed by the INitiative for the Evaluation of XML Retrieval (INEX) forms the basis for the evaluation.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "INTRODUCTION The representation of documents in XML provides an opportunity for <br>information retrieval</br> systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an XML <br>information retrieval</br> system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in XML.",
                "Figure 1 provides an example of a journal article encoded in XML, illustrating many of the important characteristics of XML documents.",
                "Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words.",
                "Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate.",
                "Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs.",
                "Each of these characteristics affects the design of an XML IR system, and each leads to fundamental problems that must be solved in an successful system.",
                "Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper.",
                "The article of figure 1 may be viewed as an XML tree, as illustrated in figure 2.",
                "Formally, a collection of XML documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes.",
                "For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example XML tree. of x.",
                "Since an element may be represented by the node at its root, the output of an XML IR system may be viewed as a ranked list of the top-m nodes.",
                "The direct application of a standard relevance ranking technique to a set of XML elements can produce a result in which the top ranks are dominated by many structurally related elements.",
                "A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article.",
                "For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms.",
                "If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content.",
                "One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it.",
                "Unfortunately, this approach destroys some of the possible benefits of XML IR.",
                "For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts.",
                "In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements.",
                "Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6].",
                "This paper presents a method for controlling overlap.",
                "Starting with an initial element ranking, a re-ranking algorithm adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
                "For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced.",
                "The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20].",
                "Extending that approach, the re-ranking algorithm varies weights dynamically as elements are processed.",
                "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a baseline retrieval method is presented in section 4.",
                "This baseline method represents a reasonable adaptation of standard IR technology to XML.",
                "Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point.",
                "A re-ranking algorithm implementing this strategy is presented in section 6 and evaluated in section 7.",
                "Section 8 discusses an extended version of the algorithm. 2.",
                "BACKGROUND This section provides a general overview of XML <br>information retrieval</br> and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
                "Much research in the area of XML retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1].",
                "Here, we take a content oriented IR perceptive, focusing on XML documents that primarily contain natural language data and queries that are primarily expressed in natural language.",
                "We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need.",
                "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional <br>information retrieval</br> applications the standard unit of retrieval is taken to be the document.",
                "Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages.",
                "When applying standard relevance ranking techniques in the context of XML IR, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
                "In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole.",
                "If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article.",
                "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an XML IR system might potentially retrieve any element, many elements may not be appropriate as retrieval results.",
                "This is usually the case when elements contain very little text [10].",
                "For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself.",
                "Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user.",
                "An effective XML IR system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18].",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (INEX) has encouraged research into XML <br>information retrieval</br> technology [7,8].",
                "INEX is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
                "Over 50 groups participated in INEX 2004, and the conference has become as influential in the area of XML IR as TREC is in other IR areas.",
                "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by INEX.",
                "Overlap causes considerable problems with retrieval evaluation, and the INEX organizers and participants have wrestled with these problems since the beginning.",
                "While substantial progress has been made, these problem are still not completely solved.",
                "Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of INEX retrieval evaluation and discuss both current and proposed evaluation metrics.",
                "Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3.",
                "INEX 2004 Space limitations prevent the inclusion of more than a brief summary of INEX 2004 tasks and evaluation methodology.",
                "For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, INEX 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002.",
                "Each document is encoded in XML using a common DTD, with the document of figures 1 and 2 providing one example.",
                "At INEX 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics.",
                "The two tasks differed in the types of topics they used.",
                "For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection.",
                "For this task, the IR system is required to select the elements to be returned.",
                "For the other task, the contentand-structure or CAS task, the topics are written in an XML query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy.",
                "Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description.",
                "In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants.",
                "Each topic includes a short keyword query, which is executed over the collection by each participating group on their own XML IR system.",
                "Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since XML IR is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient.",
                "Instead, the INEX organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic.",
                "A four-point scale is used in both dimensions.",
                "Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant.",
                "Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at INEX 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values.",
                "One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others.",
                "This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant.",
                "Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity.",
                "Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity.",
                "This paper reports results of this metric using all three of these quantization functions.",
                "Since this metric was first introduced at INEX 2002, it is generally referred as the inex-2002 metric.",
                "The inex-2002 metric does not penalize overlap.",
                "In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank.",
                "To address this problem, Kazai et al. [11] propose an XML cumulated gain metric, which compares the cumulated gain [9] of a ranked list to an ideal gain vector.",
                "This ideal gain vector is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path.",
                "Thus, the XCG metric rewards retrieval runs that avoid overlap.",
                "While XCG was not used officially at INEX 2004, a version of it is likely to be used in the future.",
                "At INEX 2003, yet another metric was introduced to ameliorate the perceived limitations of the inex-2002 metric.",
                "This inex-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them.",
                "Two versions were created, one that considered only component size and another that considered both size and overlap.",
                "While the inex-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4.",
                "BASELINE RETRIEVAL METHOD This section provides an overview of baseline XML <br>information retrieval</br> method currently used in the MultiText IR system, developed by the <br>information retrieval</br> Group at the University of Waterloo [3].",
                "This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the XML <br>information retrieval</br> task.",
                "The MultiText system performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
                "To support retrieval from XML and other structured document types, the system provides generalized queries of the form: rank X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms.",
                "For our INEX 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections.",
                "Prior to INEX 2004, the INEX collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names.",
                "Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received.",
                "Automating this selection process is planned as future work.",
                "For INEX 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.",
                "For example, keyword field of topic 166 +tree edit distance + XML -image became the four-term query $tree $edit $distance $xml where the $ operator within a quoted string stems the term that follows it.",
                "Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞.",
                "Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(inex-2002) k1 strict generalized sog Figure 3: Impact of k1 on inex-2002 mean average precision with b = 0.75 (INEX 2003 CO topics).",
                "Prior to INEX 2004, the INEX 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.",
                "For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article.",
                "These statistics are used for ranking all element types.",
                "Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length.",
                "The use of article statistics for all element types might be questioned.",
                "This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.",
                "The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics.",
                "Nonetheless, we plan to examine this issue again in the future.",
                "In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose.",
                "Prior to INEX 2004, we trained the MultiText system using the INEX 2003 queries.",
                "As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system.",
                "The results were surprising.",
                "Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions.",
                "In our experience, optimal values for k1 are typically in the range 0.0 to 2.0.",
                "In this case, large values are required for good performance.",
                "Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization.",
                "Similar improvements are seen under the generalized and sog quantizations.",
                "In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).",
                "After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our INEX 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5.",
                "CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements.",
                "At a conceptual level, re-ranking proceeds as follows: 1.",
                "Report the highest ranking element. 2.",
                "Adjust the scores of the unreported elements. 3.",
                "Repeat steps 1 and 2 until m elements are reported.",
                "One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements.",
                "For example, assume a paragraph with score p is reported in step 1.",
                "In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score.",
                "In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion.",
                "That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages.",
                "A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two.",
                "Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness.",
                "Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body.",
                "In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body.",
                "Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported.",
                "The next section presents and analysis a simple re-ranking algorithm that follows this strategy.",
                "The algorithm is evaluated experimentally in section 7.",
                "One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears.",
                "In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6.",
                "RE-RANKING ALGORITHM The re-ranking algorithm operates over XML trees, such as the one appearing in figure 2.",
                "Input to the algorithm is a list of n elements ranked according to their initial BM25 scores.",
                "During the initial ranking the XML tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |.",
                "Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores.",
                "An element is represented by the node x ∈ N at its root.",
                "Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - term frequency vector x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses.",
                "The vector x.f contains term frequency information corresponding to each term in the query.",
                "The vector x.g is initially zero and is updated by the algorithm as elements are reported.",
                "The score field contains the current BM25 score for the element, which will change as the values in x.g change.",
                "The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g.",
                "Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the re-ranking algorithm, nodes are stored in priority queues, ordered by decreasing score.",
                "Each priority queue PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
                "The core of the re-ranking algorithm is presented in figure 5.",
                "The algorithm takes as input the priority queue S containing the initial ranking, and produces the top-m reranked nodes in the priority queue F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
                "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a priority queue S, containing XML nodes ranked by their initial scores, and returns its results in priority queue F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
                "The tree traversal routines, Up and Down are given in figure 6.",
                "The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2.",
                "The Down routine performs a similar operation on each descendant.",
                "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the time complexity of the algorithm, first note that a node may be an argument to Down at most once.",
                "Thereafter, the reported flag of its parent is true.",
                "During each call to Down a node may be moved from S to F, requiring O(log n) time.",
                "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the time complexity of the loop over lines 2-15.",
                "During each iteration of this loop, a node and each of its ancestors are removed from a priority queue and then added back into a priority queue.",
                "Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time.",
                "Combining these observations produces an overall time complexity of O((n + mh) log n).",
                "In practice, re-ranking an INEX result set requires less than 200ms on a three-year-old desktop PC. 7.",
                "EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper.",
                "Nonetheless, when taken together they provide insight into the behaviour of the re-ranking algorithm.",
                "The INEX evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the inex-2002 and inex-2003 metrics.",
                "Values for the XCG metrics were computed using software supplied by its inventors [11].",
                "Figure 7 plots the three variants of inex-2002 MAP metric together with the XCG metric.",
                "Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on inex-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0.",
                "Recalling that the XCG metric is designed to penalize overlap, while the inex-2002 metric ignores overlap, the conflict between the metrics is obvious.",
                "The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at INEX 2004 [8,12].",
                "Figure 8 plots values of the inex-2003 MAP metric for two quantizations, with and without consideration of overlap.",
                "Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8.",
                "EXTENDED ALGORITHM One limitation of the re-ranking algorithm is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements.",
                "An obvious extension is to use different weights in these two cases.",
                "Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element.",
                "For example, a paragraph may form part of a reported section and then form part of a reported article.",
                "Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight.",
                "Motivated by these observations, the re-ranking algorithm may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times.",
                "Note that an upper bound on M is h, the maximum height of any XML tree in the collection.",
                "However, in practice M is likely to be relatively small (perhaps 3 or 4).",
                "Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights.",
                "One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument.",
                "When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down.",
                "The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors.",
                "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall time complexity of O((nM + mh) log n).",
                "Since M ≤ h and m ≤ n, the time complexity is also O(nh log n). 9.",
                "CONCLUDING DISCUSSION When generating retrieval results over an XML collection, some overlap in the results should be tolerated, and may be beneficial.",
                "For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship.",
                "The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance.",
                "Other approaches may also help to control overlap.",
                "For example, when XML retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them.",
                "While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster.",
                "At Waterloo, we continue to develop and test our ideas for INEX 2005.",
                "In particular, we are investigating methods for learning the α and βj weights.",
                "We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10.",
                "ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation.",
                "In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11.",
                "REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava.",
                "Holistic twig joins: Optimal XML pattern matching.",
                "In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
                "Mass, and A. Soffer.",
                "Searching XML documents via XML fragments.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in <br>information retrieval</br>, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker.",
                "MultiText experiments for INEX 2004.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas.",
                "Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit.",
                "In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu.",
                "A comprehensive XQuery to SQL translation using dynamic interval encoding.",
                "In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann.",
                "XIRQL: A query language for <br>information retrieval</br> in XML documents.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in <br>information retrieval</br>, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Second Workshop (INEX 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Third Workshop (INEX 2004), Dagstuhl, Germany, December 2004.",
                "Published as Advances in XML <br>information retrieval</br>, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson.",
                "Length normalization in XML retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in <br>information retrieval</br>, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "The overlap problem in content-oriented XML retrieval evaluation.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in <br>information retrieval</br>, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "Reliability tests for the XCG and inex-2002 metrics.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto.",
                "TRIX 2004 - Struggling with the overlap.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu.",
                "Configurable indexing and ranking for XML <br>information retrieval</br>.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in <br>information retrieval</br>, pages 88-95, Sheffield, UK, July 2004. [15] Y.",
                "Mass and M. Mandelbrod.",
                "Retrieving the most relevant XML components.",
                "In INEX 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y.",
                "Mass and M. Mandelbrod.",
                "Component ranking and automatic query refinement for XML retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan.",
                "Hierarchical language models for XML component retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [18] J. Pehcevski, J.",
                "A. Thom, and A. Vercoustre.",
                "Hybrid XML retrieval re-visited.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas.",
                "Providing consistent and exhaustive relevance assessments for XML retrieval evaluation.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor.",
                "Simple BM25 extension to multiple weighted fields.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu.",
                "Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track.",
                "In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson.",
                "NEXI, now and next.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari.",
                "An algebra for structured queries in bayesian networks.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]."
            ],
            "original_annotated_samples": [
                "INTRODUCTION The representation of documents in XML provides an opportunity for <br>information retrieval</br> systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an XML <br>information retrieval</br> system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "BACKGROUND This section provides a general overview of XML <br>information retrieval</br> and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
                "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional <br>information retrieval</br> applications the standard unit of retrieval is taken to be the document.",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (INEX) has encouraged research into XML <br>information retrieval</br> technology [7,8]."
            ],
            "translated_annotated_samples": [
                "La representación de documentos en XML brinda una oportunidad para que los sistemas de <br>recuperación de información</br> aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias.",
                "En respuesta a una consulta de usuario, un sistema de <br>recuperación de información</br> XML podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes.",
                "ANTECEDENTES Esta sección proporciona una visión general de la <br>recuperación de información</br> XML y discute trabajos relacionados, con énfasis en los problemas fundamentales mencionados en la introducción.",
                "Otra investigación en IR ha considerado consultas mixtas, en las que se especifican tanto requisitos de contenido como estructurales [2,6,14,17,23]. 2.1 Estadísticas de Términos y Documentos En las aplicaciones tradicionales de <br>recuperación de información</br>, la unidad estándar de recuperación se considera que es el documento.",
                "Componentes estándar de documentos como párrafos, secciones, subsecciones y resúmenes generalmente cumplen con estos requisitos; los títulos, frases en cursiva y campos de metadatos individuales a menudo no lo hacen. 2.3 Metodología de Evaluación En los últimos tres años, la Iniciativa para la Evaluación de la Recuperación de Información XML (INEX) ha fomentado la investigación en tecnología de <br>recuperación de información</br> XML [7,8]."
            ],
            "translated_text": "Controlando la superposición en la recuperación XML orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca RESUMEN La aplicación directa de técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos XML a menudo produce un conjunto de resultados en el que los primeros puestos están dominados por un gran número de elementos tomados de un pequeño número de documentos altamente relevantes. Este documento presenta y evalúa un algoritmo que vuelve a clasificar este conjunto de resultados, con el objetivo de minimizar el contenido redundante mientras se preservan los beneficios de la recuperación de elementos, incluido el beneficio de identificar componentes centrados en el tema contenidos en documentos relevantes. La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la Recuperación XML (INEX) constituye la base para la evaluación. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Búsqueda y Recuperación de Información Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. La representación de documentos en XML brinda una oportunidad para que los sistemas de <br>recuperación de información</br> aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias. En respuesta a una consulta de usuario, un sistema de <br>recuperación de información</br> XML podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes. Esta facilidad es de particular beneficio cuando una colección contiene documentos muy largos, como manuales de productos o libros, donde el usuario debe ser dirigido a las partes más relevantes de estos documentos. La Figura 1 proporciona un ejemplo de un artículo de revista codificado en XML, ilustrando muchas de las características importantes de los documentos XML. Las etiquetas indican el inicio y el final de cada elemento, con elementos que varían ampliamente en tamaño, desde una palabra hasta miles de palabras. Algunos elementos, como párrafos y secciones, pueden presentarse razonablemente al usuario como resultados de búsqueda, pero otros no son apropiados. Los elementos se superponen entre sí: los artículos contienen secciones, las secciones contienen subsecciones y las subsecciones contienen párrafos. Cada una de estas características afecta el diseño de un sistema de IR XML, y cada una conlleva problemas fundamentales que deben resolverse en un sistema exitoso. La mayoría de estos problemas fundamentales pueden resolverse mediante la cuidadosa adaptación de técnicas estándar de IR, pero los problemas causados por la superposición son únicos en esta área [4,11] y constituyen el enfoque principal de este artículo. El artículo de la figura 1 puede ser visto como un árbol XML, como se ilustra en la figura 2. Formalmente, una colección de documentos XML puede ser representada como un bosque de árboles ordenados y enraizados, que consiste en un conjunto de nodos N y un conjunto de aristas dirigidas E que conectan estos nodos. Para cada nodo x ∈ N, la notación x.parent se refiere al nodo padre de x, si existe, y la notación x.children se refiere al conjunto de nodos hijos de x. Dado que un elemento puede estar representado por el nodo en su raíz, la salida de un sistema de IR XML puede ser vista como una lista clasificada de los m nodos principales. La aplicación directa de una técnica estándar de clasificación de relevancia a un conjunto de elementos XML puede producir un resultado en el que los primeros puestos están dominados por muchos elementos estructuralmente relacionados. Una sección con una puntuación alta probablemente contenga varios párrafos con una puntuación alta y esté contenida en un artículo con una puntuación alta. Por ejemplo, muchos de los elementos en la figura 2 recibirían una puntuación alta en los algoritmos de compresión de índices de texto de consulta de palabras clave. Si cada uno de estos elementos se presenta a un usuario como un resultado individual y separado, puede perder mucho tiempo revisando y rechazando contenido redundante. Una posible solución es informar solo el elemento de mayor puntuación a lo largo de un camino dado en el árbol, y eliminar de los rangos inferiores cualquier elemento que lo contenga o esté contenido en él. Desafortunadamente, este enfoque destruye algunos de los posibles beneficios de XML IR. Por ejemplo, un elemento externo puede contener una cantidad sustancial de información que no aparece en un elemento interno, pero el elemento interno puede estar fuertemente enfocado en el tema de la consulta y proporcionar un breve resumen de los conceptos clave. En tales casos, es razonable informar sobre elementos que contienen, o están contenidos en, elementos de rango superior. Incluso cuando un libro entero es relevante, un usuario aún puede desear que se destaquen los párrafos más importantes, para guiar su lectura y ahorrar tiempo [6]. Este documento presenta un método para controlar la superposición. A partir de una clasificación inicial de elementos, un algoritmo de re-clasificación ajusta las puntuaciones de los elementos de menor clasificación que contienen, o están contenidos dentro de, elementos de mayor clasificación, reflejando el hecho de que esta información puede ser ahora redundante. Por ejemplo, una vez que un elemento que representa una sección aparece en la clasificación, las puntuaciones de los párrafos que contiene y del artículo que lo contiene se reducen. La inspiración para esta estrategia proviene parcialmente del trabajo reciente sobre la recuperación de documentos estructurados, donde los términos que aparecen en diferentes campos, como el título y el cuerpo, reciben diferentes pesos [20]. Extendiendo ese enfoque, el algoritmo de reordenamiento varía los pesos dinámicamente a medida que se procesan los elementos. El resto del documento está organizado de la siguiente manera: Después de una discusión sobre el trabajo de antecedentes y la metodología de evaluación, se presenta un método de recuperación de referencia en la sección 4. Este método de referencia representa una adaptación razonable de la tecnología estándar de IR al XML. La sección 5 luego describe una estrategia para controlar la superposición, utilizando el método de línea base como punto de partida. Un algoritmo de reordenamiento que implementa esta estrategia se presenta en la sección 6 y se evalúa en la sección 7. La sección 8 discute una versión extendida del algoritmo. 2. ANTECEDENTES Esta sección proporciona una visión general de la <br>recuperación de información</br> XML y discute trabajos relacionados, con énfasis en los problemas fundamentales mencionados en la introducción. Mucha investigación en el área de recuperación de XML lo ve desde una perspectiva de base de datos tradicional, preocupándose por problemas como la implementación de lenguajes de consulta estructurados [5] y el procesamiento de joins [1]. Aquí adoptamos una perspectiva de IR orientada al contenido, centrándonos en documentos XML que contienen principalmente datos en lenguaje natural y consultas que están principalmente expresadas en lenguaje natural. Suponemos que estas consultas indican únicamente la naturaleza del contenido deseado, no su estructura, y que el papel del sistema de RI es determinar qué elementos satisfacen mejor la necesidad de información subyacente. Otra investigación en IR ha considerado consultas mixtas, en las que se especifican tanto requisitos de contenido como estructurales [2,6,14,17,23]. 2.1 Estadísticas de Términos y Documentos En las aplicaciones tradicionales de <br>recuperación de información</br>, la unidad estándar de recuperación se considera que es el documento. Dependiendo de la aplicación, este término podría interpretarse para abarcar muchos objetos diferentes, incluyendo páginas web, artículos de periódico y mensajes de correo electrónico. Al aplicar técnicas estándar de clasificación de relevancia en el contexto de la RI XML, un enfoque natural es tratar cada elemento como un documento separado, con estadísticas de términos disponibles para cada uno [16]. Además, la mayoría de las técnicas de clasificación requieren estadísticas globales (por ejemplo, frecuencia inversa de documentos) calculadas sobre la colección en su totalidad. Si consideramos que esta colección incluye todos los elementos que podrían ser devueltos por el sistema, una ocurrencia específica de un término puede aparecer en varios documentos diferentes, quizás en elementos que representan un párrafo, una subsección, una sección y un artículo. No es apropiado calcular la frecuencia inversa de documentos bajo la suposición de que el término está contenido en todos estos elementos, ya que el número de elementos que contienen un término depende completamente del arreglo estructural de los documentos [13,23]. 2.2 Elementos Recuperables Si bien un sistema de recuperación de información XML podría potencialmente recuperar cualquier elemento, muchos elementos pueden no ser apropiados como resultados de recuperación. Esto suele ser el caso cuando los elementos contienen muy poco texto [10]. Por ejemplo, un título de sección que contenga solo los términos de búsqueda puede recibir una puntuación alta de un algoritmo de clasificación, pero por sí solo tendría un valor limitado para un usuario, quien podría preferir la sección real en sí misma. Otros elementos pueden reflejar la estructura física de los documentos, en lugar de la estructura lógica, lo cual puede tener poco o ningún significado para un usuario. Un sistema de recuperación de información XML efectivo debe devolver solo aquellos elementos que tengan suficiente contenido para ser utilizables y puedan funcionar como objetos independientes [15,18]. Componentes estándar de documentos como párrafos, secciones, subsecciones y resúmenes generalmente cumplen con estos requisitos; los títulos, frases en cursiva y campos de metadatos individuales a menudo no lo hacen. 2.3 Metodología de Evaluación En los últimos tres años, la Iniciativa para la Evaluación de la Recuperación de Información XML (INEX) ha fomentado la investigación en tecnología de <br>recuperación de información</br> XML [7,8]. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "xml ir": {
            "translated_key": "xml ir",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Controlling Overlap in Content-Oriented XML Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of XML documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
                "This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents.",
                "The test collection developed by the INitiative for the Evaluation of XML Retrieval (INEX) forms the basis for the evaluation.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "INTRODUCTION The representation of documents in XML provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an XML information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in XML.",
                "Figure 1 provides an example of a journal article encoded in XML, illustrating many of the important characteristics of XML documents.",
                "Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words.",
                "Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate.",
                "Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs.",
                "Each of these characteristics affects the design of an <br>xml ir</br> system, and each leads to fundamental problems that must be solved in an successful system.",
                "Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper.",
                "The article of figure 1 may be viewed as an XML tree, as illustrated in figure 2.",
                "Formally, a collection of XML documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes.",
                "For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example XML tree. of x.",
                "Since an element may be represented by the node at its root, the output of an <br>xml ir</br> system may be viewed as a ranked list of the top-m nodes.",
                "The direct application of a standard relevance ranking technique to a set of XML elements can produce a result in which the top ranks are dominated by many structurally related elements.",
                "A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article.",
                "For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms.",
                "If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content.",
                "One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it.",
                "Unfortunately, this approach destroys some of the possible benefits of <br>xml ir</br>.",
                "For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts.",
                "In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements.",
                "Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6].",
                "This paper presents a method for controlling overlap.",
                "Starting with an initial element ranking, a re-ranking algorithm adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
                "For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced.",
                "The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20].",
                "Extending that approach, the re-ranking algorithm varies weights dynamically as elements are processed.",
                "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a baseline retrieval method is presented in section 4.",
                "This baseline method represents a reasonable adaptation of standard IR technology to XML.",
                "Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point.",
                "A re-ranking algorithm implementing this strategy is presented in section 6 and evaluated in section 7.",
                "Section 8 discusses an extended version of the algorithm. 2.",
                "BACKGROUND This section provides a general overview of XML information retrieval and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
                "Much research in the area of XML retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1].",
                "Here, we take a content oriented IR perceptive, focusing on XML documents that primarily contain natural language data and queries that are primarily expressed in natural language.",
                "We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need.",
                "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional information retrieval applications the standard unit of retrieval is taken to be the document.",
                "Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages.",
                "When applying standard relevance ranking techniques in the context of <br>xml ir</br>, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
                "In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole.",
                "If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article.",
                "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an <br>xml ir</br> system might potentially retrieve any element, many elements may not be appropriate as retrieval results.",
                "This is usually the case when elements contain very little text [10].",
                "For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself.",
                "Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user.",
                "An effective <br>xml ir</br> system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18].",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (INEX) has encouraged research into XML information retrieval technology [7,8].",
                "INEX is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
                "Over 50 groups participated in INEX 2004, and the conference has become as influential in the area of <br>xml ir</br> as TREC is in other IR areas.",
                "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by INEX.",
                "Overlap causes considerable problems with retrieval evaluation, and the INEX organizers and participants have wrestled with these problems since the beginning.",
                "While substantial progress has been made, these problem are still not completely solved.",
                "Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of INEX retrieval evaluation and discuss both current and proposed evaluation metrics.",
                "Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3.",
                "INEX 2004 Space limitations prevent the inclusion of more than a brief summary of INEX 2004 tasks and evaluation methodology.",
                "For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, INEX 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002.",
                "Each document is encoded in XML using a common DTD, with the document of figures 1 and 2 providing one example.",
                "At INEX 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics.",
                "The two tasks differed in the types of topics they used.",
                "For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection.",
                "For this task, the IR system is required to select the elements to be returned.",
                "For the other task, the contentand-structure or CAS task, the topics are written in an XML query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy.",
                "Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description.",
                "In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants.",
                "Each topic includes a short keyword query, which is executed over the collection by each participating group on their own <br>xml ir</br> system.",
                "Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since <br>xml ir</br> is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient.",
                "Instead, the INEX organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic.",
                "A four-point scale is used in both dimensions.",
                "Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant.",
                "Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at INEX 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values.",
                "One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others.",
                "This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant.",
                "Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity.",
                "Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity.",
                "This paper reports results of this metric using all three of these quantization functions.",
                "Since this metric was first introduced at INEX 2002, it is generally referred as the inex-2002 metric.",
                "The inex-2002 metric does not penalize overlap.",
                "In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank.",
                "To address this problem, Kazai et al. [11] propose an XML cumulated gain metric, which compares the cumulated gain [9] of a ranked list to an ideal gain vector.",
                "This ideal gain vector is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path.",
                "Thus, the XCG metric rewards retrieval runs that avoid overlap.",
                "While XCG was not used officially at INEX 2004, a version of it is likely to be used in the future.",
                "At INEX 2003, yet another metric was introduced to ameliorate the perceived limitations of the inex-2002 metric.",
                "This inex-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them.",
                "Two versions were created, one that considered only component size and another that considered both size and overlap.",
                "While the inex-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4.",
                "BASELINE RETRIEVAL METHOD This section provides an overview of baseline XML information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3].",
                "This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the XML information retrieval task.",
                "The MultiText system performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
                "To support retrieval from XML and other structured document types, the system provides generalized queries of the form: rank X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms.",
                "For our INEX 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections.",
                "Prior to INEX 2004, the INEX collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names.",
                "Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received.",
                "Automating this selection process is planned as future work.",
                "For INEX 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.",
                "For example, keyword field of topic 166 +tree edit distance + XML -image became the four-term query $tree $edit $distance $xml where the $ operator within a quoted string stems the term that follows it.",
                "Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞.",
                "Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(inex-2002) k1 strict generalized sog Figure 3: Impact of k1 on inex-2002 mean average precision with b = 0.75 (INEX 2003 CO topics).",
                "Prior to INEX 2004, the INEX 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.",
                "For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article.",
                "These statistics are used for ranking all element types.",
                "Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length.",
                "The use of article statistics for all element types might be questioned.",
                "This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.",
                "The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics.",
                "Nonetheless, we plan to examine this issue again in the future.",
                "In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose.",
                "Prior to INEX 2004, we trained the MultiText system using the INEX 2003 queries.",
                "As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system.",
                "The results were surprising.",
                "Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions.",
                "In our experience, optimal values for k1 are typically in the range 0.0 to 2.0.",
                "In this case, large values are required for good performance.",
                "Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization.",
                "Similar improvements are seen under the generalized and sog quantizations.",
                "In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).",
                "After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our INEX 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5.",
                "CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements.",
                "At a conceptual level, re-ranking proceeds as follows: 1.",
                "Report the highest ranking element. 2.",
                "Adjust the scores of the unreported elements. 3.",
                "Repeat steps 1 and 2 until m elements are reported.",
                "One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements.",
                "For example, assume a paragraph with score p is reported in step 1.",
                "In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score.",
                "In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion.",
                "That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages.",
                "A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two.",
                "Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness.",
                "Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body.",
                "In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body.",
                "Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported.",
                "The next section presents and analysis a simple re-ranking algorithm that follows this strategy.",
                "The algorithm is evaluated experimentally in section 7.",
                "One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears.",
                "In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6.",
                "RE-RANKING ALGORITHM The re-ranking algorithm operates over XML trees, such as the one appearing in figure 2.",
                "Input to the algorithm is a list of n elements ranked according to their initial BM25 scores.",
                "During the initial ranking the XML tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |.",
                "Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores.",
                "An element is represented by the node x ∈ N at its root.",
                "Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - term frequency vector x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses.",
                "The vector x.f contains term frequency information corresponding to each term in the query.",
                "The vector x.g is initially zero and is updated by the algorithm as elements are reported.",
                "The score field contains the current BM25 score for the element, which will change as the values in x.g change.",
                "The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g.",
                "Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the re-ranking algorithm, nodes are stored in priority queues, ordered by decreasing score.",
                "Each priority queue PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
                "The core of the re-ranking algorithm is presented in figure 5.",
                "The algorithm takes as input the priority queue S containing the initial ranking, and produces the top-m reranked nodes in the priority queue F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
                "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a priority queue S, containing XML nodes ranked by their initial scores, and returns its results in priority queue F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
                "The tree traversal routines, Up and Down are given in figure 6.",
                "The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2.",
                "The Down routine performs a similar operation on each descendant.",
                "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the time complexity of the algorithm, first note that a node may be an argument to Down at most once.",
                "Thereafter, the reported flag of its parent is true.",
                "During each call to Down a node may be moved from S to F, requiring O(log n) time.",
                "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the time complexity of the loop over lines 2-15.",
                "During each iteration of this loop, a node and each of its ancestors are removed from a priority queue and then added back into a priority queue.",
                "Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time.",
                "Combining these observations produces an overall time complexity of O((n + mh) log n).",
                "In practice, re-ranking an INEX result set requires less than 200ms on a three-year-old desktop PC. 7.",
                "EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper.",
                "Nonetheless, when taken together they provide insight into the behaviour of the re-ranking algorithm.",
                "The INEX evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the inex-2002 and inex-2003 metrics.",
                "Values for the XCG metrics were computed using software supplied by its inventors [11].",
                "Figure 7 plots the three variants of inex-2002 MAP metric together with the XCG metric.",
                "Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on inex-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0.",
                "Recalling that the XCG metric is designed to penalize overlap, while the inex-2002 metric ignores overlap, the conflict between the metrics is obvious.",
                "The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at INEX 2004 [8,12].",
                "Figure 8 plots values of the inex-2003 MAP metric for two quantizations, with and without consideration of overlap.",
                "Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8.",
                "EXTENDED ALGORITHM One limitation of the re-ranking algorithm is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements.",
                "An obvious extension is to use different weights in these two cases.",
                "Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element.",
                "For example, a paragraph may form part of a reported section and then form part of a reported article.",
                "Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight.",
                "Motivated by these observations, the re-ranking algorithm may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times.",
                "Note that an upper bound on M is h, the maximum height of any XML tree in the collection.",
                "However, in practice M is likely to be relatively small (perhaps 3 or 4).",
                "Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights.",
                "One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument.",
                "When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down.",
                "The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors.",
                "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall time complexity of O((nM + mh) log n).",
                "Since M ≤ h and m ≤ n, the time complexity is also O(nh log n). 9.",
                "CONCLUDING DISCUSSION When generating retrieval results over an XML collection, some overlap in the results should be tolerated, and may be beneficial.",
                "For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship.",
                "The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance.",
                "Other approaches may also help to control overlap.",
                "For example, when XML retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them.",
                "While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster.",
                "At Waterloo, we continue to develop and test our ideas for INEX 2005.",
                "In particular, we are investigating methods for learning the α and βj weights.",
                "We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10.",
                "ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation.",
                "In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11.",
                "REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava.",
                "Holistic twig joins: Optimal XML pattern matching.",
                "In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
                "Mass, and A. Soffer.",
                "Searching XML documents via XML fragments.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker.",
                "MultiText experiments for INEX 2004.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas.",
                "Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit.",
                "In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu.",
                "A comprehensive XQuery to SQL translation using dynamic interval encoding.",
                "In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann.",
                "XIRQL: A query language for information retrieval in XML documents.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Second Workshop (INEX 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Third Workshop (INEX 2004), Dagstuhl, Germany, December 2004.",
                "Published as Advances in XML Information Retrieval, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson.",
                "Length normalization in XML retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "The overlap problem in content-oriented XML retrieval evaluation.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "Reliability tests for the XCG and inex-2002 metrics.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto.",
                "TRIX 2004 - Struggling with the overlap.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu.",
                "Configurable indexing and ranking for XML information retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 88-95, Sheffield, UK, July 2004. [15] Y.",
                "Mass and M. Mandelbrod.",
                "Retrieving the most relevant XML components.",
                "In INEX 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y.",
                "Mass and M. Mandelbrod.",
                "Component ranking and automatic query refinement for XML retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan.",
                "Hierarchical language models for XML component retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [18] J. Pehcevski, J.",
                "A. Thom, and A. Vercoustre.",
                "Hybrid XML retrieval re-visited.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas.",
                "Providing consistent and exhaustive relevance assessments for XML retrieval evaluation.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor.",
                "Simple BM25 extension to multiple weighted fields.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu.",
                "Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track.",
                "In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson.",
                "NEXI, now and next.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari.",
                "An algebra for structured queries in bayesian networks.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]."
            ],
            "original_annotated_samples": [
                "Each of these characteristics affects the design of an <br>xml ir</br> system, and each leads to fundamental problems that must be solved in an successful system.",
                "Since an element may be represented by the node at its root, the output of an <br>xml ir</br> system may be viewed as a ranked list of the top-m nodes.",
                "Unfortunately, this approach destroys some of the possible benefits of <br>xml ir</br>.",
                "When applying standard relevance ranking techniques in the context of <br>xml ir</br>, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
                "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an <br>xml ir</br> system might potentially retrieve any element, many elements may not be appropriate as retrieval results."
            ],
            "translated_annotated_samples": [
                "Cada una de estas características afecta el diseño de un <br>sistema de IR XML</br>, y cada una conlleva problemas fundamentales que deben resolverse en un sistema exitoso.",
                "Dado que un elemento puede estar representado por el nodo en su raíz, la salida de un sistema de IR XML puede ser vista como una lista clasificada de los m nodos principales.",
                "Desafortunadamente, este enfoque destruye algunos de los posibles beneficios de XML IR.",
                "Al aplicar técnicas estándar de clasificación de relevancia en el contexto de la <br>RI XML</br>, un enfoque natural es tratar cada elemento como un documento separado, con estadísticas de términos disponibles para cada uno [16].",
                "No es apropiado calcular la frecuencia inversa de documentos bajo la suposición de que el término está contenido en todos estos elementos, ya que el número de elementos que contienen un término depende completamente del arreglo estructural de los documentos [13,23]. 2.2 Elementos Recuperables Si bien un sistema de recuperación de información XML podría potencialmente recuperar cualquier elemento, muchos elementos pueden no ser apropiados como resultados de recuperación."
            ],
            "translated_text": "Controlando la superposición en la recuperación XML orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca RESUMEN La aplicación directa de técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos XML a menudo produce un conjunto de resultados en el que los primeros puestos están dominados por un gran número de elementos tomados de un pequeño número de documentos altamente relevantes. Este documento presenta y evalúa un algoritmo que vuelve a clasificar este conjunto de resultados, con el objetivo de minimizar el contenido redundante mientras se preservan los beneficios de la recuperación de elementos, incluido el beneficio de identificar componentes centrados en el tema contenidos en documentos relevantes. La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la Recuperación XML (INEX) constituye la base para la evaluación. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Búsqueda y Recuperación de Información Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. La representación de documentos en XML brinda una oportunidad para que los sistemas de recuperación de información aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias. En respuesta a una consulta de usuario, un sistema de recuperación de información XML podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes. Esta facilidad es de particular beneficio cuando una colección contiene documentos muy largos, como manuales de productos o libros, donde el usuario debe ser dirigido a las partes más relevantes de estos documentos. La Figura 1 proporciona un ejemplo de un artículo de revista codificado en XML, ilustrando muchas de las características importantes de los documentos XML. Las etiquetas indican el inicio y el final de cada elemento, con elementos que varían ampliamente en tamaño, desde una palabra hasta miles de palabras. Algunos elementos, como párrafos y secciones, pueden presentarse razonablemente al usuario como resultados de búsqueda, pero otros no son apropiados. Los elementos se superponen entre sí: los artículos contienen secciones, las secciones contienen subsecciones y las subsecciones contienen párrafos. Cada una de estas características afecta el diseño de un <br>sistema de IR XML</br>, y cada una conlleva problemas fundamentales que deben resolverse en un sistema exitoso. La mayoría de estos problemas fundamentales pueden resolverse mediante la cuidadosa adaptación de técnicas estándar de IR, pero los problemas causados por la superposición son únicos en esta área [4,11] y constituyen el enfoque principal de este artículo. El artículo de la figura 1 puede ser visto como un árbol XML, como se ilustra en la figura 2. Formalmente, una colección de documentos XML puede ser representada como un bosque de árboles ordenados y enraizados, que consiste en un conjunto de nodos N y un conjunto de aristas dirigidas E que conectan estos nodos. Para cada nodo x ∈ N, la notación x.parent se refiere al nodo padre de x, si existe, y la notación x.children se refiere al conjunto de nodos hijos de x. Dado que un elemento puede estar representado por el nodo en su raíz, la salida de un sistema de IR XML puede ser vista como una lista clasificada de los m nodos principales. La aplicación directa de una técnica estándar de clasificación de relevancia a un conjunto de elementos XML puede producir un resultado en el que los primeros puestos están dominados por muchos elementos estructuralmente relacionados. Una sección con una puntuación alta probablemente contenga varios párrafos con una puntuación alta y esté contenida en un artículo con una puntuación alta. Por ejemplo, muchos de los elementos en la figura 2 recibirían una puntuación alta en los algoritmos de compresión de índices de texto de consulta de palabras clave. Si cada uno de estos elementos se presenta a un usuario como un resultado individual y separado, puede perder mucho tiempo revisando y rechazando contenido redundante. Una posible solución es informar solo el elemento de mayor puntuación a lo largo de un camino dado en el árbol, y eliminar de los rangos inferiores cualquier elemento que lo contenga o esté contenido en él. Desafortunadamente, este enfoque destruye algunos de los posibles beneficios de XML IR. Por ejemplo, un elemento externo puede contener una cantidad sustancial de información que no aparece en un elemento interno, pero el elemento interno puede estar fuertemente enfocado en el tema de la consulta y proporcionar un breve resumen de los conceptos clave. En tales casos, es razonable informar sobre elementos que contienen, o están contenidos en, elementos de rango superior. Incluso cuando un libro entero es relevante, un usuario aún puede desear que se destaquen los párrafos más importantes, para guiar su lectura y ahorrar tiempo [6]. Este documento presenta un método para controlar la superposición. A partir de una clasificación inicial de elementos, un algoritmo de re-clasificación ajusta las puntuaciones de los elementos de menor clasificación que contienen, o están contenidos dentro de, elementos de mayor clasificación, reflejando el hecho de que esta información puede ser ahora redundante. Por ejemplo, una vez que un elemento que representa una sección aparece en la clasificación, las puntuaciones de los párrafos que contiene y del artículo que lo contiene se reducen. La inspiración para esta estrategia proviene parcialmente del trabajo reciente sobre la recuperación de documentos estructurados, donde los términos que aparecen en diferentes campos, como el título y el cuerpo, reciben diferentes pesos [20]. Extendiendo ese enfoque, el algoritmo de reordenamiento varía los pesos dinámicamente a medida que se procesan los elementos. El resto del documento está organizado de la siguiente manera: Después de una discusión sobre el trabajo de antecedentes y la metodología de evaluación, se presenta un método de recuperación de referencia en la sección 4. Este método de referencia representa una adaptación razonable de la tecnología estándar de IR al XML. La sección 5 luego describe una estrategia para controlar la superposición, utilizando el método de línea base como punto de partida. Un algoritmo de reordenamiento que implementa esta estrategia se presenta en la sección 6 y se evalúa en la sección 7. La sección 8 discute una versión extendida del algoritmo. 2. ANTECEDENTES Esta sección proporciona una visión general de la recuperación de información XML y discute trabajos relacionados, con énfasis en los problemas fundamentales mencionados en la introducción. Mucha investigación en el área de recuperación de XML lo ve desde una perspectiva de base de datos tradicional, preocupándose por problemas como la implementación de lenguajes de consulta estructurados [5] y el procesamiento de joins [1]. Aquí adoptamos una perspectiva de IR orientada al contenido, centrándonos en documentos XML que contienen principalmente datos en lenguaje natural y consultas que están principalmente expresadas en lenguaje natural. Suponemos que estas consultas indican únicamente la naturaleza del contenido deseado, no su estructura, y que el papel del sistema de RI es determinar qué elementos satisfacen mejor la necesidad de información subyacente. Otra investigación en IR ha considerado consultas mixtas, en las que se especifican tanto requisitos de contenido como estructurales [2,6,14,17,23]. 2.1 Estadísticas de Términos y Documentos En las aplicaciones tradicionales de recuperación de información, la unidad estándar de recuperación se considera que es el documento. Dependiendo de la aplicación, este término podría interpretarse para abarcar muchos objetos diferentes, incluyendo páginas web, artículos de periódico y mensajes de correo electrónico. Al aplicar técnicas estándar de clasificación de relevancia en el contexto de la <br>RI XML</br>, un enfoque natural es tratar cada elemento como un documento separado, con estadísticas de términos disponibles para cada uno [16]. Además, la mayoría de las técnicas de clasificación requieren estadísticas globales (por ejemplo, frecuencia inversa de documentos) calculadas sobre la colección en su totalidad. Si consideramos que esta colección incluye todos los elementos que podrían ser devueltos por el sistema, una ocurrencia específica de un término puede aparecer en varios documentos diferentes, quizás en elementos que representan un párrafo, una subsección, una sección y un artículo. No es apropiado calcular la frecuencia inversa de documentos bajo la suposición de que el término está contenido en todos estos elementos, ya que el número de elementos que contienen un término depende completamente del arreglo estructural de los documentos [13,23]. 2.2 Elementos Recuperables Si bien un sistema de recuperación de información XML podría potencialmente recuperar cualquier elemento, muchos elementos pueden no ser apropiados como resultados de recuperación. ",
            "candidates": [],
            "error": [
                [
                    "sistema de IR XML",
                    "RI XML"
                ]
            ]
        },
        "baseline retrieval": {
            "translated_key": "método de recuperación de referencia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Controlling Overlap in Content-Oriented XML Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of XML documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
                "This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents.",
                "The test collection developed by the INitiative for the Evaluation of XML Retrieval (INEX) forms the basis for the evaluation.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "INTRODUCTION The representation of documents in XML provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an XML information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in XML.",
                "Figure 1 provides an example of a journal article encoded in XML, illustrating many of the important characteristics of XML documents.",
                "Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words.",
                "Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate.",
                "Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs.",
                "Each of these characteristics affects the design of an XML IR system, and each leads to fundamental problems that must be solved in an successful system.",
                "Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper.",
                "The article of figure 1 may be viewed as an XML tree, as illustrated in figure 2.",
                "Formally, a collection of XML documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes.",
                "For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example XML tree. of x.",
                "Since an element may be represented by the node at its root, the output of an XML IR system may be viewed as a ranked list of the top-m nodes.",
                "The direct application of a standard relevance ranking technique to a set of XML elements can produce a result in which the top ranks are dominated by many structurally related elements.",
                "A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article.",
                "For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms.",
                "If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content.",
                "One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it.",
                "Unfortunately, this approach destroys some of the possible benefits of XML IR.",
                "For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts.",
                "In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements.",
                "Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6].",
                "This paper presents a method for controlling overlap.",
                "Starting with an initial element ranking, a re-ranking algorithm adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
                "For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced.",
                "The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20].",
                "Extending that approach, the re-ranking algorithm varies weights dynamically as elements are processed.",
                "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a <br>baseline retrieval</br> method is presented in section 4.",
                "This baseline method represents a reasonable adaptation of standard IR technology to XML.",
                "Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point.",
                "A re-ranking algorithm implementing this strategy is presented in section 6 and evaluated in section 7.",
                "Section 8 discusses an extended version of the algorithm. 2.",
                "BACKGROUND This section provides a general overview of XML information retrieval and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
                "Much research in the area of XML retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1].",
                "Here, we take a content oriented IR perceptive, focusing on XML documents that primarily contain natural language data and queries that are primarily expressed in natural language.",
                "We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need.",
                "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional information retrieval applications the standard unit of retrieval is taken to be the document.",
                "Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages.",
                "When applying standard relevance ranking techniques in the context of XML IR, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
                "In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole.",
                "If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article.",
                "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an XML IR system might potentially retrieve any element, many elements may not be appropriate as retrieval results.",
                "This is usually the case when elements contain very little text [10].",
                "For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself.",
                "Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user.",
                "An effective XML IR system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18].",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (INEX) has encouraged research into XML information retrieval technology [7,8].",
                "INEX is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
                "Over 50 groups participated in INEX 2004, and the conference has become as influential in the area of XML IR as TREC is in other IR areas.",
                "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by INEX.",
                "Overlap causes considerable problems with retrieval evaluation, and the INEX organizers and participants have wrestled with these problems since the beginning.",
                "While substantial progress has been made, these problem are still not completely solved.",
                "Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of INEX retrieval evaluation and discuss both current and proposed evaluation metrics.",
                "Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3.",
                "INEX 2004 Space limitations prevent the inclusion of more than a brief summary of INEX 2004 tasks and evaluation methodology.",
                "For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, INEX 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002.",
                "Each document is encoded in XML using a common DTD, with the document of figures 1 and 2 providing one example.",
                "At INEX 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics.",
                "The two tasks differed in the types of topics they used.",
                "For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection.",
                "For this task, the IR system is required to select the elements to be returned.",
                "For the other task, the contentand-structure or CAS task, the topics are written in an XML query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy.",
                "Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description.",
                "In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants.",
                "Each topic includes a short keyword query, which is executed over the collection by each participating group on their own XML IR system.",
                "Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since XML IR is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient.",
                "Instead, the INEX organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic.",
                "A four-point scale is used in both dimensions.",
                "Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant.",
                "Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at INEX 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values.",
                "One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others.",
                "This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant.",
                "Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity.",
                "Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity.",
                "This paper reports results of this metric using all three of these quantization functions.",
                "Since this metric was first introduced at INEX 2002, it is generally referred as the inex-2002 metric.",
                "The inex-2002 metric does not penalize overlap.",
                "In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank.",
                "To address this problem, Kazai et al. [11] propose an XML cumulated gain metric, which compares the cumulated gain [9] of a ranked list to an ideal gain vector.",
                "This ideal gain vector is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path.",
                "Thus, the XCG metric rewards retrieval runs that avoid overlap.",
                "While XCG was not used officially at INEX 2004, a version of it is likely to be used in the future.",
                "At INEX 2003, yet another metric was introduced to ameliorate the perceived limitations of the inex-2002 metric.",
                "This inex-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them.",
                "Two versions were created, one that considered only component size and another that considered both size and overlap.",
                "While the inex-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4.",
                "<br>baseline retrieval</br> METHOD This section provides an overview of baseline XML information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3].",
                "This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the XML information retrieval task.",
                "The MultiText system performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
                "To support retrieval from XML and other structured document types, the system provides generalized queries of the form: rank X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms.",
                "For our INEX 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections.",
                "Prior to INEX 2004, the INEX collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names.",
                "Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received.",
                "Automating this selection process is planned as future work.",
                "For INEX 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.",
                "For example, keyword field of topic 166 +tree edit distance + XML -image became the four-term query $tree $edit $distance $xml where the $ operator within a quoted string stems the term that follows it.",
                "Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞.",
                "Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(inex-2002) k1 strict generalized sog Figure 3: Impact of k1 on inex-2002 mean average precision with b = 0.75 (INEX 2003 CO topics).",
                "Prior to INEX 2004, the INEX 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.",
                "For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article.",
                "These statistics are used for ranking all element types.",
                "Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length.",
                "The use of article statistics for all element types might be questioned.",
                "This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.",
                "The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics.",
                "Nonetheless, we plan to examine this issue again in the future.",
                "In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose.",
                "Prior to INEX 2004, we trained the MultiText system using the INEX 2003 queries.",
                "As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system.",
                "The results were surprising.",
                "Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions.",
                "In our experience, optimal values for k1 are typically in the range 0.0 to 2.0.",
                "In this case, large values are required for good performance.",
                "Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization.",
                "Similar improvements are seen under the generalized and sog quantizations.",
                "In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).",
                "After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our INEX 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5.",
                "CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements.",
                "At a conceptual level, re-ranking proceeds as follows: 1.",
                "Report the highest ranking element. 2.",
                "Adjust the scores of the unreported elements. 3.",
                "Repeat steps 1 and 2 until m elements are reported.",
                "One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements.",
                "For example, assume a paragraph with score p is reported in step 1.",
                "In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score.",
                "In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion.",
                "That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages.",
                "A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two.",
                "Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness.",
                "Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body.",
                "In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body.",
                "Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported.",
                "The next section presents and analysis a simple re-ranking algorithm that follows this strategy.",
                "The algorithm is evaluated experimentally in section 7.",
                "One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears.",
                "In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6.",
                "RE-RANKING ALGORITHM The re-ranking algorithm operates over XML trees, such as the one appearing in figure 2.",
                "Input to the algorithm is a list of n elements ranked according to their initial BM25 scores.",
                "During the initial ranking the XML tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |.",
                "Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores.",
                "An element is represented by the node x ∈ N at its root.",
                "Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - term frequency vector x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses.",
                "The vector x.f contains term frequency information corresponding to each term in the query.",
                "The vector x.g is initially zero and is updated by the algorithm as elements are reported.",
                "The score field contains the current BM25 score for the element, which will change as the values in x.g change.",
                "The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g.",
                "Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the re-ranking algorithm, nodes are stored in priority queues, ordered by decreasing score.",
                "Each priority queue PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
                "The core of the re-ranking algorithm is presented in figure 5.",
                "The algorithm takes as input the priority queue S containing the initial ranking, and produces the top-m reranked nodes in the priority queue F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
                "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a priority queue S, containing XML nodes ranked by their initial scores, and returns its results in priority queue F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
                "The tree traversal routines, Up and Down are given in figure 6.",
                "The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2.",
                "The Down routine performs a similar operation on each descendant.",
                "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the time complexity of the algorithm, first note that a node may be an argument to Down at most once.",
                "Thereafter, the reported flag of its parent is true.",
                "During each call to Down a node may be moved from S to F, requiring O(log n) time.",
                "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the time complexity of the loop over lines 2-15.",
                "During each iteration of this loop, a node and each of its ancestors are removed from a priority queue and then added back into a priority queue.",
                "Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time.",
                "Combining these observations produces an overall time complexity of O((n + mh) log n).",
                "In practice, re-ranking an INEX result set requires less than 200ms on a three-year-old desktop PC. 7.",
                "EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper.",
                "Nonetheless, when taken together they provide insight into the behaviour of the re-ranking algorithm.",
                "The INEX evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the inex-2002 and inex-2003 metrics.",
                "Values for the XCG metrics were computed using software supplied by its inventors [11].",
                "Figure 7 plots the three variants of inex-2002 MAP metric together with the XCG metric.",
                "Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on inex-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0.",
                "Recalling that the XCG metric is designed to penalize overlap, while the inex-2002 metric ignores overlap, the conflict between the metrics is obvious.",
                "The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at INEX 2004 [8,12].",
                "Figure 8 plots values of the inex-2003 MAP metric for two quantizations, with and without consideration of overlap.",
                "Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8.",
                "EXTENDED ALGORITHM One limitation of the re-ranking algorithm is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements.",
                "An obvious extension is to use different weights in these two cases.",
                "Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element.",
                "For example, a paragraph may form part of a reported section and then form part of a reported article.",
                "Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight.",
                "Motivated by these observations, the re-ranking algorithm may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times.",
                "Note that an upper bound on M is h, the maximum height of any XML tree in the collection.",
                "However, in practice M is likely to be relatively small (perhaps 3 or 4).",
                "Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights.",
                "One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument.",
                "When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down.",
                "The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors.",
                "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall time complexity of O((nM + mh) log n).",
                "Since M ≤ h and m ≤ n, the time complexity is also O(nh log n). 9.",
                "CONCLUDING DISCUSSION When generating retrieval results over an XML collection, some overlap in the results should be tolerated, and may be beneficial.",
                "For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship.",
                "The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance.",
                "Other approaches may also help to control overlap.",
                "For example, when XML retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them.",
                "While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster.",
                "At Waterloo, we continue to develop and test our ideas for INEX 2005.",
                "In particular, we are investigating methods for learning the α and βj weights.",
                "We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10.",
                "ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation.",
                "In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11.",
                "REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava.",
                "Holistic twig joins: Optimal XML pattern matching.",
                "In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
                "Mass, and A. Soffer.",
                "Searching XML documents via XML fragments.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker.",
                "MultiText experiments for INEX 2004.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas.",
                "Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit.",
                "In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu.",
                "A comprehensive XQuery to SQL translation using dynamic interval encoding.",
                "In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann.",
                "XIRQL: A query language for information retrieval in XML documents.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Second Workshop (INEX 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Third Workshop (INEX 2004), Dagstuhl, Germany, December 2004.",
                "Published as Advances in XML Information Retrieval, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson.",
                "Length normalization in XML retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "The overlap problem in content-oriented XML retrieval evaluation.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "Reliability tests for the XCG and inex-2002 metrics.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto.",
                "TRIX 2004 - Struggling with the overlap.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu.",
                "Configurable indexing and ranking for XML information retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 88-95, Sheffield, UK, July 2004. [15] Y.",
                "Mass and M. Mandelbrod.",
                "Retrieving the most relevant XML components.",
                "In INEX 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y.",
                "Mass and M. Mandelbrod.",
                "Component ranking and automatic query refinement for XML retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan.",
                "Hierarchical language models for XML component retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [18] J. Pehcevski, J.",
                "A. Thom, and A. Vercoustre.",
                "Hybrid XML retrieval re-visited.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas.",
                "Providing consistent and exhaustive relevance assessments for XML retrieval evaluation.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor.",
                "Simple BM25 extension to multiple weighted fields.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu.",
                "Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track.",
                "In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson.",
                "NEXI, now and next.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari.",
                "An algebra for structured queries in bayesian networks.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]."
            ],
            "original_annotated_samples": [
                "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a <br>baseline retrieval</br> method is presented in section 4.",
                "<br>baseline retrieval</br> METHOD This section provides an overview of baseline XML information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3]."
            ],
            "translated_annotated_samples": [
                "El resto del documento está organizado de la siguiente manera: Después de una discusión sobre el trabajo de antecedentes y la metodología de evaluación, se presenta un <br>método de recuperación de referencia</br> en la sección 4.",
                "MÉTODO DE RECUPERACIÓN DE BASELINE Esta sección proporciona una descripción general del método de recuperación de información XML de base actualmente utilizado en el sistema MultiText IR, desarrollado por el Grupo de Recuperación de Información de la Universidad de Waterloo [3]."
            ],
            "translated_text": "Controlando la superposición en la recuperación XML orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca RESUMEN La aplicación directa de técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos XML a menudo produce un conjunto de resultados en el que los primeros puestos están dominados por un gran número de elementos tomados de un pequeño número de documentos altamente relevantes. Este documento presenta y evalúa un algoritmo que vuelve a clasificar este conjunto de resultados, con el objetivo de minimizar el contenido redundante mientras se preservan los beneficios de la recuperación de elementos, incluido el beneficio de identificar componentes centrados en el tema contenidos en documentos relevantes. La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la Recuperación XML (INEX) constituye la base para la evaluación. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Búsqueda y Recuperación de Información Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. La representación de documentos en XML brinda una oportunidad para que los sistemas de recuperación de información aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias. En respuesta a una consulta de usuario, un sistema de recuperación de información XML podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes. Esta facilidad es de particular beneficio cuando una colección contiene documentos muy largos, como manuales de productos o libros, donde el usuario debe ser dirigido a las partes más relevantes de estos documentos. La Figura 1 proporciona un ejemplo de un artículo de revista codificado en XML, ilustrando muchas de las características importantes de los documentos XML. Las etiquetas indican el inicio y el final de cada elemento, con elementos que varían ampliamente en tamaño, desde una palabra hasta miles de palabras. Algunos elementos, como párrafos y secciones, pueden presentarse razonablemente al usuario como resultados de búsqueda, pero otros no son apropiados. Los elementos se superponen entre sí: los artículos contienen secciones, las secciones contienen subsecciones y las subsecciones contienen párrafos. Cada una de estas características afecta el diseño de un sistema de IR XML, y cada una conlleva problemas fundamentales que deben resolverse en un sistema exitoso. La mayoría de estos problemas fundamentales pueden resolverse mediante la cuidadosa adaptación de técnicas estándar de IR, pero los problemas causados por la superposición son únicos en esta área [4,11] y constituyen el enfoque principal de este artículo. El artículo de la figura 1 puede ser visto como un árbol XML, como se ilustra en la figura 2. Formalmente, una colección de documentos XML puede ser representada como un bosque de árboles ordenados y enraizados, que consiste en un conjunto de nodos N y un conjunto de aristas dirigidas E que conectan estos nodos. Para cada nodo x ∈ N, la notación x.parent se refiere al nodo padre de x, si existe, y la notación x.children se refiere al conjunto de nodos hijos de x. Dado que un elemento puede estar representado por el nodo en su raíz, la salida de un sistema de IR XML puede ser vista como una lista clasificada de los m nodos principales. La aplicación directa de una técnica estándar de clasificación de relevancia a un conjunto de elementos XML puede producir un resultado en el que los primeros puestos están dominados por muchos elementos estructuralmente relacionados. Una sección con una puntuación alta probablemente contenga varios párrafos con una puntuación alta y esté contenida en un artículo con una puntuación alta. Por ejemplo, muchos de los elementos en la figura 2 recibirían una puntuación alta en los algoritmos de compresión de índices de texto de consulta de palabras clave. Si cada uno de estos elementos se presenta a un usuario como un resultado individual y separado, puede perder mucho tiempo revisando y rechazando contenido redundante. Una posible solución es informar solo el elemento de mayor puntuación a lo largo de un camino dado en el árbol, y eliminar de los rangos inferiores cualquier elemento que lo contenga o esté contenido en él. Desafortunadamente, este enfoque destruye algunos de los posibles beneficios de XML IR. Por ejemplo, un elemento externo puede contener una cantidad sustancial de información que no aparece en un elemento interno, pero el elemento interno puede estar fuertemente enfocado en el tema de la consulta y proporcionar un breve resumen de los conceptos clave. En tales casos, es razonable informar sobre elementos que contienen, o están contenidos en, elementos de rango superior. Incluso cuando un libro entero es relevante, un usuario aún puede desear que se destaquen los párrafos más importantes, para guiar su lectura y ahorrar tiempo [6]. Este documento presenta un método para controlar la superposición. A partir de una clasificación inicial de elementos, un algoritmo de re-clasificación ajusta las puntuaciones de los elementos de menor clasificación que contienen, o están contenidos dentro de, elementos de mayor clasificación, reflejando el hecho de que esta información puede ser ahora redundante. Por ejemplo, una vez que un elemento que representa una sección aparece en la clasificación, las puntuaciones de los párrafos que contiene y del artículo que lo contiene se reducen. La inspiración para esta estrategia proviene parcialmente del trabajo reciente sobre la recuperación de documentos estructurados, donde los términos que aparecen en diferentes campos, como el título y el cuerpo, reciben diferentes pesos [20]. Extendiendo ese enfoque, el algoritmo de reordenamiento varía los pesos dinámicamente a medida que se procesan los elementos. El resto del documento está organizado de la siguiente manera: Después de una discusión sobre el trabajo de antecedentes y la metodología de evaluación, se presenta un <br>método de recuperación de referencia</br> en la sección 4. Este método de referencia representa una adaptación razonable de la tecnología estándar de IR al XML. La sección 5 luego describe una estrategia para controlar la superposición, utilizando el método de línea base como punto de partida. Un algoritmo de reordenamiento que implementa esta estrategia se presenta en la sección 6 y se evalúa en la sección 7. La sección 8 discute una versión extendida del algoritmo. 2. ANTECEDENTES Esta sección proporciona una visión general de la recuperación de información XML y discute trabajos relacionados, con énfasis en los problemas fundamentales mencionados en la introducción. Mucha investigación en el área de recuperación de XML lo ve desde una perspectiva de base de datos tradicional, preocupándose por problemas como la implementación de lenguajes de consulta estructurados [5] y el procesamiento de joins [1]. Aquí adoptamos una perspectiva de IR orientada al contenido, centrándonos en documentos XML que contienen principalmente datos en lenguaje natural y consultas que están principalmente expresadas en lenguaje natural. Suponemos que estas consultas indican únicamente la naturaleza del contenido deseado, no su estructura, y que el papel del sistema de RI es determinar qué elementos satisfacen mejor la necesidad de información subyacente. Otra investigación en IR ha considerado consultas mixtas, en las que se especifican tanto requisitos de contenido como estructurales [2,6,14,17,23]. 2.1 Estadísticas de Términos y Documentos En las aplicaciones tradicionales de recuperación de información, la unidad estándar de recuperación se considera que es el documento. Dependiendo de la aplicación, este término podría interpretarse para abarcar muchos objetos diferentes, incluyendo páginas web, artículos de periódico y mensajes de correo electrónico. Al aplicar técnicas estándar de clasificación de relevancia en el contexto de la RI XML, un enfoque natural es tratar cada elemento como un documento separado, con estadísticas de términos disponibles para cada uno [16]. Además, la mayoría de las técnicas de clasificación requieren estadísticas globales (por ejemplo, frecuencia inversa de documentos) calculadas sobre la colección en su totalidad. Si consideramos que esta colección incluye todos los elementos que podrían ser devueltos por el sistema, una ocurrencia específica de un término puede aparecer en varios documentos diferentes, quizás en elementos que representan un párrafo, una subsección, una sección y un artículo. No es apropiado calcular la frecuencia inversa de documentos bajo la suposición de que el término está contenido en todos estos elementos, ya que el número de elementos que contienen un término depende completamente del arreglo estructural de los documentos [13,23]. 2.2 Elementos Recuperables Si bien un sistema de recuperación de información XML podría potencialmente recuperar cualquier elemento, muchos elementos pueden no ser apropiados como resultados de recuperación. Esto suele ser el caso cuando los elementos contienen muy poco texto [10]. Por ejemplo, un título de sección que contenga solo los términos de búsqueda puede recibir una puntuación alta de un algoritmo de clasificación, pero por sí solo tendría un valor limitado para un usuario, quien podría preferir la sección real en sí misma. Otros elementos pueden reflejar la estructura física de los documentos, en lugar de la estructura lógica, lo cual puede tener poco o ningún significado para un usuario. Un sistema de recuperación de información XML efectivo debe devolver solo aquellos elementos que tengan suficiente contenido para ser utilizables y puedan funcionar como objetos independientes [15,18]. Componentes estándar de documentos como párrafos, secciones, subsecciones y resúmenes generalmente cumplen con estos requisitos; los títulos, frases en cursiva y campos de metadatos individuales a menudo no lo hacen. 2.3 Metodología de Evaluación En los últimos tres años, la Iniciativa para la Evaluación de la Recuperación de Información XML (INEX) ha fomentado la investigación en tecnología de recuperación de información XML [7,8]. INEX es una serie de conferencias experimentales, similar a TREC, en la que grupos de diferentes instituciones completan una o más tareas experimentales utilizando sus propias herramientas y sistemas, y comparan sus resultados en la propia conferencia. Más de 50 grupos participaron en INEX 2004, y la conferencia se ha convertido en tan influyente en el área de la RI XML como lo es TREC en otras áreas de la RI. La investigación descrita en este artículo, al igual que gran parte del trabajo relacionado que cita, depende de las colecciones de pruebas desarrolladas por INEX. La superposición causa problemas considerables en la evaluación de la recuperación, y los organizadores y participantes de INEX han luchado con estos problemas desde el principio. Aunque se ha logrado un progreso sustancial, estos problemas aún no están completamente resueltos. Kazai et al. [11] proporcionan una exposición detallada del problema de superposición en el contexto de la evaluación de recuperación de INEX y discuten tanto las métricas de evaluación actuales como las propuestas. Muchas de estas métricas se aplican para evaluar los experimentos reportados en este artículo, y se describen brevemente en la siguiente sección. 3. Las limitaciones de espacio impiden incluir más que un breve resumen de las tareas y metodología de evaluación de INEX 2004. Para obtener información detallada, se deben consultar las actas de la conferencia en sí [8]. 3.1 Tareas Para las principales tareas experimentales, a los participantes de INEX 2004 se les proporcionó una colección de 12,107 artículos tomados de las revistas y publicaciones de la IEEE Computer Societies entre 1995 y 2002. Cada documento está codificado en XML utilizando una DTD común, siendo el documento de las figuras 1 y 2 un ejemplo. En INEX 2004, las dos principales tareas experimentales fueron ambas tareas de recuperación ad hoc, investigando el rendimiento de sistemas que buscan en una colección estática utilizando temas previamente no vistos. Las dos tareas diferían en los tipos de temas que utilizaban. Para una tarea, la tarea de solo contenido o CO, los temas consisten en declaraciones cortas en lenguaje natural sin hacer referencia directa a la estructura de los documentos en la colección. Para esta tarea, se requiere que el sistema de IR seleccione los elementos a devolver. Para la otra tarea, la tarea de contenido y estructura o CAS, los temas están escritos en un lenguaje de consulta XML [22] y contienen referencias explícitas a la estructura del documento, que el sistema de IR debe intentar satisfacer. Dado que el trabajo descrito en este documento se enfoca en la tarea de solo contenido, donde el sistema de IR no recibe orientación sobre los elementos a devolver, la tarea de CAS se ignora en el resto de nuestra descripción. En 2004, los organizadores de la conferencia seleccionaron 40 nuevos temas de CO de las contribuciones proporcionadas por los participantes de la conferencia. Cada tema incluye una breve consulta de palabras clave, la cual es ejecutada sobre la colección por cada grupo participante en su propio sistema de IR XML. Cada grupo podría presentar hasta tres ejecuciones experimentales que consistieran en los primeros m = 1500 elementos para cada tema. 3.2 Evaluación de Relevancia Dado que la RI XML se preocupa por localizar aquellos elementos que proporcionan una cobertura completa de un tema mientras contienen la menor cantidad de información irrelevante posible, los juicios simples de relevante vs. no relevante no son suficientes. En cambio, los organizadores de INEX adoptaron dos dimensiones para la evaluación de relevancia: la dimensión de exhaustividad refleja el grado en que un elemento abarca el tema, y la dimensión de especificidad refleja el grado en que un elemento se enfoca en el tema. Se utiliza una escala de cuatro puntos en ambas dimensiones. Por lo tanto, un elemento (3,3) es altamente exhaustivo y altamente específico, un elemento (1,3) es marginalmente exhaustivo y altamente específico, y un elemento (0,0) no es relevante. Información adicional sobre la metodología de evaluación se puede encontrar en Piwowarski y Lalmas [19], quienes proporcionan una justificación detallada. 3.3 Métricas de Evaluación La métrica de evaluación principal utilizada en INEX 2004 es una versión de la precisión promedio media (MAP), ajustada por diversas funciones de cuantificación para dar diferentes pesos a diferentes elementos, dependiendo de sus valores de exhaustividad y especificidad. Una variante, la función de cuantización estricta asigna un peso de 1 a los elementos (3,3) y un peso de 0 a todos los demás. Esta variante es esencialmente el valor MAP familiar, con elementos (3,3) tratados como relevantes y todos los demás elementos tratados como no relevantes. Otras funciones de cuantización están diseñadas para otorgar crédito parcial a elementos que son aproximaciones cercanas, debido a la falta de exhaustividad y/o especificidad. Tanto la función de cuantificación generalizada como la función de generalización orientada a la especificidad (sog) acreditan elementos según su grado de relevancia [11], siendo que la segunda función pone mayor énfasis en la especificidad. Este documento informa los resultados de esta métrica utilizando las tres funciones de cuantización. Desde que esta métrica fue introducida por primera vez en INEX 2002, generalmente se le conoce como la métrica inex-2002. La métrica inex-2002 no penaliza la superposición. En particular, tanto las funciones de cuantificación generalizadas como las de sog otorgan crédito parcial a un casi acierto incluso cuando se informa un elemento (3,3) que se superpone a él en un rango más alto. Para abordar este problema, Kazai et al. [11] proponen una métrica de ganancia acumulada XML, que compara la ganancia acumulada [9] de una lista clasificada con un vector de ganancia ideal. Este vector de ganancia ideal se construye a partir de las valoraciones de relevancia al eliminar la superposición y retener solo el mejor elemento a lo largo de un camino dado. Por lo tanto, la métrica XCG recompensa las ejecuciones de recuperación que evitan la superposición. Aunque XCG no se utilizó oficialmente en INEX 2004, es probable que se utilice una versión de él en el futuro. En INEX 2003, se introdujo otra métrica para mejorar las limitaciones percibidas de la métrica inex-2002. Este métrico inex-2003 extiende las definiciones de precisión y exhaustividad para considerar tanto el tamaño de los componentes informados como la superposición entre ellos. Se crearon dos versiones, una que consideraba solo el tamaño de los componentes y otra que consideraba tanto el tamaño como la superposición. Si bien la métrica inex-2003 presenta anomalías no deseadas [11] y no se utilizó en 2004, se informan valores en la sección de evaluación para proporcionar un instrumento adicional para investigar la superposición. 4. MÉTODO DE RECUPERACIÓN DE BASELINE Esta sección proporciona una descripción general del método de recuperación de información XML de base actualmente utilizado en el sistema MultiText IR, desarrollado por el Grupo de Recuperación de Información de la Universidad de Waterloo [3]. Este método de recuperación resulta de la adaptación y ajuste de la medida Okapi BM25 [21] a la tarea de recuperación de información en XML. El sistema MultiText tuvo un desempeño respetable en INEX 2004, ubicándose entre los diez primeros en todas las funciones de cuantización, y ocupando el primer lugar cuando la función de cuantización enfatizaba la exhaustividad. Para admitir la recuperación de XML y otros tipos de documentos estructurados, el sistema proporciona consultas generalizadas de la forma: clasificar X por Y donde X es una subconsulta que especifica un conjunto de elementos de documentos a clasificar y Y es un vector de subconsultas que especifican términos de recuperación individuales. Para nuestras ejecuciones de INEX 2004, la subconsulta X especificó una lista de elementos recuperables como aquellos con nombres de etiquetas de la siguiente manera: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt. Esta lista incluye entradas bibliográficas (bb) y leyendas de figuras (fig) así como párrafos, secciones y subsecciones. Antes de INEX 2004, la colección de INEX y las evaluaciones de relevancia de INEX 2003 fueron analizadas manualmente para seleccionar estos nombres de etiquetas. Los nombres de las etiquetas fueron seleccionados en base a su frecuencia en la colección, el tamaño promedio de sus elementos asociados y el número relativo de juicios de relevancia positiva que recibieron. Automatizar este proceso de selección está planeado como trabajo futuro. Para INEX 2004, el vector término Y se derivó del tema dividiendo frases en palabras individuales, eliminando palabras vacías y términos negativos (aquellos que comienzan con -), y aplicando un stemmer. Por ejemplo, el campo de palabra clave del tema 166 +distancia de edición de árbol + XML -imagen se convirtió en la consulta de cuatro términos $árbol $edición $distancia $xml donde el operador $ dentro de una cadena entre comillas deriva el término que le sigue. Nuestra implementación de Okapi BM25 se deriva de la fórmula de Robertson et al. [21] al establecer los parámetros k2 = 0 y k3 = ∞. Dado un conjunto de términos Q, a un elemento x se le asigna la puntuación t∈Q w(1) qt (k1 + 1)xt K + xt (1) donde w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = número de documentos en el corpus Dt = número de documentos que contienen t qt = frecuencia con la que t ocurre en el tema xt = frecuencia con la que t ocurre en x K = k1((1 − b) + b · lx/lavg) lx = longitud de x lavg = longitud promedio del documento 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 PrecisiónPromedio(inex-2002) k1 estricto generalizado sog Figura 3: Impacto de k1 en la precisión promedio de inex-2002 con b = 0.75 (temas CO de INEX 2003). Antes de INEX 2004, los temas y juicios de INEX 2003 se utilizaron para ajustar los parámetros b y k1, y el impacto de este ajuste se discute más adelante en esta sección. Para los propósitos de calcular estadísticas a nivel de documento (D, Dt y lavg), un documento se define como un artículo. Estas estadísticas se utilizan para clasificar todos los tipos de elementos. Siguiendo la sugerencia de Kamps et al. [10], los resultados de recuperación se filtran para eliminar elementos muy cortos, aquellos con menos de 25 palabras de longitud. El uso de estadísticas de artículos para todos los tipos de elementos podría ser cuestionado. Este enfoque puede justificarse al considerar la colección como un conjunto de artículos que se pueden buscar utilizando técnicas estándar orientadas a documentos, donde solo se devuelven artículos. El puntaje calculado para un elemento es esencialmente el puntaje que recibiría si se agregara a la colección como un nuevo documento, ignorando los ajustes menores necesarios para las estadísticas a nivel de documento. Sin embargo, planeamos examinar este tema nuevamente en el futuro. En nuestra experiencia, el rendimiento de BM25 suele beneficiarse al ajustar los parámetros b y k1 a la colección, siempre que haya consultas de entrenamiento disponibles con este propósito. Antes de INEX 2004, entrenamos el sistema MultiText utilizando las consultas de INEX 2003. Como punto de partida, utilizamos los valores b = 0.75 y k1 = 1.2, que funcionan bien en colecciones TREC adhoc y se utilizan como valores predeterminados en nuestro sistema. Los resultados fueron sorprendentes. La Figura 3 muestra el resultado de variar k1 con b = 0.75 en los valores de MAP bajo tres funciones de cuantización. En nuestra experiencia, los valores óptimos para k1 suelen estar en el rango de 0.0 a 2.0. En este caso, se requieren valores grandes para un buen rendimiento. Entre k1 = 1.0 y k1 = 6.0, el MAP aumenta en más del 15% bajo la cuantización estricta. Se observan mejoras similares bajo las cuantizaciones generalizada y SOG. Por el contrario, nuestro valor predeterminado de b = 0.75 funciona bien bajo todas las funciones de cuantificación (figura 4). Después de ajustar una amplia gama de valores bajo varias funciones de cuantización, seleccionamos los valores de k = 10.0 y b = 0.80 para nuestros experimentos de INEX 2004, y estos valores se utilizan para los experimentos reportados en la sección 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 PrecisiónPromedioMedia (inex-2002) b estricto generalizado sog Figura 4: Impacto de b en la precisión promedio media de inex-2002 con k1 = 10 (temas CO de INEX 2003). 5. CONTROL DE SUPERPOSICIÓN Comenzando con una clasificación de elementos generada por el método de referencia descrito en la sección anterior, los elementos se vuelven a clasificar para controlar la superposición ajustando de forma iterativa las puntuaciones de aquellos elementos que contienen o están contenidos en elementos de clasificación más alta. A nivel conceptual, la reorganización procede de la siguiente manera: 1. Informe el elemento de rango más alto. Ajustar las puntuaciones de los elementos no reportados. 3. Repetir los pasos 1 y 2 hasta que se informen m elementos. Un enfoque para ajustar las puntuaciones de los elementos no informados en el paso 2 podría basarse en las puntuaciones Okapi BM25 de los elementos involucrados. Por ejemplo, supongamos que se informa un párrafo con una puntuación p en el paso 1. En el paso 2, la sección que contiene el párrafo podría tener su puntuación s reducida en una cantidad α · p para reflejar la contribución reducida que el párrafo debería hacer a la puntuación de las secciones. En un contexto relacionado, Robertson et al. [20] argumentan en contra de la combinación lineal de las puntuaciones de Okapi de esta manera. Ese trabajo considera el problema de asignar diferentes pesos a diferentes campos de documentos, como el título y el cuerpo asociados con páginas web. Un enfoque común para este problema puntúa el título y el cuerpo por separado y genera una puntuación final como una combinación lineal de ambos. Robertson et al. discuten las deficiencias teóricas en este enfoque y demuestran experimentalmente que puede perjudicar realmente la efectividad de la recuperación. En cambio, aplican los pesos a nivel de frecuencia de términos, donde la aparición de un término de consulta t en el título contribuye más al puntaje que una aparición en el cuerpo. En la ecuación 1, xt se convierte en α0 · yt + α1 · zt, donde yt es el número de veces que t aparece en el título y zt es el número de veces que t aparece en el cuerpo. Al traducir este enfoque a nuestro contexto, la contribución de los términos que aparecen en los elementos se reduce dinámicamente a medida que se informan. La siguiente sección presenta y analiza un algoritmo de reordenamiento simple que sigue esta estrategia. El algoritmo se evalúa experimentalmente en la sección 7. Una limitación del algoritmo es que la contribución de los términos que aparecen en los elementos informados se reduce por el mismo factor independientemente del número de elementos informados en los que aparezca. En la sección 8, el algoritmo se extiende para aplicar pesos crecientes, disminuyendo la puntuación, cuando un término aparece en más de un elemento informado. 6. ALGORITMO DE REORDENAMIENTO El algoritmo de reordenamiento opera sobre árboles XML, como el que aparece en la figura 2. La entrada al algoritmo es una lista de n elementos clasificados según sus puntuaciones iniciales de BM25. Durante la clasificación inicial, el árbol XML se reconstruye dinámicamente para incluir solo aquellos nodos con puntuaciones BM25 distintas de cero, por lo que n puede ser considerablemente menor que |N|. La salida del algoritmo es una lista de los primeros m elementos, clasificados según sus puntajes ajustados. Un elemento está representado por el nodo x ∈ N en su raíz. Asociados con este nodo se encuentran campos que almacenan la longitud del elemento, las frecuencias de términos y otra información requerida por el algoritmo de re-ranking, de la siguiente manera: x.f - vector de frecuencia de términos x.g - ajustes de frecuencia de términos x.l - longitud del elemento x.score - puntaje actual de Okapi BM25 x.reported - bandera booleana, inicialmente falsa x.children - conjunto de nodos hijos x.parent - nodo padre, si existe Estos campos se llenan durante el proceso de clasificación inicial y se actualizan a medida que avanza el algoritmo. El vector x.f contiene información de frecuencia de términos correspondiente a cada término en la consulta. El vector x.g es inicialmente cero y se actualiza por el algoritmo a medida que se informan elementos. El campo de puntuación contiene la puntuación BM25 actual para el elemento, la cual cambiará a medida que cambien los valores en x.g. El puntaje se calcula utilizando la ecuación 1, con el valor xt para cada término determinado por una combinación de los valores en x.f y x.g. Dado un término t ∈ Q, sea ft el componente de x.f correspondiente a t, y sea gt el componente de x.g correspondiente a t, entonces: xt = ft − α · gt (2) Para el procesamiento por el algoritmo de reordenamiento, los nodos se almacenan en colas de prioridad, ordenadas por puntaje decreciente. Cada cola de prioridad PQ admite tres operaciones: PQ.front() - devuelve el nodo con la puntuación más alta, PQ.add(x) - agrega el nodo x a la cola, PQ.remove(x) - elimina el nodo x de la cola. Cuando se implementan utilizando estructuras de datos estándar, la operación front requiere tiempo O(1), y las otras operaciones requieren tiempo O(log n), donde n es el tamaño de la cola. El núcleo del algoritmo de reordenamiento se presenta en la figura 5. El algoritmo toma como entrada la cola de prioridad S que contiene la clasificación inicial, y produce los primeros m nodos reordenados en la cola de prioridad F. Después de inicializar F como vacío en la línea 1, el algoritmo recorre m veces las líneas 215, transfiriendo al menos un nodo de S a F durante cada iteración. Al inicio de cada iteración, el nodo no reportado al frente de S tiene el mayor puntaje ajustado, y se elimina y se agrega a F. El algoritmo luego recorre el 1 F ← ∅ 2 para i ← 1 a m hacer 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 para cada y ∈ x.children hacer 9 Abajo (y) 10 fin hacer 11 12 si x no es un nodo raíz entonces 13 Arriba (x, x.parent) 14 fin si 15 fin hacer Figura 5: Algoritmo de Re-Ranking - Como entrada, el algoritmo toma una cola de prioridad S, que contiene nodos XML clasificados por sus puntajes iniciales, y devuelve sus resultados en la cola de prioridad F, clasificados por puntajes ajustados. 1 Arriba(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recalcular y.score 5 S.add(y) 6 si y no es un nodo raíz entonces 7 Arriba (x, y.parent) 8 fin si 9 10 Abajo(x) ≡ 11 si no x.reported entonces 12 S.remove(x) 14 x.g ← x.f 15 recalcular x.score 16 si x.score > 0 entonces 17 F.add(x) 18 fin si 19 x.reported ← true 20 para cada y ∈ x.children hacer 21 Abajo (y) 22 fin hacer 23 fin si Figura 6: Rutinas de recorrido de árbol llamadas por el algoritmo de re-ranking. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 PrecisiónPromedioMedia (inex-2002) GananciaAcumuladaXML(XCG) alfa MAP (estricto) MAP (generalizado) MAP (sog) XCG (sog2) Figura 7: Impacto de α en XCG y MAP inex-2002 (temas CO de INEX 2004; conjunto de evaluación I). nodos ancestros (líneas 8-10) y descendientes (líneas 12-14) ajustando los puntajes de estos nodos. Las rutinas de recorrido de árboles, Arriba y Abajo, se muestran en la figura 6. El procedimiento Up elimina cada nodo ancestro de S, ajusta sus valores de frecuencia de término, recalcula su puntuación y lo vuelve a agregar a S. El ajuste de los valores de frecuencia de término (línea 3) agrega a y.g solo las ocurrencias de términos no reportadas previamente en x. El recalculo de la puntuación en la línea 4 utiliza las ecuaciones 1 y 2. La rutina Down realiza una operación similar en cada descendiente. Sin embargo, dado que el contenido de cada descendiente está completamente contenido en un elemento informado, su puntuación final puede ser calculada, y se elimina de S y se agrega a F. Para determinar la complejidad temporal del algoritmo, primero observe que un nodo puede ser un argumento de Down como máximo una vez. Posteriormente, la bandera reportada de su padre es verdadera. Durante cada llamada a Down, un nodo puede ser movido de S a F, lo que requiere un tiempo O(log n). Por lo tanto, el tiempo total para todas las llamadas a Down es O(n log n), y podemos ignorar temporalmente las líneas 8-10 de la figura 5 al considerar la complejidad temporal del bucle sobre las líneas 2-15. Durante cada iteración de este bucle, se elimina un nodo y cada uno de sus ancestros de una cola de prioridad y luego se vuelven a agregar a la cola de prioridad. Dado que un nodo puede tener como máximo h ancestros, donde h es la altura máxima de cualquier árbol en la colección, cada una de las m iteraciones requiere un tiempo de O(h log n). La combinación de estas observaciones produce una complejidad temporal general de O((n + mh) log n). En la práctica, volver a clasificar un conjunto de resultados de INEX requiere menos de 200 ms en una PC de escritorio de tres años de antigüedad. EVALUACIÓN Ninguna de las métricas descritas en la sección 3.3 se ajusta adecuadamente a la perspectiva de superposición defendida por este documento. Sin embargo, cuando se toman en conjunto, proporcionan información sobre el comportamiento del algoritmo de reordenamiento. Los paquetes de evaluación de INEX (inex_eval e inex_eval_ng) se utilizaron para calcular los valores de las métricas inex-2002 e inex-2003. Los valores de las métricas XCG fueron calculados utilizando el software proporcionado por sus inventores [11]. La Figura 7 representa juntas las tres variantes de la métrica MAP inex-2002 junto con la métrica XCG. Los valores para estas métricas 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Precisión Media Promedio (inex-2003) alfa estricto, superposición no considerada estricto, superposición considerada generalizado, superposición no considerada generalizado, superposición considerada Figura 8: Impacto de α en MAP inex-2003 (temas CO de INEX 2004; conjunto de evaluación I). se trazan para valores de α entre 0.0 y 1.0. Recordando que la métrica XCG está diseñada para penalizar la superposición, mientras que la métrica inex-2002 ignora la superposición, el conflicto entre las métricas es evidente. Los valores de MAP en un extremo (α = 0.0) y el valor de XCG en el otro extremo (α = 1.0) representan un rendimiento de recuperación comparable a los mejores sistemas en INEX 2004 [8,12]. La Figura 8 muestra los valores de la métrica MAP inex-2003 para dos cuantificaciones, con y sin consideración de la superposición. Una vez más, el conflicto es evidente, con la influencia de α considerablemente disminuida cuando se considera la superposición. 8. ALGORITMO EXTENDIDO Una limitación del algoritmo de reordenamiento es que se utiliza un único peso α para ajustar las puntuaciones tanto de los ancestros como de los descendientes de los elementos informados. Una extensión obvia es usar diferentes pesos en estos dos casos. Además, se utiliza el mismo peso independientemente de cuántas veces un elemento esté contenido en un elemento informado. Por ejemplo, un párrafo puede formar parte de una sección reportada y luego formar parte de un artículo reportado. Dado que el usuario puede haber visto este párrafo dos veces, su puntuación debería ser reducida aún más aumentando el valor del peso. Motivado por estas observaciones, el algoritmo de reordenamiento puede ser extendido con una serie de pesos 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0, donde βj es el peso aplicado a un nodo que ha sido descendiente de un nodo reportado j veces. Ten en cuenta que un límite superior en M es h, la altura máxima de cualquier árbol XML en la colección. Sin embargo, en la práctica es probable que M sea relativamente pequeño (quizás 3 o 4). La Figura 9 presenta reemplazos para las rutinas de Subir y Bajar de la Figura 6, incorporando esta serie de pesas. Se requiere un campo adicional en cada nodo, de la siguiente manera: x.j - conteo descendente El valor de x.j se establece inicialmente en cero en todos los nodos y se incrementa cada vez que se llama a Down con x como su argumento. Al calcular la puntuación del nodo, el valor de x.j selecciona 1 Up(x, y) ≡ 2 si no y.reported entonces 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recalcular y.score 6 S.add(y) 8 si y no es un nodo raíz entonces 9 Up (x, y.padre) 10 fin si 11 fin si 12 13 Down(x) ≡ 14 si x.j < M entonces 15 x.j ← x.j + 1 16 si no x.reported entonces 17 S.remove(x) 18 recalcular x.score 19 S.add(x) 20 fin si 21 para cada y ∈ x.hijos hacer 22 Down (y) 23 fin hacer 24 fin si Figura 9: Rutinas extendidas de recorrido de árbol. el peso a aplicar al nodo ajustando el valor de xt en la ecuación 1, de la siguiente manera: xt = βx.j · (ft − α · gt) (3) donde ft y gt son los componentes de x.f y x.g correspondientes al término t. Se requieren algunos cambios adicionales para extender Up y Down. La rutina Up devuelve inmediatamente (línea 2) si su argumento ya ha sido reportado, ya que las frecuencias de términos ya han sido ajustadas en sus ancestros. El procedimiento Down no informa su argumento, sino que vuelve a calcular su puntuación y la agrega de nuevo a S. Un nodo no puede ser un argumento de Down más de M +1 veces, lo que a su vez implica una complejidad temporal total de O((nM + mh) log n). Dado que M ≤ h y m ≤ n, la complejidad temporal también es O(nh log n). DISCUSIÓN CONCLUSIVA Al generar resultados de recuperación en una colección de XML, se debe tolerar cierta superposición en los resultados, lo cual puede ser beneficioso. Por ejemplo, cuando un elemento altamente exhaustivo y bastante específico (3,2) contiene un elemento mucho más pequeño (2,3), ambos deben ser informados al usuario, y los algoritmos de recuperación y las métricas de evaluación deben respetar esta relación. El algoritmo presentado en este documento controla la superposición ponderando los términos que aparecen en los elementos informados para reflejar su menor importancia. Otros enfoques también pueden ayudar a controlar la superposición. Por ejemplo, cuando se presentan los resultados de recuperación de XML a los usuarios, puede ser deseable agrupar elementos relacionados estructuralmente juntos, ilustrando visualmente las relaciones entre ellos. Si bien este estilo de interfaz de usuario puede ayudar a un usuario a lidiar con la superposición, la estrategia presentada en este documento sigue siendo aplicable, al determinar los mejores elementos para incluir en cada grupo. En Waterloo, seguimos desarrollando y probando nuestras ideas para INEX 2005. En particular, estamos investigando métodos para aprender los pesos α y βj. También estamos reevaluando nuestro enfoque en las estadísticas de documentos y examinando ajustes apropiados al parámetro k1 a medida que cambian los pesos de los términos [20]. 10. AGRADECIMIENTOS Gracias a Gabriella Kazai y Arjen de Vries por proporcionar una versión temprana de su software para calcular la métrica XCG, y gracias a Phil Tilker y Stefan B¨uttcher por su ayuda con la evaluación experimental. En parte, la financiación para este proyecto fue proporcionada por IBM Canadá a través del Instituto Nacional de Investigación de Software. 11. REFERENCIAS [1] N. Bruno, N. Koudas y D. Srivastava. Uniones de ramas holísticas: Coincidencia óptima de patrones XML. En Actas de la Conferencia Internacional ACM SIGMOD 2002 sobre la Gestión de Datos, páginas 310-321, Madison, Wisconsin, junio de 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y. Masa y A. Soffer. Buscando documentos XML a través de fragmentos XML. En Actas de la 26ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 151-158, Toronto, Canadá, 2003. [3] C. L. A. Clarke y P. L. Tilker. Experimentos MultiText para INEX 2004. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai y M. Lalmas. Tolerancia a la irrelevancia: Una evaluación orientada al esfuerzo del usuario de sistemas de recuperación sin unidad de recuperación predefinida. En las Actas de la Conferencia RIAO 2004, páginas 463-473, Aviñón, Francia, abril de 2004. [5] D. DeHaan, D. Toman, M. P. Consens y M. T. ¨Ozsu. Una traducción exhaustiva de XQuery a SQL utilizando codificación dinámica de intervalos. En Actas de la Conferencia Internacional ACM SIGMOD 2003 sobre la Gestión de Datos, San Diego, junio de 2003. [6] N. Fuhr y K. Großjohann. XIRQL: Un lenguaje de consulta para la recuperación de información en documentos XML. En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 172-180, Nueva Orleans, septiembre de 2001. [7] N. Fuhr, M. Lalmas y S. Malik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Segundo Taller (INEX 2003), Dagstuhl, Alemania, diciembre de 2003. [8] N. Fuhr, M. Lalmas, S. Malik y Zoltán Szlávik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Tercer Taller (INEX 2004), Dagstuhl, Alemania, diciembre de 2004. Publicado como Avances en la Recuperación de Información XML, Notas de Conferencia en Ciencias de la Computación, volumen 3493, Springer, 2005. [9] K. J¨avelin y J. Kek¨al¨ainen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, y B. Sigurbjörnsson. Normalización de longitud en la recuperación de XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 80-87, Sheffield, Reino Unido, julio de 2004. [11] G. Kazai, M. Lalmas y A. P. de Vries. El problema de superposición en la evaluación de la recuperación de XML orientada al contenido. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 72-79, Sheffield, Reino Unido, julio de 2004. [12] G. Kazai, M. Lalmas y A. P. de Vries. Pruebas de confiabilidad para las métricas XCG e inex-2002. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola y T. Aalto. TRIX 2004 - Luchando con la superposición. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [14] S. Liu, Q. Zou y W. W. Chu. Indexación y clasificación configurables para la recuperación de información en XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 88-95, Sheffield, Reino Unido, julio de 2004. [15] Y. Masa y M. Mandelbrot. Recuperando los componentes XML más relevantes. En las Actas del Taller INEX 2003, Dagstuhl, Alemania, diciembre de 2003. [16] Y. Masa y M. Mandelbrot. Clasificación de componentes y refinamiento automático de consultas para la recuperación de XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [17] P. Ogilvie y J. Callan. Modelos de lenguaje jerárquicos para la recuperación de componentes XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [18] J. Pehcevski, J. A. Thom y A. Vercoustre. Recuperación híbrida de XML revisitada. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [19] B. Piwowarski y M. Lalmas. Proporcionando evaluaciones de relevancia consistentes y exhaustivas para la evaluación de recuperación de XML. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 361-370, Washington, DC, noviembre de 2004. [20] S. Robertson, H. Zaragoza y M. Taylor. Extensión simple de BM25 a múltiples campos ponderados. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 42-50, Washington, DC, noviembre de 2004. [21] S. E. Robertson, S. Walker y M. Beaulieu. Okapi en TREC-7: Búsqueda automática, filtrado, VLC y pista interactiva. En Actas de la Séptima Conferencia de Recuperación de Texto, Gaithersburg, MD, noviembre de 1998. [22] A. Trotman y B. Sigurbjörnsson. NEXI, ahora y después. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski y P. Gallinari. Un álgebra para consultas estructuradas en redes bayesianas. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "inex": {
            "translated_key": "inex",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Controlling Overlap in Content-Oriented XML Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of XML documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
                "This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents.",
                "The test collection developed by the INitiative for the Evaluation of XML Retrieval (<br>inex</br>) forms the basis for the evaluation.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "INTRODUCTION The representation of documents in XML provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an XML information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in XML.",
                "Figure 1 provides an example of a journal article encoded in XML, illustrating many of the important characteristics of XML documents.",
                "Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words.",
                "Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate.",
                "Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs.",
                "Each of these characteristics affects the design of an XML IR system, and each leads to fundamental problems that must be solved in an successful system.",
                "Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper.",
                "The article of figure 1 may be viewed as an XML tree, as illustrated in figure 2.",
                "Formally, a collection of XML documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes.",
                "For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example XML tree. of x.",
                "Since an element may be represented by the node at its root, the output of an XML IR system may be viewed as a ranked list of the top-m nodes.",
                "The direct application of a standard relevance ranking technique to a set of XML elements can produce a result in which the top ranks are dominated by many structurally related elements.",
                "A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article.",
                "For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms.",
                "If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content.",
                "One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it.",
                "Unfortunately, this approach destroys some of the possible benefits of XML IR.",
                "For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts.",
                "In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements.",
                "Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6].",
                "This paper presents a method for controlling overlap.",
                "Starting with an initial element ranking, a re-ranking algorithm adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
                "For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced.",
                "The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20].",
                "Extending that approach, the re-ranking algorithm varies weights dynamically as elements are processed.",
                "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a baseline retrieval method is presented in section 4.",
                "This baseline method represents a reasonable adaptation of standard IR technology to XML.",
                "Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point.",
                "A re-ranking algorithm implementing this strategy is presented in section 6 and evaluated in section 7.",
                "Section 8 discusses an extended version of the algorithm. 2.",
                "BACKGROUND This section provides a general overview of XML information retrieval and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
                "Much research in the area of XML retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1].",
                "Here, we take a content oriented IR perceptive, focusing on XML documents that primarily contain natural language data and queries that are primarily expressed in natural language.",
                "We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need.",
                "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional information retrieval applications the standard unit of retrieval is taken to be the document.",
                "Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages.",
                "When applying standard relevance ranking techniques in the context of XML IR, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
                "In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole.",
                "If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article.",
                "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an XML IR system might potentially retrieve any element, many elements may not be appropriate as retrieval results.",
                "This is usually the case when elements contain very little text [10].",
                "For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself.",
                "Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user.",
                "An effective XML IR system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18].",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (<br>inex</br>) has encouraged research into XML information retrieval technology [7,8].",
                "<br>inex</br> is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
                "Over 50 groups participated in <br>inex</br> 2004, and the conference has become as influential in the area of XML IR as TREC is in other IR areas.",
                "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by <br>inex</br>.",
                "Overlap causes considerable problems with retrieval evaluation, and the <br>inex</br> organizers and participants have wrestled with these problems since the beginning.",
                "While substantial progress has been made, these problem are still not completely solved.",
                "Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of <br>inex</br> retrieval evaluation and discuss both current and proposed evaluation metrics.",
                "Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3.",
                "<br>inex</br> 2004 Space limitations prevent the inclusion of more than a brief summary of <br>inex</br> 2004 tasks and evaluation methodology.",
                "For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, <br>inex</br> 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002.",
                "Each document is encoded in XML using a common DTD, with the document of figures 1 and 2 providing one example.",
                "At <br>inex</br> 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics.",
                "The two tasks differed in the types of topics they used.",
                "For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection.",
                "For this task, the IR system is required to select the elements to be returned.",
                "For the other task, the contentand-structure or CAS task, the topics are written in an XML query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy.",
                "Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description.",
                "In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants.",
                "Each topic includes a short keyword query, which is executed over the collection by each participating group on their own XML IR system.",
                "Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since XML IR is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient.",
                "Instead, the <br>inex</br> organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic.",
                "A four-point scale is used in both dimensions.",
                "Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant.",
                "Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at <br>inex</br> 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values.",
                "One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others.",
                "This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant.",
                "Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity.",
                "Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity.",
                "This paper reports results of this metric using all three of these quantization functions.",
                "Since this metric was first introduced at <br>inex</br> 2002, it is generally referred as the <br>inex</br>-2002 metric.",
                "The <br>inex</br>-2002 metric does not penalize overlap.",
                "In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank.",
                "To address this problem, Kazai et al. [11] propose an XML cumulated gain metric, which compares the cumulated gain [9] of a ranked list to an ideal gain vector.",
                "This ideal gain vector is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path.",
                "Thus, the XCG metric rewards retrieval runs that avoid overlap.",
                "While XCG was not used officially at <br>inex</br> 2004, a version of it is likely to be used in the future.",
                "At <br>inex</br> 2003, yet another metric was introduced to ameliorate the perceived limitations of the <br>inex</br>-2002 metric.",
                "This <br>inex</br>-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them.",
                "Two versions were created, one that considered only component size and another that considered both size and overlap.",
                "While the <br>inex</br>-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4.",
                "BASELINE RETRIEVAL METHOD This section provides an overview of baseline XML information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3].",
                "This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the XML information retrieval task.",
                "The MultiText system performed respectably at <br>inex</br> 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
                "To support retrieval from XML and other structured document types, the system provides generalized queries of the form: rank X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms.",
                "For our <br>inex</br> 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections.",
                "Prior to <br>inex</br> 2004, the <br>inex</br> collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names.",
                "Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received.",
                "Automating this selection process is planned as future work.",
                "For <br>inex</br> 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.",
                "For example, keyword field of topic 166 +tree edit distance + XML -image became the four-term query $tree $edit $distance $xml where the $ operator within a quoted string stems the term that follows it.",
                "Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞.",
                "Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(<br>inex</br>-2002) k1 strict generalized sog Figure 3: Impact of k1 on <br>inex</br>-2002 mean average precision with b = 0.75 (INEX 2003 CO topics).",
                "Prior to <br>inex</br> 2004, the <br>inex</br> 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.",
                "For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article.",
                "These statistics are used for ranking all element types.",
                "Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length.",
                "The use of article statistics for all element types might be questioned.",
                "This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.",
                "The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics.",
                "Nonetheless, we plan to examine this issue again in the future.",
                "In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose.",
                "Prior to <br>inex</br> 2004, we trained the MultiText system using the <br>inex</br> 2003 queries.",
                "As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system.",
                "The results were surprising.",
                "Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions.",
                "In our experience, optimal values for k1 are typically in the range 0.0 to 2.0.",
                "In this case, large values are required for good performance.",
                "Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization.",
                "Similar improvements are seen under the generalized and sog quantizations.",
                "In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).",
                "After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our <br>inex</br> 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(<br>inex</br>-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5.",
                "CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements.",
                "At a conceptual level, re-ranking proceeds as follows: 1.",
                "Report the highest ranking element. 2.",
                "Adjust the scores of the unreported elements. 3.",
                "Repeat steps 1 and 2 until m elements are reported.",
                "One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements.",
                "For example, assume a paragraph with score p is reported in step 1.",
                "In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score.",
                "In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion.",
                "That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages.",
                "A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two.",
                "Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness.",
                "Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body.",
                "In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body.",
                "Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported.",
                "The next section presents and analysis a simple re-ranking algorithm that follows this strategy.",
                "The algorithm is evaluated experimentally in section 7.",
                "One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears.",
                "In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6.",
                "RE-RANKING ALGORITHM The re-ranking algorithm operates over XML trees, such as the one appearing in figure 2.",
                "Input to the algorithm is a list of n elements ranked according to their initial BM25 scores.",
                "During the initial ranking the XML tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |.",
                "Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores.",
                "An element is represented by the node x ∈ N at its root.",
                "Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - term frequency vector x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses.",
                "The vector x.f contains term frequency information corresponding to each term in the query.",
                "The vector x.g is initially zero and is updated by the algorithm as elements are reported.",
                "The score field contains the current BM25 score for the element, which will change as the values in x.g change.",
                "The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g.",
                "Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the re-ranking algorithm, nodes are stored in priority queues, ordered by decreasing score.",
                "Each priority queue PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
                "The core of the re-ranking algorithm is presented in figure 5.",
                "The algorithm takes as input the priority queue S containing the initial ranking, and produces the top-m reranked nodes in the priority queue F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
                "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a priority queue S, containing XML nodes ranked by their initial scores, and returns its results in priority queue F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(<br>inex</br>-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and <br>inex</br>-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
                "The tree traversal routines, Up and Down are given in figure 6.",
                "The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2.",
                "The Down routine performs a similar operation on each descendant.",
                "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the time complexity of the algorithm, first note that a node may be an argument to Down at most once.",
                "Thereafter, the reported flag of its parent is true.",
                "During each call to Down a node may be moved from S to F, requiring O(log n) time.",
                "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the time complexity of the loop over lines 2-15.",
                "During each iteration of this loop, a node and each of its ancestors are removed from a priority queue and then added back into a priority queue.",
                "Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time.",
                "Combining these observations produces an overall time complexity of O((n + mh) log n).",
                "In practice, re-ranking an <br>inex</br> result set requires less than 200ms on a three-year-old desktop PC. 7.",
                "EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper.",
                "Nonetheless, when taken together they provide insight into the behaviour of the re-ranking algorithm.",
                "The <br>inex</br> evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the <br>inex</br>-2002 and inex-2003 metrics.",
                "Values for the XCG metrics were computed using software supplied by its inventors [11].",
                "Figure 7 plots the three variants of <br>inex</br>-2002 MAP metric together with the XCG metric.",
                "Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(<br>inex</br>-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on <br>inex</br>-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0.",
                "Recalling that the XCG metric is designed to penalize overlap, while the <br>inex</br>-2002 metric ignores overlap, the conflict between the metrics is obvious.",
                "The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at <br>inex</br> 2004 [8,12].",
                "Figure 8 plots values of the <br>inex</br>-2003 MAP metric for two quantizations, with and without consideration of overlap.",
                "Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8.",
                "EXTENDED ALGORITHM One limitation of the re-ranking algorithm is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements.",
                "An obvious extension is to use different weights in these two cases.",
                "Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element.",
                "For example, a paragraph may form part of a reported section and then form part of a reported article.",
                "Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight.",
                "Motivated by these observations, the re-ranking algorithm may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times.",
                "Note that an upper bound on M is h, the maximum height of any XML tree in the collection.",
                "However, in practice M is likely to be relatively small (perhaps 3 or 4).",
                "Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights.",
                "One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument.",
                "When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down.",
                "The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors.",
                "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall time complexity of O((nM + mh) log n).",
                "Since M ≤ h and m ≤ n, the time complexity is also O(nh log n). 9.",
                "CONCLUDING DISCUSSION When generating retrieval results over an XML collection, some overlap in the results should be tolerated, and may be beneficial.",
                "For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship.",
                "The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance.",
                "Other approaches may also help to control overlap.",
                "For example, when XML retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them.",
                "While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster.",
                "At Waterloo, we continue to develop and test our ideas for <br>inex</br> 2005.",
                "In particular, we are investigating methods for learning the α and βj weights.",
                "We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10.",
                "ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation.",
                "In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11.",
                "REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava.",
                "Holistic twig joins: Optimal XML pattern matching.",
                "In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
                "Mass, and A. Soffer.",
                "Searching XML documents via XML fragments.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker.",
                "MultiText experiments for <br>inex</br> 2004.",
                "In <br>inex</br> 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas.",
                "Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit.",
                "In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu.",
                "A comprehensive XQuery to SQL translation using dynamic interval encoding.",
                "In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann.",
                "XIRQL: A query language for information retrieval in XML documents.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Second Workshop (<br>inex</br> 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Third Workshop (<br>inex</br> 2004), Dagstuhl, Germany, December 2004.",
                "Published as Advances in XML Information Retrieval, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson.",
                "Length normalization in XML retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "The overlap problem in content-oriented XML retrieval evaluation.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "Reliability tests for the XCG and <br>inex</br>-2002 metrics.",
                "In <br>inex</br> 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto.",
                "TRIX 2004 - Struggling with the overlap.",
                "In <br>inex</br> 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu.",
                "Configurable indexing and ranking for XML information retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 88-95, Sheffield, UK, July 2004. [15] Y.",
                "Mass and M. Mandelbrod.",
                "Retrieving the most relevant XML components.",
                "In <br>inex</br> 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y.",
                "Mass and M. Mandelbrod.",
                "Component ranking and automatic query refinement for XML retrieval.",
                "In <br>inex</br> 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan.",
                "Hierarchical language models for XML component retrieval.",
                "In <br>inex</br> 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [18] J. Pehcevski, J.",
                "A. Thom, and A. Vercoustre.",
                "Hybrid XML retrieval re-visited.",
                "In <br>inex</br> 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas.",
                "Providing consistent and exhaustive relevance assessments for XML retrieval evaluation.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor.",
                "Simple BM25 extension to multiple weighted fields.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu.",
                "Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track.",
                "In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson.",
                "NEXI, now and next.",
                "In <br>inex</br> 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari.",
                "An algebra for structured queries in bayesian networks.",
                "In <br>inex</br> 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]."
            ],
            "original_annotated_samples": [
                "The test collection developed by the INitiative for the Evaluation of XML Retrieval (<br>inex</br>) forms the basis for the evaluation.",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (<br>inex</br>) has encouraged research into XML information retrieval technology [7,8].",
                "<br>inex</br> is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
                "Over 50 groups participated in <br>inex</br> 2004, and the conference has become as influential in the area of XML IR as TREC is in other IR areas.",
                "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by <br>inex</br>."
            ],
            "translated_annotated_samples": [
                "La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la <br>Recuperación XML</br> (INEX) constituye la base para la evaluación.",
                "Componentes estándar de documentos como párrafos, secciones, subsecciones y resúmenes generalmente cumplen con estos requisitos; los títulos, frases en cursiva y campos de metadatos individuales a menudo no lo hacen. 2.3 Metodología de Evaluación En los últimos tres años, la Iniciativa para la Evaluación de la Recuperación de Información XML (<br>INEX</br>) ha fomentado la investigación en tecnología de recuperación de información XML [7,8].",
                "INEX es una serie de conferencias experimentales, similar a TREC, en la que grupos de diferentes instituciones completan una o más tareas experimentales utilizando sus propias herramientas y sistemas, y comparan sus resultados en la propia conferencia.",
                "Más de 50 grupos participaron en INEX 2004, y la conferencia se ha convertido en tan influyente en el área de la <br>RI XML</br> como lo es TREC en otras áreas de la RI.",
                "La investigación descrita en este artículo, al igual que gran parte del trabajo relacionado que cita, depende de las <br>colecciones de pruebas</br> desarrolladas por INEX."
            ],
            "translated_text": "Controlando la superposición en la recuperación XML orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca RESUMEN La aplicación directa de técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos XML a menudo produce un conjunto de resultados en el que los primeros puestos están dominados por un gran número de elementos tomados de un pequeño número de documentos altamente relevantes. Este documento presenta y evalúa un algoritmo que vuelve a clasificar este conjunto de resultados, con el objetivo de minimizar el contenido redundante mientras se preservan los beneficios de la recuperación de elementos, incluido el beneficio de identificar componentes centrados en el tema contenidos en documentos relevantes. La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la <br>Recuperación XML</br> (INEX) constituye la base para la evaluación. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Búsqueda y Recuperación de Información Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. La representación de documentos en XML brinda una oportunidad para que los sistemas de recuperación de información aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias. En respuesta a una consulta de usuario, un sistema de recuperación de información XML podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes. Esta facilidad es de particular beneficio cuando una colección contiene documentos muy largos, como manuales de productos o libros, donde el usuario debe ser dirigido a las partes más relevantes de estos documentos. La Figura 1 proporciona un ejemplo de un artículo de revista codificado en XML, ilustrando muchas de las características importantes de los documentos XML. Las etiquetas indican el inicio y el final de cada elemento, con elementos que varían ampliamente en tamaño, desde una palabra hasta miles de palabras. Algunos elementos, como párrafos y secciones, pueden presentarse razonablemente al usuario como resultados de búsqueda, pero otros no son apropiados. Los elementos se superponen entre sí: los artículos contienen secciones, las secciones contienen subsecciones y las subsecciones contienen párrafos. Cada una de estas características afecta el diseño de un sistema de IR XML, y cada una conlleva problemas fundamentales que deben resolverse en un sistema exitoso. La mayoría de estos problemas fundamentales pueden resolverse mediante la cuidadosa adaptación de técnicas estándar de IR, pero los problemas causados por la superposición son únicos en esta área [4,11] y constituyen el enfoque principal de este artículo. El artículo de la figura 1 puede ser visto como un árbol XML, como se ilustra en la figura 2. Formalmente, una colección de documentos XML puede ser representada como un bosque de árboles ordenados y enraizados, que consiste en un conjunto de nodos N y un conjunto de aristas dirigidas E que conectan estos nodos. Para cada nodo x ∈ N, la notación x.parent se refiere al nodo padre de x, si existe, y la notación x.children se refiere al conjunto de nodos hijos de x. Dado que un elemento puede estar representado por el nodo en su raíz, la salida de un sistema de IR XML puede ser vista como una lista clasificada de los m nodos principales. La aplicación directa de una técnica estándar de clasificación de relevancia a un conjunto de elementos XML puede producir un resultado en el que los primeros puestos están dominados por muchos elementos estructuralmente relacionados. Una sección con una puntuación alta probablemente contenga varios párrafos con una puntuación alta y esté contenida en un artículo con una puntuación alta. Por ejemplo, muchos de los elementos en la figura 2 recibirían una puntuación alta en los algoritmos de compresión de índices de texto de consulta de palabras clave. Si cada uno de estos elementos se presenta a un usuario como un resultado individual y separado, puede perder mucho tiempo revisando y rechazando contenido redundante. Una posible solución es informar solo el elemento de mayor puntuación a lo largo de un camino dado en el árbol, y eliminar de los rangos inferiores cualquier elemento que lo contenga o esté contenido en él. Desafortunadamente, este enfoque destruye algunos de los posibles beneficios de XML IR. Por ejemplo, un elemento externo puede contener una cantidad sustancial de información que no aparece en un elemento interno, pero el elemento interno puede estar fuertemente enfocado en el tema de la consulta y proporcionar un breve resumen de los conceptos clave. En tales casos, es razonable informar sobre elementos que contienen, o están contenidos en, elementos de rango superior. Incluso cuando un libro entero es relevante, un usuario aún puede desear que se destaquen los párrafos más importantes, para guiar su lectura y ahorrar tiempo [6]. Este documento presenta un método para controlar la superposición. A partir de una clasificación inicial de elementos, un algoritmo de re-clasificación ajusta las puntuaciones de los elementos de menor clasificación que contienen, o están contenidos dentro de, elementos de mayor clasificación, reflejando el hecho de que esta información puede ser ahora redundante. Por ejemplo, una vez que un elemento que representa una sección aparece en la clasificación, las puntuaciones de los párrafos que contiene y del artículo que lo contiene se reducen. La inspiración para esta estrategia proviene parcialmente del trabajo reciente sobre la recuperación de documentos estructurados, donde los términos que aparecen en diferentes campos, como el título y el cuerpo, reciben diferentes pesos [20]. Extendiendo ese enfoque, el algoritmo de reordenamiento varía los pesos dinámicamente a medida que se procesan los elementos. El resto del documento está organizado de la siguiente manera: Después de una discusión sobre el trabajo de antecedentes y la metodología de evaluación, se presenta un método de recuperación de referencia en la sección 4. Este método de referencia representa una adaptación razonable de la tecnología estándar de IR al XML. La sección 5 luego describe una estrategia para controlar la superposición, utilizando el método de línea base como punto de partida. Un algoritmo de reordenamiento que implementa esta estrategia se presenta en la sección 6 y se evalúa en la sección 7. La sección 8 discute una versión extendida del algoritmo. 2. ANTECEDENTES Esta sección proporciona una visión general de la recuperación de información XML y discute trabajos relacionados, con énfasis en los problemas fundamentales mencionados en la introducción. Mucha investigación en el área de recuperación de XML lo ve desde una perspectiva de base de datos tradicional, preocupándose por problemas como la implementación de lenguajes de consulta estructurados [5] y el procesamiento de joins [1]. Aquí adoptamos una perspectiva de IR orientada al contenido, centrándonos en documentos XML que contienen principalmente datos en lenguaje natural y consultas que están principalmente expresadas en lenguaje natural. Suponemos que estas consultas indican únicamente la naturaleza del contenido deseado, no su estructura, y que el papel del sistema de RI es determinar qué elementos satisfacen mejor la necesidad de información subyacente. Otra investigación en IR ha considerado consultas mixtas, en las que se especifican tanto requisitos de contenido como estructurales [2,6,14,17,23]. 2.1 Estadísticas de Términos y Documentos En las aplicaciones tradicionales de recuperación de información, la unidad estándar de recuperación se considera que es el documento. Dependiendo de la aplicación, este término podría interpretarse para abarcar muchos objetos diferentes, incluyendo páginas web, artículos de periódico y mensajes de correo electrónico. Al aplicar técnicas estándar de clasificación de relevancia en el contexto de la RI XML, un enfoque natural es tratar cada elemento como un documento separado, con estadísticas de términos disponibles para cada uno [16]. Además, la mayoría de las técnicas de clasificación requieren estadísticas globales (por ejemplo, frecuencia inversa de documentos) calculadas sobre la colección en su totalidad. Si consideramos que esta colección incluye todos los elementos que podrían ser devueltos por el sistema, una ocurrencia específica de un término puede aparecer en varios documentos diferentes, quizás en elementos que representan un párrafo, una subsección, una sección y un artículo. No es apropiado calcular la frecuencia inversa de documentos bajo la suposición de que el término está contenido en todos estos elementos, ya que el número de elementos que contienen un término depende completamente del arreglo estructural de los documentos [13,23]. 2.2 Elementos Recuperables Si bien un sistema de recuperación de información XML podría potencialmente recuperar cualquier elemento, muchos elementos pueden no ser apropiados como resultados de recuperación. Esto suele ser el caso cuando los elementos contienen muy poco texto [10]. Por ejemplo, un título de sección que contenga solo los términos de búsqueda puede recibir una puntuación alta de un algoritmo de clasificación, pero por sí solo tendría un valor limitado para un usuario, quien podría preferir la sección real en sí misma. Otros elementos pueden reflejar la estructura física de los documentos, en lugar de la estructura lógica, lo cual puede tener poco o ningún significado para un usuario. Un sistema de recuperación de información XML efectivo debe devolver solo aquellos elementos que tengan suficiente contenido para ser utilizables y puedan funcionar como objetos independientes [15,18]. Componentes estándar de documentos como párrafos, secciones, subsecciones y resúmenes generalmente cumplen con estos requisitos; los títulos, frases en cursiva y campos de metadatos individuales a menudo no lo hacen. 2.3 Metodología de Evaluación En los últimos tres años, la Iniciativa para la Evaluación de la Recuperación de Información XML (<br>INEX</br>) ha fomentado la investigación en tecnología de recuperación de información XML [7,8]. INEX es una serie de conferencias experimentales, similar a TREC, en la que grupos de diferentes instituciones completan una o más tareas experimentales utilizando sus propias herramientas y sistemas, y comparan sus resultados en la propia conferencia. Más de 50 grupos participaron en INEX 2004, y la conferencia se ha convertido en tan influyente en el área de la <br>RI XML</br> como lo es TREC en otras áreas de la RI. La investigación descrita en este artículo, al igual que gran parte del trabajo relacionado que cita, depende de las <br>colecciones de pruebas</br> desarrolladas por INEX. ",
            "candidates": [],
            "error": [
                [
                    "Recuperación XML",
                    "INEX",
                    "RI XML",
                    "colecciones de pruebas"
                ]
            ]
        },
        "sog quantization": {
            "translated_key": "cuantificación sog",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Controlling Overlap in Content-Oriented XML Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of XML documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
                "This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents.",
                "The test collection developed by the INitiative for the Evaluation of XML Retrieval (INEX) forms the basis for the evaluation.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "INTRODUCTION The representation of documents in XML provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an XML information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in XML.",
                "Figure 1 provides an example of a journal article encoded in XML, illustrating many of the important characteristics of XML documents.",
                "Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words.",
                "Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate.",
                "Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs.",
                "Each of these characteristics affects the design of an XML IR system, and each leads to fundamental problems that must be solved in an successful system.",
                "Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper.",
                "The article of figure 1 may be viewed as an XML tree, as illustrated in figure 2.",
                "Formally, a collection of XML documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes.",
                "For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example XML tree. of x.",
                "Since an element may be represented by the node at its root, the output of an XML IR system may be viewed as a ranked list of the top-m nodes.",
                "The direct application of a standard relevance ranking technique to a set of XML elements can produce a result in which the top ranks are dominated by many structurally related elements.",
                "A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article.",
                "For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms.",
                "If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content.",
                "One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it.",
                "Unfortunately, this approach destroys some of the possible benefits of XML IR.",
                "For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts.",
                "In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements.",
                "Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6].",
                "This paper presents a method for controlling overlap.",
                "Starting with an initial element ranking, a re-ranking algorithm adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
                "For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced.",
                "The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20].",
                "Extending that approach, the re-ranking algorithm varies weights dynamically as elements are processed.",
                "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a baseline retrieval method is presented in section 4.",
                "This baseline method represents a reasonable adaptation of standard IR technology to XML.",
                "Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point.",
                "A re-ranking algorithm implementing this strategy is presented in section 6 and evaluated in section 7.",
                "Section 8 discusses an extended version of the algorithm. 2.",
                "BACKGROUND This section provides a general overview of XML information retrieval and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
                "Much research in the area of XML retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1].",
                "Here, we take a content oriented IR perceptive, focusing on XML documents that primarily contain natural language data and queries that are primarily expressed in natural language.",
                "We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need.",
                "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional information retrieval applications the standard unit of retrieval is taken to be the document.",
                "Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages.",
                "When applying standard relevance ranking techniques in the context of XML IR, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
                "In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole.",
                "If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article.",
                "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an XML IR system might potentially retrieve any element, many elements may not be appropriate as retrieval results.",
                "This is usually the case when elements contain very little text [10].",
                "For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself.",
                "Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user.",
                "An effective XML IR system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18].",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (INEX) has encouraged research into XML information retrieval technology [7,8].",
                "INEX is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
                "Over 50 groups participated in INEX 2004, and the conference has become as influential in the area of XML IR as TREC is in other IR areas.",
                "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by INEX.",
                "Overlap causes considerable problems with retrieval evaluation, and the INEX organizers and participants have wrestled with these problems since the beginning.",
                "While substantial progress has been made, these problem are still not completely solved.",
                "Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of INEX retrieval evaluation and discuss both current and proposed evaluation metrics.",
                "Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3.",
                "INEX 2004 Space limitations prevent the inclusion of more than a brief summary of INEX 2004 tasks and evaluation methodology.",
                "For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, INEX 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002.",
                "Each document is encoded in XML using a common DTD, with the document of figures 1 and 2 providing one example.",
                "At INEX 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics.",
                "The two tasks differed in the types of topics they used.",
                "For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection.",
                "For this task, the IR system is required to select the elements to be returned.",
                "For the other task, the contentand-structure or CAS task, the topics are written in an XML query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy.",
                "Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description.",
                "In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants.",
                "Each topic includes a short keyword query, which is executed over the collection by each participating group on their own XML IR system.",
                "Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since XML IR is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient.",
                "Instead, the INEX organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic.",
                "A four-point scale is used in both dimensions.",
                "Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant.",
                "Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at INEX 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values.",
                "One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others.",
                "This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant.",
                "Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity.",
                "Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity.",
                "This paper reports results of this metric using all three of these quantization functions.",
                "Since this metric was first introduced at INEX 2002, it is generally referred as the inex-2002 metric.",
                "The inex-2002 metric does not penalize overlap.",
                "In particular, both the generalized and <br>sog quantization</br> functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank.",
                "To address this problem, Kazai et al. [11] propose an XML cumulated gain metric, which compares the cumulated gain [9] of a ranked list to an ideal gain vector.",
                "This ideal gain vector is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path.",
                "Thus, the XCG metric rewards retrieval runs that avoid overlap.",
                "While XCG was not used officially at INEX 2004, a version of it is likely to be used in the future.",
                "At INEX 2003, yet another metric was introduced to ameliorate the perceived limitations of the inex-2002 metric.",
                "This inex-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them.",
                "Two versions were created, one that considered only component size and another that considered both size and overlap.",
                "While the inex-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4.",
                "BASELINE RETRIEVAL METHOD This section provides an overview of baseline XML information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3].",
                "This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the XML information retrieval task.",
                "The MultiText system performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
                "To support retrieval from XML and other structured document types, the system provides generalized queries of the form: rank X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms.",
                "For our INEX 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections.",
                "Prior to INEX 2004, the INEX collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names.",
                "Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received.",
                "Automating this selection process is planned as future work.",
                "For INEX 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.",
                "For example, keyword field of topic 166 +tree edit distance + XML -image became the four-term query $tree $edit $distance $xml where the $ operator within a quoted string stems the term that follows it.",
                "Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞.",
                "Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(inex-2002) k1 strict generalized sog Figure 3: Impact of k1 on inex-2002 mean average precision with b = 0.75 (INEX 2003 CO topics).",
                "Prior to INEX 2004, the INEX 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.",
                "For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article.",
                "These statistics are used for ranking all element types.",
                "Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length.",
                "The use of article statistics for all element types might be questioned.",
                "This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.",
                "The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics.",
                "Nonetheless, we plan to examine this issue again in the future.",
                "In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose.",
                "Prior to INEX 2004, we trained the MultiText system using the INEX 2003 queries.",
                "As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system.",
                "The results were surprising.",
                "Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions.",
                "In our experience, optimal values for k1 are typically in the range 0.0 to 2.0.",
                "In this case, large values are required for good performance.",
                "Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization.",
                "Similar improvements are seen under the generalized and sog quantizations.",
                "In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).",
                "After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our INEX 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5.",
                "CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements.",
                "At a conceptual level, re-ranking proceeds as follows: 1.",
                "Report the highest ranking element. 2.",
                "Adjust the scores of the unreported elements. 3.",
                "Repeat steps 1 and 2 until m elements are reported.",
                "One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements.",
                "For example, assume a paragraph with score p is reported in step 1.",
                "In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score.",
                "In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion.",
                "That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages.",
                "A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two.",
                "Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness.",
                "Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body.",
                "In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body.",
                "Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported.",
                "The next section presents and analysis a simple re-ranking algorithm that follows this strategy.",
                "The algorithm is evaluated experimentally in section 7.",
                "One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears.",
                "In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6.",
                "RE-RANKING ALGORITHM The re-ranking algorithm operates over XML trees, such as the one appearing in figure 2.",
                "Input to the algorithm is a list of n elements ranked according to their initial BM25 scores.",
                "During the initial ranking the XML tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |.",
                "Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores.",
                "An element is represented by the node x ∈ N at its root.",
                "Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - term frequency vector x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses.",
                "The vector x.f contains term frequency information corresponding to each term in the query.",
                "The vector x.g is initially zero and is updated by the algorithm as elements are reported.",
                "The score field contains the current BM25 score for the element, which will change as the values in x.g change.",
                "The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g.",
                "Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the re-ranking algorithm, nodes are stored in priority queues, ordered by decreasing score.",
                "Each priority queue PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
                "The core of the re-ranking algorithm is presented in figure 5.",
                "The algorithm takes as input the priority queue S containing the initial ranking, and produces the top-m reranked nodes in the priority queue F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
                "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a priority queue S, containing XML nodes ranked by their initial scores, and returns its results in priority queue F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
                "The tree traversal routines, Up and Down are given in figure 6.",
                "The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2.",
                "The Down routine performs a similar operation on each descendant.",
                "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the time complexity of the algorithm, first note that a node may be an argument to Down at most once.",
                "Thereafter, the reported flag of its parent is true.",
                "During each call to Down a node may be moved from S to F, requiring O(log n) time.",
                "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the time complexity of the loop over lines 2-15.",
                "During each iteration of this loop, a node and each of its ancestors are removed from a priority queue and then added back into a priority queue.",
                "Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time.",
                "Combining these observations produces an overall time complexity of O((n + mh) log n).",
                "In practice, re-ranking an INEX result set requires less than 200ms on a three-year-old desktop PC. 7.",
                "EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper.",
                "Nonetheless, when taken together they provide insight into the behaviour of the re-ranking algorithm.",
                "The INEX evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the inex-2002 and inex-2003 metrics.",
                "Values for the XCG metrics were computed using software supplied by its inventors [11].",
                "Figure 7 plots the three variants of inex-2002 MAP metric together with the XCG metric.",
                "Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on inex-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0.",
                "Recalling that the XCG metric is designed to penalize overlap, while the inex-2002 metric ignores overlap, the conflict between the metrics is obvious.",
                "The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at INEX 2004 [8,12].",
                "Figure 8 plots values of the inex-2003 MAP metric for two quantizations, with and without consideration of overlap.",
                "Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8.",
                "EXTENDED ALGORITHM One limitation of the re-ranking algorithm is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements.",
                "An obvious extension is to use different weights in these two cases.",
                "Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element.",
                "For example, a paragraph may form part of a reported section and then form part of a reported article.",
                "Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight.",
                "Motivated by these observations, the re-ranking algorithm may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times.",
                "Note that an upper bound on M is h, the maximum height of any XML tree in the collection.",
                "However, in practice M is likely to be relatively small (perhaps 3 or 4).",
                "Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights.",
                "One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument.",
                "When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down.",
                "The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors.",
                "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall time complexity of O((nM + mh) log n).",
                "Since M ≤ h and m ≤ n, the time complexity is also O(nh log n). 9.",
                "CONCLUDING DISCUSSION When generating retrieval results over an XML collection, some overlap in the results should be tolerated, and may be beneficial.",
                "For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship.",
                "The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance.",
                "Other approaches may also help to control overlap.",
                "For example, when XML retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them.",
                "While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster.",
                "At Waterloo, we continue to develop and test our ideas for INEX 2005.",
                "In particular, we are investigating methods for learning the α and βj weights.",
                "We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10.",
                "ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation.",
                "In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11.",
                "REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava.",
                "Holistic twig joins: Optimal XML pattern matching.",
                "In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
                "Mass, and A. Soffer.",
                "Searching XML documents via XML fragments.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker.",
                "MultiText experiments for INEX 2004.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas.",
                "Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit.",
                "In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu.",
                "A comprehensive XQuery to SQL translation using dynamic interval encoding.",
                "In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann.",
                "XIRQL: A query language for information retrieval in XML documents.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Second Workshop (INEX 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Third Workshop (INEX 2004), Dagstuhl, Germany, December 2004.",
                "Published as Advances in XML Information Retrieval, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson.",
                "Length normalization in XML retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "The overlap problem in content-oriented XML retrieval evaluation.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "Reliability tests for the XCG and inex-2002 metrics.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto.",
                "TRIX 2004 - Struggling with the overlap.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu.",
                "Configurable indexing and ranking for XML information retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 88-95, Sheffield, UK, July 2004. [15] Y.",
                "Mass and M. Mandelbrod.",
                "Retrieving the most relevant XML components.",
                "In INEX 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y.",
                "Mass and M. Mandelbrod.",
                "Component ranking and automatic query refinement for XML retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan.",
                "Hierarchical language models for XML component retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [18] J. Pehcevski, J.",
                "A. Thom, and A. Vercoustre.",
                "Hybrid XML retrieval re-visited.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas.",
                "Providing consistent and exhaustive relevance assessments for XML retrieval evaluation.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor.",
                "Simple BM25 extension to multiple weighted fields.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu.",
                "Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track.",
                "In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson.",
                "NEXI, now and next.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari.",
                "An algebra for structured queries in bayesian networks.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]."
            ],
            "original_annotated_samples": [
                "In particular, both the generalized and <br>sog quantization</br> functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank."
            ],
            "translated_annotated_samples": [
                "En particular, tanto las funciones de cuantificación generalizadas como las de sog otorgan crédito parcial a un casi acierto incluso cuando se informa un elemento (3,3) que se superpone a él en un rango más alto."
            ],
            "translated_text": "Controlando la superposición en la recuperación XML orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca RESUMEN La aplicación directa de técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos XML a menudo produce un conjunto de resultados en el que los primeros puestos están dominados por un gran número de elementos tomados de un pequeño número de documentos altamente relevantes. Este documento presenta y evalúa un algoritmo que vuelve a clasificar este conjunto de resultados, con el objetivo de minimizar el contenido redundante mientras se preservan los beneficios de la recuperación de elementos, incluido el beneficio de identificar componentes centrados en el tema contenidos en documentos relevantes. La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la Recuperación XML (INEX) constituye la base para la evaluación. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Búsqueda y Recuperación de Información Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. La representación de documentos en XML brinda una oportunidad para que los sistemas de recuperación de información aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias. En respuesta a una consulta de usuario, un sistema de recuperación de información XML podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes. Esta facilidad es de particular beneficio cuando una colección contiene documentos muy largos, como manuales de productos o libros, donde el usuario debe ser dirigido a las partes más relevantes de estos documentos. La Figura 1 proporciona un ejemplo de un artículo de revista codificado en XML, ilustrando muchas de las características importantes de los documentos XML. Las etiquetas indican el inicio y el final de cada elemento, con elementos que varían ampliamente en tamaño, desde una palabra hasta miles de palabras. Algunos elementos, como párrafos y secciones, pueden presentarse razonablemente al usuario como resultados de búsqueda, pero otros no son apropiados. Los elementos se superponen entre sí: los artículos contienen secciones, las secciones contienen subsecciones y las subsecciones contienen párrafos. Cada una de estas características afecta el diseño de un sistema de IR XML, y cada una conlleva problemas fundamentales que deben resolverse en un sistema exitoso. La mayoría de estos problemas fundamentales pueden resolverse mediante la cuidadosa adaptación de técnicas estándar de IR, pero los problemas causados por la superposición son únicos en esta área [4,11] y constituyen el enfoque principal de este artículo. El artículo de la figura 1 puede ser visto como un árbol XML, como se ilustra en la figura 2. Formalmente, una colección de documentos XML puede ser representada como un bosque de árboles ordenados y enraizados, que consiste en un conjunto de nodos N y un conjunto de aristas dirigidas E que conectan estos nodos. Para cada nodo x ∈ N, la notación x.parent se refiere al nodo padre de x, si existe, y la notación x.children se refiere al conjunto de nodos hijos de x. Dado que un elemento puede estar representado por el nodo en su raíz, la salida de un sistema de IR XML puede ser vista como una lista clasificada de los m nodos principales. La aplicación directa de una técnica estándar de clasificación de relevancia a un conjunto de elementos XML puede producir un resultado en el que los primeros puestos están dominados por muchos elementos estructuralmente relacionados. Una sección con una puntuación alta probablemente contenga varios párrafos con una puntuación alta y esté contenida en un artículo con una puntuación alta. Por ejemplo, muchos de los elementos en la figura 2 recibirían una puntuación alta en los algoritmos de compresión de índices de texto de consulta de palabras clave. Si cada uno de estos elementos se presenta a un usuario como un resultado individual y separado, puede perder mucho tiempo revisando y rechazando contenido redundante. Una posible solución es informar solo el elemento de mayor puntuación a lo largo de un camino dado en el árbol, y eliminar de los rangos inferiores cualquier elemento que lo contenga o esté contenido en él. Desafortunadamente, este enfoque destruye algunos de los posibles beneficios de XML IR. Por ejemplo, un elemento externo puede contener una cantidad sustancial de información que no aparece en un elemento interno, pero el elemento interno puede estar fuertemente enfocado en el tema de la consulta y proporcionar un breve resumen de los conceptos clave. En tales casos, es razonable informar sobre elementos que contienen, o están contenidos en, elementos de rango superior. Incluso cuando un libro entero es relevante, un usuario aún puede desear que se destaquen los párrafos más importantes, para guiar su lectura y ahorrar tiempo [6]. Este documento presenta un método para controlar la superposición. A partir de una clasificación inicial de elementos, un algoritmo de re-clasificación ajusta las puntuaciones de los elementos de menor clasificación que contienen, o están contenidos dentro de, elementos de mayor clasificación, reflejando el hecho de que esta información puede ser ahora redundante. Por ejemplo, una vez que un elemento que representa una sección aparece en la clasificación, las puntuaciones de los párrafos que contiene y del artículo que lo contiene se reducen. La inspiración para esta estrategia proviene parcialmente del trabajo reciente sobre la recuperación de documentos estructurados, donde los términos que aparecen en diferentes campos, como el título y el cuerpo, reciben diferentes pesos [20]. Extendiendo ese enfoque, el algoritmo de reordenamiento varía los pesos dinámicamente a medida que se procesan los elementos. El resto del documento está organizado de la siguiente manera: Después de una discusión sobre el trabajo de antecedentes y la metodología de evaluación, se presenta un método de recuperación de referencia en la sección 4. Este método de referencia representa una adaptación razonable de la tecnología estándar de IR al XML. La sección 5 luego describe una estrategia para controlar la superposición, utilizando el método de línea base como punto de partida. Un algoritmo de reordenamiento que implementa esta estrategia se presenta en la sección 6 y se evalúa en la sección 7. La sección 8 discute una versión extendida del algoritmo. 2. ANTECEDENTES Esta sección proporciona una visión general de la recuperación de información XML y discute trabajos relacionados, con énfasis en los problemas fundamentales mencionados en la introducción. Mucha investigación en el área de recuperación de XML lo ve desde una perspectiva de base de datos tradicional, preocupándose por problemas como la implementación de lenguajes de consulta estructurados [5] y el procesamiento de joins [1]. Aquí adoptamos una perspectiva de IR orientada al contenido, centrándonos en documentos XML que contienen principalmente datos en lenguaje natural y consultas que están principalmente expresadas en lenguaje natural. Suponemos que estas consultas indican únicamente la naturaleza del contenido deseado, no su estructura, y que el papel del sistema de RI es determinar qué elementos satisfacen mejor la necesidad de información subyacente. Otra investigación en IR ha considerado consultas mixtas, en las que se especifican tanto requisitos de contenido como estructurales [2,6,14,17,23]. 2.1 Estadísticas de Términos y Documentos En las aplicaciones tradicionales de recuperación de información, la unidad estándar de recuperación se considera que es el documento. Dependiendo de la aplicación, este término podría interpretarse para abarcar muchos objetos diferentes, incluyendo páginas web, artículos de periódico y mensajes de correo electrónico. Al aplicar técnicas estándar de clasificación de relevancia en el contexto de la RI XML, un enfoque natural es tratar cada elemento como un documento separado, con estadísticas de términos disponibles para cada uno [16]. Además, la mayoría de las técnicas de clasificación requieren estadísticas globales (por ejemplo, frecuencia inversa de documentos) calculadas sobre la colección en su totalidad. Si consideramos que esta colección incluye todos los elementos que podrían ser devueltos por el sistema, una ocurrencia específica de un término puede aparecer en varios documentos diferentes, quizás en elementos que representan un párrafo, una subsección, una sección y un artículo. No es apropiado calcular la frecuencia inversa de documentos bajo la suposición de que el término está contenido en todos estos elementos, ya que el número de elementos que contienen un término depende completamente del arreglo estructural de los documentos [13,23]. 2.2 Elementos Recuperables Si bien un sistema de recuperación de información XML podría potencialmente recuperar cualquier elemento, muchos elementos pueden no ser apropiados como resultados de recuperación. Esto suele ser el caso cuando los elementos contienen muy poco texto [10]. Por ejemplo, un título de sección que contenga solo los términos de búsqueda puede recibir una puntuación alta de un algoritmo de clasificación, pero por sí solo tendría un valor limitado para un usuario, quien podría preferir la sección real en sí misma. Otros elementos pueden reflejar la estructura física de los documentos, en lugar de la estructura lógica, lo cual puede tener poco o ningún significado para un usuario. Un sistema de recuperación de información XML efectivo debe devolver solo aquellos elementos que tengan suficiente contenido para ser utilizables y puedan funcionar como objetos independientes [15,18]. Componentes estándar de documentos como párrafos, secciones, subsecciones y resúmenes generalmente cumplen con estos requisitos; los títulos, frases en cursiva y campos de metadatos individuales a menudo no lo hacen. 2.3 Metodología de Evaluación En los últimos tres años, la Iniciativa para la Evaluación de la Recuperación de Información XML (INEX) ha fomentado la investigación en tecnología de recuperación de información XML [7,8]. INEX es una serie de conferencias experimentales, similar a TREC, en la que grupos de diferentes instituciones completan una o más tareas experimentales utilizando sus propias herramientas y sistemas, y comparan sus resultados en la propia conferencia. Más de 50 grupos participaron en INEX 2004, y la conferencia se ha convertido en tan influyente en el área de la RI XML como lo es TREC en otras áreas de la RI. La investigación descrita en este artículo, al igual que gran parte del trabajo relacionado que cita, depende de las colecciones de pruebas desarrolladas por INEX. La superposición causa problemas considerables en la evaluación de la recuperación, y los organizadores y participantes de INEX han luchado con estos problemas desde el principio. Aunque se ha logrado un progreso sustancial, estos problemas aún no están completamente resueltos. Kazai et al. [11] proporcionan una exposición detallada del problema de superposición en el contexto de la evaluación de recuperación de INEX y discuten tanto las métricas de evaluación actuales como las propuestas. Muchas de estas métricas se aplican para evaluar los experimentos reportados en este artículo, y se describen brevemente en la siguiente sección. 3. Las limitaciones de espacio impiden incluir más que un breve resumen de las tareas y metodología de evaluación de INEX 2004. Para obtener información detallada, se deben consultar las actas de la conferencia en sí [8]. 3.1 Tareas Para las principales tareas experimentales, a los participantes de INEX 2004 se les proporcionó una colección de 12,107 artículos tomados de las revistas y publicaciones de la IEEE Computer Societies entre 1995 y 2002. Cada documento está codificado en XML utilizando una DTD común, siendo el documento de las figuras 1 y 2 un ejemplo. En INEX 2004, las dos principales tareas experimentales fueron ambas tareas de recuperación ad hoc, investigando el rendimiento de sistemas que buscan en una colección estática utilizando temas previamente no vistos. Las dos tareas diferían en los tipos de temas que utilizaban. Para una tarea, la tarea de solo contenido o CO, los temas consisten en declaraciones cortas en lenguaje natural sin hacer referencia directa a la estructura de los documentos en la colección. Para esta tarea, se requiere que el sistema de IR seleccione los elementos a devolver. Para la otra tarea, la tarea de contenido y estructura o CAS, los temas están escritos en un lenguaje de consulta XML [22] y contienen referencias explícitas a la estructura del documento, que el sistema de IR debe intentar satisfacer. Dado que el trabajo descrito en este documento se enfoca en la tarea de solo contenido, donde el sistema de IR no recibe orientación sobre los elementos a devolver, la tarea de CAS se ignora en el resto de nuestra descripción. En 2004, los organizadores de la conferencia seleccionaron 40 nuevos temas de CO de las contribuciones proporcionadas por los participantes de la conferencia. Cada tema incluye una breve consulta de palabras clave, la cual es ejecutada sobre la colección por cada grupo participante en su propio sistema de IR XML. Cada grupo podría presentar hasta tres ejecuciones experimentales que consistieran en los primeros m = 1500 elementos para cada tema. 3.2 Evaluación de Relevancia Dado que la RI XML se preocupa por localizar aquellos elementos que proporcionan una cobertura completa de un tema mientras contienen la menor cantidad de información irrelevante posible, los juicios simples de relevante vs. no relevante no son suficientes. En cambio, los organizadores de INEX adoptaron dos dimensiones para la evaluación de relevancia: la dimensión de exhaustividad refleja el grado en que un elemento abarca el tema, y la dimensión de especificidad refleja el grado en que un elemento se enfoca en el tema. Se utiliza una escala de cuatro puntos en ambas dimensiones. Por lo tanto, un elemento (3,3) es altamente exhaustivo y altamente específico, un elemento (1,3) es marginalmente exhaustivo y altamente específico, y un elemento (0,0) no es relevante. Información adicional sobre la metodología de evaluación se puede encontrar en Piwowarski y Lalmas [19], quienes proporcionan una justificación detallada. 3.3 Métricas de Evaluación La métrica de evaluación principal utilizada en INEX 2004 es una versión de la precisión promedio media (MAP), ajustada por diversas funciones de cuantificación para dar diferentes pesos a diferentes elementos, dependiendo de sus valores de exhaustividad y especificidad. Una variante, la función de cuantización estricta asigna un peso de 1 a los elementos (3,3) y un peso de 0 a todos los demás. Esta variante es esencialmente el valor MAP familiar, con elementos (3,3) tratados como relevantes y todos los demás elementos tratados como no relevantes. Otras funciones de cuantización están diseñadas para otorgar crédito parcial a elementos que son aproximaciones cercanas, debido a la falta de exhaustividad y/o especificidad. Tanto la función de cuantificación generalizada como la función de generalización orientada a la especificidad (sog) acreditan elementos según su grado de relevancia [11], siendo que la segunda función pone mayor énfasis en la especificidad. Este documento informa los resultados de esta métrica utilizando las tres funciones de cuantización. Desde que esta métrica fue introducida por primera vez en INEX 2002, generalmente se le conoce como la métrica inex-2002. La métrica inex-2002 no penaliza la superposición. En particular, tanto las funciones de cuantificación generalizadas como las de sog otorgan crédito parcial a un casi acierto incluso cuando se informa un elemento (3,3) que se superpone a él en un rango más alto. Para abordar este problema, Kazai et al. [11] proponen una métrica de ganancia acumulada XML, que compara la ganancia acumulada [9] de una lista clasificada con un vector de ganancia ideal. Este vector de ganancia ideal se construye a partir de las valoraciones de relevancia al eliminar la superposición y retener solo el mejor elemento a lo largo de un camino dado. Por lo tanto, la métrica XCG recompensa las ejecuciones de recuperación que evitan la superposición. Aunque XCG no se utilizó oficialmente en INEX 2004, es probable que se utilice una versión de él en el futuro. En INEX 2003, se introdujo otra métrica para mejorar las limitaciones percibidas de la métrica inex-2002. Este métrico inex-2003 extiende las definiciones de precisión y exhaustividad para considerar tanto el tamaño de los componentes informados como la superposición entre ellos. Se crearon dos versiones, una que consideraba solo el tamaño de los componentes y otra que consideraba tanto el tamaño como la superposición. Si bien la métrica inex-2003 presenta anomalías no deseadas [11] y no se utilizó en 2004, se informan valores en la sección de evaluación para proporcionar un instrumento adicional para investigar la superposición. 4. MÉTODO DE RECUPERACIÓN DE BASELINE Esta sección proporciona una descripción general del método de recuperación de información XML de base actualmente utilizado en el sistema MultiText IR, desarrollado por el Grupo de Recuperación de Información de la Universidad de Waterloo [3]. Este método de recuperación resulta de la adaptación y ajuste de la medida Okapi BM25 [21] a la tarea de recuperación de información en XML. El sistema MultiText tuvo un desempeño respetable en INEX 2004, ubicándose entre los diez primeros en todas las funciones de cuantización, y ocupando el primer lugar cuando la función de cuantización enfatizaba la exhaustividad. Para admitir la recuperación de XML y otros tipos de documentos estructurados, el sistema proporciona consultas generalizadas de la forma: clasificar X por Y donde X es una subconsulta que especifica un conjunto de elementos de documentos a clasificar y Y es un vector de subconsultas que especifican términos de recuperación individuales. Para nuestras ejecuciones de INEX 2004, la subconsulta X especificó una lista de elementos recuperables como aquellos con nombres de etiquetas de la siguiente manera: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt. Esta lista incluye entradas bibliográficas (bb) y leyendas de figuras (fig) así como párrafos, secciones y subsecciones. Antes de INEX 2004, la colección de INEX y las evaluaciones de relevancia de INEX 2003 fueron analizadas manualmente para seleccionar estos nombres de etiquetas. Los nombres de las etiquetas fueron seleccionados en base a su frecuencia en la colección, el tamaño promedio de sus elementos asociados y el número relativo de juicios de relevancia positiva que recibieron. Automatizar este proceso de selección está planeado como trabajo futuro. Para INEX 2004, el vector término Y se derivó del tema dividiendo frases en palabras individuales, eliminando palabras vacías y términos negativos (aquellos que comienzan con -), y aplicando un stemmer. Por ejemplo, el campo de palabra clave del tema 166 +distancia de edición de árbol + XML -imagen se convirtió en la consulta de cuatro términos $árbol $edición $distancia $xml donde el operador $ dentro de una cadena entre comillas deriva el término que le sigue. Nuestra implementación de Okapi BM25 se deriva de la fórmula de Robertson et al. [21] al establecer los parámetros k2 = 0 y k3 = ∞. Dado un conjunto de términos Q, a un elemento x se le asigna la puntuación t∈Q w(1) qt (k1 + 1)xt K + xt (1) donde w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = número de documentos en el corpus Dt = número de documentos que contienen t qt = frecuencia con la que t ocurre en el tema xt = frecuencia con la que t ocurre en x K = k1((1 − b) + b · lx/lavg) lx = longitud de x lavg = longitud promedio del documento 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 PrecisiónPromedio(inex-2002) k1 estricto generalizado sog Figura 3: Impacto de k1 en la precisión promedio de inex-2002 con b = 0.75 (temas CO de INEX 2003). Antes de INEX 2004, los temas y juicios de INEX 2003 se utilizaron para ajustar los parámetros b y k1, y el impacto de este ajuste se discute más adelante en esta sección. Para los propósitos de calcular estadísticas a nivel de documento (D, Dt y lavg), un documento se define como un artículo. Estas estadísticas se utilizan para clasificar todos los tipos de elementos. Siguiendo la sugerencia de Kamps et al. [10], los resultados de recuperación se filtran para eliminar elementos muy cortos, aquellos con menos de 25 palabras de longitud. El uso de estadísticas de artículos para todos los tipos de elementos podría ser cuestionado. Este enfoque puede justificarse al considerar la colección como un conjunto de artículos que se pueden buscar utilizando técnicas estándar orientadas a documentos, donde solo se devuelven artículos. El puntaje calculado para un elemento es esencialmente el puntaje que recibiría si se agregara a la colección como un nuevo documento, ignorando los ajustes menores necesarios para las estadísticas a nivel de documento. Sin embargo, planeamos examinar este tema nuevamente en el futuro. En nuestra experiencia, el rendimiento de BM25 suele beneficiarse al ajustar los parámetros b y k1 a la colección, siempre que haya consultas de entrenamiento disponibles con este propósito. Antes de INEX 2004, entrenamos el sistema MultiText utilizando las consultas de INEX 2003. Como punto de partida, utilizamos los valores b = 0.75 y k1 = 1.2, que funcionan bien en colecciones TREC adhoc y se utilizan como valores predeterminados en nuestro sistema. Los resultados fueron sorprendentes. La Figura 3 muestra el resultado de variar k1 con b = 0.75 en los valores de MAP bajo tres funciones de cuantización. En nuestra experiencia, los valores óptimos para k1 suelen estar en el rango de 0.0 a 2.0. En este caso, se requieren valores grandes para un buen rendimiento. Entre k1 = 1.0 y k1 = 6.0, el MAP aumenta en más del 15% bajo la cuantización estricta. Se observan mejoras similares bajo las cuantizaciones generalizada y SOG. Por el contrario, nuestro valor predeterminado de b = 0.75 funciona bien bajo todas las funciones de cuantificación (figura 4). Después de ajustar una amplia gama de valores bajo varias funciones de cuantización, seleccionamos los valores de k = 10.0 y b = 0.80 para nuestros experimentos de INEX 2004, y estos valores se utilizan para los experimentos reportados en la sección 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 PrecisiónPromedioMedia (inex-2002) b estricto generalizado sog Figura 4: Impacto de b en la precisión promedio media de inex-2002 con k1 = 10 (temas CO de INEX 2003). 5. CONTROL DE SUPERPOSICIÓN Comenzando con una clasificación de elementos generada por el método de referencia descrito en la sección anterior, los elementos se vuelven a clasificar para controlar la superposición ajustando de forma iterativa las puntuaciones de aquellos elementos que contienen o están contenidos en elementos de clasificación más alta. A nivel conceptual, la reorganización procede de la siguiente manera: 1. Informe el elemento de rango más alto. Ajustar las puntuaciones de los elementos no reportados. 3. Repetir los pasos 1 y 2 hasta que se informen m elementos. Un enfoque para ajustar las puntuaciones de los elementos no informados en el paso 2 podría basarse en las puntuaciones Okapi BM25 de los elementos involucrados. Por ejemplo, supongamos que se informa un párrafo con una puntuación p en el paso 1. En el paso 2, la sección que contiene el párrafo podría tener su puntuación s reducida en una cantidad α · p para reflejar la contribución reducida que el párrafo debería hacer a la puntuación de las secciones. En un contexto relacionado, Robertson et al. [20] argumentan en contra de la combinación lineal de las puntuaciones de Okapi de esta manera. Ese trabajo considera el problema de asignar diferentes pesos a diferentes campos de documentos, como el título y el cuerpo asociados con páginas web. Un enfoque común para este problema puntúa el título y el cuerpo por separado y genera una puntuación final como una combinación lineal de ambos. Robertson et al. discuten las deficiencias teóricas en este enfoque y demuestran experimentalmente que puede perjudicar realmente la efectividad de la recuperación. En cambio, aplican los pesos a nivel de frecuencia de términos, donde la aparición de un término de consulta t en el título contribuye más al puntaje que una aparición en el cuerpo. En la ecuación 1, xt se convierte en α0 · yt + α1 · zt, donde yt es el número de veces que t aparece en el título y zt es el número de veces que t aparece en el cuerpo. Al traducir este enfoque a nuestro contexto, la contribución de los términos que aparecen en los elementos se reduce dinámicamente a medida que se informan. La siguiente sección presenta y analiza un algoritmo de reordenamiento simple que sigue esta estrategia. El algoritmo se evalúa experimentalmente en la sección 7. Una limitación del algoritmo es que la contribución de los términos que aparecen en los elementos informados se reduce por el mismo factor independientemente del número de elementos informados en los que aparezca. En la sección 8, el algoritmo se extiende para aplicar pesos crecientes, disminuyendo la puntuación, cuando un término aparece en más de un elemento informado. 6. ALGORITMO DE REORDENAMIENTO El algoritmo de reordenamiento opera sobre árboles XML, como el que aparece en la figura 2. La entrada al algoritmo es una lista de n elementos clasificados según sus puntuaciones iniciales de BM25. Durante la clasificación inicial, el árbol XML se reconstruye dinámicamente para incluir solo aquellos nodos con puntuaciones BM25 distintas de cero, por lo que n puede ser considerablemente menor que |N|. La salida del algoritmo es una lista de los primeros m elementos, clasificados según sus puntajes ajustados. Un elemento está representado por el nodo x ∈ N en su raíz. Asociados con este nodo se encuentran campos que almacenan la longitud del elemento, las frecuencias de términos y otra información requerida por el algoritmo de re-ranking, de la siguiente manera: x.f - vector de frecuencia de términos x.g - ajustes de frecuencia de términos x.l - longitud del elemento x.score - puntaje actual de Okapi BM25 x.reported - bandera booleana, inicialmente falsa x.children - conjunto de nodos hijos x.parent - nodo padre, si existe Estos campos se llenan durante el proceso de clasificación inicial y se actualizan a medida que avanza el algoritmo. El vector x.f contiene información de frecuencia de términos correspondiente a cada término en la consulta. El vector x.g es inicialmente cero y se actualiza por el algoritmo a medida que se informan elementos. El campo de puntuación contiene la puntuación BM25 actual para el elemento, la cual cambiará a medida que cambien los valores en x.g. El puntaje se calcula utilizando la ecuación 1, con el valor xt para cada término determinado por una combinación de los valores en x.f y x.g. Dado un término t ∈ Q, sea ft el componente de x.f correspondiente a t, y sea gt el componente de x.g correspondiente a t, entonces: xt = ft − α · gt (2) Para el procesamiento por el algoritmo de reordenamiento, los nodos se almacenan en colas de prioridad, ordenadas por puntaje decreciente. Cada cola de prioridad PQ admite tres operaciones: PQ.front() - devuelve el nodo con la puntuación más alta, PQ.add(x) - agrega el nodo x a la cola, PQ.remove(x) - elimina el nodo x de la cola. Cuando se implementan utilizando estructuras de datos estándar, la operación front requiere tiempo O(1), y las otras operaciones requieren tiempo O(log n), donde n es el tamaño de la cola. El núcleo del algoritmo de reordenamiento se presenta en la figura 5. El algoritmo toma como entrada la cola de prioridad S que contiene la clasificación inicial, y produce los primeros m nodos reordenados en la cola de prioridad F. Después de inicializar F como vacío en la línea 1, el algoritmo recorre m veces las líneas 215, transfiriendo al menos un nodo de S a F durante cada iteración. Al inicio de cada iteración, el nodo no reportado al frente de S tiene el mayor puntaje ajustado, y se elimina y se agrega a F. El algoritmo luego recorre el 1 F ← ∅ 2 para i ← 1 a m hacer 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 para cada y ∈ x.children hacer 9 Abajo (y) 10 fin hacer 11 12 si x no es un nodo raíz entonces 13 Arriba (x, x.parent) 14 fin si 15 fin hacer Figura 5: Algoritmo de Re-Ranking - Como entrada, el algoritmo toma una cola de prioridad S, que contiene nodos XML clasificados por sus puntajes iniciales, y devuelve sus resultados en la cola de prioridad F, clasificados por puntajes ajustados. 1 Arriba(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recalcular y.score 5 S.add(y) 6 si y no es un nodo raíz entonces 7 Arriba (x, y.parent) 8 fin si 9 10 Abajo(x) ≡ 11 si no x.reported entonces 12 S.remove(x) 14 x.g ← x.f 15 recalcular x.score 16 si x.score > 0 entonces 17 F.add(x) 18 fin si 19 x.reported ← true 20 para cada y ∈ x.children hacer 21 Abajo (y) 22 fin hacer 23 fin si Figura 6: Rutinas de recorrido de árbol llamadas por el algoritmo de re-ranking. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 PrecisiónPromedioMedia (inex-2002) GananciaAcumuladaXML(XCG) alfa MAP (estricto) MAP (generalizado) MAP (sog) XCG (sog2) Figura 7: Impacto de α en XCG y MAP inex-2002 (temas CO de INEX 2004; conjunto de evaluación I). nodos ancestros (líneas 8-10) y descendientes (líneas 12-14) ajustando los puntajes de estos nodos. Las rutinas de recorrido de árboles, Arriba y Abajo, se muestran en la figura 6. El procedimiento Up elimina cada nodo ancestro de S, ajusta sus valores de frecuencia de término, recalcula su puntuación y lo vuelve a agregar a S. El ajuste de los valores de frecuencia de término (línea 3) agrega a y.g solo las ocurrencias de términos no reportadas previamente en x. El recalculo de la puntuación en la línea 4 utiliza las ecuaciones 1 y 2. La rutina Down realiza una operación similar en cada descendiente. Sin embargo, dado que el contenido de cada descendiente está completamente contenido en un elemento informado, su puntuación final puede ser calculada, y se elimina de S y se agrega a F. Para determinar la complejidad temporal del algoritmo, primero observe que un nodo puede ser un argumento de Down como máximo una vez. Posteriormente, la bandera reportada de su padre es verdadera. Durante cada llamada a Down, un nodo puede ser movido de S a F, lo que requiere un tiempo O(log n). Por lo tanto, el tiempo total para todas las llamadas a Down es O(n log n), y podemos ignorar temporalmente las líneas 8-10 de la figura 5 al considerar la complejidad temporal del bucle sobre las líneas 2-15. Durante cada iteración de este bucle, se elimina un nodo y cada uno de sus ancestros de una cola de prioridad y luego se vuelven a agregar a la cola de prioridad. Dado que un nodo puede tener como máximo h ancestros, donde h es la altura máxima de cualquier árbol en la colección, cada una de las m iteraciones requiere un tiempo de O(h log n). La combinación de estas observaciones produce una complejidad temporal general de O((n + mh) log n). En la práctica, volver a clasificar un conjunto de resultados de INEX requiere menos de 200 ms en una PC de escritorio de tres años de antigüedad. EVALUACIÓN Ninguna de las métricas descritas en la sección 3.3 se ajusta adecuadamente a la perspectiva de superposición defendida por este documento. Sin embargo, cuando se toman en conjunto, proporcionan información sobre el comportamiento del algoritmo de reordenamiento. Los paquetes de evaluación de INEX (inex_eval e inex_eval_ng) se utilizaron para calcular los valores de las métricas inex-2002 e inex-2003. Los valores de las métricas XCG fueron calculados utilizando el software proporcionado por sus inventores [11]. La Figura 7 representa juntas las tres variantes de la métrica MAP inex-2002 junto con la métrica XCG. Los valores para estas métricas 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Precisión Media Promedio (inex-2003) alfa estricto, superposición no considerada estricto, superposición considerada generalizado, superposición no considerada generalizado, superposición considerada Figura 8: Impacto de α en MAP inex-2003 (temas CO de INEX 2004; conjunto de evaluación I). se trazan para valores de α entre 0.0 y 1.0. Recordando que la métrica XCG está diseñada para penalizar la superposición, mientras que la métrica inex-2002 ignora la superposición, el conflicto entre las métricas es evidente. Los valores de MAP en un extremo (α = 0.0) y el valor de XCG en el otro extremo (α = 1.0) representan un rendimiento de recuperación comparable a los mejores sistemas en INEX 2004 [8,12]. La Figura 8 muestra los valores de la métrica MAP inex-2003 para dos cuantificaciones, con y sin consideración de la superposición. Una vez más, el conflicto es evidente, con la influencia de α considerablemente disminuida cuando se considera la superposición. 8. ALGORITMO EXTENDIDO Una limitación del algoritmo de reordenamiento es que se utiliza un único peso α para ajustar las puntuaciones tanto de los ancestros como de los descendientes de los elementos informados. Una extensión obvia es usar diferentes pesos en estos dos casos. Además, se utiliza el mismo peso independientemente de cuántas veces un elemento esté contenido en un elemento informado. Por ejemplo, un párrafo puede formar parte de una sección reportada y luego formar parte de un artículo reportado. Dado que el usuario puede haber visto este párrafo dos veces, su puntuación debería ser reducida aún más aumentando el valor del peso. Motivado por estas observaciones, el algoritmo de reordenamiento puede ser extendido con una serie de pesos 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0, donde βj es el peso aplicado a un nodo que ha sido descendiente de un nodo reportado j veces. Ten en cuenta que un límite superior en M es h, la altura máxima de cualquier árbol XML en la colección. Sin embargo, en la práctica es probable que M sea relativamente pequeño (quizás 3 o 4). La Figura 9 presenta reemplazos para las rutinas de Subir y Bajar de la Figura 6, incorporando esta serie de pesas. Se requiere un campo adicional en cada nodo, de la siguiente manera: x.j - conteo descendente El valor de x.j se establece inicialmente en cero en todos los nodos y se incrementa cada vez que se llama a Down con x como su argumento. Al calcular la puntuación del nodo, el valor de x.j selecciona 1 Up(x, y) ≡ 2 si no y.reported entonces 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recalcular y.score 6 S.add(y) 8 si y no es un nodo raíz entonces 9 Up (x, y.padre) 10 fin si 11 fin si 12 13 Down(x) ≡ 14 si x.j < M entonces 15 x.j ← x.j + 1 16 si no x.reported entonces 17 S.remove(x) 18 recalcular x.score 19 S.add(x) 20 fin si 21 para cada y ∈ x.hijos hacer 22 Down (y) 23 fin hacer 24 fin si Figura 9: Rutinas extendidas de recorrido de árbol. el peso a aplicar al nodo ajustando el valor de xt en la ecuación 1, de la siguiente manera: xt = βx.j · (ft − α · gt) (3) donde ft y gt son los componentes de x.f y x.g correspondientes al término t. Se requieren algunos cambios adicionales para extender Up y Down. La rutina Up devuelve inmediatamente (línea 2) si su argumento ya ha sido reportado, ya que las frecuencias de términos ya han sido ajustadas en sus ancestros. El procedimiento Down no informa su argumento, sino que vuelve a calcular su puntuación y la agrega de nuevo a S. Un nodo no puede ser un argumento de Down más de M +1 veces, lo que a su vez implica una complejidad temporal total de O((nM + mh) log n). Dado que M ≤ h y m ≤ n, la complejidad temporal también es O(nh log n). DISCUSIÓN CONCLUSIVA Al generar resultados de recuperación en una colección de XML, se debe tolerar cierta superposición en los resultados, lo cual puede ser beneficioso. Por ejemplo, cuando un elemento altamente exhaustivo y bastante específico (3,2) contiene un elemento mucho más pequeño (2,3), ambos deben ser informados al usuario, y los algoritmos de recuperación y las métricas de evaluación deben respetar esta relación. El algoritmo presentado en este documento controla la superposición ponderando los términos que aparecen en los elementos informados para reflejar su menor importancia. Otros enfoques también pueden ayudar a controlar la superposición. Por ejemplo, cuando se presentan los resultados de recuperación de XML a los usuarios, puede ser deseable agrupar elementos relacionados estructuralmente juntos, ilustrando visualmente las relaciones entre ellos. Si bien este estilo de interfaz de usuario puede ayudar a un usuario a lidiar con la superposición, la estrategia presentada en este documento sigue siendo aplicable, al determinar los mejores elementos para incluir en cada grupo. En Waterloo, seguimos desarrollando y probando nuestras ideas para INEX 2005. En particular, estamos investigando métodos para aprender los pesos α y βj. También estamos reevaluando nuestro enfoque en las estadísticas de documentos y examinando ajustes apropiados al parámetro k1 a medida que cambian los pesos de los términos [20]. 10. AGRADECIMIENTOS Gracias a Gabriella Kazai y Arjen de Vries por proporcionar una versión temprana de su software para calcular la métrica XCG, y gracias a Phil Tilker y Stefan B¨uttcher por su ayuda con la evaluación experimental. En parte, la financiación para este proyecto fue proporcionada por IBM Canadá a través del Instituto Nacional de Investigación de Software. 11. REFERENCIAS [1] N. Bruno, N. Koudas y D. Srivastava. Uniones de ramas holísticas: Coincidencia óptima de patrones XML. En Actas de la Conferencia Internacional ACM SIGMOD 2002 sobre la Gestión de Datos, páginas 310-321, Madison, Wisconsin, junio de 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y. Masa y A. Soffer. Buscando documentos XML a través de fragmentos XML. En Actas de la 26ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 151-158, Toronto, Canadá, 2003. [3] C. L. A. Clarke y P. L. Tilker. Experimentos MultiText para INEX 2004. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai y M. Lalmas. Tolerancia a la irrelevancia: Una evaluación orientada al esfuerzo del usuario de sistemas de recuperación sin unidad de recuperación predefinida. En las Actas de la Conferencia RIAO 2004, páginas 463-473, Aviñón, Francia, abril de 2004. [5] D. DeHaan, D. Toman, M. P. Consens y M. T. ¨Ozsu. Una traducción exhaustiva de XQuery a SQL utilizando codificación dinámica de intervalos. En Actas de la Conferencia Internacional ACM SIGMOD 2003 sobre la Gestión de Datos, San Diego, junio de 2003. [6] N. Fuhr y K. Großjohann. XIRQL: Un lenguaje de consulta para la recuperación de información en documentos XML. En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 172-180, Nueva Orleans, septiembre de 2001. [7] N. Fuhr, M. Lalmas y S. Malik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Segundo Taller (INEX 2003), Dagstuhl, Alemania, diciembre de 2003. [8] N. Fuhr, M. Lalmas, S. Malik y Zoltán Szlávik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Tercer Taller (INEX 2004), Dagstuhl, Alemania, diciembre de 2004. Publicado como Avances en la Recuperación de Información XML, Notas de Conferencia en Ciencias de la Computación, volumen 3493, Springer, 2005. [9] K. J¨avelin y J. Kek¨al¨ainen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, y B. Sigurbjörnsson. Normalización de longitud en la recuperación de XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 80-87, Sheffield, Reino Unido, julio de 2004. [11] G. Kazai, M. Lalmas y A. P. de Vries. El problema de superposición en la evaluación de la recuperación de XML orientada al contenido. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 72-79, Sheffield, Reino Unido, julio de 2004. [12] G. Kazai, M. Lalmas y A. P. de Vries. Pruebas de confiabilidad para las métricas XCG e inex-2002. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola y T. Aalto. TRIX 2004 - Luchando con la superposición. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [14] S. Liu, Q. Zou y W. W. Chu. Indexación y clasificación configurables para la recuperación de información en XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 88-95, Sheffield, Reino Unido, julio de 2004. [15] Y. Masa y M. Mandelbrot. Recuperando los componentes XML más relevantes. En las Actas del Taller INEX 2003, Dagstuhl, Alemania, diciembre de 2003. [16] Y. Masa y M. Mandelbrot. Clasificación de componentes y refinamiento automático de consultas para la recuperación de XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [17] P. Ogilvie y J. Callan. Modelos de lenguaje jerárquicos para la recuperación de componentes XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [18] J. Pehcevski, J. A. Thom y A. Vercoustre. Recuperación híbrida de XML revisitada. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [19] B. Piwowarski y M. Lalmas. Proporcionando evaluaciones de relevancia consistentes y exhaustivas para la evaluación de recuperación de XML. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 361-370, Washington, DC, noviembre de 2004. [20] S. Robertson, H. Zaragoza y M. Taylor. Extensión simple de BM25 a múltiples campos ponderados. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 42-50, Washington, DC, noviembre de 2004. [21] S. E. Robertson, S. Walker y M. Beaulieu. Okapi en TREC-7: Búsqueda automática, filtrado, VLC y pista interactiva. En Actas de la Séptima Conferencia de Recuperación de Texto, Gaithersburg, MD, noviembre de 1998. [22] A. Trotman y B. Sigurbjörnsson. NEXI, ahora y después. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski y P. Gallinari. Un álgebra para consultas estructuradas en redes bayesianas. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. ",
            "candidates": [],
            "error": [
                []
            ]
        },
        "xml cumulated gain metric": {
            "translated_key": "métrica de ganancia acumulada XML",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Controlling Overlap in Content-Oriented XML Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of XML documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
                "This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents.",
                "The test collection developed by the INitiative for the Evaluation of XML Retrieval (INEX) forms the basis for the evaluation.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "INTRODUCTION The representation of documents in XML provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an XML information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in XML.",
                "Figure 1 provides an example of a journal article encoded in XML, illustrating many of the important characteristics of XML documents.",
                "Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words.",
                "Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate.",
                "Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs.",
                "Each of these characteristics affects the design of an XML IR system, and each leads to fundamental problems that must be solved in an successful system.",
                "Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper.",
                "The article of figure 1 may be viewed as an XML tree, as illustrated in figure 2.",
                "Formally, a collection of XML documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes.",
                "For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example XML tree. of x.",
                "Since an element may be represented by the node at its root, the output of an XML IR system may be viewed as a ranked list of the top-m nodes.",
                "The direct application of a standard relevance ranking technique to a set of XML elements can produce a result in which the top ranks are dominated by many structurally related elements.",
                "A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article.",
                "For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms.",
                "If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content.",
                "One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it.",
                "Unfortunately, this approach destroys some of the possible benefits of XML IR.",
                "For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts.",
                "In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements.",
                "Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6].",
                "This paper presents a method for controlling overlap.",
                "Starting with an initial element ranking, a re-ranking algorithm adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
                "For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced.",
                "The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20].",
                "Extending that approach, the re-ranking algorithm varies weights dynamically as elements are processed.",
                "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a baseline retrieval method is presented in section 4.",
                "This baseline method represents a reasonable adaptation of standard IR technology to XML.",
                "Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point.",
                "A re-ranking algorithm implementing this strategy is presented in section 6 and evaluated in section 7.",
                "Section 8 discusses an extended version of the algorithm. 2.",
                "BACKGROUND This section provides a general overview of XML information retrieval and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
                "Much research in the area of XML retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1].",
                "Here, we take a content oriented IR perceptive, focusing on XML documents that primarily contain natural language data and queries that are primarily expressed in natural language.",
                "We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need.",
                "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional information retrieval applications the standard unit of retrieval is taken to be the document.",
                "Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages.",
                "When applying standard relevance ranking techniques in the context of XML IR, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
                "In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole.",
                "If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article.",
                "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an XML IR system might potentially retrieve any element, many elements may not be appropriate as retrieval results.",
                "This is usually the case when elements contain very little text [10].",
                "For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself.",
                "Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user.",
                "An effective XML IR system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18].",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (INEX) has encouraged research into XML information retrieval technology [7,8].",
                "INEX is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
                "Over 50 groups participated in INEX 2004, and the conference has become as influential in the area of XML IR as TREC is in other IR areas.",
                "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by INEX.",
                "Overlap causes considerable problems with retrieval evaluation, and the INEX organizers and participants have wrestled with these problems since the beginning.",
                "While substantial progress has been made, these problem are still not completely solved.",
                "Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of INEX retrieval evaluation and discuss both current and proposed evaluation metrics.",
                "Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3.",
                "INEX 2004 Space limitations prevent the inclusion of more than a brief summary of INEX 2004 tasks and evaluation methodology.",
                "For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, INEX 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002.",
                "Each document is encoded in XML using a common DTD, with the document of figures 1 and 2 providing one example.",
                "At INEX 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics.",
                "The two tasks differed in the types of topics they used.",
                "For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection.",
                "For this task, the IR system is required to select the elements to be returned.",
                "For the other task, the contentand-structure or CAS task, the topics are written in an XML query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy.",
                "Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description.",
                "In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants.",
                "Each topic includes a short keyword query, which is executed over the collection by each participating group on their own XML IR system.",
                "Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since XML IR is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient.",
                "Instead, the INEX organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic.",
                "A four-point scale is used in both dimensions.",
                "Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant.",
                "Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at INEX 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values.",
                "One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others.",
                "This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant.",
                "Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity.",
                "Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity.",
                "This paper reports results of this metric using all three of these quantization functions.",
                "Since this metric was first introduced at INEX 2002, it is generally referred as the inex-2002 metric.",
                "The inex-2002 metric does not penalize overlap.",
                "In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank.",
                "To address this problem, Kazai et al. [11] propose an <br>xml cumulated gain metric</br>, which compares the cumulated gain [9] of a ranked list to an ideal gain vector.",
                "This ideal gain vector is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path.",
                "Thus, the XCG metric rewards retrieval runs that avoid overlap.",
                "While XCG was not used officially at INEX 2004, a version of it is likely to be used in the future.",
                "At INEX 2003, yet another metric was introduced to ameliorate the perceived limitations of the inex-2002 metric.",
                "This inex-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them.",
                "Two versions were created, one that considered only component size and another that considered both size and overlap.",
                "While the inex-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4.",
                "BASELINE RETRIEVAL METHOD This section provides an overview of baseline XML information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3].",
                "This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the XML information retrieval task.",
                "The MultiText system performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
                "To support retrieval from XML and other structured document types, the system provides generalized queries of the form: rank X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms.",
                "For our INEX 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections.",
                "Prior to INEX 2004, the INEX collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names.",
                "Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received.",
                "Automating this selection process is planned as future work.",
                "For INEX 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.",
                "For example, keyword field of topic 166 +tree edit distance + XML -image became the four-term query $tree $edit $distance $xml where the $ operator within a quoted string stems the term that follows it.",
                "Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞.",
                "Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(inex-2002) k1 strict generalized sog Figure 3: Impact of k1 on inex-2002 mean average precision with b = 0.75 (INEX 2003 CO topics).",
                "Prior to INEX 2004, the INEX 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.",
                "For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article.",
                "These statistics are used for ranking all element types.",
                "Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length.",
                "The use of article statistics for all element types might be questioned.",
                "This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.",
                "The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics.",
                "Nonetheless, we plan to examine this issue again in the future.",
                "In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose.",
                "Prior to INEX 2004, we trained the MultiText system using the INEX 2003 queries.",
                "As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system.",
                "The results were surprising.",
                "Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions.",
                "In our experience, optimal values for k1 are typically in the range 0.0 to 2.0.",
                "In this case, large values are required for good performance.",
                "Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization.",
                "Similar improvements are seen under the generalized and sog quantizations.",
                "In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).",
                "After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our INEX 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5.",
                "CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements.",
                "At a conceptual level, re-ranking proceeds as follows: 1.",
                "Report the highest ranking element. 2.",
                "Adjust the scores of the unreported elements. 3.",
                "Repeat steps 1 and 2 until m elements are reported.",
                "One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements.",
                "For example, assume a paragraph with score p is reported in step 1.",
                "In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score.",
                "In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion.",
                "That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages.",
                "A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two.",
                "Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness.",
                "Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body.",
                "In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body.",
                "Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported.",
                "The next section presents and analysis a simple re-ranking algorithm that follows this strategy.",
                "The algorithm is evaluated experimentally in section 7.",
                "One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears.",
                "In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6.",
                "RE-RANKING ALGORITHM The re-ranking algorithm operates over XML trees, such as the one appearing in figure 2.",
                "Input to the algorithm is a list of n elements ranked according to their initial BM25 scores.",
                "During the initial ranking the XML tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |.",
                "Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores.",
                "An element is represented by the node x ∈ N at its root.",
                "Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - term frequency vector x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses.",
                "The vector x.f contains term frequency information corresponding to each term in the query.",
                "The vector x.g is initially zero and is updated by the algorithm as elements are reported.",
                "The score field contains the current BM25 score for the element, which will change as the values in x.g change.",
                "The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g.",
                "Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the re-ranking algorithm, nodes are stored in priority queues, ordered by decreasing score.",
                "Each priority queue PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
                "The core of the re-ranking algorithm is presented in figure 5.",
                "The algorithm takes as input the priority queue S containing the initial ranking, and produces the top-m reranked nodes in the priority queue F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
                "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a priority queue S, containing XML nodes ranked by their initial scores, and returns its results in priority queue F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
                "The tree traversal routines, Up and Down are given in figure 6.",
                "The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2.",
                "The Down routine performs a similar operation on each descendant.",
                "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the time complexity of the algorithm, first note that a node may be an argument to Down at most once.",
                "Thereafter, the reported flag of its parent is true.",
                "During each call to Down a node may be moved from S to F, requiring O(log n) time.",
                "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the time complexity of the loop over lines 2-15.",
                "During each iteration of this loop, a node and each of its ancestors are removed from a priority queue and then added back into a priority queue.",
                "Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time.",
                "Combining these observations produces an overall time complexity of O((n + mh) log n).",
                "In practice, re-ranking an INEX result set requires less than 200ms on a three-year-old desktop PC. 7.",
                "EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper.",
                "Nonetheless, when taken together they provide insight into the behaviour of the re-ranking algorithm.",
                "The INEX evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the inex-2002 and inex-2003 metrics.",
                "Values for the XCG metrics were computed using software supplied by its inventors [11].",
                "Figure 7 plots the three variants of inex-2002 MAP metric together with the XCG metric.",
                "Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on inex-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0.",
                "Recalling that the XCG metric is designed to penalize overlap, while the inex-2002 metric ignores overlap, the conflict between the metrics is obvious.",
                "The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at INEX 2004 [8,12].",
                "Figure 8 plots values of the inex-2003 MAP metric for two quantizations, with and without consideration of overlap.",
                "Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8.",
                "EXTENDED ALGORITHM One limitation of the re-ranking algorithm is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements.",
                "An obvious extension is to use different weights in these two cases.",
                "Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element.",
                "For example, a paragraph may form part of a reported section and then form part of a reported article.",
                "Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight.",
                "Motivated by these observations, the re-ranking algorithm may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times.",
                "Note that an upper bound on M is h, the maximum height of any XML tree in the collection.",
                "However, in practice M is likely to be relatively small (perhaps 3 or 4).",
                "Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights.",
                "One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument.",
                "When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down.",
                "The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors.",
                "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall time complexity of O((nM + mh) log n).",
                "Since M ≤ h and m ≤ n, the time complexity is also O(nh log n). 9.",
                "CONCLUDING DISCUSSION When generating retrieval results over an XML collection, some overlap in the results should be tolerated, and may be beneficial.",
                "For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship.",
                "The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance.",
                "Other approaches may also help to control overlap.",
                "For example, when XML retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them.",
                "While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster.",
                "At Waterloo, we continue to develop and test our ideas for INEX 2005.",
                "In particular, we are investigating methods for learning the α and βj weights.",
                "We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10.",
                "ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation.",
                "In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11.",
                "REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava.",
                "Holistic twig joins: Optimal XML pattern matching.",
                "In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
                "Mass, and A. Soffer.",
                "Searching XML documents via XML fragments.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker.",
                "MultiText experiments for INEX 2004.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas.",
                "Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit.",
                "In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu.",
                "A comprehensive XQuery to SQL translation using dynamic interval encoding.",
                "In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann.",
                "XIRQL: A query language for information retrieval in XML documents.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Second Workshop (INEX 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Third Workshop (INEX 2004), Dagstuhl, Germany, December 2004.",
                "Published as Advances in XML Information Retrieval, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson.",
                "Length normalization in XML retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "The overlap problem in content-oriented XML retrieval evaluation.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "Reliability tests for the XCG and inex-2002 metrics.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto.",
                "TRIX 2004 - Struggling with the overlap.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu.",
                "Configurable indexing and ranking for XML information retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 88-95, Sheffield, UK, July 2004. [15] Y.",
                "Mass and M. Mandelbrod.",
                "Retrieving the most relevant XML components.",
                "In INEX 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y.",
                "Mass and M. Mandelbrod.",
                "Component ranking and automatic query refinement for XML retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan.",
                "Hierarchical language models for XML component retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [18] J. Pehcevski, J.",
                "A. Thom, and A. Vercoustre.",
                "Hybrid XML retrieval re-visited.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas.",
                "Providing consistent and exhaustive relevance assessments for XML retrieval evaluation.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor.",
                "Simple BM25 extension to multiple weighted fields.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu.",
                "Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track.",
                "In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson.",
                "NEXI, now and next.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari.",
                "An algebra for structured queries in bayesian networks.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]."
            ],
            "original_annotated_samples": [
                "To address this problem, Kazai et al. [11] propose an <br>xml cumulated gain metric</br>, which compares the cumulated gain [9] of a ranked list to an ideal gain vector."
            ],
            "translated_annotated_samples": [
                "Para abordar este problema, Kazai et al. [11] proponen una <br>métrica de ganancia acumulada XML</br>, que compara la ganancia acumulada [9] de una lista clasificada con un vector de ganancia ideal."
            ],
            "translated_text": "Controlando la superposición en la recuperación XML orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca RESUMEN La aplicación directa de técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos XML a menudo produce un conjunto de resultados en el que los primeros puestos están dominados por un gran número de elementos tomados de un pequeño número de documentos altamente relevantes. Este documento presenta y evalúa un algoritmo que vuelve a clasificar este conjunto de resultados, con el objetivo de minimizar el contenido redundante mientras se preservan los beneficios de la recuperación de elementos, incluido el beneficio de identificar componentes centrados en el tema contenidos en documentos relevantes. La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la Recuperación XML (INEX) constituye la base para la evaluación. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Búsqueda y Recuperación de Información Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. La representación de documentos en XML brinda una oportunidad para que los sistemas de recuperación de información aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias. En respuesta a una consulta de usuario, un sistema de recuperación de información XML podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes. Esta facilidad es de particular beneficio cuando una colección contiene documentos muy largos, como manuales de productos o libros, donde el usuario debe ser dirigido a las partes más relevantes de estos documentos. La Figura 1 proporciona un ejemplo de un artículo de revista codificado en XML, ilustrando muchas de las características importantes de los documentos XML. Las etiquetas indican el inicio y el final de cada elemento, con elementos que varían ampliamente en tamaño, desde una palabra hasta miles de palabras. Algunos elementos, como párrafos y secciones, pueden presentarse razonablemente al usuario como resultados de búsqueda, pero otros no son apropiados. Los elementos se superponen entre sí: los artículos contienen secciones, las secciones contienen subsecciones y las subsecciones contienen párrafos. Cada una de estas características afecta el diseño de un sistema de IR XML, y cada una conlleva problemas fundamentales que deben resolverse en un sistema exitoso. La mayoría de estos problemas fundamentales pueden resolverse mediante la cuidadosa adaptación de técnicas estándar de IR, pero los problemas causados por la superposición son únicos en esta área [4,11] y constituyen el enfoque principal de este artículo. El artículo de la figura 1 puede ser visto como un árbol XML, como se ilustra en la figura 2. Formalmente, una colección de documentos XML puede ser representada como un bosque de árboles ordenados y enraizados, que consiste en un conjunto de nodos N y un conjunto de aristas dirigidas E que conectan estos nodos. Para cada nodo x ∈ N, la notación x.parent se refiere al nodo padre de x, si existe, y la notación x.children se refiere al conjunto de nodos hijos de x. Dado que un elemento puede estar representado por el nodo en su raíz, la salida de un sistema de IR XML puede ser vista como una lista clasificada de los m nodos principales. La aplicación directa de una técnica estándar de clasificación de relevancia a un conjunto de elementos XML puede producir un resultado en el que los primeros puestos están dominados por muchos elementos estructuralmente relacionados. Una sección con una puntuación alta probablemente contenga varios párrafos con una puntuación alta y esté contenida en un artículo con una puntuación alta. Por ejemplo, muchos de los elementos en la figura 2 recibirían una puntuación alta en los algoritmos de compresión de índices de texto de consulta de palabras clave. Si cada uno de estos elementos se presenta a un usuario como un resultado individual y separado, puede perder mucho tiempo revisando y rechazando contenido redundante. Una posible solución es informar solo el elemento de mayor puntuación a lo largo de un camino dado en el árbol, y eliminar de los rangos inferiores cualquier elemento que lo contenga o esté contenido en él. Desafortunadamente, este enfoque destruye algunos de los posibles beneficios de XML IR. Por ejemplo, un elemento externo puede contener una cantidad sustancial de información que no aparece en un elemento interno, pero el elemento interno puede estar fuertemente enfocado en el tema de la consulta y proporcionar un breve resumen de los conceptos clave. En tales casos, es razonable informar sobre elementos que contienen, o están contenidos en, elementos de rango superior. Incluso cuando un libro entero es relevante, un usuario aún puede desear que se destaquen los párrafos más importantes, para guiar su lectura y ahorrar tiempo [6]. Este documento presenta un método para controlar la superposición. A partir de una clasificación inicial de elementos, un algoritmo de re-clasificación ajusta las puntuaciones de los elementos de menor clasificación que contienen, o están contenidos dentro de, elementos de mayor clasificación, reflejando el hecho de que esta información puede ser ahora redundante. Por ejemplo, una vez que un elemento que representa una sección aparece en la clasificación, las puntuaciones de los párrafos que contiene y del artículo que lo contiene se reducen. La inspiración para esta estrategia proviene parcialmente del trabajo reciente sobre la recuperación de documentos estructurados, donde los términos que aparecen en diferentes campos, como el título y el cuerpo, reciben diferentes pesos [20]. Extendiendo ese enfoque, el algoritmo de reordenamiento varía los pesos dinámicamente a medida que se procesan los elementos. El resto del documento está organizado de la siguiente manera: Después de una discusión sobre el trabajo de antecedentes y la metodología de evaluación, se presenta un método de recuperación de referencia en la sección 4. Este método de referencia representa una adaptación razonable de la tecnología estándar de IR al XML. La sección 5 luego describe una estrategia para controlar la superposición, utilizando el método de línea base como punto de partida. Un algoritmo de reordenamiento que implementa esta estrategia se presenta en la sección 6 y se evalúa en la sección 7. La sección 8 discute una versión extendida del algoritmo. 2. ANTECEDENTES Esta sección proporciona una visión general de la recuperación de información XML y discute trabajos relacionados, con énfasis en los problemas fundamentales mencionados en la introducción. Mucha investigación en el área de recuperación de XML lo ve desde una perspectiva de base de datos tradicional, preocupándose por problemas como la implementación de lenguajes de consulta estructurados [5] y el procesamiento de joins [1]. Aquí adoptamos una perspectiva de IR orientada al contenido, centrándonos en documentos XML que contienen principalmente datos en lenguaje natural y consultas que están principalmente expresadas en lenguaje natural. Suponemos que estas consultas indican únicamente la naturaleza del contenido deseado, no su estructura, y que el papel del sistema de RI es determinar qué elementos satisfacen mejor la necesidad de información subyacente. Otra investigación en IR ha considerado consultas mixtas, en las que se especifican tanto requisitos de contenido como estructurales [2,6,14,17,23]. 2.1 Estadísticas de Términos y Documentos En las aplicaciones tradicionales de recuperación de información, la unidad estándar de recuperación se considera que es el documento. Dependiendo de la aplicación, este término podría interpretarse para abarcar muchos objetos diferentes, incluyendo páginas web, artículos de periódico y mensajes de correo electrónico. Al aplicar técnicas estándar de clasificación de relevancia en el contexto de la RI XML, un enfoque natural es tratar cada elemento como un documento separado, con estadísticas de términos disponibles para cada uno [16]. Además, la mayoría de las técnicas de clasificación requieren estadísticas globales (por ejemplo, frecuencia inversa de documentos) calculadas sobre la colección en su totalidad. Si consideramos que esta colección incluye todos los elementos que podrían ser devueltos por el sistema, una ocurrencia específica de un término puede aparecer en varios documentos diferentes, quizás en elementos que representan un párrafo, una subsección, una sección y un artículo. No es apropiado calcular la frecuencia inversa de documentos bajo la suposición de que el término está contenido en todos estos elementos, ya que el número de elementos que contienen un término depende completamente del arreglo estructural de los documentos [13,23]. 2.2 Elementos Recuperables Si bien un sistema de recuperación de información XML podría potencialmente recuperar cualquier elemento, muchos elementos pueden no ser apropiados como resultados de recuperación. Esto suele ser el caso cuando los elementos contienen muy poco texto [10]. Por ejemplo, un título de sección que contenga solo los términos de búsqueda puede recibir una puntuación alta de un algoritmo de clasificación, pero por sí solo tendría un valor limitado para un usuario, quien podría preferir la sección real en sí misma. Otros elementos pueden reflejar la estructura física de los documentos, en lugar de la estructura lógica, lo cual puede tener poco o ningún significado para un usuario. Un sistema de recuperación de información XML efectivo debe devolver solo aquellos elementos que tengan suficiente contenido para ser utilizables y puedan funcionar como objetos independientes [15,18]. Componentes estándar de documentos como párrafos, secciones, subsecciones y resúmenes generalmente cumplen con estos requisitos; los títulos, frases en cursiva y campos de metadatos individuales a menudo no lo hacen. 2.3 Metodología de Evaluación En los últimos tres años, la Iniciativa para la Evaluación de la Recuperación de Información XML (INEX) ha fomentado la investigación en tecnología de recuperación de información XML [7,8]. INEX es una serie de conferencias experimentales, similar a TREC, en la que grupos de diferentes instituciones completan una o más tareas experimentales utilizando sus propias herramientas y sistemas, y comparan sus resultados en la propia conferencia. Más de 50 grupos participaron en INEX 2004, y la conferencia se ha convertido en tan influyente en el área de la RI XML como lo es TREC en otras áreas de la RI. La investigación descrita en este artículo, al igual que gran parte del trabajo relacionado que cita, depende de las colecciones de pruebas desarrolladas por INEX. La superposición causa problemas considerables en la evaluación de la recuperación, y los organizadores y participantes de INEX han luchado con estos problemas desde el principio. Aunque se ha logrado un progreso sustancial, estos problemas aún no están completamente resueltos. Kazai et al. [11] proporcionan una exposición detallada del problema de superposición en el contexto de la evaluación de recuperación de INEX y discuten tanto las métricas de evaluación actuales como las propuestas. Muchas de estas métricas se aplican para evaluar los experimentos reportados en este artículo, y se describen brevemente en la siguiente sección. 3. Las limitaciones de espacio impiden incluir más que un breve resumen de las tareas y metodología de evaluación de INEX 2004. Para obtener información detallada, se deben consultar las actas de la conferencia en sí [8]. 3.1 Tareas Para las principales tareas experimentales, a los participantes de INEX 2004 se les proporcionó una colección de 12,107 artículos tomados de las revistas y publicaciones de la IEEE Computer Societies entre 1995 y 2002. Cada documento está codificado en XML utilizando una DTD común, siendo el documento de las figuras 1 y 2 un ejemplo. En INEX 2004, las dos principales tareas experimentales fueron ambas tareas de recuperación ad hoc, investigando el rendimiento de sistemas que buscan en una colección estática utilizando temas previamente no vistos. Las dos tareas diferían en los tipos de temas que utilizaban. Para una tarea, la tarea de solo contenido o CO, los temas consisten en declaraciones cortas en lenguaje natural sin hacer referencia directa a la estructura de los documentos en la colección. Para esta tarea, se requiere que el sistema de IR seleccione los elementos a devolver. Para la otra tarea, la tarea de contenido y estructura o CAS, los temas están escritos en un lenguaje de consulta XML [22] y contienen referencias explícitas a la estructura del documento, que el sistema de IR debe intentar satisfacer. Dado que el trabajo descrito en este documento se enfoca en la tarea de solo contenido, donde el sistema de IR no recibe orientación sobre los elementos a devolver, la tarea de CAS se ignora en el resto de nuestra descripción. En 2004, los organizadores de la conferencia seleccionaron 40 nuevos temas de CO de las contribuciones proporcionadas por los participantes de la conferencia. Cada tema incluye una breve consulta de palabras clave, la cual es ejecutada sobre la colección por cada grupo participante en su propio sistema de IR XML. Cada grupo podría presentar hasta tres ejecuciones experimentales que consistieran en los primeros m = 1500 elementos para cada tema. 3.2 Evaluación de Relevancia Dado que la RI XML se preocupa por localizar aquellos elementos que proporcionan una cobertura completa de un tema mientras contienen la menor cantidad de información irrelevante posible, los juicios simples de relevante vs. no relevante no son suficientes. En cambio, los organizadores de INEX adoptaron dos dimensiones para la evaluación de relevancia: la dimensión de exhaustividad refleja el grado en que un elemento abarca el tema, y la dimensión de especificidad refleja el grado en que un elemento se enfoca en el tema. Se utiliza una escala de cuatro puntos en ambas dimensiones. Por lo tanto, un elemento (3,3) es altamente exhaustivo y altamente específico, un elemento (1,3) es marginalmente exhaustivo y altamente específico, y un elemento (0,0) no es relevante. Información adicional sobre la metodología de evaluación se puede encontrar en Piwowarski y Lalmas [19], quienes proporcionan una justificación detallada. 3.3 Métricas de Evaluación La métrica de evaluación principal utilizada en INEX 2004 es una versión de la precisión promedio media (MAP), ajustada por diversas funciones de cuantificación para dar diferentes pesos a diferentes elementos, dependiendo de sus valores de exhaustividad y especificidad. Una variante, la función de cuantización estricta asigna un peso de 1 a los elementos (3,3) y un peso de 0 a todos los demás. Esta variante es esencialmente el valor MAP familiar, con elementos (3,3) tratados como relevantes y todos los demás elementos tratados como no relevantes. Otras funciones de cuantización están diseñadas para otorgar crédito parcial a elementos que son aproximaciones cercanas, debido a la falta de exhaustividad y/o especificidad. Tanto la función de cuantificación generalizada como la función de generalización orientada a la especificidad (sog) acreditan elementos según su grado de relevancia [11], siendo que la segunda función pone mayor énfasis en la especificidad. Este documento informa los resultados de esta métrica utilizando las tres funciones de cuantización. Desde que esta métrica fue introducida por primera vez en INEX 2002, generalmente se le conoce como la métrica inex-2002. La métrica inex-2002 no penaliza la superposición. En particular, tanto las funciones de cuantificación generalizadas como las de sog otorgan crédito parcial a un casi acierto incluso cuando se informa un elemento (3,3) que se superpone a él en un rango más alto. Para abordar este problema, Kazai et al. [11] proponen una <br>métrica de ganancia acumulada XML</br>, que compara la ganancia acumulada [9] de una lista clasificada con un vector de ganancia ideal. Este vector de ganancia ideal se construye a partir de las valoraciones de relevancia al eliminar la superposición y retener solo el mejor elemento a lo largo de un camino dado. Por lo tanto, la métrica XCG recompensa las ejecuciones de recuperación que evitan la superposición. Aunque XCG no se utilizó oficialmente en INEX 2004, es probable que se utilice una versión de él en el futuro. En INEX 2003, se introdujo otra métrica para mejorar las limitaciones percibidas de la métrica inex-2002. Este métrico inex-2003 extiende las definiciones de precisión y exhaustividad para considerar tanto el tamaño de los componentes informados como la superposición entre ellos. Se crearon dos versiones, una que consideraba solo el tamaño de los componentes y otra que consideraba tanto el tamaño como la superposición. Si bien la métrica inex-2003 presenta anomalías no deseadas [11] y no se utilizó en 2004, se informan valores en la sección de evaluación para proporcionar un instrumento adicional para investigar la superposición. 4. MÉTODO DE RECUPERACIÓN DE BASELINE Esta sección proporciona una descripción general del método de recuperación de información XML de base actualmente utilizado en el sistema MultiText IR, desarrollado por el Grupo de Recuperación de Información de la Universidad de Waterloo [3]. Este método de recuperación resulta de la adaptación y ajuste de la medida Okapi BM25 [21] a la tarea de recuperación de información en XML. El sistema MultiText tuvo un desempeño respetable en INEX 2004, ubicándose entre los diez primeros en todas las funciones de cuantización, y ocupando el primer lugar cuando la función de cuantización enfatizaba la exhaustividad. Para admitir la recuperación de XML y otros tipos de documentos estructurados, el sistema proporciona consultas generalizadas de la forma: clasificar X por Y donde X es una subconsulta que especifica un conjunto de elementos de documentos a clasificar y Y es un vector de subconsultas que especifican términos de recuperación individuales. Para nuestras ejecuciones de INEX 2004, la subconsulta X especificó una lista de elementos recuperables como aquellos con nombres de etiquetas de la siguiente manera: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt. Esta lista incluye entradas bibliográficas (bb) y leyendas de figuras (fig) así como párrafos, secciones y subsecciones. Antes de INEX 2004, la colección de INEX y las evaluaciones de relevancia de INEX 2003 fueron analizadas manualmente para seleccionar estos nombres de etiquetas. Los nombres de las etiquetas fueron seleccionados en base a su frecuencia en la colección, el tamaño promedio de sus elementos asociados y el número relativo de juicios de relevancia positiva que recibieron. Automatizar este proceso de selección está planeado como trabajo futuro. Para INEX 2004, el vector término Y se derivó del tema dividiendo frases en palabras individuales, eliminando palabras vacías y términos negativos (aquellos que comienzan con -), y aplicando un stemmer. Por ejemplo, el campo de palabra clave del tema 166 +distancia de edición de árbol + XML -imagen se convirtió en la consulta de cuatro términos $árbol $edición $distancia $xml donde el operador $ dentro de una cadena entre comillas deriva el término que le sigue. Nuestra implementación de Okapi BM25 se deriva de la fórmula de Robertson et al. [21] al establecer los parámetros k2 = 0 y k3 = ∞. Dado un conjunto de términos Q, a un elemento x se le asigna la puntuación t∈Q w(1) qt (k1 + 1)xt K + xt (1) donde w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = número de documentos en el corpus Dt = número de documentos que contienen t qt = frecuencia con la que t ocurre en el tema xt = frecuencia con la que t ocurre en x K = k1((1 − b) + b · lx/lavg) lx = longitud de x lavg = longitud promedio del documento 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 PrecisiónPromedio(inex-2002) k1 estricto generalizado sog Figura 3: Impacto de k1 en la precisión promedio de inex-2002 con b = 0.75 (temas CO de INEX 2003). Antes de INEX 2004, los temas y juicios de INEX 2003 se utilizaron para ajustar los parámetros b y k1, y el impacto de este ajuste se discute más adelante en esta sección. Para los propósitos de calcular estadísticas a nivel de documento (D, Dt y lavg), un documento se define como un artículo. Estas estadísticas se utilizan para clasificar todos los tipos de elementos. Siguiendo la sugerencia de Kamps et al. [10], los resultados de recuperación se filtran para eliminar elementos muy cortos, aquellos con menos de 25 palabras de longitud. El uso de estadísticas de artículos para todos los tipos de elementos podría ser cuestionado. Este enfoque puede justificarse al considerar la colección como un conjunto de artículos que se pueden buscar utilizando técnicas estándar orientadas a documentos, donde solo se devuelven artículos. El puntaje calculado para un elemento es esencialmente el puntaje que recibiría si se agregara a la colección como un nuevo documento, ignorando los ajustes menores necesarios para las estadísticas a nivel de documento. Sin embargo, planeamos examinar este tema nuevamente en el futuro. En nuestra experiencia, el rendimiento de BM25 suele beneficiarse al ajustar los parámetros b y k1 a la colección, siempre que haya consultas de entrenamiento disponibles con este propósito. Antes de INEX 2004, entrenamos el sistema MultiText utilizando las consultas de INEX 2003. Como punto de partida, utilizamos los valores b = 0.75 y k1 = 1.2, que funcionan bien en colecciones TREC adhoc y se utilizan como valores predeterminados en nuestro sistema. Los resultados fueron sorprendentes. La Figura 3 muestra el resultado de variar k1 con b = 0.75 en los valores de MAP bajo tres funciones de cuantización. En nuestra experiencia, los valores óptimos para k1 suelen estar en el rango de 0.0 a 2.0. En este caso, se requieren valores grandes para un buen rendimiento. Entre k1 = 1.0 y k1 = 6.0, el MAP aumenta en más del 15% bajo la cuantización estricta. Se observan mejoras similares bajo las cuantizaciones generalizada y SOG. Por el contrario, nuestro valor predeterminado de b = 0.75 funciona bien bajo todas las funciones de cuantificación (figura 4). Después de ajustar una amplia gama de valores bajo varias funciones de cuantización, seleccionamos los valores de k = 10.0 y b = 0.80 para nuestros experimentos de INEX 2004, y estos valores se utilizan para los experimentos reportados en la sección 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 PrecisiónPromedioMedia (inex-2002) b estricto generalizado sog Figura 4: Impacto de b en la precisión promedio media de inex-2002 con k1 = 10 (temas CO de INEX 2003). 5. CONTROL DE SUPERPOSICIÓN Comenzando con una clasificación de elementos generada por el método de referencia descrito en la sección anterior, los elementos se vuelven a clasificar para controlar la superposición ajustando de forma iterativa las puntuaciones de aquellos elementos que contienen o están contenidos en elementos de clasificación más alta. A nivel conceptual, la reorganización procede de la siguiente manera: 1. Informe el elemento de rango más alto. Ajustar las puntuaciones de los elementos no reportados. 3. Repetir los pasos 1 y 2 hasta que se informen m elementos. Un enfoque para ajustar las puntuaciones de los elementos no informados en el paso 2 podría basarse en las puntuaciones Okapi BM25 de los elementos involucrados. Por ejemplo, supongamos que se informa un párrafo con una puntuación p en el paso 1. En el paso 2, la sección que contiene el párrafo podría tener su puntuación s reducida en una cantidad α · p para reflejar la contribución reducida que el párrafo debería hacer a la puntuación de las secciones. En un contexto relacionado, Robertson et al. [20] argumentan en contra de la combinación lineal de las puntuaciones de Okapi de esta manera. Ese trabajo considera el problema de asignar diferentes pesos a diferentes campos de documentos, como el título y el cuerpo asociados con páginas web. Un enfoque común para este problema puntúa el título y el cuerpo por separado y genera una puntuación final como una combinación lineal de ambos. Robertson et al. discuten las deficiencias teóricas en este enfoque y demuestran experimentalmente que puede perjudicar realmente la efectividad de la recuperación. En cambio, aplican los pesos a nivel de frecuencia de términos, donde la aparición de un término de consulta t en el título contribuye más al puntaje que una aparición en el cuerpo. En la ecuación 1, xt se convierte en α0 · yt + α1 · zt, donde yt es el número de veces que t aparece en el título y zt es el número de veces que t aparece en el cuerpo. Al traducir este enfoque a nuestro contexto, la contribución de los términos que aparecen en los elementos se reduce dinámicamente a medida que se informan. La siguiente sección presenta y analiza un algoritmo de reordenamiento simple que sigue esta estrategia. El algoritmo se evalúa experimentalmente en la sección 7. Una limitación del algoritmo es que la contribución de los términos que aparecen en los elementos informados se reduce por el mismo factor independientemente del número de elementos informados en los que aparezca. En la sección 8, el algoritmo se extiende para aplicar pesos crecientes, disminuyendo la puntuación, cuando un término aparece en más de un elemento informado. 6. ALGORITMO DE REORDENAMIENTO El algoritmo de reordenamiento opera sobre árboles XML, como el que aparece en la figura 2. La entrada al algoritmo es una lista de n elementos clasificados según sus puntuaciones iniciales de BM25. Durante la clasificación inicial, el árbol XML se reconstruye dinámicamente para incluir solo aquellos nodos con puntuaciones BM25 distintas de cero, por lo que n puede ser considerablemente menor que |N|. La salida del algoritmo es una lista de los primeros m elementos, clasificados según sus puntajes ajustados. Un elemento está representado por el nodo x ∈ N en su raíz. Asociados con este nodo se encuentran campos que almacenan la longitud del elemento, las frecuencias de términos y otra información requerida por el algoritmo de re-ranking, de la siguiente manera: x.f - vector de frecuencia de términos x.g - ajustes de frecuencia de términos x.l - longitud del elemento x.score - puntaje actual de Okapi BM25 x.reported - bandera booleana, inicialmente falsa x.children - conjunto de nodos hijos x.parent - nodo padre, si existe Estos campos se llenan durante el proceso de clasificación inicial y se actualizan a medida que avanza el algoritmo. El vector x.f contiene información de frecuencia de términos correspondiente a cada término en la consulta. El vector x.g es inicialmente cero y se actualiza por el algoritmo a medida que se informan elementos. El campo de puntuación contiene la puntuación BM25 actual para el elemento, la cual cambiará a medida que cambien los valores en x.g. El puntaje se calcula utilizando la ecuación 1, con el valor xt para cada término determinado por una combinación de los valores en x.f y x.g. Dado un término t ∈ Q, sea ft el componente de x.f correspondiente a t, y sea gt el componente de x.g correspondiente a t, entonces: xt = ft − α · gt (2) Para el procesamiento por el algoritmo de reordenamiento, los nodos se almacenan en colas de prioridad, ordenadas por puntaje decreciente. Cada cola de prioridad PQ admite tres operaciones: PQ.front() - devuelve el nodo con la puntuación más alta, PQ.add(x) - agrega el nodo x a la cola, PQ.remove(x) - elimina el nodo x de la cola. Cuando se implementan utilizando estructuras de datos estándar, la operación front requiere tiempo O(1), y las otras operaciones requieren tiempo O(log n), donde n es el tamaño de la cola. El núcleo del algoritmo de reordenamiento se presenta en la figura 5. El algoritmo toma como entrada la cola de prioridad S que contiene la clasificación inicial, y produce los primeros m nodos reordenados en la cola de prioridad F. Después de inicializar F como vacío en la línea 1, el algoritmo recorre m veces las líneas 215, transfiriendo al menos un nodo de S a F durante cada iteración. Al inicio de cada iteración, el nodo no reportado al frente de S tiene el mayor puntaje ajustado, y se elimina y se agrega a F. El algoritmo luego recorre el 1 F ← ∅ 2 para i ← 1 a m hacer 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 para cada y ∈ x.children hacer 9 Abajo (y) 10 fin hacer 11 12 si x no es un nodo raíz entonces 13 Arriba (x, x.parent) 14 fin si 15 fin hacer Figura 5: Algoritmo de Re-Ranking - Como entrada, el algoritmo toma una cola de prioridad S, que contiene nodos XML clasificados por sus puntajes iniciales, y devuelve sus resultados en la cola de prioridad F, clasificados por puntajes ajustados. 1 Arriba(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recalcular y.score 5 S.add(y) 6 si y no es un nodo raíz entonces 7 Arriba (x, y.parent) 8 fin si 9 10 Abajo(x) ≡ 11 si no x.reported entonces 12 S.remove(x) 14 x.g ← x.f 15 recalcular x.score 16 si x.score > 0 entonces 17 F.add(x) 18 fin si 19 x.reported ← true 20 para cada y ∈ x.children hacer 21 Abajo (y) 22 fin hacer 23 fin si Figura 6: Rutinas de recorrido de árbol llamadas por el algoritmo de re-ranking. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 PrecisiónPromedioMedia (inex-2002) GananciaAcumuladaXML(XCG) alfa MAP (estricto) MAP (generalizado) MAP (sog) XCG (sog2) Figura 7: Impacto de α en XCG y MAP inex-2002 (temas CO de INEX 2004; conjunto de evaluación I). nodos ancestros (líneas 8-10) y descendientes (líneas 12-14) ajustando los puntajes de estos nodos. Las rutinas de recorrido de árboles, Arriba y Abajo, se muestran en la figura 6. El procedimiento Up elimina cada nodo ancestro de S, ajusta sus valores de frecuencia de término, recalcula su puntuación y lo vuelve a agregar a S. El ajuste de los valores de frecuencia de término (línea 3) agrega a y.g solo las ocurrencias de términos no reportadas previamente en x. El recalculo de la puntuación en la línea 4 utiliza las ecuaciones 1 y 2. La rutina Down realiza una operación similar en cada descendiente. Sin embargo, dado que el contenido de cada descendiente está completamente contenido en un elemento informado, su puntuación final puede ser calculada, y se elimina de S y se agrega a F. Para determinar la complejidad temporal del algoritmo, primero observe que un nodo puede ser un argumento de Down como máximo una vez. Posteriormente, la bandera reportada de su padre es verdadera. Durante cada llamada a Down, un nodo puede ser movido de S a F, lo que requiere un tiempo O(log n). Por lo tanto, el tiempo total para todas las llamadas a Down es O(n log n), y podemos ignorar temporalmente las líneas 8-10 de la figura 5 al considerar la complejidad temporal del bucle sobre las líneas 2-15. Durante cada iteración de este bucle, se elimina un nodo y cada uno de sus ancestros de una cola de prioridad y luego se vuelven a agregar a la cola de prioridad. Dado que un nodo puede tener como máximo h ancestros, donde h es la altura máxima de cualquier árbol en la colección, cada una de las m iteraciones requiere un tiempo de O(h log n). La combinación de estas observaciones produce una complejidad temporal general de O((n + mh) log n). En la práctica, volver a clasificar un conjunto de resultados de INEX requiere menos de 200 ms en una PC de escritorio de tres años de antigüedad. EVALUACIÓN Ninguna de las métricas descritas en la sección 3.3 se ajusta adecuadamente a la perspectiva de superposición defendida por este documento. Sin embargo, cuando se toman en conjunto, proporcionan información sobre el comportamiento del algoritmo de reordenamiento. Los paquetes de evaluación de INEX (inex_eval e inex_eval_ng) se utilizaron para calcular los valores de las métricas inex-2002 e inex-2003. Los valores de las métricas XCG fueron calculados utilizando el software proporcionado por sus inventores [11]. La Figura 7 representa juntas las tres variantes de la métrica MAP inex-2002 junto con la métrica XCG. Los valores para estas métricas 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Precisión Media Promedio (inex-2003) alfa estricto, superposición no considerada estricto, superposición considerada generalizado, superposición no considerada generalizado, superposición considerada Figura 8: Impacto de α en MAP inex-2003 (temas CO de INEX 2004; conjunto de evaluación I). se trazan para valores de α entre 0.0 y 1.0. Recordando que la métrica XCG está diseñada para penalizar la superposición, mientras que la métrica inex-2002 ignora la superposición, el conflicto entre las métricas es evidente. Los valores de MAP en un extremo (α = 0.0) y el valor de XCG en el otro extremo (α = 1.0) representan un rendimiento de recuperación comparable a los mejores sistemas en INEX 2004 [8,12]. La Figura 8 muestra los valores de la métrica MAP inex-2003 para dos cuantificaciones, con y sin consideración de la superposición. Una vez más, el conflicto es evidente, con la influencia de α considerablemente disminuida cuando se considera la superposición. 8. ALGORITMO EXTENDIDO Una limitación del algoritmo de reordenamiento es que se utiliza un único peso α para ajustar las puntuaciones tanto de los ancestros como de los descendientes de los elementos informados. Una extensión obvia es usar diferentes pesos en estos dos casos. Además, se utiliza el mismo peso independientemente de cuántas veces un elemento esté contenido en un elemento informado. Por ejemplo, un párrafo puede formar parte de una sección reportada y luego formar parte de un artículo reportado. Dado que el usuario puede haber visto este párrafo dos veces, su puntuación debería ser reducida aún más aumentando el valor del peso. Motivado por estas observaciones, el algoritmo de reordenamiento puede ser extendido con una serie de pesos 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0, donde βj es el peso aplicado a un nodo que ha sido descendiente de un nodo reportado j veces. Ten en cuenta que un límite superior en M es h, la altura máxima de cualquier árbol XML en la colección. Sin embargo, en la práctica es probable que M sea relativamente pequeño (quizás 3 o 4). La Figura 9 presenta reemplazos para las rutinas de Subir y Bajar de la Figura 6, incorporando esta serie de pesas. Se requiere un campo adicional en cada nodo, de la siguiente manera: x.j - conteo descendente El valor de x.j se establece inicialmente en cero en todos los nodos y se incrementa cada vez que se llama a Down con x como su argumento. Al calcular la puntuación del nodo, el valor de x.j selecciona 1 Up(x, y) ≡ 2 si no y.reported entonces 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recalcular y.score 6 S.add(y) 8 si y no es un nodo raíz entonces 9 Up (x, y.padre) 10 fin si 11 fin si 12 13 Down(x) ≡ 14 si x.j < M entonces 15 x.j ← x.j + 1 16 si no x.reported entonces 17 S.remove(x) 18 recalcular x.score 19 S.add(x) 20 fin si 21 para cada y ∈ x.hijos hacer 22 Down (y) 23 fin hacer 24 fin si Figura 9: Rutinas extendidas de recorrido de árbol. el peso a aplicar al nodo ajustando el valor de xt en la ecuación 1, de la siguiente manera: xt = βx.j · (ft − α · gt) (3) donde ft y gt son los componentes de x.f y x.g correspondientes al término t. Se requieren algunos cambios adicionales para extender Up y Down. La rutina Up devuelve inmediatamente (línea 2) si su argumento ya ha sido reportado, ya que las frecuencias de términos ya han sido ajustadas en sus ancestros. El procedimiento Down no informa su argumento, sino que vuelve a calcular su puntuación y la agrega de nuevo a S. Un nodo no puede ser un argumento de Down más de M +1 veces, lo que a su vez implica una complejidad temporal total de O((nM + mh) log n). Dado que M ≤ h y m ≤ n, la complejidad temporal también es O(nh log n). DISCUSIÓN CONCLUSIVA Al generar resultados de recuperación en una colección de XML, se debe tolerar cierta superposición en los resultados, lo cual puede ser beneficioso. Por ejemplo, cuando un elemento altamente exhaustivo y bastante específico (3,2) contiene un elemento mucho más pequeño (2,3), ambos deben ser informados al usuario, y los algoritmos de recuperación y las métricas de evaluación deben respetar esta relación. El algoritmo presentado en este documento controla la superposición ponderando los términos que aparecen en los elementos informados para reflejar su menor importancia. Otros enfoques también pueden ayudar a controlar la superposición. Por ejemplo, cuando se presentan los resultados de recuperación de XML a los usuarios, puede ser deseable agrupar elementos relacionados estructuralmente juntos, ilustrando visualmente las relaciones entre ellos. Si bien este estilo de interfaz de usuario puede ayudar a un usuario a lidiar con la superposición, la estrategia presentada en este documento sigue siendo aplicable, al determinar los mejores elementos para incluir en cada grupo. En Waterloo, seguimos desarrollando y probando nuestras ideas para INEX 2005. En particular, estamos investigando métodos para aprender los pesos α y βj. También estamos reevaluando nuestro enfoque en las estadísticas de documentos y examinando ajustes apropiados al parámetro k1 a medida que cambian los pesos de los términos [20]. 10. AGRADECIMIENTOS Gracias a Gabriella Kazai y Arjen de Vries por proporcionar una versión temprana de su software para calcular la métrica XCG, y gracias a Phil Tilker y Stefan B¨uttcher por su ayuda con la evaluación experimental. En parte, la financiación para este proyecto fue proporcionada por IBM Canadá a través del Instituto Nacional de Investigación de Software. 11. REFERENCIAS [1] N. Bruno, N. Koudas y D. Srivastava. Uniones de ramas holísticas: Coincidencia óptima de patrones XML. En Actas de la Conferencia Internacional ACM SIGMOD 2002 sobre la Gestión de Datos, páginas 310-321, Madison, Wisconsin, junio de 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y. Masa y A. Soffer. Buscando documentos XML a través de fragmentos XML. En Actas de la 26ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 151-158, Toronto, Canadá, 2003. [3] C. L. A. Clarke y P. L. Tilker. Experimentos MultiText para INEX 2004. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai y M. Lalmas. Tolerancia a la irrelevancia: Una evaluación orientada al esfuerzo del usuario de sistemas de recuperación sin unidad de recuperación predefinida. En las Actas de la Conferencia RIAO 2004, páginas 463-473, Aviñón, Francia, abril de 2004. [5] D. DeHaan, D. Toman, M. P. Consens y M. T. ¨Ozsu. Una traducción exhaustiva de XQuery a SQL utilizando codificación dinámica de intervalos. En Actas de la Conferencia Internacional ACM SIGMOD 2003 sobre la Gestión de Datos, San Diego, junio de 2003. [6] N. Fuhr y K. Großjohann. XIRQL: Un lenguaje de consulta para la recuperación de información en documentos XML. En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 172-180, Nueva Orleans, septiembre de 2001. [7] N. Fuhr, M. Lalmas y S. Malik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Segundo Taller (INEX 2003), Dagstuhl, Alemania, diciembre de 2003. [8] N. Fuhr, M. Lalmas, S. Malik y Zoltán Szlávik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Tercer Taller (INEX 2004), Dagstuhl, Alemania, diciembre de 2004. Publicado como Avances en la Recuperación de Información XML, Notas de Conferencia en Ciencias de la Computación, volumen 3493, Springer, 2005. [9] K. J¨avelin y J. Kek¨al¨ainen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, y B. Sigurbjörnsson. Normalización de longitud en la recuperación de XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 80-87, Sheffield, Reino Unido, julio de 2004. [11] G. Kazai, M. Lalmas y A. P. de Vries. El problema de superposición en la evaluación de la recuperación de XML orientada al contenido. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 72-79, Sheffield, Reino Unido, julio de 2004. [12] G. Kazai, M. Lalmas y A. P. de Vries. Pruebas de confiabilidad para las métricas XCG e inex-2002. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola y T. Aalto. TRIX 2004 - Luchando con la superposición. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [14] S. Liu, Q. Zou y W. W. Chu. Indexación y clasificación configurables para la recuperación de información en XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 88-95, Sheffield, Reino Unido, julio de 2004. [15] Y. Masa y M. Mandelbrot. Recuperando los componentes XML más relevantes. En las Actas del Taller INEX 2003, Dagstuhl, Alemania, diciembre de 2003. [16] Y. Masa y M. Mandelbrot. Clasificación de componentes y refinamiento automático de consultas para la recuperación de XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [17] P. Ogilvie y J. Callan. Modelos de lenguaje jerárquicos para la recuperación de componentes XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [18] J. Pehcevski, J. A. Thom y A. Vercoustre. Recuperación híbrida de XML revisitada. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [19] B. Piwowarski y M. Lalmas. Proporcionando evaluaciones de relevancia consistentes y exhaustivas para la evaluación de recuperación de XML. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 361-370, Washington, DC, noviembre de 2004. [20] S. Robertson, H. Zaragoza y M. Taylor. Extensión simple de BM25 a múltiples campos ponderados. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 42-50, Washington, DC, noviembre de 2004. [21] S. E. Robertson, S. Walker y M. Beaulieu. Okapi en TREC-7: Búsqueda automática, filtrado, VLC y pista interactiva. En Actas de la Séptima Conferencia de Recuperación de Texto, Gaithersburg, MD, noviembre de 1998. [22] A. Trotman y B. Sigurbjörnsson. NEXI, ahora y después. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski y P. Gallinari. Un álgebra para consultas estructuradas en redes bayesianas. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "cumulated gain": {
            "translated_key": "ganancia acumulada",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Controlling Overlap in Content-Oriented XML Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of XML documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
                "This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents.",
                "The test collection developed by the INitiative for the Evaluation of XML Retrieval (INEX) forms the basis for the evaluation.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "INTRODUCTION The representation of documents in XML provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an XML information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in XML.",
                "Figure 1 provides an example of a journal article encoded in XML, illustrating many of the important characteristics of XML documents.",
                "Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words.",
                "Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate.",
                "Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs.",
                "Each of these characteristics affects the design of an XML IR system, and each leads to fundamental problems that must be solved in an successful system.",
                "Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper.",
                "The article of figure 1 may be viewed as an XML tree, as illustrated in figure 2.",
                "Formally, a collection of XML documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes.",
                "For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example XML tree. of x.",
                "Since an element may be represented by the node at its root, the output of an XML IR system may be viewed as a ranked list of the top-m nodes.",
                "The direct application of a standard relevance ranking technique to a set of XML elements can produce a result in which the top ranks are dominated by many structurally related elements.",
                "A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article.",
                "For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms.",
                "If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content.",
                "One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it.",
                "Unfortunately, this approach destroys some of the possible benefits of XML IR.",
                "For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts.",
                "In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements.",
                "Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6].",
                "This paper presents a method for controlling overlap.",
                "Starting with an initial element ranking, a re-ranking algorithm adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
                "For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced.",
                "The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20].",
                "Extending that approach, the re-ranking algorithm varies weights dynamically as elements are processed.",
                "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a baseline retrieval method is presented in section 4.",
                "This baseline method represents a reasonable adaptation of standard IR technology to XML.",
                "Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point.",
                "A re-ranking algorithm implementing this strategy is presented in section 6 and evaluated in section 7.",
                "Section 8 discusses an extended version of the algorithm. 2.",
                "BACKGROUND This section provides a general overview of XML information retrieval and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
                "Much research in the area of XML retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1].",
                "Here, we take a content oriented IR perceptive, focusing on XML documents that primarily contain natural language data and queries that are primarily expressed in natural language.",
                "We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need.",
                "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional information retrieval applications the standard unit of retrieval is taken to be the document.",
                "Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages.",
                "When applying standard relevance ranking techniques in the context of XML IR, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
                "In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole.",
                "If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article.",
                "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an XML IR system might potentially retrieve any element, many elements may not be appropriate as retrieval results.",
                "This is usually the case when elements contain very little text [10].",
                "For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself.",
                "Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user.",
                "An effective XML IR system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18].",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (INEX) has encouraged research into XML information retrieval technology [7,8].",
                "INEX is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
                "Over 50 groups participated in INEX 2004, and the conference has become as influential in the area of XML IR as TREC is in other IR areas.",
                "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by INEX.",
                "Overlap causes considerable problems with retrieval evaluation, and the INEX organizers and participants have wrestled with these problems since the beginning.",
                "While substantial progress has been made, these problem are still not completely solved.",
                "Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of INEX retrieval evaluation and discuss both current and proposed evaluation metrics.",
                "Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3.",
                "INEX 2004 Space limitations prevent the inclusion of more than a brief summary of INEX 2004 tasks and evaluation methodology.",
                "For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, INEX 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002.",
                "Each document is encoded in XML using a common DTD, with the document of figures 1 and 2 providing one example.",
                "At INEX 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics.",
                "The two tasks differed in the types of topics they used.",
                "For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection.",
                "For this task, the IR system is required to select the elements to be returned.",
                "For the other task, the contentand-structure or CAS task, the topics are written in an XML query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy.",
                "Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description.",
                "In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants.",
                "Each topic includes a short keyword query, which is executed over the collection by each participating group on their own XML IR system.",
                "Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since XML IR is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient.",
                "Instead, the INEX organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic.",
                "A four-point scale is used in both dimensions.",
                "Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant.",
                "Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at INEX 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values.",
                "One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others.",
                "This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant.",
                "Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity.",
                "Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity.",
                "This paper reports results of this metric using all three of these quantization functions.",
                "Since this metric was first introduced at INEX 2002, it is generally referred as the inex-2002 metric.",
                "The inex-2002 metric does not penalize overlap.",
                "In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank.",
                "To address this problem, Kazai et al. [11] propose an XML <br>cumulated gain</br> metric, which compares the <br>cumulated gain</br> [9] of a ranked list to an ideal gain vector.",
                "This ideal gain vector is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path.",
                "Thus, the XCG metric rewards retrieval runs that avoid overlap.",
                "While XCG was not used officially at INEX 2004, a version of it is likely to be used in the future.",
                "At INEX 2003, yet another metric was introduced to ameliorate the perceived limitations of the inex-2002 metric.",
                "This inex-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them.",
                "Two versions were created, one that considered only component size and another that considered both size and overlap.",
                "While the inex-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4.",
                "BASELINE RETRIEVAL METHOD This section provides an overview of baseline XML information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3].",
                "This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the XML information retrieval task.",
                "The MultiText system performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
                "To support retrieval from XML and other structured document types, the system provides generalized queries of the form: rank X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms.",
                "For our INEX 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections.",
                "Prior to INEX 2004, the INEX collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names.",
                "Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received.",
                "Automating this selection process is planned as future work.",
                "For INEX 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.",
                "For example, keyword field of topic 166 +tree edit distance + XML -image became the four-term query $tree $edit $distance $xml where the $ operator within a quoted string stems the term that follows it.",
                "Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞.",
                "Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(inex-2002) k1 strict generalized sog Figure 3: Impact of k1 on inex-2002 mean average precision with b = 0.75 (INEX 2003 CO topics).",
                "Prior to INEX 2004, the INEX 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.",
                "For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article.",
                "These statistics are used for ranking all element types.",
                "Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length.",
                "The use of article statistics for all element types might be questioned.",
                "This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.",
                "The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics.",
                "Nonetheless, we plan to examine this issue again in the future.",
                "In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose.",
                "Prior to INEX 2004, we trained the MultiText system using the INEX 2003 queries.",
                "As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system.",
                "The results were surprising.",
                "Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions.",
                "In our experience, optimal values for k1 are typically in the range 0.0 to 2.0.",
                "In this case, large values are required for good performance.",
                "Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization.",
                "Similar improvements are seen under the generalized and sog quantizations.",
                "In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).",
                "After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our INEX 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5.",
                "CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements.",
                "At a conceptual level, re-ranking proceeds as follows: 1.",
                "Report the highest ranking element. 2.",
                "Adjust the scores of the unreported elements. 3.",
                "Repeat steps 1 and 2 until m elements are reported.",
                "One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements.",
                "For example, assume a paragraph with score p is reported in step 1.",
                "In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score.",
                "In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion.",
                "That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages.",
                "A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two.",
                "Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness.",
                "Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body.",
                "In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body.",
                "Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported.",
                "The next section presents and analysis a simple re-ranking algorithm that follows this strategy.",
                "The algorithm is evaluated experimentally in section 7.",
                "One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears.",
                "In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6.",
                "RE-RANKING ALGORITHM The re-ranking algorithm operates over XML trees, such as the one appearing in figure 2.",
                "Input to the algorithm is a list of n elements ranked according to their initial BM25 scores.",
                "During the initial ranking the XML tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |.",
                "Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores.",
                "An element is represented by the node x ∈ N at its root.",
                "Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - term frequency vector x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses.",
                "The vector x.f contains term frequency information corresponding to each term in the query.",
                "The vector x.g is initially zero and is updated by the algorithm as elements are reported.",
                "The score field contains the current BM25 score for the element, which will change as the values in x.g change.",
                "The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g.",
                "Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the re-ranking algorithm, nodes are stored in priority queues, ordered by decreasing score.",
                "Each priority queue PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
                "The core of the re-ranking algorithm is presented in figure 5.",
                "The algorithm takes as input the priority queue S containing the initial ranking, and produces the top-m reranked nodes in the priority queue F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
                "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a priority queue S, containing XML nodes ranked by their initial scores, and returns its results in priority queue F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
                "The tree traversal routines, Up and Down are given in figure 6.",
                "The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2.",
                "The Down routine performs a similar operation on each descendant.",
                "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the time complexity of the algorithm, first note that a node may be an argument to Down at most once.",
                "Thereafter, the reported flag of its parent is true.",
                "During each call to Down a node may be moved from S to F, requiring O(log n) time.",
                "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the time complexity of the loop over lines 2-15.",
                "During each iteration of this loop, a node and each of its ancestors are removed from a priority queue and then added back into a priority queue.",
                "Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time.",
                "Combining these observations produces an overall time complexity of O((n + mh) log n).",
                "In practice, re-ranking an INEX result set requires less than 200ms on a three-year-old desktop PC. 7.",
                "EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper.",
                "Nonetheless, when taken together they provide insight into the behaviour of the re-ranking algorithm.",
                "The INEX evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the inex-2002 and inex-2003 metrics.",
                "Values for the XCG metrics were computed using software supplied by its inventors [11].",
                "Figure 7 plots the three variants of inex-2002 MAP metric together with the XCG metric.",
                "Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on inex-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0.",
                "Recalling that the XCG metric is designed to penalize overlap, while the inex-2002 metric ignores overlap, the conflict between the metrics is obvious.",
                "The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at INEX 2004 [8,12].",
                "Figure 8 plots values of the inex-2003 MAP metric for two quantizations, with and without consideration of overlap.",
                "Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8.",
                "EXTENDED ALGORITHM One limitation of the re-ranking algorithm is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements.",
                "An obvious extension is to use different weights in these two cases.",
                "Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element.",
                "For example, a paragraph may form part of a reported section and then form part of a reported article.",
                "Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight.",
                "Motivated by these observations, the re-ranking algorithm may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times.",
                "Note that an upper bound on M is h, the maximum height of any XML tree in the collection.",
                "However, in practice M is likely to be relatively small (perhaps 3 or 4).",
                "Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights.",
                "One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument.",
                "When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down.",
                "The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors.",
                "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall time complexity of O((nM + mh) log n).",
                "Since M ≤ h and m ≤ n, the time complexity is also O(nh log n). 9.",
                "CONCLUDING DISCUSSION When generating retrieval results over an XML collection, some overlap in the results should be tolerated, and may be beneficial.",
                "For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship.",
                "The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance.",
                "Other approaches may also help to control overlap.",
                "For example, when XML retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them.",
                "While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster.",
                "At Waterloo, we continue to develop and test our ideas for INEX 2005.",
                "In particular, we are investigating methods for learning the α and βj weights.",
                "We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10.",
                "ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation.",
                "In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11.",
                "REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava.",
                "Holistic twig joins: Optimal XML pattern matching.",
                "In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
                "Mass, and A. Soffer.",
                "Searching XML documents via XML fragments.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker.",
                "MultiText experiments for INEX 2004.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas.",
                "Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit.",
                "In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu.",
                "A comprehensive XQuery to SQL translation using dynamic interval encoding.",
                "In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann.",
                "XIRQL: A query language for information retrieval in XML documents.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Second Workshop (INEX 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Third Workshop (INEX 2004), Dagstuhl, Germany, December 2004.",
                "Published as Advances in XML Information Retrieval, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen.",
                "<br>cumulated gain</br>-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson.",
                "Length normalization in XML retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "The overlap problem in content-oriented XML retrieval evaluation.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "Reliability tests for the XCG and inex-2002 metrics.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto.",
                "TRIX 2004 - Struggling with the overlap.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu.",
                "Configurable indexing and ranking for XML information retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 88-95, Sheffield, UK, July 2004. [15] Y.",
                "Mass and M. Mandelbrod.",
                "Retrieving the most relevant XML components.",
                "In INEX 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y.",
                "Mass and M. Mandelbrod.",
                "Component ranking and automatic query refinement for XML retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan.",
                "Hierarchical language models for XML component retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [18] J. Pehcevski, J.",
                "A. Thom, and A. Vercoustre.",
                "Hybrid XML retrieval re-visited.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas.",
                "Providing consistent and exhaustive relevance assessments for XML retrieval evaluation.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor.",
                "Simple BM25 extension to multiple weighted fields.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu.",
                "Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track.",
                "In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson.",
                "NEXI, now and next.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari.",
                "An algebra for structured queries in bayesian networks.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]."
            ],
            "original_annotated_samples": [
                "To address this problem, Kazai et al. [11] propose an XML <br>cumulated gain</br> metric, which compares the <br>cumulated gain</br> [9] of a ranked list to an ideal gain vector.",
                "<br>cumulated gain</br>-based evaluation of IR techniques."
            ],
            "translated_annotated_samples": [
                "Para abordar este problema, Kazai et al. [11] proponen una métrica de <br>ganancia acumulada</br> XML, que compara la <br>ganancia acumulada</br> [9] de una lista clasificada con un vector de ganancia ideal.",
                "Evaluación basada en la <br>ganancia acumulada</br> de técnicas de recuperación de información."
            ],
            "translated_text": "Controlando la superposición en la recuperación XML orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca RESUMEN La aplicación directa de técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos XML a menudo produce un conjunto de resultados en el que los primeros puestos están dominados por un gran número de elementos tomados de un pequeño número de documentos altamente relevantes. Este documento presenta y evalúa un algoritmo que vuelve a clasificar este conjunto de resultados, con el objetivo de minimizar el contenido redundante mientras se preservan los beneficios de la recuperación de elementos, incluido el beneficio de identificar componentes centrados en el tema contenidos en documentos relevantes. La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la Recuperación XML (INEX) constituye la base para la evaluación. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Búsqueda y Recuperación de Información Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. La representación de documentos en XML brinda una oportunidad para que los sistemas de recuperación de información aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias. En respuesta a una consulta de usuario, un sistema de recuperación de información XML podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes. Esta facilidad es de particular beneficio cuando una colección contiene documentos muy largos, como manuales de productos o libros, donde el usuario debe ser dirigido a las partes más relevantes de estos documentos. La Figura 1 proporciona un ejemplo de un artículo de revista codificado en XML, ilustrando muchas de las características importantes de los documentos XML. Las etiquetas indican el inicio y el final de cada elemento, con elementos que varían ampliamente en tamaño, desde una palabra hasta miles de palabras. Algunos elementos, como párrafos y secciones, pueden presentarse razonablemente al usuario como resultados de búsqueda, pero otros no son apropiados. Los elementos se superponen entre sí: los artículos contienen secciones, las secciones contienen subsecciones y las subsecciones contienen párrafos. Cada una de estas características afecta el diseño de un sistema de IR XML, y cada una conlleva problemas fundamentales que deben resolverse en un sistema exitoso. La mayoría de estos problemas fundamentales pueden resolverse mediante la cuidadosa adaptación de técnicas estándar de IR, pero los problemas causados por la superposición son únicos en esta área [4,11] y constituyen el enfoque principal de este artículo. El artículo de la figura 1 puede ser visto como un árbol XML, como se ilustra en la figura 2. Formalmente, una colección de documentos XML puede ser representada como un bosque de árboles ordenados y enraizados, que consiste en un conjunto de nodos N y un conjunto de aristas dirigidas E que conectan estos nodos. Para cada nodo x ∈ N, la notación x.parent se refiere al nodo padre de x, si existe, y la notación x.children se refiere al conjunto de nodos hijos de x. Dado que un elemento puede estar representado por el nodo en su raíz, la salida de un sistema de IR XML puede ser vista como una lista clasificada de los m nodos principales. La aplicación directa de una técnica estándar de clasificación de relevancia a un conjunto de elementos XML puede producir un resultado en el que los primeros puestos están dominados por muchos elementos estructuralmente relacionados. Una sección con una puntuación alta probablemente contenga varios párrafos con una puntuación alta y esté contenida en un artículo con una puntuación alta. Por ejemplo, muchos de los elementos en la figura 2 recibirían una puntuación alta en los algoritmos de compresión de índices de texto de consulta de palabras clave. Si cada uno de estos elementos se presenta a un usuario como un resultado individual y separado, puede perder mucho tiempo revisando y rechazando contenido redundante. Una posible solución es informar solo el elemento de mayor puntuación a lo largo de un camino dado en el árbol, y eliminar de los rangos inferiores cualquier elemento que lo contenga o esté contenido en él. Desafortunadamente, este enfoque destruye algunos de los posibles beneficios de XML IR. Por ejemplo, un elemento externo puede contener una cantidad sustancial de información que no aparece en un elemento interno, pero el elemento interno puede estar fuertemente enfocado en el tema de la consulta y proporcionar un breve resumen de los conceptos clave. En tales casos, es razonable informar sobre elementos que contienen, o están contenidos en, elementos de rango superior. Incluso cuando un libro entero es relevante, un usuario aún puede desear que se destaquen los párrafos más importantes, para guiar su lectura y ahorrar tiempo [6]. Este documento presenta un método para controlar la superposición. A partir de una clasificación inicial de elementos, un algoritmo de re-clasificación ajusta las puntuaciones de los elementos de menor clasificación que contienen, o están contenidos dentro de, elementos de mayor clasificación, reflejando el hecho de que esta información puede ser ahora redundante. Por ejemplo, una vez que un elemento que representa una sección aparece en la clasificación, las puntuaciones de los párrafos que contiene y del artículo que lo contiene se reducen. La inspiración para esta estrategia proviene parcialmente del trabajo reciente sobre la recuperación de documentos estructurados, donde los términos que aparecen en diferentes campos, como el título y el cuerpo, reciben diferentes pesos [20]. Extendiendo ese enfoque, el algoritmo de reordenamiento varía los pesos dinámicamente a medida que se procesan los elementos. El resto del documento está organizado de la siguiente manera: Después de una discusión sobre el trabajo de antecedentes y la metodología de evaluación, se presenta un método de recuperación de referencia en la sección 4. Este método de referencia representa una adaptación razonable de la tecnología estándar de IR al XML. La sección 5 luego describe una estrategia para controlar la superposición, utilizando el método de línea base como punto de partida. Un algoritmo de reordenamiento que implementa esta estrategia se presenta en la sección 6 y se evalúa en la sección 7. La sección 8 discute una versión extendida del algoritmo. 2. ANTECEDENTES Esta sección proporciona una visión general de la recuperación de información XML y discute trabajos relacionados, con énfasis en los problemas fundamentales mencionados en la introducción. Mucha investigación en el área de recuperación de XML lo ve desde una perspectiva de base de datos tradicional, preocupándose por problemas como la implementación de lenguajes de consulta estructurados [5] y el procesamiento de joins [1]. Aquí adoptamos una perspectiva de IR orientada al contenido, centrándonos en documentos XML que contienen principalmente datos en lenguaje natural y consultas que están principalmente expresadas en lenguaje natural. Suponemos que estas consultas indican únicamente la naturaleza del contenido deseado, no su estructura, y que el papel del sistema de RI es determinar qué elementos satisfacen mejor la necesidad de información subyacente. Otra investigación en IR ha considerado consultas mixtas, en las que se especifican tanto requisitos de contenido como estructurales [2,6,14,17,23]. 2.1 Estadísticas de Términos y Documentos En las aplicaciones tradicionales de recuperación de información, la unidad estándar de recuperación se considera que es el documento. Dependiendo de la aplicación, este término podría interpretarse para abarcar muchos objetos diferentes, incluyendo páginas web, artículos de periódico y mensajes de correo electrónico. Al aplicar técnicas estándar de clasificación de relevancia en el contexto de la RI XML, un enfoque natural es tratar cada elemento como un documento separado, con estadísticas de términos disponibles para cada uno [16]. Además, la mayoría de las técnicas de clasificación requieren estadísticas globales (por ejemplo, frecuencia inversa de documentos) calculadas sobre la colección en su totalidad. Si consideramos que esta colección incluye todos los elementos que podrían ser devueltos por el sistema, una ocurrencia específica de un término puede aparecer en varios documentos diferentes, quizás en elementos que representan un párrafo, una subsección, una sección y un artículo. No es apropiado calcular la frecuencia inversa de documentos bajo la suposición de que el término está contenido en todos estos elementos, ya que el número de elementos que contienen un término depende completamente del arreglo estructural de los documentos [13,23]. 2.2 Elementos Recuperables Si bien un sistema de recuperación de información XML podría potencialmente recuperar cualquier elemento, muchos elementos pueden no ser apropiados como resultados de recuperación. Esto suele ser el caso cuando los elementos contienen muy poco texto [10]. Por ejemplo, un título de sección que contenga solo los términos de búsqueda puede recibir una puntuación alta de un algoritmo de clasificación, pero por sí solo tendría un valor limitado para un usuario, quien podría preferir la sección real en sí misma. Otros elementos pueden reflejar la estructura física de los documentos, en lugar de la estructura lógica, lo cual puede tener poco o ningún significado para un usuario. Un sistema de recuperación de información XML efectivo debe devolver solo aquellos elementos que tengan suficiente contenido para ser utilizables y puedan funcionar como objetos independientes [15,18]. Componentes estándar de documentos como párrafos, secciones, subsecciones y resúmenes generalmente cumplen con estos requisitos; los títulos, frases en cursiva y campos de metadatos individuales a menudo no lo hacen. 2.3 Metodología de Evaluación En los últimos tres años, la Iniciativa para la Evaluación de la Recuperación de Información XML (INEX) ha fomentado la investigación en tecnología de recuperación de información XML [7,8]. INEX es una serie de conferencias experimentales, similar a TREC, en la que grupos de diferentes instituciones completan una o más tareas experimentales utilizando sus propias herramientas y sistemas, y comparan sus resultados en la propia conferencia. Más de 50 grupos participaron en INEX 2004, y la conferencia se ha convertido en tan influyente en el área de la RI XML como lo es TREC en otras áreas de la RI. La investigación descrita en este artículo, al igual que gran parte del trabajo relacionado que cita, depende de las colecciones de pruebas desarrolladas por INEX. La superposición causa problemas considerables en la evaluación de la recuperación, y los organizadores y participantes de INEX han luchado con estos problemas desde el principio. Aunque se ha logrado un progreso sustancial, estos problemas aún no están completamente resueltos. Kazai et al. [11] proporcionan una exposición detallada del problema de superposición en el contexto de la evaluación de recuperación de INEX y discuten tanto las métricas de evaluación actuales como las propuestas. Muchas de estas métricas se aplican para evaluar los experimentos reportados en este artículo, y se describen brevemente en la siguiente sección. 3. Las limitaciones de espacio impiden incluir más que un breve resumen de las tareas y metodología de evaluación de INEX 2004. Para obtener información detallada, se deben consultar las actas de la conferencia en sí [8]. 3.1 Tareas Para las principales tareas experimentales, a los participantes de INEX 2004 se les proporcionó una colección de 12,107 artículos tomados de las revistas y publicaciones de la IEEE Computer Societies entre 1995 y 2002. Cada documento está codificado en XML utilizando una DTD común, siendo el documento de las figuras 1 y 2 un ejemplo. En INEX 2004, las dos principales tareas experimentales fueron ambas tareas de recuperación ad hoc, investigando el rendimiento de sistemas que buscan en una colección estática utilizando temas previamente no vistos. Las dos tareas diferían en los tipos de temas que utilizaban. Para una tarea, la tarea de solo contenido o CO, los temas consisten en declaraciones cortas en lenguaje natural sin hacer referencia directa a la estructura de los documentos en la colección. Para esta tarea, se requiere que el sistema de IR seleccione los elementos a devolver. Para la otra tarea, la tarea de contenido y estructura o CAS, los temas están escritos en un lenguaje de consulta XML [22] y contienen referencias explícitas a la estructura del documento, que el sistema de IR debe intentar satisfacer. Dado que el trabajo descrito en este documento se enfoca en la tarea de solo contenido, donde el sistema de IR no recibe orientación sobre los elementos a devolver, la tarea de CAS se ignora en el resto de nuestra descripción. En 2004, los organizadores de la conferencia seleccionaron 40 nuevos temas de CO de las contribuciones proporcionadas por los participantes de la conferencia. Cada tema incluye una breve consulta de palabras clave, la cual es ejecutada sobre la colección por cada grupo participante en su propio sistema de IR XML. Cada grupo podría presentar hasta tres ejecuciones experimentales que consistieran en los primeros m = 1500 elementos para cada tema. 3.2 Evaluación de Relevancia Dado que la RI XML se preocupa por localizar aquellos elementos que proporcionan una cobertura completa de un tema mientras contienen la menor cantidad de información irrelevante posible, los juicios simples de relevante vs. no relevante no son suficientes. En cambio, los organizadores de INEX adoptaron dos dimensiones para la evaluación de relevancia: la dimensión de exhaustividad refleja el grado en que un elemento abarca el tema, y la dimensión de especificidad refleja el grado en que un elemento se enfoca en el tema. Se utiliza una escala de cuatro puntos en ambas dimensiones. Por lo tanto, un elemento (3,3) es altamente exhaustivo y altamente específico, un elemento (1,3) es marginalmente exhaustivo y altamente específico, y un elemento (0,0) no es relevante. Información adicional sobre la metodología de evaluación se puede encontrar en Piwowarski y Lalmas [19], quienes proporcionan una justificación detallada. 3.3 Métricas de Evaluación La métrica de evaluación principal utilizada en INEX 2004 es una versión de la precisión promedio media (MAP), ajustada por diversas funciones de cuantificación para dar diferentes pesos a diferentes elementos, dependiendo de sus valores de exhaustividad y especificidad. Una variante, la función de cuantización estricta asigna un peso de 1 a los elementos (3,3) y un peso de 0 a todos los demás. Esta variante es esencialmente el valor MAP familiar, con elementos (3,3) tratados como relevantes y todos los demás elementos tratados como no relevantes. Otras funciones de cuantización están diseñadas para otorgar crédito parcial a elementos que son aproximaciones cercanas, debido a la falta de exhaustividad y/o especificidad. Tanto la función de cuantificación generalizada como la función de generalización orientada a la especificidad (sog) acreditan elementos según su grado de relevancia [11], siendo que la segunda función pone mayor énfasis en la especificidad. Este documento informa los resultados de esta métrica utilizando las tres funciones de cuantización. Desde que esta métrica fue introducida por primera vez en INEX 2002, generalmente se le conoce como la métrica inex-2002. La métrica inex-2002 no penaliza la superposición. En particular, tanto las funciones de cuantificación generalizadas como las de sog otorgan crédito parcial a un casi acierto incluso cuando se informa un elemento (3,3) que se superpone a él en un rango más alto. Para abordar este problema, Kazai et al. [11] proponen una métrica de <br>ganancia acumulada</br> XML, que compara la <br>ganancia acumulada</br> [9] de una lista clasificada con un vector de ganancia ideal. Este vector de ganancia ideal se construye a partir de las valoraciones de relevancia al eliminar la superposición y retener solo el mejor elemento a lo largo de un camino dado. Por lo tanto, la métrica XCG recompensa las ejecuciones de recuperación que evitan la superposición. Aunque XCG no se utilizó oficialmente en INEX 2004, es probable que se utilice una versión de él en el futuro. En INEX 2003, se introdujo otra métrica para mejorar las limitaciones percibidas de la métrica inex-2002. Este métrico inex-2003 extiende las definiciones de precisión y exhaustividad para considerar tanto el tamaño de los componentes informados como la superposición entre ellos. Se crearon dos versiones, una que consideraba solo el tamaño de los componentes y otra que consideraba tanto el tamaño como la superposición. Si bien la métrica inex-2003 presenta anomalías no deseadas [11] y no se utilizó en 2004, se informan valores en la sección de evaluación para proporcionar un instrumento adicional para investigar la superposición. 4. MÉTODO DE RECUPERACIÓN DE BASELINE Esta sección proporciona una descripción general del método de recuperación de información XML de base actualmente utilizado en el sistema MultiText IR, desarrollado por el Grupo de Recuperación de Información de la Universidad de Waterloo [3]. Este método de recuperación resulta de la adaptación y ajuste de la medida Okapi BM25 [21] a la tarea de recuperación de información en XML. El sistema MultiText tuvo un desempeño respetable en INEX 2004, ubicándose entre los diez primeros en todas las funciones de cuantización, y ocupando el primer lugar cuando la función de cuantización enfatizaba la exhaustividad. Para admitir la recuperación de XML y otros tipos de documentos estructurados, el sistema proporciona consultas generalizadas de la forma: clasificar X por Y donde X es una subconsulta que especifica un conjunto de elementos de documentos a clasificar y Y es un vector de subconsultas que especifican términos de recuperación individuales. Para nuestras ejecuciones de INEX 2004, la subconsulta X especificó una lista de elementos recuperables como aquellos con nombres de etiquetas de la siguiente manera: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt. Esta lista incluye entradas bibliográficas (bb) y leyendas de figuras (fig) así como párrafos, secciones y subsecciones. Antes de INEX 2004, la colección de INEX y las evaluaciones de relevancia de INEX 2003 fueron analizadas manualmente para seleccionar estos nombres de etiquetas. Los nombres de las etiquetas fueron seleccionados en base a su frecuencia en la colección, el tamaño promedio de sus elementos asociados y el número relativo de juicios de relevancia positiva que recibieron. Automatizar este proceso de selección está planeado como trabajo futuro. Para INEX 2004, el vector término Y se derivó del tema dividiendo frases en palabras individuales, eliminando palabras vacías y términos negativos (aquellos que comienzan con -), y aplicando un stemmer. Por ejemplo, el campo de palabra clave del tema 166 +distancia de edición de árbol + XML -imagen se convirtió en la consulta de cuatro términos $árbol $edición $distancia $xml donde el operador $ dentro de una cadena entre comillas deriva el término que le sigue. Nuestra implementación de Okapi BM25 se deriva de la fórmula de Robertson et al. [21] al establecer los parámetros k2 = 0 y k3 = ∞. Dado un conjunto de términos Q, a un elemento x se le asigna la puntuación t∈Q w(1) qt (k1 + 1)xt K + xt (1) donde w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = número de documentos en el corpus Dt = número de documentos que contienen t qt = frecuencia con la que t ocurre en el tema xt = frecuencia con la que t ocurre en x K = k1((1 − b) + b · lx/lavg) lx = longitud de x lavg = longitud promedio del documento 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 PrecisiónPromedio(inex-2002) k1 estricto generalizado sog Figura 3: Impacto de k1 en la precisión promedio de inex-2002 con b = 0.75 (temas CO de INEX 2003). Antes de INEX 2004, los temas y juicios de INEX 2003 se utilizaron para ajustar los parámetros b y k1, y el impacto de este ajuste se discute más adelante en esta sección. Para los propósitos de calcular estadísticas a nivel de documento (D, Dt y lavg), un documento se define como un artículo. Estas estadísticas se utilizan para clasificar todos los tipos de elementos. Siguiendo la sugerencia de Kamps et al. [10], los resultados de recuperación se filtran para eliminar elementos muy cortos, aquellos con menos de 25 palabras de longitud. El uso de estadísticas de artículos para todos los tipos de elementos podría ser cuestionado. Este enfoque puede justificarse al considerar la colección como un conjunto de artículos que se pueden buscar utilizando técnicas estándar orientadas a documentos, donde solo se devuelven artículos. El puntaje calculado para un elemento es esencialmente el puntaje que recibiría si se agregara a la colección como un nuevo documento, ignorando los ajustes menores necesarios para las estadísticas a nivel de documento. Sin embargo, planeamos examinar este tema nuevamente en el futuro. En nuestra experiencia, el rendimiento de BM25 suele beneficiarse al ajustar los parámetros b y k1 a la colección, siempre que haya consultas de entrenamiento disponibles con este propósito. Antes de INEX 2004, entrenamos el sistema MultiText utilizando las consultas de INEX 2003. Como punto de partida, utilizamos los valores b = 0.75 y k1 = 1.2, que funcionan bien en colecciones TREC adhoc y se utilizan como valores predeterminados en nuestro sistema. Los resultados fueron sorprendentes. La Figura 3 muestra el resultado de variar k1 con b = 0.75 en los valores de MAP bajo tres funciones de cuantización. En nuestra experiencia, los valores óptimos para k1 suelen estar en el rango de 0.0 a 2.0. En este caso, se requieren valores grandes para un buen rendimiento. Entre k1 = 1.0 y k1 = 6.0, el MAP aumenta en más del 15% bajo la cuantización estricta. Se observan mejoras similares bajo las cuantizaciones generalizada y SOG. Por el contrario, nuestro valor predeterminado de b = 0.75 funciona bien bajo todas las funciones de cuantificación (figura 4). Después de ajustar una amplia gama de valores bajo varias funciones de cuantización, seleccionamos los valores de k = 10.0 y b = 0.80 para nuestros experimentos de INEX 2004, y estos valores se utilizan para los experimentos reportados en la sección 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 PrecisiónPromedioMedia (inex-2002) b estricto generalizado sog Figura 4: Impacto de b en la precisión promedio media de inex-2002 con k1 = 10 (temas CO de INEX 2003). 5. CONTROL DE SUPERPOSICIÓN Comenzando con una clasificación de elementos generada por el método de referencia descrito en la sección anterior, los elementos se vuelven a clasificar para controlar la superposición ajustando de forma iterativa las puntuaciones de aquellos elementos que contienen o están contenidos en elementos de clasificación más alta. A nivel conceptual, la reorganización procede de la siguiente manera: 1. Informe el elemento de rango más alto. Ajustar las puntuaciones de los elementos no reportados. 3. Repetir los pasos 1 y 2 hasta que se informen m elementos. Un enfoque para ajustar las puntuaciones de los elementos no informados en el paso 2 podría basarse en las puntuaciones Okapi BM25 de los elementos involucrados. Por ejemplo, supongamos que se informa un párrafo con una puntuación p en el paso 1. En el paso 2, la sección que contiene el párrafo podría tener su puntuación s reducida en una cantidad α · p para reflejar la contribución reducida que el párrafo debería hacer a la puntuación de las secciones. En un contexto relacionado, Robertson et al. [20] argumentan en contra de la combinación lineal de las puntuaciones de Okapi de esta manera. Ese trabajo considera el problema de asignar diferentes pesos a diferentes campos de documentos, como el título y el cuerpo asociados con páginas web. Un enfoque común para este problema puntúa el título y el cuerpo por separado y genera una puntuación final como una combinación lineal de ambos. Robertson et al. discuten las deficiencias teóricas en este enfoque y demuestran experimentalmente que puede perjudicar realmente la efectividad de la recuperación. En cambio, aplican los pesos a nivel de frecuencia de términos, donde la aparición de un término de consulta t en el título contribuye más al puntaje que una aparición en el cuerpo. En la ecuación 1, xt se convierte en α0 · yt + α1 · zt, donde yt es el número de veces que t aparece en el título y zt es el número de veces que t aparece en el cuerpo. Al traducir este enfoque a nuestro contexto, la contribución de los términos que aparecen en los elementos se reduce dinámicamente a medida que se informan. La siguiente sección presenta y analiza un algoritmo de reordenamiento simple que sigue esta estrategia. El algoritmo se evalúa experimentalmente en la sección 7. Una limitación del algoritmo es que la contribución de los términos que aparecen en los elementos informados se reduce por el mismo factor independientemente del número de elementos informados en los que aparezca. En la sección 8, el algoritmo se extiende para aplicar pesos crecientes, disminuyendo la puntuación, cuando un término aparece en más de un elemento informado. 6. ALGORITMO DE REORDENAMIENTO El algoritmo de reordenamiento opera sobre árboles XML, como el que aparece en la figura 2. La entrada al algoritmo es una lista de n elementos clasificados según sus puntuaciones iniciales de BM25. Durante la clasificación inicial, el árbol XML se reconstruye dinámicamente para incluir solo aquellos nodos con puntuaciones BM25 distintas de cero, por lo que n puede ser considerablemente menor que |N|. La salida del algoritmo es una lista de los primeros m elementos, clasificados según sus puntajes ajustados. Un elemento está representado por el nodo x ∈ N en su raíz. Asociados con este nodo se encuentran campos que almacenan la longitud del elemento, las frecuencias de términos y otra información requerida por el algoritmo de re-ranking, de la siguiente manera: x.f - vector de frecuencia de términos x.g - ajustes de frecuencia de términos x.l - longitud del elemento x.score - puntaje actual de Okapi BM25 x.reported - bandera booleana, inicialmente falsa x.children - conjunto de nodos hijos x.parent - nodo padre, si existe Estos campos se llenan durante el proceso de clasificación inicial y se actualizan a medida que avanza el algoritmo. El vector x.f contiene información de frecuencia de términos correspondiente a cada término en la consulta. El vector x.g es inicialmente cero y se actualiza por el algoritmo a medida que se informan elementos. El campo de puntuación contiene la puntuación BM25 actual para el elemento, la cual cambiará a medida que cambien los valores en x.g. El puntaje se calcula utilizando la ecuación 1, con el valor xt para cada término determinado por una combinación de los valores en x.f y x.g. Dado un término t ∈ Q, sea ft el componente de x.f correspondiente a t, y sea gt el componente de x.g correspondiente a t, entonces: xt = ft − α · gt (2) Para el procesamiento por el algoritmo de reordenamiento, los nodos se almacenan en colas de prioridad, ordenadas por puntaje decreciente. Cada cola de prioridad PQ admite tres operaciones: PQ.front() - devuelve el nodo con la puntuación más alta, PQ.add(x) - agrega el nodo x a la cola, PQ.remove(x) - elimina el nodo x de la cola. Cuando se implementan utilizando estructuras de datos estándar, la operación front requiere tiempo O(1), y las otras operaciones requieren tiempo O(log n), donde n es el tamaño de la cola. El núcleo del algoritmo de reordenamiento se presenta en la figura 5. El algoritmo toma como entrada la cola de prioridad S que contiene la clasificación inicial, y produce los primeros m nodos reordenados en la cola de prioridad F. Después de inicializar F como vacío en la línea 1, el algoritmo recorre m veces las líneas 215, transfiriendo al menos un nodo de S a F durante cada iteración. Al inicio de cada iteración, el nodo no reportado al frente de S tiene el mayor puntaje ajustado, y se elimina y se agrega a F. El algoritmo luego recorre el 1 F ← ∅ 2 para i ← 1 a m hacer 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 para cada y ∈ x.children hacer 9 Abajo (y) 10 fin hacer 11 12 si x no es un nodo raíz entonces 13 Arriba (x, x.parent) 14 fin si 15 fin hacer Figura 5: Algoritmo de Re-Ranking - Como entrada, el algoritmo toma una cola de prioridad S, que contiene nodos XML clasificados por sus puntajes iniciales, y devuelve sus resultados en la cola de prioridad F, clasificados por puntajes ajustados. 1 Arriba(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recalcular y.score 5 S.add(y) 6 si y no es un nodo raíz entonces 7 Arriba (x, y.parent) 8 fin si 9 10 Abajo(x) ≡ 11 si no x.reported entonces 12 S.remove(x) 14 x.g ← x.f 15 recalcular x.score 16 si x.score > 0 entonces 17 F.add(x) 18 fin si 19 x.reported ← true 20 para cada y ∈ x.children hacer 21 Abajo (y) 22 fin hacer 23 fin si Figura 6: Rutinas de recorrido de árbol llamadas por el algoritmo de re-ranking. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 PrecisiónPromedioMedia (inex-2002) GananciaAcumuladaXML(XCG) alfa MAP (estricto) MAP (generalizado) MAP (sog) XCG (sog2) Figura 7: Impacto de α en XCG y MAP inex-2002 (temas CO de INEX 2004; conjunto de evaluación I). nodos ancestros (líneas 8-10) y descendientes (líneas 12-14) ajustando los puntajes de estos nodos. Las rutinas de recorrido de árboles, Arriba y Abajo, se muestran en la figura 6. El procedimiento Up elimina cada nodo ancestro de S, ajusta sus valores de frecuencia de término, recalcula su puntuación y lo vuelve a agregar a S. El ajuste de los valores de frecuencia de término (línea 3) agrega a y.g solo las ocurrencias de términos no reportadas previamente en x. El recalculo de la puntuación en la línea 4 utiliza las ecuaciones 1 y 2. La rutina Down realiza una operación similar en cada descendiente. Sin embargo, dado que el contenido de cada descendiente está completamente contenido en un elemento informado, su puntuación final puede ser calculada, y se elimina de S y se agrega a F. Para determinar la complejidad temporal del algoritmo, primero observe que un nodo puede ser un argumento de Down como máximo una vez. Posteriormente, la bandera reportada de su padre es verdadera. Durante cada llamada a Down, un nodo puede ser movido de S a F, lo que requiere un tiempo O(log n). Por lo tanto, el tiempo total para todas las llamadas a Down es O(n log n), y podemos ignorar temporalmente las líneas 8-10 de la figura 5 al considerar la complejidad temporal del bucle sobre las líneas 2-15. Durante cada iteración de este bucle, se elimina un nodo y cada uno de sus ancestros de una cola de prioridad y luego se vuelven a agregar a la cola de prioridad. Dado que un nodo puede tener como máximo h ancestros, donde h es la altura máxima de cualquier árbol en la colección, cada una de las m iteraciones requiere un tiempo de O(h log n). La combinación de estas observaciones produce una complejidad temporal general de O((n + mh) log n). En la práctica, volver a clasificar un conjunto de resultados de INEX requiere menos de 200 ms en una PC de escritorio de tres años de antigüedad. EVALUACIÓN Ninguna de las métricas descritas en la sección 3.3 se ajusta adecuadamente a la perspectiva de superposición defendida por este documento. Sin embargo, cuando se toman en conjunto, proporcionan información sobre el comportamiento del algoritmo de reordenamiento. Los paquetes de evaluación de INEX (inex_eval e inex_eval_ng) se utilizaron para calcular los valores de las métricas inex-2002 e inex-2003. Los valores de las métricas XCG fueron calculados utilizando el software proporcionado por sus inventores [11]. La Figura 7 representa juntas las tres variantes de la métrica MAP inex-2002 junto con la métrica XCG. Los valores para estas métricas 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Precisión Media Promedio (inex-2003) alfa estricto, superposición no considerada estricto, superposición considerada generalizado, superposición no considerada generalizado, superposición considerada Figura 8: Impacto de α en MAP inex-2003 (temas CO de INEX 2004; conjunto de evaluación I). se trazan para valores de α entre 0.0 y 1.0. Recordando que la métrica XCG está diseñada para penalizar la superposición, mientras que la métrica inex-2002 ignora la superposición, el conflicto entre las métricas es evidente. Los valores de MAP en un extremo (α = 0.0) y el valor de XCG en el otro extremo (α = 1.0) representan un rendimiento de recuperación comparable a los mejores sistemas en INEX 2004 [8,12]. La Figura 8 muestra los valores de la métrica MAP inex-2003 para dos cuantificaciones, con y sin consideración de la superposición. Una vez más, el conflicto es evidente, con la influencia de α considerablemente disminuida cuando se considera la superposición. 8. ALGORITMO EXTENDIDO Una limitación del algoritmo de reordenamiento es que se utiliza un único peso α para ajustar las puntuaciones tanto de los ancestros como de los descendientes de los elementos informados. Una extensión obvia es usar diferentes pesos en estos dos casos. Además, se utiliza el mismo peso independientemente de cuántas veces un elemento esté contenido en un elemento informado. Por ejemplo, un párrafo puede formar parte de una sección reportada y luego formar parte de un artículo reportado. Dado que el usuario puede haber visto este párrafo dos veces, su puntuación debería ser reducida aún más aumentando el valor del peso. Motivado por estas observaciones, el algoritmo de reordenamiento puede ser extendido con una serie de pesos 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0, donde βj es el peso aplicado a un nodo que ha sido descendiente de un nodo reportado j veces. Ten en cuenta que un límite superior en M es h, la altura máxima de cualquier árbol XML en la colección. Sin embargo, en la práctica es probable que M sea relativamente pequeño (quizás 3 o 4). La Figura 9 presenta reemplazos para las rutinas de Subir y Bajar de la Figura 6, incorporando esta serie de pesas. Se requiere un campo adicional en cada nodo, de la siguiente manera: x.j - conteo descendente El valor de x.j se establece inicialmente en cero en todos los nodos y se incrementa cada vez que se llama a Down con x como su argumento. Al calcular la puntuación del nodo, el valor de x.j selecciona 1 Up(x, y) ≡ 2 si no y.reported entonces 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recalcular y.score 6 S.add(y) 8 si y no es un nodo raíz entonces 9 Up (x, y.padre) 10 fin si 11 fin si 12 13 Down(x) ≡ 14 si x.j < M entonces 15 x.j ← x.j + 1 16 si no x.reported entonces 17 S.remove(x) 18 recalcular x.score 19 S.add(x) 20 fin si 21 para cada y ∈ x.hijos hacer 22 Down (y) 23 fin hacer 24 fin si Figura 9: Rutinas extendidas de recorrido de árbol. el peso a aplicar al nodo ajustando el valor de xt en la ecuación 1, de la siguiente manera: xt = βx.j · (ft − α · gt) (3) donde ft y gt son los componentes de x.f y x.g correspondientes al término t. Se requieren algunos cambios adicionales para extender Up y Down. La rutina Up devuelve inmediatamente (línea 2) si su argumento ya ha sido reportado, ya que las frecuencias de términos ya han sido ajustadas en sus ancestros. El procedimiento Down no informa su argumento, sino que vuelve a calcular su puntuación y la agrega de nuevo a S. Un nodo no puede ser un argumento de Down más de M +1 veces, lo que a su vez implica una complejidad temporal total de O((nM + mh) log n). Dado que M ≤ h y m ≤ n, la complejidad temporal también es O(nh log n). DISCUSIÓN CONCLUSIVA Al generar resultados de recuperación en una colección de XML, se debe tolerar cierta superposición en los resultados, lo cual puede ser beneficioso. Por ejemplo, cuando un elemento altamente exhaustivo y bastante específico (3,2) contiene un elemento mucho más pequeño (2,3), ambos deben ser informados al usuario, y los algoritmos de recuperación y las métricas de evaluación deben respetar esta relación. El algoritmo presentado en este documento controla la superposición ponderando los términos que aparecen en los elementos informados para reflejar su menor importancia. Otros enfoques también pueden ayudar a controlar la superposición. Por ejemplo, cuando se presentan los resultados de recuperación de XML a los usuarios, puede ser deseable agrupar elementos relacionados estructuralmente juntos, ilustrando visualmente las relaciones entre ellos. Si bien este estilo de interfaz de usuario puede ayudar a un usuario a lidiar con la superposición, la estrategia presentada en este documento sigue siendo aplicable, al determinar los mejores elementos para incluir en cada grupo. En Waterloo, seguimos desarrollando y probando nuestras ideas para INEX 2005. En particular, estamos investigando métodos para aprender los pesos α y βj. También estamos reevaluando nuestro enfoque en las estadísticas de documentos y examinando ajustes apropiados al parámetro k1 a medida que cambian los pesos de los términos [20]. 10. AGRADECIMIENTOS Gracias a Gabriella Kazai y Arjen de Vries por proporcionar una versión temprana de su software para calcular la métrica XCG, y gracias a Phil Tilker y Stefan B¨uttcher por su ayuda con la evaluación experimental. En parte, la financiación para este proyecto fue proporcionada por IBM Canadá a través del Instituto Nacional de Investigación de Software. 11. REFERENCIAS [1] N. Bruno, N. Koudas y D. Srivastava. Uniones de ramas holísticas: Coincidencia óptima de patrones XML. En Actas de la Conferencia Internacional ACM SIGMOD 2002 sobre la Gestión de Datos, páginas 310-321, Madison, Wisconsin, junio de 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y. Masa y A. Soffer. Buscando documentos XML a través de fragmentos XML. En Actas de la 26ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 151-158, Toronto, Canadá, 2003. [3] C. L. A. Clarke y P. L. Tilker. Experimentos MultiText para INEX 2004. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai y M. Lalmas. Tolerancia a la irrelevancia: Una evaluación orientada al esfuerzo del usuario de sistemas de recuperación sin unidad de recuperación predefinida. En las Actas de la Conferencia RIAO 2004, páginas 463-473, Aviñón, Francia, abril de 2004. [5] D. DeHaan, D. Toman, M. P. Consens y M. T. ¨Ozsu. Una traducción exhaustiva de XQuery a SQL utilizando codificación dinámica de intervalos. En Actas de la Conferencia Internacional ACM SIGMOD 2003 sobre la Gestión de Datos, San Diego, junio de 2003. [6] N. Fuhr y K. Großjohann. XIRQL: Un lenguaje de consulta para la recuperación de información en documentos XML. En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 172-180, Nueva Orleans, septiembre de 2001. [7] N. Fuhr, M. Lalmas y S. Malik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Segundo Taller (INEX 2003), Dagstuhl, Alemania, diciembre de 2003. [8] N. Fuhr, M. Lalmas, S. Malik y Zoltán Szlávik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Tercer Taller (INEX 2004), Dagstuhl, Alemania, diciembre de 2004. Publicado como Avances en la Recuperación de Información XML, Notas de Conferencia en Ciencias de la Computación, volumen 3493, Springer, 2005. [9] K. J¨avelin y J. Kek¨al¨ainen. Evaluación basada en la <br>ganancia acumulada</br> de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, y B. Sigurbjörnsson. Normalización de longitud en la recuperación de XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 80-87, Sheffield, Reino Unido, julio de 2004. [11] G. Kazai, M. Lalmas y A. P. de Vries. El problema de superposición en la evaluación de la recuperación de XML orientada al contenido. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 72-79, Sheffield, Reino Unido, julio de 2004. [12] G. Kazai, M. Lalmas y A. P. de Vries. Pruebas de confiabilidad para las métricas XCG e inex-2002. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola y T. Aalto. TRIX 2004 - Luchando con la superposición. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [14] S. Liu, Q. Zou y W. W. Chu. Indexación y clasificación configurables para la recuperación de información en XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 88-95, Sheffield, Reino Unido, julio de 2004. [15] Y. Masa y M. Mandelbrot. Recuperando los componentes XML más relevantes. En las Actas del Taller INEX 2003, Dagstuhl, Alemania, diciembre de 2003. [16] Y. Masa y M. Mandelbrot. Clasificación de componentes y refinamiento automático de consultas para la recuperación de XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [17] P. Ogilvie y J. Callan. Modelos de lenguaje jerárquicos para la recuperación de componentes XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [18] J. Pehcevski, J. A. Thom y A. Vercoustre. Recuperación híbrida de XML revisitada. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [19] B. Piwowarski y M. Lalmas. Proporcionando evaluaciones de relevancia consistentes y exhaustivas para la evaluación de recuperación de XML. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 361-370, Washington, DC, noviembre de 2004. [20] S. Robertson, H. Zaragoza y M. Taylor. Extensión simple de BM25 a múltiples campos ponderados. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 42-50, Washington, DC, noviembre de 2004. [21] S. E. Robertson, S. Walker y M. Beaulieu. Okapi en TREC-7: Búsqueda automática, filtrado, VLC y pista interactiva. En Actas de la Séptima Conferencia de Recuperación de Texto, Gaithersburg, MD, noviembre de 1998. [22] A. Trotman y B. Sigurbjörnsson. NEXI, ahora y después. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski y P. Gallinari. Un álgebra para consultas estructuradas en redes bayesianas. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "ideal gain vector": {
            "translated_key": "vector de ganancia ideal",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Controlling Overlap in Content-Oriented XML Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of XML documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
                "This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents.",
                "The test collection developed by the INitiative for the Evaluation of XML Retrieval (INEX) forms the basis for the evaluation.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "INTRODUCTION The representation of documents in XML provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an XML information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in XML.",
                "Figure 1 provides an example of a journal article encoded in XML, illustrating many of the important characteristics of XML documents.",
                "Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words.",
                "Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate.",
                "Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs.",
                "Each of these characteristics affects the design of an XML IR system, and each leads to fundamental problems that must be solved in an successful system.",
                "Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper.",
                "The article of figure 1 may be viewed as an XML tree, as illustrated in figure 2.",
                "Formally, a collection of XML documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes.",
                "For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example XML tree. of x.",
                "Since an element may be represented by the node at its root, the output of an XML IR system may be viewed as a ranked list of the top-m nodes.",
                "The direct application of a standard relevance ranking technique to a set of XML elements can produce a result in which the top ranks are dominated by many structurally related elements.",
                "A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article.",
                "For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms.",
                "If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content.",
                "One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it.",
                "Unfortunately, this approach destroys some of the possible benefits of XML IR.",
                "For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts.",
                "In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements.",
                "Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6].",
                "This paper presents a method for controlling overlap.",
                "Starting with an initial element ranking, a re-ranking algorithm adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
                "For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced.",
                "The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20].",
                "Extending that approach, the re-ranking algorithm varies weights dynamically as elements are processed.",
                "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a baseline retrieval method is presented in section 4.",
                "This baseline method represents a reasonable adaptation of standard IR technology to XML.",
                "Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point.",
                "A re-ranking algorithm implementing this strategy is presented in section 6 and evaluated in section 7.",
                "Section 8 discusses an extended version of the algorithm. 2.",
                "BACKGROUND This section provides a general overview of XML information retrieval and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
                "Much research in the area of XML retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1].",
                "Here, we take a content oriented IR perceptive, focusing on XML documents that primarily contain natural language data and queries that are primarily expressed in natural language.",
                "We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need.",
                "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional information retrieval applications the standard unit of retrieval is taken to be the document.",
                "Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages.",
                "When applying standard relevance ranking techniques in the context of XML IR, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
                "In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole.",
                "If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article.",
                "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an XML IR system might potentially retrieve any element, many elements may not be appropriate as retrieval results.",
                "This is usually the case when elements contain very little text [10].",
                "For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself.",
                "Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user.",
                "An effective XML IR system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18].",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (INEX) has encouraged research into XML information retrieval technology [7,8].",
                "INEX is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
                "Over 50 groups participated in INEX 2004, and the conference has become as influential in the area of XML IR as TREC is in other IR areas.",
                "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by INEX.",
                "Overlap causes considerable problems with retrieval evaluation, and the INEX organizers and participants have wrestled with these problems since the beginning.",
                "While substantial progress has been made, these problem are still not completely solved.",
                "Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of INEX retrieval evaluation and discuss both current and proposed evaluation metrics.",
                "Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3.",
                "INEX 2004 Space limitations prevent the inclusion of more than a brief summary of INEX 2004 tasks and evaluation methodology.",
                "For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, INEX 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002.",
                "Each document is encoded in XML using a common DTD, with the document of figures 1 and 2 providing one example.",
                "At INEX 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics.",
                "The two tasks differed in the types of topics they used.",
                "For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection.",
                "For this task, the IR system is required to select the elements to be returned.",
                "For the other task, the contentand-structure or CAS task, the topics are written in an XML query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy.",
                "Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description.",
                "In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants.",
                "Each topic includes a short keyword query, which is executed over the collection by each participating group on their own XML IR system.",
                "Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since XML IR is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient.",
                "Instead, the INEX organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic.",
                "A four-point scale is used in both dimensions.",
                "Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant.",
                "Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at INEX 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values.",
                "One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others.",
                "This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant.",
                "Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity.",
                "Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity.",
                "This paper reports results of this metric using all three of these quantization functions.",
                "Since this metric was first introduced at INEX 2002, it is generally referred as the inex-2002 metric.",
                "The inex-2002 metric does not penalize overlap.",
                "In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank.",
                "To address this problem, Kazai et al. [11] propose an XML cumulated gain metric, which compares the cumulated gain [9] of a ranked list to an <br>ideal gain vector</br>.",
                "This <br>ideal gain vector</br> is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path.",
                "Thus, the XCG metric rewards retrieval runs that avoid overlap.",
                "While XCG was not used officially at INEX 2004, a version of it is likely to be used in the future.",
                "At INEX 2003, yet another metric was introduced to ameliorate the perceived limitations of the inex-2002 metric.",
                "This inex-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them.",
                "Two versions were created, one that considered only component size and another that considered both size and overlap.",
                "While the inex-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4.",
                "BASELINE RETRIEVAL METHOD This section provides an overview of baseline XML information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3].",
                "This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the XML information retrieval task.",
                "The MultiText system performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
                "To support retrieval from XML and other structured document types, the system provides generalized queries of the form: rank X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms.",
                "For our INEX 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections.",
                "Prior to INEX 2004, the INEX collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names.",
                "Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received.",
                "Automating this selection process is planned as future work.",
                "For INEX 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.",
                "For example, keyword field of topic 166 +tree edit distance + XML -image became the four-term query $tree $edit $distance $xml where the $ operator within a quoted string stems the term that follows it.",
                "Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞.",
                "Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(inex-2002) k1 strict generalized sog Figure 3: Impact of k1 on inex-2002 mean average precision with b = 0.75 (INEX 2003 CO topics).",
                "Prior to INEX 2004, the INEX 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.",
                "For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article.",
                "These statistics are used for ranking all element types.",
                "Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length.",
                "The use of article statistics for all element types might be questioned.",
                "This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.",
                "The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics.",
                "Nonetheless, we plan to examine this issue again in the future.",
                "In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose.",
                "Prior to INEX 2004, we trained the MultiText system using the INEX 2003 queries.",
                "As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system.",
                "The results were surprising.",
                "Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions.",
                "In our experience, optimal values for k1 are typically in the range 0.0 to 2.0.",
                "In this case, large values are required for good performance.",
                "Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization.",
                "Similar improvements are seen under the generalized and sog quantizations.",
                "In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).",
                "After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our INEX 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5.",
                "CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements.",
                "At a conceptual level, re-ranking proceeds as follows: 1.",
                "Report the highest ranking element. 2.",
                "Adjust the scores of the unreported elements. 3.",
                "Repeat steps 1 and 2 until m elements are reported.",
                "One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements.",
                "For example, assume a paragraph with score p is reported in step 1.",
                "In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score.",
                "In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion.",
                "That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages.",
                "A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two.",
                "Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness.",
                "Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body.",
                "In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body.",
                "Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported.",
                "The next section presents and analysis a simple re-ranking algorithm that follows this strategy.",
                "The algorithm is evaluated experimentally in section 7.",
                "One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears.",
                "In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6.",
                "RE-RANKING ALGORITHM The re-ranking algorithm operates over XML trees, such as the one appearing in figure 2.",
                "Input to the algorithm is a list of n elements ranked according to their initial BM25 scores.",
                "During the initial ranking the XML tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |.",
                "Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores.",
                "An element is represented by the node x ∈ N at its root.",
                "Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - term frequency vector x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses.",
                "The vector x.f contains term frequency information corresponding to each term in the query.",
                "The vector x.g is initially zero and is updated by the algorithm as elements are reported.",
                "The score field contains the current BM25 score for the element, which will change as the values in x.g change.",
                "The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g.",
                "Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the re-ranking algorithm, nodes are stored in priority queues, ordered by decreasing score.",
                "Each priority queue PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
                "The core of the re-ranking algorithm is presented in figure 5.",
                "The algorithm takes as input the priority queue S containing the initial ranking, and produces the top-m reranked nodes in the priority queue F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
                "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a priority queue S, containing XML nodes ranked by their initial scores, and returns its results in priority queue F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
                "The tree traversal routines, Up and Down are given in figure 6.",
                "The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2.",
                "The Down routine performs a similar operation on each descendant.",
                "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the time complexity of the algorithm, first note that a node may be an argument to Down at most once.",
                "Thereafter, the reported flag of its parent is true.",
                "During each call to Down a node may be moved from S to F, requiring O(log n) time.",
                "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the time complexity of the loop over lines 2-15.",
                "During each iteration of this loop, a node and each of its ancestors are removed from a priority queue and then added back into a priority queue.",
                "Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time.",
                "Combining these observations produces an overall time complexity of O((n + mh) log n).",
                "In practice, re-ranking an INEX result set requires less than 200ms on a three-year-old desktop PC. 7.",
                "EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper.",
                "Nonetheless, when taken together they provide insight into the behaviour of the re-ranking algorithm.",
                "The INEX evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the inex-2002 and inex-2003 metrics.",
                "Values for the XCG metrics were computed using software supplied by its inventors [11].",
                "Figure 7 plots the three variants of inex-2002 MAP metric together with the XCG metric.",
                "Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on inex-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0.",
                "Recalling that the XCG metric is designed to penalize overlap, while the inex-2002 metric ignores overlap, the conflict between the metrics is obvious.",
                "The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at INEX 2004 [8,12].",
                "Figure 8 plots values of the inex-2003 MAP metric for two quantizations, with and without consideration of overlap.",
                "Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8.",
                "EXTENDED ALGORITHM One limitation of the re-ranking algorithm is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements.",
                "An obvious extension is to use different weights in these two cases.",
                "Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element.",
                "For example, a paragraph may form part of a reported section and then form part of a reported article.",
                "Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight.",
                "Motivated by these observations, the re-ranking algorithm may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times.",
                "Note that an upper bound on M is h, the maximum height of any XML tree in the collection.",
                "However, in practice M is likely to be relatively small (perhaps 3 or 4).",
                "Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights.",
                "One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument.",
                "When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down.",
                "The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors.",
                "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall time complexity of O((nM + mh) log n).",
                "Since M ≤ h and m ≤ n, the time complexity is also O(nh log n). 9.",
                "CONCLUDING DISCUSSION When generating retrieval results over an XML collection, some overlap in the results should be tolerated, and may be beneficial.",
                "For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship.",
                "The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance.",
                "Other approaches may also help to control overlap.",
                "For example, when XML retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them.",
                "While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster.",
                "At Waterloo, we continue to develop and test our ideas for INEX 2005.",
                "In particular, we are investigating methods for learning the α and βj weights.",
                "We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10.",
                "ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation.",
                "In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11.",
                "REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava.",
                "Holistic twig joins: Optimal XML pattern matching.",
                "In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
                "Mass, and A. Soffer.",
                "Searching XML documents via XML fragments.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker.",
                "MultiText experiments for INEX 2004.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas.",
                "Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit.",
                "In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu.",
                "A comprehensive XQuery to SQL translation using dynamic interval encoding.",
                "In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann.",
                "XIRQL: A query language for information retrieval in XML documents.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Second Workshop (INEX 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Third Workshop (INEX 2004), Dagstuhl, Germany, December 2004.",
                "Published as Advances in XML Information Retrieval, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson.",
                "Length normalization in XML retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "The overlap problem in content-oriented XML retrieval evaluation.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "Reliability tests for the XCG and inex-2002 metrics.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto.",
                "TRIX 2004 - Struggling with the overlap.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu.",
                "Configurable indexing and ranking for XML information retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 88-95, Sheffield, UK, July 2004. [15] Y.",
                "Mass and M. Mandelbrod.",
                "Retrieving the most relevant XML components.",
                "In INEX 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y.",
                "Mass and M. Mandelbrod.",
                "Component ranking and automatic query refinement for XML retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan.",
                "Hierarchical language models for XML component retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [18] J. Pehcevski, J.",
                "A. Thom, and A. Vercoustre.",
                "Hybrid XML retrieval re-visited.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas.",
                "Providing consistent and exhaustive relevance assessments for XML retrieval evaluation.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor.",
                "Simple BM25 extension to multiple weighted fields.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu.",
                "Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track.",
                "In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson.",
                "NEXI, now and next.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari.",
                "An algebra for structured queries in bayesian networks.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]."
            ],
            "original_annotated_samples": [
                "To address this problem, Kazai et al. [11] propose an XML cumulated gain metric, which compares the cumulated gain [9] of a ranked list to an <br>ideal gain vector</br>.",
                "This <br>ideal gain vector</br> is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path."
            ],
            "translated_annotated_samples": [
                "Para abordar este problema, Kazai et al. [11] proponen una métrica de ganancia acumulada XML, que compara la ganancia acumulada [9] de una lista clasificada con un <br>vector de ganancia ideal</br>.",
                "Este <br>vector de ganancia ideal</br> se construye a partir de las valoraciones de relevancia al eliminar la superposición y retener solo el mejor elemento a lo largo de un camino dado."
            ],
            "translated_text": "Controlando la superposición en la recuperación XML orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca RESUMEN La aplicación directa de técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos XML a menudo produce un conjunto de resultados en el que los primeros puestos están dominados por un gran número de elementos tomados de un pequeño número de documentos altamente relevantes. Este documento presenta y evalúa un algoritmo que vuelve a clasificar este conjunto de resultados, con el objetivo de minimizar el contenido redundante mientras se preservan los beneficios de la recuperación de elementos, incluido el beneficio de identificar componentes centrados en el tema contenidos en documentos relevantes. La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la Recuperación XML (INEX) constituye la base para la evaluación. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Búsqueda y Recuperación de Información Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. La representación de documentos en XML brinda una oportunidad para que los sistemas de recuperación de información aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias. En respuesta a una consulta de usuario, un sistema de recuperación de información XML podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes. Esta facilidad es de particular beneficio cuando una colección contiene documentos muy largos, como manuales de productos o libros, donde el usuario debe ser dirigido a las partes más relevantes de estos documentos. La Figura 1 proporciona un ejemplo de un artículo de revista codificado en XML, ilustrando muchas de las características importantes de los documentos XML. Las etiquetas indican el inicio y el final de cada elemento, con elementos que varían ampliamente en tamaño, desde una palabra hasta miles de palabras. Algunos elementos, como párrafos y secciones, pueden presentarse razonablemente al usuario como resultados de búsqueda, pero otros no son apropiados. Los elementos se superponen entre sí: los artículos contienen secciones, las secciones contienen subsecciones y las subsecciones contienen párrafos. Cada una de estas características afecta el diseño de un sistema de IR XML, y cada una conlleva problemas fundamentales que deben resolverse en un sistema exitoso. La mayoría de estos problemas fundamentales pueden resolverse mediante la cuidadosa adaptación de técnicas estándar de IR, pero los problemas causados por la superposición son únicos en esta área [4,11] y constituyen el enfoque principal de este artículo. El artículo de la figura 1 puede ser visto como un árbol XML, como se ilustra en la figura 2. Formalmente, una colección de documentos XML puede ser representada como un bosque de árboles ordenados y enraizados, que consiste en un conjunto de nodos N y un conjunto de aristas dirigidas E que conectan estos nodos. Para cada nodo x ∈ N, la notación x.parent se refiere al nodo padre de x, si existe, y la notación x.children se refiere al conjunto de nodos hijos de x. Dado que un elemento puede estar representado por el nodo en su raíz, la salida de un sistema de IR XML puede ser vista como una lista clasificada de los m nodos principales. La aplicación directa de una técnica estándar de clasificación de relevancia a un conjunto de elementos XML puede producir un resultado en el que los primeros puestos están dominados por muchos elementos estructuralmente relacionados. Una sección con una puntuación alta probablemente contenga varios párrafos con una puntuación alta y esté contenida en un artículo con una puntuación alta. Por ejemplo, muchos de los elementos en la figura 2 recibirían una puntuación alta en los algoritmos de compresión de índices de texto de consulta de palabras clave. Si cada uno de estos elementos se presenta a un usuario como un resultado individual y separado, puede perder mucho tiempo revisando y rechazando contenido redundante. Una posible solución es informar solo el elemento de mayor puntuación a lo largo de un camino dado en el árbol, y eliminar de los rangos inferiores cualquier elemento que lo contenga o esté contenido en él. Desafortunadamente, este enfoque destruye algunos de los posibles beneficios de XML IR. Por ejemplo, un elemento externo puede contener una cantidad sustancial de información que no aparece en un elemento interno, pero el elemento interno puede estar fuertemente enfocado en el tema de la consulta y proporcionar un breve resumen de los conceptos clave. En tales casos, es razonable informar sobre elementos que contienen, o están contenidos en, elementos de rango superior. Incluso cuando un libro entero es relevante, un usuario aún puede desear que se destaquen los párrafos más importantes, para guiar su lectura y ahorrar tiempo [6]. Este documento presenta un método para controlar la superposición. A partir de una clasificación inicial de elementos, un algoritmo de re-clasificación ajusta las puntuaciones de los elementos de menor clasificación que contienen, o están contenidos dentro de, elementos de mayor clasificación, reflejando el hecho de que esta información puede ser ahora redundante. Por ejemplo, una vez que un elemento que representa una sección aparece en la clasificación, las puntuaciones de los párrafos que contiene y del artículo que lo contiene se reducen. La inspiración para esta estrategia proviene parcialmente del trabajo reciente sobre la recuperación de documentos estructurados, donde los términos que aparecen en diferentes campos, como el título y el cuerpo, reciben diferentes pesos [20]. Extendiendo ese enfoque, el algoritmo de reordenamiento varía los pesos dinámicamente a medida que se procesan los elementos. El resto del documento está organizado de la siguiente manera: Después de una discusión sobre el trabajo de antecedentes y la metodología de evaluación, se presenta un método de recuperación de referencia en la sección 4. Este método de referencia representa una adaptación razonable de la tecnología estándar de IR al XML. La sección 5 luego describe una estrategia para controlar la superposición, utilizando el método de línea base como punto de partida. Un algoritmo de reordenamiento que implementa esta estrategia se presenta en la sección 6 y se evalúa en la sección 7. La sección 8 discute una versión extendida del algoritmo. 2. ANTECEDENTES Esta sección proporciona una visión general de la recuperación de información XML y discute trabajos relacionados, con énfasis en los problemas fundamentales mencionados en la introducción. Mucha investigación en el área de recuperación de XML lo ve desde una perspectiva de base de datos tradicional, preocupándose por problemas como la implementación de lenguajes de consulta estructurados [5] y el procesamiento de joins [1]. Aquí adoptamos una perspectiva de IR orientada al contenido, centrándonos en documentos XML que contienen principalmente datos en lenguaje natural y consultas que están principalmente expresadas en lenguaje natural. Suponemos que estas consultas indican únicamente la naturaleza del contenido deseado, no su estructura, y que el papel del sistema de RI es determinar qué elementos satisfacen mejor la necesidad de información subyacente. Otra investigación en IR ha considerado consultas mixtas, en las que se especifican tanto requisitos de contenido como estructurales [2,6,14,17,23]. 2.1 Estadísticas de Términos y Documentos En las aplicaciones tradicionales de recuperación de información, la unidad estándar de recuperación se considera que es el documento. Dependiendo de la aplicación, este término podría interpretarse para abarcar muchos objetos diferentes, incluyendo páginas web, artículos de periódico y mensajes de correo electrónico. Al aplicar técnicas estándar de clasificación de relevancia en el contexto de la RI XML, un enfoque natural es tratar cada elemento como un documento separado, con estadísticas de términos disponibles para cada uno [16]. Además, la mayoría de las técnicas de clasificación requieren estadísticas globales (por ejemplo, frecuencia inversa de documentos) calculadas sobre la colección en su totalidad. Si consideramos que esta colección incluye todos los elementos que podrían ser devueltos por el sistema, una ocurrencia específica de un término puede aparecer en varios documentos diferentes, quizás en elementos que representan un párrafo, una subsección, una sección y un artículo. No es apropiado calcular la frecuencia inversa de documentos bajo la suposición de que el término está contenido en todos estos elementos, ya que el número de elementos que contienen un término depende completamente del arreglo estructural de los documentos [13,23]. 2.2 Elementos Recuperables Si bien un sistema de recuperación de información XML podría potencialmente recuperar cualquier elemento, muchos elementos pueden no ser apropiados como resultados de recuperación. Esto suele ser el caso cuando los elementos contienen muy poco texto [10]. Por ejemplo, un título de sección que contenga solo los términos de búsqueda puede recibir una puntuación alta de un algoritmo de clasificación, pero por sí solo tendría un valor limitado para un usuario, quien podría preferir la sección real en sí misma. Otros elementos pueden reflejar la estructura física de los documentos, en lugar de la estructura lógica, lo cual puede tener poco o ningún significado para un usuario. Un sistema de recuperación de información XML efectivo debe devolver solo aquellos elementos que tengan suficiente contenido para ser utilizables y puedan funcionar como objetos independientes [15,18]. Componentes estándar de documentos como párrafos, secciones, subsecciones y resúmenes generalmente cumplen con estos requisitos; los títulos, frases en cursiva y campos de metadatos individuales a menudo no lo hacen. 2.3 Metodología de Evaluación En los últimos tres años, la Iniciativa para la Evaluación de la Recuperación de Información XML (INEX) ha fomentado la investigación en tecnología de recuperación de información XML [7,8]. INEX es una serie de conferencias experimentales, similar a TREC, en la que grupos de diferentes instituciones completan una o más tareas experimentales utilizando sus propias herramientas y sistemas, y comparan sus resultados en la propia conferencia. Más de 50 grupos participaron en INEX 2004, y la conferencia se ha convertido en tan influyente en el área de la RI XML como lo es TREC en otras áreas de la RI. La investigación descrita en este artículo, al igual que gran parte del trabajo relacionado que cita, depende de las colecciones de pruebas desarrolladas por INEX. La superposición causa problemas considerables en la evaluación de la recuperación, y los organizadores y participantes de INEX han luchado con estos problemas desde el principio. Aunque se ha logrado un progreso sustancial, estos problemas aún no están completamente resueltos. Kazai et al. [11] proporcionan una exposición detallada del problema de superposición en el contexto de la evaluación de recuperación de INEX y discuten tanto las métricas de evaluación actuales como las propuestas. Muchas de estas métricas se aplican para evaluar los experimentos reportados en este artículo, y se describen brevemente en la siguiente sección. 3. Las limitaciones de espacio impiden incluir más que un breve resumen de las tareas y metodología de evaluación de INEX 2004. Para obtener información detallada, se deben consultar las actas de la conferencia en sí [8]. 3.1 Tareas Para las principales tareas experimentales, a los participantes de INEX 2004 se les proporcionó una colección de 12,107 artículos tomados de las revistas y publicaciones de la IEEE Computer Societies entre 1995 y 2002. Cada documento está codificado en XML utilizando una DTD común, siendo el documento de las figuras 1 y 2 un ejemplo. En INEX 2004, las dos principales tareas experimentales fueron ambas tareas de recuperación ad hoc, investigando el rendimiento de sistemas que buscan en una colección estática utilizando temas previamente no vistos. Las dos tareas diferían en los tipos de temas que utilizaban. Para una tarea, la tarea de solo contenido o CO, los temas consisten en declaraciones cortas en lenguaje natural sin hacer referencia directa a la estructura de los documentos en la colección. Para esta tarea, se requiere que el sistema de IR seleccione los elementos a devolver. Para la otra tarea, la tarea de contenido y estructura o CAS, los temas están escritos en un lenguaje de consulta XML [22] y contienen referencias explícitas a la estructura del documento, que el sistema de IR debe intentar satisfacer. Dado que el trabajo descrito en este documento se enfoca en la tarea de solo contenido, donde el sistema de IR no recibe orientación sobre los elementos a devolver, la tarea de CAS se ignora en el resto de nuestra descripción. En 2004, los organizadores de la conferencia seleccionaron 40 nuevos temas de CO de las contribuciones proporcionadas por los participantes de la conferencia. Cada tema incluye una breve consulta de palabras clave, la cual es ejecutada sobre la colección por cada grupo participante en su propio sistema de IR XML. Cada grupo podría presentar hasta tres ejecuciones experimentales que consistieran en los primeros m = 1500 elementos para cada tema. 3.2 Evaluación de Relevancia Dado que la RI XML se preocupa por localizar aquellos elementos que proporcionan una cobertura completa de un tema mientras contienen la menor cantidad de información irrelevante posible, los juicios simples de relevante vs. no relevante no son suficientes. En cambio, los organizadores de INEX adoptaron dos dimensiones para la evaluación de relevancia: la dimensión de exhaustividad refleja el grado en que un elemento abarca el tema, y la dimensión de especificidad refleja el grado en que un elemento se enfoca en el tema. Se utiliza una escala de cuatro puntos en ambas dimensiones. Por lo tanto, un elemento (3,3) es altamente exhaustivo y altamente específico, un elemento (1,3) es marginalmente exhaustivo y altamente específico, y un elemento (0,0) no es relevante. Información adicional sobre la metodología de evaluación se puede encontrar en Piwowarski y Lalmas [19], quienes proporcionan una justificación detallada. 3.3 Métricas de Evaluación La métrica de evaluación principal utilizada en INEX 2004 es una versión de la precisión promedio media (MAP), ajustada por diversas funciones de cuantificación para dar diferentes pesos a diferentes elementos, dependiendo de sus valores de exhaustividad y especificidad. Una variante, la función de cuantización estricta asigna un peso de 1 a los elementos (3,3) y un peso de 0 a todos los demás. Esta variante es esencialmente el valor MAP familiar, con elementos (3,3) tratados como relevantes y todos los demás elementos tratados como no relevantes. Otras funciones de cuantización están diseñadas para otorgar crédito parcial a elementos que son aproximaciones cercanas, debido a la falta de exhaustividad y/o especificidad. Tanto la función de cuantificación generalizada como la función de generalización orientada a la especificidad (sog) acreditan elementos según su grado de relevancia [11], siendo que la segunda función pone mayor énfasis en la especificidad. Este documento informa los resultados de esta métrica utilizando las tres funciones de cuantización. Desde que esta métrica fue introducida por primera vez en INEX 2002, generalmente se le conoce como la métrica inex-2002. La métrica inex-2002 no penaliza la superposición. En particular, tanto las funciones de cuantificación generalizadas como las de sog otorgan crédito parcial a un casi acierto incluso cuando se informa un elemento (3,3) que se superpone a él en un rango más alto. Para abordar este problema, Kazai et al. [11] proponen una métrica de ganancia acumulada XML, que compara la ganancia acumulada [9] de una lista clasificada con un <br>vector de ganancia ideal</br>. Este <br>vector de ganancia ideal</br> se construye a partir de las valoraciones de relevancia al eliminar la superposición y retener solo el mejor elemento a lo largo de un camino dado. Por lo tanto, la métrica XCG recompensa las ejecuciones de recuperación que evitan la superposición. Aunque XCG no se utilizó oficialmente en INEX 2004, es probable que se utilice una versión de él en el futuro. En INEX 2003, se introdujo otra métrica para mejorar las limitaciones percibidas de la métrica inex-2002. Este métrico inex-2003 extiende las definiciones de precisión y exhaustividad para considerar tanto el tamaño de los componentes informados como la superposición entre ellos. Se crearon dos versiones, una que consideraba solo el tamaño de los componentes y otra que consideraba tanto el tamaño como la superposición. Si bien la métrica inex-2003 presenta anomalías no deseadas [11] y no se utilizó en 2004, se informan valores en la sección de evaluación para proporcionar un instrumento adicional para investigar la superposición. 4. MÉTODO DE RECUPERACIÓN DE BASELINE Esta sección proporciona una descripción general del método de recuperación de información XML de base actualmente utilizado en el sistema MultiText IR, desarrollado por el Grupo de Recuperación de Información de la Universidad de Waterloo [3]. Este método de recuperación resulta de la adaptación y ajuste de la medida Okapi BM25 [21] a la tarea de recuperación de información en XML. El sistema MultiText tuvo un desempeño respetable en INEX 2004, ubicándose entre los diez primeros en todas las funciones de cuantización, y ocupando el primer lugar cuando la función de cuantización enfatizaba la exhaustividad. Para admitir la recuperación de XML y otros tipos de documentos estructurados, el sistema proporciona consultas generalizadas de la forma: clasificar X por Y donde X es una subconsulta que especifica un conjunto de elementos de documentos a clasificar y Y es un vector de subconsultas que especifican términos de recuperación individuales. Para nuestras ejecuciones de INEX 2004, la subconsulta X especificó una lista de elementos recuperables como aquellos con nombres de etiquetas de la siguiente manera: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt. Esta lista incluye entradas bibliográficas (bb) y leyendas de figuras (fig) así como párrafos, secciones y subsecciones. Antes de INEX 2004, la colección de INEX y las evaluaciones de relevancia de INEX 2003 fueron analizadas manualmente para seleccionar estos nombres de etiquetas. Los nombres de las etiquetas fueron seleccionados en base a su frecuencia en la colección, el tamaño promedio de sus elementos asociados y el número relativo de juicios de relevancia positiva que recibieron. Automatizar este proceso de selección está planeado como trabajo futuro. Para INEX 2004, el vector término Y se derivó del tema dividiendo frases en palabras individuales, eliminando palabras vacías y términos negativos (aquellos que comienzan con -), y aplicando un stemmer. Por ejemplo, el campo de palabra clave del tema 166 +distancia de edición de árbol + XML -imagen se convirtió en la consulta de cuatro términos $árbol $edición $distancia $xml donde el operador $ dentro de una cadena entre comillas deriva el término que le sigue. Nuestra implementación de Okapi BM25 se deriva de la fórmula de Robertson et al. [21] al establecer los parámetros k2 = 0 y k3 = ∞. Dado un conjunto de términos Q, a un elemento x se le asigna la puntuación t∈Q w(1) qt (k1 + 1)xt K + xt (1) donde w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = número de documentos en el corpus Dt = número de documentos que contienen t qt = frecuencia con la que t ocurre en el tema xt = frecuencia con la que t ocurre en x K = k1((1 − b) + b · lx/lavg) lx = longitud de x lavg = longitud promedio del documento 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 PrecisiónPromedio(inex-2002) k1 estricto generalizado sog Figura 3: Impacto de k1 en la precisión promedio de inex-2002 con b = 0.75 (temas CO de INEX 2003). Antes de INEX 2004, los temas y juicios de INEX 2003 se utilizaron para ajustar los parámetros b y k1, y el impacto de este ajuste se discute más adelante en esta sección. Para los propósitos de calcular estadísticas a nivel de documento (D, Dt y lavg), un documento se define como un artículo. Estas estadísticas se utilizan para clasificar todos los tipos de elementos. Siguiendo la sugerencia de Kamps et al. [10], los resultados de recuperación se filtran para eliminar elementos muy cortos, aquellos con menos de 25 palabras de longitud. El uso de estadísticas de artículos para todos los tipos de elementos podría ser cuestionado. Este enfoque puede justificarse al considerar la colección como un conjunto de artículos que se pueden buscar utilizando técnicas estándar orientadas a documentos, donde solo se devuelven artículos. El puntaje calculado para un elemento es esencialmente el puntaje que recibiría si se agregara a la colección como un nuevo documento, ignorando los ajustes menores necesarios para las estadísticas a nivel de documento. Sin embargo, planeamos examinar este tema nuevamente en el futuro. En nuestra experiencia, el rendimiento de BM25 suele beneficiarse al ajustar los parámetros b y k1 a la colección, siempre que haya consultas de entrenamiento disponibles con este propósito. Antes de INEX 2004, entrenamos el sistema MultiText utilizando las consultas de INEX 2003. Como punto de partida, utilizamos los valores b = 0.75 y k1 = 1.2, que funcionan bien en colecciones TREC adhoc y se utilizan como valores predeterminados en nuestro sistema. Los resultados fueron sorprendentes. La Figura 3 muestra el resultado de variar k1 con b = 0.75 en los valores de MAP bajo tres funciones de cuantización. En nuestra experiencia, los valores óptimos para k1 suelen estar en el rango de 0.0 a 2.0. En este caso, se requieren valores grandes para un buen rendimiento. Entre k1 = 1.0 y k1 = 6.0, el MAP aumenta en más del 15% bajo la cuantización estricta. Se observan mejoras similares bajo las cuantizaciones generalizada y SOG. Por el contrario, nuestro valor predeterminado de b = 0.75 funciona bien bajo todas las funciones de cuantificación (figura 4). Después de ajustar una amplia gama de valores bajo varias funciones de cuantización, seleccionamos los valores de k = 10.0 y b = 0.80 para nuestros experimentos de INEX 2004, y estos valores se utilizan para los experimentos reportados en la sección 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 PrecisiónPromedioMedia (inex-2002) b estricto generalizado sog Figura 4: Impacto de b en la precisión promedio media de inex-2002 con k1 = 10 (temas CO de INEX 2003). 5. CONTROL DE SUPERPOSICIÓN Comenzando con una clasificación de elementos generada por el método de referencia descrito en la sección anterior, los elementos se vuelven a clasificar para controlar la superposición ajustando de forma iterativa las puntuaciones de aquellos elementos que contienen o están contenidos en elementos de clasificación más alta. A nivel conceptual, la reorganización procede de la siguiente manera: 1. Informe el elemento de rango más alto. Ajustar las puntuaciones de los elementos no reportados. 3. Repetir los pasos 1 y 2 hasta que se informen m elementos. Un enfoque para ajustar las puntuaciones de los elementos no informados en el paso 2 podría basarse en las puntuaciones Okapi BM25 de los elementos involucrados. Por ejemplo, supongamos que se informa un párrafo con una puntuación p en el paso 1. En el paso 2, la sección que contiene el párrafo podría tener su puntuación s reducida en una cantidad α · p para reflejar la contribución reducida que el párrafo debería hacer a la puntuación de las secciones. En un contexto relacionado, Robertson et al. [20] argumentan en contra de la combinación lineal de las puntuaciones de Okapi de esta manera. Ese trabajo considera el problema de asignar diferentes pesos a diferentes campos de documentos, como el título y el cuerpo asociados con páginas web. Un enfoque común para este problema puntúa el título y el cuerpo por separado y genera una puntuación final como una combinación lineal de ambos. Robertson et al. discuten las deficiencias teóricas en este enfoque y demuestran experimentalmente que puede perjudicar realmente la efectividad de la recuperación. En cambio, aplican los pesos a nivel de frecuencia de términos, donde la aparición de un término de consulta t en el título contribuye más al puntaje que una aparición en el cuerpo. En la ecuación 1, xt se convierte en α0 · yt + α1 · zt, donde yt es el número de veces que t aparece en el título y zt es el número de veces que t aparece en el cuerpo. Al traducir este enfoque a nuestro contexto, la contribución de los términos que aparecen en los elementos se reduce dinámicamente a medida que se informan. La siguiente sección presenta y analiza un algoritmo de reordenamiento simple que sigue esta estrategia. El algoritmo se evalúa experimentalmente en la sección 7. Una limitación del algoritmo es que la contribución de los términos que aparecen en los elementos informados se reduce por el mismo factor independientemente del número de elementos informados en los que aparezca. En la sección 8, el algoritmo se extiende para aplicar pesos crecientes, disminuyendo la puntuación, cuando un término aparece en más de un elemento informado. 6. ALGORITMO DE REORDENAMIENTO El algoritmo de reordenamiento opera sobre árboles XML, como el que aparece en la figura 2. La entrada al algoritmo es una lista de n elementos clasificados según sus puntuaciones iniciales de BM25. Durante la clasificación inicial, el árbol XML se reconstruye dinámicamente para incluir solo aquellos nodos con puntuaciones BM25 distintas de cero, por lo que n puede ser considerablemente menor que |N|. La salida del algoritmo es una lista de los primeros m elementos, clasificados según sus puntajes ajustados. Un elemento está representado por el nodo x ∈ N en su raíz. Asociados con este nodo se encuentran campos que almacenan la longitud del elemento, las frecuencias de términos y otra información requerida por el algoritmo de re-ranking, de la siguiente manera: x.f - vector de frecuencia de términos x.g - ajustes de frecuencia de términos x.l - longitud del elemento x.score - puntaje actual de Okapi BM25 x.reported - bandera booleana, inicialmente falsa x.children - conjunto de nodos hijos x.parent - nodo padre, si existe Estos campos se llenan durante el proceso de clasificación inicial y se actualizan a medida que avanza el algoritmo. El vector x.f contiene información de frecuencia de términos correspondiente a cada término en la consulta. El vector x.g es inicialmente cero y se actualiza por el algoritmo a medida que se informan elementos. El campo de puntuación contiene la puntuación BM25 actual para el elemento, la cual cambiará a medida que cambien los valores en x.g. El puntaje se calcula utilizando la ecuación 1, con el valor xt para cada término determinado por una combinación de los valores en x.f y x.g. Dado un término t ∈ Q, sea ft el componente de x.f correspondiente a t, y sea gt el componente de x.g correspondiente a t, entonces: xt = ft − α · gt (2) Para el procesamiento por el algoritmo de reordenamiento, los nodos se almacenan en colas de prioridad, ordenadas por puntaje decreciente. Cada cola de prioridad PQ admite tres operaciones: PQ.front() - devuelve el nodo con la puntuación más alta, PQ.add(x) - agrega el nodo x a la cola, PQ.remove(x) - elimina el nodo x de la cola. Cuando se implementan utilizando estructuras de datos estándar, la operación front requiere tiempo O(1), y las otras operaciones requieren tiempo O(log n), donde n es el tamaño de la cola. El núcleo del algoritmo de reordenamiento se presenta en la figura 5. El algoritmo toma como entrada la cola de prioridad S que contiene la clasificación inicial, y produce los primeros m nodos reordenados en la cola de prioridad F. Después de inicializar F como vacío en la línea 1, el algoritmo recorre m veces las líneas 215, transfiriendo al menos un nodo de S a F durante cada iteración. Al inicio de cada iteración, el nodo no reportado al frente de S tiene el mayor puntaje ajustado, y se elimina y se agrega a F. El algoritmo luego recorre el 1 F ← ∅ 2 para i ← 1 a m hacer 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 para cada y ∈ x.children hacer 9 Abajo (y) 10 fin hacer 11 12 si x no es un nodo raíz entonces 13 Arriba (x, x.parent) 14 fin si 15 fin hacer Figura 5: Algoritmo de Re-Ranking - Como entrada, el algoritmo toma una cola de prioridad S, que contiene nodos XML clasificados por sus puntajes iniciales, y devuelve sus resultados en la cola de prioridad F, clasificados por puntajes ajustados. 1 Arriba(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recalcular y.score 5 S.add(y) 6 si y no es un nodo raíz entonces 7 Arriba (x, y.parent) 8 fin si 9 10 Abajo(x) ≡ 11 si no x.reported entonces 12 S.remove(x) 14 x.g ← x.f 15 recalcular x.score 16 si x.score > 0 entonces 17 F.add(x) 18 fin si 19 x.reported ← true 20 para cada y ∈ x.children hacer 21 Abajo (y) 22 fin hacer 23 fin si Figura 6: Rutinas de recorrido de árbol llamadas por el algoritmo de re-ranking. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 PrecisiónPromedioMedia (inex-2002) GananciaAcumuladaXML(XCG) alfa MAP (estricto) MAP (generalizado) MAP (sog) XCG (sog2) Figura 7: Impacto de α en XCG y MAP inex-2002 (temas CO de INEX 2004; conjunto de evaluación I). nodos ancestros (líneas 8-10) y descendientes (líneas 12-14) ajustando los puntajes de estos nodos. Las rutinas de recorrido de árboles, Arriba y Abajo, se muestran en la figura 6. El procedimiento Up elimina cada nodo ancestro de S, ajusta sus valores de frecuencia de término, recalcula su puntuación y lo vuelve a agregar a S. El ajuste de los valores de frecuencia de término (línea 3) agrega a y.g solo las ocurrencias de términos no reportadas previamente en x. El recalculo de la puntuación en la línea 4 utiliza las ecuaciones 1 y 2. La rutina Down realiza una operación similar en cada descendiente. Sin embargo, dado que el contenido de cada descendiente está completamente contenido en un elemento informado, su puntuación final puede ser calculada, y se elimina de S y se agrega a F. Para determinar la complejidad temporal del algoritmo, primero observe que un nodo puede ser un argumento de Down como máximo una vez. Posteriormente, la bandera reportada de su padre es verdadera. Durante cada llamada a Down, un nodo puede ser movido de S a F, lo que requiere un tiempo O(log n). Por lo tanto, el tiempo total para todas las llamadas a Down es O(n log n), y podemos ignorar temporalmente las líneas 8-10 de la figura 5 al considerar la complejidad temporal del bucle sobre las líneas 2-15. Durante cada iteración de este bucle, se elimina un nodo y cada uno de sus ancestros de una cola de prioridad y luego se vuelven a agregar a la cola de prioridad. Dado que un nodo puede tener como máximo h ancestros, donde h es la altura máxima de cualquier árbol en la colección, cada una de las m iteraciones requiere un tiempo de O(h log n). La combinación de estas observaciones produce una complejidad temporal general de O((n + mh) log n). En la práctica, volver a clasificar un conjunto de resultados de INEX requiere menos de 200 ms en una PC de escritorio de tres años de antigüedad. EVALUACIÓN Ninguna de las métricas descritas en la sección 3.3 se ajusta adecuadamente a la perspectiva de superposición defendida por este documento. Sin embargo, cuando se toman en conjunto, proporcionan información sobre el comportamiento del algoritmo de reordenamiento. Los paquetes de evaluación de INEX (inex_eval e inex_eval_ng) se utilizaron para calcular los valores de las métricas inex-2002 e inex-2003. Los valores de las métricas XCG fueron calculados utilizando el software proporcionado por sus inventores [11]. La Figura 7 representa juntas las tres variantes de la métrica MAP inex-2002 junto con la métrica XCG. Los valores para estas métricas 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Precisión Media Promedio (inex-2003) alfa estricto, superposición no considerada estricto, superposición considerada generalizado, superposición no considerada generalizado, superposición considerada Figura 8: Impacto de α en MAP inex-2003 (temas CO de INEX 2004; conjunto de evaluación I). se trazan para valores de α entre 0.0 y 1.0. Recordando que la métrica XCG está diseñada para penalizar la superposición, mientras que la métrica inex-2002 ignora la superposición, el conflicto entre las métricas es evidente. Los valores de MAP en un extremo (α = 0.0) y el valor de XCG en el otro extremo (α = 1.0) representan un rendimiento de recuperación comparable a los mejores sistemas en INEX 2004 [8,12]. La Figura 8 muestra los valores de la métrica MAP inex-2003 para dos cuantificaciones, con y sin consideración de la superposición. Una vez más, el conflicto es evidente, con la influencia de α considerablemente disminuida cuando se considera la superposición. 8. ALGORITMO EXTENDIDO Una limitación del algoritmo de reordenamiento es que se utiliza un único peso α para ajustar las puntuaciones tanto de los ancestros como de los descendientes de los elementos informados. Una extensión obvia es usar diferentes pesos en estos dos casos. Además, se utiliza el mismo peso independientemente de cuántas veces un elemento esté contenido en un elemento informado. Por ejemplo, un párrafo puede formar parte de una sección reportada y luego formar parte de un artículo reportado. Dado que el usuario puede haber visto este párrafo dos veces, su puntuación debería ser reducida aún más aumentando el valor del peso. Motivado por estas observaciones, el algoritmo de reordenamiento puede ser extendido con una serie de pesos 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0, donde βj es el peso aplicado a un nodo que ha sido descendiente de un nodo reportado j veces. Ten en cuenta que un límite superior en M es h, la altura máxima de cualquier árbol XML en la colección. Sin embargo, en la práctica es probable que M sea relativamente pequeño (quizás 3 o 4). La Figura 9 presenta reemplazos para las rutinas de Subir y Bajar de la Figura 6, incorporando esta serie de pesas. Se requiere un campo adicional en cada nodo, de la siguiente manera: x.j - conteo descendente El valor de x.j se establece inicialmente en cero en todos los nodos y se incrementa cada vez que se llama a Down con x como su argumento. Al calcular la puntuación del nodo, el valor de x.j selecciona 1 Up(x, y) ≡ 2 si no y.reported entonces 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recalcular y.score 6 S.add(y) 8 si y no es un nodo raíz entonces 9 Up (x, y.padre) 10 fin si 11 fin si 12 13 Down(x) ≡ 14 si x.j < M entonces 15 x.j ← x.j + 1 16 si no x.reported entonces 17 S.remove(x) 18 recalcular x.score 19 S.add(x) 20 fin si 21 para cada y ∈ x.hijos hacer 22 Down (y) 23 fin hacer 24 fin si Figura 9: Rutinas extendidas de recorrido de árbol. el peso a aplicar al nodo ajustando el valor de xt en la ecuación 1, de la siguiente manera: xt = βx.j · (ft − α · gt) (3) donde ft y gt son los componentes de x.f y x.g correspondientes al término t. Se requieren algunos cambios adicionales para extender Up y Down. La rutina Up devuelve inmediatamente (línea 2) si su argumento ya ha sido reportado, ya que las frecuencias de términos ya han sido ajustadas en sus ancestros. El procedimiento Down no informa su argumento, sino que vuelve a calcular su puntuación y la agrega de nuevo a S. Un nodo no puede ser un argumento de Down más de M +1 veces, lo que a su vez implica una complejidad temporal total de O((nM + mh) log n). Dado que M ≤ h y m ≤ n, la complejidad temporal también es O(nh log n). DISCUSIÓN CONCLUSIVA Al generar resultados de recuperación en una colección de XML, se debe tolerar cierta superposición en los resultados, lo cual puede ser beneficioso. Por ejemplo, cuando un elemento altamente exhaustivo y bastante específico (3,2) contiene un elemento mucho más pequeño (2,3), ambos deben ser informados al usuario, y los algoritmos de recuperación y las métricas de evaluación deben respetar esta relación. El algoritmo presentado en este documento controla la superposición ponderando los términos que aparecen en los elementos informados para reflejar su menor importancia. Otros enfoques también pueden ayudar a controlar la superposición. Por ejemplo, cuando se presentan los resultados de recuperación de XML a los usuarios, puede ser deseable agrupar elementos relacionados estructuralmente juntos, ilustrando visualmente las relaciones entre ellos. Si bien este estilo de interfaz de usuario puede ayudar a un usuario a lidiar con la superposición, la estrategia presentada en este documento sigue siendo aplicable, al determinar los mejores elementos para incluir en cada grupo. En Waterloo, seguimos desarrollando y probando nuestras ideas para INEX 2005. En particular, estamos investigando métodos para aprender los pesos α y βj. También estamos reevaluando nuestro enfoque en las estadísticas de documentos y examinando ajustes apropiados al parámetro k1 a medida que cambian los pesos de los términos [20]. 10. AGRADECIMIENTOS Gracias a Gabriella Kazai y Arjen de Vries por proporcionar una versión temprana de su software para calcular la métrica XCG, y gracias a Phil Tilker y Stefan B¨uttcher por su ayuda con la evaluación experimental. En parte, la financiación para este proyecto fue proporcionada por IBM Canadá a través del Instituto Nacional de Investigación de Software. 11. REFERENCIAS [1] N. Bruno, N. Koudas y D. Srivastava. Uniones de ramas holísticas: Coincidencia óptima de patrones XML. En Actas de la Conferencia Internacional ACM SIGMOD 2002 sobre la Gestión de Datos, páginas 310-321, Madison, Wisconsin, junio de 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y. Masa y A. Soffer. Buscando documentos XML a través de fragmentos XML. En Actas de la 26ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 151-158, Toronto, Canadá, 2003. [3] C. L. A. Clarke y P. L. Tilker. Experimentos MultiText para INEX 2004. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai y M. Lalmas. Tolerancia a la irrelevancia: Una evaluación orientada al esfuerzo del usuario de sistemas de recuperación sin unidad de recuperación predefinida. En las Actas de la Conferencia RIAO 2004, páginas 463-473, Aviñón, Francia, abril de 2004. [5] D. DeHaan, D. Toman, M. P. Consens y M. T. ¨Ozsu. Una traducción exhaustiva de XQuery a SQL utilizando codificación dinámica de intervalos. En Actas de la Conferencia Internacional ACM SIGMOD 2003 sobre la Gestión de Datos, San Diego, junio de 2003. [6] N. Fuhr y K. Großjohann. XIRQL: Un lenguaje de consulta para la recuperación de información en documentos XML. En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 172-180, Nueva Orleans, septiembre de 2001. [7] N. Fuhr, M. Lalmas y S. Malik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Segundo Taller (INEX 2003), Dagstuhl, Alemania, diciembre de 2003. [8] N. Fuhr, M. Lalmas, S. Malik y Zoltán Szlávik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Tercer Taller (INEX 2004), Dagstuhl, Alemania, diciembre de 2004. Publicado como Avances en la Recuperación de Información XML, Notas de Conferencia en Ciencias de la Computación, volumen 3493, Springer, 2005. [9] K. J¨avelin y J. Kek¨al¨ainen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, y B. Sigurbjörnsson. Normalización de longitud en la recuperación de XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 80-87, Sheffield, Reino Unido, julio de 2004. [11] G. Kazai, M. Lalmas y A. P. de Vries. El problema de superposición en la evaluación de la recuperación de XML orientada al contenido. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 72-79, Sheffield, Reino Unido, julio de 2004. [12] G. Kazai, M. Lalmas y A. P. de Vries. Pruebas de confiabilidad para las métricas XCG e inex-2002. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola y T. Aalto. TRIX 2004 - Luchando con la superposición. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [14] S. Liu, Q. Zou y W. W. Chu. Indexación y clasificación configurables para la recuperación de información en XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 88-95, Sheffield, Reino Unido, julio de 2004. [15] Y. Masa y M. Mandelbrot. Recuperando los componentes XML más relevantes. En las Actas del Taller INEX 2003, Dagstuhl, Alemania, diciembre de 2003. [16] Y. Masa y M. Mandelbrot. Clasificación de componentes y refinamiento automático de consultas para la recuperación de XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [17] P. Ogilvie y J. Callan. Modelos de lenguaje jerárquicos para la recuperación de componentes XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [18] J. Pehcevski, J. A. Thom y A. Vercoustre. Recuperación híbrida de XML revisitada. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [19] B. Piwowarski y M. Lalmas. Proporcionando evaluaciones de relevancia consistentes y exhaustivas para la evaluación de recuperación de XML. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 361-370, Washington, DC, noviembre de 2004. [20] S. Robertson, H. Zaragoza y M. Taylor. Extensión simple de BM25 a múltiples campos ponderados. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 42-50, Washington, DC, noviembre de 2004. [21] S. E. Robertson, S. Walker y M. Beaulieu. Okapi en TREC-7: Búsqueda automática, filtrado, VLC y pista interactiva. En Actas de la Séptima Conferencia de Recuperación de Texto, Gaithersburg, MD, noviembre de 1998. [22] A. Trotman y B. Sigurbjörnsson. NEXI, ahora y después. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski y P. Gallinari. Un álgebra para consultas estructuradas en redes bayesianas. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "xcg metric reward retrieval": {
            "translated_key": "Recuperación de recompensa métrica XCG",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Controlling Overlap in Content-Oriented XML Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of XML documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
                "This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents.",
                "The test collection developed by the INitiative for the Evaluation of XML Retrieval (INEX) forms the basis for the evaluation.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "INTRODUCTION The representation of documents in XML provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an XML information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in XML.",
                "Figure 1 provides an example of a journal article encoded in XML, illustrating many of the important characteristics of XML documents.",
                "Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words.",
                "Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate.",
                "Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs.",
                "Each of these characteristics affects the design of an XML IR system, and each leads to fundamental problems that must be solved in an successful system.",
                "Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper.",
                "The article of figure 1 may be viewed as an XML tree, as illustrated in figure 2.",
                "Formally, a collection of XML documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes.",
                "For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example XML tree. of x.",
                "Since an element may be represented by the node at its root, the output of an XML IR system may be viewed as a ranked list of the top-m nodes.",
                "The direct application of a standard relevance ranking technique to a set of XML elements can produce a result in which the top ranks are dominated by many structurally related elements.",
                "A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article.",
                "For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms.",
                "If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content.",
                "One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it.",
                "Unfortunately, this approach destroys some of the possible benefits of XML IR.",
                "For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts.",
                "In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements.",
                "Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6].",
                "This paper presents a method for controlling overlap.",
                "Starting with an initial element ranking, a re-ranking algorithm adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
                "For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced.",
                "The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20].",
                "Extending that approach, the re-ranking algorithm varies weights dynamically as elements are processed.",
                "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a baseline retrieval method is presented in section 4.",
                "This baseline method represents a reasonable adaptation of standard IR technology to XML.",
                "Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point.",
                "A re-ranking algorithm implementing this strategy is presented in section 6 and evaluated in section 7.",
                "Section 8 discusses an extended version of the algorithm. 2.",
                "BACKGROUND This section provides a general overview of XML information retrieval and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
                "Much research in the area of XML retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1].",
                "Here, we take a content oriented IR perceptive, focusing on XML documents that primarily contain natural language data and queries that are primarily expressed in natural language.",
                "We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need.",
                "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional information retrieval applications the standard unit of retrieval is taken to be the document.",
                "Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages.",
                "When applying standard relevance ranking techniques in the context of XML IR, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
                "In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole.",
                "If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article.",
                "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an XML IR system might potentially retrieve any element, many elements may not be appropriate as retrieval results.",
                "This is usually the case when elements contain very little text [10].",
                "For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself.",
                "Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user.",
                "An effective XML IR system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18].",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (INEX) has encouraged research into XML information retrieval technology [7,8].",
                "INEX is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
                "Over 50 groups participated in INEX 2004, and the conference has become as influential in the area of XML IR as TREC is in other IR areas.",
                "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by INEX.",
                "Overlap causes considerable problems with retrieval evaluation, and the INEX organizers and participants have wrestled with these problems since the beginning.",
                "While substantial progress has been made, these problem are still not completely solved.",
                "Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of INEX retrieval evaluation and discuss both current and proposed evaluation metrics.",
                "Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3.",
                "INEX 2004 Space limitations prevent the inclusion of more than a brief summary of INEX 2004 tasks and evaluation methodology.",
                "For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, INEX 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002.",
                "Each document is encoded in XML using a common DTD, with the document of figures 1 and 2 providing one example.",
                "At INEX 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics.",
                "The two tasks differed in the types of topics they used.",
                "For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection.",
                "For this task, the IR system is required to select the elements to be returned.",
                "For the other task, the contentand-structure or CAS task, the topics are written in an XML query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy.",
                "Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description.",
                "In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants.",
                "Each topic includes a short keyword query, which is executed over the collection by each participating group on their own XML IR system.",
                "Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since XML IR is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient.",
                "Instead, the INEX organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic.",
                "A four-point scale is used in both dimensions.",
                "Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant.",
                "Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at INEX 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values.",
                "One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others.",
                "This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant.",
                "Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity.",
                "Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity.",
                "This paper reports results of this metric using all three of these quantization functions.",
                "Since this metric was first introduced at INEX 2002, it is generally referred as the inex-2002 metric.",
                "The inex-2002 metric does not penalize overlap.",
                "In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank.",
                "To address this problem, Kazai et al. [11] propose an XML cumulated gain metric, which compares the cumulated gain [9] of a ranked list to an ideal gain vector.",
                "This ideal gain vector is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path.",
                "Thus, the XCG metric rewards retrieval runs that avoid overlap.",
                "While XCG was not used officially at INEX 2004, a version of it is likely to be used in the future.",
                "At INEX 2003, yet another metric was introduced to ameliorate the perceived limitations of the inex-2002 metric.",
                "This inex-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them.",
                "Two versions were created, one that considered only component size and another that considered both size and overlap.",
                "While the inex-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4.",
                "BASELINE RETRIEVAL METHOD This section provides an overview of baseline XML information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3].",
                "This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the XML information retrieval task.",
                "The MultiText system performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
                "To support retrieval from XML and other structured document types, the system provides generalized queries of the form: rank X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms.",
                "For our INEX 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections.",
                "Prior to INEX 2004, the INEX collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names.",
                "Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received.",
                "Automating this selection process is planned as future work.",
                "For INEX 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.",
                "For example, keyword field of topic 166 +tree edit distance + XML -image became the four-term query $tree $edit $distance $xml where the $ operator within a quoted string stems the term that follows it.",
                "Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞.",
                "Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(inex-2002) k1 strict generalized sog Figure 3: Impact of k1 on inex-2002 mean average precision with b = 0.75 (INEX 2003 CO topics).",
                "Prior to INEX 2004, the INEX 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.",
                "For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article.",
                "These statistics are used for ranking all element types.",
                "Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length.",
                "The use of article statistics for all element types might be questioned.",
                "This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.",
                "The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics.",
                "Nonetheless, we plan to examine this issue again in the future.",
                "In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose.",
                "Prior to INEX 2004, we trained the MultiText system using the INEX 2003 queries.",
                "As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system.",
                "The results were surprising.",
                "Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions.",
                "In our experience, optimal values for k1 are typically in the range 0.0 to 2.0.",
                "In this case, large values are required for good performance.",
                "Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization.",
                "Similar improvements are seen under the generalized and sog quantizations.",
                "In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).",
                "After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our INEX 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5.",
                "CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements.",
                "At a conceptual level, re-ranking proceeds as follows: 1.",
                "Report the highest ranking element. 2.",
                "Adjust the scores of the unreported elements. 3.",
                "Repeat steps 1 and 2 until m elements are reported.",
                "One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements.",
                "For example, assume a paragraph with score p is reported in step 1.",
                "In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score.",
                "In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion.",
                "That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages.",
                "A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two.",
                "Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness.",
                "Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body.",
                "In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body.",
                "Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported.",
                "The next section presents and analysis a simple re-ranking algorithm that follows this strategy.",
                "The algorithm is evaluated experimentally in section 7.",
                "One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears.",
                "In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6.",
                "RE-RANKING ALGORITHM The re-ranking algorithm operates over XML trees, such as the one appearing in figure 2.",
                "Input to the algorithm is a list of n elements ranked according to their initial BM25 scores.",
                "During the initial ranking the XML tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |.",
                "Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores.",
                "An element is represented by the node x ∈ N at its root.",
                "Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - term frequency vector x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses.",
                "The vector x.f contains term frequency information corresponding to each term in the query.",
                "The vector x.g is initially zero and is updated by the algorithm as elements are reported.",
                "The score field contains the current BM25 score for the element, which will change as the values in x.g change.",
                "The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g.",
                "Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the re-ranking algorithm, nodes are stored in priority queues, ordered by decreasing score.",
                "Each priority queue PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
                "The core of the re-ranking algorithm is presented in figure 5.",
                "The algorithm takes as input the priority queue S containing the initial ranking, and produces the top-m reranked nodes in the priority queue F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
                "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a priority queue S, containing XML nodes ranked by their initial scores, and returns its results in priority queue F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
                "The tree traversal routines, Up and Down are given in figure 6.",
                "The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2.",
                "The Down routine performs a similar operation on each descendant.",
                "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the time complexity of the algorithm, first note that a node may be an argument to Down at most once.",
                "Thereafter, the reported flag of its parent is true.",
                "During each call to Down a node may be moved from S to F, requiring O(log n) time.",
                "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the time complexity of the loop over lines 2-15.",
                "During each iteration of this loop, a node and each of its ancestors are removed from a priority queue and then added back into a priority queue.",
                "Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time.",
                "Combining these observations produces an overall time complexity of O((n + mh) log n).",
                "In practice, re-ranking an INEX result set requires less than 200ms on a three-year-old desktop PC. 7.",
                "EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper.",
                "Nonetheless, when taken together they provide insight into the behaviour of the re-ranking algorithm.",
                "The INEX evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the inex-2002 and inex-2003 metrics.",
                "Values for the XCG metrics were computed using software supplied by its inventors [11].",
                "Figure 7 plots the three variants of inex-2002 MAP metric together with the XCG metric.",
                "Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on inex-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0.",
                "Recalling that the XCG metric is designed to penalize overlap, while the inex-2002 metric ignores overlap, the conflict between the metrics is obvious.",
                "The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at INEX 2004 [8,12].",
                "Figure 8 plots values of the inex-2003 MAP metric for two quantizations, with and without consideration of overlap.",
                "Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8.",
                "EXTENDED ALGORITHM One limitation of the re-ranking algorithm is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements.",
                "An obvious extension is to use different weights in these two cases.",
                "Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element.",
                "For example, a paragraph may form part of a reported section and then form part of a reported article.",
                "Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight.",
                "Motivated by these observations, the re-ranking algorithm may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times.",
                "Note that an upper bound on M is h, the maximum height of any XML tree in the collection.",
                "However, in practice M is likely to be relatively small (perhaps 3 or 4).",
                "Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights.",
                "One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument.",
                "When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down.",
                "The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors.",
                "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall time complexity of O((nM + mh) log n).",
                "Since M ≤ h and m ≤ n, the time complexity is also O(nh log n). 9.",
                "CONCLUDING DISCUSSION When generating retrieval results over an XML collection, some overlap in the results should be tolerated, and may be beneficial.",
                "For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship.",
                "The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance.",
                "Other approaches may also help to control overlap.",
                "For example, when XML retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them.",
                "While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster.",
                "At Waterloo, we continue to develop and test our ideas for INEX 2005.",
                "In particular, we are investigating methods for learning the α and βj weights.",
                "We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10.",
                "ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation.",
                "In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11.",
                "REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava.",
                "Holistic twig joins: Optimal XML pattern matching.",
                "In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
                "Mass, and A. Soffer.",
                "Searching XML documents via XML fragments.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker.",
                "MultiText experiments for INEX 2004.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas.",
                "Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit.",
                "In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu.",
                "A comprehensive XQuery to SQL translation using dynamic interval encoding.",
                "In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann.",
                "XIRQL: A query language for information retrieval in XML documents.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Second Workshop (INEX 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Third Workshop (INEX 2004), Dagstuhl, Germany, December 2004.",
                "Published as Advances in XML Information Retrieval, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson.",
                "Length normalization in XML retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "The overlap problem in content-oriented XML retrieval evaluation.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "Reliability tests for the XCG and inex-2002 metrics.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto.",
                "TRIX 2004 - Struggling with the overlap.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu.",
                "Configurable indexing and ranking for XML information retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 88-95, Sheffield, UK, July 2004. [15] Y.",
                "Mass and M. Mandelbrod.",
                "Retrieving the most relevant XML components.",
                "In INEX 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y.",
                "Mass and M. Mandelbrod.",
                "Component ranking and automatic query refinement for XML retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan.",
                "Hierarchical language models for XML component retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [18] J. Pehcevski, J.",
                "A. Thom, and A. Vercoustre.",
                "Hybrid XML retrieval re-visited.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas.",
                "Providing consistent and exhaustive relevance assessments for XML retrieval evaluation.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor.",
                "Simple BM25 extension to multiple weighted fields.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu.",
                "Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track.",
                "In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson.",
                "NEXI, now and next.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari.",
                "An algebra for structured queries in bayesian networks.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "multitext system": {
            "translated_key": "sistema MultiText",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Controlling Overlap in Content-Oriented XML Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of XML documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
                "This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents.",
                "The test collection developed by the INitiative for the Evaluation of XML Retrieval (INEX) forms the basis for the evaluation.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "INTRODUCTION The representation of documents in XML provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an XML information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in XML.",
                "Figure 1 provides an example of a journal article encoded in XML, illustrating many of the important characteristics of XML documents.",
                "Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words.",
                "Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate.",
                "Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs.",
                "Each of these characteristics affects the design of an XML IR system, and each leads to fundamental problems that must be solved in an successful system.",
                "Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper.",
                "The article of figure 1 may be viewed as an XML tree, as illustrated in figure 2.",
                "Formally, a collection of XML documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes.",
                "For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example XML tree. of x.",
                "Since an element may be represented by the node at its root, the output of an XML IR system may be viewed as a ranked list of the top-m nodes.",
                "The direct application of a standard relevance ranking technique to a set of XML elements can produce a result in which the top ranks are dominated by many structurally related elements.",
                "A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article.",
                "For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms.",
                "If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content.",
                "One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it.",
                "Unfortunately, this approach destroys some of the possible benefits of XML IR.",
                "For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts.",
                "In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements.",
                "Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6].",
                "This paper presents a method for controlling overlap.",
                "Starting with an initial element ranking, a re-ranking algorithm adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
                "For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced.",
                "The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20].",
                "Extending that approach, the re-ranking algorithm varies weights dynamically as elements are processed.",
                "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a baseline retrieval method is presented in section 4.",
                "This baseline method represents a reasonable adaptation of standard IR technology to XML.",
                "Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point.",
                "A re-ranking algorithm implementing this strategy is presented in section 6 and evaluated in section 7.",
                "Section 8 discusses an extended version of the algorithm. 2.",
                "BACKGROUND This section provides a general overview of XML information retrieval and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
                "Much research in the area of XML retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1].",
                "Here, we take a content oriented IR perceptive, focusing on XML documents that primarily contain natural language data and queries that are primarily expressed in natural language.",
                "We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need.",
                "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional information retrieval applications the standard unit of retrieval is taken to be the document.",
                "Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages.",
                "When applying standard relevance ranking techniques in the context of XML IR, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
                "In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole.",
                "If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article.",
                "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an XML IR system might potentially retrieve any element, many elements may not be appropriate as retrieval results.",
                "This is usually the case when elements contain very little text [10].",
                "For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself.",
                "Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user.",
                "An effective XML IR system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18].",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (INEX) has encouraged research into XML information retrieval technology [7,8].",
                "INEX is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
                "Over 50 groups participated in INEX 2004, and the conference has become as influential in the area of XML IR as TREC is in other IR areas.",
                "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by INEX.",
                "Overlap causes considerable problems with retrieval evaluation, and the INEX organizers and participants have wrestled with these problems since the beginning.",
                "While substantial progress has been made, these problem are still not completely solved.",
                "Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of INEX retrieval evaluation and discuss both current and proposed evaluation metrics.",
                "Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3.",
                "INEX 2004 Space limitations prevent the inclusion of more than a brief summary of INEX 2004 tasks and evaluation methodology.",
                "For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, INEX 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002.",
                "Each document is encoded in XML using a common DTD, with the document of figures 1 and 2 providing one example.",
                "At INEX 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics.",
                "The two tasks differed in the types of topics they used.",
                "For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection.",
                "For this task, the IR system is required to select the elements to be returned.",
                "For the other task, the contentand-structure or CAS task, the topics are written in an XML query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy.",
                "Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description.",
                "In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants.",
                "Each topic includes a short keyword query, which is executed over the collection by each participating group on their own XML IR system.",
                "Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since XML IR is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient.",
                "Instead, the INEX organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic.",
                "A four-point scale is used in both dimensions.",
                "Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant.",
                "Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at INEX 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values.",
                "One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others.",
                "This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant.",
                "Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity.",
                "Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity.",
                "This paper reports results of this metric using all three of these quantization functions.",
                "Since this metric was first introduced at INEX 2002, it is generally referred as the inex-2002 metric.",
                "The inex-2002 metric does not penalize overlap.",
                "In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank.",
                "To address this problem, Kazai et al. [11] propose an XML cumulated gain metric, which compares the cumulated gain [9] of a ranked list to an ideal gain vector.",
                "This ideal gain vector is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path.",
                "Thus, the XCG metric rewards retrieval runs that avoid overlap.",
                "While XCG was not used officially at INEX 2004, a version of it is likely to be used in the future.",
                "At INEX 2003, yet another metric was introduced to ameliorate the perceived limitations of the inex-2002 metric.",
                "This inex-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them.",
                "Two versions were created, one that considered only component size and another that considered both size and overlap.",
                "While the inex-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4.",
                "BASELINE RETRIEVAL METHOD This section provides an overview of baseline XML information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3].",
                "This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the XML information retrieval task.",
                "The <br>multitext system</br> performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
                "To support retrieval from XML and other structured document types, the system provides generalized queries of the form: rank X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms.",
                "For our INEX 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections.",
                "Prior to INEX 2004, the INEX collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names.",
                "Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received.",
                "Automating this selection process is planned as future work.",
                "For INEX 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.",
                "For example, keyword field of topic 166 +tree edit distance + XML -image became the four-term query $tree $edit $distance $xml where the $ operator within a quoted string stems the term that follows it.",
                "Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞.",
                "Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(inex-2002) k1 strict generalized sog Figure 3: Impact of k1 on inex-2002 mean average precision with b = 0.75 (INEX 2003 CO topics).",
                "Prior to INEX 2004, the INEX 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.",
                "For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article.",
                "These statistics are used for ranking all element types.",
                "Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length.",
                "The use of article statistics for all element types might be questioned.",
                "This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.",
                "The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics.",
                "Nonetheless, we plan to examine this issue again in the future.",
                "In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose.",
                "Prior to INEX 2004, we trained the <br>multitext system</br> using the INEX 2003 queries.",
                "As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system.",
                "The results were surprising.",
                "Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions.",
                "In our experience, optimal values for k1 are typically in the range 0.0 to 2.0.",
                "In this case, large values are required for good performance.",
                "Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization.",
                "Similar improvements are seen under the generalized and sog quantizations.",
                "In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).",
                "After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our INEX 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5.",
                "CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements.",
                "At a conceptual level, re-ranking proceeds as follows: 1.",
                "Report the highest ranking element. 2.",
                "Adjust the scores of the unreported elements. 3.",
                "Repeat steps 1 and 2 until m elements are reported.",
                "One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements.",
                "For example, assume a paragraph with score p is reported in step 1.",
                "In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score.",
                "In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion.",
                "That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages.",
                "A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two.",
                "Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness.",
                "Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body.",
                "In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body.",
                "Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported.",
                "The next section presents and analysis a simple re-ranking algorithm that follows this strategy.",
                "The algorithm is evaluated experimentally in section 7.",
                "One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears.",
                "In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6.",
                "RE-RANKING ALGORITHM The re-ranking algorithm operates over XML trees, such as the one appearing in figure 2.",
                "Input to the algorithm is a list of n elements ranked according to their initial BM25 scores.",
                "During the initial ranking the XML tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |.",
                "Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores.",
                "An element is represented by the node x ∈ N at its root.",
                "Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - term frequency vector x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses.",
                "The vector x.f contains term frequency information corresponding to each term in the query.",
                "The vector x.g is initially zero and is updated by the algorithm as elements are reported.",
                "The score field contains the current BM25 score for the element, which will change as the values in x.g change.",
                "The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g.",
                "Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the re-ranking algorithm, nodes are stored in priority queues, ordered by decreasing score.",
                "Each priority queue PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
                "The core of the re-ranking algorithm is presented in figure 5.",
                "The algorithm takes as input the priority queue S containing the initial ranking, and produces the top-m reranked nodes in the priority queue F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
                "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a priority queue S, containing XML nodes ranked by their initial scores, and returns its results in priority queue F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
                "The tree traversal routines, Up and Down are given in figure 6.",
                "The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2.",
                "The Down routine performs a similar operation on each descendant.",
                "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the time complexity of the algorithm, first note that a node may be an argument to Down at most once.",
                "Thereafter, the reported flag of its parent is true.",
                "During each call to Down a node may be moved from S to F, requiring O(log n) time.",
                "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the time complexity of the loop over lines 2-15.",
                "During each iteration of this loop, a node and each of its ancestors are removed from a priority queue and then added back into a priority queue.",
                "Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time.",
                "Combining these observations produces an overall time complexity of O((n + mh) log n).",
                "In practice, re-ranking an INEX result set requires less than 200ms on a three-year-old desktop PC. 7.",
                "EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper.",
                "Nonetheless, when taken together they provide insight into the behaviour of the re-ranking algorithm.",
                "The INEX evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the inex-2002 and inex-2003 metrics.",
                "Values for the XCG metrics were computed using software supplied by its inventors [11].",
                "Figure 7 plots the three variants of inex-2002 MAP metric together with the XCG metric.",
                "Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on inex-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0.",
                "Recalling that the XCG metric is designed to penalize overlap, while the inex-2002 metric ignores overlap, the conflict between the metrics is obvious.",
                "The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at INEX 2004 [8,12].",
                "Figure 8 plots values of the inex-2003 MAP metric for two quantizations, with and without consideration of overlap.",
                "Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8.",
                "EXTENDED ALGORITHM One limitation of the re-ranking algorithm is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements.",
                "An obvious extension is to use different weights in these two cases.",
                "Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element.",
                "For example, a paragraph may form part of a reported section and then form part of a reported article.",
                "Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight.",
                "Motivated by these observations, the re-ranking algorithm may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times.",
                "Note that an upper bound on M is h, the maximum height of any XML tree in the collection.",
                "However, in practice M is likely to be relatively small (perhaps 3 or 4).",
                "Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights.",
                "One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument.",
                "When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down.",
                "The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors.",
                "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall time complexity of O((nM + mh) log n).",
                "Since M ≤ h and m ≤ n, the time complexity is also O(nh log n). 9.",
                "CONCLUDING DISCUSSION When generating retrieval results over an XML collection, some overlap in the results should be tolerated, and may be beneficial.",
                "For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship.",
                "The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance.",
                "Other approaches may also help to control overlap.",
                "For example, when XML retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them.",
                "While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster.",
                "At Waterloo, we continue to develop and test our ideas for INEX 2005.",
                "In particular, we are investigating methods for learning the α and βj weights.",
                "We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10.",
                "ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation.",
                "In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11.",
                "REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava.",
                "Holistic twig joins: Optimal XML pattern matching.",
                "In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
                "Mass, and A. Soffer.",
                "Searching XML documents via XML fragments.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker.",
                "MultiText experiments for INEX 2004.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas.",
                "Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit.",
                "In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu.",
                "A comprehensive XQuery to SQL translation using dynamic interval encoding.",
                "In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann.",
                "XIRQL: A query language for information retrieval in XML documents.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Second Workshop (INEX 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Third Workshop (INEX 2004), Dagstuhl, Germany, December 2004.",
                "Published as Advances in XML Information Retrieval, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson.",
                "Length normalization in XML retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "The overlap problem in content-oriented XML retrieval evaluation.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "Reliability tests for the XCG and inex-2002 metrics.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto.",
                "TRIX 2004 - Struggling with the overlap.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu.",
                "Configurable indexing and ranking for XML information retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 88-95, Sheffield, UK, July 2004. [15] Y.",
                "Mass and M. Mandelbrod.",
                "Retrieving the most relevant XML components.",
                "In INEX 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y.",
                "Mass and M. Mandelbrod.",
                "Component ranking and automatic query refinement for XML retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan.",
                "Hierarchical language models for XML component retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [18] J. Pehcevski, J.",
                "A. Thom, and A. Vercoustre.",
                "Hybrid XML retrieval re-visited.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas.",
                "Providing consistent and exhaustive relevance assessments for XML retrieval evaluation.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor.",
                "Simple BM25 extension to multiple weighted fields.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu.",
                "Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track.",
                "In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson.",
                "NEXI, now and next.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari.",
                "An algebra for structured queries in bayesian networks.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]."
            ],
            "original_annotated_samples": [
                "The <br>multitext system</br> performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
                "Prior to INEX 2004, we trained the <br>multitext system</br> using the INEX 2003 queries."
            ],
            "translated_annotated_samples": [
                "El <br>sistema MultiText</br> tuvo un desempeño respetable en INEX 2004, ubicándose entre los diez primeros en todas las funciones de cuantización, y ocupando el primer lugar cuando la función de cuantización enfatizaba la exhaustividad.",
                "Antes de INEX 2004, entrenamos el <br>sistema MultiText</br> utilizando las consultas de INEX 2003."
            ],
            "translated_text": "Controlando la superposición en la recuperación XML orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca RESUMEN La aplicación directa de técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos XML a menudo produce un conjunto de resultados en el que los primeros puestos están dominados por un gran número de elementos tomados de un pequeño número de documentos altamente relevantes. Este documento presenta y evalúa un algoritmo que vuelve a clasificar este conjunto de resultados, con el objetivo de minimizar el contenido redundante mientras se preservan los beneficios de la recuperación de elementos, incluido el beneficio de identificar componentes centrados en el tema contenidos en documentos relevantes. La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la Recuperación XML (INEX) constituye la base para la evaluación. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Búsqueda y Recuperación de Información Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. La representación de documentos en XML brinda una oportunidad para que los sistemas de recuperación de información aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias. En respuesta a una consulta de usuario, un sistema de recuperación de información XML podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes. Esta facilidad es de particular beneficio cuando una colección contiene documentos muy largos, como manuales de productos o libros, donde el usuario debe ser dirigido a las partes más relevantes de estos documentos. La Figura 1 proporciona un ejemplo de un artículo de revista codificado en XML, ilustrando muchas de las características importantes de los documentos XML. Las etiquetas indican el inicio y el final de cada elemento, con elementos que varían ampliamente en tamaño, desde una palabra hasta miles de palabras. Algunos elementos, como párrafos y secciones, pueden presentarse razonablemente al usuario como resultados de búsqueda, pero otros no son apropiados. Los elementos se superponen entre sí: los artículos contienen secciones, las secciones contienen subsecciones y las subsecciones contienen párrafos. Cada una de estas características afecta el diseño de un sistema de IR XML, y cada una conlleva problemas fundamentales que deben resolverse en un sistema exitoso. La mayoría de estos problemas fundamentales pueden resolverse mediante la cuidadosa adaptación de técnicas estándar de IR, pero los problemas causados por la superposición son únicos en esta área [4,11] y constituyen el enfoque principal de este artículo. El artículo de la figura 1 puede ser visto como un árbol XML, como se ilustra en la figura 2. Formalmente, una colección de documentos XML puede ser representada como un bosque de árboles ordenados y enraizados, que consiste en un conjunto de nodos N y un conjunto de aristas dirigidas E que conectan estos nodos. Para cada nodo x ∈ N, la notación x.parent se refiere al nodo padre de x, si existe, y la notación x.children se refiere al conjunto de nodos hijos de x. Dado que un elemento puede estar representado por el nodo en su raíz, la salida de un sistema de IR XML puede ser vista como una lista clasificada de los m nodos principales. La aplicación directa de una técnica estándar de clasificación de relevancia a un conjunto de elementos XML puede producir un resultado en el que los primeros puestos están dominados por muchos elementos estructuralmente relacionados. Una sección con una puntuación alta probablemente contenga varios párrafos con una puntuación alta y esté contenida en un artículo con una puntuación alta. Por ejemplo, muchos de los elementos en la figura 2 recibirían una puntuación alta en los algoritmos de compresión de índices de texto de consulta de palabras clave. Si cada uno de estos elementos se presenta a un usuario como un resultado individual y separado, puede perder mucho tiempo revisando y rechazando contenido redundante. Una posible solución es informar solo el elemento de mayor puntuación a lo largo de un camino dado en el árbol, y eliminar de los rangos inferiores cualquier elemento que lo contenga o esté contenido en él. Desafortunadamente, este enfoque destruye algunos de los posibles beneficios de XML IR. Por ejemplo, un elemento externo puede contener una cantidad sustancial de información que no aparece en un elemento interno, pero el elemento interno puede estar fuertemente enfocado en el tema de la consulta y proporcionar un breve resumen de los conceptos clave. En tales casos, es razonable informar sobre elementos que contienen, o están contenidos en, elementos de rango superior. Incluso cuando un libro entero es relevante, un usuario aún puede desear que se destaquen los párrafos más importantes, para guiar su lectura y ahorrar tiempo [6]. Este documento presenta un método para controlar la superposición. A partir de una clasificación inicial de elementos, un algoritmo de re-clasificación ajusta las puntuaciones de los elementos de menor clasificación que contienen, o están contenidos dentro de, elementos de mayor clasificación, reflejando el hecho de que esta información puede ser ahora redundante. Por ejemplo, una vez que un elemento que representa una sección aparece en la clasificación, las puntuaciones de los párrafos que contiene y del artículo que lo contiene se reducen. La inspiración para esta estrategia proviene parcialmente del trabajo reciente sobre la recuperación de documentos estructurados, donde los términos que aparecen en diferentes campos, como el título y el cuerpo, reciben diferentes pesos [20]. Extendiendo ese enfoque, el algoritmo de reordenamiento varía los pesos dinámicamente a medida que se procesan los elementos. El resto del documento está organizado de la siguiente manera: Después de una discusión sobre el trabajo de antecedentes y la metodología de evaluación, se presenta un método de recuperación de referencia en la sección 4. Este método de referencia representa una adaptación razonable de la tecnología estándar de IR al XML. La sección 5 luego describe una estrategia para controlar la superposición, utilizando el método de línea base como punto de partida. Un algoritmo de reordenamiento que implementa esta estrategia se presenta en la sección 6 y se evalúa en la sección 7. La sección 8 discute una versión extendida del algoritmo. 2. ANTECEDENTES Esta sección proporciona una visión general de la recuperación de información XML y discute trabajos relacionados, con énfasis en los problemas fundamentales mencionados en la introducción. Mucha investigación en el área de recuperación de XML lo ve desde una perspectiva de base de datos tradicional, preocupándose por problemas como la implementación de lenguajes de consulta estructurados [5] y el procesamiento de joins [1]. Aquí adoptamos una perspectiva de IR orientada al contenido, centrándonos en documentos XML que contienen principalmente datos en lenguaje natural y consultas que están principalmente expresadas en lenguaje natural. Suponemos que estas consultas indican únicamente la naturaleza del contenido deseado, no su estructura, y que el papel del sistema de RI es determinar qué elementos satisfacen mejor la necesidad de información subyacente. Otra investigación en IR ha considerado consultas mixtas, en las que se especifican tanto requisitos de contenido como estructurales [2,6,14,17,23]. 2.1 Estadísticas de Términos y Documentos En las aplicaciones tradicionales de recuperación de información, la unidad estándar de recuperación se considera que es el documento. Dependiendo de la aplicación, este término podría interpretarse para abarcar muchos objetos diferentes, incluyendo páginas web, artículos de periódico y mensajes de correo electrónico. Al aplicar técnicas estándar de clasificación de relevancia en el contexto de la RI XML, un enfoque natural es tratar cada elemento como un documento separado, con estadísticas de términos disponibles para cada uno [16]. Además, la mayoría de las técnicas de clasificación requieren estadísticas globales (por ejemplo, frecuencia inversa de documentos) calculadas sobre la colección en su totalidad. Si consideramos que esta colección incluye todos los elementos que podrían ser devueltos por el sistema, una ocurrencia específica de un término puede aparecer en varios documentos diferentes, quizás en elementos que representan un párrafo, una subsección, una sección y un artículo. No es apropiado calcular la frecuencia inversa de documentos bajo la suposición de que el término está contenido en todos estos elementos, ya que el número de elementos que contienen un término depende completamente del arreglo estructural de los documentos [13,23]. 2.2 Elementos Recuperables Si bien un sistema de recuperación de información XML podría potencialmente recuperar cualquier elemento, muchos elementos pueden no ser apropiados como resultados de recuperación. Esto suele ser el caso cuando los elementos contienen muy poco texto [10]. Por ejemplo, un título de sección que contenga solo los términos de búsqueda puede recibir una puntuación alta de un algoritmo de clasificación, pero por sí solo tendría un valor limitado para un usuario, quien podría preferir la sección real en sí misma. Otros elementos pueden reflejar la estructura física de los documentos, en lugar de la estructura lógica, lo cual puede tener poco o ningún significado para un usuario. Un sistema de recuperación de información XML efectivo debe devolver solo aquellos elementos que tengan suficiente contenido para ser utilizables y puedan funcionar como objetos independientes [15,18]. Componentes estándar de documentos como párrafos, secciones, subsecciones y resúmenes generalmente cumplen con estos requisitos; los títulos, frases en cursiva y campos de metadatos individuales a menudo no lo hacen. 2.3 Metodología de Evaluación En los últimos tres años, la Iniciativa para la Evaluación de la Recuperación de Información XML (INEX) ha fomentado la investigación en tecnología de recuperación de información XML [7,8]. INEX es una serie de conferencias experimentales, similar a TREC, en la que grupos de diferentes instituciones completan una o más tareas experimentales utilizando sus propias herramientas y sistemas, y comparan sus resultados en la propia conferencia. Más de 50 grupos participaron en INEX 2004, y la conferencia se ha convertido en tan influyente en el área de la RI XML como lo es TREC en otras áreas de la RI. La investigación descrita en este artículo, al igual que gran parte del trabajo relacionado que cita, depende de las colecciones de pruebas desarrolladas por INEX. La superposición causa problemas considerables en la evaluación de la recuperación, y los organizadores y participantes de INEX han luchado con estos problemas desde el principio. Aunque se ha logrado un progreso sustancial, estos problemas aún no están completamente resueltos. Kazai et al. [11] proporcionan una exposición detallada del problema de superposición en el contexto de la evaluación de recuperación de INEX y discuten tanto las métricas de evaluación actuales como las propuestas. Muchas de estas métricas se aplican para evaluar los experimentos reportados en este artículo, y se describen brevemente en la siguiente sección. 3. Las limitaciones de espacio impiden incluir más que un breve resumen de las tareas y metodología de evaluación de INEX 2004. Para obtener información detallada, se deben consultar las actas de la conferencia en sí [8]. 3.1 Tareas Para las principales tareas experimentales, a los participantes de INEX 2004 se les proporcionó una colección de 12,107 artículos tomados de las revistas y publicaciones de la IEEE Computer Societies entre 1995 y 2002. Cada documento está codificado en XML utilizando una DTD común, siendo el documento de las figuras 1 y 2 un ejemplo. En INEX 2004, las dos principales tareas experimentales fueron ambas tareas de recuperación ad hoc, investigando el rendimiento de sistemas que buscan en una colección estática utilizando temas previamente no vistos. Las dos tareas diferían en los tipos de temas que utilizaban. Para una tarea, la tarea de solo contenido o CO, los temas consisten en declaraciones cortas en lenguaje natural sin hacer referencia directa a la estructura de los documentos en la colección. Para esta tarea, se requiere que el sistema de IR seleccione los elementos a devolver. Para la otra tarea, la tarea de contenido y estructura o CAS, los temas están escritos en un lenguaje de consulta XML [22] y contienen referencias explícitas a la estructura del documento, que el sistema de IR debe intentar satisfacer. Dado que el trabajo descrito en este documento se enfoca en la tarea de solo contenido, donde el sistema de IR no recibe orientación sobre los elementos a devolver, la tarea de CAS se ignora en el resto de nuestra descripción. En 2004, los organizadores de la conferencia seleccionaron 40 nuevos temas de CO de las contribuciones proporcionadas por los participantes de la conferencia. Cada tema incluye una breve consulta de palabras clave, la cual es ejecutada sobre la colección por cada grupo participante en su propio sistema de IR XML. Cada grupo podría presentar hasta tres ejecuciones experimentales que consistieran en los primeros m = 1500 elementos para cada tema. 3.2 Evaluación de Relevancia Dado que la RI XML se preocupa por localizar aquellos elementos que proporcionan una cobertura completa de un tema mientras contienen la menor cantidad de información irrelevante posible, los juicios simples de relevante vs. no relevante no son suficientes. En cambio, los organizadores de INEX adoptaron dos dimensiones para la evaluación de relevancia: la dimensión de exhaustividad refleja el grado en que un elemento abarca el tema, y la dimensión de especificidad refleja el grado en que un elemento se enfoca en el tema. Se utiliza una escala de cuatro puntos en ambas dimensiones. Por lo tanto, un elemento (3,3) es altamente exhaustivo y altamente específico, un elemento (1,3) es marginalmente exhaustivo y altamente específico, y un elemento (0,0) no es relevante. Información adicional sobre la metodología de evaluación se puede encontrar en Piwowarski y Lalmas [19], quienes proporcionan una justificación detallada. 3.3 Métricas de Evaluación La métrica de evaluación principal utilizada en INEX 2004 es una versión de la precisión promedio media (MAP), ajustada por diversas funciones de cuantificación para dar diferentes pesos a diferentes elementos, dependiendo de sus valores de exhaustividad y especificidad. Una variante, la función de cuantización estricta asigna un peso de 1 a los elementos (3,3) y un peso de 0 a todos los demás. Esta variante es esencialmente el valor MAP familiar, con elementos (3,3) tratados como relevantes y todos los demás elementos tratados como no relevantes. Otras funciones de cuantización están diseñadas para otorgar crédito parcial a elementos que son aproximaciones cercanas, debido a la falta de exhaustividad y/o especificidad. Tanto la función de cuantificación generalizada como la función de generalización orientada a la especificidad (sog) acreditan elementos según su grado de relevancia [11], siendo que la segunda función pone mayor énfasis en la especificidad. Este documento informa los resultados de esta métrica utilizando las tres funciones de cuantización. Desde que esta métrica fue introducida por primera vez en INEX 2002, generalmente se le conoce como la métrica inex-2002. La métrica inex-2002 no penaliza la superposición. En particular, tanto las funciones de cuantificación generalizadas como las de sog otorgan crédito parcial a un casi acierto incluso cuando se informa un elemento (3,3) que se superpone a él en un rango más alto. Para abordar este problema, Kazai et al. [11] proponen una métrica de ganancia acumulada XML, que compara la ganancia acumulada [9] de una lista clasificada con un vector de ganancia ideal. Este vector de ganancia ideal se construye a partir de las valoraciones de relevancia al eliminar la superposición y retener solo el mejor elemento a lo largo de un camino dado. Por lo tanto, la métrica XCG recompensa las ejecuciones de recuperación que evitan la superposición. Aunque XCG no se utilizó oficialmente en INEX 2004, es probable que se utilice una versión de él en el futuro. En INEX 2003, se introdujo otra métrica para mejorar las limitaciones percibidas de la métrica inex-2002. Este métrico inex-2003 extiende las definiciones de precisión y exhaustividad para considerar tanto el tamaño de los componentes informados como la superposición entre ellos. Se crearon dos versiones, una que consideraba solo el tamaño de los componentes y otra que consideraba tanto el tamaño como la superposición. Si bien la métrica inex-2003 presenta anomalías no deseadas [11] y no se utilizó en 2004, se informan valores en la sección de evaluación para proporcionar un instrumento adicional para investigar la superposición. 4. MÉTODO DE RECUPERACIÓN DE BASELINE Esta sección proporciona una descripción general del método de recuperación de información XML de base actualmente utilizado en el sistema MultiText IR, desarrollado por el Grupo de Recuperación de Información de la Universidad de Waterloo [3]. Este método de recuperación resulta de la adaptación y ajuste de la medida Okapi BM25 [21] a la tarea de recuperación de información en XML. El <br>sistema MultiText</br> tuvo un desempeño respetable en INEX 2004, ubicándose entre los diez primeros en todas las funciones de cuantización, y ocupando el primer lugar cuando la función de cuantización enfatizaba la exhaustividad. Para admitir la recuperación de XML y otros tipos de documentos estructurados, el sistema proporciona consultas generalizadas de la forma: clasificar X por Y donde X es una subconsulta que especifica un conjunto de elementos de documentos a clasificar y Y es un vector de subconsultas que especifican términos de recuperación individuales. Para nuestras ejecuciones de INEX 2004, la subconsulta X especificó una lista de elementos recuperables como aquellos con nombres de etiquetas de la siguiente manera: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt. Esta lista incluye entradas bibliográficas (bb) y leyendas de figuras (fig) así como párrafos, secciones y subsecciones. Antes de INEX 2004, la colección de INEX y las evaluaciones de relevancia de INEX 2003 fueron analizadas manualmente para seleccionar estos nombres de etiquetas. Los nombres de las etiquetas fueron seleccionados en base a su frecuencia en la colección, el tamaño promedio de sus elementos asociados y el número relativo de juicios de relevancia positiva que recibieron. Automatizar este proceso de selección está planeado como trabajo futuro. Para INEX 2004, el vector término Y se derivó del tema dividiendo frases en palabras individuales, eliminando palabras vacías y términos negativos (aquellos que comienzan con -), y aplicando un stemmer. Por ejemplo, el campo de palabra clave del tema 166 +distancia de edición de árbol + XML -imagen se convirtió en la consulta de cuatro términos $árbol $edición $distancia $xml donde el operador $ dentro de una cadena entre comillas deriva el término que le sigue. Nuestra implementación de Okapi BM25 se deriva de la fórmula de Robertson et al. [21] al establecer los parámetros k2 = 0 y k3 = ∞. Dado un conjunto de términos Q, a un elemento x se le asigna la puntuación t∈Q w(1) qt (k1 + 1)xt K + xt (1) donde w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = número de documentos en el corpus Dt = número de documentos que contienen t qt = frecuencia con la que t ocurre en el tema xt = frecuencia con la que t ocurre en x K = k1((1 − b) + b · lx/lavg) lx = longitud de x lavg = longitud promedio del documento 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 PrecisiónPromedio(inex-2002) k1 estricto generalizado sog Figura 3: Impacto de k1 en la precisión promedio de inex-2002 con b = 0.75 (temas CO de INEX 2003). Antes de INEX 2004, los temas y juicios de INEX 2003 se utilizaron para ajustar los parámetros b y k1, y el impacto de este ajuste se discute más adelante en esta sección. Para los propósitos de calcular estadísticas a nivel de documento (D, Dt y lavg), un documento se define como un artículo. Estas estadísticas se utilizan para clasificar todos los tipos de elementos. Siguiendo la sugerencia de Kamps et al. [10], los resultados de recuperación se filtran para eliminar elementos muy cortos, aquellos con menos de 25 palabras de longitud. El uso de estadísticas de artículos para todos los tipos de elementos podría ser cuestionado. Este enfoque puede justificarse al considerar la colección como un conjunto de artículos que se pueden buscar utilizando técnicas estándar orientadas a documentos, donde solo se devuelven artículos. El puntaje calculado para un elemento es esencialmente el puntaje que recibiría si se agregara a la colección como un nuevo documento, ignorando los ajustes menores necesarios para las estadísticas a nivel de documento. Sin embargo, planeamos examinar este tema nuevamente en el futuro. En nuestra experiencia, el rendimiento de BM25 suele beneficiarse al ajustar los parámetros b y k1 a la colección, siempre que haya consultas de entrenamiento disponibles con este propósito. Antes de INEX 2004, entrenamos el <br>sistema MultiText</br> utilizando las consultas de INEX 2003. Como punto de partida, utilizamos los valores b = 0.75 y k1 = 1.2, que funcionan bien en colecciones TREC adhoc y se utilizan como valores predeterminados en nuestro sistema. Los resultados fueron sorprendentes. La Figura 3 muestra el resultado de variar k1 con b = 0.75 en los valores de MAP bajo tres funciones de cuantización. En nuestra experiencia, los valores óptimos para k1 suelen estar en el rango de 0.0 a 2.0. En este caso, se requieren valores grandes para un buen rendimiento. Entre k1 = 1.0 y k1 = 6.0, el MAP aumenta en más del 15% bajo la cuantización estricta. Se observan mejoras similares bajo las cuantizaciones generalizada y SOG. Por el contrario, nuestro valor predeterminado de b = 0.75 funciona bien bajo todas las funciones de cuantificación (figura 4). Después de ajustar una amplia gama de valores bajo varias funciones de cuantización, seleccionamos los valores de k = 10.0 y b = 0.80 para nuestros experimentos de INEX 2004, y estos valores se utilizan para los experimentos reportados en la sección 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 PrecisiónPromedioMedia (inex-2002) b estricto generalizado sog Figura 4: Impacto de b en la precisión promedio media de inex-2002 con k1 = 10 (temas CO de INEX 2003). 5. CONTROL DE SUPERPOSICIÓN Comenzando con una clasificación de elementos generada por el método de referencia descrito en la sección anterior, los elementos se vuelven a clasificar para controlar la superposición ajustando de forma iterativa las puntuaciones de aquellos elementos que contienen o están contenidos en elementos de clasificación más alta. A nivel conceptual, la reorganización procede de la siguiente manera: 1. Informe el elemento de rango más alto. Ajustar las puntuaciones de los elementos no reportados. 3. Repetir los pasos 1 y 2 hasta que se informen m elementos. Un enfoque para ajustar las puntuaciones de los elementos no informados en el paso 2 podría basarse en las puntuaciones Okapi BM25 de los elementos involucrados. Por ejemplo, supongamos que se informa un párrafo con una puntuación p en el paso 1. En el paso 2, la sección que contiene el párrafo podría tener su puntuación s reducida en una cantidad α · p para reflejar la contribución reducida que el párrafo debería hacer a la puntuación de las secciones. En un contexto relacionado, Robertson et al. [20] argumentan en contra de la combinación lineal de las puntuaciones de Okapi de esta manera. Ese trabajo considera el problema de asignar diferentes pesos a diferentes campos de documentos, como el título y el cuerpo asociados con páginas web. Un enfoque común para este problema puntúa el título y el cuerpo por separado y genera una puntuación final como una combinación lineal de ambos. Robertson et al. discuten las deficiencias teóricas en este enfoque y demuestran experimentalmente que puede perjudicar realmente la efectividad de la recuperación. En cambio, aplican los pesos a nivel de frecuencia de términos, donde la aparición de un término de consulta t en el título contribuye más al puntaje que una aparición en el cuerpo. En la ecuación 1, xt se convierte en α0 · yt + α1 · zt, donde yt es el número de veces que t aparece en el título y zt es el número de veces que t aparece en el cuerpo. Al traducir este enfoque a nuestro contexto, la contribución de los términos que aparecen en los elementos se reduce dinámicamente a medida que se informan. La siguiente sección presenta y analiza un algoritmo de reordenamiento simple que sigue esta estrategia. El algoritmo se evalúa experimentalmente en la sección 7. Una limitación del algoritmo es que la contribución de los términos que aparecen en los elementos informados se reduce por el mismo factor independientemente del número de elementos informados en los que aparezca. En la sección 8, el algoritmo se extiende para aplicar pesos crecientes, disminuyendo la puntuación, cuando un término aparece en más de un elemento informado. 6. ALGORITMO DE REORDENAMIENTO El algoritmo de reordenamiento opera sobre árboles XML, como el que aparece en la figura 2. La entrada al algoritmo es una lista de n elementos clasificados según sus puntuaciones iniciales de BM25. Durante la clasificación inicial, el árbol XML se reconstruye dinámicamente para incluir solo aquellos nodos con puntuaciones BM25 distintas de cero, por lo que n puede ser considerablemente menor que |N|. La salida del algoritmo es una lista de los primeros m elementos, clasificados según sus puntajes ajustados. Un elemento está representado por el nodo x ∈ N en su raíz. Asociados con este nodo se encuentran campos que almacenan la longitud del elemento, las frecuencias de términos y otra información requerida por el algoritmo de re-ranking, de la siguiente manera: x.f - vector de frecuencia de términos x.g - ajustes de frecuencia de términos x.l - longitud del elemento x.score - puntaje actual de Okapi BM25 x.reported - bandera booleana, inicialmente falsa x.children - conjunto de nodos hijos x.parent - nodo padre, si existe Estos campos se llenan durante el proceso de clasificación inicial y se actualizan a medida que avanza el algoritmo. El vector x.f contiene información de frecuencia de términos correspondiente a cada término en la consulta. El vector x.g es inicialmente cero y se actualiza por el algoritmo a medida que se informan elementos. El campo de puntuación contiene la puntuación BM25 actual para el elemento, la cual cambiará a medida que cambien los valores en x.g. El puntaje se calcula utilizando la ecuación 1, con el valor xt para cada término determinado por una combinación de los valores en x.f y x.g. Dado un término t ∈ Q, sea ft el componente de x.f correspondiente a t, y sea gt el componente de x.g correspondiente a t, entonces: xt = ft − α · gt (2) Para el procesamiento por el algoritmo de reordenamiento, los nodos se almacenan en colas de prioridad, ordenadas por puntaje decreciente. Cada cola de prioridad PQ admite tres operaciones: PQ.front() - devuelve el nodo con la puntuación más alta, PQ.add(x) - agrega el nodo x a la cola, PQ.remove(x) - elimina el nodo x de la cola. Cuando se implementan utilizando estructuras de datos estándar, la operación front requiere tiempo O(1), y las otras operaciones requieren tiempo O(log n), donde n es el tamaño de la cola. El núcleo del algoritmo de reordenamiento se presenta en la figura 5. El algoritmo toma como entrada la cola de prioridad S que contiene la clasificación inicial, y produce los primeros m nodos reordenados en la cola de prioridad F. Después de inicializar F como vacío en la línea 1, el algoritmo recorre m veces las líneas 215, transfiriendo al menos un nodo de S a F durante cada iteración. Al inicio de cada iteración, el nodo no reportado al frente de S tiene el mayor puntaje ajustado, y se elimina y se agrega a F. El algoritmo luego recorre el 1 F ← ∅ 2 para i ← 1 a m hacer 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 para cada y ∈ x.children hacer 9 Abajo (y) 10 fin hacer 11 12 si x no es un nodo raíz entonces 13 Arriba (x, x.parent) 14 fin si 15 fin hacer Figura 5: Algoritmo de Re-Ranking - Como entrada, el algoritmo toma una cola de prioridad S, que contiene nodos XML clasificados por sus puntajes iniciales, y devuelve sus resultados en la cola de prioridad F, clasificados por puntajes ajustados. 1 Arriba(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recalcular y.score 5 S.add(y) 6 si y no es un nodo raíz entonces 7 Arriba (x, y.parent) 8 fin si 9 10 Abajo(x) ≡ 11 si no x.reported entonces 12 S.remove(x) 14 x.g ← x.f 15 recalcular x.score 16 si x.score > 0 entonces 17 F.add(x) 18 fin si 19 x.reported ← true 20 para cada y ∈ x.children hacer 21 Abajo (y) 22 fin hacer 23 fin si Figura 6: Rutinas de recorrido de árbol llamadas por el algoritmo de re-ranking. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 PrecisiónPromedioMedia (inex-2002) GananciaAcumuladaXML(XCG) alfa MAP (estricto) MAP (generalizado) MAP (sog) XCG (sog2) Figura 7: Impacto de α en XCG y MAP inex-2002 (temas CO de INEX 2004; conjunto de evaluación I). nodos ancestros (líneas 8-10) y descendientes (líneas 12-14) ajustando los puntajes de estos nodos. Las rutinas de recorrido de árboles, Arriba y Abajo, se muestran en la figura 6. El procedimiento Up elimina cada nodo ancestro de S, ajusta sus valores de frecuencia de término, recalcula su puntuación y lo vuelve a agregar a S. El ajuste de los valores de frecuencia de término (línea 3) agrega a y.g solo las ocurrencias de términos no reportadas previamente en x. El recalculo de la puntuación en la línea 4 utiliza las ecuaciones 1 y 2. La rutina Down realiza una operación similar en cada descendiente. Sin embargo, dado que el contenido de cada descendiente está completamente contenido en un elemento informado, su puntuación final puede ser calculada, y se elimina de S y se agrega a F. Para determinar la complejidad temporal del algoritmo, primero observe que un nodo puede ser un argumento de Down como máximo una vez. Posteriormente, la bandera reportada de su padre es verdadera. Durante cada llamada a Down, un nodo puede ser movido de S a F, lo que requiere un tiempo O(log n). Por lo tanto, el tiempo total para todas las llamadas a Down es O(n log n), y podemos ignorar temporalmente las líneas 8-10 de la figura 5 al considerar la complejidad temporal del bucle sobre las líneas 2-15. Durante cada iteración de este bucle, se elimina un nodo y cada uno de sus ancestros de una cola de prioridad y luego se vuelven a agregar a la cola de prioridad. Dado que un nodo puede tener como máximo h ancestros, donde h es la altura máxima de cualquier árbol en la colección, cada una de las m iteraciones requiere un tiempo de O(h log n). La combinación de estas observaciones produce una complejidad temporal general de O((n + mh) log n). En la práctica, volver a clasificar un conjunto de resultados de INEX requiere menos de 200 ms en una PC de escritorio de tres años de antigüedad. EVALUACIÓN Ninguna de las métricas descritas en la sección 3.3 se ajusta adecuadamente a la perspectiva de superposición defendida por este documento. Sin embargo, cuando se toman en conjunto, proporcionan información sobre el comportamiento del algoritmo de reordenamiento. Los paquetes de evaluación de INEX (inex_eval e inex_eval_ng) se utilizaron para calcular los valores de las métricas inex-2002 e inex-2003. Los valores de las métricas XCG fueron calculados utilizando el software proporcionado por sus inventores [11]. La Figura 7 representa juntas las tres variantes de la métrica MAP inex-2002 junto con la métrica XCG. Los valores para estas métricas 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Precisión Media Promedio (inex-2003) alfa estricto, superposición no considerada estricto, superposición considerada generalizado, superposición no considerada generalizado, superposición considerada Figura 8: Impacto de α en MAP inex-2003 (temas CO de INEX 2004; conjunto de evaluación I). se trazan para valores de α entre 0.0 y 1.0. Recordando que la métrica XCG está diseñada para penalizar la superposición, mientras que la métrica inex-2002 ignora la superposición, el conflicto entre las métricas es evidente. Los valores de MAP en un extremo (α = 0.0) y el valor de XCG en el otro extremo (α = 1.0) representan un rendimiento de recuperación comparable a los mejores sistemas en INEX 2004 [8,12]. La Figura 8 muestra los valores de la métrica MAP inex-2003 para dos cuantificaciones, con y sin consideración de la superposición. Una vez más, el conflicto es evidente, con la influencia de α considerablemente disminuida cuando se considera la superposición. 8. ALGORITMO EXTENDIDO Una limitación del algoritmo de reordenamiento es que se utiliza un único peso α para ajustar las puntuaciones tanto de los ancestros como de los descendientes de los elementos informados. Una extensión obvia es usar diferentes pesos en estos dos casos. Además, se utiliza el mismo peso independientemente de cuántas veces un elemento esté contenido en un elemento informado. Por ejemplo, un párrafo puede formar parte de una sección reportada y luego formar parte de un artículo reportado. Dado que el usuario puede haber visto este párrafo dos veces, su puntuación debería ser reducida aún más aumentando el valor del peso. Motivado por estas observaciones, el algoritmo de reordenamiento puede ser extendido con una serie de pesos 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0, donde βj es el peso aplicado a un nodo que ha sido descendiente de un nodo reportado j veces. Ten en cuenta que un límite superior en M es h, la altura máxima de cualquier árbol XML en la colección. Sin embargo, en la práctica es probable que M sea relativamente pequeño (quizás 3 o 4). La Figura 9 presenta reemplazos para las rutinas de Subir y Bajar de la Figura 6, incorporando esta serie de pesas. Se requiere un campo adicional en cada nodo, de la siguiente manera: x.j - conteo descendente El valor de x.j se establece inicialmente en cero en todos los nodos y se incrementa cada vez que se llama a Down con x como su argumento. Al calcular la puntuación del nodo, el valor de x.j selecciona 1 Up(x, y) ≡ 2 si no y.reported entonces 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recalcular y.score 6 S.add(y) 8 si y no es un nodo raíz entonces 9 Up (x, y.padre) 10 fin si 11 fin si 12 13 Down(x) ≡ 14 si x.j < M entonces 15 x.j ← x.j + 1 16 si no x.reported entonces 17 S.remove(x) 18 recalcular x.score 19 S.add(x) 20 fin si 21 para cada y ∈ x.hijos hacer 22 Down (y) 23 fin hacer 24 fin si Figura 9: Rutinas extendidas de recorrido de árbol. el peso a aplicar al nodo ajustando el valor de xt en la ecuación 1, de la siguiente manera: xt = βx.j · (ft − α · gt) (3) donde ft y gt son los componentes de x.f y x.g correspondientes al término t. Se requieren algunos cambios adicionales para extender Up y Down. La rutina Up devuelve inmediatamente (línea 2) si su argumento ya ha sido reportado, ya que las frecuencias de términos ya han sido ajustadas en sus ancestros. El procedimiento Down no informa su argumento, sino que vuelve a calcular su puntuación y la agrega de nuevo a S. Un nodo no puede ser un argumento de Down más de M +1 veces, lo que a su vez implica una complejidad temporal total de O((nM + mh) log n). Dado que M ≤ h y m ≤ n, la complejidad temporal también es O(nh log n). DISCUSIÓN CONCLUSIVA Al generar resultados de recuperación en una colección de XML, se debe tolerar cierta superposición en los resultados, lo cual puede ser beneficioso. Por ejemplo, cuando un elemento altamente exhaustivo y bastante específico (3,2) contiene un elemento mucho más pequeño (2,3), ambos deben ser informados al usuario, y los algoritmos de recuperación y las métricas de evaluación deben respetar esta relación. El algoritmo presentado en este documento controla la superposición ponderando los términos que aparecen en los elementos informados para reflejar su menor importancia. Otros enfoques también pueden ayudar a controlar la superposición. Por ejemplo, cuando se presentan los resultados de recuperación de XML a los usuarios, puede ser deseable agrupar elementos relacionados estructuralmente juntos, ilustrando visualmente las relaciones entre ellos. Si bien este estilo de interfaz de usuario puede ayudar a un usuario a lidiar con la superposición, la estrategia presentada en este documento sigue siendo aplicable, al determinar los mejores elementos para incluir en cada grupo. En Waterloo, seguimos desarrollando y probando nuestras ideas para INEX 2005. En particular, estamos investigando métodos para aprender los pesos α y βj. También estamos reevaluando nuestro enfoque en las estadísticas de documentos y examinando ajustes apropiados al parámetro k1 a medida que cambian los pesos de los términos [20]. 10. AGRADECIMIENTOS Gracias a Gabriella Kazai y Arjen de Vries por proporcionar una versión temprana de su software para calcular la métrica XCG, y gracias a Phil Tilker y Stefan B¨uttcher por su ayuda con la evaluación experimental. En parte, la financiación para este proyecto fue proporcionada por IBM Canadá a través del Instituto Nacional de Investigación de Software. 11. REFERENCIAS [1] N. Bruno, N. Koudas y D. Srivastava. Uniones de ramas holísticas: Coincidencia óptima de patrones XML. En Actas de la Conferencia Internacional ACM SIGMOD 2002 sobre la Gestión de Datos, páginas 310-321, Madison, Wisconsin, junio de 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y. Masa y A. Soffer. Buscando documentos XML a través de fragmentos XML. En Actas de la 26ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 151-158, Toronto, Canadá, 2003. [3] C. L. A. Clarke y P. L. Tilker. Experimentos MultiText para INEX 2004. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai y M. Lalmas. Tolerancia a la irrelevancia: Una evaluación orientada al esfuerzo del usuario de sistemas de recuperación sin unidad de recuperación predefinida. En las Actas de la Conferencia RIAO 2004, páginas 463-473, Aviñón, Francia, abril de 2004. [5] D. DeHaan, D. Toman, M. P. Consens y M. T. ¨Ozsu. Una traducción exhaustiva de XQuery a SQL utilizando codificación dinámica de intervalos. En Actas de la Conferencia Internacional ACM SIGMOD 2003 sobre la Gestión de Datos, San Diego, junio de 2003. [6] N. Fuhr y K. Großjohann. XIRQL: Un lenguaje de consulta para la recuperación de información en documentos XML. En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 172-180, Nueva Orleans, septiembre de 2001. [7] N. Fuhr, M. Lalmas y S. Malik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Segundo Taller (INEX 2003), Dagstuhl, Alemania, diciembre de 2003. [8] N. Fuhr, M. Lalmas, S. Malik y Zoltán Szlávik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Tercer Taller (INEX 2004), Dagstuhl, Alemania, diciembre de 2004. Publicado como Avances en la Recuperación de Información XML, Notas de Conferencia en Ciencias de la Computación, volumen 3493, Springer, 2005. [9] K. J¨avelin y J. Kek¨al¨ainen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, y B. Sigurbjörnsson. Normalización de longitud en la recuperación de XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 80-87, Sheffield, Reino Unido, julio de 2004. [11] G. Kazai, M. Lalmas y A. P. de Vries. El problema de superposición en la evaluación de la recuperación de XML orientada al contenido. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 72-79, Sheffield, Reino Unido, julio de 2004. [12] G. Kazai, M. Lalmas y A. P. de Vries. Pruebas de confiabilidad para las métricas XCG e inex-2002. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola y T. Aalto. TRIX 2004 - Luchando con la superposición. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [14] S. Liu, Q. Zou y W. W. Chu. Indexación y clasificación configurables para la recuperación de información en XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 88-95, Sheffield, Reino Unido, julio de 2004. [15] Y. Masa y M. Mandelbrot. Recuperando los componentes XML más relevantes. En las Actas del Taller INEX 2003, Dagstuhl, Alemania, diciembre de 2003. [16] Y. Masa y M. Mandelbrot. Clasificación de componentes y refinamiento automático de consultas para la recuperación de XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [17] P. Ogilvie y J. Callan. Modelos de lenguaje jerárquicos para la recuperación de componentes XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [18] J. Pehcevski, J. A. Thom y A. Vercoustre. Recuperación híbrida de XML revisitada. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [19] B. Piwowarski y M. Lalmas. Proporcionando evaluaciones de relevancia consistentes y exhaustivas para la evaluación de recuperación de XML. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 361-370, Washington, DC, noviembre de 2004. [20] S. Robertson, H. Zaragoza y M. Taylor. Extensión simple de BM25 a múltiples campos ponderados. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 42-50, Washington, DC, noviembre de 2004. [21] S. E. Robertson, S. Walker y M. Beaulieu. Okapi en TREC-7: Búsqueda automática, filtrado, VLC y pista interactiva. En Actas de la Séptima Conferencia de Recuperación de Texto, Gaithersburg, MD, noviembre de 1998. [22] A. Trotman y B. Sigurbjörnsson. NEXI, ahora y después. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski y P. Gallinari. Un álgebra para consultas estructuradas en redes bayesianas. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "re-ranking algorithm": {
            "translated_key": "algoritmo de re-clasificación",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Controlling Overlap in Content-Oriented XML Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of XML documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
                "This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents.",
                "The test collection developed by the INitiative for the Evaluation of XML Retrieval (INEX) forms the basis for the evaluation.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "INTRODUCTION The representation of documents in XML provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an XML information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in XML.",
                "Figure 1 provides an example of a journal article encoded in XML, illustrating many of the important characteristics of XML documents.",
                "Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words.",
                "Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate.",
                "Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs.",
                "Each of these characteristics affects the design of an XML IR system, and each leads to fundamental problems that must be solved in an successful system.",
                "Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper.",
                "The article of figure 1 may be viewed as an XML tree, as illustrated in figure 2.",
                "Formally, a collection of XML documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes.",
                "For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example XML tree. of x.",
                "Since an element may be represented by the node at its root, the output of an XML IR system may be viewed as a ranked list of the top-m nodes.",
                "The direct application of a standard relevance ranking technique to a set of XML elements can produce a result in which the top ranks are dominated by many structurally related elements.",
                "A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article.",
                "For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms.",
                "If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content.",
                "One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it.",
                "Unfortunately, this approach destroys some of the possible benefits of XML IR.",
                "For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts.",
                "In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements.",
                "Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6].",
                "This paper presents a method for controlling overlap.",
                "Starting with an initial element ranking, a <br>re-ranking algorithm</br> adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
                "For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced.",
                "The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20].",
                "Extending that approach, the <br>re-ranking algorithm</br> varies weights dynamically as elements are processed.",
                "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a baseline retrieval method is presented in section 4.",
                "This baseline method represents a reasonable adaptation of standard IR technology to XML.",
                "Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point.",
                "A <br>re-ranking algorithm</br> implementing this strategy is presented in section 6 and evaluated in section 7.",
                "Section 8 discusses an extended version of the algorithm. 2.",
                "BACKGROUND This section provides a general overview of XML information retrieval and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
                "Much research in the area of XML retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1].",
                "Here, we take a content oriented IR perceptive, focusing on XML documents that primarily contain natural language data and queries that are primarily expressed in natural language.",
                "We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need.",
                "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional information retrieval applications the standard unit of retrieval is taken to be the document.",
                "Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages.",
                "When applying standard relevance ranking techniques in the context of XML IR, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
                "In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole.",
                "If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article.",
                "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an XML IR system might potentially retrieve any element, many elements may not be appropriate as retrieval results.",
                "This is usually the case when elements contain very little text [10].",
                "For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself.",
                "Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user.",
                "An effective XML IR system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18].",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (INEX) has encouraged research into XML information retrieval technology [7,8].",
                "INEX is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
                "Over 50 groups participated in INEX 2004, and the conference has become as influential in the area of XML IR as TREC is in other IR areas.",
                "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by INEX.",
                "Overlap causes considerable problems with retrieval evaluation, and the INEX organizers and participants have wrestled with these problems since the beginning.",
                "While substantial progress has been made, these problem are still not completely solved.",
                "Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of INEX retrieval evaluation and discuss both current and proposed evaluation metrics.",
                "Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3.",
                "INEX 2004 Space limitations prevent the inclusion of more than a brief summary of INEX 2004 tasks and evaluation methodology.",
                "For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, INEX 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002.",
                "Each document is encoded in XML using a common DTD, with the document of figures 1 and 2 providing one example.",
                "At INEX 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics.",
                "The two tasks differed in the types of topics they used.",
                "For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection.",
                "For this task, the IR system is required to select the elements to be returned.",
                "For the other task, the contentand-structure or CAS task, the topics are written in an XML query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy.",
                "Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description.",
                "In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants.",
                "Each topic includes a short keyword query, which is executed over the collection by each participating group on their own XML IR system.",
                "Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since XML IR is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient.",
                "Instead, the INEX organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic.",
                "A four-point scale is used in both dimensions.",
                "Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant.",
                "Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at INEX 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values.",
                "One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others.",
                "This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant.",
                "Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity.",
                "Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity.",
                "This paper reports results of this metric using all three of these quantization functions.",
                "Since this metric was first introduced at INEX 2002, it is generally referred as the inex-2002 metric.",
                "The inex-2002 metric does not penalize overlap.",
                "In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank.",
                "To address this problem, Kazai et al. [11] propose an XML cumulated gain metric, which compares the cumulated gain [9] of a ranked list to an ideal gain vector.",
                "This ideal gain vector is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path.",
                "Thus, the XCG metric rewards retrieval runs that avoid overlap.",
                "While XCG was not used officially at INEX 2004, a version of it is likely to be used in the future.",
                "At INEX 2003, yet another metric was introduced to ameliorate the perceived limitations of the inex-2002 metric.",
                "This inex-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them.",
                "Two versions were created, one that considered only component size and another that considered both size and overlap.",
                "While the inex-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4.",
                "BASELINE RETRIEVAL METHOD This section provides an overview of baseline XML information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3].",
                "This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the XML information retrieval task.",
                "The MultiText system performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
                "To support retrieval from XML and other structured document types, the system provides generalized queries of the form: rank X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms.",
                "For our INEX 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections.",
                "Prior to INEX 2004, the INEX collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names.",
                "Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received.",
                "Automating this selection process is planned as future work.",
                "For INEX 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.",
                "For example, keyword field of topic 166 +tree edit distance + XML -image became the four-term query $tree $edit $distance $xml where the $ operator within a quoted string stems the term that follows it.",
                "Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞.",
                "Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(inex-2002) k1 strict generalized sog Figure 3: Impact of k1 on inex-2002 mean average precision with b = 0.75 (INEX 2003 CO topics).",
                "Prior to INEX 2004, the INEX 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.",
                "For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article.",
                "These statistics are used for ranking all element types.",
                "Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length.",
                "The use of article statistics for all element types might be questioned.",
                "This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.",
                "The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics.",
                "Nonetheless, we plan to examine this issue again in the future.",
                "In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose.",
                "Prior to INEX 2004, we trained the MultiText system using the INEX 2003 queries.",
                "As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system.",
                "The results were surprising.",
                "Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions.",
                "In our experience, optimal values for k1 are typically in the range 0.0 to 2.0.",
                "In this case, large values are required for good performance.",
                "Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization.",
                "Similar improvements are seen under the generalized and sog quantizations.",
                "In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).",
                "After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our INEX 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5.",
                "CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements.",
                "At a conceptual level, re-ranking proceeds as follows: 1.",
                "Report the highest ranking element. 2.",
                "Adjust the scores of the unreported elements. 3.",
                "Repeat steps 1 and 2 until m elements are reported.",
                "One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements.",
                "For example, assume a paragraph with score p is reported in step 1.",
                "In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score.",
                "In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion.",
                "That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages.",
                "A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two.",
                "Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness.",
                "Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body.",
                "In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body.",
                "Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported.",
                "The next section presents and analysis a simple <br>re-ranking algorithm</br> that follows this strategy.",
                "The algorithm is evaluated experimentally in section 7.",
                "One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears.",
                "In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6.",
                "<br>re-ranking algorithm</br> The <br>re-ranking algorithm</br> operates over XML trees, such as the one appearing in figure 2.",
                "Input to the algorithm is a list of n elements ranked according to their initial BM25 scores.",
                "During the initial ranking the XML tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |.",
                "Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores.",
                "An element is represented by the node x ∈ N at its root.",
                "Associated with this node are fields storing the length of element, term frequencies, and other information required by the <br>re-ranking algorithm</br>, as follows: x.f - term frequency vector x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses.",
                "The vector x.f contains term frequency information corresponding to each term in the query.",
                "The vector x.g is initially zero and is updated by the algorithm as elements are reported.",
                "The score field contains the current BM25 score for the element, which will change as the values in x.g change.",
                "The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g.",
                "Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the <br>re-ranking algorithm</br>, nodes are stored in priority queues, ordered by decreasing score.",
                "Each priority queue PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
                "The core of the <br>re-ranking algorithm</br> is presented in figure 5.",
                "The algorithm takes as input the priority queue S containing the initial ranking, and produces the top-m reranked nodes in the priority queue F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
                "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: <br>re-ranking algorithm</br> - As input, the algorithm takes a priority queue S, containing XML nodes ranked by their initial scores, and returns its results in priority queue F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
                "The tree traversal routines, Up and Down are given in figure 6.",
                "The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2.",
                "The Down routine performs a similar operation on each descendant.",
                "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the time complexity of the algorithm, first note that a node may be an argument to Down at most once.",
                "Thereafter, the reported flag of its parent is true.",
                "During each call to Down a node may be moved from S to F, requiring O(log n) time.",
                "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the time complexity of the loop over lines 2-15.",
                "During each iteration of this loop, a node and each of its ancestors are removed from a priority queue and then added back into a priority queue.",
                "Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time.",
                "Combining these observations produces an overall time complexity of O((n + mh) log n).",
                "In practice, re-ranking an INEX result set requires less than 200ms on a three-year-old desktop PC. 7.",
                "EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper.",
                "Nonetheless, when taken together they provide insight into the behaviour of the <br>re-ranking algorithm</br>.",
                "The INEX evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the inex-2002 and inex-2003 metrics.",
                "Values for the XCG metrics were computed using software supplied by its inventors [11].",
                "Figure 7 plots the three variants of inex-2002 MAP metric together with the XCG metric.",
                "Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on inex-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0.",
                "Recalling that the XCG metric is designed to penalize overlap, while the inex-2002 metric ignores overlap, the conflict between the metrics is obvious.",
                "The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at INEX 2004 [8,12].",
                "Figure 8 plots values of the inex-2003 MAP metric for two quantizations, with and without consideration of overlap.",
                "Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8.",
                "EXTENDED ALGORITHM One limitation of the <br>re-ranking algorithm</br> is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements.",
                "An obvious extension is to use different weights in these two cases.",
                "Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element.",
                "For example, a paragraph may form part of a reported section and then form part of a reported article.",
                "Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight.",
                "Motivated by these observations, the <br>re-ranking algorithm</br> may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times.",
                "Note that an upper bound on M is h, the maximum height of any XML tree in the collection.",
                "However, in practice M is likely to be relatively small (perhaps 3 or 4).",
                "Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights.",
                "One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument.",
                "When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down.",
                "The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors.",
                "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall time complexity of O((nM + mh) log n).",
                "Since M ≤ h and m ≤ n, the time complexity is also O(nh log n). 9.",
                "CONCLUDING DISCUSSION When generating retrieval results over an XML collection, some overlap in the results should be tolerated, and may be beneficial.",
                "For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship.",
                "The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance.",
                "Other approaches may also help to control overlap.",
                "For example, when XML retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them.",
                "While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster.",
                "At Waterloo, we continue to develop and test our ideas for INEX 2005.",
                "In particular, we are investigating methods for learning the α and βj weights.",
                "We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10.",
                "ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation.",
                "In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11.",
                "REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava.",
                "Holistic twig joins: Optimal XML pattern matching.",
                "In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
                "Mass, and A. Soffer.",
                "Searching XML documents via XML fragments.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker.",
                "MultiText experiments for INEX 2004.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas.",
                "Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit.",
                "In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu.",
                "A comprehensive XQuery to SQL translation using dynamic interval encoding.",
                "In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann.",
                "XIRQL: A query language for information retrieval in XML documents.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Second Workshop (INEX 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Third Workshop (INEX 2004), Dagstuhl, Germany, December 2004.",
                "Published as Advances in XML Information Retrieval, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson.",
                "Length normalization in XML retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "The overlap problem in content-oriented XML retrieval evaluation.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "Reliability tests for the XCG and inex-2002 metrics.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto.",
                "TRIX 2004 - Struggling with the overlap.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu.",
                "Configurable indexing and ranking for XML information retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 88-95, Sheffield, UK, July 2004. [15] Y.",
                "Mass and M. Mandelbrod.",
                "Retrieving the most relevant XML components.",
                "In INEX 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y.",
                "Mass and M. Mandelbrod.",
                "Component ranking and automatic query refinement for XML retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan.",
                "Hierarchical language models for XML component retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [18] J. Pehcevski, J.",
                "A. Thom, and A. Vercoustre.",
                "Hybrid XML retrieval re-visited.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas.",
                "Providing consistent and exhaustive relevance assessments for XML retrieval evaluation.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor.",
                "Simple BM25 extension to multiple weighted fields.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu.",
                "Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track.",
                "In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson.",
                "NEXI, now and next.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari.",
                "An algebra for structured queries in bayesian networks.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]."
            ],
            "original_annotated_samples": [
                "Starting with an initial element ranking, a <br>re-ranking algorithm</br> adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
                "Extending that approach, the <br>re-ranking algorithm</br> varies weights dynamically as elements are processed.",
                "A <br>re-ranking algorithm</br> implementing this strategy is presented in section 6 and evaluated in section 7.",
                "The next section presents and analysis a simple <br>re-ranking algorithm</br> that follows this strategy.",
                "<br>re-ranking algorithm</br> The <br>re-ranking algorithm</br> operates over XML trees, such as the one appearing in figure 2."
            ],
            "translated_annotated_samples": [
                "A partir de una clasificación inicial de elementos, un <br>algoritmo de re-clasificación</br> ajusta las puntuaciones de los elementos de menor clasificación que contienen, o están contenidos dentro de, elementos de mayor clasificación, reflejando el hecho de que esta información puede ser ahora redundante.",
                "Extendiendo ese enfoque, el <br>algoritmo de reordenamiento</br> varía los pesos dinámicamente a medida que se procesan los elementos.",
                "Un <br>algoritmo de reordenamiento</br> que implementa esta estrategia se presenta en la sección 6 y se evalúa en la sección 7.",
                "La siguiente sección presenta y analiza un <br>algoritmo de reordenamiento</br> simple que sigue esta estrategia.",
                "ALGORITMO DE REORDENAMIENTO El <br>algoritmo de reordenamiento</br> opera sobre árboles XML, como el que aparece en la figura 2."
            ],
            "translated_text": "Controlando la superposición en la recuperación XML orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca RESUMEN La aplicación directa de técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos XML a menudo produce un conjunto de resultados en el que los primeros puestos están dominados por un gran número de elementos tomados de un pequeño número de documentos altamente relevantes. Este documento presenta y evalúa un algoritmo que vuelve a clasificar este conjunto de resultados, con el objetivo de minimizar el contenido redundante mientras se preservan los beneficios de la recuperación de elementos, incluido el beneficio de identificar componentes centrados en el tema contenidos en documentos relevantes. La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la Recuperación XML (INEX) constituye la base para la evaluación. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Búsqueda y Recuperación de Información Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. La representación de documentos en XML brinda una oportunidad para que los sistemas de recuperación de información aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias. En respuesta a una consulta de usuario, un sistema de recuperación de información XML podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes. Esta facilidad es de particular beneficio cuando una colección contiene documentos muy largos, como manuales de productos o libros, donde el usuario debe ser dirigido a las partes más relevantes de estos documentos. La Figura 1 proporciona un ejemplo de un artículo de revista codificado en XML, ilustrando muchas de las características importantes de los documentos XML. Las etiquetas indican el inicio y el final de cada elemento, con elementos que varían ampliamente en tamaño, desde una palabra hasta miles de palabras. Algunos elementos, como párrafos y secciones, pueden presentarse razonablemente al usuario como resultados de búsqueda, pero otros no son apropiados. Los elementos se superponen entre sí: los artículos contienen secciones, las secciones contienen subsecciones y las subsecciones contienen párrafos. Cada una de estas características afecta el diseño de un sistema de IR XML, y cada una conlleva problemas fundamentales que deben resolverse en un sistema exitoso. La mayoría de estos problemas fundamentales pueden resolverse mediante la cuidadosa adaptación de técnicas estándar de IR, pero los problemas causados por la superposición son únicos en esta área [4,11] y constituyen el enfoque principal de este artículo. El artículo de la figura 1 puede ser visto como un árbol XML, como se ilustra en la figura 2. Formalmente, una colección de documentos XML puede ser representada como un bosque de árboles ordenados y enraizados, que consiste en un conjunto de nodos N y un conjunto de aristas dirigidas E que conectan estos nodos. Para cada nodo x ∈ N, la notación x.parent se refiere al nodo padre de x, si existe, y la notación x.children se refiere al conjunto de nodos hijos de x. Dado que un elemento puede estar representado por el nodo en su raíz, la salida de un sistema de IR XML puede ser vista como una lista clasificada de los m nodos principales. La aplicación directa de una técnica estándar de clasificación de relevancia a un conjunto de elementos XML puede producir un resultado en el que los primeros puestos están dominados por muchos elementos estructuralmente relacionados. Una sección con una puntuación alta probablemente contenga varios párrafos con una puntuación alta y esté contenida en un artículo con una puntuación alta. Por ejemplo, muchos de los elementos en la figura 2 recibirían una puntuación alta en los algoritmos de compresión de índices de texto de consulta de palabras clave. Si cada uno de estos elementos se presenta a un usuario como un resultado individual y separado, puede perder mucho tiempo revisando y rechazando contenido redundante. Una posible solución es informar solo el elemento de mayor puntuación a lo largo de un camino dado en el árbol, y eliminar de los rangos inferiores cualquier elemento que lo contenga o esté contenido en él. Desafortunadamente, este enfoque destruye algunos de los posibles beneficios de XML IR. Por ejemplo, un elemento externo puede contener una cantidad sustancial de información que no aparece en un elemento interno, pero el elemento interno puede estar fuertemente enfocado en el tema de la consulta y proporcionar un breve resumen de los conceptos clave. En tales casos, es razonable informar sobre elementos que contienen, o están contenidos en, elementos de rango superior. Incluso cuando un libro entero es relevante, un usuario aún puede desear que se destaquen los párrafos más importantes, para guiar su lectura y ahorrar tiempo [6]. Este documento presenta un método para controlar la superposición. A partir de una clasificación inicial de elementos, un <br>algoritmo de re-clasificación</br> ajusta las puntuaciones de los elementos de menor clasificación que contienen, o están contenidos dentro de, elementos de mayor clasificación, reflejando el hecho de que esta información puede ser ahora redundante. Por ejemplo, una vez que un elemento que representa una sección aparece en la clasificación, las puntuaciones de los párrafos que contiene y del artículo que lo contiene se reducen. La inspiración para esta estrategia proviene parcialmente del trabajo reciente sobre la recuperación de documentos estructurados, donde los términos que aparecen en diferentes campos, como el título y el cuerpo, reciben diferentes pesos [20]. Extendiendo ese enfoque, el <br>algoritmo de reordenamiento</br> varía los pesos dinámicamente a medida que se procesan los elementos. El resto del documento está organizado de la siguiente manera: Después de una discusión sobre el trabajo de antecedentes y la metodología de evaluación, se presenta un método de recuperación de referencia en la sección 4. Este método de referencia representa una adaptación razonable de la tecnología estándar de IR al XML. La sección 5 luego describe una estrategia para controlar la superposición, utilizando el método de línea base como punto de partida. Un <br>algoritmo de reordenamiento</br> que implementa esta estrategia se presenta en la sección 6 y se evalúa en la sección 7. La sección 8 discute una versión extendida del algoritmo. 2. ANTECEDENTES Esta sección proporciona una visión general de la recuperación de información XML y discute trabajos relacionados, con énfasis en los problemas fundamentales mencionados en la introducción. Mucha investigación en el área de recuperación de XML lo ve desde una perspectiva de base de datos tradicional, preocupándose por problemas como la implementación de lenguajes de consulta estructurados [5] y el procesamiento de joins [1]. Aquí adoptamos una perspectiva de IR orientada al contenido, centrándonos en documentos XML que contienen principalmente datos en lenguaje natural y consultas que están principalmente expresadas en lenguaje natural. Suponemos que estas consultas indican únicamente la naturaleza del contenido deseado, no su estructura, y que el papel del sistema de RI es determinar qué elementos satisfacen mejor la necesidad de información subyacente. Otra investigación en IR ha considerado consultas mixtas, en las que se especifican tanto requisitos de contenido como estructurales [2,6,14,17,23]. 2.1 Estadísticas de Términos y Documentos En las aplicaciones tradicionales de recuperación de información, la unidad estándar de recuperación se considera que es el documento. Dependiendo de la aplicación, este término podría interpretarse para abarcar muchos objetos diferentes, incluyendo páginas web, artículos de periódico y mensajes de correo electrónico. Al aplicar técnicas estándar de clasificación de relevancia en el contexto de la RI XML, un enfoque natural es tratar cada elemento como un documento separado, con estadísticas de términos disponibles para cada uno [16]. Además, la mayoría de las técnicas de clasificación requieren estadísticas globales (por ejemplo, frecuencia inversa de documentos) calculadas sobre la colección en su totalidad. Si consideramos que esta colección incluye todos los elementos que podrían ser devueltos por el sistema, una ocurrencia específica de un término puede aparecer en varios documentos diferentes, quizás en elementos que representan un párrafo, una subsección, una sección y un artículo. No es apropiado calcular la frecuencia inversa de documentos bajo la suposición de que el término está contenido en todos estos elementos, ya que el número de elementos que contienen un término depende completamente del arreglo estructural de los documentos [13,23]. 2.2 Elementos Recuperables Si bien un sistema de recuperación de información XML podría potencialmente recuperar cualquier elemento, muchos elementos pueden no ser apropiados como resultados de recuperación. Esto suele ser el caso cuando los elementos contienen muy poco texto [10]. Por ejemplo, un título de sección que contenga solo los términos de búsqueda puede recibir una puntuación alta de un algoritmo de clasificación, pero por sí solo tendría un valor limitado para un usuario, quien podría preferir la sección real en sí misma. Otros elementos pueden reflejar la estructura física de los documentos, en lugar de la estructura lógica, lo cual puede tener poco o ningún significado para un usuario. Un sistema de recuperación de información XML efectivo debe devolver solo aquellos elementos que tengan suficiente contenido para ser utilizables y puedan funcionar como objetos independientes [15,18]. Componentes estándar de documentos como párrafos, secciones, subsecciones y resúmenes generalmente cumplen con estos requisitos; los títulos, frases en cursiva y campos de metadatos individuales a menudo no lo hacen. 2.3 Metodología de Evaluación En los últimos tres años, la Iniciativa para la Evaluación de la Recuperación de Información XML (INEX) ha fomentado la investigación en tecnología de recuperación de información XML [7,8]. INEX es una serie de conferencias experimentales, similar a TREC, en la que grupos de diferentes instituciones completan una o más tareas experimentales utilizando sus propias herramientas y sistemas, y comparan sus resultados en la propia conferencia. Más de 50 grupos participaron en INEX 2004, y la conferencia se ha convertido en tan influyente en el área de la RI XML como lo es TREC en otras áreas de la RI. La investigación descrita en este artículo, al igual que gran parte del trabajo relacionado que cita, depende de las colecciones de pruebas desarrolladas por INEX. La superposición causa problemas considerables en la evaluación de la recuperación, y los organizadores y participantes de INEX han luchado con estos problemas desde el principio. Aunque se ha logrado un progreso sustancial, estos problemas aún no están completamente resueltos. Kazai et al. [11] proporcionan una exposición detallada del problema de superposición en el contexto de la evaluación de recuperación de INEX y discuten tanto las métricas de evaluación actuales como las propuestas. Muchas de estas métricas se aplican para evaluar los experimentos reportados en este artículo, y se describen brevemente en la siguiente sección. 3. Las limitaciones de espacio impiden incluir más que un breve resumen de las tareas y metodología de evaluación de INEX 2004. Para obtener información detallada, se deben consultar las actas de la conferencia en sí [8]. 3.1 Tareas Para las principales tareas experimentales, a los participantes de INEX 2004 se les proporcionó una colección de 12,107 artículos tomados de las revistas y publicaciones de la IEEE Computer Societies entre 1995 y 2002. Cada documento está codificado en XML utilizando una DTD común, siendo el documento de las figuras 1 y 2 un ejemplo. En INEX 2004, las dos principales tareas experimentales fueron ambas tareas de recuperación ad hoc, investigando el rendimiento de sistemas que buscan en una colección estática utilizando temas previamente no vistos. Las dos tareas diferían en los tipos de temas que utilizaban. Para una tarea, la tarea de solo contenido o CO, los temas consisten en declaraciones cortas en lenguaje natural sin hacer referencia directa a la estructura de los documentos en la colección. Para esta tarea, se requiere que el sistema de IR seleccione los elementos a devolver. Para la otra tarea, la tarea de contenido y estructura o CAS, los temas están escritos en un lenguaje de consulta XML [22] y contienen referencias explícitas a la estructura del documento, que el sistema de IR debe intentar satisfacer. Dado que el trabajo descrito en este documento se enfoca en la tarea de solo contenido, donde el sistema de IR no recibe orientación sobre los elementos a devolver, la tarea de CAS se ignora en el resto de nuestra descripción. En 2004, los organizadores de la conferencia seleccionaron 40 nuevos temas de CO de las contribuciones proporcionadas por los participantes de la conferencia. Cada tema incluye una breve consulta de palabras clave, la cual es ejecutada sobre la colección por cada grupo participante en su propio sistema de IR XML. Cada grupo podría presentar hasta tres ejecuciones experimentales que consistieran en los primeros m = 1500 elementos para cada tema. 3.2 Evaluación de Relevancia Dado que la RI XML se preocupa por localizar aquellos elementos que proporcionan una cobertura completa de un tema mientras contienen la menor cantidad de información irrelevante posible, los juicios simples de relevante vs. no relevante no son suficientes. En cambio, los organizadores de INEX adoptaron dos dimensiones para la evaluación de relevancia: la dimensión de exhaustividad refleja el grado en que un elemento abarca el tema, y la dimensión de especificidad refleja el grado en que un elemento se enfoca en el tema. Se utiliza una escala de cuatro puntos en ambas dimensiones. Por lo tanto, un elemento (3,3) es altamente exhaustivo y altamente específico, un elemento (1,3) es marginalmente exhaustivo y altamente específico, y un elemento (0,0) no es relevante. Información adicional sobre la metodología de evaluación se puede encontrar en Piwowarski y Lalmas [19], quienes proporcionan una justificación detallada. 3.3 Métricas de Evaluación La métrica de evaluación principal utilizada en INEX 2004 es una versión de la precisión promedio media (MAP), ajustada por diversas funciones de cuantificación para dar diferentes pesos a diferentes elementos, dependiendo de sus valores de exhaustividad y especificidad. Una variante, la función de cuantización estricta asigna un peso de 1 a los elementos (3,3) y un peso de 0 a todos los demás. Esta variante es esencialmente el valor MAP familiar, con elementos (3,3) tratados como relevantes y todos los demás elementos tratados como no relevantes. Otras funciones de cuantización están diseñadas para otorgar crédito parcial a elementos que son aproximaciones cercanas, debido a la falta de exhaustividad y/o especificidad. Tanto la función de cuantificación generalizada como la función de generalización orientada a la especificidad (sog) acreditan elementos según su grado de relevancia [11], siendo que la segunda función pone mayor énfasis en la especificidad. Este documento informa los resultados de esta métrica utilizando las tres funciones de cuantización. Desde que esta métrica fue introducida por primera vez en INEX 2002, generalmente se le conoce como la métrica inex-2002. La métrica inex-2002 no penaliza la superposición. En particular, tanto las funciones de cuantificación generalizadas como las de sog otorgan crédito parcial a un casi acierto incluso cuando se informa un elemento (3,3) que se superpone a él en un rango más alto. Para abordar este problema, Kazai et al. [11] proponen una métrica de ganancia acumulada XML, que compara la ganancia acumulada [9] de una lista clasificada con un vector de ganancia ideal. Este vector de ganancia ideal se construye a partir de las valoraciones de relevancia al eliminar la superposición y retener solo el mejor elemento a lo largo de un camino dado. Por lo tanto, la métrica XCG recompensa las ejecuciones de recuperación que evitan la superposición. Aunque XCG no se utilizó oficialmente en INEX 2004, es probable que se utilice una versión de él en el futuro. En INEX 2003, se introdujo otra métrica para mejorar las limitaciones percibidas de la métrica inex-2002. Este métrico inex-2003 extiende las definiciones de precisión y exhaustividad para considerar tanto el tamaño de los componentes informados como la superposición entre ellos. Se crearon dos versiones, una que consideraba solo el tamaño de los componentes y otra que consideraba tanto el tamaño como la superposición. Si bien la métrica inex-2003 presenta anomalías no deseadas [11] y no se utilizó en 2004, se informan valores en la sección de evaluación para proporcionar un instrumento adicional para investigar la superposición. 4. MÉTODO DE RECUPERACIÓN DE BASELINE Esta sección proporciona una descripción general del método de recuperación de información XML de base actualmente utilizado en el sistema MultiText IR, desarrollado por el Grupo de Recuperación de Información de la Universidad de Waterloo [3]. Este método de recuperación resulta de la adaptación y ajuste de la medida Okapi BM25 [21] a la tarea de recuperación de información en XML. El sistema MultiText tuvo un desempeño respetable en INEX 2004, ubicándose entre los diez primeros en todas las funciones de cuantización, y ocupando el primer lugar cuando la función de cuantización enfatizaba la exhaustividad. Para admitir la recuperación de XML y otros tipos de documentos estructurados, el sistema proporciona consultas generalizadas de la forma: clasificar X por Y donde X es una subconsulta que especifica un conjunto de elementos de documentos a clasificar y Y es un vector de subconsultas que especifican términos de recuperación individuales. Para nuestras ejecuciones de INEX 2004, la subconsulta X especificó una lista de elementos recuperables como aquellos con nombres de etiquetas de la siguiente manera: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt. Esta lista incluye entradas bibliográficas (bb) y leyendas de figuras (fig) así como párrafos, secciones y subsecciones. Antes de INEX 2004, la colección de INEX y las evaluaciones de relevancia de INEX 2003 fueron analizadas manualmente para seleccionar estos nombres de etiquetas. Los nombres de las etiquetas fueron seleccionados en base a su frecuencia en la colección, el tamaño promedio de sus elementos asociados y el número relativo de juicios de relevancia positiva que recibieron. Automatizar este proceso de selección está planeado como trabajo futuro. Para INEX 2004, el vector término Y se derivó del tema dividiendo frases en palabras individuales, eliminando palabras vacías y términos negativos (aquellos que comienzan con -), y aplicando un stemmer. Por ejemplo, el campo de palabra clave del tema 166 +distancia de edición de árbol + XML -imagen se convirtió en la consulta de cuatro términos $árbol $edición $distancia $xml donde el operador $ dentro de una cadena entre comillas deriva el término que le sigue. Nuestra implementación de Okapi BM25 se deriva de la fórmula de Robertson et al. [21] al establecer los parámetros k2 = 0 y k3 = ∞. Dado un conjunto de términos Q, a un elemento x se le asigna la puntuación t∈Q w(1) qt (k1 + 1)xt K + xt (1) donde w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = número de documentos en el corpus Dt = número de documentos que contienen t qt = frecuencia con la que t ocurre en el tema xt = frecuencia con la que t ocurre en x K = k1((1 − b) + b · lx/lavg) lx = longitud de x lavg = longitud promedio del documento 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 PrecisiónPromedio(inex-2002) k1 estricto generalizado sog Figura 3: Impacto de k1 en la precisión promedio de inex-2002 con b = 0.75 (temas CO de INEX 2003). Antes de INEX 2004, los temas y juicios de INEX 2003 se utilizaron para ajustar los parámetros b y k1, y el impacto de este ajuste se discute más adelante en esta sección. Para los propósitos de calcular estadísticas a nivel de documento (D, Dt y lavg), un documento se define como un artículo. Estas estadísticas se utilizan para clasificar todos los tipos de elementos. Siguiendo la sugerencia de Kamps et al. [10], los resultados de recuperación se filtran para eliminar elementos muy cortos, aquellos con menos de 25 palabras de longitud. El uso de estadísticas de artículos para todos los tipos de elementos podría ser cuestionado. Este enfoque puede justificarse al considerar la colección como un conjunto de artículos que se pueden buscar utilizando técnicas estándar orientadas a documentos, donde solo se devuelven artículos. El puntaje calculado para un elemento es esencialmente el puntaje que recibiría si se agregara a la colección como un nuevo documento, ignorando los ajustes menores necesarios para las estadísticas a nivel de documento. Sin embargo, planeamos examinar este tema nuevamente en el futuro. En nuestra experiencia, el rendimiento de BM25 suele beneficiarse al ajustar los parámetros b y k1 a la colección, siempre que haya consultas de entrenamiento disponibles con este propósito. Antes de INEX 2004, entrenamos el sistema MultiText utilizando las consultas de INEX 2003. Como punto de partida, utilizamos los valores b = 0.75 y k1 = 1.2, que funcionan bien en colecciones TREC adhoc y se utilizan como valores predeterminados en nuestro sistema. Los resultados fueron sorprendentes. La Figura 3 muestra el resultado de variar k1 con b = 0.75 en los valores de MAP bajo tres funciones de cuantización. En nuestra experiencia, los valores óptimos para k1 suelen estar en el rango de 0.0 a 2.0. En este caso, se requieren valores grandes para un buen rendimiento. Entre k1 = 1.0 y k1 = 6.0, el MAP aumenta en más del 15% bajo la cuantización estricta. Se observan mejoras similares bajo las cuantizaciones generalizada y SOG. Por el contrario, nuestro valor predeterminado de b = 0.75 funciona bien bajo todas las funciones de cuantificación (figura 4). Después de ajustar una amplia gama de valores bajo varias funciones de cuantización, seleccionamos los valores de k = 10.0 y b = 0.80 para nuestros experimentos de INEX 2004, y estos valores se utilizan para los experimentos reportados en la sección 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 PrecisiónPromedioMedia (inex-2002) b estricto generalizado sog Figura 4: Impacto de b en la precisión promedio media de inex-2002 con k1 = 10 (temas CO de INEX 2003). 5. CONTROL DE SUPERPOSICIÓN Comenzando con una clasificación de elementos generada por el método de referencia descrito en la sección anterior, los elementos se vuelven a clasificar para controlar la superposición ajustando de forma iterativa las puntuaciones de aquellos elementos que contienen o están contenidos en elementos de clasificación más alta. A nivel conceptual, la reorganización procede de la siguiente manera: 1. Informe el elemento de rango más alto. Ajustar las puntuaciones de los elementos no reportados. 3. Repetir los pasos 1 y 2 hasta que se informen m elementos. Un enfoque para ajustar las puntuaciones de los elementos no informados en el paso 2 podría basarse en las puntuaciones Okapi BM25 de los elementos involucrados. Por ejemplo, supongamos que se informa un párrafo con una puntuación p en el paso 1. En el paso 2, la sección que contiene el párrafo podría tener su puntuación s reducida en una cantidad α · p para reflejar la contribución reducida que el párrafo debería hacer a la puntuación de las secciones. En un contexto relacionado, Robertson et al. [20] argumentan en contra de la combinación lineal de las puntuaciones de Okapi de esta manera. Ese trabajo considera el problema de asignar diferentes pesos a diferentes campos de documentos, como el título y el cuerpo asociados con páginas web. Un enfoque común para este problema puntúa el título y el cuerpo por separado y genera una puntuación final como una combinación lineal de ambos. Robertson et al. discuten las deficiencias teóricas en este enfoque y demuestran experimentalmente que puede perjudicar realmente la efectividad de la recuperación. En cambio, aplican los pesos a nivel de frecuencia de términos, donde la aparición de un término de consulta t en el título contribuye más al puntaje que una aparición en el cuerpo. En la ecuación 1, xt se convierte en α0 · yt + α1 · zt, donde yt es el número de veces que t aparece en el título y zt es el número de veces que t aparece en el cuerpo. Al traducir este enfoque a nuestro contexto, la contribución de los términos que aparecen en los elementos se reduce dinámicamente a medida que se informan. La siguiente sección presenta y analiza un <br>algoritmo de reordenamiento</br> simple que sigue esta estrategia. El algoritmo se evalúa experimentalmente en la sección 7. Una limitación del algoritmo es que la contribución de los términos que aparecen en los elementos informados se reduce por el mismo factor independientemente del número de elementos informados en los que aparezca. En la sección 8, el algoritmo se extiende para aplicar pesos crecientes, disminuyendo la puntuación, cuando un término aparece en más de un elemento informado. 6. ALGORITMO DE REORDENAMIENTO El <br>algoritmo de reordenamiento</br> opera sobre árboles XML, como el que aparece en la figura 2. ",
            "candidates": [],
            "error": [
                [
                    "algoritmo de re-clasificación",
                    "algoritmo de reordenamiento",
                    "algoritmo de reordenamiento",
                    "algoritmo de reordenamiento",
                    "algoritmo de reordenamiento"
                ]
            ]
        },
        "term frequency vector": {
            "translated_key": "vector de frecuencia de términos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Controlling Overlap in Content-Oriented XML Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of XML documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
                "This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents.",
                "The test collection developed by the INitiative for the Evaluation of XML Retrieval (INEX) forms the basis for the evaluation.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "INTRODUCTION The representation of documents in XML provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an XML information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in XML.",
                "Figure 1 provides an example of a journal article encoded in XML, illustrating many of the important characteristics of XML documents.",
                "Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words.",
                "Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate.",
                "Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs.",
                "Each of these characteristics affects the design of an XML IR system, and each leads to fundamental problems that must be solved in an successful system.",
                "Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper.",
                "The article of figure 1 may be viewed as an XML tree, as illustrated in figure 2.",
                "Formally, a collection of XML documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes.",
                "For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example XML tree. of x.",
                "Since an element may be represented by the node at its root, the output of an XML IR system may be viewed as a ranked list of the top-m nodes.",
                "The direct application of a standard relevance ranking technique to a set of XML elements can produce a result in which the top ranks are dominated by many structurally related elements.",
                "A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article.",
                "For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms.",
                "If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content.",
                "One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it.",
                "Unfortunately, this approach destroys some of the possible benefits of XML IR.",
                "For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts.",
                "In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements.",
                "Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6].",
                "This paper presents a method for controlling overlap.",
                "Starting with an initial element ranking, a re-ranking algorithm adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
                "For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced.",
                "The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20].",
                "Extending that approach, the re-ranking algorithm varies weights dynamically as elements are processed.",
                "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a baseline retrieval method is presented in section 4.",
                "This baseline method represents a reasonable adaptation of standard IR technology to XML.",
                "Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point.",
                "A re-ranking algorithm implementing this strategy is presented in section 6 and evaluated in section 7.",
                "Section 8 discusses an extended version of the algorithm. 2.",
                "BACKGROUND This section provides a general overview of XML information retrieval and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
                "Much research in the area of XML retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1].",
                "Here, we take a content oriented IR perceptive, focusing on XML documents that primarily contain natural language data and queries that are primarily expressed in natural language.",
                "We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need.",
                "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional information retrieval applications the standard unit of retrieval is taken to be the document.",
                "Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages.",
                "When applying standard relevance ranking techniques in the context of XML IR, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
                "In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole.",
                "If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article.",
                "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an XML IR system might potentially retrieve any element, many elements may not be appropriate as retrieval results.",
                "This is usually the case when elements contain very little text [10].",
                "For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself.",
                "Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user.",
                "An effective XML IR system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18].",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (INEX) has encouraged research into XML information retrieval technology [7,8].",
                "INEX is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
                "Over 50 groups participated in INEX 2004, and the conference has become as influential in the area of XML IR as TREC is in other IR areas.",
                "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by INEX.",
                "Overlap causes considerable problems with retrieval evaluation, and the INEX organizers and participants have wrestled with these problems since the beginning.",
                "While substantial progress has been made, these problem are still not completely solved.",
                "Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of INEX retrieval evaluation and discuss both current and proposed evaluation metrics.",
                "Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3.",
                "INEX 2004 Space limitations prevent the inclusion of more than a brief summary of INEX 2004 tasks and evaluation methodology.",
                "For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, INEX 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002.",
                "Each document is encoded in XML using a common DTD, with the document of figures 1 and 2 providing one example.",
                "At INEX 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics.",
                "The two tasks differed in the types of topics they used.",
                "For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection.",
                "For this task, the IR system is required to select the elements to be returned.",
                "For the other task, the contentand-structure or CAS task, the topics are written in an XML query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy.",
                "Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description.",
                "In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants.",
                "Each topic includes a short keyword query, which is executed over the collection by each participating group on their own XML IR system.",
                "Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since XML IR is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient.",
                "Instead, the INEX organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic.",
                "A four-point scale is used in both dimensions.",
                "Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant.",
                "Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at INEX 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values.",
                "One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others.",
                "This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant.",
                "Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity.",
                "Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity.",
                "This paper reports results of this metric using all three of these quantization functions.",
                "Since this metric was first introduced at INEX 2002, it is generally referred as the inex-2002 metric.",
                "The inex-2002 metric does not penalize overlap.",
                "In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank.",
                "To address this problem, Kazai et al. [11] propose an XML cumulated gain metric, which compares the cumulated gain [9] of a ranked list to an ideal gain vector.",
                "This ideal gain vector is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path.",
                "Thus, the XCG metric rewards retrieval runs that avoid overlap.",
                "While XCG was not used officially at INEX 2004, a version of it is likely to be used in the future.",
                "At INEX 2003, yet another metric was introduced to ameliorate the perceived limitations of the inex-2002 metric.",
                "This inex-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them.",
                "Two versions were created, one that considered only component size and another that considered both size and overlap.",
                "While the inex-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4.",
                "BASELINE RETRIEVAL METHOD This section provides an overview of baseline XML information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3].",
                "This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the XML information retrieval task.",
                "The MultiText system performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
                "To support retrieval from XML and other structured document types, the system provides generalized queries of the form: rank X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms.",
                "For our INEX 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections.",
                "Prior to INEX 2004, the INEX collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names.",
                "Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received.",
                "Automating this selection process is planned as future work.",
                "For INEX 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.",
                "For example, keyword field of topic 166 +tree edit distance + XML -image became the four-term query $tree $edit $distance $xml where the $ operator within a quoted string stems the term that follows it.",
                "Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞.",
                "Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(inex-2002) k1 strict generalized sog Figure 3: Impact of k1 on inex-2002 mean average precision with b = 0.75 (INEX 2003 CO topics).",
                "Prior to INEX 2004, the INEX 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.",
                "For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article.",
                "These statistics are used for ranking all element types.",
                "Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length.",
                "The use of article statistics for all element types might be questioned.",
                "This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.",
                "The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics.",
                "Nonetheless, we plan to examine this issue again in the future.",
                "In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose.",
                "Prior to INEX 2004, we trained the MultiText system using the INEX 2003 queries.",
                "As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system.",
                "The results were surprising.",
                "Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions.",
                "In our experience, optimal values for k1 are typically in the range 0.0 to 2.0.",
                "In this case, large values are required for good performance.",
                "Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization.",
                "Similar improvements are seen under the generalized and sog quantizations.",
                "In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).",
                "After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our INEX 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5.",
                "CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements.",
                "At a conceptual level, re-ranking proceeds as follows: 1.",
                "Report the highest ranking element. 2.",
                "Adjust the scores of the unreported elements. 3.",
                "Repeat steps 1 and 2 until m elements are reported.",
                "One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements.",
                "For example, assume a paragraph with score p is reported in step 1.",
                "In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score.",
                "In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion.",
                "That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages.",
                "A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two.",
                "Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness.",
                "Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body.",
                "In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body.",
                "Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported.",
                "The next section presents and analysis a simple re-ranking algorithm that follows this strategy.",
                "The algorithm is evaluated experimentally in section 7.",
                "One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears.",
                "In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6.",
                "RE-RANKING ALGORITHM The re-ranking algorithm operates over XML trees, such as the one appearing in figure 2.",
                "Input to the algorithm is a list of n elements ranked according to their initial BM25 scores.",
                "During the initial ranking the XML tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |.",
                "Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores.",
                "An element is represented by the node x ∈ N at its root.",
                "Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - <br>term frequency vector</br> x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses.",
                "The vector x.f contains term frequency information corresponding to each term in the query.",
                "The vector x.g is initially zero and is updated by the algorithm as elements are reported.",
                "The score field contains the current BM25 score for the element, which will change as the values in x.g change.",
                "The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g.",
                "Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the re-ranking algorithm, nodes are stored in priority queues, ordered by decreasing score.",
                "Each priority queue PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
                "The core of the re-ranking algorithm is presented in figure 5.",
                "The algorithm takes as input the priority queue S containing the initial ranking, and produces the top-m reranked nodes in the priority queue F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
                "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a priority queue S, containing XML nodes ranked by their initial scores, and returns its results in priority queue F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
                "The tree traversal routines, Up and Down are given in figure 6.",
                "The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2.",
                "The Down routine performs a similar operation on each descendant.",
                "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the time complexity of the algorithm, first note that a node may be an argument to Down at most once.",
                "Thereafter, the reported flag of its parent is true.",
                "During each call to Down a node may be moved from S to F, requiring O(log n) time.",
                "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the time complexity of the loop over lines 2-15.",
                "During each iteration of this loop, a node and each of its ancestors are removed from a priority queue and then added back into a priority queue.",
                "Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time.",
                "Combining these observations produces an overall time complexity of O((n + mh) log n).",
                "In practice, re-ranking an INEX result set requires less than 200ms on a three-year-old desktop PC. 7.",
                "EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper.",
                "Nonetheless, when taken together they provide insight into the behaviour of the re-ranking algorithm.",
                "The INEX evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the inex-2002 and inex-2003 metrics.",
                "Values for the XCG metrics were computed using software supplied by its inventors [11].",
                "Figure 7 plots the three variants of inex-2002 MAP metric together with the XCG metric.",
                "Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on inex-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0.",
                "Recalling that the XCG metric is designed to penalize overlap, while the inex-2002 metric ignores overlap, the conflict between the metrics is obvious.",
                "The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at INEX 2004 [8,12].",
                "Figure 8 plots values of the inex-2003 MAP metric for two quantizations, with and without consideration of overlap.",
                "Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8.",
                "EXTENDED ALGORITHM One limitation of the re-ranking algorithm is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements.",
                "An obvious extension is to use different weights in these two cases.",
                "Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element.",
                "For example, a paragraph may form part of a reported section and then form part of a reported article.",
                "Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight.",
                "Motivated by these observations, the re-ranking algorithm may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times.",
                "Note that an upper bound on M is h, the maximum height of any XML tree in the collection.",
                "However, in practice M is likely to be relatively small (perhaps 3 or 4).",
                "Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights.",
                "One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument.",
                "When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down.",
                "The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors.",
                "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall time complexity of O((nM + mh) log n).",
                "Since M ≤ h and m ≤ n, the time complexity is also O(nh log n). 9.",
                "CONCLUDING DISCUSSION When generating retrieval results over an XML collection, some overlap in the results should be tolerated, and may be beneficial.",
                "For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship.",
                "The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance.",
                "Other approaches may also help to control overlap.",
                "For example, when XML retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them.",
                "While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster.",
                "At Waterloo, we continue to develop and test our ideas for INEX 2005.",
                "In particular, we are investigating methods for learning the α and βj weights.",
                "We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10.",
                "ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation.",
                "In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11.",
                "REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava.",
                "Holistic twig joins: Optimal XML pattern matching.",
                "In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
                "Mass, and A. Soffer.",
                "Searching XML documents via XML fragments.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker.",
                "MultiText experiments for INEX 2004.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas.",
                "Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit.",
                "In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu.",
                "A comprehensive XQuery to SQL translation using dynamic interval encoding.",
                "In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann.",
                "XIRQL: A query language for information retrieval in XML documents.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Second Workshop (INEX 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Third Workshop (INEX 2004), Dagstuhl, Germany, December 2004.",
                "Published as Advances in XML Information Retrieval, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson.",
                "Length normalization in XML retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "The overlap problem in content-oriented XML retrieval evaluation.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "Reliability tests for the XCG and inex-2002 metrics.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto.",
                "TRIX 2004 - Struggling with the overlap.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu.",
                "Configurable indexing and ranking for XML information retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 88-95, Sheffield, UK, July 2004. [15] Y.",
                "Mass and M. Mandelbrod.",
                "Retrieving the most relevant XML components.",
                "In INEX 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y.",
                "Mass and M. Mandelbrod.",
                "Component ranking and automatic query refinement for XML retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan.",
                "Hierarchical language models for XML component retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [18] J. Pehcevski, J.",
                "A. Thom, and A. Vercoustre.",
                "Hybrid XML retrieval re-visited.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas.",
                "Providing consistent and exhaustive relevance assessments for XML retrieval evaluation.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor.",
                "Simple BM25 extension to multiple weighted fields.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu.",
                "Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track.",
                "In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson.",
                "NEXI, now and next.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari.",
                "An algebra for structured queries in bayesian networks.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]."
            ],
            "original_annotated_samples": [
                "Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - <br>term frequency vector</br> x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses."
            ],
            "translated_annotated_samples": [
                "Asociados con este nodo se encuentran campos que almacenan la longitud del elemento, las frecuencias de términos y otra información requerida por el algoritmo de re-ranking, de la siguiente manera: x.f - <br>vector de frecuencia de términos</br> x.g - ajustes de frecuencia de términos x.l - longitud del elemento x.score - puntaje actual de Okapi BM25 x.reported - bandera booleana, inicialmente falsa x.children - conjunto de nodos hijos x.parent - nodo padre, si existe Estos campos se llenan durante el proceso de clasificación inicial y se actualizan a medida que avanza el algoritmo."
            ],
            "translated_text": "Controlando la superposición en la recuperación XML orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca RESUMEN La aplicación directa de técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos XML a menudo produce un conjunto de resultados en el que los primeros puestos están dominados por un gran número de elementos tomados de un pequeño número de documentos altamente relevantes. Este documento presenta y evalúa un algoritmo que vuelve a clasificar este conjunto de resultados, con el objetivo de minimizar el contenido redundante mientras se preservan los beneficios de la recuperación de elementos, incluido el beneficio de identificar componentes centrados en el tema contenidos en documentos relevantes. La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la Recuperación XML (INEX) constituye la base para la evaluación. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Búsqueda y Recuperación de Información Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. La representación de documentos en XML brinda una oportunidad para que los sistemas de recuperación de información aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias. En respuesta a una consulta de usuario, un sistema de recuperación de información XML podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes. Esta facilidad es de particular beneficio cuando una colección contiene documentos muy largos, como manuales de productos o libros, donde el usuario debe ser dirigido a las partes más relevantes de estos documentos. La Figura 1 proporciona un ejemplo de un artículo de revista codificado en XML, ilustrando muchas de las características importantes de los documentos XML. Las etiquetas indican el inicio y el final de cada elemento, con elementos que varían ampliamente en tamaño, desde una palabra hasta miles de palabras. Algunos elementos, como párrafos y secciones, pueden presentarse razonablemente al usuario como resultados de búsqueda, pero otros no son apropiados. Los elementos se superponen entre sí: los artículos contienen secciones, las secciones contienen subsecciones y las subsecciones contienen párrafos. Cada una de estas características afecta el diseño de un sistema de IR XML, y cada una conlleva problemas fundamentales que deben resolverse en un sistema exitoso. La mayoría de estos problemas fundamentales pueden resolverse mediante la cuidadosa adaptación de técnicas estándar de IR, pero los problemas causados por la superposición son únicos en esta área [4,11] y constituyen el enfoque principal de este artículo. El artículo de la figura 1 puede ser visto como un árbol XML, como se ilustra en la figura 2. Formalmente, una colección de documentos XML puede ser representada como un bosque de árboles ordenados y enraizados, que consiste en un conjunto de nodos N y un conjunto de aristas dirigidas E que conectan estos nodos. Para cada nodo x ∈ N, la notación x.parent se refiere al nodo padre de x, si existe, y la notación x.children se refiere al conjunto de nodos hijos de x. Dado que un elemento puede estar representado por el nodo en su raíz, la salida de un sistema de IR XML puede ser vista como una lista clasificada de los m nodos principales. La aplicación directa de una técnica estándar de clasificación de relevancia a un conjunto de elementos XML puede producir un resultado en el que los primeros puestos están dominados por muchos elementos estructuralmente relacionados. Una sección con una puntuación alta probablemente contenga varios párrafos con una puntuación alta y esté contenida en un artículo con una puntuación alta. Por ejemplo, muchos de los elementos en la figura 2 recibirían una puntuación alta en los algoritmos de compresión de índices de texto de consulta de palabras clave. Si cada uno de estos elementos se presenta a un usuario como un resultado individual y separado, puede perder mucho tiempo revisando y rechazando contenido redundante. Una posible solución es informar solo el elemento de mayor puntuación a lo largo de un camino dado en el árbol, y eliminar de los rangos inferiores cualquier elemento que lo contenga o esté contenido en él. Desafortunadamente, este enfoque destruye algunos de los posibles beneficios de XML IR. Por ejemplo, un elemento externo puede contener una cantidad sustancial de información que no aparece en un elemento interno, pero el elemento interno puede estar fuertemente enfocado en el tema de la consulta y proporcionar un breve resumen de los conceptos clave. En tales casos, es razonable informar sobre elementos que contienen, o están contenidos en, elementos de rango superior. Incluso cuando un libro entero es relevante, un usuario aún puede desear que se destaquen los párrafos más importantes, para guiar su lectura y ahorrar tiempo [6]. Este documento presenta un método para controlar la superposición. A partir de una clasificación inicial de elementos, un algoritmo de re-clasificación ajusta las puntuaciones de los elementos de menor clasificación que contienen, o están contenidos dentro de, elementos de mayor clasificación, reflejando el hecho de que esta información puede ser ahora redundante. Por ejemplo, una vez que un elemento que representa una sección aparece en la clasificación, las puntuaciones de los párrafos que contiene y del artículo que lo contiene se reducen. La inspiración para esta estrategia proviene parcialmente del trabajo reciente sobre la recuperación de documentos estructurados, donde los términos que aparecen en diferentes campos, como el título y el cuerpo, reciben diferentes pesos [20]. Extendiendo ese enfoque, el algoritmo de reordenamiento varía los pesos dinámicamente a medida que se procesan los elementos. El resto del documento está organizado de la siguiente manera: Después de una discusión sobre el trabajo de antecedentes y la metodología de evaluación, se presenta un método de recuperación de referencia en la sección 4. Este método de referencia representa una adaptación razonable de la tecnología estándar de IR al XML. La sección 5 luego describe una estrategia para controlar la superposición, utilizando el método de línea base como punto de partida. Un algoritmo de reordenamiento que implementa esta estrategia se presenta en la sección 6 y se evalúa en la sección 7. La sección 8 discute una versión extendida del algoritmo. 2. ANTECEDENTES Esta sección proporciona una visión general de la recuperación de información XML y discute trabajos relacionados, con énfasis en los problemas fundamentales mencionados en la introducción. Mucha investigación en el área de recuperación de XML lo ve desde una perspectiva de base de datos tradicional, preocupándose por problemas como la implementación de lenguajes de consulta estructurados [5] y el procesamiento de joins [1]. Aquí adoptamos una perspectiva de IR orientada al contenido, centrándonos en documentos XML que contienen principalmente datos en lenguaje natural y consultas que están principalmente expresadas en lenguaje natural. Suponemos que estas consultas indican únicamente la naturaleza del contenido deseado, no su estructura, y que el papel del sistema de RI es determinar qué elementos satisfacen mejor la necesidad de información subyacente. Otra investigación en IR ha considerado consultas mixtas, en las que se especifican tanto requisitos de contenido como estructurales [2,6,14,17,23]. 2.1 Estadísticas de Términos y Documentos En las aplicaciones tradicionales de recuperación de información, la unidad estándar de recuperación se considera que es el documento. Dependiendo de la aplicación, este término podría interpretarse para abarcar muchos objetos diferentes, incluyendo páginas web, artículos de periódico y mensajes de correo electrónico. Al aplicar técnicas estándar de clasificación de relevancia en el contexto de la RI XML, un enfoque natural es tratar cada elemento como un documento separado, con estadísticas de términos disponibles para cada uno [16]. Además, la mayoría de las técnicas de clasificación requieren estadísticas globales (por ejemplo, frecuencia inversa de documentos) calculadas sobre la colección en su totalidad. Si consideramos que esta colección incluye todos los elementos que podrían ser devueltos por el sistema, una ocurrencia específica de un término puede aparecer en varios documentos diferentes, quizás en elementos que representan un párrafo, una subsección, una sección y un artículo. No es apropiado calcular la frecuencia inversa de documentos bajo la suposición de que el término está contenido en todos estos elementos, ya que el número de elementos que contienen un término depende completamente del arreglo estructural de los documentos [13,23]. 2.2 Elementos Recuperables Si bien un sistema de recuperación de información XML podría potencialmente recuperar cualquier elemento, muchos elementos pueden no ser apropiados como resultados de recuperación. Esto suele ser el caso cuando los elementos contienen muy poco texto [10]. Por ejemplo, un título de sección que contenga solo los términos de búsqueda puede recibir una puntuación alta de un algoritmo de clasificación, pero por sí solo tendría un valor limitado para un usuario, quien podría preferir la sección real en sí misma. Otros elementos pueden reflejar la estructura física de los documentos, en lugar de la estructura lógica, lo cual puede tener poco o ningún significado para un usuario. Un sistema de recuperación de información XML efectivo debe devolver solo aquellos elementos que tengan suficiente contenido para ser utilizables y puedan funcionar como objetos independientes [15,18]. Componentes estándar de documentos como párrafos, secciones, subsecciones y resúmenes generalmente cumplen con estos requisitos; los títulos, frases en cursiva y campos de metadatos individuales a menudo no lo hacen. 2.3 Metodología de Evaluación En los últimos tres años, la Iniciativa para la Evaluación de la Recuperación de Información XML (INEX) ha fomentado la investigación en tecnología de recuperación de información XML [7,8]. INEX es una serie de conferencias experimentales, similar a TREC, en la que grupos de diferentes instituciones completan una o más tareas experimentales utilizando sus propias herramientas y sistemas, y comparan sus resultados en la propia conferencia. Más de 50 grupos participaron en INEX 2004, y la conferencia se ha convertido en tan influyente en el área de la RI XML como lo es TREC en otras áreas de la RI. La investigación descrita en este artículo, al igual que gran parte del trabajo relacionado que cita, depende de las colecciones de pruebas desarrolladas por INEX. La superposición causa problemas considerables en la evaluación de la recuperación, y los organizadores y participantes de INEX han luchado con estos problemas desde el principio. Aunque se ha logrado un progreso sustancial, estos problemas aún no están completamente resueltos. Kazai et al. [11] proporcionan una exposición detallada del problema de superposición en el contexto de la evaluación de recuperación de INEX y discuten tanto las métricas de evaluación actuales como las propuestas. Muchas de estas métricas se aplican para evaluar los experimentos reportados en este artículo, y se describen brevemente en la siguiente sección. 3. Las limitaciones de espacio impiden incluir más que un breve resumen de las tareas y metodología de evaluación de INEX 2004. Para obtener información detallada, se deben consultar las actas de la conferencia en sí [8]. 3.1 Tareas Para las principales tareas experimentales, a los participantes de INEX 2004 se les proporcionó una colección de 12,107 artículos tomados de las revistas y publicaciones de la IEEE Computer Societies entre 1995 y 2002. Cada documento está codificado en XML utilizando una DTD común, siendo el documento de las figuras 1 y 2 un ejemplo. En INEX 2004, las dos principales tareas experimentales fueron ambas tareas de recuperación ad hoc, investigando el rendimiento de sistemas que buscan en una colección estática utilizando temas previamente no vistos. Las dos tareas diferían en los tipos de temas que utilizaban. Para una tarea, la tarea de solo contenido o CO, los temas consisten en declaraciones cortas en lenguaje natural sin hacer referencia directa a la estructura de los documentos en la colección. Para esta tarea, se requiere que el sistema de IR seleccione los elementos a devolver. Para la otra tarea, la tarea de contenido y estructura o CAS, los temas están escritos en un lenguaje de consulta XML [22] y contienen referencias explícitas a la estructura del documento, que el sistema de IR debe intentar satisfacer. Dado que el trabajo descrito en este documento se enfoca en la tarea de solo contenido, donde el sistema de IR no recibe orientación sobre los elementos a devolver, la tarea de CAS se ignora en el resto de nuestra descripción. En 2004, los organizadores de la conferencia seleccionaron 40 nuevos temas de CO de las contribuciones proporcionadas por los participantes de la conferencia. Cada tema incluye una breve consulta de palabras clave, la cual es ejecutada sobre la colección por cada grupo participante en su propio sistema de IR XML. Cada grupo podría presentar hasta tres ejecuciones experimentales que consistieran en los primeros m = 1500 elementos para cada tema. 3.2 Evaluación de Relevancia Dado que la RI XML se preocupa por localizar aquellos elementos que proporcionan una cobertura completa de un tema mientras contienen la menor cantidad de información irrelevante posible, los juicios simples de relevante vs. no relevante no son suficientes. En cambio, los organizadores de INEX adoptaron dos dimensiones para la evaluación de relevancia: la dimensión de exhaustividad refleja el grado en que un elemento abarca el tema, y la dimensión de especificidad refleja el grado en que un elemento se enfoca en el tema. Se utiliza una escala de cuatro puntos en ambas dimensiones. Por lo tanto, un elemento (3,3) es altamente exhaustivo y altamente específico, un elemento (1,3) es marginalmente exhaustivo y altamente específico, y un elemento (0,0) no es relevante. Información adicional sobre la metodología de evaluación se puede encontrar en Piwowarski y Lalmas [19], quienes proporcionan una justificación detallada. 3.3 Métricas de Evaluación La métrica de evaluación principal utilizada en INEX 2004 es una versión de la precisión promedio media (MAP), ajustada por diversas funciones de cuantificación para dar diferentes pesos a diferentes elementos, dependiendo de sus valores de exhaustividad y especificidad. Una variante, la función de cuantización estricta asigna un peso de 1 a los elementos (3,3) y un peso de 0 a todos los demás. Esta variante es esencialmente el valor MAP familiar, con elementos (3,3) tratados como relevantes y todos los demás elementos tratados como no relevantes. Otras funciones de cuantización están diseñadas para otorgar crédito parcial a elementos que son aproximaciones cercanas, debido a la falta de exhaustividad y/o especificidad. Tanto la función de cuantificación generalizada como la función de generalización orientada a la especificidad (sog) acreditan elementos según su grado de relevancia [11], siendo que la segunda función pone mayor énfasis en la especificidad. Este documento informa los resultados de esta métrica utilizando las tres funciones de cuantización. Desde que esta métrica fue introducida por primera vez en INEX 2002, generalmente se le conoce como la métrica inex-2002. La métrica inex-2002 no penaliza la superposición. En particular, tanto las funciones de cuantificación generalizadas como las de sog otorgan crédito parcial a un casi acierto incluso cuando se informa un elemento (3,3) que se superpone a él en un rango más alto. Para abordar este problema, Kazai et al. [11] proponen una métrica de ganancia acumulada XML, que compara la ganancia acumulada [9] de una lista clasificada con un vector de ganancia ideal. Este vector de ganancia ideal se construye a partir de las valoraciones de relevancia al eliminar la superposición y retener solo el mejor elemento a lo largo de un camino dado. Por lo tanto, la métrica XCG recompensa las ejecuciones de recuperación que evitan la superposición. Aunque XCG no se utilizó oficialmente en INEX 2004, es probable que se utilice una versión de él en el futuro. En INEX 2003, se introdujo otra métrica para mejorar las limitaciones percibidas de la métrica inex-2002. Este métrico inex-2003 extiende las definiciones de precisión y exhaustividad para considerar tanto el tamaño de los componentes informados como la superposición entre ellos. Se crearon dos versiones, una que consideraba solo el tamaño de los componentes y otra que consideraba tanto el tamaño como la superposición. Si bien la métrica inex-2003 presenta anomalías no deseadas [11] y no se utilizó en 2004, se informan valores en la sección de evaluación para proporcionar un instrumento adicional para investigar la superposición. 4. MÉTODO DE RECUPERACIÓN DE BASELINE Esta sección proporciona una descripción general del método de recuperación de información XML de base actualmente utilizado en el sistema MultiText IR, desarrollado por el Grupo de Recuperación de Información de la Universidad de Waterloo [3]. Este método de recuperación resulta de la adaptación y ajuste de la medida Okapi BM25 [21] a la tarea de recuperación de información en XML. El sistema MultiText tuvo un desempeño respetable en INEX 2004, ubicándose entre los diez primeros en todas las funciones de cuantización, y ocupando el primer lugar cuando la función de cuantización enfatizaba la exhaustividad. Para admitir la recuperación de XML y otros tipos de documentos estructurados, el sistema proporciona consultas generalizadas de la forma: clasificar X por Y donde X es una subconsulta que especifica un conjunto de elementos de documentos a clasificar y Y es un vector de subconsultas que especifican términos de recuperación individuales. Para nuestras ejecuciones de INEX 2004, la subconsulta X especificó una lista de elementos recuperables como aquellos con nombres de etiquetas de la siguiente manera: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt. Esta lista incluye entradas bibliográficas (bb) y leyendas de figuras (fig) así como párrafos, secciones y subsecciones. Antes de INEX 2004, la colección de INEX y las evaluaciones de relevancia de INEX 2003 fueron analizadas manualmente para seleccionar estos nombres de etiquetas. Los nombres de las etiquetas fueron seleccionados en base a su frecuencia en la colección, el tamaño promedio de sus elementos asociados y el número relativo de juicios de relevancia positiva que recibieron. Automatizar este proceso de selección está planeado como trabajo futuro. Para INEX 2004, el vector término Y se derivó del tema dividiendo frases en palabras individuales, eliminando palabras vacías y términos negativos (aquellos que comienzan con -), y aplicando un stemmer. Por ejemplo, el campo de palabra clave del tema 166 +distancia de edición de árbol + XML -imagen se convirtió en la consulta de cuatro términos $árbol $edición $distancia $xml donde el operador $ dentro de una cadena entre comillas deriva el término que le sigue. Nuestra implementación de Okapi BM25 se deriva de la fórmula de Robertson et al. [21] al establecer los parámetros k2 = 0 y k3 = ∞. Dado un conjunto de términos Q, a un elemento x se le asigna la puntuación t∈Q w(1) qt (k1 + 1)xt K + xt (1) donde w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = número de documentos en el corpus Dt = número de documentos que contienen t qt = frecuencia con la que t ocurre en el tema xt = frecuencia con la que t ocurre en x K = k1((1 − b) + b · lx/lavg) lx = longitud de x lavg = longitud promedio del documento 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 PrecisiónPromedio(inex-2002) k1 estricto generalizado sog Figura 3: Impacto de k1 en la precisión promedio de inex-2002 con b = 0.75 (temas CO de INEX 2003). Antes de INEX 2004, los temas y juicios de INEX 2003 se utilizaron para ajustar los parámetros b y k1, y el impacto de este ajuste se discute más adelante en esta sección. Para los propósitos de calcular estadísticas a nivel de documento (D, Dt y lavg), un documento se define como un artículo. Estas estadísticas se utilizan para clasificar todos los tipos de elementos. Siguiendo la sugerencia de Kamps et al. [10], los resultados de recuperación se filtran para eliminar elementos muy cortos, aquellos con menos de 25 palabras de longitud. El uso de estadísticas de artículos para todos los tipos de elementos podría ser cuestionado. Este enfoque puede justificarse al considerar la colección como un conjunto de artículos que se pueden buscar utilizando técnicas estándar orientadas a documentos, donde solo se devuelven artículos. El puntaje calculado para un elemento es esencialmente el puntaje que recibiría si se agregara a la colección como un nuevo documento, ignorando los ajustes menores necesarios para las estadísticas a nivel de documento. Sin embargo, planeamos examinar este tema nuevamente en el futuro. En nuestra experiencia, el rendimiento de BM25 suele beneficiarse al ajustar los parámetros b y k1 a la colección, siempre que haya consultas de entrenamiento disponibles con este propósito. Antes de INEX 2004, entrenamos el sistema MultiText utilizando las consultas de INEX 2003. Como punto de partida, utilizamos los valores b = 0.75 y k1 = 1.2, que funcionan bien en colecciones TREC adhoc y se utilizan como valores predeterminados en nuestro sistema. Los resultados fueron sorprendentes. La Figura 3 muestra el resultado de variar k1 con b = 0.75 en los valores de MAP bajo tres funciones de cuantización. En nuestra experiencia, los valores óptimos para k1 suelen estar en el rango de 0.0 a 2.0. En este caso, se requieren valores grandes para un buen rendimiento. Entre k1 = 1.0 y k1 = 6.0, el MAP aumenta en más del 15% bajo la cuantización estricta. Se observan mejoras similares bajo las cuantizaciones generalizada y SOG. Por el contrario, nuestro valor predeterminado de b = 0.75 funciona bien bajo todas las funciones de cuantificación (figura 4). Después de ajustar una amplia gama de valores bajo varias funciones de cuantización, seleccionamos los valores de k = 10.0 y b = 0.80 para nuestros experimentos de INEX 2004, y estos valores se utilizan para los experimentos reportados en la sección 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 PrecisiónPromedioMedia (inex-2002) b estricto generalizado sog Figura 4: Impacto de b en la precisión promedio media de inex-2002 con k1 = 10 (temas CO de INEX 2003). 5. CONTROL DE SUPERPOSICIÓN Comenzando con una clasificación de elementos generada por el método de referencia descrito en la sección anterior, los elementos se vuelven a clasificar para controlar la superposición ajustando de forma iterativa las puntuaciones de aquellos elementos que contienen o están contenidos en elementos de clasificación más alta. A nivel conceptual, la reorganización procede de la siguiente manera: 1. Informe el elemento de rango más alto. Ajustar las puntuaciones de los elementos no reportados. 3. Repetir los pasos 1 y 2 hasta que se informen m elementos. Un enfoque para ajustar las puntuaciones de los elementos no informados en el paso 2 podría basarse en las puntuaciones Okapi BM25 de los elementos involucrados. Por ejemplo, supongamos que se informa un párrafo con una puntuación p en el paso 1. En el paso 2, la sección que contiene el párrafo podría tener su puntuación s reducida en una cantidad α · p para reflejar la contribución reducida que el párrafo debería hacer a la puntuación de las secciones. En un contexto relacionado, Robertson et al. [20] argumentan en contra de la combinación lineal de las puntuaciones de Okapi de esta manera. Ese trabajo considera el problema de asignar diferentes pesos a diferentes campos de documentos, como el título y el cuerpo asociados con páginas web. Un enfoque común para este problema puntúa el título y el cuerpo por separado y genera una puntuación final como una combinación lineal de ambos. Robertson et al. discuten las deficiencias teóricas en este enfoque y demuestran experimentalmente que puede perjudicar realmente la efectividad de la recuperación. En cambio, aplican los pesos a nivel de frecuencia de términos, donde la aparición de un término de consulta t en el título contribuye más al puntaje que una aparición en el cuerpo. En la ecuación 1, xt se convierte en α0 · yt + α1 · zt, donde yt es el número de veces que t aparece en el título y zt es el número de veces que t aparece en el cuerpo. Al traducir este enfoque a nuestro contexto, la contribución de los términos que aparecen en los elementos se reduce dinámicamente a medida que se informan. La siguiente sección presenta y analiza un algoritmo de reordenamiento simple que sigue esta estrategia. El algoritmo se evalúa experimentalmente en la sección 7. Una limitación del algoritmo es que la contribución de los términos que aparecen en los elementos informados se reduce por el mismo factor independientemente del número de elementos informados en los que aparezca. En la sección 8, el algoritmo se extiende para aplicar pesos crecientes, disminuyendo la puntuación, cuando un término aparece en más de un elemento informado. 6. ALGORITMO DE REORDENAMIENTO El algoritmo de reordenamiento opera sobre árboles XML, como el que aparece en la figura 2. La entrada al algoritmo es una lista de n elementos clasificados según sus puntuaciones iniciales de BM25. Durante la clasificación inicial, el árbol XML se reconstruye dinámicamente para incluir solo aquellos nodos con puntuaciones BM25 distintas de cero, por lo que n puede ser considerablemente menor que |N|. La salida del algoritmo es una lista de los primeros m elementos, clasificados según sus puntajes ajustados. Un elemento está representado por el nodo x ∈ N en su raíz. Asociados con este nodo se encuentran campos que almacenan la longitud del elemento, las frecuencias de términos y otra información requerida por el algoritmo de re-ranking, de la siguiente manera: x.f - <br>vector de frecuencia de términos</br> x.g - ajustes de frecuencia de términos x.l - longitud del elemento x.score - puntaje actual de Okapi BM25 x.reported - bandera booleana, inicialmente falsa x.children - conjunto de nodos hijos x.parent - nodo padre, si existe Estos campos se llenan durante el proceso de clasificación inicial y se actualizan a medida que avanza el algoritmo. El vector x.f contiene información de frecuencia de términos correspondiente a cada término en la consulta. El vector x.g es inicialmente cero y se actualiza por el algoritmo a medida que se informan elementos. El campo de puntuación contiene la puntuación BM25 actual para el elemento, la cual cambiará a medida que cambien los valores en x.g. El puntaje se calcula utilizando la ecuación 1, con el valor xt para cada término determinado por una combinación de los valores en x.f y x.g. Dado un término t ∈ Q, sea ft el componente de x.f correspondiente a t, y sea gt el componente de x.g correspondiente a t, entonces: xt = ft − α · gt (2) Para el procesamiento por el algoritmo de reordenamiento, los nodos se almacenan en colas de prioridad, ordenadas por puntaje decreciente. Cada cola de prioridad PQ admite tres operaciones: PQ.front() - devuelve el nodo con la puntuación más alta, PQ.add(x) - agrega el nodo x a la cola, PQ.remove(x) - elimina el nodo x de la cola. Cuando se implementan utilizando estructuras de datos estándar, la operación front requiere tiempo O(1), y las otras operaciones requieren tiempo O(log n), donde n es el tamaño de la cola. El núcleo del algoritmo de reordenamiento se presenta en la figura 5. El algoritmo toma como entrada la cola de prioridad S que contiene la clasificación inicial, y produce los primeros m nodos reordenados en la cola de prioridad F. Después de inicializar F como vacío en la línea 1, el algoritmo recorre m veces las líneas 215, transfiriendo al menos un nodo de S a F durante cada iteración. Al inicio de cada iteración, el nodo no reportado al frente de S tiene el mayor puntaje ajustado, y se elimina y se agrega a F. El algoritmo luego recorre el 1 F ← ∅ 2 para i ← 1 a m hacer 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 para cada y ∈ x.children hacer 9 Abajo (y) 10 fin hacer 11 12 si x no es un nodo raíz entonces 13 Arriba (x, x.parent) 14 fin si 15 fin hacer Figura 5: Algoritmo de Re-Ranking - Como entrada, el algoritmo toma una cola de prioridad S, que contiene nodos XML clasificados por sus puntajes iniciales, y devuelve sus resultados en la cola de prioridad F, clasificados por puntajes ajustados. 1 Arriba(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recalcular y.score 5 S.add(y) 6 si y no es un nodo raíz entonces 7 Arriba (x, y.parent) 8 fin si 9 10 Abajo(x) ≡ 11 si no x.reported entonces 12 S.remove(x) 14 x.g ← x.f 15 recalcular x.score 16 si x.score > 0 entonces 17 F.add(x) 18 fin si 19 x.reported ← true 20 para cada y ∈ x.children hacer 21 Abajo (y) 22 fin hacer 23 fin si Figura 6: Rutinas de recorrido de árbol llamadas por el algoritmo de re-ranking. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 PrecisiónPromedioMedia (inex-2002) GananciaAcumuladaXML(XCG) alfa MAP (estricto) MAP (generalizado) MAP (sog) XCG (sog2) Figura 7: Impacto de α en XCG y MAP inex-2002 (temas CO de INEX 2004; conjunto de evaluación I). nodos ancestros (líneas 8-10) y descendientes (líneas 12-14) ajustando los puntajes de estos nodos. Las rutinas de recorrido de árboles, Arriba y Abajo, se muestran en la figura 6. El procedimiento Up elimina cada nodo ancestro de S, ajusta sus valores de frecuencia de término, recalcula su puntuación y lo vuelve a agregar a S. El ajuste de los valores de frecuencia de término (línea 3) agrega a y.g solo las ocurrencias de términos no reportadas previamente en x. El recalculo de la puntuación en la línea 4 utiliza las ecuaciones 1 y 2. La rutina Down realiza una operación similar en cada descendiente. Sin embargo, dado que el contenido de cada descendiente está completamente contenido en un elemento informado, su puntuación final puede ser calculada, y se elimina de S y se agrega a F. Para determinar la complejidad temporal del algoritmo, primero observe que un nodo puede ser un argumento de Down como máximo una vez. Posteriormente, la bandera reportada de su padre es verdadera. Durante cada llamada a Down, un nodo puede ser movido de S a F, lo que requiere un tiempo O(log n). Por lo tanto, el tiempo total para todas las llamadas a Down es O(n log n), y podemos ignorar temporalmente las líneas 8-10 de la figura 5 al considerar la complejidad temporal del bucle sobre las líneas 2-15. Durante cada iteración de este bucle, se elimina un nodo y cada uno de sus ancestros de una cola de prioridad y luego se vuelven a agregar a la cola de prioridad. Dado que un nodo puede tener como máximo h ancestros, donde h es la altura máxima de cualquier árbol en la colección, cada una de las m iteraciones requiere un tiempo de O(h log n). La combinación de estas observaciones produce una complejidad temporal general de O((n + mh) log n). En la práctica, volver a clasificar un conjunto de resultados de INEX requiere menos de 200 ms en una PC de escritorio de tres años de antigüedad. EVALUACIÓN Ninguna de las métricas descritas en la sección 3.3 se ajusta adecuadamente a la perspectiva de superposición defendida por este documento. Sin embargo, cuando se toman en conjunto, proporcionan información sobre el comportamiento del algoritmo de reordenamiento. Los paquetes de evaluación de INEX (inex_eval e inex_eval_ng) se utilizaron para calcular los valores de las métricas inex-2002 e inex-2003. Los valores de las métricas XCG fueron calculados utilizando el software proporcionado por sus inventores [11]. La Figura 7 representa juntas las tres variantes de la métrica MAP inex-2002 junto con la métrica XCG. Los valores para estas métricas 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Precisión Media Promedio (inex-2003) alfa estricto, superposición no considerada estricto, superposición considerada generalizado, superposición no considerada generalizado, superposición considerada Figura 8: Impacto de α en MAP inex-2003 (temas CO de INEX 2004; conjunto de evaluación I). se trazan para valores de α entre 0.0 y 1.0. Recordando que la métrica XCG está diseñada para penalizar la superposición, mientras que la métrica inex-2002 ignora la superposición, el conflicto entre las métricas es evidente. Los valores de MAP en un extremo (α = 0.0) y el valor de XCG en el otro extremo (α = 1.0) representan un rendimiento de recuperación comparable a los mejores sistemas en INEX 2004 [8,12]. La Figura 8 muestra los valores de la métrica MAP inex-2003 para dos cuantificaciones, con y sin consideración de la superposición. Una vez más, el conflicto es evidente, con la influencia de α considerablemente disminuida cuando se considera la superposición. 8. ALGORITMO EXTENDIDO Una limitación del algoritmo de reordenamiento es que se utiliza un único peso α para ajustar las puntuaciones tanto de los ancestros como de los descendientes de los elementos informados. Una extensión obvia es usar diferentes pesos en estos dos casos. Además, se utiliza el mismo peso independientemente de cuántas veces un elemento esté contenido en un elemento informado. Por ejemplo, un párrafo puede formar parte de una sección reportada y luego formar parte de un artículo reportado. Dado que el usuario puede haber visto este párrafo dos veces, su puntuación debería ser reducida aún más aumentando el valor del peso. Motivado por estas observaciones, el algoritmo de reordenamiento puede ser extendido con una serie de pesos 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0, donde βj es el peso aplicado a un nodo que ha sido descendiente de un nodo reportado j veces. Ten en cuenta que un límite superior en M es h, la altura máxima de cualquier árbol XML en la colección. Sin embargo, en la práctica es probable que M sea relativamente pequeño (quizás 3 o 4). La Figura 9 presenta reemplazos para las rutinas de Subir y Bajar de la Figura 6, incorporando esta serie de pesas. Se requiere un campo adicional en cada nodo, de la siguiente manera: x.j - conteo descendente El valor de x.j se establece inicialmente en cero en todos los nodos y se incrementa cada vez que se llama a Down con x como su argumento. Al calcular la puntuación del nodo, el valor de x.j selecciona 1 Up(x, y) ≡ 2 si no y.reported entonces 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recalcular y.score 6 S.add(y) 8 si y no es un nodo raíz entonces 9 Up (x, y.padre) 10 fin si 11 fin si 12 13 Down(x) ≡ 14 si x.j < M entonces 15 x.j ← x.j + 1 16 si no x.reported entonces 17 S.remove(x) 18 recalcular x.score 19 S.add(x) 20 fin si 21 para cada y ∈ x.hijos hacer 22 Down (y) 23 fin hacer 24 fin si Figura 9: Rutinas extendidas de recorrido de árbol. el peso a aplicar al nodo ajustando el valor de xt en la ecuación 1, de la siguiente manera: xt = βx.j · (ft − α · gt) (3) donde ft y gt son los componentes de x.f y x.g correspondientes al término t. Se requieren algunos cambios adicionales para extender Up y Down. La rutina Up devuelve inmediatamente (línea 2) si su argumento ya ha sido reportado, ya que las frecuencias de términos ya han sido ajustadas en sus ancestros. El procedimiento Down no informa su argumento, sino que vuelve a calcular su puntuación y la agrega de nuevo a S. Un nodo no puede ser un argumento de Down más de M +1 veces, lo que a su vez implica una complejidad temporal total de O((nM + mh) log n). Dado que M ≤ h y m ≤ n, la complejidad temporal también es O(nh log n). DISCUSIÓN CONCLUSIVA Al generar resultados de recuperación en una colección de XML, se debe tolerar cierta superposición en los resultados, lo cual puede ser beneficioso. Por ejemplo, cuando un elemento altamente exhaustivo y bastante específico (3,2) contiene un elemento mucho más pequeño (2,3), ambos deben ser informados al usuario, y los algoritmos de recuperación y las métricas de evaluación deben respetar esta relación. El algoritmo presentado en este documento controla la superposición ponderando los términos que aparecen en los elementos informados para reflejar su menor importancia. Otros enfoques también pueden ayudar a controlar la superposición. Por ejemplo, cuando se presentan los resultados de recuperación de XML a los usuarios, puede ser deseable agrupar elementos relacionados estructuralmente juntos, ilustrando visualmente las relaciones entre ellos. Si bien este estilo de interfaz de usuario puede ayudar a un usuario a lidiar con la superposición, la estrategia presentada en este documento sigue siendo aplicable, al determinar los mejores elementos para incluir en cada grupo. En Waterloo, seguimos desarrollando y probando nuestras ideas para INEX 2005. En particular, estamos investigando métodos para aprender los pesos α y βj. También estamos reevaluando nuestro enfoque en las estadísticas de documentos y examinando ajustes apropiados al parámetro k1 a medida que cambian los pesos de los términos [20]. 10. AGRADECIMIENTOS Gracias a Gabriella Kazai y Arjen de Vries por proporcionar una versión temprana de su software para calcular la métrica XCG, y gracias a Phil Tilker y Stefan B¨uttcher por su ayuda con la evaluación experimental. En parte, la financiación para este proyecto fue proporcionada por IBM Canadá a través del Instituto Nacional de Investigación de Software. 11. REFERENCIAS [1] N. Bruno, N. Koudas y D. Srivastava. Uniones de ramas holísticas: Coincidencia óptima de patrones XML. En Actas de la Conferencia Internacional ACM SIGMOD 2002 sobre la Gestión de Datos, páginas 310-321, Madison, Wisconsin, junio de 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y. Masa y A. Soffer. Buscando documentos XML a través de fragmentos XML. En Actas de la 26ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 151-158, Toronto, Canadá, 2003. [3] C. L. A. Clarke y P. L. Tilker. Experimentos MultiText para INEX 2004. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai y M. Lalmas. Tolerancia a la irrelevancia: Una evaluación orientada al esfuerzo del usuario de sistemas de recuperación sin unidad de recuperación predefinida. En las Actas de la Conferencia RIAO 2004, páginas 463-473, Aviñón, Francia, abril de 2004. [5] D. DeHaan, D. Toman, M. P. Consens y M. T. ¨Ozsu. Una traducción exhaustiva de XQuery a SQL utilizando codificación dinámica de intervalos. En Actas de la Conferencia Internacional ACM SIGMOD 2003 sobre la Gestión de Datos, San Diego, junio de 2003. [6] N. Fuhr y K. Großjohann. XIRQL: Un lenguaje de consulta para la recuperación de información en documentos XML. En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 172-180, Nueva Orleans, septiembre de 2001. [7] N. Fuhr, M. Lalmas y S. Malik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Segundo Taller (INEX 2003), Dagstuhl, Alemania, diciembre de 2003. [8] N. Fuhr, M. Lalmas, S. Malik y Zoltán Szlávik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Tercer Taller (INEX 2004), Dagstuhl, Alemania, diciembre de 2004. Publicado como Avances en la Recuperación de Información XML, Notas de Conferencia en Ciencias de la Computación, volumen 3493, Springer, 2005. [9] K. J¨avelin y J. Kek¨al¨ainen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, y B. Sigurbjörnsson. Normalización de longitud en la recuperación de XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 80-87, Sheffield, Reino Unido, julio de 2004. [11] G. Kazai, M. Lalmas y A. P. de Vries. El problema de superposición en la evaluación de la recuperación de XML orientada al contenido. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 72-79, Sheffield, Reino Unido, julio de 2004. [12] G. Kazai, M. Lalmas y A. P. de Vries. Pruebas de confiabilidad para las métricas XCG e inex-2002. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola y T. Aalto. TRIX 2004 - Luchando con la superposición. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [14] S. Liu, Q. Zou y W. W. Chu. Indexación y clasificación configurables para la recuperación de información en XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 88-95, Sheffield, Reino Unido, julio de 2004. [15] Y. Masa y M. Mandelbrot. Recuperando los componentes XML más relevantes. En las Actas del Taller INEX 2003, Dagstuhl, Alemania, diciembre de 2003. [16] Y. Masa y M. Mandelbrot. Clasificación de componentes y refinamiento automático de consultas para la recuperación de XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [17] P. Ogilvie y J. Callan. Modelos de lenguaje jerárquicos para la recuperación de componentes XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [18] J. Pehcevski, J. A. Thom y A. Vercoustre. Recuperación híbrida de XML revisitada. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [19] B. Piwowarski y M. Lalmas. Proporcionando evaluaciones de relevancia consistentes y exhaustivas para la evaluación de recuperación de XML. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 361-370, Washington, DC, noviembre de 2004. [20] S. Robertson, H. Zaragoza y M. Taylor. Extensión simple de BM25 a múltiples campos ponderados. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 42-50, Washington, DC, noviembre de 2004. [21] S. E. Robertson, S. Walker y M. Beaulieu. Okapi en TREC-7: Búsqueda automática, filtrado, VLC y pista interactiva. En Actas de la Séptima Conferencia de Recuperación de Texto, Gaithersburg, MD, noviembre de 1998. [22] A. Trotman y B. Sigurbjörnsson. NEXI, ahora y después. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski y P. Gallinari. Un álgebra para consultas estructuradas en redes bayesianas. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "priority queue": {
            "translated_key": "cola de prioridad",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Controlling Overlap in Content-Oriented XML Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of XML documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
                "This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents.",
                "The test collection developed by the INitiative for the Evaluation of XML Retrieval (INEX) forms the basis for the evaluation.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "INTRODUCTION The representation of documents in XML provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an XML information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in XML.",
                "Figure 1 provides an example of a journal article encoded in XML, illustrating many of the important characteristics of XML documents.",
                "Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words.",
                "Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate.",
                "Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs.",
                "Each of these characteristics affects the design of an XML IR system, and each leads to fundamental problems that must be solved in an successful system.",
                "Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper.",
                "The article of figure 1 may be viewed as an XML tree, as illustrated in figure 2.",
                "Formally, a collection of XML documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes.",
                "For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example XML tree. of x.",
                "Since an element may be represented by the node at its root, the output of an XML IR system may be viewed as a ranked list of the top-m nodes.",
                "The direct application of a standard relevance ranking technique to a set of XML elements can produce a result in which the top ranks are dominated by many structurally related elements.",
                "A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article.",
                "For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms.",
                "If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content.",
                "One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it.",
                "Unfortunately, this approach destroys some of the possible benefits of XML IR.",
                "For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts.",
                "In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements.",
                "Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6].",
                "This paper presents a method for controlling overlap.",
                "Starting with an initial element ranking, a re-ranking algorithm adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
                "For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced.",
                "The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20].",
                "Extending that approach, the re-ranking algorithm varies weights dynamically as elements are processed.",
                "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a baseline retrieval method is presented in section 4.",
                "This baseline method represents a reasonable adaptation of standard IR technology to XML.",
                "Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point.",
                "A re-ranking algorithm implementing this strategy is presented in section 6 and evaluated in section 7.",
                "Section 8 discusses an extended version of the algorithm. 2.",
                "BACKGROUND This section provides a general overview of XML information retrieval and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
                "Much research in the area of XML retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1].",
                "Here, we take a content oriented IR perceptive, focusing on XML documents that primarily contain natural language data and queries that are primarily expressed in natural language.",
                "We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need.",
                "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional information retrieval applications the standard unit of retrieval is taken to be the document.",
                "Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages.",
                "When applying standard relevance ranking techniques in the context of XML IR, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
                "In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole.",
                "If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article.",
                "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an XML IR system might potentially retrieve any element, many elements may not be appropriate as retrieval results.",
                "This is usually the case when elements contain very little text [10].",
                "For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself.",
                "Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user.",
                "An effective XML IR system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18].",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (INEX) has encouraged research into XML information retrieval technology [7,8].",
                "INEX is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
                "Over 50 groups participated in INEX 2004, and the conference has become as influential in the area of XML IR as TREC is in other IR areas.",
                "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by INEX.",
                "Overlap causes considerable problems with retrieval evaluation, and the INEX organizers and participants have wrestled with these problems since the beginning.",
                "While substantial progress has been made, these problem are still not completely solved.",
                "Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of INEX retrieval evaluation and discuss both current and proposed evaluation metrics.",
                "Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3.",
                "INEX 2004 Space limitations prevent the inclusion of more than a brief summary of INEX 2004 tasks and evaluation methodology.",
                "For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, INEX 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002.",
                "Each document is encoded in XML using a common DTD, with the document of figures 1 and 2 providing one example.",
                "At INEX 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics.",
                "The two tasks differed in the types of topics they used.",
                "For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection.",
                "For this task, the IR system is required to select the elements to be returned.",
                "For the other task, the contentand-structure or CAS task, the topics are written in an XML query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy.",
                "Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description.",
                "In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants.",
                "Each topic includes a short keyword query, which is executed over the collection by each participating group on their own XML IR system.",
                "Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since XML IR is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient.",
                "Instead, the INEX organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic.",
                "A four-point scale is used in both dimensions.",
                "Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant.",
                "Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at INEX 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values.",
                "One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others.",
                "This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant.",
                "Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity.",
                "Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity.",
                "This paper reports results of this metric using all three of these quantization functions.",
                "Since this metric was first introduced at INEX 2002, it is generally referred as the inex-2002 metric.",
                "The inex-2002 metric does not penalize overlap.",
                "In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank.",
                "To address this problem, Kazai et al. [11] propose an XML cumulated gain metric, which compares the cumulated gain [9] of a ranked list to an ideal gain vector.",
                "This ideal gain vector is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path.",
                "Thus, the XCG metric rewards retrieval runs that avoid overlap.",
                "While XCG was not used officially at INEX 2004, a version of it is likely to be used in the future.",
                "At INEX 2003, yet another metric was introduced to ameliorate the perceived limitations of the inex-2002 metric.",
                "This inex-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them.",
                "Two versions were created, one that considered only component size and another that considered both size and overlap.",
                "While the inex-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4.",
                "BASELINE RETRIEVAL METHOD This section provides an overview of baseline XML information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3].",
                "This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the XML information retrieval task.",
                "The MultiText system performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
                "To support retrieval from XML and other structured document types, the system provides generalized queries of the form: rank X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms.",
                "For our INEX 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections.",
                "Prior to INEX 2004, the INEX collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names.",
                "Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received.",
                "Automating this selection process is planned as future work.",
                "For INEX 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.",
                "For example, keyword field of topic 166 +tree edit distance + XML -image became the four-term query $tree $edit $distance $xml where the $ operator within a quoted string stems the term that follows it.",
                "Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞.",
                "Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(inex-2002) k1 strict generalized sog Figure 3: Impact of k1 on inex-2002 mean average precision with b = 0.75 (INEX 2003 CO topics).",
                "Prior to INEX 2004, the INEX 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.",
                "For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article.",
                "These statistics are used for ranking all element types.",
                "Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length.",
                "The use of article statistics for all element types might be questioned.",
                "This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.",
                "The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics.",
                "Nonetheless, we plan to examine this issue again in the future.",
                "In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose.",
                "Prior to INEX 2004, we trained the MultiText system using the INEX 2003 queries.",
                "As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system.",
                "The results were surprising.",
                "Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions.",
                "In our experience, optimal values for k1 are typically in the range 0.0 to 2.0.",
                "In this case, large values are required for good performance.",
                "Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization.",
                "Similar improvements are seen under the generalized and sog quantizations.",
                "In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).",
                "After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our INEX 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5.",
                "CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements.",
                "At a conceptual level, re-ranking proceeds as follows: 1.",
                "Report the highest ranking element. 2.",
                "Adjust the scores of the unreported elements. 3.",
                "Repeat steps 1 and 2 until m elements are reported.",
                "One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements.",
                "For example, assume a paragraph with score p is reported in step 1.",
                "In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score.",
                "In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion.",
                "That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages.",
                "A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two.",
                "Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness.",
                "Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body.",
                "In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body.",
                "Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported.",
                "The next section presents and analysis a simple re-ranking algorithm that follows this strategy.",
                "The algorithm is evaluated experimentally in section 7.",
                "One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears.",
                "In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6.",
                "RE-RANKING ALGORITHM The re-ranking algorithm operates over XML trees, such as the one appearing in figure 2.",
                "Input to the algorithm is a list of n elements ranked according to their initial BM25 scores.",
                "During the initial ranking the XML tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |.",
                "Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores.",
                "An element is represented by the node x ∈ N at its root.",
                "Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - term frequency vector x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses.",
                "The vector x.f contains term frequency information corresponding to each term in the query.",
                "The vector x.g is initially zero and is updated by the algorithm as elements are reported.",
                "The score field contains the current BM25 score for the element, which will change as the values in x.g change.",
                "The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g.",
                "Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the re-ranking algorithm, nodes are stored in priority queues, ordered by decreasing score.",
                "Each <br>priority queue</br> PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
                "The core of the re-ranking algorithm is presented in figure 5.",
                "The algorithm takes as input the <br>priority queue</br> S containing the initial ranking, and produces the top-m reranked nodes in the <br>priority queue</br> F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
                "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a <br>priority queue</br> S, containing XML nodes ranked by their initial scores, and returns its results in <br>priority queue</br> F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
                "The tree traversal routines, Up and Down are given in figure 6.",
                "The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2.",
                "The Down routine performs a similar operation on each descendant.",
                "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the time complexity of the algorithm, first note that a node may be an argument to Down at most once.",
                "Thereafter, the reported flag of its parent is true.",
                "During each call to Down a node may be moved from S to F, requiring O(log n) time.",
                "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the time complexity of the loop over lines 2-15.",
                "During each iteration of this loop, a node and each of its ancestors are removed from a <br>priority queue</br> and then added back into a <br>priority queue</br>.",
                "Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time.",
                "Combining these observations produces an overall time complexity of O((n + mh) log n).",
                "In practice, re-ranking an INEX result set requires less than 200ms on a three-year-old desktop PC. 7.",
                "EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper.",
                "Nonetheless, when taken together they provide insight into the behaviour of the re-ranking algorithm.",
                "The INEX evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the inex-2002 and inex-2003 metrics.",
                "Values for the XCG metrics were computed using software supplied by its inventors [11].",
                "Figure 7 plots the three variants of inex-2002 MAP metric together with the XCG metric.",
                "Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on inex-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0.",
                "Recalling that the XCG metric is designed to penalize overlap, while the inex-2002 metric ignores overlap, the conflict between the metrics is obvious.",
                "The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at INEX 2004 [8,12].",
                "Figure 8 plots values of the inex-2003 MAP metric for two quantizations, with and without consideration of overlap.",
                "Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8.",
                "EXTENDED ALGORITHM One limitation of the re-ranking algorithm is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements.",
                "An obvious extension is to use different weights in these two cases.",
                "Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element.",
                "For example, a paragraph may form part of a reported section and then form part of a reported article.",
                "Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight.",
                "Motivated by these observations, the re-ranking algorithm may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times.",
                "Note that an upper bound on M is h, the maximum height of any XML tree in the collection.",
                "However, in practice M is likely to be relatively small (perhaps 3 or 4).",
                "Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights.",
                "One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument.",
                "When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down.",
                "The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors.",
                "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall time complexity of O((nM + mh) log n).",
                "Since M ≤ h and m ≤ n, the time complexity is also O(nh log n). 9.",
                "CONCLUDING DISCUSSION When generating retrieval results over an XML collection, some overlap in the results should be tolerated, and may be beneficial.",
                "For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship.",
                "The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance.",
                "Other approaches may also help to control overlap.",
                "For example, when XML retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them.",
                "While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster.",
                "At Waterloo, we continue to develop and test our ideas for INEX 2005.",
                "In particular, we are investigating methods for learning the α and βj weights.",
                "We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10.",
                "ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation.",
                "In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11.",
                "REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava.",
                "Holistic twig joins: Optimal XML pattern matching.",
                "In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
                "Mass, and A. Soffer.",
                "Searching XML documents via XML fragments.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker.",
                "MultiText experiments for INEX 2004.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas.",
                "Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit.",
                "In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu.",
                "A comprehensive XQuery to SQL translation using dynamic interval encoding.",
                "In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann.",
                "XIRQL: A query language for information retrieval in XML documents.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Second Workshop (INEX 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Third Workshop (INEX 2004), Dagstuhl, Germany, December 2004.",
                "Published as Advances in XML Information Retrieval, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson.",
                "Length normalization in XML retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "The overlap problem in content-oriented XML retrieval evaluation.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "Reliability tests for the XCG and inex-2002 metrics.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto.",
                "TRIX 2004 - Struggling with the overlap.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu.",
                "Configurable indexing and ranking for XML information retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 88-95, Sheffield, UK, July 2004. [15] Y.",
                "Mass and M. Mandelbrod.",
                "Retrieving the most relevant XML components.",
                "In INEX 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y.",
                "Mass and M. Mandelbrod.",
                "Component ranking and automatic query refinement for XML retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan.",
                "Hierarchical language models for XML component retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [18] J. Pehcevski, J.",
                "A. Thom, and A. Vercoustre.",
                "Hybrid XML retrieval re-visited.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas.",
                "Providing consistent and exhaustive relevance assessments for XML retrieval evaluation.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor.",
                "Simple BM25 extension to multiple weighted fields.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu.",
                "Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track.",
                "In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson.",
                "NEXI, now and next.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari.",
                "An algebra for structured queries in bayesian networks.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]."
            ],
            "original_annotated_samples": [
                "Each <br>priority queue</br> PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
                "The algorithm takes as input the <br>priority queue</br> S containing the initial ranking, and produces the top-m reranked nodes in the <br>priority queue</br> F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
                "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a <br>priority queue</br> S, containing XML nodes ranked by their initial scores, and returns its results in <br>priority queue</br> F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
                "During each iteration of this loop, a node and each of its ancestors are removed from a <br>priority queue</br> and then added back into a <br>priority queue</br>."
            ],
            "translated_annotated_samples": [
                "Cada <br>cola de prioridad</br> PQ admite tres operaciones: PQ.front() - devuelve el nodo con la puntuación más alta, PQ.add(x) - agrega el nodo x a la cola, PQ.remove(x) - elimina el nodo x de la cola. Cuando se implementan utilizando estructuras de datos estándar, la operación front requiere tiempo O(1), y las otras operaciones requieren tiempo O(log n), donde n es el tamaño de la cola.",
                "El algoritmo toma como entrada la <br>cola de prioridad</br> S que contiene la clasificación inicial, y produce los primeros m nodos reordenados en la <br>cola de prioridad</br> F. Después de inicializar F como vacío en la línea 1, el algoritmo recorre m veces las líneas 215, transfiriendo al menos un nodo de S a F durante cada iteración.",
                "Al inicio de cada iteración, el nodo no reportado al frente de S tiene el mayor puntaje ajustado, y se elimina y se agrega a F. El algoritmo luego recorre el 1 F ← ∅ 2 para i ← 1 a m hacer 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 para cada y ∈ x.children hacer 9 Abajo (y) 10 fin hacer 11 12 si x no es un nodo raíz entonces 13 Arriba (x, x.parent) 14 fin si 15 fin hacer Figura 5: Algoritmo de Re-Ranking - Como entrada, el algoritmo toma una <br>cola de prioridad</br> S, que contiene nodos XML clasificados por sus puntajes iniciales, y devuelve sus resultados en la <br>cola de prioridad</br> F, clasificados por puntajes ajustados. 1 Arriba(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recalcular y.score 5 S.add(y) 6 si y no es un nodo raíz entonces 7 Arriba (x, y.parent) 8 fin si 9 10 Abajo(x) ≡ 11 si no x.reported entonces 12 S.remove(x) 14 x.g ← x.f 15 recalcular x.score 16 si x.score > 0 entonces 17 F.add(x) 18 fin si 19 x.reported ← true 20 para cada y ∈ x.children hacer 21 Abajo (y) 22 fin hacer 23 fin si Figura 6: Rutinas de recorrido de árbol llamadas por el algoritmo de re-ranking. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 PrecisiónPromedioMedia (inex-2002) GananciaAcumuladaXML(XCG) alfa MAP (estricto) MAP (generalizado) MAP (sog) XCG (sog2) Figura 7: Impacto de α en XCG y MAP inex-2002 (temas CO de INEX 2004; conjunto de evaluación I). nodos ancestros (líneas 8-10) y descendientes (líneas 12-14) ajustando los puntajes de estos nodos.",
                "Durante cada iteración de este bucle, se elimina un nodo y cada uno de sus ancestros de una <br>cola de prioridad</br> y luego se vuelven a agregar a la <br>cola de prioridad</br>."
            ],
            "translated_text": "Controlando la superposición en la recuperación XML orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca RESUMEN La aplicación directa de técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos XML a menudo produce un conjunto de resultados en el que los primeros puestos están dominados por un gran número de elementos tomados de un pequeño número de documentos altamente relevantes. Este documento presenta y evalúa un algoritmo que vuelve a clasificar este conjunto de resultados, con el objetivo de minimizar el contenido redundante mientras se preservan los beneficios de la recuperación de elementos, incluido el beneficio de identificar componentes centrados en el tema contenidos en documentos relevantes. La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la Recuperación XML (INEX) constituye la base para la evaluación. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Búsqueda y Recuperación de Información Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. La representación de documentos en XML brinda una oportunidad para que los sistemas de recuperación de información aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias. En respuesta a una consulta de usuario, un sistema de recuperación de información XML podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes. Esta facilidad es de particular beneficio cuando una colección contiene documentos muy largos, como manuales de productos o libros, donde el usuario debe ser dirigido a las partes más relevantes de estos documentos. La Figura 1 proporciona un ejemplo de un artículo de revista codificado en XML, ilustrando muchas de las características importantes de los documentos XML. Las etiquetas indican el inicio y el final de cada elemento, con elementos que varían ampliamente en tamaño, desde una palabra hasta miles de palabras. Algunos elementos, como párrafos y secciones, pueden presentarse razonablemente al usuario como resultados de búsqueda, pero otros no son apropiados. Los elementos se superponen entre sí: los artículos contienen secciones, las secciones contienen subsecciones y las subsecciones contienen párrafos. Cada una de estas características afecta el diseño de un sistema de IR XML, y cada una conlleva problemas fundamentales que deben resolverse en un sistema exitoso. La mayoría de estos problemas fundamentales pueden resolverse mediante la cuidadosa adaptación de técnicas estándar de IR, pero los problemas causados por la superposición son únicos en esta área [4,11] y constituyen el enfoque principal de este artículo. El artículo de la figura 1 puede ser visto como un árbol XML, como se ilustra en la figura 2. Formalmente, una colección de documentos XML puede ser representada como un bosque de árboles ordenados y enraizados, que consiste en un conjunto de nodos N y un conjunto de aristas dirigidas E que conectan estos nodos. Para cada nodo x ∈ N, la notación x.parent se refiere al nodo padre de x, si existe, y la notación x.children se refiere al conjunto de nodos hijos de x. Dado que un elemento puede estar representado por el nodo en su raíz, la salida de un sistema de IR XML puede ser vista como una lista clasificada de los m nodos principales. La aplicación directa de una técnica estándar de clasificación de relevancia a un conjunto de elementos XML puede producir un resultado en el que los primeros puestos están dominados por muchos elementos estructuralmente relacionados. Una sección con una puntuación alta probablemente contenga varios párrafos con una puntuación alta y esté contenida en un artículo con una puntuación alta. Por ejemplo, muchos de los elementos en la figura 2 recibirían una puntuación alta en los algoritmos de compresión de índices de texto de consulta de palabras clave. Si cada uno de estos elementos se presenta a un usuario como un resultado individual y separado, puede perder mucho tiempo revisando y rechazando contenido redundante. Una posible solución es informar solo el elemento de mayor puntuación a lo largo de un camino dado en el árbol, y eliminar de los rangos inferiores cualquier elemento que lo contenga o esté contenido en él. Desafortunadamente, este enfoque destruye algunos de los posibles beneficios de XML IR. Por ejemplo, un elemento externo puede contener una cantidad sustancial de información que no aparece en un elemento interno, pero el elemento interno puede estar fuertemente enfocado en el tema de la consulta y proporcionar un breve resumen de los conceptos clave. En tales casos, es razonable informar sobre elementos que contienen, o están contenidos en, elementos de rango superior. Incluso cuando un libro entero es relevante, un usuario aún puede desear que se destaquen los párrafos más importantes, para guiar su lectura y ahorrar tiempo [6]. Este documento presenta un método para controlar la superposición. A partir de una clasificación inicial de elementos, un algoritmo de re-clasificación ajusta las puntuaciones de los elementos de menor clasificación que contienen, o están contenidos dentro de, elementos de mayor clasificación, reflejando el hecho de que esta información puede ser ahora redundante. Por ejemplo, una vez que un elemento que representa una sección aparece en la clasificación, las puntuaciones de los párrafos que contiene y del artículo que lo contiene se reducen. La inspiración para esta estrategia proviene parcialmente del trabajo reciente sobre la recuperación de documentos estructurados, donde los términos que aparecen en diferentes campos, como el título y el cuerpo, reciben diferentes pesos [20]. Extendiendo ese enfoque, el algoritmo de reordenamiento varía los pesos dinámicamente a medida que se procesan los elementos. El resto del documento está organizado de la siguiente manera: Después de una discusión sobre el trabajo de antecedentes y la metodología de evaluación, se presenta un método de recuperación de referencia en la sección 4. Este método de referencia representa una adaptación razonable de la tecnología estándar de IR al XML. La sección 5 luego describe una estrategia para controlar la superposición, utilizando el método de línea base como punto de partida. Un algoritmo de reordenamiento que implementa esta estrategia se presenta en la sección 6 y se evalúa en la sección 7. La sección 8 discute una versión extendida del algoritmo. 2. ANTECEDENTES Esta sección proporciona una visión general de la recuperación de información XML y discute trabajos relacionados, con énfasis en los problemas fundamentales mencionados en la introducción. Mucha investigación en el área de recuperación de XML lo ve desde una perspectiva de base de datos tradicional, preocupándose por problemas como la implementación de lenguajes de consulta estructurados [5] y el procesamiento de joins [1]. Aquí adoptamos una perspectiva de IR orientada al contenido, centrándonos en documentos XML que contienen principalmente datos en lenguaje natural y consultas que están principalmente expresadas en lenguaje natural. Suponemos que estas consultas indican únicamente la naturaleza del contenido deseado, no su estructura, y que el papel del sistema de RI es determinar qué elementos satisfacen mejor la necesidad de información subyacente. Otra investigación en IR ha considerado consultas mixtas, en las que se especifican tanto requisitos de contenido como estructurales [2,6,14,17,23]. 2.1 Estadísticas de Términos y Documentos En las aplicaciones tradicionales de recuperación de información, la unidad estándar de recuperación se considera que es el documento. Dependiendo de la aplicación, este término podría interpretarse para abarcar muchos objetos diferentes, incluyendo páginas web, artículos de periódico y mensajes de correo electrónico. Al aplicar técnicas estándar de clasificación de relevancia en el contexto de la RI XML, un enfoque natural es tratar cada elemento como un documento separado, con estadísticas de términos disponibles para cada uno [16]. Además, la mayoría de las técnicas de clasificación requieren estadísticas globales (por ejemplo, frecuencia inversa de documentos) calculadas sobre la colección en su totalidad. Si consideramos que esta colección incluye todos los elementos que podrían ser devueltos por el sistema, una ocurrencia específica de un término puede aparecer en varios documentos diferentes, quizás en elementos que representan un párrafo, una subsección, una sección y un artículo. No es apropiado calcular la frecuencia inversa de documentos bajo la suposición de que el término está contenido en todos estos elementos, ya que el número de elementos que contienen un término depende completamente del arreglo estructural de los documentos [13,23]. 2.2 Elementos Recuperables Si bien un sistema de recuperación de información XML podría potencialmente recuperar cualquier elemento, muchos elementos pueden no ser apropiados como resultados de recuperación. Esto suele ser el caso cuando los elementos contienen muy poco texto [10]. Por ejemplo, un título de sección que contenga solo los términos de búsqueda puede recibir una puntuación alta de un algoritmo de clasificación, pero por sí solo tendría un valor limitado para un usuario, quien podría preferir la sección real en sí misma. Otros elementos pueden reflejar la estructura física de los documentos, en lugar de la estructura lógica, lo cual puede tener poco o ningún significado para un usuario. Un sistema de recuperación de información XML efectivo debe devolver solo aquellos elementos que tengan suficiente contenido para ser utilizables y puedan funcionar como objetos independientes [15,18]. Componentes estándar de documentos como párrafos, secciones, subsecciones y resúmenes generalmente cumplen con estos requisitos; los títulos, frases en cursiva y campos de metadatos individuales a menudo no lo hacen. 2.3 Metodología de Evaluación En los últimos tres años, la Iniciativa para la Evaluación de la Recuperación de Información XML (INEX) ha fomentado la investigación en tecnología de recuperación de información XML [7,8]. INEX es una serie de conferencias experimentales, similar a TREC, en la que grupos de diferentes instituciones completan una o más tareas experimentales utilizando sus propias herramientas y sistemas, y comparan sus resultados en la propia conferencia. Más de 50 grupos participaron en INEX 2004, y la conferencia se ha convertido en tan influyente en el área de la RI XML como lo es TREC en otras áreas de la RI. La investigación descrita en este artículo, al igual que gran parte del trabajo relacionado que cita, depende de las colecciones de pruebas desarrolladas por INEX. La superposición causa problemas considerables en la evaluación de la recuperación, y los organizadores y participantes de INEX han luchado con estos problemas desde el principio. Aunque se ha logrado un progreso sustancial, estos problemas aún no están completamente resueltos. Kazai et al. [11] proporcionan una exposición detallada del problema de superposición en el contexto de la evaluación de recuperación de INEX y discuten tanto las métricas de evaluación actuales como las propuestas. Muchas de estas métricas se aplican para evaluar los experimentos reportados en este artículo, y se describen brevemente en la siguiente sección. 3. Las limitaciones de espacio impiden incluir más que un breve resumen de las tareas y metodología de evaluación de INEX 2004. Para obtener información detallada, se deben consultar las actas de la conferencia en sí [8]. 3.1 Tareas Para las principales tareas experimentales, a los participantes de INEX 2004 se les proporcionó una colección de 12,107 artículos tomados de las revistas y publicaciones de la IEEE Computer Societies entre 1995 y 2002. Cada documento está codificado en XML utilizando una DTD común, siendo el documento de las figuras 1 y 2 un ejemplo. En INEX 2004, las dos principales tareas experimentales fueron ambas tareas de recuperación ad hoc, investigando el rendimiento de sistemas que buscan en una colección estática utilizando temas previamente no vistos. Las dos tareas diferían en los tipos de temas que utilizaban. Para una tarea, la tarea de solo contenido o CO, los temas consisten en declaraciones cortas en lenguaje natural sin hacer referencia directa a la estructura de los documentos en la colección. Para esta tarea, se requiere que el sistema de IR seleccione los elementos a devolver. Para la otra tarea, la tarea de contenido y estructura o CAS, los temas están escritos en un lenguaje de consulta XML [22] y contienen referencias explícitas a la estructura del documento, que el sistema de IR debe intentar satisfacer. Dado que el trabajo descrito en este documento se enfoca en la tarea de solo contenido, donde el sistema de IR no recibe orientación sobre los elementos a devolver, la tarea de CAS se ignora en el resto de nuestra descripción. En 2004, los organizadores de la conferencia seleccionaron 40 nuevos temas de CO de las contribuciones proporcionadas por los participantes de la conferencia. Cada tema incluye una breve consulta de palabras clave, la cual es ejecutada sobre la colección por cada grupo participante en su propio sistema de IR XML. Cada grupo podría presentar hasta tres ejecuciones experimentales que consistieran en los primeros m = 1500 elementos para cada tema. 3.2 Evaluación de Relevancia Dado que la RI XML se preocupa por localizar aquellos elementos que proporcionan una cobertura completa de un tema mientras contienen la menor cantidad de información irrelevante posible, los juicios simples de relevante vs. no relevante no son suficientes. En cambio, los organizadores de INEX adoptaron dos dimensiones para la evaluación de relevancia: la dimensión de exhaustividad refleja el grado en que un elemento abarca el tema, y la dimensión de especificidad refleja el grado en que un elemento se enfoca en el tema. Se utiliza una escala de cuatro puntos en ambas dimensiones. Por lo tanto, un elemento (3,3) es altamente exhaustivo y altamente específico, un elemento (1,3) es marginalmente exhaustivo y altamente específico, y un elemento (0,0) no es relevante. Información adicional sobre la metodología de evaluación se puede encontrar en Piwowarski y Lalmas [19], quienes proporcionan una justificación detallada. 3.3 Métricas de Evaluación La métrica de evaluación principal utilizada en INEX 2004 es una versión de la precisión promedio media (MAP), ajustada por diversas funciones de cuantificación para dar diferentes pesos a diferentes elementos, dependiendo de sus valores de exhaustividad y especificidad. Una variante, la función de cuantización estricta asigna un peso de 1 a los elementos (3,3) y un peso de 0 a todos los demás. Esta variante es esencialmente el valor MAP familiar, con elementos (3,3) tratados como relevantes y todos los demás elementos tratados como no relevantes. Otras funciones de cuantización están diseñadas para otorgar crédito parcial a elementos que son aproximaciones cercanas, debido a la falta de exhaustividad y/o especificidad. Tanto la función de cuantificación generalizada como la función de generalización orientada a la especificidad (sog) acreditan elementos según su grado de relevancia [11], siendo que la segunda función pone mayor énfasis en la especificidad. Este documento informa los resultados de esta métrica utilizando las tres funciones de cuantización. Desde que esta métrica fue introducida por primera vez en INEX 2002, generalmente se le conoce como la métrica inex-2002. La métrica inex-2002 no penaliza la superposición. En particular, tanto las funciones de cuantificación generalizadas como las de sog otorgan crédito parcial a un casi acierto incluso cuando se informa un elemento (3,3) que se superpone a él en un rango más alto. Para abordar este problema, Kazai et al. [11] proponen una métrica de ganancia acumulada XML, que compara la ganancia acumulada [9] de una lista clasificada con un vector de ganancia ideal. Este vector de ganancia ideal se construye a partir de las valoraciones de relevancia al eliminar la superposición y retener solo el mejor elemento a lo largo de un camino dado. Por lo tanto, la métrica XCG recompensa las ejecuciones de recuperación que evitan la superposición. Aunque XCG no se utilizó oficialmente en INEX 2004, es probable que se utilice una versión de él en el futuro. En INEX 2003, se introdujo otra métrica para mejorar las limitaciones percibidas de la métrica inex-2002. Este métrico inex-2003 extiende las definiciones de precisión y exhaustividad para considerar tanto el tamaño de los componentes informados como la superposición entre ellos. Se crearon dos versiones, una que consideraba solo el tamaño de los componentes y otra que consideraba tanto el tamaño como la superposición. Si bien la métrica inex-2003 presenta anomalías no deseadas [11] y no se utilizó en 2004, se informan valores en la sección de evaluación para proporcionar un instrumento adicional para investigar la superposición. 4. MÉTODO DE RECUPERACIÓN DE BASELINE Esta sección proporciona una descripción general del método de recuperación de información XML de base actualmente utilizado en el sistema MultiText IR, desarrollado por el Grupo de Recuperación de Información de la Universidad de Waterloo [3]. Este método de recuperación resulta de la adaptación y ajuste de la medida Okapi BM25 [21] a la tarea de recuperación de información en XML. El sistema MultiText tuvo un desempeño respetable en INEX 2004, ubicándose entre los diez primeros en todas las funciones de cuantización, y ocupando el primer lugar cuando la función de cuantización enfatizaba la exhaustividad. Para admitir la recuperación de XML y otros tipos de documentos estructurados, el sistema proporciona consultas generalizadas de la forma: clasificar X por Y donde X es una subconsulta que especifica un conjunto de elementos de documentos a clasificar y Y es un vector de subconsultas que especifican términos de recuperación individuales. Para nuestras ejecuciones de INEX 2004, la subconsulta X especificó una lista de elementos recuperables como aquellos con nombres de etiquetas de la siguiente manera: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt. Esta lista incluye entradas bibliográficas (bb) y leyendas de figuras (fig) así como párrafos, secciones y subsecciones. Antes de INEX 2004, la colección de INEX y las evaluaciones de relevancia de INEX 2003 fueron analizadas manualmente para seleccionar estos nombres de etiquetas. Los nombres de las etiquetas fueron seleccionados en base a su frecuencia en la colección, el tamaño promedio de sus elementos asociados y el número relativo de juicios de relevancia positiva que recibieron. Automatizar este proceso de selección está planeado como trabajo futuro. Para INEX 2004, el vector término Y se derivó del tema dividiendo frases en palabras individuales, eliminando palabras vacías y términos negativos (aquellos que comienzan con -), y aplicando un stemmer. Por ejemplo, el campo de palabra clave del tema 166 +distancia de edición de árbol + XML -imagen se convirtió en la consulta de cuatro términos $árbol $edición $distancia $xml donde el operador $ dentro de una cadena entre comillas deriva el término que le sigue. Nuestra implementación de Okapi BM25 se deriva de la fórmula de Robertson et al. [21] al establecer los parámetros k2 = 0 y k3 = ∞. Dado un conjunto de términos Q, a un elemento x se le asigna la puntuación t∈Q w(1) qt (k1 + 1)xt K + xt (1) donde w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = número de documentos en el corpus Dt = número de documentos que contienen t qt = frecuencia con la que t ocurre en el tema xt = frecuencia con la que t ocurre en x K = k1((1 − b) + b · lx/lavg) lx = longitud de x lavg = longitud promedio del documento 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 PrecisiónPromedio(inex-2002) k1 estricto generalizado sog Figura 3: Impacto de k1 en la precisión promedio de inex-2002 con b = 0.75 (temas CO de INEX 2003). Antes de INEX 2004, los temas y juicios de INEX 2003 se utilizaron para ajustar los parámetros b y k1, y el impacto de este ajuste se discute más adelante en esta sección. Para los propósitos de calcular estadísticas a nivel de documento (D, Dt y lavg), un documento se define como un artículo. Estas estadísticas se utilizan para clasificar todos los tipos de elementos. Siguiendo la sugerencia de Kamps et al. [10], los resultados de recuperación se filtran para eliminar elementos muy cortos, aquellos con menos de 25 palabras de longitud. El uso de estadísticas de artículos para todos los tipos de elementos podría ser cuestionado. Este enfoque puede justificarse al considerar la colección como un conjunto de artículos que se pueden buscar utilizando técnicas estándar orientadas a documentos, donde solo se devuelven artículos. El puntaje calculado para un elemento es esencialmente el puntaje que recibiría si se agregara a la colección como un nuevo documento, ignorando los ajustes menores necesarios para las estadísticas a nivel de documento. Sin embargo, planeamos examinar este tema nuevamente en el futuro. En nuestra experiencia, el rendimiento de BM25 suele beneficiarse al ajustar los parámetros b y k1 a la colección, siempre que haya consultas de entrenamiento disponibles con este propósito. Antes de INEX 2004, entrenamos el sistema MultiText utilizando las consultas de INEX 2003. Como punto de partida, utilizamos los valores b = 0.75 y k1 = 1.2, que funcionan bien en colecciones TREC adhoc y se utilizan como valores predeterminados en nuestro sistema. Los resultados fueron sorprendentes. La Figura 3 muestra el resultado de variar k1 con b = 0.75 en los valores de MAP bajo tres funciones de cuantización. En nuestra experiencia, los valores óptimos para k1 suelen estar en el rango de 0.0 a 2.0. En este caso, se requieren valores grandes para un buen rendimiento. Entre k1 = 1.0 y k1 = 6.0, el MAP aumenta en más del 15% bajo la cuantización estricta. Se observan mejoras similares bajo las cuantizaciones generalizada y SOG. Por el contrario, nuestro valor predeterminado de b = 0.75 funciona bien bajo todas las funciones de cuantificación (figura 4). Después de ajustar una amplia gama de valores bajo varias funciones de cuantización, seleccionamos los valores de k = 10.0 y b = 0.80 para nuestros experimentos de INEX 2004, y estos valores se utilizan para los experimentos reportados en la sección 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 PrecisiónPromedioMedia (inex-2002) b estricto generalizado sog Figura 4: Impacto de b en la precisión promedio media de inex-2002 con k1 = 10 (temas CO de INEX 2003). 5. CONTROL DE SUPERPOSICIÓN Comenzando con una clasificación de elementos generada por el método de referencia descrito en la sección anterior, los elementos se vuelven a clasificar para controlar la superposición ajustando de forma iterativa las puntuaciones de aquellos elementos que contienen o están contenidos en elementos de clasificación más alta. A nivel conceptual, la reorganización procede de la siguiente manera: 1. Informe el elemento de rango más alto. Ajustar las puntuaciones de los elementos no reportados. 3. Repetir los pasos 1 y 2 hasta que se informen m elementos. Un enfoque para ajustar las puntuaciones de los elementos no informados en el paso 2 podría basarse en las puntuaciones Okapi BM25 de los elementos involucrados. Por ejemplo, supongamos que se informa un párrafo con una puntuación p en el paso 1. En el paso 2, la sección que contiene el párrafo podría tener su puntuación s reducida en una cantidad α · p para reflejar la contribución reducida que el párrafo debería hacer a la puntuación de las secciones. En un contexto relacionado, Robertson et al. [20] argumentan en contra de la combinación lineal de las puntuaciones de Okapi de esta manera. Ese trabajo considera el problema de asignar diferentes pesos a diferentes campos de documentos, como el título y el cuerpo asociados con páginas web. Un enfoque común para este problema puntúa el título y el cuerpo por separado y genera una puntuación final como una combinación lineal de ambos. Robertson et al. discuten las deficiencias teóricas en este enfoque y demuestran experimentalmente que puede perjudicar realmente la efectividad de la recuperación. En cambio, aplican los pesos a nivel de frecuencia de términos, donde la aparición de un término de consulta t en el título contribuye más al puntaje que una aparición en el cuerpo. En la ecuación 1, xt se convierte en α0 · yt + α1 · zt, donde yt es el número de veces que t aparece en el título y zt es el número de veces que t aparece en el cuerpo. Al traducir este enfoque a nuestro contexto, la contribución de los términos que aparecen en los elementos se reduce dinámicamente a medida que se informan. La siguiente sección presenta y analiza un algoritmo de reordenamiento simple que sigue esta estrategia. El algoritmo se evalúa experimentalmente en la sección 7. Una limitación del algoritmo es que la contribución de los términos que aparecen en los elementos informados se reduce por el mismo factor independientemente del número de elementos informados en los que aparezca. En la sección 8, el algoritmo se extiende para aplicar pesos crecientes, disminuyendo la puntuación, cuando un término aparece en más de un elemento informado. 6. ALGORITMO DE REORDENAMIENTO El algoritmo de reordenamiento opera sobre árboles XML, como el que aparece en la figura 2. La entrada al algoritmo es una lista de n elementos clasificados según sus puntuaciones iniciales de BM25. Durante la clasificación inicial, el árbol XML se reconstruye dinámicamente para incluir solo aquellos nodos con puntuaciones BM25 distintas de cero, por lo que n puede ser considerablemente menor que |N|. La salida del algoritmo es una lista de los primeros m elementos, clasificados según sus puntajes ajustados. Un elemento está representado por el nodo x ∈ N en su raíz. Asociados con este nodo se encuentran campos que almacenan la longitud del elemento, las frecuencias de términos y otra información requerida por el algoritmo de re-ranking, de la siguiente manera: x.f - vector de frecuencia de términos x.g - ajustes de frecuencia de términos x.l - longitud del elemento x.score - puntaje actual de Okapi BM25 x.reported - bandera booleana, inicialmente falsa x.children - conjunto de nodos hijos x.parent - nodo padre, si existe Estos campos se llenan durante el proceso de clasificación inicial y se actualizan a medida que avanza el algoritmo. El vector x.f contiene información de frecuencia de términos correspondiente a cada término en la consulta. El vector x.g es inicialmente cero y se actualiza por el algoritmo a medida que se informan elementos. El campo de puntuación contiene la puntuación BM25 actual para el elemento, la cual cambiará a medida que cambien los valores en x.g. El puntaje se calcula utilizando la ecuación 1, con el valor xt para cada término determinado por una combinación de los valores en x.f y x.g. Dado un término t ∈ Q, sea ft el componente de x.f correspondiente a t, y sea gt el componente de x.g correspondiente a t, entonces: xt = ft − α · gt (2) Para el procesamiento por el algoritmo de reordenamiento, los nodos se almacenan en colas de prioridad, ordenadas por puntaje decreciente. Cada <br>cola de prioridad</br> PQ admite tres operaciones: PQ.front() - devuelve el nodo con la puntuación más alta, PQ.add(x) - agrega el nodo x a la cola, PQ.remove(x) - elimina el nodo x de la cola. Cuando se implementan utilizando estructuras de datos estándar, la operación front requiere tiempo O(1), y las otras operaciones requieren tiempo O(log n), donde n es el tamaño de la cola. El núcleo del algoritmo de reordenamiento se presenta en la figura 5. El algoritmo toma como entrada la <br>cola de prioridad</br> S que contiene la clasificación inicial, y produce los primeros m nodos reordenados en la <br>cola de prioridad</br> F. Después de inicializar F como vacío en la línea 1, el algoritmo recorre m veces las líneas 215, transfiriendo al menos un nodo de S a F durante cada iteración. Al inicio de cada iteración, el nodo no reportado al frente de S tiene el mayor puntaje ajustado, y se elimina y se agrega a F. El algoritmo luego recorre el 1 F ← ∅ 2 para i ← 1 a m hacer 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 para cada y ∈ x.children hacer 9 Abajo (y) 10 fin hacer 11 12 si x no es un nodo raíz entonces 13 Arriba (x, x.parent) 14 fin si 15 fin hacer Figura 5: Algoritmo de Re-Ranking - Como entrada, el algoritmo toma una <br>cola de prioridad</br> S, que contiene nodos XML clasificados por sus puntajes iniciales, y devuelve sus resultados en la <br>cola de prioridad</br> F, clasificados por puntajes ajustados. 1 Arriba(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recalcular y.score 5 S.add(y) 6 si y no es un nodo raíz entonces 7 Arriba (x, y.parent) 8 fin si 9 10 Abajo(x) ≡ 11 si no x.reported entonces 12 S.remove(x) 14 x.g ← x.f 15 recalcular x.score 16 si x.score > 0 entonces 17 F.add(x) 18 fin si 19 x.reported ← true 20 para cada y ∈ x.children hacer 21 Abajo (y) 22 fin hacer 23 fin si Figura 6: Rutinas de recorrido de árbol llamadas por el algoritmo de re-ranking. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 PrecisiónPromedioMedia (inex-2002) GananciaAcumuladaXML(XCG) alfa MAP (estricto) MAP (generalizado) MAP (sog) XCG (sog2) Figura 7: Impacto de α en XCG y MAP inex-2002 (temas CO de INEX 2004; conjunto de evaluación I). nodos ancestros (líneas 8-10) y descendientes (líneas 12-14) ajustando los puntajes de estos nodos. Las rutinas de recorrido de árboles, Arriba y Abajo, se muestran en la figura 6. El procedimiento Up elimina cada nodo ancestro de S, ajusta sus valores de frecuencia de término, recalcula su puntuación y lo vuelve a agregar a S. El ajuste de los valores de frecuencia de término (línea 3) agrega a y.g solo las ocurrencias de términos no reportadas previamente en x. El recalculo de la puntuación en la línea 4 utiliza las ecuaciones 1 y 2. La rutina Down realiza una operación similar en cada descendiente. Sin embargo, dado que el contenido de cada descendiente está completamente contenido en un elemento informado, su puntuación final puede ser calculada, y se elimina de S y se agrega a F. Para determinar la complejidad temporal del algoritmo, primero observe que un nodo puede ser un argumento de Down como máximo una vez. Posteriormente, la bandera reportada de su padre es verdadera. Durante cada llamada a Down, un nodo puede ser movido de S a F, lo que requiere un tiempo O(log n). Por lo tanto, el tiempo total para todas las llamadas a Down es O(n log n), y podemos ignorar temporalmente las líneas 8-10 de la figura 5 al considerar la complejidad temporal del bucle sobre las líneas 2-15. Durante cada iteración de este bucle, se elimina un nodo y cada uno de sus ancestros de una <br>cola de prioridad</br> y luego se vuelven a agregar a la <br>cola de prioridad</br>. Dado que un nodo puede tener como máximo h ancestros, donde h es la altura máxima de cualquier árbol en la colección, cada una de las m iteraciones requiere un tiempo de O(h log n). La combinación de estas observaciones produce una complejidad temporal general de O((n + mh) log n). En la práctica, volver a clasificar un conjunto de resultados de INEX requiere menos de 200 ms en una PC de escritorio de tres años de antigüedad. EVALUACIÓN Ninguna de las métricas descritas en la sección 3.3 se ajusta adecuadamente a la perspectiva de superposición defendida por este documento. Sin embargo, cuando se toman en conjunto, proporcionan información sobre el comportamiento del algoritmo de reordenamiento. Los paquetes de evaluación de INEX (inex_eval e inex_eval_ng) se utilizaron para calcular los valores de las métricas inex-2002 e inex-2003. Los valores de las métricas XCG fueron calculados utilizando el software proporcionado por sus inventores [11]. La Figura 7 representa juntas las tres variantes de la métrica MAP inex-2002 junto con la métrica XCG. Los valores para estas métricas 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Precisión Media Promedio (inex-2003) alfa estricto, superposición no considerada estricto, superposición considerada generalizado, superposición no considerada generalizado, superposición considerada Figura 8: Impacto de α en MAP inex-2003 (temas CO de INEX 2004; conjunto de evaluación I). se trazan para valores de α entre 0.0 y 1.0. Recordando que la métrica XCG está diseñada para penalizar la superposición, mientras que la métrica inex-2002 ignora la superposición, el conflicto entre las métricas es evidente. Los valores de MAP en un extremo (α = 0.0) y el valor de XCG en el otro extremo (α = 1.0) representan un rendimiento de recuperación comparable a los mejores sistemas en INEX 2004 [8,12]. La Figura 8 muestra los valores de la métrica MAP inex-2003 para dos cuantificaciones, con y sin consideración de la superposición. Una vez más, el conflicto es evidente, con la influencia de α considerablemente disminuida cuando se considera la superposición. 8. ALGORITMO EXTENDIDO Una limitación del algoritmo de reordenamiento es que se utiliza un único peso α para ajustar las puntuaciones tanto de los ancestros como de los descendientes de los elementos informados. Una extensión obvia es usar diferentes pesos en estos dos casos. Además, se utiliza el mismo peso independientemente de cuántas veces un elemento esté contenido en un elemento informado. Por ejemplo, un párrafo puede formar parte de una sección reportada y luego formar parte de un artículo reportado. Dado que el usuario puede haber visto este párrafo dos veces, su puntuación debería ser reducida aún más aumentando el valor del peso. Motivado por estas observaciones, el algoritmo de reordenamiento puede ser extendido con una serie de pesos 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0, donde βj es el peso aplicado a un nodo que ha sido descendiente de un nodo reportado j veces. Ten en cuenta que un límite superior en M es h, la altura máxima de cualquier árbol XML en la colección. Sin embargo, en la práctica es probable que M sea relativamente pequeño (quizás 3 o 4). La Figura 9 presenta reemplazos para las rutinas de Subir y Bajar de la Figura 6, incorporando esta serie de pesas. Se requiere un campo adicional en cada nodo, de la siguiente manera: x.j - conteo descendente El valor de x.j se establece inicialmente en cero en todos los nodos y se incrementa cada vez que se llama a Down con x como su argumento. Al calcular la puntuación del nodo, el valor de x.j selecciona 1 Up(x, y) ≡ 2 si no y.reported entonces 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recalcular y.score 6 S.add(y) 8 si y no es un nodo raíz entonces 9 Up (x, y.padre) 10 fin si 11 fin si 12 13 Down(x) ≡ 14 si x.j < M entonces 15 x.j ← x.j + 1 16 si no x.reported entonces 17 S.remove(x) 18 recalcular x.score 19 S.add(x) 20 fin si 21 para cada y ∈ x.hijos hacer 22 Down (y) 23 fin hacer 24 fin si Figura 9: Rutinas extendidas de recorrido de árbol. el peso a aplicar al nodo ajustando el valor de xt en la ecuación 1, de la siguiente manera: xt = βx.j · (ft − α · gt) (3) donde ft y gt son los componentes de x.f y x.g correspondientes al término t. Se requieren algunos cambios adicionales para extender Up y Down. La rutina Up devuelve inmediatamente (línea 2) si su argumento ya ha sido reportado, ya que las frecuencias de términos ya han sido ajustadas en sus ancestros. El procedimiento Down no informa su argumento, sino que vuelve a calcular su puntuación y la agrega de nuevo a S. Un nodo no puede ser un argumento de Down más de M +1 veces, lo que a su vez implica una complejidad temporal total de O((nM + mh) log n). Dado que M ≤ h y m ≤ n, la complejidad temporal también es O(nh log n). DISCUSIÓN CONCLUSIVA Al generar resultados de recuperación en una colección de XML, se debe tolerar cierta superposición en los resultados, lo cual puede ser beneficioso. Por ejemplo, cuando un elemento altamente exhaustivo y bastante específico (3,2) contiene un elemento mucho más pequeño (2,3), ambos deben ser informados al usuario, y los algoritmos de recuperación y las métricas de evaluación deben respetar esta relación. El algoritmo presentado en este documento controla la superposición ponderando los términos que aparecen en los elementos informados para reflejar su menor importancia. Otros enfoques también pueden ayudar a controlar la superposición. Por ejemplo, cuando se presentan los resultados de recuperación de XML a los usuarios, puede ser deseable agrupar elementos relacionados estructuralmente juntos, ilustrando visualmente las relaciones entre ellos. Si bien este estilo de interfaz de usuario puede ayudar a un usuario a lidiar con la superposición, la estrategia presentada en este documento sigue siendo aplicable, al determinar los mejores elementos para incluir en cada grupo. En Waterloo, seguimos desarrollando y probando nuestras ideas para INEX 2005. En particular, estamos investigando métodos para aprender los pesos α y βj. También estamos reevaluando nuestro enfoque en las estadísticas de documentos y examinando ajustes apropiados al parámetro k1 a medida que cambian los pesos de los términos [20]. 10. AGRADECIMIENTOS Gracias a Gabriella Kazai y Arjen de Vries por proporcionar una versión temprana de su software para calcular la métrica XCG, y gracias a Phil Tilker y Stefan B¨uttcher por su ayuda con la evaluación experimental. En parte, la financiación para este proyecto fue proporcionada por IBM Canadá a través del Instituto Nacional de Investigación de Software. 11. REFERENCIAS [1] N. Bruno, N. Koudas y D. Srivastava. Uniones de ramas holísticas: Coincidencia óptima de patrones XML. En Actas de la Conferencia Internacional ACM SIGMOD 2002 sobre la Gestión de Datos, páginas 310-321, Madison, Wisconsin, junio de 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y. Masa y A. Soffer. Buscando documentos XML a través de fragmentos XML. En Actas de la 26ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 151-158, Toronto, Canadá, 2003. [3] C. L. A. Clarke y P. L. Tilker. Experimentos MultiText para INEX 2004. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai y M. Lalmas. Tolerancia a la irrelevancia: Una evaluación orientada al esfuerzo del usuario de sistemas de recuperación sin unidad de recuperación predefinida. En las Actas de la Conferencia RIAO 2004, páginas 463-473, Aviñón, Francia, abril de 2004. [5] D. DeHaan, D. Toman, M. P. Consens y M. T. ¨Ozsu. Una traducción exhaustiva de XQuery a SQL utilizando codificación dinámica de intervalos. En Actas de la Conferencia Internacional ACM SIGMOD 2003 sobre la Gestión de Datos, San Diego, junio de 2003. [6] N. Fuhr y K. Großjohann. XIRQL: Un lenguaje de consulta para la recuperación de información en documentos XML. En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 172-180, Nueva Orleans, septiembre de 2001. [7] N. Fuhr, M. Lalmas y S. Malik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Segundo Taller (INEX 2003), Dagstuhl, Alemania, diciembre de 2003. [8] N. Fuhr, M. Lalmas, S. Malik y Zoltán Szlávik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Tercer Taller (INEX 2004), Dagstuhl, Alemania, diciembre de 2004. Publicado como Avances en la Recuperación de Información XML, Notas de Conferencia en Ciencias de la Computación, volumen 3493, Springer, 2005. [9] K. J¨avelin y J. Kek¨al¨ainen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, y B. Sigurbjörnsson. Normalización de longitud en la recuperación de XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 80-87, Sheffield, Reino Unido, julio de 2004. [11] G. Kazai, M. Lalmas y A. P. de Vries. El problema de superposición en la evaluación de la recuperación de XML orientada al contenido. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 72-79, Sheffield, Reino Unido, julio de 2004. [12] G. Kazai, M. Lalmas y A. P. de Vries. Pruebas de confiabilidad para las métricas XCG e inex-2002. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola y T. Aalto. TRIX 2004 - Luchando con la superposición. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [14] S. Liu, Q. Zou y W. W. Chu. Indexación y clasificación configurables para la recuperación de información en XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 88-95, Sheffield, Reino Unido, julio de 2004. [15] Y. Masa y M. Mandelbrot. Recuperando los componentes XML más relevantes. En las Actas del Taller INEX 2003, Dagstuhl, Alemania, diciembre de 2003. [16] Y. Masa y M. Mandelbrot. Clasificación de componentes y refinamiento automático de consultas para la recuperación de XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [17] P. Ogilvie y J. Callan. Modelos de lenguaje jerárquicos para la recuperación de componentes XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [18] J. Pehcevski, J. A. Thom y A. Vercoustre. Recuperación híbrida de XML revisitada. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [19] B. Piwowarski y M. Lalmas. Proporcionando evaluaciones de relevancia consistentes y exhaustivas para la evaluación de recuperación de XML. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 361-370, Washington, DC, noviembre de 2004. [20] S. Robertson, H. Zaragoza y M. Taylor. Extensión simple de BM25 a múltiples campos ponderados. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 42-50, Washington, DC, noviembre de 2004. [21] S. E. Robertson, S. Walker y M. Beaulieu. Okapi en TREC-7: Búsqueda automática, filtrado, VLC y pista interactiva. En Actas de la Séptima Conferencia de Recuperación de Texto, Gaithersburg, MD, noviembre de 1998. [22] A. Trotman y B. Sigurbjörnsson. NEXI, ahora y después. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski y P. Gallinari. Un álgebra para consultas estructuradas en redes bayesianas. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "time complexity": {
            "translated_key": "complejidad temporal",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Controlling Overlap in Content-Oriented XML Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of XML documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
                "This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents.",
                "The test collection developed by the INitiative for the Evaluation of XML Retrieval (INEX) forms the basis for the evaluation.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "INTRODUCTION The representation of documents in XML provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an XML information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in XML.",
                "Figure 1 provides an example of a journal article encoded in XML, illustrating many of the important characteristics of XML documents.",
                "Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words.",
                "Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate.",
                "Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs.",
                "Each of these characteristics affects the design of an XML IR system, and each leads to fundamental problems that must be solved in an successful system.",
                "Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper.",
                "The article of figure 1 may be viewed as an XML tree, as illustrated in figure 2.",
                "Formally, a collection of XML documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes.",
                "For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example XML tree. of x.",
                "Since an element may be represented by the node at its root, the output of an XML IR system may be viewed as a ranked list of the top-m nodes.",
                "The direct application of a standard relevance ranking technique to a set of XML elements can produce a result in which the top ranks are dominated by many structurally related elements.",
                "A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article.",
                "For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms.",
                "If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content.",
                "One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it.",
                "Unfortunately, this approach destroys some of the possible benefits of XML IR.",
                "For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts.",
                "In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements.",
                "Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6].",
                "This paper presents a method for controlling overlap.",
                "Starting with an initial element ranking, a re-ranking algorithm adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
                "For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced.",
                "The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20].",
                "Extending that approach, the re-ranking algorithm varies weights dynamically as elements are processed.",
                "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a baseline retrieval method is presented in section 4.",
                "This baseline method represents a reasonable adaptation of standard IR technology to XML.",
                "Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point.",
                "A re-ranking algorithm implementing this strategy is presented in section 6 and evaluated in section 7.",
                "Section 8 discusses an extended version of the algorithm. 2.",
                "BACKGROUND This section provides a general overview of XML information retrieval and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
                "Much research in the area of XML retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1].",
                "Here, we take a content oriented IR perceptive, focusing on XML documents that primarily contain natural language data and queries that are primarily expressed in natural language.",
                "We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need.",
                "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional information retrieval applications the standard unit of retrieval is taken to be the document.",
                "Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages.",
                "When applying standard relevance ranking techniques in the context of XML IR, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
                "In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole.",
                "If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article.",
                "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an XML IR system might potentially retrieve any element, many elements may not be appropriate as retrieval results.",
                "This is usually the case when elements contain very little text [10].",
                "For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself.",
                "Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user.",
                "An effective XML IR system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18].",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (INEX) has encouraged research into XML information retrieval technology [7,8].",
                "INEX is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
                "Over 50 groups participated in INEX 2004, and the conference has become as influential in the area of XML IR as TREC is in other IR areas.",
                "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by INEX.",
                "Overlap causes considerable problems with retrieval evaluation, and the INEX organizers and participants have wrestled with these problems since the beginning.",
                "While substantial progress has been made, these problem are still not completely solved.",
                "Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of INEX retrieval evaluation and discuss both current and proposed evaluation metrics.",
                "Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3.",
                "INEX 2004 Space limitations prevent the inclusion of more than a brief summary of INEX 2004 tasks and evaluation methodology.",
                "For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, INEX 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002.",
                "Each document is encoded in XML using a common DTD, with the document of figures 1 and 2 providing one example.",
                "At INEX 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics.",
                "The two tasks differed in the types of topics they used.",
                "For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection.",
                "For this task, the IR system is required to select the elements to be returned.",
                "For the other task, the contentand-structure or CAS task, the topics are written in an XML query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy.",
                "Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description.",
                "In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants.",
                "Each topic includes a short keyword query, which is executed over the collection by each participating group on their own XML IR system.",
                "Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since XML IR is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient.",
                "Instead, the INEX organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic.",
                "A four-point scale is used in both dimensions.",
                "Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant.",
                "Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at INEX 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values.",
                "One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others.",
                "This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant.",
                "Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity.",
                "Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity.",
                "This paper reports results of this metric using all three of these quantization functions.",
                "Since this metric was first introduced at INEX 2002, it is generally referred as the inex-2002 metric.",
                "The inex-2002 metric does not penalize overlap.",
                "In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank.",
                "To address this problem, Kazai et al. [11] propose an XML cumulated gain metric, which compares the cumulated gain [9] of a ranked list to an ideal gain vector.",
                "This ideal gain vector is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path.",
                "Thus, the XCG metric rewards retrieval runs that avoid overlap.",
                "While XCG was not used officially at INEX 2004, a version of it is likely to be used in the future.",
                "At INEX 2003, yet another metric was introduced to ameliorate the perceived limitations of the inex-2002 metric.",
                "This inex-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them.",
                "Two versions were created, one that considered only component size and another that considered both size and overlap.",
                "While the inex-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4.",
                "BASELINE RETRIEVAL METHOD This section provides an overview of baseline XML information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3].",
                "This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the XML information retrieval task.",
                "The MultiText system performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
                "To support retrieval from XML and other structured document types, the system provides generalized queries of the form: rank X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms.",
                "For our INEX 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections.",
                "Prior to INEX 2004, the INEX collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names.",
                "Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received.",
                "Automating this selection process is planned as future work.",
                "For INEX 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.",
                "For example, keyword field of topic 166 +tree edit distance + XML -image became the four-term query $tree $edit $distance $xml where the $ operator within a quoted string stems the term that follows it.",
                "Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞.",
                "Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(inex-2002) k1 strict generalized sog Figure 3: Impact of k1 on inex-2002 mean average precision with b = 0.75 (INEX 2003 CO topics).",
                "Prior to INEX 2004, the INEX 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.",
                "For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article.",
                "These statistics are used for ranking all element types.",
                "Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length.",
                "The use of article statistics for all element types might be questioned.",
                "This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.",
                "The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics.",
                "Nonetheless, we plan to examine this issue again in the future.",
                "In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose.",
                "Prior to INEX 2004, we trained the MultiText system using the INEX 2003 queries.",
                "As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system.",
                "The results were surprising.",
                "Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions.",
                "In our experience, optimal values for k1 are typically in the range 0.0 to 2.0.",
                "In this case, large values are required for good performance.",
                "Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization.",
                "Similar improvements are seen under the generalized and sog quantizations.",
                "In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).",
                "After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our INEX 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5.",
                "CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements.",
                "At a conceptual level, re-ranking proceeds as follows: 1.",
                "Report the highest ranking element. 2.",
                "Adjust the scores of the unreported elements. 3.",
                "Repeat steps 1 and 2 until m elements are reported.",
                "One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements.",
                "For example, assume a paragraph with score p is reported in step 1.",
                "In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score.",
                "In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion.",
                "That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages.",
                "A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two.",
                "Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness.",
                "Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body.",
                "In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body.",
                "Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported.",
                "The next section presents and analysis a simple re-ranking algorithm that follows this strategy.",
                "The algorithm is evaluated experimentally in section 7.",
                "One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears.",
                "In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6.",
                "RE-RANKING ALGORITHM The re-ranking algorithm operates over XML trees, such as the one appearing in figure 2.",
                "Input to the algorithm is a list of n elements ranked according to their initial BM25 scores.",
                "During the initial ranking the XML tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |.",
                "Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores.",
                "An element is represented by the node x ∈ N at its root.",
                "Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - term frequency vector x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses.",
                "The vector x.f contains term frequency information corresponding to each term in the query.",
                "The vector x.g is initially zero and is updated by the algorithm as elements are reported.",
                "The score field contains the current BM25 score for the element, which will change as the values in x.g change.",
                "The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g.",
                "Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the re-ranking algorithm, nodes are stored in priority queues, ordered by decreasing score.",
                "Each priority queue PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
                "The core of the re-ranking algorithm is presented in figure 5.",
                "The algorithm takes as input the priority queue S containing the initial ranking, and produces the top-m reranked nodes in the priority queue F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
                "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a priority queue S, containing XML nodes ranked by their initial scores, and returns its results in priority queue F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
                "The tree traversal routines, Up and Down are given in figure 6.",
                "The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2.",
                "The Down routine performs a similar operation on each descendant.",
                "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the <br>time complexity</br> of the algorithm, first note that a node may be an argument to Down at most once.",
                "Thereafter, the reported flag of its parent is true.",
                "During each call to Down a node may be moved from S to F, requiring O(log n) time.",
                "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the <br>time complexity</br> of the loop over lines 2-15.",
                "During each iteration of this loop, a node and each of its ancestors are removed from a priority queue and then added back into a priority queue.",
                "Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time.",
                "Combining these observations produces an overall <br>time complexity</br> of O((n + mh) log n).",
                "In practice, re-ranking an INEX result set requires less than 200ms on a three-year-old desktop PC. 7.",
                "EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper.",
                "Nonetheless, when taken together they provide insight into the behaviour of the re-ranking algorithm.",
                "The INEX evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the inex-2002 and inex-2003 metrics.",
                "Values for the XCG metrics were computed using software supplied by its inventors [11].",
                "Figure 7 plots the three variants of inex-2002 MAP metric together with the XCG metric.",
                "Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on inex-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0.",
                "Recalling that the XCG metric is designed to penalize overlap, while the inex-2002 metric ignores overlap, the conflict between the metrics is obvious.",
                "The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at INEX 2004 [8,12].",
                "Figure 8 plots values of the inex-2003 MAP metric for two quantizations, with and without consideration of overlap.",
                "Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8.",
                "EXTENDED ALGORITHM One limitation of the re-ranking algorithm is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements.",
                "An obvious extension is to use different weights in these two cases.",
                "Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element.",
                "For example, a paragraph may form part of a reported section and then form part of a reported article.",
                "Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight.",
                "Motivated by these observations, the re-ranking algorithm may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times.",
                "Note that an upper bound on M is h, the maximum height of any XML tree in the collection.",
                "However, in practice M is likely to be relatively small (perhaps 3 or 4).",
                "Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights.",
                "One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument.",
                "When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down.",
                "The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors.",
                "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall <br>time complexity</br> of O((nM + mh) log n).",
                "Since M ≤ h and m ≤ n, the <br>time complexity</br> is also O(nh log n). 9.",
                "CONCLUDING DISCUSSION When generating retrieval results over an XML collection, some overlap in the results should be tolerated, and may be beneficial.",
                "For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship.",
                "The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance.",
                "Other approaches may also help to control overlap.",
                "For example, when XML retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them.",
                "While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster.",
                "At Waterloo, we continue to develop and test our ideas for INEX 2005.",
                "In particular, we are investigating methods for learning the α and βj weights.",
                "We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10.",
                "ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation.",
                "In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11.",
                "REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava.",
                "Holistic twig joins: Optimal XML pattern matching.",
                "In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
                "Mass, and A. Soffer.",
                "Searching XML documents via XML fragments.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker.",
                "MultiText experiments for INEX 2004.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas.",
                "Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit.",
                "In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu.",
                "A comprehensive XQuery to SQL translation using dynamic interval encoding.",
                "In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann.",
                "XIRQL: A query language for information retrieval in XML documents.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Second Workshop (INEX 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Third Workshop (INEX 2004), Dagstuhl, Germany, December 2004.",
                "Published as Advances in XML Information Retrieval, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson.",
                "Length normalization in XML retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "The overlap problem in content-oriented XML retrieval evaluation.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "Reliability tests for the XCG and inex-2002 metrics.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto.",
                "TRIX 2004 - Struggling with the overlap.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu.",
                "Configurable indexing and ranking for XML information retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 88-95, Sheffield, UK, July 2004. [15] Y.",
                "Mass and M. Mandelbrod.",
                "Retrieving the most relevant XML components.",
                "In INEX 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y.",
                "Mass and M. Mandelbrod.",
                "Component ranking and automatic query refinement for XML retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan.",
                "Hierarchical language models for XML component retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [18] J. Pehcevski, J.",
                "A. Thom, and A. Vercoustre.",
                "Hybrid XML retrieval re-visited.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas.",
                "Providing consistent and exhaustive relevance assessments for XML retrieval evaluation.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor.",
                "Simple BM25 extension to multiple weighted fields.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu.",
                "Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track.",
                "In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson.",
                "NEXI, now and next.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari.",
                "An algebra for structured queries in bayesian networks.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]."
            ],
            "original_annotated_samples": [
                "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the <br>time complexity</br> of the algorithm, first note that a node may be an argument to Down at most once.",
                "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the <br>time complexity</br> of the loop over lines 2-15.",
                "Combining these observations produces an overall <br>time complexity</br> of O((n + mh) log n).",
                "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall <br>time complexity</br> of O((nM + mh) log n).",
                "Since M ≤ h and m ≤ n, the <br>time complexity</br> is also O(nh log n). 9."
            ],
            "translated_annotated_samples": [
                "Sin embargo, dado que el contenido de cada descendiente está completamente contenido en un elemento informado, su puntuación final puede ser calculada, y se elimina de S y se agrega a F. Para determinar la <br>complejidad temporal</br> del algoritmo, primero observe que un nodo puede ser un argumento de Down como máximo una vez.",
                "Por lo tanto, el tiempo total para todas las llamadas a Down es O(n log n), y podemos ignorar temporalmente las líneas 8-10 de la figura 5 al considerar la <br>complejidad temporal</br> del bucle sobre las líneas 2-15.",
                "La combinación de estas observaciones produce una <br>complejidad temporal</br> general de O((n + mh) log n).",
                "El procedimiento Down no informa su argumento, sino que vuelve a calcular su puntuación y la agrega de nuevo a S. Un nodo no puede ser un argumento de Down más de M +1 veces, lo que a su vez implica una <br>complejidad temporal</br> total de O((nM + mh) log n).",
                "Dado que M ≤ h y m ≤ n, la <br>complejidad temporal</br> también es O(nh log n)."
            ],
            "translated_text": "Controlando la superposición en la recuperación XML orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca RESUMEN La aplicación directa de técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos XML a menudo produce un conjunto de resultados en el que los primeros puestos están dominados por un gran número de elementos tomados de un pequeño número de documentos altamente relevantes. Este documento presenta y evalúa un algoritmo que vuelve a clasificar este conjunto de resultados, con el objetivo de minimizar el contenido redundante mientras se preservan los beneficios de la recuperación de elementos, incluido el beneficio de identificar componentes centrados en el tema contenidos en documentos relevantes. La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la Recuperación XML (INEX) constituye la base para la evaluación. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Búsqueda y Recuperación de Información Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. La representación de documentos en XML brinda una oportunidad para que los sistemas de recuperación de información aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias. En respuesta a una consulta de usuario, un sistema de recuperación de información XML podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes. Esta facilidad es de particular beneficio cuando una colección contiene documentos muy largos, como manuales de productos o libros, donde el usuario debe ser dirigido a las partes más relevantes de estos documentos. La Figura 1 proporciona un ejemplo de un artículo de revista codificado en XML, ilustrando muchas de las características importantes de los documentos XML. Las etiquetas indican el inicio y el final de cada elemento, con elementos que varían ampliamente en tamaño, desde una palabra hasta miles de palabras. Algunos elementos, como párrafos y secciones, pueden presentarse razonablemente al usuario como resultados de búsqueda, pero otros no son apropiados. Los elementos se superponen entre sí: los artículos contienen secciones, las secciones contienen subsecciones y las subsecciones contienen párrafos. Cada una de estas características afecta el diseño de un sistema de IR XML, y cada una conlleva problemas fundamentales que deben resolverse en un sistema exitoso. La mayoría de estos problemas fundamentales pueden resolverse mediante la cuidadosa adaptación de técnicas estándar de IR, pero los problemas causados por la superposición son únicos en esta área [4,11] y constituyen el enfoque principal de este artículo. El artículo de la figura 1 puede ser visto como un árbol XML, como se ilustra en la figura 2. Formalmente, una colección de documentos XML puede ser representada como un bosque de árboles ordenados y enraizados, que consiste en un conjunto de nodos N y un conjunto de aristas dirigidas E que conectan estos nodos. Para cada nodo x ∈ N, la notación x.parent se refiere al nodo padre de x, si existe, y la notación x.children se refiere al conjunto de nodos hijos de x. Dado que un elemento puede estar representado por el nodo en su raíz, la salida de un sistema de IR XML puede ser vista como una lista clasificada de los m nodos principales. La aplicación directa de una técnica estándar de clasificación de relevancia a un conjunto de elementos XML puede producir un resultado en el que los primeros puestos están dominados por muchos elementos estructuralmente relacionados. Una sección con una puntuación alta probablemente contenga varios párrafos con una puntuación alta y esté contenida en un artículo con una puntuación alta. Por ejemplo, muchos de los elementos en la figura 2 recibirían una puntuación alta en los algoritmos de compresión de índices de texto de consulta de palabras clave. Si cada uno de estos elementos se presenta a un usuario como un resultado individual y separado, puede perder mucho tiempo revisando y rechazando contenido redundante. Una posible solución es informar solo el elemento de mayor puntuación a lo largo de un camino dado en el árbol, y eliminar de los rangos inferiores cualquier elemento que lo contenga o esté contenido en él. Desafortunadamente, este enfoque destruye algunos de los posibles beneficios de XML IR. Por ejemplo, un elemento externo puede contener una cantidad sustancial de información que no aparece en un elemento interno, pero el elemento interno puede estar fuertemente enfocado en el tema de la consulta y proporcionar un breve resumen de los conceptos clave. En tales casos, es razonable informar sobre elementos que contienen, o están contenidos en, elementos de rango superior. Incluso cuando un libro entero es relevante, un usuario aún puede desear que se destaquen los párrafos más importantes, para guiar su lectura y ahorrar tiempo [6]. Este documento presenta un método para controlar la superposición. A partir de una clasificación inicial de elementos, un algoritmo de re-clasificación ajusta las puntuaciones de los elementos de menor clasificación que contienen, o están contenidos dentro de, elementos de mayor clasificación, reflejando el hecho de que esta información puede ser ahora redundante. Por ejemplo, una vez que un elemento que representa una sección aparece en la clasificación, las puntuaciones de los párrafos que contiene y del artículo que lo contiene se reducen. La inspiración para esta estrategia proviene parcialmente del trabajo reciente sobre la recuperación de documentos estructurados, donde los términos que aparecen en diferentes campos, como el título y el cuerpo, reciben diferentes pesos [20]. Extendiendo ese enfoque, el algoritmo de reordenamiento varía los pesos dinámicamente a medida que se procesan los elementos. El resto del documento está organizado de la siguiente manera: Después de una discusión sobre el trabajo de antecedentes y la metodología de evaluación, se presenta un método de recuperación de referencia en la sección 4. Este método de referencia representa una adaptación razonable de la tecnología estándar de IR al XML. La sección 5 luego describe una estrategia para controlar la superposición, utilizando el método de línea base como punto de partida. Un algoritmo de reordenamiento que implementa esta estrategia se presenta en la sección 6 y se evalúa en la sección 7. La sección 8 discute una versión extendida del algoritmo. 2. ANTECEDENTES Esta sección proporciona una visión general de la recuperación de información XML y discute trabajos relacionados, con énfasis en los problemas fundamentales mencionados en la introducción. Mucha investigación en el área de recuperación de XML lo ve desde una perspectiva de base de datos tradicional, preocupándose por problemas como la implementación de lenguajes de consulta estructurados [5] y el procesamiento de joins [1]. Aquí adoptamos una perspectiva de IR orientada al contenido, centrándonos en documentos XML que contienen principalmente datos en lenguaje natural y consultas que están principalmente expresadas en lenguaje natural. Suponemos que estas consultas indican únicamente la naturaleza del contenido deseado, no su estructura, y que el papel del sistema de RI es determinar qué elementos satisfacen mejor la necesidad de información subyacente. Otra investigación en IR ha considerado consultas mixtas, en las que se especifican tanto requisitos de contenido como estructurales [2,6,14,17,23]. 2.1 Estadísticas de Términos y Documentos En las aplicaciones tradicionales de recuperación de información, la unidad estándar de recuperación se considera que es el documento. Dependiendo de la aplicación, este término podría interpretarse para abarcar muchos objetos diferentes, incluyendo páginas web, artículos de periódico y mensajes de correo electrónico. Al aplicar técnicas estándar de clasificación de relevancia en el contexto de la RI XML, un enfoque natural es tratar cada elemento como un documento separado, con estadísticas de términos disponibles para cada uno [16]. Además, la mayoría de las técnicas de clasificación requieren estadísticas globales (por ejemplo, frecuencia inversa de documentos) calculadas sobre la colección en su totalidad. Si consideramos que esta colección incluye todos los elementos que podrían ser devueltos por el sistema, una ocurrencia específica de un término puede aparecer en varios documentos diferentes, quizás en elementos que representan un párrafo, una subsección, una sección y un artículo. No es apropiado calcular la frecuencia inversa de documentos bajo la suposición de que el término está contenido en todos estos elementos, ya que el número de elementos que contienen un término depende completamente del arreglo estructural de los documentos [13,23]. 2.2 Elementos Recuperables Si bien un sistema de recuperación de información XML podría potencialmente recuperar cualquier elemento, muchos elementos pueden no ser apropiados como resultados de recuperación. Esto suele ser el caso cuando los elementos contienen muy poco texto [10]. Por ejemplo, un título de sección que contenga solo los términos de búsqueda puede recibir una puntuación alta de un algoritmo de clasificación, pero por sí solo tendría un valor limitado para un usuario, quien podría preferir la sección real en sí misma. Otros elementos pueden reflejar la estructura física de los documentos, en lugar de la estructura lógica, lo cual puede tener poco o ningún significado para un usuario. Un sistema de recuperación de información XML efectivo debe devolver solo aquellos elementos que tengan suficiente contenido para ser utilizables y puedan funcionar como objetos independientes [15,18]. Componentes estándar de documentos como párrafos, secciones, subsecciones y resúmenes generalmente cumplen con estos requisitos; los títulos, frases en cursiva y campos de metadatos individuales a menudo no lo hacen. 2.3 Metodología de Evaluación En los últimos tres años, la Iniciativa para la Evaluación de la Recuperación de Información XML (INEX) ha fomentado la investigación en tecnología de recuperación de información XML [7,8]. INEX es una serie de conferencias experimentales, similar a TREC, en la que grupos de diferentes instituciones completan una o más tareas experimentales utilizando sus propias herramientas y sistemas, y comparan sus resultados en la propia conferencia. Más de 50 grupos participaron en INEX 2004, y la conferencia se ha convertido en tan influyente en el área de la RI XML como lo es TREC en otras áreas de la RI. La investigación descrita en este artículo, al igual que gran parte del trabajo relacionado que cita, depende de las colecciones de pruebas desarrolladas por INEX. La superposición causa problemas considerables en la evaluación de la recuperación, y los organizadores y participantes de INEX han luchado con estos problemas desde el principio. Aunque se ha logrado un progreso sustancial, estos problemas aún no están completamente resueltos. Kazai et al. [11] proporcionan una exposición detallada del problema de superposición en el contexto de la evaluación de recuperación de INEX y discuten tanto las métricas de evaluación actuales como las propuestas. Muchas de estas métricas se aplican para evaluar los experimentos reportados en este artículo, y se describen brevemente en la siguiente sección. 3. Las limitaciones de espacio impiden incluir más que un breve resumen de las tareas y metodología de evaluación de INEX 2004. Para obtener información detallada, se deben consultar las actas de la conferencia en sí [8]. 3.1 Tareas Para las principales tareas experimentales, a los participantes de INEX 2004 se les proporcionó una colección de 12,107 artículos tomados de las revistas y publicaciones de la IEEE Computer Societies entre 1995 y 2002. Cada documento está codificado en XML utilizando una DTD común, siendo el documento de las figuras 1 y 2 un ejemplo. En INEX 2004, las dos principales tareas experimentales fueron ambas tareas de recuperación ad hoc, investigando el rendimiento de sistemas que buscan en una colección estática utilizando temas previamente no vistos. Las dos tareas diferían en los tipos de temas que utilizaban. Para una tarea, la tarea de solo contenido o CO, los temas consisten en declaraciones cortas en lenguaje natural sin hacer referencia directa a la estructura de los documentos en la colección. Para esta tarea, se requiere que el sistema de IR seleccione los elementos a devolver. Para la otra tarea, la tarea de contenido y estructura o CAS, los temas están escritos en un lenguaje de consulta XML [22] y contienen referencias explícitas a la estructura del documento, que el sistema de IR debe intentar satisfacer. Dado que el trabajo descrito en este documento se enfoca en la tarea de solo contenido, donde el sistema de IR no recibe orientación sobre los elementos a devolver, la tarea de CAS se ignora en el resto de nuestra descripción. En 2004, los organizadores de la conferencia seleccionaron 40 nuevos temas de CO de las contribuciones proporcionadas por los participantes de la conferencia. Cada tema incluye una breve consulta de palabras clave, la cual es ejecutada sobre la colección por cada grupo participante en su propio sistema de IR XML. Cada grupo podría presentar hasta tres ejecuciones experimentales que consistieran en los primeros m = 1500 elementos para cada tema. 3.2 Evaluación de Relevancia Dado que la RI XML se preocupa por localizar aquellos elementos que proporcionan una cobertura completa de un tema mientras contienen la menor cantidad de información irrelevante posible, los juicios simples de relevante vs. no relevante no son suficientes. En cambio, los organizadores de INEX adoptaron dos dimensiones para la evaluación de relevancia: la dimensión de exhaustividad refleja el grado en que un elemento abarca el tema, y la dimensión de especificidad refleja el grado en que un elemento se enfoca en el tema. Se utiliza una escala de cuatro puntos en ambas dimensiones. Por lo tanto, un elemento (3,3) es altamente exhaustivo y altamente específico, un elemento (1,3) es marginalmente exhaustivo y altamente específico, y un elemento (0,0) no es relevante. Información adicional sobre la metodología de evaluación se puede encontrar en Piwowarski y Lalmas [19], quienes proporcionan una justificación detallada. 3.3 Métricas de Evaluación La métrica de evaluación principal utilizada en INEX 2004 es una versión de la precisión promedio media (MAP), ajustada por diversas funciones de cuantificación para dar diferentes pesos a diferentes elementos, dependiendo de sus valores de exhaustividad y especificidad. Una variante, la función de cuantización estricta asigna un peso de 1 a los elementos (3,3) y un peso de 0 a todos los demás. Esta variante es esencialmente el valor MAP familiar, con elementos (3,3) tratados como relevantes y todos los demás elementos tratados como no relevantes. Otras funciones de cuantización están diseñadas para otorgar crédito parcial a elementos que son aproximaciones cercanas, debido a la falta de exhaustividad y/o especificidad. Tanto la función de cuantificación generalizada como la función de generalización orientada a la especificidad (sog) acreditan elementos según su grado de relevancia [11], siendo que la segunda función pone mayor énfasis en la especificidad. Este documento informa los resultados de esta métrica utilizando las tres funciones de cuantización. Desde que esta métrica fue introducida por primera vez en INEX 2002, generalmente se le conoce como la métrica inex-2002. La métrica inex-2002 no penaliza la superposición. En particular, tanto las funciones de cuantificación generalizadas como las de sog otorgan crédito parcial a un casi acierto incluso cuando se informa un elemento (3,3) que se superpone a él en un rango más alto. Para abordar este problema, Kazai et al. [11] proponen una métrica de ganancia acumulada XML, que compara la ganancia acumulada [9] de una lista clasificada con un vector de ganancia ideal. Este vector de ganancia ideal se construye a partir de las valoraciones de relevancia al eliminar la superposición y retener solo el mejor elemento a lo largo de un camino dado. Por lo tanto, la métrica XCG recompensa las ejecuciones de recuperación que evitan la superposición. Aunque XCG no se utilizó oficialmente en INEX 2004, es probable que se utilice una versión de él en el futuro. En INEX 2003, se introdujo otra métrica para mejorar las limitaciones percibidas de la métrica inex-2002. Este métrico inex-2003 extiende las definiciones de precisión y exhaustividad para considerar tanto el tamaño de los componentes informados como la superposición entre ellos. Se crearon dos versiones, una que consideraba solo el tamaño de los componentes y otra que consideraba tanto el tamaño como la superposición. Si bien la métrica inex-2003 presenta anomalías no deseadas [11] y no se utilizó en 2004, se informan valores en la sección de evaluación para proporcionar un instrumento adicional para investigar la superposición. 4. MÉTODO DE RECUPERACIÓN DE BASELINE Esta sección proporciona una descripción general del método de recuperación de información XML de base actualmente utilizado en el sistema MultiText IR, desarrollado por el Grupo de Recuperación de Información de la Universidad de Waterloo [3]. Este método de recuperación resulta de la adaptación y ajuste de la medida Okapi BM25 [21] a la tarea de recuperación de información en XML. El sistema MultiText tuvo un desempeño respetable en INEX 2004, ubicándose entre los diez primeros en todas las funciones de cuantización, y ocupando el primer lugar cuando la función de cuantización enfatizaba la exhaustividad. Para admitir la recuperación de XML y otros tipos de documentos estructurados, el sistema proporciona consultas generalizadas de la forma: clasificar X por Y donde X es una subconsulta que especifica un conjunto de elementos de documentos a clasificar y Y es un vector de subconsultas que especifican términos de recuperación individuales. Para nuestras ejecuciones de INEX 2004, la subconsulta X especificó una lista de elementos recuperables como aquellos con nombres de etiquetas de la siguiente manera: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt. Esta lista incluye entradas bibliográficas (bb) y leyendas de figuras (fig) así como párrafos, secciones y subsecciones. Antes de INEX 2004, la colección de INEX y las evaluaciones de relevancia de INEX 2003 fueron analizadas manualmente para seleccionar estos nombres de etiquetas. Los nombres de las etiquetas fueron seleccionados en base a su frecuencia en la colección, el tamaño promedio de sus elementos asociados y el número relativo de juicios de relevancia positiva que recibieron. Automatizar este proceso de selección está planeado como trabajo futuro. Para INEX 2004, el vector término Y se derivó del tema dividiendo frases en palabras individuales, eliminando palabras vacías y términos negativos (aquellos que comienzan con -), y aplicando un stemmer. Por ejemplo, el campo de palabra clave del tema 166 +distancia de edición de árbol + XML -imagen se convirtió en la consulta de cuatro términos $árbol $edición $distancia $xml donde el operador $ dentro de una cadena entre comillas deriva el término que le sigue. Nuestra implementación de Okapi BM25 se deriva de la fórmula de Robertson et al. [21] al establecer los parámetros k2 = 0 y k3 = ∞. Dado un conjunto de términos Q, a un elemento x se le asigna la puntuación t∈Q w(1) qt (k1 + 1)xt K + xt (1) donde w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = número de documentos en el corpus Dt = número de documentos que contienen t qt = frecuencia con la que t ocurre en el tema xt = frecuencia con la que t ocurre en x K = k1((1 − b) + b · lx/lavg) lx = longitud de x lavg = longitud promedio del documento 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 PrecisiónPromedio(inex-2002) k1 estricto generalizado sog Figura 3: Impacto de k1 en la precisión promedio de inex-2002 con b = 0.75 (temas CO de INEX 2003). Antes de INEX 2004, los temas y juicios de INEX 2003 se utilizaron para ajustar los parámetros b y k1, y el impacto de este ajuste se discute más adelante en esta sección. Para los propósitos de calcular estadísticas a nivel de documento (D, Dt y lavg), un documento se define como un artículo. Estas estadísticas se utilizan para clasificar todos los tipos de elementos. Siguiendo la sugerencia de Kamps et al. [10], los resultados de recuperación se filtran para eliminar elementos muy cortos, aquellos con menos de 25 palabras de longitud. El uso de estadísticas de artículos para todos los tipos de elementos podría ser cuestionado. Este enfoque puede justificarse al considerar la colección como un conjunto de artículos que se pueden buscar utilizando técnicas estándar orientadas a documentos, donde solo se devuelven artículos. El puntaje calculado para un elemento es esencialmente el puntaje que recibiría si se agregara a la colección como un nuevo documento, ignorando los ajustes menores necesarios para las estadísticas a nivel de documento. Sin embargo, planeamos examinar este tema nuevamente en el futuro. En nuestra experiencia, el rendimiento de BM25 suele beneficiarse al ajustar los parámetros b y k1 a la colección, siempre que haya consultas de entrenamiento disponibles con este propósito. Antes de INEX 2004, entrenamos el sistema MultiText utilizando las consultas de INEX 2003. Como punto de partida, utilizamos los valores b = 0.75 y k1 = 1.2, que funcionan bien en colecciones TREC adhoc y se utilizan como valores predeterminados en nuestro sistema. Los resultados fueron sorprendentes. La Figura 3 muestra el resultado de variar k1 con b = 0.75 en los valores de MAP bajo tres funciones de cuantización. En nuestra experiencia, los valores óptimos para k1 suelen estar en el rango de 0.0 a 2.0. En este caso, se requieren valores grandes para un buen rendimiento. Entre k1 = 1.0 y k1 = 6.0, el MAP aumenta en más del 15% bajo la cuantización estricta. Se observan mejoras similares bajo las cuantizaciones generalizada y SOG. Por el contrario, nuestro valor predeterminado de b = 0.75 funciona bien bajo todas las funciones de cuantificación (figura 4). Después de ajustar una amplia gama de valores bajo varias funciones de cuantización, seleccionamos los valores de k = 10.0 y b = 0.80 para nuestros experimentos de INEX 2004, y estos valores se utilizan para los experimentos reportados en la sección 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 PrecisiónPromedioMedia (inex-2002) b estricto generalizado sog Figura 4: Impacto de b en la precisión promedio media de inex-2002 con k1 = 10 (temas CO de INEX 2003). 5. CONTROL DE SUPERPOSICIÓN Comenzando con una clasificación de elementos generada por el método de referencia descrito en la sección anterior, los elementos se vuelven a clasificar para controlar la superposición ajustando de forma iterativa las puntuaciones de aquellos elementos que contienen o están contenidos en elementos de clasificación más alta. A nivel conceptual, la reorganización procede de la siguiente manera: 1. Informe el elemento de rango más alto. Ajustar las puntuaciones de los elementos no reportados. 3. Repetir los pasos 1 y 2 hasta que se informen m elementos. Un enfoque para ajustar las puntuaciones de los elementos no informados en el paso 2 podría basarse en las puntuaciones Okapi BM25 de los elementos involucrados. Por ejemplo, supongamos que se informa un párrafo con una puntuación p en el paso 1. En el paso 2, la sección que contiene el párrafo podría tener su puntuación s reducida en una cantidad α · p para reflejar la contribución reducida que el párrafo debería hacer a la puntuación de las secciones. En un contexto relacionado, Robertson et al. [20] argumentan en contra de la combinación lineal de las puntuaciones de Okapi de esta manera. Ese trabajo considera el problema de asignar diferentes pesos a diferentes campos de documentos, como el título y el cuerpo asociados con páginas web. Un enfoque común para este problema puntúa el título y el cuerpo por separado y genera una puntuación final como una combinación lineal de ambos. Robertson et al. discuten las deficiencias teóricas en este enfoque y demuestran experimentalmente que puede perjudicar realmente la efectividad de la recuperación. En cambio, aplican los pesos a nivel de frecuencia de términos, donde la aparición de un término de consulta t en el título contribuye más al puntaje que una aparición en el cuerpo. En la ecuación 1, xt se convierte en α0 · yt + α1 · zt, donde yt es el número de veces que t aparece en el título y zt es el número de veces que t aparece en el cuerpo. Al traducir este enfoque a nuestro contexto, la contribución de los términos que aparecen en los elementos se reduce dinámicamente a medida que se informan. La siguiente sección presenta y analiza un algoritmo de reordenamiento simple que sigue esta estrategia. El algoritmo se evalúa experimentalmente en la sección 7. Una limitación del algoritmo es que la contribución de los términos que aparecen en los elementos informados se reduce por el mismo factor independientemente del número de elementos informados en los que aparezca. En la sección 8, el algoritmo se extiende para aplicar pesos crecientes, disminuyendo la puntuación, cuando un término aparece en más de un elemento informado. 6. ALGORITMO DE REORDENAMIENTO El algoritmo de reordenamiento opera sobre árboles XML, como el que aparece en la figura 2. La entrada al algoritmo es una lista de n elementos clasificados según sus puntuaciones iniciales de BM25. Durante la clasificación inicial, el árbol XML se reconstruye dinámicamente para incluir solo aquellos nodos con puntuaciones BM25 distintas de cero, por lo que n puede ser considerablemente menor que |N|. La salida del algoritmo es una lista de los primeros m elementos, clasificados según sus puntajes ajustados. Un elemento está representado por el nodo x ∈ N en su raíz. Asociados con este nodo se encuentran campos que almacenan la longitud del elemento, las frecuencias de términos y otra información requerida por el algoritmo de re-ranking, de la siguiente manera: x.f - vector de frecuencia de términos x.g - ajustes de frecuencia de términos x.l - longitud del elemento x.score - puntaje actual de Okapi BM25 x.reported - bandera booleana, inicialmente falsa x.children - conjunto de nodos hijos x.parent - nodo padre, si existe Estos campos se llenan durante el proceso de clasificación inicial y se actualizan a medida que avanza el algoritmo. El vector x.f contiene información de frecuencia de términos correspondiente a cada término en la consulta. El vector x.g es inicialmente cero y se actualiza por el algoritmo a medida que se informan elementos. El campo de puntuación contiene la puntuación BM25 actual para el elemento, la cual cambiará a medida que cambien los valores en x.g. El puntaje se calcula utilizando la ecuación 1, con el valor xt para cada término determinado por una combinación de los valores en x.f y x.g. Dado un término t ∈ Q, sea ft el componente de x.f correspondiente a t, y sea gt el componente de x.g correspondiente a t, entonces: xt = ft − α · gt (2) Para el procesamiento por el algoritmo de reordenamiento, los nodos se almacenan en colas de prioridad, ordenadas por puntaje decreciente. Cada cola de prioridad PQ admite tres operaciones: PQ.front() - devuelve el nodo con la puntuación más alta, PQ.add(x) - agrega el nodo x a la cola, PQ.remove(x) - elimina el nodo x de la cola. Cuando se implementan utilizando estructuras de datos estándar, la operación front requiere tiempo O(1), y las otras operaciones requieren tiempo O(log n), donde n es el tamaño de la cola. El núcleo del algoritmo de reordenamiento se presenta en la figura 5. El algoritmo toma como entrada la cola de prioridad S que contiene la clasificación inicial, y produce los primeros m nodos reordenados en la cola de prioridad F. Después de inicializar F como vacío en la línea 1, el algoritmo recorre m veces las líneas 215, transfiriendo al menos un nodo de S a F durante cada iteración. Al inicio de cada iteración, el nodo no reportado al frente de S tiene el mayor puntaje ajustado, y se elimina y se agrega a F. El algoritmo luego recorre el 1 F ← ∅ 2 para i ← 1 a m hacer 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 para cada y ∈ x.children hacer 9 Abajo (y) 10 fin hacer 11 12 si x no es un nodo raíz entonces 13 Arriba (x, x.parent) 14 fin si 15 fin hacer Figura 5: Algoritmo de Re-Ranking - Como entrada, el algoritmo toma una cola de prioridad S, que contiene nodos XML clasificados por sus puntajes iniciales, y devuelve sus resultados en la cola de prioridad F, clasificados por puntajes ajustados. 1 Arriba(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recalcular y.score 5 S.add(y) 6 si y no es un nodo raíz entonces 7 Arriba (x, y.parent) 8 fin si 9 10 Abajo(x) ≡ 11 si no x.reported entonces 12 S.remove(x) 14 x.g ← x.f 15 recalcular x.score 16 si x.score > 0 entonces 17 F.add(x) 18 fin si 19 x.reported ← true 20 para cada y ∈ x.children hacer 21 Abajo (y) 22 fin hacer 23 fin si Figura 6: Rutinas de recorrido de árbol llamadas por el algoritmo de re-ranking. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 PrecisiónPromedioMedia (inex-2002) GananciaAcumuladaXML(XCG) alfa MAP (estricto) MAP (generalizado) MAP (sog) XCG (sog2) Figura 7: Impacto de α en XCG y MAP inex-2002 (temas CO de INEX 2004; conjunto de evaluación I). nodos ancestros (líneas 8-10) y descendientes (líneas 12-14) ajustando los puntajes de estos nodos. Las rutinas de recorrido de árboles, Arriba y Abajo, se muestran en la figura 6. El procedimiento Up elimina cada nodo ancestro de S, ajusta sus valores de frecuencia de término, recalcula su puntuación y lo vuelve a agregar a S. El ajuste de los valores de frecuencia de término (línea 3) agrega a y.g solo las ocurrencias de términos no reportadas previamente en x. El recalculo de la puntuación en la línea 4 utiliza las ecuaciones 1 y 2. La rutina Down realiza una operación similar en cada descendiente. Sin embargo, dado que el contenido de cada descendiente está completamente contenido en un elemento informado, su puntuación final puede ser calculada, y se elimina de S y se agrega a F. Para determinar la <br>complejidad temporal</br> del algoritmo, primero observe que un nodo puede ser un argumento de Down como máximo una vez. Posteriormente, la bandera reportada de su padre es verdadera. Durante cada llamada a Down, un nodo puede ser movido de S a F, lo que requiere un tiempo O(log n). Por lo tanto, el tiempo total para todas las llamadas a Down es O(n log n), y podemos ignorar temporalmente las líneas 8-10 de la figura 5 al considerar la <br>complejidad temporal</br> del bucle sobre las líneas 2-15. Durante cada iteración de este bucle, se elimina un nodo y cada uno de sus ancestros de una cola de prioridad y luego se vuelven a agregar a la cola de prioridad. Dado que un nodo puede tener como máximo h ancestros, donde h es la altura máxima de cualquier árbol en la colección, cada una de las m iteraciones requiere un tiempo de O(h log n). La combinación de estas observaciones produce una <br>complejidad temporal</br> general de O((n + mh) log n). En la práctica, volver a clasificar un conjunto de resultados de INEX requiere menos de 200 ms en una PC de escritorio de tres años de antigüedad. EVALUACIÓN Ninguna de las métricas descritas en la sección 3.3 se ajusta adecuadamente a la perspectiva de superposición defendida por este documento. Sin embargo, cuando se toman en conjunto, proporcionan información sobre el comportamiento del algoritmo de reordenamiento. Los paquetes de evaluación de INEX (inex_eval e inex_eval_ng) se utilizaron para calcular los valores de las métricas inex-2002 e inex-2003. Los valores de las métricas XCG fueron calculados utilizando el software proporcionado por sus inventores [11]. La Figura 7 representa juntas las tres variantes de la métrica MAP inex-2002 junto con la métrica XCG. Los valores para estas métricas 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Precisión Media Promedio (inex-2003) alfa estricto, superposición no considerada estricto, superposición considerada generalizado, superposición no considerada generalizado, superposición considerada Figura 8: Impacto de α en MAP inex-2003 (temas CO de INEX 2004; conjunto de evaluación I). se trazan para valores de α entre 0.0 y 1.0. Recordando que la métrica XCG está diseñada para penalizar la superposición, mientras que la métrica inex-2002 ignora la superposición, el conflicto entre las métricas es evidente. Los valores de MAP en un extremo (α = 0.0) y el valor de XCG en el otro extremo (α = 1.0) representan un rendimiento de recuperación comparable a los mejores sistemas en INEX 2004 [8,12]. La Figura 8 muestra los valores de la métrica MAP inex-2003 para dos cuantificaciones, con y sin consideración de la superposición. Una vez más, el conflicto es evidente, con la influencia de α considerablemente disminuida cuando se considera la superposición. 8. ALGORITMO EXTENDIDO Una limitación del algoritmo de reordenamiento es que se utiliza un único peso α para ajustar las puntuaciones tanto de los ancestros como de los descendientes de los elementos informados. Una extensión obvia es usar diferentes pesos en estos dos casos. Además, se utiliza el mismo peso independientemente de cuántas veces un elemento esté contenido en un elemento informado. Por ejemplo, un párrafo puede formar parte de una sección reportada y luego formar parte de un artículo reportado. Dado que el usuario puede haber visto este párrafo dos veces, su puntuación debería ser reducida aún más aumentando el valor del peso. Motivado por estas observaciones, el algoritmo de reordenamiento puede ser extendido con una serie de pesos 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0, donde βj es el peso aplicado a un nodo que ha sido descendiente de un nodo reportado j veces. Ten en cuenta que un límite superior en M es h, la altura máxima de cualquier árbol XML en la colección. Sin embargo, en la práctica es probable que M sea relativamente pequeño (quizás 3 o 4). La Figura 9 presenta reemplazos para las rutinas de Subir y Bajar de la Figura 6, incorporando esta serie de pesas. Se requiere un campo adicional en cada nodo, de la siguiente manera: x.j - conteo descendente El valor de x.j se establece inicialmente en cero en todos los nodos y se incrementa cada vez que se llama a Down con x como su argumento. Al calcular la puntuación del nodo, el valor de x.j selecciona 1 Up(x, y) ≡ 2 si no y.reported entonces 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recalcular y.score 6 S.add(y) 8 si y no es un nodo raíz entonces 9 Up (x, y.padre) 10 fin si 11 fin si 12 13 Down(x) ≡ 14 si x.j < M entonces 15 x.j ← x.j + 1 16 si no x.reported entonces 17 S.remove(x) 18 recalcular x.score 19 S.add(x) 20 fin si 21 para cada y ∈ x.hijos hacer 22 Down (y) 23 fin hacer 24 fin si Figura 9: Rutinas extendidas de recorrido de árbol. el peso a aplicar al nodo ajustando el valor de xt en la ecuación 1, de la siguiente manera: xt = βx.j · (ft − α · gt) (3) donde ft y gt son los componentes de x.f y x.g correspondientes al término t. Se requieren algunos cambios adicionales para extender Up y Down. La rutina Up devuelve inmediatamente (línea 2) si su argumento ya ha sido reportado, ya que las frecuencias de términos ya han sido ajustadas en sus ancestros. El procedimiento Down no informa su argumento, sino que vuelve a calcular su puntuación y la agrega de nuevo a S. Un nodo no puede ser un argumento de Down más de M +1 veces, lo que a su vez implica una <br>complejidad temporal</br> total de O((nM + mh) log n). Dado que M ≤ h y m ≤ n, la <br>complejidad temporal</br> también es O(nh log n). ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "extended tree traversal routine": {
            "translated_key": "rutina de recorrido extendido de árbol",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Controlling Overlap in Content-Oriented XML Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of XML documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
                "This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents.",
                "The test collection developed by the INitiative for the Evaluation of XML Retrieval (INEX) forms the basis for the evaluation.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "INTRODUCTION The representation of documents in XML provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an XML information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in XML.",
                "Figure 1 provides an example of a journal article encoded in XML, illustrating many of the important characteristics of XML documents.",
                "Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words.",
                "Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate.",
                "Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs.",
                "Each of these characteristics affects the design of an XML IR system, and each leads to fundamental problems that must be solved in an successful system.",
                "Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper.",
                "The article of figure 1 may be viewed as an XML tree, as illustrated in figure 2.",
                "Formally, a collection of XML documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes.",
                "For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example XML tree. of x.",
                "Since an element may be represented by the node at its root, the output of an XML IR system may be viewed as a ranked list of the top-m nodes.",
                "The direct application of a standard relevance ranking technique to a set of XML elements can produce a result in which the top ranks are dominated by many structurally related elements.",
                "A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article.",
                "For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms.",
                "If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content.",
                "One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it.",
                "Unfortunately, this approach destroys some of the possible benefits of XML IR.",
                "For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts.",
                "In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements.",
                "Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6].",
                "This paper presents a method for controlling overlap.",
                "Starting with an initial element ranking, a re-ranking algorithm adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
                "For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced.",
                "The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20].",
                "Extending that approach, the re-ranking algorithm varies weights dynamically as elements are processed.",
                "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a baseline retrieval method is presented in section 4.",
                "This baseline method represents a reasonable adaptation of standard IR technology to XML.",
                "Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point.",
                "A re-ranking algorithm implementing this strategy is presented in section 6 and evaluated in section 7.",
                "Section 8 discusses an extended version of the algorithm. 2.",
                "BACKGROUND This section provides a general overview of XML information retrieval and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
                "Much research in the area of XML retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1].",
                "Here, we take a content oriented IR perceptive, focusing on XML documents that primarily contain natural language data and queries that are primarily expressed in natural language.",
                "We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need.",
                "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional information retrieval applications the standard unit of retrieval is taken to be the document.",
                "Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages.",
                "When applying standard relevance ranking techniques in the context of XML IR, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
                "In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole.",
                "If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article.",
                "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an XML IR system might potentially retrieve any element, many elements may not be appropriate as retrieval results.",
                "This is usually the case when elements contain very little text [10].",
                "For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself.",
                "Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user.",
                "An effective XML IR system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18].",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (INEX) has encouraged research into XML information retrieval technology [7,8].",
                "INEX is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
                "Over 50 groups participated in INEX 2004, and the conference has become as influential in the area of XML IR as TREC is in other IR areas.",
                "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by INEX.",
                "Overlap causes considerable problems with retrieval evaluation, and the INEX organizers and participants have wrestled with these problems since the beginning.",
                "While substantial progress has been made, these problem are still not completely solved.",
                "Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of INEX retrieval evaluation and discuss both current and proposed evaluation metrics.",
                "Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3.",
                "INEX 2004 Space limitations prevent the inclusion of more than a brief summary of INEX 2004 tasks and evaluation methodology.",
                "For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, INEX 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002.",
                "Each document is encoded in XML using a common DTD, with the document of figures 1 and 2 providing one example.",
                "At INEX 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics.",
                "The two tasks differed in the types of topics they used.",
                "For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection.",
                "For this task, the IR system is required to select the elements to be returned.",
                "For the other task, the contentand-structure or CAS task, the topics are written in an XML query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy.",
                "Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description.",
                "In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants.",
                "Each topic includes a short keyword query, which is executed over the collection by each participating group on their own XML IR system.",
                "Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since XML IR is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient.",
                "Instead, the INEX organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic.",
                "A four-point scale is used in both dimensions.",
                "Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant.",
                "Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at INEX 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values.",
                "One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others.",
                "This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant.",
                "Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity.",
                "Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity.",
                "This paper reports results of this metric using all three of these quantization functions.",
                "Since this metric was first introduced at INEX 2002, it is generally referred as the inex-2002 metric.",
                "The inex-2002 metric does not penalize overlap.",
                "In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank.",
                "To address this problem, Kazai et al. [11] propose an XML cumulated gain metric, which compares the cumulated gain [9] of a ranked list to an ideal gain vector.",
                "This ideal gain vector is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path.",
                "Thus, the XCG metric rewards retrieval runs that avoid overlap.",
                "While XCG was not used officially at INEX 2004, a version of it is likely to be used in the future.",
                "At INEX 2003, yet another metric was introduced to ameliorate the perceived limitations of the inex-2002 metric.",
                "This inex-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them.",
                "Two versions were created, one that considered only component size and another that considered both size and overlap.",
                "While the inex-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4.",
                "BASELINE RETRIEVAL METHOD This section provides an overview of baseline XML information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3].",
                "This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the XML information retrieval task.",
                "The MultiText system performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
                "To support retrieval from XML and other structured document types, the system provides generalized queries of the form: rank X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms.",
                "For our INEX 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections.",
                "Prior to INEX 2004, the INEX collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names.",
                "Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received.",
                "Automating this selection process is planned as future work.",
                "For INEX 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.",
                "For example, keyword field of topic 166 +tree edit distance + XML -image became the four-term query $tree $edit $distance $xml where the $ operator within a quoted string stems the term that follows it.",
                "Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞.",
                "Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(inex-2002) k1 strict generalized sog Figure 3: Impact of k1 on inex-2002 mean average precision with b = 0.75 (INEX 2003 CO topics).",
                "Prior to INEX 2004, the INEX 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.",
                "For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article.",
                "These statistics are used for ranking all element types.",
                "Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length.",
                "The use of article statistics for all element types might be questioned.",
                "This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.",
                "The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics.",
                "Nonetheless, we plan to examine this issue again in the future.",
                "In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose.",
                "Prior to INEX 2004, we trained the MultiText system using the INEX 2003 queries.",
                "As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system.",
                "The results were surprising.",
                "Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions.",
                "In our experience, optimal values for k1 are typically in the range 0.0 to 2.0.",
                "In this case, large values are required for good performance.",
                "Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization.",
                "Similar improvements are seen under the generalized and sog quantizations.",
                "In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).",
                "After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our INEX 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5.",
                "CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements.",
                "At a conceptual level, re-ranking proceeds as follows: 1.",
                "Report the highest ranking element. 2.",
                "Adjust the scores of the unreported elements. 3.",
                "Repeat steps 1 and 2 until m elements are reported.",
                "One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements.",
                "For example, assume a paragraph with score p is reported in step 1.",
                "In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score.",
                "In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion.",
                "That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages.",
                "A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two.",
                "Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness.",
                "Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body.",
                "In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body.",
                "Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported.",
                "The next section presents and analysis a simple re-ranking algorithm that follows this strategy.",
                "The algorithm is evaluated experimentally in section 7.",
                "One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears.",
                "In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6.",
                "RE-RANKING ALGORITHM The re-ranking algorithm operates over XML trees, such as the one appearing in figure 2.",
                "Input to the algorithm is a list of n elements ranked according to their initial BM25 scores.",
                "During the initial ranking the XML tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |.",
                "Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores.",
                "An element is represented by the node x ∈ N at its root.",
                "Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - term frequency vector x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses.",
                "The vector x.f contains term frequency information corresponding to each term in the query.",
                "The vector x.g is initially zero and is updated by the algorithm as elements are reported.",
                "The score field contains the current BM25 score for the element, which will change as the values in x.g change.",
                "The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g.",
                "Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the re-ranking algorithm, nodes are stored in priority queues, ordered by decreasing score.",
                "Each priority queue PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
                "The core of the re-ranking algorithm is presented in figure 5.",
                "The algorithm takes as input the priority queue S containing the initial ranking, and produces the top-m reranked nodes in the priority queue F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
                "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a priority queue S, containing XML nodes ranked by their initial scores, and returns its results in priority queue F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
                "The tree traversal routines, Up and Down are given in figure 6.",
                "The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2.",
                "The Down routine performs a similar operation on each descendant.",
                "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the time complexity of the algorithm, first note that a node may be an argument to Down at most once.",
                "Thereafter, the reported flag of its parent is true.",
                "During each call to Down a node may be moved from S to F, requiring O(log n) time.",
                "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the time complexity of the loop over lines 2-15.",
                "During each iteration of this loop, a node and each of its ancestors are removed from a priority queue and then added back into a priority queue.",
                "Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time.",
                "Combining these observations produces an overall time complexity of O((n + mh) log n).",
                "In practice, re-ranking an INEX result set requires less than 200ms on a three-year-old desktop PC. 7.",
                "EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper.",
                "Nonetheless, when taken together they provide insight into the behaviour of the re-ranking algorithm.",
                "The INEX evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the inex-2002 and inex-2003 metrics.",
                "Values for the XCG metrics were computed using software supplied by its inventors [11].",
                "Figure 7 plots the three variants of inex-2002 MAP metric together with the XCG metric.",
                "Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on inex-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0.",
                "Recalling that the XCG metric is designed to penalize overlap, while the inex-2002 metric ignores overlap, the conflict between the metrics is obvious.",
                "The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at INEX 2004 [8,12].",
                "Figure 8 plots values of the inex-2003 MAP metric for two quantizations, with and without consideration of overlap.",
                "Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8.",
                "EXTENDED ALGORITHM One limitation of the re-ranking algorithm is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements.",
                "An obvious extension is to use different weights in these two cases.",
                "Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element.",
                "For example, a paragraph may form part of a reported section and then form part of a reported article.",
                "Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight.",
                "Motivated by these observations, the re-ranking algorithm may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times.",
                "Note that an upper bound on M is h, the maximum height of any XML tree in the collection.",
                "However, in practice M is likely to be relatively small (perhaps 3 or 4).",
                "Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights.",
                "One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument.",
                "When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down.",
                "The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors.",
                "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall time complexity of O((nM + mh) log n).",
                "Since M ≤ h and m ≤ n, the time complexity is also O(nh log n). 9.",
                "CONCLUDING DISCUSSION When generating retrieval results over an XML collection, some overlap in the results should be tolerated, and may be beneficial.",
                "For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship.",
                "The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance.",
                "Other approaches may also help to control overlap.",
                "For example, when XML retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them.",
                "While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster.",
                "At Waterloo, we continue to develop and test our ideas for INEX 2005.",
                "In particular, we are investigating methods for learning the α and βj weights.",
                "We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10.",
                "ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation.",
                "In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11.",
                "REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava.",
                "Holistic twig joins: Optimal XML pattern matching.",
                "In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
                "Mass, and A. Soffer.",
                "Searching XML documents via XML fragments.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker.",
                "MultiText experiments for INEX 2004.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas.",
                "Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit.",
                "In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu.",
                "A comprehensive XQuery to SQL translation using dynamic interval encoding.",
                "In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann.",
                "XIRQL: A query language for information retrieval in XML documents.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Second Workshop (INEX 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Third Workshop (INEX 2004), Dagstuhl, Germany, December 2004.",
                "Published as Advances in XML Information Retrieval, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson.",
                "Length normalization in XML retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "The overlap problem in content-oriented XML retrieval evaluation.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "Reliability tests for the XCG and inex-2002 metrics.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto.",
                "TRIX 2004 - Struggling with the overlap.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu.",
                "Configurable indexing and ranking for XML information retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 88-95, Sheffield, UK, July 2004. [15] Y.",
                "Mass and M. Mandelbrod.",
                "Retrieving the most relevant XML components.",
                "In INEX 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y.",
                "Mass and M. Mandelbrod.",
                "Component ranking and automatic query refinement for XML retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan.",
                "Hierarchical language models for XML component retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [18] J. Pehcevski, J.",
                "A. Thom, and A. Vercoustre.",
                "Hybrid XML retrieval re-visited.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas.",
                "Providing consistent and exhaustive relevance assessments for XML retrieval evaluation.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor.",
                "Simple BM25 extension to multiple weighted fields.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu.",
                "Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track.",
                "In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson.",
                "NEXI, now and next.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari.",
                "An algebra for structured queries in bayesian networks.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "xml": {
            "translated_key": "xml",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Controlling Overlap in Content-Oriented <br>xml</br> Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of <br>xml</br> documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
                "This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents.",
                "The test collection developed by the INitiative for the Evaluation of <br>xml</br> Retrieval (INEX) forms the basis for the evaluation.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "INTRODUCTION The representation of documents in <br>xml</br> provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an <br>xml</br> information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in <br>xml</br>.",
                "Figure 1 provides an example of a journal article encoded in <br>xml</br>, illustrating many of the important characteristics of <br>xml</br> documents.",
                "Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words.",
                "Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate.",
                "Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs.",
                "Each of these characteristics affects the design of an <br>xml</br> IR system, and each leads to fundamental problems that must be solved in an successful system.",
                "Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper.",
                "The article of figure 1 may be viewed as an <br>xml</br> tree, as illustrated in figure 2.",
                "Formally, a collection of <br>xml</br> documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes.",
                "For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example <br>xml</br> tree. of x.",
                "Since an element may be represented by the node at its root, the output of an <br>xml</br> IR system may be viewed as a ranked list of the top-m nodes.",
                "The direct application of a standard relevance ranking technique to a set of <br>xml</br> elements can produce a result in which the top ranks are dominated by many structurally related elements.",
                "A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article.",
                "For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms.",
                "If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content.",
                "One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it.",
                "Unfortunately, this approach destroys some of the possible benefits of <br>xml</br> IR.",
                "For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts.",
                "In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements.",
                "Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6].",
                "This paper presents a method for controlling overlap.",
                "Starting with an initial element ranking, a re-ranking algorithm adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
                "For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced.",
                "The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20].",
                "Extending that approach, the re-ranking algorithm varies weights dynamically as elements are processed.",
                "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a baseline retrieval method is presented in section 4.",
                "This baseline method represents a reasonable adaptation of standard IR technology to <br>xml</br>.",
                "Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point.",
                "A re-ranking algorithm implementing this strategy is presented in section 6 and evaluated in section 7.",
                "Section 8 discusses an extended version of the algorithm. 2.",
                "BACKGROUND This section provides a general overview of <br>xml</br> information retrieval and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
                "Much research in the area of <br>xml</br> retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1].",
                "Here, we take a content oriented IR perceptive, focusing on <br>xml</br> documents that primarily contain natural language data and queries that are primarily expressed in natural language.",
                "We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need.",
                "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional information retrieval applications the standard unit of retrieval is taken to be the document.",
                "Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages.",
                "When applying standard relevance ranking techniques in the context of <br>xml</br> IR, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
                "In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole.",
                "If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article.",
                "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an <br>xml</br> IR system might potentially retrieve any element, many elements may not be appropriate as retrieval results.",
                "This is usually the case when elements contain very little text [10].",
                "For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself.",
                "Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user.",
                "An effective <br>xml</br> IR system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18].",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of <br>xml</br> Retrieval (INEX) has encouraged research into <br>xml</br> information retrieval technology [7,8].",
                "INEX is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
                "Over 50 groups participated in INEX 2004, and the conference has become as influential in the area of <br>xml</br> IR as TREC is in other IR areas.",
                "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by INEX.",
                "Overlap causes considerable problems with retrieval evaluation, and the INEX organizers and participants have wrestled with these problems since the beginning.",
                "While substantial progress has been made, these problem are still not completely solved.",
                "Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of INEX retrieval evaluation and discuss both current and proposed evaluation metrics.",
                "Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3.",
                "INEX 2004 Space limitations prevent the inclusion of more than a brief summary of INEX 2004 tasks and evaluation methodology.",
                "For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, INEX 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002.",
                "Each document is encoded in <br>xml</br> using a common DTD, with the document of figures 1 and 2 providing one example.",
                "At INEX 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics.",
                "The two tasks differed in the types of topics they used.",
                "For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection.",
                "For this task, the IR system is required to select the elements to be returned.",
                "For the other task, the contentand-structure or CAS task, the topics are written in an <br>xml</br> query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy.",
                "Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description.",
                "In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants.",
                "Each topic includes a short keyword query, which is executed over the collection by each participating group on their own <br>xml</br> IR system.",
                "Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since <br>xml</br> IR is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient.",
                "Instead, the INEX organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic.",
                "A four-point scale is used in both dimensions.",
                "Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant.",
                "Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at INEX 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values.",
                "One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others.",
                "This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant.",
                "Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity.",
                "Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity.",
                "This paper reports results of this metric using all three of these quantization functions.",
                "Since this metric was first introduced at INEX 2002, it is generally referred as the inex-2002 metric.",
                "The inex-2002 metric does not penalize overlap.",
                "In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher rank.",
                "To address this problem, Kazai et al. [11] propose an <br>xml</br> cumulated gain metric, which compares the cumulated gain [9] of a ranked list to an ideal gain vector.",
                "This ideal gain vector is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path.",
                "Thus, the XCG metric rewards retrieval runs that avoid overlap.",
                "While XCG was not used officially at INEX 2004, a version of it is likely to be used in the future.",
                "At INEX 2003, yet another metric was introduced to ameliorate the perceived limitations of the inex-2002 metric.",
                "This inex-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them.",
                "Two versions were created, one that considered only component size and another that considered both size and overlap.",
                "While the inex-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4.",
                "BASELINE RETRIEVAL METHOD This section provides an overview of baseline <br>xml</br> information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3].",
                "This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the <br>xml</br> information retrieval task.",
                "The MultiText system performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
                "To support retrieval from <br>xml</br> and other structured document types, the system provides generalized queries of the form: rank X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms.",
                "For our INEX 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections.",
                "Prior to INEX 2004, the INEX collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names.",
                "Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received.",
                "Automating this selection process is planned as future work.",
                "For INEX 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.",
                "For example, keyword field of topic 166 +tree edit distance + <br>xml</br> -image became the four-term query $tree $edit $distance $<br>xml</br> where the $ operator within a quoted string stems the term that follows it.",
                "Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞.",
                "Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(inex-2002) k1 strict generalized sog Figure 3: Impact of k1 on inex-2002 mean average precision with b = 0.75 (INEX 2003 CO topics).",
                "Prior to INEX 2004, the INEX 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.",
                "For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article.",
                "These statistics are used for ranking all element types.",
                "Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length.",
                "The use of article statistics for all element types might be questioned.",
                "This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.",
                "The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics.",
                "Nonetheless, we plan to examine this issue again in the future.",
                "In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose.",
                "Prior to INEX 2004, we trained the MultiText system using the INEX 2003 queries.",
                "As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system.",
                "The results were surprising.",
                "Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions.",
                "In our experience, optimal values for k1 are typically in the range 0.0 to 2.0.",
                "In this case, large values are required for good performance.",
                "Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization.",
                "Similar improvements are seen under the generalized and sog quantizations.",
                "In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).",
                "After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our INEX 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5.",
                "CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements.",
                "At a conceptual level, re-ranking proceeds as follows: 1.",
                "Report the highest ranking element. 2.",
                "Adjust the scores of the unreported elements. 3.",
                "Repeat steps 1 and 2 until m elements are reported.",
                "One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements.",
                "For example, assume a paragraph with score p is reported in step 1.",
                "In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score.",
                "In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion.",
                "That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages.",
                "A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two.",
                "Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness.",
                "Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body.",
                "In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body.",
                "Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported.",
                "The next section presents and analysis a simple re-ranking algorithm that follows this strategy.",
                "The algorithm is evaluated experimentally in section 7.",
                "One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears.",
                "In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6.",
                "RE-RANKING ALGORITHM The re-ranking algorithm operates over <br>xml</br> trees, such as the one appearing in figure 2.",
                "Input to the algorithm is a list of n elements ranked according to their initial BM25 scores.",
                "During the initial ranking the <br>xml</br> tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |.",
                "Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores.",
                "An element is represented by the node x ∈ N at its root.",
                "Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - term frequency vector x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses.",
                "The vector x.f contains term frequency information corresponding to each term in the query.",
                "The vector x.g is initially zero and is updated by the algorithm as elements are reported.",
                "The score field contains the current BM25 score for the element, which will change as the values in x.g change.",
                "The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g.",
                "Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the re-ranking algorithm, nodes are stored in priority queues, ordered by decreasing score.",
                "Each priority queue PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
                "The core of the re-ranking algorithm is presented in figure 5.",
                "The algorithm takes as input the priority queue S containing the initial ranking, and produces the top-m reranked nodes in the priority queue F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
                "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a priority queue S, containing <br>xml</br> nodes ranked by their initial scores, and returns its results in priority queue F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
                "The tree traversal routines, Up and Down are given in figure 6.",
                "The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2.",
                "The Down routine performs a similar operation on each descendant.",
                "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the time complexity of the algorithm, first note that a node may be an argument to Down at most once.",
                "Thereafter, the reported flag of its parent is true.",
                "During each call to Down a node may be moved from S to F, requiring O(log n) time.",
                "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the time complexity of the loop over lines 2-15.",
                "During each iteration of this loop, a node and each of its ancestors are removed from a priority queue and then added back into a priority queue.",
                "Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time.",
                "Combining these observations produces an overall time complexity of O((n + mh) log n).",
                "In practice, re-ranking an INEX result set requires less than 200ms on a three-year-old desktop PC. 7.",
                "EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper.",
                "Nonetheless, when taken together they provide insight into the behaviour of the re-ranking algorithm.",
                "The INEX evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the inex-2002 and inex-2003 metrics.",
                "Values for the XCG metrics were computed using software supplied by its inventors [11].",
                "Figure 7 plots the three variants of inex-2002 MAP metric together with the XCG metric.",
                "Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on inex-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0.",
                "Recalling that the XCG metric is designed to penalize overlap, while the inex-2002 metric ignores overlap, the conflict between the metrics is obvious.",
                "The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at INEX 2004 [8,12].",
                "Figure 8 plots values of the inex-2003 MAP metric for two quantizations, with and without consideration of overlap.",
                "Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8.",
                "EXTENDED ALGORITHM One limitation of the re-ranking algorithm is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements.",
                "An obvious extension is to use different weights in these two cases.",
                "Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element.",
                "For example, a paragraph may form part of a reported section and then form part of a reported article.",
                "Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight.",
                "Motivated by these observations, the re-ranking algorithm may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times.",
                "Note that an upper bound on M is h, the maximum height of any <br>xml</br> tree in the collection.",
                "However, in practice M is likely to be relatively small (perhaps 3 or 4).",
                "Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights.",
                "One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument.",
                "When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down.",
                "The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors.",
                "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall time complexity of O((nM + mh) log n).",
                "Since M ≤ h and m ≤ n, the time complexity is also O(nh log n). 9.",
                "CONCLUDING DISCUSSION When generating retrieval results over an <br>xml</br> collection, some overlap in the results should be tolerated, and may be beneficial.",
                "For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship.",
                "The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance.",
                "Other approaches may also help to control overlap.",
                "For example, when <br>xml</br> retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them.",
                "While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster.",
                "At Waterloo, we continue to develop and test our ideas for INEX 2005.",
                "In particular, we are investigating methods for learning the α and βj weights.",
                "We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10.",
                "ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation.",
                "In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11.",
                "REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava.",
                "Holistic twig joins: Optimal <br>xml</br> pattern matching.",
                "In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
                "Mass, and A. Soffer.",
                "Searching <br>xml</br> documents via <br>xml</br> fragments.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker.",
                "MultiText experiments for INEX 2004.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas.",
                "Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit.",
                "In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu.",
                "A comprehensive XQuery to SQL translation using dynamic interval encoding.",
                "In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann.",
                "XIRQL: A query language for information retrieval in <br>xml</br> documents.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors.",
                "Initiative for the Evaluation of <br>xml</br> Retrieval.",
                "Proceedings of the Second Workshop (INEX 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors.",
                "Initiative for the Evaluation of <br>xml</br> Retrieval.",
                "Proceedings of the Third Workshop (INEX 2004), Dagstuhl, Germany, December 2004.",
                "Published as Advances in <br>xml</br> Information Retrieval, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson.",
                "Length normalization in <br>xml</br> retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "The overlap problem in content-oriented <br>xml</br> retrieval evaluation.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "Reliability tests for the XCG and inex-2002 metrics.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto.",
                "TRIX 2004 - Struggling with the overlap.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu.",
                "Configurable indexing and ranking for <br>xml</br> information retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 88-95, Sheffield, UK, July 2004. [15] Y.",
                "Mass and M. Mandelbrod.",
                "Retrieving the most relevant <br>xml</br> components.",
                "In INEX 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y.",
                "Mass and M. Mandelbrod.",
                "Component ranking and automatic query refinement for <br>xml</br> retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan.",
                "Hierarchical language models for <br>xml</br> component retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [18] J. Pehcevski, J.",
                "A. Thom, and A. Vercoustre.",
                "Hybrid <br>xml</br> retrieval re-visited.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas.",
                "Providing consistent and exhaustive relevance assessments for <br>xml</br> retrieval evaluation.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor.",
                "Simple BM25 extension to multiple weighted fields.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu.",
                "Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track.",
                "In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson.",
                "NEXI, now and next.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari.",
                "An algebra for structured queries in bayesian networks.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]."
            ],
            "original_annotated_samples": [
                "Controlling Overlap in Content-Oriented <br>xml</br> Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of <br>xml</br> documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
                "The test collection developed by the INitiative for the Evaluation of <br>xml</br> Retrieval (INEX) forms the basis for the evaluation.",
                "INTRODUCTION The representation of documents in <br>xml</br> provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an <br>xml</br> information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in <br>xml</br>."
            ],
            "translated_annotated_samples": [
                "Controlando la superposición en la recuperación <br>XML</br> orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca RESUMEN La aplicación directa de técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos <br>XML</br> a menudo produce un conjunto de resultados en el que los primeros puestos están dominados por un gran número de elementos tomados de un pequeño número de documentos altamente relevantes.",
                "La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la <br>Recuperación XML</br> (INEX) constituye la base para la evaluación.",
                "La representación de documentos en <br>XML</br> brinda una oportunidad para que los sistemas de recuperación de información aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias.",
                "En respuesta a una consulta de usuario, un sistema de recuperación de información <br>XML</br> podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes.",
                "Esta facilidad es de particular beneficio cuando una colección contiene documentos muy largos, como manuales de productos o libros, donde el usuario debe ser dirigido a las partes más relevantes de estos documentos."
            ],
            "translated_text": "Controlando la superposición en la recuperación <br>XML</br> orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca RESUMEN La aplicación directa de técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos <br>XML</br> a menudo produce un conjunto de resultados en el que los primeros puestos están dominados por un gran número de elementos tomados de un pequeño número de documentos altamente relevantes. Este documento presenta y evalúa un algoritmo que vuelve a clasificar este conjunto de resultados, con el objetivo de minimizar el contenido redundante mientras se preservan los beneficios de la recuperación de elementos, incluido el beneficio de identificar componentes centrados en el tema contenidos en documentos relevantes. La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la <br>Recuperación XML</br> (INEX) constituye la base para la evaluación. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Búsqueda y Recuperación de Información Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. La representación de documentos en <br>XML</br> brinda una oportunidad para que los sistemas de recuperación de información aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias. En respuesta a una consulta de usuario, un sistema de recuperación de información <br>XML</br> podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes. Esta facilidad es de particular beneficio cuando una colección contiene documentos muy largos, como manuales de productos o libros, donde el usuario debe ser dirigido a las partes más relevantes de estos documentos. ",
            "candidates": [],
            "error": [
                [
                    "XML",
                    "XML",
                    "Recuperación XML",
                    "XML",
                    "XML"
                ]
            ]
        },
        "rank": {
            "translated_key": "rango",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Controlling Overlap in Content-Oriented XML Retrieval Charles L. A. Clarke School of Computer Science, University of Waterloo, Canada claclark@plg.uwaterloo.ca ABSTRACT The direct application of standard ranking techniques to retrieve individual elements from a collection of XML documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents.",
                "This paper presents and evaluates an algorithm that re-ranks this result set, with the aim of minimizing redundant content while preserving the benefits of element retrieval, including the benefit of identifying topic-focused components contained within relevant documents.",
                "The test collection developed by the INitiative for the Evaluation of XML Retrieval (INEX) forms the basis for the evaluation.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Information Search and Retrieval General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "INTRODUCTION The representation of documents in XML provides an opportunity for information retrieval systems to take advantage of document structure, returning individual document components when appropriate, rather than complete documents in all circumstances.",
                "In response to a user query, an XML information retrieval system might return a mixture of paragraphs, sections, articles, bibliographic entries and other components.",
                "This facility is of particular benefit when a collection contains very long documents, such as product manuals or books, where the user should be directed to the most relevant portions of these documents. <article> <fm> <atl>Text Compression for Dynamic Document Databases</atl> <au>Alistair Moffat</au> <au>Justin Zobel</au> <au>Neil Sharman</au> <abs><p><b>Abstract</b> For ...</p></abs> </fm> <bdy> <sec><st>INTRODUCTION</st> <ip1>Modern document databases...</ip1> <p>There are good reasons to compress...</p> </sec> <sec><st>REDUCING MEMORY REQUIREMENTS</st>... <ss1><st>2.1 Method A</st>... </sec> ... </bdy> </article> Figure 1: A journal article encoded in XML.",
                "Figure 1 provides an example of a journal article encoded in XML, illustrating many of the important characteristics of XML documents.",
                "Tags indicate the beginning and end of each element, with elements varying widely in size, from one word to thousands of words.",
                "Some elements, such as paragraphs and sections, may be reasonably presented to the user as retrieval results, but others are not appropriate.",
                "Elements overlap each other - articles contain sections, sections contain subsections, and subsections contain paragraphs.",
                "Each of these characteristics affects the design of an XML IR system, and each leads to fundamental problems that must be solved in an successful system.",
                "Most of these fundamental problems can be solved through the careful adaptation of standard IR techniques, but the problems caused by overlap are unique to this area [4,11] and form the primary focus of this paper.",
                "The article of figure 1 may be viewed as an XML tree, as illustrated in figure 2.",
                "Formally, a collection of XML documents may be represented as a forest of ordered, rooted trees, consisting of a set of nodes N and a set of directed edges E connecting these nodes.",
                "For each node x ∈ N , the notation x.parent refers to the parent node of x, if one exists, and the notation x.children refers to the set of child nodes sec bdyfm atl au au au abs p b st ip1 sec st ss1 st article p Figure 2: Example XML tree. of x.",
                "Since an element may be represented by the node at its root, the output of an XML IR system may be viewed as a ranked list of the top-m nodes.",
                "The direct application of a standard relevance ranking technique to a set of XML elements can produce a result in which the top ranks are dominated by many structurally related elements.",
                "A high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article.",
                "For example, many of the elements in figure 2 would receive a high score on the keyword query text index compression algorithms.",
                "If each of these elements are presented to a user as an individual and separate result, she may waste considerable time reviewing and rejecting redundant content.",
                "One possible solution is to report only the highest scoring element along a given path in the tree, and to remove from the lower ranks any element containing it, or contained within it.",
                "Unfortunately, this approach destroys some of the possible benefits of XML IR.",
                "For example, an outer element may contain a substantial amount of information that does not appear in an inner element, but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts.",
                "In such cases, it is reasonable to report elements which contain, or are contained in, higher ranking elements.",
                "Even when an entire book is relevant, a user may still wish to have the most important paragraphs highlighted, to guide her reading and to save time [6].",
                "This paper presents a method for controlling overlap.",
                "Starting with an initial element ranking, a re-ranking algorithm adjusts the scores of lower ranking elements that contain, or are contained within, higher ranking elements, reflecting the fact that this information may now be redundant.",
                "For example, once an element representing a section appears in the ranking, the scores for the paragraphs it contains and the article that contains it are reduced.",
                "The inspiration for this strategy comes partially from recent work on structured documents retrieval, where terms appearing in different fields, such as the title and body, are given different weights [20].",
                "Extending that approach, the re-ranking algorithm varies weights dynamically as elements are processed.",
                "The remainder of the paper is organized as follows: After a discussion of background work and evaluation methodology, a baseline retrieval method is presented in section 4.",
                "This baseline method represents a reasonable adaptation of standard IR technology to XML.",
                "Section 5 then outlines a strategy for controlling overlap, using the baseline method as a starting point.",
                "A re-ranking algorithm implementing this strategy is presented in section 6 and evaluated in section 7.",
                "Section 8 discusses an extended version of the algorithm. 2.",
                "BACKGROUND This section provides a general overview of XML information retrieval and discusses related work, with an emphasis on the fundamental problems mentioned in the introduction.",
                "Much research in the area of XML retrieval views it from a traditional database perspective, being concerned with such problems as the implementation of structured query languages [5] and the processing of joins [1].",
                "Here, we take a content oriented IR perceptive, focusing on XML documents that primarily contain natural language data and queries that are primarily expressed in natural language.",
                "We assume that these queries indicate only the nature of desired content, not its structure, and that the role of the IR system is to determine which elements best satisfy the underlying information need.",
                "Other IR research has considered mixed queries, in which both content and structural requirements are specified [2,6,14,17,23]. 2.1 Term and Document Statistics In traditional information retrieval applications the standard unit of retrieval is taken to be the document.",
                "Depending on the application, this term might be interpreted to encompass many different objects, including web pages, newspaper articles and email messages.",
                "When applying standard relevance ranking techniques in the context of XML IR, a natural approach is to treat each element as a separate document, with term statistics available for each [16].",
                "In addition, most ranking techniques require global statistics (e.g. inverse document frequency) computed over the collection as a whole.",
                "If we consider this collection to include all elements that might be returned by the system, a specific occurrence of a term may appear in several different documents, perhaps in elements representing a paragraph, a subsection, a section and an article.",
                "It is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements, since the number of elements that contain a term depends entirely on the structural arrangement of the documents [13,23]. 2.2 Retrievable Elements While an XML IR system might potentially retrieve any element, many elements may not be appropriate as retrieval results.",
                "This is usually the case when elements contain very little text [10].",
                "For example, a section title containing only the query terms may receive a high score from a ranking algorithm, but alone it would be of limited value to a user, who might prefer the actual section itself.",
                "Other elements may reflect the documents physical, rather than logical, structure, which may have little or no meaning to a user.",
                "An effective XML IR system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects [15,18].",
                "Standard document components such as paragraphs, sections, subsections, and abstracts usually meet these requirements; titles, italicized phrases, and individual metadata fields often do not. 2.3 Evaluation Methodology Over the past three years, the INitiative for the Evaluation of XML Retrieval (INEX) has encouraged research into XML information retrieval technology [7,8].",
                "INEX is an experimental conference series, similar to TREC, with groups from different institutions completing one or more experimental tasks using their own tools and systems, and comparing their results at the conference itself.",
                "Over 50 groups participated in INEX 2004, and the conference has become as influential in the area of XML IR as TREC is in other IR areas.",
                "The research described in this paper, as well as much of the related work it cites, depends on the test collections developed by INEX.",
                "Overlap causes considerable problems with retrieval evaluation, and the INEX organizers and participants have wrestled with these problems since the beginning.",
                "While substantial progress has been made, these problem are still not completely solved.",
                "Kazai et al. [11] provide a detailed exposition of the overlap problem in the context of INEX retrieval evaluation and discuss both current and proposed evaluation metrics.",
                "Many of these metrics are applied to evaluate the experiments reported in this paper, and they are briefly outlined in the next section. 3.",
                "INEX 2004 Space limitations prevent the inclusion of more than a brief summary of INEX 2004 tasks and evaluation methodology.",
                "For detailed information, the proceedings of the conference itself should be consulted [8]. 3.1 Tasks For the main experimental tasks, INEX 2004 participants were provided with a collection of 12,107 articles taken from the IEEE Computer Societies magazines and journals between 1995 and 2002.",
                "Each document is encoded in XML using a common DTD, with the document of figures 1 and 2 providing one example.",
                "At INEX 2004, the two main experimental tasks were both adhoc retrieval tasks, investigating the performance of systems searching a static collection using previously unseen topics.",
                "The two tasks differed in the types of topics they used.",
                "For one task, the content-only or CO task, the topics consist of short natural language statements with no direct reference to the structure of the documents in the collection.",
                "For this task, the IR system is required to select the elements to be returned.",
                "For the other task, the contentand-structure or CAS task, the topics are written in an XML query language [22] and contain explicit references to document structure, which the IR system must attempt to satisfy.",
                "Since the work described in this paper is directed at the content-only task, where the IR system receives no guidance regarding the elements to return, the CAS task is ignored in the remainder of our description.",
                "In 2004, 40 new CO topics were selected by the conference organizers from contributions provided by the conference participants.",
                "Each topic includes a short keyword query, which is executed over the collection by each participating group on their own XML IR system.",
                "Each group could submit up to three experimental runs consisting of the top m = 1500 elements for each topic. 3.2 Relevance Assessment Since XML IR is concerned with locating those elements that provide complete coverage of a topic while containing as little extraneous information as possible, simple relevant vs. not relevant judgments are not sufficient.",
                "Instead, the INEX organizers adopted two dimensions for relevance assessment: The exhaustivity dimension reflects the degree to which an element covers the topic, and the specificity dimension reflects the degree to which an element is focused on the topic.",
                "A four-point scale is used in both dimensions.",
                "Thus, a (3,3) element is highly exhaustive and highly specific, a (1,3) element is marginally exhaustive and highly specific, and a (0,0) element is not relevant.",
                "Additional information on the assessment methodology may be found in Piwowarski and Lalmas [19], who provide a detailed rationale. 3.3 Evaluation Metrics The principle evaluation metric used at INEX 2004 is a version of mean average precision (MAP), adjusted by various quantization functions to give different weights to different elements, depending on their exhaustivity and specificity values.",
                "One variant, the strict quantization function gives a weight of 1 to (3,3) elements and a weight of 0 to all others.",
                "This variant is essentially the familiar MAP value, with (3,3) elements treated as relevant and all other elements treated as not relevant.",
                "Other quantization functions are designed to give partial credit to elements which are near misses, due to a lack or exhaustivity and/or specificity.",
                "Both the generalized quantization function and the specificity-oriented generalization (sog) function credit elements according to their degree of relevance [11], with the second function placing greater emphasis on specificity.",
                "This paper reports results of this metric using all three of these quantization functions.",
                "Since this metric was first introduced at INEX 2002, it is generally referred as the inex-2002 metric.",
                "The inex-2002 metric does not penalize overlap.",
                "In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher <br>rank</br>.",
                "To address this problem, Kazai et al. [11] propose an XML cumulated gain metric, which compares the cumulated gain [9] of a ranked list to an ideal gain vector.",
                "This ideal gain vector is constructed from the relevance judgments by eliminating overlap and retaining only best element along a given path.",
                "Thus, the XCG metric rewards retrieval runs that avoid overlap.",
                "While XCG was not used officially at INEX 2004, a version of it is likely to be used in the future.",
                "At INEX 2003, yet another metric was introduced to ameliorate the perceived limitations of the inex-2002 metric.",
                "This inex-2003 metric extends the definitions of precision and recall to consider both the size of reported components and the overlap between them.",
                "Two versions were created, one that considered only component size and another that considered both size and overlap.",
                "While the inex-2003 metric exhibits undesirable anomalies [11], and was not used in 2004, values are reported in the evaluation section to provide an additional instrument for investigating overlap. 4.",
                "BASELINE RETRIEVAL METHOD This section provides an overview of baseline XML information retrieval method currently used in the MultiText IR system, developed by the Information Retrieval Group at the University of Waterloo [3].",
                "This retrieval method results from the adaptation and tuning of the Okapi BM25 measure [21] to the XML information retrieval task.",
                "The MultiText system performed respectably at INEX 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized exhaustivity.",
                "To support retrieval from XML and other structured document types, the system provides generalized queries of the form: <br>rank</br> X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms.",
                "For our INEX 2004 runs, the sub-query X specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt This list includes bibliographic entries (bb) and figure captions (fig) as well as paragraphs, sections and subsections.",
                "Prior to INEX 2004, the INEX collection and the INEX 2003 relevance judgments were manually analyzed to select these tag names.",
                "Tag names were selected on the basis of their frequency in the collection, the average size of their associated elements, and the relative number of positive relevance judgments they received.",
                "Automating this selection process is planned as future work.",
                "For INEX 2004, the term vector Y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.",
                "For example, keyword field of topic 166 +tree edit distance + XML -image became the four-term query $tree $edit $distance $xml where the $ operator within a quoted string stems the term that follows it.",
                "Our implementation of Okapi BM25 is derived from the formula of Robertson et al. [21] by setting parameters k2 = 0 and k3 = ∞.",
                "Given a term set Q, an element x is assigned the score   t∈Q w(1) qt (k1 + 1)xt K + xt (1) where w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = number of documents in the corpus Dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x K = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 MeanAveragePrecision(inex-2002) k1 strict generalized sog Figure 3: Impact of k1 on inex-2002 mean average precision with b = 0.75 (INEX 2003 CO topics).",
                "Prior to INEX 2004, the INEX 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.",
                "For the purposes of computing document-level statistics (D, Dt and lavg) a document is defined to be an article.",
                "These statistics are used for ranking all element types.",
                "Following the suggestion of Kamps et al. [10], the retrieval results are filtered to eliminate very short elements, those less than 25 words in length.",
                "The use of article statistics for all element types might be questioned.",
                "This approach may be justified by viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.",
                "The score computed for an element is essentially the score it would receive if it were added to the collection as a new document, ignoring the minor adjustments needed to the document-level statistics.",
                "Nonetheless, we plan to examine this issue again in the future.",
                "In our experience, the performance of BM25 typically benefits from tuning the b and k1 parameters to the collection, whenever training queries are available for this purpose.",
                "Prior to INEX 2004, we trained the MultiText system using the INEX 2003 queries.",
                "As a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on TREC adhoc collections and are used as default values in our system.",
                "The results were surprising.",
                "Figure 3 shows the result of varying k1 with b = 0.75 on the MAP values under three quantization functions.",
                "In our experience, optimal values for k1 are typically in the range 0.0 to 2.0.",
                "In this case, large values are required for good performance.",
                "Between k1 = 1.0 and k1 = 6.0 MAP increases by over 15% under the strict quantization.",
                "Similar improvements are seen under the generalized and sog quantizations.",
                "In contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).",
                "After tuning over a wide range of values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our INEX 2004 experiments, and these values are used for the experiments reported in section 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2002) b strict generalized sog Figure 4: Impact of b on inex-2002 mean average precision with k1 = 10 (INEX 2003 CO topics). 5.",
                "CONTROLLING OVERLAP Starting with an element ranking generated by the baseline method described in the previous section, elements are re-ranked to control overlap by iteratively adjusting the scores of those elements containing or contained in higher ranking elements.",
                "At a conceptual level, re-ranking proceeds as follows: 1.",
                "Report the highest ranking element. 2.",
                "Adjust the scores of the unreported elements. 3.",
                "Repeat steps 1 and 2 until m elements are reported.",
                "One approach to adjusting the scores of unreported elements in step 2 might be based on the Okapi BM25 scores of the involved elements.",
                "For example, assume a paragraph with score p is reported in step 1.",
                "In step 2, the section containing the paragraph might then have its score s lowered by an amount α · p to reflect the reduced contribution the paragraph should make to the sections score.",
                "In a related context, Robertson et al. [20] argue strongly against the linear combination of Okapi scores in this fashion.",
                "That work considers the problem of assigning different weights to different document fields, such as the title and body associated with Web pages.",
                "A common approach to this problem scores the title and body separately and generates a final score as a linear combination of the two.",
                "Robertson et al. discuss the theoretical flaws in this approach and demonstrate experimentally that it can actually harm retrieval effectiveness.",
                "Instead, they apply the weights at the term frequency level, with an occurrence of a query term t in the title making a greater contribution to the score than an occurrence in the body.",
                "In equation 1, xt becomes α0 · yt + α1 · zt, where yt is the number of times t occurs in the title and zt is the number of times t occurs in the body.",
                "Translating this approach to our context, the contribution of terms appearing in elements is dynamically reduced as they are reported.",
                "The next section presents and analysis a simple re-ranking algorithm that follows this strategy.",
                "The algorithm is evaluated experimentally in section 7.",
                "One limitation of the algorithm is that the contribution of terms appearing in reported elements is reduced by the same factor regardless of the number of reported elements in which it appears.",
                "In section 8 the algorithm is extended to apply increasing weights, lowering the score, when a term appears in more than one reported element. 6.",
                "RE-RANKING ALGORITHM The re-ranking algorithm operates over XML trees, such as the one appearing in figure 2.",
                "Input to the algorithm is a list of n elements ranked according to their initial BM25 scores.",
                "During the initial ranking the XML tree is dynamically re-constructed to include only those nodes with nonzero BM25 scores, so n may be considerably less than |N |.",
                "Output from the algorithm is a list of the top m elements, ranked according to their adjusted scores.",
                "An element is represented by the node x ∈ N at its root.",
                "Associated with this node are fields storing the length of element, term frequencies, and other information required by the re-ranking algorithm, as follows: x.f - term frequency vector x.g - term frequency adjustments x.l - element length x.score - current Okapi BM25 score x.reported - boolean flag, initially false x.children - set of child nodes x.parent - parent node, if one exists These fields are populated during the initial ranking process, and updated as the algorithm progresses.",
                "The vector x.f contains term frequency information corresponding to each term in the query.",
                "The vector x.g is initially zero and is updated by the algorithm as elements are reported.",
                "The score field contains the current BM25 score for the element, which will change as the values in x.g change.",
                "The score is computed using equation 1, with the xt value for each term determined by a combination of the values in x.f and x.g.",
                "Given a term t ∈ Q, let ft be the component of x.f corresponding to t, and let gt be the component of x.g corresponding to t, then: xt = ft − α · gt (2) For processing by the re-ranking algorithm, nodes are stored in priority queues, ordered by decreasing score.",
                "Each priority queue PQ supports three operations: PQ.front() - returns the node with greatest score PQ.add (x) - adds node x to the queue PQ.remove(x) - removes node x from the queue When implemented using standard data structures, the front operation requires O(1) time, and the other operations require O(log n) time, where n is the size of the queue.",
                "The core of the re-ranking algorithm is presented in figure 5.",
                "The algorithm takes as input the priority queue S containing the initial ranking, and produces the top-m reranked nodes in the priority queue F. After initializing F to be empty on line 1, the algorithm loops m times over lines 215, transferring at least one node from S to F during each iteration.",
                "At the start of each iteration, the unreported node at the front of S has the greatest adjusted score, and it is removed and added to F. The algorithm then traverses the 1 F ← ∅ 2 for i ← 1 to m do 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 foreach y ∈ x.children do 9 Down (y) 10 end do 11 12 if x is not a root node then 13 Up (x, x.parent) 14 end if 15 end do Figure 5: Re-Ranking Algorithm - As input, the algorithm takes a priority queue S, containing XML nodes ranked by their initial scores, and returns its results in priority queue F, ranked by adjusted scores. 1 Up(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recompute y.score 5 S.add(y) 6 if y is not a root node then 7 Up (x, y.parent) 8 end if 9 10 Down(x) ≡ 11 if not x.reported then 12 S.remove(x) 14 x.g ← x.f 15 recompute x.score 16 if x.score > 0 then 17 F.add(x) 18 end if 19 x.reported ← true 20 foreach y ∈ x.children do 21 Down (y) 22 end do 23 end if Figure 6: Tree traversal routines called by the reranking algorithm. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 MeanAveragePrecision(inex-2002) XMLCumulatedGain(XCG) alpha MAP (strict) MAP (generalized) MAP (sog) XCG (sog2) Figure 7: Impact of α on XCG and inex-2002 MAP (INEX 2004 CO topics; assessment set I). nodes ancestors (lines 8-10) and descendants (lines 12-14) adjusting the scores of these nodes.",
                "The tree traversal routines, Up and Down are given in figure 6.",
                "The Up routine removes each ancestor node from S, adjusts its term frequency values, recomputes its score, and adds it back into S. The adjustment of the term frequency values (line 3) adds to y.g only the previously unreported term occurrences in x. Re-computation of the score on line 4 uses equations 1 and 2.",
                "The Down routine performs a similar operation on each descendant.",
                "However, since the contents of each descendant are entirely contained in a reported element its final score may be computed, and it is removed from S and added to F. In order to determine the time complexity of the algorithm, first note that a node may be an argument to Down at most once.",
                "Thereafter, the reported flag of its parent is true.",
                "During each call to Down a node may be moved from S to F, requiring O(log n) time.",
                "Thus, the total time for all calls to Down is O(n log n), and we may temporarily ignore lines 8-10 of figure 5 when considering the time complexity of the loop over lines 2-15.",
                "During each iteration of this loop, a node and each of its ancestors are removed from a priority queue and then added back into a priority queue.",
                "Since a node may have at most h ancestors, where h is the maximum height of any tree in the collection, each of the m iterations requires O(h log n) time.",
                "Combining these observations produces an overall time complexity of O((n + mh) log n).",
                "In practice, re-ranking an INEX result set requires less than 200ms on a three-year-old desktop PC. 7.",
                "EVALUATION None of the metrics described in section 3.3 is a close fit with the view of overlap advocated by this paper.",
                "Nonetheless, when taken together they provide insight into the behaviour of the re-ranking algorithm.",
                "The INEX evaluation packages (inex_eval and inex_eval_ng) were used to compute values for the inex-2002 and inex-2003 metrics.",
                "Values for the XCG metrics were computed using software supplied by its inventors [11].",
                "Figure 7 plots the three variants of inex-2002 MAP metric together with the XCG metric.",
                "Values for these metrics 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 MeanAveragePrecision(inex-2003) alpha strict, overlap not considered strict, overlap considered generalized, overlap not considered generalized, overlap considered Figure 8: Impact of α on inex-2003 MAP (INEX 2004 CO topics; assessment set I). are plotted for values of α between 0.0 and 1.0.",
                "Recalling that the XCG metric is designed to penalize overlap, while the inex-2002 metric ignores overlap, the conflict between the metrics is obvious.",
                "The MAP values at one extreme (α = 0.0) and the XCG value at the other extreme (α = 1.0) represent retrieval performance comparable to the best systems at INEX 2004 [8,12].",
                "Figure 8 plots values of the inex-2003 MAP metric for two quantizations, with and without consideration of overlap.",
                "Once again, conflict is apparent, with the influence of α substantially lessened when overlap is considered. 8.",
                "EXTENDED ALGORITHM One limitation of the re-ranking algorithm is that a single weight α is used to adjust the scores of both the ancestors and descendants of reported elements.",
                "An obvious extension is to use different weights in these two cases.",
                "Furthermore, the same weight is used regardless of the number of times an element is contained in a reported element.",
                "For example, a paragraph may form part of a reported section and then form part of a reported article.",
                "Since the user may now have seen this paragraph twice, its score should be further lowered by increasing the value of the weight.",
                "Motivated by these observations, the re-ranking algorithm may be extended with a series of weights 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0. where βj is the weight applied to a node that has been a descendant of a reported node j times.",
                "Note that an upper bound on M is h, the maximum height of any XML tree in the collection.",
                "However, in practice M is likely to be relatively small (perhaps 3 or 4).",
                "Figure 9 presents replacements for the Up and Down routines of figure 6, incorporating this series of weights.",
                "One extra field is required in each node, as follows: x.j - down count The value of x.j is initially set to zero in all nodes and is incremented each time Down is called with x as its argument.",
                "When computing the score of node, the value of x.j selects 1 Up(x, y) ≡ 2 if not y.reported then 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recompute y.score 6 S.add(y) 8 if y is not a root node then 9 Up (x, y.parent) 10 end if 11 end if 12 13 Down(x) ≡ 14 if x.j < M then 15 x.j ← x.j + 1 16 if not x.reported then 17 S.remove(x) 18 recompute x.score 19 S.add(x) 20 end if 21 foreach y ∈ x.children do 22 Down (y) 23 end do 24 end if Figure 9: Extended tree traversal routines. the weight to be applied to the node by adjusting the value of xt in equation 1, as follows: xt = βx.j · (ft − α · gt) (3) where ft and gt are the components of x.f and x.g corresponding to term t. A few additional changes are required to extend Up and Down.",
                "The Up routine returns immediately (line 2) if its argument has already been reported, since term frequencies have already been adjusted in its ancestors.",
                "The Down routine does not report its argument, but instead recomputes its score and adds it back into S. A node cannot be an argument to Down more than M +1 times, which in turn implies an overall time complexity of O((nM + mh) log n).",
                "Since M ≤ h and m ≤ n, the time complexity is also O(nh log n). 9.",
                "CONCLUDING DISCUSSION When generating retrieval results over an XML collection, some overlap in the results should be tolerated, and may be beneficial.",
                "For example, when a highly exhaustive and fairly specific (3,2) element contains a much smaller (2,3) element, both should be reported to the user, and retrieval algorithms and evaluation metrics should respect this relationship.",
                "The algorithm presented in this paper controls overlap by weighting the terms occurring in reported elements to reflect their reduced importance.",
                "Other approaches may also help to control overlap.",
                "For example, when XML retrieval results are presented to users it may be desirable to cluster structurally related elements together, visually illustrating the relationships between them.",
                "While this style of user interface may help a user cope with overlap, the strategy presented in this paper continues to be applicable, by determining the best elements to include in each cluster.",
                "At Waterloo, we continue to develop and test our ideas for INEX 2005.",
                "In particular, we are investigating methods for learning the α and βj weights.",
                "We are also re-evaluating our approach to document statistics and examining appropriate adjustments to the k1 parameter as term weights change [20]. 10.",
                "ACKNOWLEDGMENTS Thanks to Gabriella Kazai and Arjen de Vries for providing an early version of their software for computing the XCG metric, and thanks to Phil Tilker and Stefan B¨uttcher for their help with the experimental evaluation.",
                "In part, funding for this project was provided by IBM Canada through the National Institute for Software Research. 11.",
                "REFERENCES [1] N. Bruno, N. Koudas, and D. Srivastava.",
                "Holistic twig joins: Optimal XML pattern matching.",
                "In Proceedings of the 2002 ACM SIGMOD International Conference on the Management of Data, pages 310-321, Madison, Wisconsin, June 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y.",
                "Mass, and A. Soffer.",
                "Searching XML documents via XML fragments.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 151-158, Toronto, Canada, 2003. [3] C. L. A. Clarke and P. L. Tilker.",
                "MultiText experiments for INEX 2004.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai, and M. Lalmas.",
                "Tolerance to irrelevance: A user-effort oriented evaluation of retrieval systems without predefined retrieval unit.",
                "In RIAO 2004 Conference Proceedings, pages 463-473, Avignon, France, April 2004. [5] D. DeHaan, D. Toman, M. P. Consens, and M. T. ¨Ozsu.",
                "A comprehensive XQuery to SQL translation using dynamic interval encoding.",
                "In Proceedings of the 2003 ACM SIGMOD International Conference on the Management of Data, San Diego, June 2003. [6] N. Fuhr and K. Großjohann.",
                "XIRQL: A query language for information retrieval in XML documents.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 172-180, New Orleans, September 2001. [7] N. Fuhr, M. Lalmas, and S. Malik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Second Workshop (INEX 2003), Dagstuhl, Germany, December 2003. [8] N. Fuhr, M. Lalmas, S. Malik, and Zolt´an Szl´avik, editors.",
                "Initiative for the Evaluation of XML Retrieval.",
                "Proceedings of the Third Workshop (INEX 2004), Dagstuhl, Germany, December 2004.",
                "Published as Advances in XML Information Retrieval, Lecture Notes in Computer Science, volume 3493, Springer, 2005. [9] K. J¨avelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, and B. Sigurbj¨ornsson.",
                "Length normalization in XML retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 80-87, Sheffield, UK, July 2004. [11] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "The overlap problem in content-oriented XML retrieval evaluation.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 72-79, Sheffield, UK, July 2004. [12] G. Kazai, M. Lalmas, and A. P. de Vries.",
                "Reliability tests for the XCG and inex-2002 metrics.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola, and T. Aalto.",
                "TRIX 2004 - Struggling with the overlap.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [14] S. Liu, Q. Zou, and W. W. Chu.",
                "Configurable indexing and ranking for XML information retrieval.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 88-95, Sheffield, UK, July 2004. [15] Y.",
                "Mass and M. Mandelbrod.",
                "Retrieving the most relevant XML components.",
                "In INEX 2003 Workshop Proceedings, Dagstuhl, Germany, December 2003. [16] Y.",
                "Mass and M. Mandelbrod.",
                "Component ranking and automatic query refinement for XML retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [17] P. Ogilvie and J. Callan.",
                "Hierarchical language models for XML component retrieval.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [18] J. Pehcevski, J.",
                "A. Thom, and A. Vercoustre.",
                "Hybrid XML retrieval re-visited.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [19] B. Piwowarski and M. Lalmas.",
                "Providing consistent and exhaustive relevance assessments for XML retrieval evaluation.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 361-370, Washington, DC, November 2004. [20] S. Robertson, H. Zaragoza, and M. Taylor.",
                "Simple BM25 extension to multiple weighted fields.",
                "In Proceedings of the 13th ACM Conference on Information and Knowledge Management, pages 42-50, Washington, DC, November 2004. [21] S. E. Robertson, S. Walker, and M. Beaulieu.",
                "Okapi at TREC-7: Automatic ad-hoc, filtering, VLC and interactive track.",
                "In Proceedings of the Seventh Text REtrieval Conference, Gaithersburg, MD, November 1998. [22] A. Trotman and B. Sigurbj¨ornsson.",
                "NEXI, now and next.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski, and P. Gallinari.",
                "An algebra for structured queries in bayesian networks.",
                "In INEX 2004 Workshop Proceedings, 2004.",
                "Published in LNCS 3493 [8]."
            ],
            "original_annotated_samples": [
                "In particular, both the generalized and sog quantization functions give partial credit to a near miss even when a (3,3) element overlapping it is reported at a higher <br>rank</br>.",
                "To support retrieval from XML and other structured document types, the system provides generalized queries of the form: <br>rank</br> X by Y where X is a sub-query specifying a set of document elements to be ranked and Y is a vector of sub-queries specifying individual retrieval terms."
            ],
            "translated_annotated_samples": [
                "En particular, tanto las funciones de cuantificación generalizadas como las de sog otorgan crédito parcial a un casi acierto incluso cuando se informa un elemento (3,3) que se superpone a él en un <br>rango</br> más alto.",
                "Para admitir la recuperación de XML y otros tipos de documentos estructurados, el sistema proporciona consultas generalizadas de la forma: <br>clasificar</br> X por Y donde X es una subconsulta que especifica un conjunto de elementos de documentos a <br>clasificar</br> y Y es un vector de subconsultas que especifican términos de recuperación individuales."
            ],
            "translated_text": "Controlando la superposición en la recuperación XML orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca RESUMEN La aplicación directa de técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos XML a menudo produce un conjunto de resultados en el que los primeros puestos están dominados por un gran número de elementos tomados de un pequeño número de documentos altamente relevantes. Este documento presenta y evalúa un algoritmo que vuelve a clasificar este conjunto de resultados, con el objetivo de minimizar el contenido redundante mientras se preservan los beneficios de la recuperación de elementos, incluido el beneficio de identificar componentes centrados en el tema contenidos en documentos relevantes. La colección de pruebas desarrollada por la Iniciativa para la Evaluación de la Recuperación XML (INEX) constituye la base para la evaluación. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Búsqueda y Recuperación de Información Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. La representación de documentos en XML brinda una oportunidad para que los sistemas de recuperación de información aprovechen la estructura del documento, devolviendo componentes individuales del documento cuando sea apropiado, en lugar de documentos completos en todas las circunstancias. En respuesta a una consulta de usuario, un sistema de recuperación de información XML podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes. Esta facilidad es de particular beneficio cuando una colección contiene documentos muy largos, como manuales de productos o libros, donde el usuario debe ser dirigido a las partes más relevantes de estos documentos. La Figura 1 proporciona un ejemplo de un artículo de revista codificado en XML, ilustrando muchas de las características importantes de los documentos XML. Las etiquetas indican el inicio y el final de cada elemento, con elementos que varían ampliamente en tamaño, desde una palabra hasta miles de palabras. Algunos elementos, como párrafos y secciones, pueden presentarse razonablemente al usuario como resultados de búsqueda, pero otros no son apropiados. Los elementos se superponen entre sí: los artículos contienen secciones, las secciones contienen subsecciones y las subsecciones contienen párrafos. Cada una de estas características afecta el diseño de un sistema de IR XML, y cada una conlleva problemas fundamentales que deben resolverse en un sistema exitoso. La mayoría de estos problemas fundamentales pueden resolverse mediante la cuidadosa adaptación de técnicas estándar de IR, pero los problemas causados por la superposición son únicos en esta área [4,11] y constituyen el enfoque principal de este artículo. El artículo de la figura 1 puede ser visto como un árbol XML, como se ilustra en la figura 2. Formalmente, una colección de documentos XML puede ser representada como un bosque de árboles ordenados y enraizados, que consiste en un conjunto de nodos N y un conjunto de aristas dirigidas E que conectan estos nodos. Para cada nodo x ∈ N, la notación x.parent se refiere al nodo padre de x, si existe, y la notación x.children se refiere al conjunto de nodos hijos de x. Dado que un elemento puede estar representado por el nodo en su raíz, la salida de un sistema de IR XML puede ser vista como una lista clasificada de los m nodos principales. La aplicación directa de una técnica estándar de clasificación de relevancia a un conjunto de elementos XML puede producir un resultado en el que los primeros puestos están dominados por muchos elementos estructuralmente relacionados. Una sección con una puntuación alta probablemente contenga varios párrafos con una puntuación alta y esté contenida en un artículo con una puntuación alta. Por ejemplo, muchos de los elementos en la figura 2 recibirían una puntuación alta en los algoritmos de compresión de índices de texto de consulta de palabras clave. Si cada uno de estos elementos se presenta a un usuario como un resultado individual y separado, puede perder mucho tiempo revisando y rechazando contenido redundante. Una posible solución es informar solo el elemento de mayor puntuación a lo largo de un camino dado en el árbol, y eliminar de los rangos inferiores cualquier elemento que lo contenga o esté contenido en él. Desafortunadamente, este enfoque destruye algunos de los posibles beneficios de XML IR. Por ejemplo, un elemento externo puede contener una cantidad sustancial de información que no aparece en un elemento interno, pero el elemento interno puede estar fuertemente enfocado en el tema de la consulta y proporcionar un breve resumen de los conceptos clave. En tales casos, es razonable informar sobre elementos que contienen, o están contenidos en, elementos de rango superior. Incluso cuando un libro entero es relevante, un usuario aún puede desear que se destaquen los párrafos más importantes, para guiar su lectura y ahorrar tiempo [6]. Este documento presenta un método para controlar la superposición. A partir de una clasificación inicial de elementos, un algoritmo de re-clasificación ajusta las puntuaciones de los elementos de menor clasificación que contienen, o están contenidos dentro de, elementos de mayor clasificación, reflejando el hecho de que esta información puede ser ahora redundante. Por ejemplo, una vez que un elemento que representa una sección aparece en la clasificación, las puntuaciones de los párrafos que contiene y del artículo que lo contiene se reducen. La inspiración para esta estrategia proviene parcialmente del trabajo reciente sobre la recuperación de documentos estructurados, donde los términos que aparecen en diferentes campos, como el título y el cuerpo, reciben diferentes pesos [20]. Extendiendo ese enfoque, el algoritmo de reordenamiento varía los pesos dinámicamente a medida que se procesan los elementos. El resto del documento está organizado de la siguiente manera: Después de una discusión sobre el trabajo de antecedentes y la metodología de evaluación, se presenta un método de recuperación de referencia en la sección 4. Este método de referencia representa una adaptación razonable de la tecnología estándar de IR al XML. La sección 5 luego describe una estrategia para controlar la superposición, utilizando el método de línea base como punto de partida. Un algoritmo de reordenamiento que implementa esta estrategia se presenta en la sección 6 y se evalúa en la sección 7. La sección 8 discute una versión extendida del algoritmo. 2. ANTECEDENTES Esta sección proporciona una visión general de la recuperación de información XML y discute trabajos relacionados, con énfasis en los problemas fundamentales mencionados en la introducción. Mucha investigación en el área de recuperación de XML lo ve desde una perspectiva de base de datos tradicional, preocupándose por problemas como la implementación de lenguajes de consulta estructurados [5] y el procesamiento de joins [1]. Aquí adoptamos una perspectiva de IR orientada al contenido, centrándonos en documentos XML que contienen principalmente datos en lenguaje natural y consultas que están principalmente expresadas en lenguaje natural. Suponemos que estas consultas indican únicamente la naturaleza del contenido deseado, no su estructura, y que el papel del sistema de RI es determinar qué elementos satisfacen mejor la necesidad de información subyacente. Otra investigación en IR ha considerado consultas mixtas, en las que se especifican tanto requisitos de contenido como estructurales [2,6,14,17,23]. 2.1 Estadísticas de Términos y Documentos En las aplicaciones tradicionales de recuperación de información, la unidad estándar de recuperación se considera que es el documento. Dependiendo de la aplicación, este término podría interpretarse para abarcar muchos objetos diferentes, incluyendo páginas web, artículos de periódico y mensajes de correo electrónico. Al aplicar técnicas estándar de clasificación de relevancia en el contexto de la RI XML, un enfoque natural es tratar cada elemento como un documento separado, con estadísticas de términos disponibles para cada uno [16]. Además, la mayoría de las técnicas de clasificación requieren estadísticas globales (por ejemplo, frecuencia inversa de documentos) calculadas sobre la colección en su totalidad. Si consideramos que esta colección incluye todos los elementos que podrían ser devueltos por el sistema, una ocurrencia específica de un término puede aparecer en varios documentos diferentes, quizás en elementos que representan un párrafo, una subsección, una sección y un artículo. No es apropiado calcular la frecuencia inversa de documentos bajo la suposición de que el término está contenido en todos estos elementos, ya que el número de elementos que contienen un término depende completamente del arreglo estructural de los documentos [13,23]. 2.2 Elementos Recuperables Si bien un sistema de recuperación de información XML podría potencialmente recuperar cualquier elemento, muchos elementos pueden no ser apropiados como resultados de recuperación. Esto suele ser el caso cuando los elementos contienen muy poco texto [10]. Por ejemplo, un título de sección que contenga solo los términos de búsqueda puede recibir una puntuación alta de un algoritmo de clasificación, pero por sí solo tendría un valor limitado para un usuario, quien podría preferir la sección real en sí misma. Otros elementos pueden reflejar la estructura física de los documentos, en lugar de la estructura lógica, lo cual puede tener poco o ningún significado para un usuario. Un sistema de recuperación de información XML efectivo debe devolver solo aquellos elementos que tengan suficiente contenido para ser utilizables y puedan funcionar como objetos independientes [15,18]. Componentes estándar de documentos como párrafos, secciones, subsecciones y resúmenes generalmente cumplen con estos requisitos; los títulos, frases en cursiva y campos de metadatos individuales a menudo no lo hacen. 2.3 Metodología de Evaluación En los últimos tres años, la Iniciativa para la Evaluación de la Recuperación de Información XML (INEX) ha fomentado la investigación en tecnología de recuperación de información XML [7,8]. INEX es una serie de conferencias experimentales, similar a TREC, en la que grupos de diferentes instituciones completan una o más tareas experimentales utilizando sus propias herramientas y sistemas, y comparan sus resultados en la propia conferencia. Más de 50 grupos participaron en INEX 2004, y la conferencia se ha convertido en tan influyente en el área de la RI XML como lo es TREC en otras áreas de la RI. La investigación descrita en este artículo, al igual que gran parte del trabajo relacionado que cita, depende de las colecciones de pruebas desarrolladas por INEX. La superposición causa problemas considerables en la evaluación de la recuperación, y los organizadores y participantes de INEX han luchado con estos problemas desde el principio. Aunque se ha logrado un progreso sustancial, estos problemas aún no están completamente resueltos. Kazai et al. [11] proporcionan una exposición detallada del problema de superposición en el contexto de la evaluación de recuperación de INEX y discuten tanto las métricas de evaluación actuales como las propuestas. Muchas de estas métricas se aplican para evaluar los experimentos reportados en este artículo, y se describen brevemente en la siguiente sección. 3. Las limitaciones de espacio impiden incluir más que un breve resumen de las tareas y metodología de evaluación de INEX 2004. Para obtener información detallada, se deben consultar las actas de la conferencia en sí [8]. 3.1 Tareas Para las principales tareas experimentales, a los participantes de INEX 2004 se les proporcionó una colección de 12,107 artículos tomados de las revistas y publicaciones de la IEEE Computer Societies entre 1995 y 2002. Cada documento está codificado en XML utilizando una DTD común, siendo el documento de las figuras 1 y 2 un ejemplo. En INEX 2004, las dos principales tareas experimentales fueron ambas tareas de recuperación ad hoc, investigando el rendimiento de sistemas que buscan en una colección estática utilizando temas previamente no vistos. Las dos tareas diferían en los tipos de temas que utilizaban. Para una tarea, la tarea de solo contenido o CO, los temas consisten en declaraciones cortas en lenguaje natural sin hacer referencia directa a la estructura de los documentos en la colección. Para esta tarea, se requiere que el sistema de IR seleccione los elementos a devolver. Para la otra tarea, la tarea de contenido y estructura o CAS, los temas están escritos en un lenguaje de consulta XML [22] y contienen referencias explícitas a la estructura del documento, que el sistema de IR debe intentar satisfacer. Dado que el trabajo descrito en este documento se enfoca en la tarea de solo contenido, donde el sistema de IR no recibe orientación sobre los elementos a devolver, la tarea de CAS se ignora en el resto de nuestra descripción. En 2004, los organizadores de la conferencia seleccionaron 40 nuevos temas de CO de las contribuciones proporcionadas por los participantes de la conferencia. Cada tema incluye una breve consulta de palabras clave, la cual es ejecutada sobre la colección por cada grupo participante en su propio sistema de IR XML. Cada grupo podría presentar hasta tres ejecuciones experimentales que consistieran en los primeros m = 1500 elementos para cada tema. 3.2 Evaluación de Relevancia Dado que la RI XML se preocupa por localizar aquellos elementos que proporcionan una cobertura completa de un tema mientras contienen la menor cantidad de información irrelevante posible, los juicios simples de relevante vs. no relevante no son suficientes. En cambio, los organizadores de INEX adoptaron dos dimensiones para la evaluación de relevancia: la dimensión de exhaustividad refleja el grado en que un elemento abarca el tema, y la dimensión de especificidad refleja el grado en que un elemento se enfoca en el tema. Se utiliza una escala de cuatro puntos en ambas dimensiones. Por lo tanto, un elemento (3,3) es altamente exhaustivo y altamente específico, un elemento (1,3) es marginalmente exhaustivo y altamente específico, y un elemento (0,0) no es relevante. Información adicional sobre la metodología de evaluación se puede encontrar en Piwowarski y Lalmas [19], quienes proporcionan una justificación detallada. 3.3 Métricas de Evaluación La métrica de evaluación principal utilizada en INEX 2004 es una versión de la precisión promedio media (MAP), ajustada por diversas funciones de cuantificación para dar diferentes pesos a diferentes elementos, dependiendo de sus valores de exhaustividad y especificidad. Una variante, la función de cuantización estricta asigna un peso de 1 a los elementos (3,3) y un peso de 0 a todos los demás. Esta variante es esencialmente el valor MAP familiar, con elementos (3,3) tratados como relevantes y todos los demás elementos tratados como no relevantes. Otras funciones de cuantización están diseñadas para otorgar crédito parcial a elementos que son aproximaciones cercanas, debido a la falta de exhaustividad y/o especificidad. Tanto la función de cuantificación generalizada como la función de generalización orientada a la especificidad (sog) acreditan elementos según su grado de relevancia [11], siendo que la segunda función pone mayor énfasis en la especificidad. Este documento informa los resultados de esta métrica utilizando las tres funciones de cuantización. Desde que esta métrica fue introducida por primera vez en INEX 2002, generalmente se le conoce como la métrica inex-2002. La métrica inex-2002 no penaliza la superposición. En particular, tanto las funciones de cuantificación generalizadas como las de sog otorgan crédito parcial a un casi acierto incluso cuando se informa un elemento (3,3) que se superpone a él en un <br>rango</br> más alto. Para abordar este problema, Kazai et al. [11] proponen una métrica de ganancia acumulada XML, que compara la ganancia acumulada [9] de una lista clasificada con un vector de ganancia ideal. Este vector de ganancia ideal se construye a partir de las valoraciones de relevancia al eliminar la superposición y retener solo el mejor elemento a lo largo de un camino dado. Por lo tanto, la métrica XCG recompensa las ejecuciones de recuperación que evitan la superposición. Aunque XCG no se utilizó oficialmente en INEX 2004, es probable que se utilice una versión de él en el futuro. En INEX 2003, se introdujo otra métrica para mejorar las limitaciones percibidas de la métrica inex-2002. Este métrico inex-2003 extiende las definiciones de precisión y exhaustividad para considerar tanto el tamaño de los componentes informados como la superposición entre ellos. Se crearon dos versiones, una que consideraba solo el tamaño de los componentes y otra que consideraba tanto el tamaño como la superposición. Si bien la métrica inex-2003 presenta anomalías no deseadas [11] y no se utilizó en 2004, se informan valores en la sección de evaluación para proporcionar un instrumento adicional para investigar la superposición. 4. MÉTODO DE RECUPERACIÓN DE BASELINE Esta sección proporciona una descripción general del método de recuperación de información XML de base actualmente utilizado en el sistema MultiText IR, desarrollado por el Grupo de Recuperación de Información de la Universidad de Waterloo [3]. Este método de recuperación resulta de la adaptación y ajuste de la medida Okapi BM25 [21] a la tarea de recuperación de información en XML. El sistema MultiText tuvo un desempeño respetable en INEX 2004, ubicándose entre los diez primeros en todas las funciones de cuantización, y ocupando el primer lugar cuando la función de cuantización enfatizaba la exhaustividad. Para admitir la recuperación de XML y otros tipos de documentos estructurados, el sistema proporciona consultas generalizadas de la forma: <br>clasificar</br> X por Y donde X es una subconsulta que especifica un conjunto de elementos de documentos a <br>clasificar</br> y Y es un vector de subconsultas que especifican términos de recuperación individuales. Para nuestras ejecuciones de INEX 2004, la subconsulta X especificó una lista de elementos recuperables como aquellos con nombres de etiquetas de la siguiente manera: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt. Esta lista incluye entradas bibliográficas (bb) y leyendas de figuras (fig) así como párrafos, secciones y subsecciones. Antes de INEX 2004, la colección de INEX y las evaluaciones de relevancia de INEX 2003 fueron analizadas manualmente para seleccionar estos nombres de etiquetas. Los nombres de las etiquetas fueron seleccionados en base a su frecuencia en la colección, el tamaño promedio de sus elementos asociados y el número relativo de juicios de relevancia positiva que recibieron. Automatizar este proceso de selección está planeado como trabajo futuro. Para INEX 2004, el vector término Y se derivó del tema dividiendo frases en palabras individuales, eliminando palabras vacías y términos negativos (aquellos que comienzan con -), y aplicando un stemmer. Por ejemplo, el campo de palabra clave del tema 166 +distancia de edición de árbol + XML -imagen se convirtió en la consulta de cuatro términos $árbol $edición $distancia $xml donde el operador $ dentro de una cadena entre comillas deriva el término que le sigue. Nuestra implementación de Okapi BM25 se deriva de la fórmula de Robertson et al. [21] al establecer los parámetros k2 = 0 y k3 = ∞. Dado un conjunto de términos Q, a un elemento x se le asigna la puntuación t∈Q w(1) qt (k1 + 1)xt K + xt (1) donde w(1) = log ¡ D − Dt + 0.5 Dt + 0.5 ¢ D = número de documentos en el corpus Dt = número de documentos que contienen t qt = frecuencia con la que t ocurre en el tema xt = frecuencia con la que t ocurre en x K = k1((1 − b) + b · lx/lavg) lx = longitud de x lavg = longitud promedio del documento 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 PrecisiónPromedio(inex-2002) k1 estricto generalizado sog Figura 3: Impacto de k1 en la precisión promedio de inex-2002 con b = 0.75 (temas CO de INEX 2003). Antes de INEX 2004, los temas y juicios de INEX 2003 se utilizaron para ajustar los parámetros b y k1, y el impacto de este ajuste se discute más adelante en esta sección. Para los propósitos de calcular estadísticas a nivel de documento (D, Dt y lavg), un documento se define como un artículo. Estas estadísticas se utilizan para clasificar todos los tipos de elementos. Siguiendo la sugerencia de Kamps et al. [10], los resultados de recuperación se filtran para eliminar elementos muy cortos, aquellos con menos de 25 palabras de longitud. El uso de estadísticas de artículos para todos los tipos de elementos podría ser cuestionado. Este enfoque puede justificarse al considerar la colección como un conjunto de artículos que se pueden buscar utilizando técnicas estándar orientadas a documentos, donde solo se devuelven artículos. El puntaje calculado para un elemento es esencialmente el puntaje que recibiría si se agregara a la colección como un nuevo documento, ignorando los ajustes menores necesarios para las estadísticas a nivel de documento. Sin embargo, planeamos examinar este tema nuevamente en el futuro. En nuestra experiencia, el rendimiento de BM25 suele beneficiarse al ajustar los parámetros b y k1 a la colección, siempre que haya consultas de entrenamiento disponibles con este propósito. Antes de INEX 2004, entrenamos el sistema MultiText utilizando las consultas de INEX 2003. Como punto de partida, utilizamos los valores b = 0.75 y k1 = 1.2, que funcionan bien en colecciones TREC adhoc y se utilizan como valores predeterminados en nuestro sistema. Los resultados fueron sorprendentes. La Figura 3 muestra el resultado de variar k1 con b = 0.75 en los valores de MAP bajo tres funciones de cuantización. En nuestra experiencia, los valores óptimos para k1 suelen estar en el rango de 0.0 a 2.0. En este caso, se requieren valores grandes para un buen rendimiento. Entre k1 = 1.0 y k1 = 6.0, el MAP aumenta en más del 15% bajo la cuantización estricta. Se observan mejoras similares bajo las cuantizaciones generalizada y SOG. Por el contrario, nuestro valor predeterminado de b = 0.75 funciona bien bajo todas las funciones de cuantificación (figura 4). Después de ajustar una amplia gama de valores bajo varias funciones de cuantización, seleccionamos los valores de k = 10.0 y b = 0.80 para nuestros experimentos de INEX 2004, y estos valores se utilizan para los experimentos reportados en la sección 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 PrecisiónPromedioMedia (inex-2002) b estricto generalizado sog Figura 4: Impacto de b en la precisión promedio media de inex-2002 con k1 = 10 (temas CO de INEX 2003). 5. CONTROL DE SUPERPOSICIÓN Comenzando con una clasificación de elementos generada por el método de referencia descrito en la sección anterior, los elementos se vuelven a clasificar para controlar la superposición ajustando de forma iterativa las puntuaciones de aquellos elementos que contienen o están contenidos en elementos de clasificación más alta. A nivel conceptual, la reorganización procede de la siguiente manera: 1. Informe el elemento de rango más alto. Ajustar las puntuaciones de los elementos no reportados. 3. Repetir los pasos 1 y 2 hasta que se informen m elementos. Un enfoque para ajustar las puntuaciones de los elementos no informados en el paso 2 podría basarse en las puntuaciones Okapi BM25 de los elementos involucrados. Por ejemplo, supongamos que se informa un párrafo con una puntuación p en el paso 1. En el paso 2, la sección que contiene el párrafo podría tener su puntuación s reducida en una cantidad α · p para reflejar la contribución reducida que el párrafo debería hacer a la puntuación de las secciones. En un contexto relacionado, Robertson et al. [20] argumentan en contra de la combinación lineal de las puntuaciones de Okapi de esta manera. Ese trabajo considera el problema de asignar diferentes pesos a diferentes campos de documentos, como el título y el cuerpo asociados con páginas web. Un enfoque común para este problema puntúa el título y el cuerpo por separado y genera una puntuación final como una combinación lineal de ambos. Robertson et al. discuten las deficiencias teóricas en este enfoque y demuestran experimentalmente que puede perjudicar realmente la efectividad de la recuperación. En cambio, aplican los pesos a nivel de frecuencia de términos, donde la aparición de un término de consulta t en el título contribuye más al puntaje que una aparición en el cuerpo. En la ecuación 1, xt se convierte en α0 · yt + α1 · zt, donde yt es el número de veces que t aparece en el título y zt es el número de veces que t aparece en el cuerpo. Al traducir este enfoque a nuestro contexto, la contribución de los términos que aparecen en los elementos se reduce dinámicamente a medida que se informan. La siguiente sección presenta y analiza un algoritmo de reordenamiento simple que sigue esta estrategia. El algoritmo se evalúa experimentalmente en la sección 7. Una limitación del algoritmo es que la contribución de los términos que aparecen en los elementos informados se reduce por el mismo factor independientemente del número de elementos informados en los que aparezca. En la sección 8, el algoritmo se extiende para aplicar pesos crecientes, disminuyendo la puntuación, cuando un término aparece en más de un elemento informado. 6. ALGORITMO DE REORDENAMIENTO El algoritmo de reordenamiento opera sobre árboles XML, como el que aparece en la figura 2. La entrada al algoritmo es una lista de n elementos clasificados según sus puntuaciones iniciales de BM25. Durante la clasificación inicial, el árbol XML se reconstruye dinámicamente para incluir solo aquellos nodos con puntuaciones BM25 distintas de cero, por lo que n puede ser considerablemente menor que |N|. La salida del algoritmo es una lista de los primeros m elementos, clasificados según sus puntajes ajustados. Un elemento está representado por el nodo x ∈ N en su raíz. Asociados con este nodo se encuentran campos que almacenan la longitud del elemento, las frecuencias de términos y otra información requerida por el algoritmo de re-ranking, de la siguiente manera: x.f - vector de frecuencia de términos x.g - ajustes de frecuencia de términos x.l - longitud del elemento x.score - puntaje actual de Okapi BM25 x.reported - bandera booleana, inicialmente falsa x.children - conjunto de nodos hijos x.parent - nodo padre, si existe Estos campos se llenan durante el proceso de clasificación inicial y se actualizan a medida que avanza el algoritmo. El vector x.f contiene información de frecuencia de términos correspondiente a cada término en la consulta. El vector x.g es inicialmente cero y se actualiza por el algoritmo a medida que se informan elementos. El campo de puntuación contiene la puntuación BM25 actual para el elemento, la cual cambiará a medida que cambien los valores en x.g. El puntaje se calcula utilizando la ecuación 1, con el valor xt para cada término determinado por una combinación de los valores en x.f y x.g. Dado un término t ∈ Q, sea ft el componente de x.f correspondiente a t, y sea gt el componente de x.g correspondiente a t, entonces: xt = ft − α · gt (2) Para el procesamiento por el algoritmo de reordenamiento, los nodos se almacenan en colas de prioridad, ordenadas por puntaje decreciente. Cada cola de prioridad PQ admite tres operaciones: PQ.front() - devuelve el nodo con la puntuación más alta, PQ.add(x) - agrega el nodo x a la cola, PQ.remove(x) - elimina el nodo x de la cola. Cuando se implementan utilizando estructuras de datos estándar, la operación front requiere tiempo O(1), y las otras operaciones requieren tiempo O(log n), donde n es el tamaño de la cola. El núcleo del algoritmo de reordenamiento se presenta en la figura 5. El algoritmo toma como entrada la cola de prioridad S que contiene la clasificación inicial, y produce los primeros m nodos reordenados en la cola de prioridad F. Después de inicializar F como vacío en la línea 1, el algoritmo recorre m veces las líneas 215, transfiriendo al menos un nodo de S a F durante cada iteración. Al inicio de cada iteración, el nodo no reportado al frente de S tiene el mayor puntaje ajustado, y se elimina y se agrega a F. El algoritmo luego recorre el 1 F ← ∅ 2 para i ← 1 a m hacer 3 x ← S.front() 4 S.remove(x) 5 x.reported ← true 6 F.add(x) 7 8 para cada y ∈ x.children hacer 9 Abajo (y) 10 fin hacer 11 12 si x no es un nodo raíz entonces 13 Arriba (x, x.parent) 14 fin si 15 fin hacer Figura 5: Algoritmo de Re-Ranking - Como entrada, el algoritmo toma una cola de prioridad S, que contiene nodos XML clasificados por sus puntajes iniciales, y devuelve sus resultados en la cola de prioridad F, clasificados por puntajes ajustados. 1 Arriba(x, y) ≡ 2 S.remove(y) 3 y.g ← y.g + x.f − x.g 4 recalcular y.score 5 S.add(y) 6 si y no es un nodo raíz entonces 7 Arriba (x, y.parent) 8 fin si 9 10 Abajo(x) ≡ 11 si no x.reported entonces 12 S.remove(x) 14 x.g ← x.f 15 recalcular x.score 16 si x.score > 0 entonces 17 F.add(x) 18 fin si 19 x.reported ← true 20 para cada y ∈ x.children hacer 21 Abajo (y) 22 fin hacer 23 fin si Figura 6: Rutinas de recorrido de árbol llamadas por el algoritmo de re-ranking. 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 PrecisiónPromedioMedia (inex-2002) GananciaAcumuladaXML(XCG) alfa MAP (estricto) MAP (generalizado) MAP (sog) XCG (sog2) Figura 7: Impacto de α en XCG y MAP inex-2002 (temas CO de INEX 2004; conjunto de evaluación I). nodos ancestros (líneas 8-10) y descendientes (líneas 12-14) ajustando los puntajes de estos nodos. Las rutinas de recorrido de árboles, Arriba y Abajo, se muestran en la figura 6. El procedimiento Up elimina cada nodo ancestro de S, ajusta sus valores de frecuencia de término, recalcula su puntuación y lo vuelve a agregar a S. El ajuste de los valores de frecuencia de término (línea 3) agrega a y.g solo las ocurrencias de términos no reportadas previamente en x. El recalculo de la puntuación en la línea 4 utiliza las ecuaciones 1 y 2. La rutina Down realiza una operación similar en cada descendiente. Sin embargo, dado que el contenido de cada descendiente está completamente contenido en un elemento informado, su puntuación final puede ser calculada, y se elimina de S y se agrega a F. Para determinar la complejidad temporal del algoritmo, primero observe que un nodo puede ser un argumento de Down como máximo una vez. Posteriormente, la bandera reportada de su padre es verdadera. Durante cada llamada a Down, un nodo puede ser movido de S a F, lo que requiere un tiempo O(log n). Por lo tanto, el tiempo total para todas las llamadas a Down es O(n log n), y podemos ignorar temporalmente las líneas 8-10 de la figura 5 al considerar la complejidad temporal del bucle sobre las líneas 2-15. Durante cada iteración de este bucle, se elimina un nodo y cada uno de sus ancestros de una cola de prioridad y luego se vuelven a agregar a la cola de prioridad. Dado que un nodo puede tener como máximo h ancestros, donde h es la altura máxima de cualquier árbol en la colección, cada una de las m iteraciones requiere un tiempo de O(h log n). La combinación de estas observaciones produce una complejidad temporal general de O((n + mh) log n). En la práctica, volver a clasificar un conjunto de resultados de INEX requiere menos de 200 ms en una PC de escritorio de tres años de antigüedad. EVALUACIÓN Ninguna de las métricas descritas en la sección 3.3 se ajusta adecuadamente a la perspectiva de superposición defendida por este documento. Sin embargo, cuando se toman en conjunto, proporcionan información sobre el comportamiento del algoritmo de reordenamiento. Los paquetes de evaluación de INEX (inex_eval e inex_eval_ng) se utilizaron para calcular los valores de las métricas inex-2002 e inex-2003. Los valores de las métricas XCG fueron calculados utilizando el software proporcionado por sus inventores [11]. La Figura 7 representa juntas las tres variantes de la métrica MAP inex-2002 junto con la métrica XCG. Los valores para estas métricas 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Precisión Media Promedio (inex-2003) alfa estricto, superposición no considerada estricto, superposición considerada generalizado, superposición no considerada generalizado, superposición considerada Figura 8: Impacto de α en MAP inex-2003 (temas CO de INEX 2004; conjunto de evaluación I). se trazan para valores de α entre 0.0 y 1.0. Recordando que la métrica XCG está diseñada para penalizar la superposición, mientras que la métrica inex-2002 ignora la superposición, el conflicto entre las métricas es evidente. Los valores de MAP en un extremo (α = 0.0) y el valor de XCG en el otro extremo (α = 1.0) representan un rendimiento de recuperación comparable a los mejores sistemas en INEX 2004 [8,12]. La Figura 8 muestra los valores de la métrica MAP inex-2003 para dos cuantificaciones, con y sin consideración de la superposición. Una vez más, el conflicto es evidente, con la influencia de α considerablemente disminuida cuando se considera la superposición. 8. ALGORITMO EXTENDIDO Una limitación del algoritmo de reordenamiento es que se utiliza un único peso α para ajustar las puntuaciones tanto de los ancestros como de los descendientes de los elementos informados. Una extensión obvia es usar diferentes pesos en estos dos casos. Además, se utiliza el mismo peso independientemente de cuántas veces un elemento esté contenido en un elemento informado. Por ejemplo, un párrafo puede formar parte de una sección reportada y luego formar parte de un artículo reportado. Dado que el usuario puede haber visto este párrafo dos veces, su puntuación debería ser reducida aún más aumentando el valor del peso. Motivado por estas observaciones, el algoritmo de reordenamiento puede ser extendido con una serie de pesos 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βM ≥ 0, donde βj es el peso aplicado a un nodo que ha sido descendiente de un nodo reportado j veces. Ten en cuenta que un límite superior en M es h, la altura máxima de cualquier árbol XML en la colección. Sin embargo, en la práctica es probable que M sea relativamente pequeño (quizás 3 o 4). La Figura 9 presenta reemplazos para las rutinas de Subir y Bajar de la Figura 6, incorporando esta serie de pesas. Se requiere un campo adicional en cada nodo, de la siguiente manera: x.j - conteo descendente El valor de x.j se establece inicialmente en cero en todos los nodos y se incrementa cada vez que se llama a Down con x como su argumento. Al calcular la puntuación del nodo, el valor de x.j selecciona 1 Up(x, y) ≡ 2 si no y.reported entonces 3 S.remove(y) 4 y.g ← y.g + x.f − x.g 5 recalcular y.score 6 S.add(y) 8 si y no es un nodo raíz entonces 9 Up (x, y.padre) 10 fin si 11 fin si 12 13 Down(x) ≡ 14 si x.j < M entonces 15 x.j ← x.j + 1 16 si no x.reported entonces 17 S.remove(x) 18 recalcular x.score 19 S.add(x) 20 fin si 21 para cada y ∈ x.hijos hacer 22 Down (y) 23 fin hacer 24 fin si Figura 9: Rutinas extendidas de recorrido de árbol. el peso a aplicar al nodo ajustando el valor de xt en la ecuación 1, de la siguiente manera: xt = βx.j · (ft − α · gt) (3) donde ft y gt son los componentes de x.f y x.g correspondientes al término t. Se requieren algunos cambios adicionales para extender Up y Down. La rutina Up devuelve inmediatamente (línea 2) si su argumento ya ha sido reportado, ya que las frecuencias de términos ya han sido ajustadas en sus ancestros. El procedimiento Down no informa su argumento, sino que vuelve a calcular su puntuación y la agrega de nuevo a S. Un nodo no puede ser un argumento de Down más de M +1 veces, lo que a su vez implica una complejidad temporal total de O((nM + mh) log n). Dado que M ≤ h y m ≤ n, la complejidad temporal también es O(nh log n). DISCUSIÓN CONCLUSIVA Al generar resultados de recuperación en una colección de XML, se debe tolerar cierta superposición en los resultados, lo cual puede ser beneficioso. Por ejemplo, cuando un elemento altamente exhaustivo y bastante específico (3,2) contiene un elemento mucho más pequeño (2,3), ambos deben ser informados al usuario, y los algoritmos de recuperación y las métricas de evaluación deben respetar esta relación. El algoritmo presentado en este documento controla la superposición ponderando los términos que aparecen en los elementos informados para reflejar su menor importancia. Otros enfoques también pueden ayudar a controlar la superposición. Por ejemplo, cuando se presentan los resultados de recuperación de XML a los usuarios, puede ser deseable agrupar elementos relacionados estructuralmente juntos, ilustrando visualmente las relaciones entre ellos. Si bien este estilo de interfaz de usuario puede ayudar a un usuario a lidiar con la superposición, la estrategia presentada en este documento sigue siendo aplicable, al determinar los mejores elementos para incluir en cada grupo. En Waterloo, seguimos desarrollando y probando nuestras ideas para INEX 2005. En particular, estamos investigando métodos para aprender los pesos α y βj. También estamos reevaluando nuestro enfoque en las estadísticas de documentos y examinando ajustes apropiados al parámetro k1 a medida que cambian los pesos de los términos [20]. 10. AGRADECIMIENTOS Gracias a Gabriella Kazai y Arjen de Vries por proporcionar una versión temprana de su software para calcular la métrica XCG, y gracias a Phil Tilker y Stefan B¨uttcher por su ayuda con la evaluación experimental. En parte, la financiación para este proyecto fue proporcionada por IBM Canadá a través del Instituto Nacional de Investigación de Software. 11. REFERENCIAS [1] N. Bruno, N. Koudas y D. Srivastava. Uniones de ramas holísticas: Coincidencia óptima de patrones XML. En Actas de la Conferencia Internacional ACM SIGMOD 2002 sobre la Gestión de Datos, páginas 310-321, Madison, Wisconsin, junio de 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y. Masa y A. Soffer. Buscando documentos XML a través de fragmentos XML. En Actas de la 26ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 151-158, Toronto, Canadá, 2003. [3] C. L. A. Clarke y P. L. Tilker. Experimentos MultiText para INEX 2004. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [4] A. P. de Vries, G. Kazai y M. Lalmas. Tolerancia a la irrelevancia: Una evaluación orientada al esfuerzo del usuario de sistemas de recuperación sin unidad de recuperación predefinida. En las Actas de la Conferencia RIAO 2004, páginas 463-473, Aviñón, Francia, abril de 2004. [5] D. DeHaan, D. Toman, M. P. Consens y M. T. ¨Ozsu. Una traducción exhaustiva de XQuery a SQL utilizando codificación dinámica de intervalos. En Actas de la Conferencia Internacional ACM SIGMOD 2003 sobre la Gestión de Datos, San Diego, junio de 2003. [6] N. Fuhr y K. Großjohann. XIRQL: Un lenguaje de consulta para la recuperación de información en documentos XML. En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 172-180, Nueva Orleans, septiembre de 2001. [7] N. Fuhr, M. Lalmas y S. Malik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Segundo Taller (INEX 2003), Dagstuhl, Alemania, diciembre de 2003. [8] N. Fuhr, M. Lalmas, S. Malik y Zoltán Szlávik, editores. Iniciativa para la Evaluación de la Recuperación de XML. Actas del Tercer Taller (INEX 2004), Dagstuhl, Alemania, diciembre de 2004. Publicado como Avances en la Recuperación de Información XML, Notas de Conferencia en Ciencias de la Computación, volumen 3493, Springer, 2005. [9] K. J¨avelin y J. Kek¨al¨ainen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [10] J. Kamps, M. de Rijke, y B. Sigurbjörnsson. Normalización de longitud en la recuperación de XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 80-87, Sheffield, Reino Unido, julio de 2004. [11] G. Kazai, M. Lalmas y A. P. de Vries. El problema de superposición en la evaluación de la recuperación de XML orientada al contenido. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 72-79, Sheffield, Reino Unido, julio de 2004. [12] G. Kazai, M. Lalmas y A. P. de Vries. Pruebas de confiabilidad para las métricas XCG e inex-2002. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [13] J. Kek¨al¨ainen, M. Junkkari, P. Arvola y T. Aalto. TRIX 2004 - Luchando con la superposición. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [14] S. Liu, Q. Zou y W. W. Chu. Indexación y clasificación configurables para la recuperación de información en XML. En Actas de la 27ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 88-95, Sheffield, Reino Unido, julio de 2004. [15] Y. Masa y M. Mandelbrot. Recuperando los componentes XML más relevantes. En las Actas del Taller INEX 2003, Dagstuhl, Alemania, diciembre de 2003. [16] Y. Masa y M. Mandelbrot. Clasificación de componentes y refinamiento automático de consultas para la recuperación de XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [17] P. Ogilvie y J. Callan. Modelos de lenguaje jerárquicos para la recuperación de componentes XML. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [18] J. Pehcevski, J. A. Thom y A. Vercoustre. Recuperación híbrida de XML revisitada. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [19] B. Piwowarski y M. Lalmas. Proporcionando evaluaciones de relevancia consistentes y exhaustivas para la evaluación de recuperación de XML. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 361-370, Washington, DC, noviembre de 2004. [20] S. Robertson, H. Zaragoza y M. Taylor. Extensión simple de BM25 a múltiples campos ponderados. En Actas de la 13ª Conferencia de la ACM sobre Gestión de la Información y el Conocimiento, páginas 42-50, Washington, DC, noviembre de 2004. [21] S. E. Robertson, S. Walker y M. Beaulieu. Okapi en TREC-7: Búsqueda automática, filtrado, VLC y pista interactiva. En Actas de la Séptima Conferencia de Recuperación de Texto, Gaithersburg, MD, noviembre de 1998. [22] A. Trotman y B. Sigurbjörnsson. NEXI, ahora y después. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. [23] J. Vittaut, B. Piwowarski y P. Gallinari. Un álgebra para consultas estructuradas en redes bayesianas. En Actas del Taller INEX 2004, 2004. Publicado en LNCS 3493 [8]. ",
            "candidates": [],
            "error": [
                [
                    "rango",
                    "clasificar",
                    "clasificar"
                ]
            ]
        }
    }
}