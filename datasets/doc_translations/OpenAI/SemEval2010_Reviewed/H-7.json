{
    "id": "H-7",
    "original_text": "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest. A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model. Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive. The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications. This paper proposes a new fast learning technique to learn a large number of individual user profiles. The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens. Categories and Subject Descriptors: B.3.3 [Information Search and Retrieval]: Information filtering General Terms: Algorithms 1. INTRODUCTION Personalization is the future of the Web, and it has achieved great success in industrial applications. For example, online stores, such as Amazon and Netflix, provide customized recommendations for additional products or services based on a users history. Recent offerings such as My MSN, My Yahoo!, My Google, and Google News have attracted much attention due to their potential ability to infer a users interests from his/her history. One major personalization topic studied in the information retrieval community is content-based personal recommendation systems1 . These systems learn user-specific profiles from user feedback so that they can recommend information tailored to each individual users interest without requiring the user to make an explicit query. Learning the user profiles is the core problem for these systems. A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user. One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small. This is known as the cold start problem. This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile. There has been much research on improving classification accuracy when the amount of labeled training data is small. The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal [26]. Another approach is using domain knowledge. Researchers have modified different learning algorithms, such as Na¨ıveBayes [17], logistic regression [7], and SVMs [22], to integrate domain knowledge into a text classifier. The third approach is borrowing training data from other resources [5][7]. The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data. One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach. Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial performance for each user[27][25]. In order to learn a Bayesian hierarchical model, the system usually tries to find the most likely model parameters for the given data. A mature recommendation system usually works for millions of users. It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users. The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee. However, a content based recommendation system often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector. With careful analysis of the EM algorithm in this scenario (Section 4), we find that the EM tering, or item-based collaborative filtering. In this paper, the words filtering and recommendation are used interchangeably. algorithm converges very slowly due to the sparseness of the input variables. We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O(MK), where M is the number of users and K is the number of dimensions. This paper modifies the standard EM algorithm to create an improved learning algorithm, which we call the Modified EM algorithm. The basic idea is that instead of calculating the numerical solution for all the user profile parameters, we derive the analytical solution of the parameters for some feature dimensions, and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters. This greatly reduces the computation at a single EM iteration, and also has the benefit of increasing the convergence speed of the learning algorithm. The proposed technique is not only well supported by theory, but also by experimental results. The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression modeling framework used for content-based recommendations. Section 4 describes how to learn the model parameters using the standard EM algorithm, along with using the new technique proposed in this paper. The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6. Section 7 summarizes and offers concluding remarks. 2. RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the IR community since the 1970s. The approaches that have been used to solve this problem can be roughly classified into two major categories: content based filtering versus collaborative filtering. Content-based filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user. The user may read the delivered documents and provide explicit relevance feedback, which the filtering system then uses to update the users profile using relevance feedback retrieval models (e.g. Boolean models, vector space models, traditional probabilistic models [20] , inference networks [3] and language models [6]) or machine learning algorithms (e.g. Support Vector Machines (SVM), K nearest neighbors (K-NN) clustering, neural networks, logistic regression, or Winnow [16] [4] [23]). Collaborative filtering goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past. Memorybased heuristics and model based approaches have been used in collaborative filtering task [15] [8] [2] [14] [12] [11]. This paper contributes to the content-based recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks[27][25]. This paper does not intend to compare content-based filtering with collaborative filtering or claim which one is a better. We think each complements the other, and that content-based filtering is extremely useful for handling new documents/items with little or no user feedback. Similar to some other researchers[18][1][21], we found that a recommendation system will be more effective when both techniques are combined. However, this is beyond the scope of this paper and thus not discussed here. 3. BAYESIAN HIERARCHICAL LINEAR REGRESSION Assume there are M users in the system. The task of the system is to recommend documents that are relevant to each user. For each user, the system learns a user model from the users history. In the rest of this paper, we will use the following notations to represent the variables in the system. m = 1, 2, ..., M: The index for each individual user. M is the total number of users. wm: The user model parameter associated with user m. wm is a K dimensional vector. j = 1, 2, ..., Jm: The index for a set of data for user m. Jm is the number of training data for user m. Dm = {(xm,j, ym,j)}: A set of data associated with user m. xm,j is a K dimensional vector that represents the mth users jth training document.2 ym,j is a scalar that represents the label of document xm,j. k = 1, 2, ..., K: The dimensional index of input variable x. The Bayesian hierarchical modeling approach has been widely used in real-world information retrieval applications. Generalized Bayesian hierarchical linear models, one of the simplest Bayesian hierarchical models, are commonly used and have achieved good performance on collaborative filtering [25] and content-based adaptive filtering [27] tasks. Figure 1 shows the graphical representation of a Bayesian hierarchical model. In this graph, each user model is represented by a random vector wm. We assume a user model is sampled randomly from a prior distribution P(w|Φ). The system can predict the user label y of a document x given an estimation of wm (or wms distribution) using a function y = f(x, w). The model is called generalized Bayesian hierarchical linear model when y = f(wT x) is any generalized linear model such as logistic regression, SVM, and linear regression. To reliably estimate the user model wm, the system can borrow information from other users through the prior Φ = (µ, Σ). Now we look at one commonly used model where y = wT x + , where ∼ N(0, σ2 ) is a random noise [25][27]. Assume that each user model wm is an independent draw from a population distribution P(w|Φ), which is governed by some unknown hyperparameter Φ. Let the prior distribution of user model w be a Gaussian distribution with parameter Φ = (µ, Σ), which is the commonly used prior for linear models. µ = (µ1, µ2, ..., µK ) is a K dimensional vector that represents the mean of the Gaussian distribution, and Σ is the covariance matrix of the Gaussian. Usually, a Normal distribution N(0, aI) and an Inverse Wishart distribution P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) are used as hyperprior to model the prior distribution of µ and Σ respectively. I is the K dimensional identity matrix, and a, b, and c are real numbers. With these settings, we have the following model for the system: 1. µ and Σ are sampled from N(0, aI) and IWν (aI), respectively. 2 The first dimension of x is a dummy variable that always equals to 1. Figure 1: Illustration of dependencies of variables in the hierarchical model. The rating, y, for a document, x, is conditioned on the document and the user model, wm, associated with the user m. Users share information about their models through the prior, Φ = (µ, Σ). 2. For each user m, wm is sampled randomly from a Normal distribution: wm ∼ N(µ, Σ2 ) 3. For each item xm,j, ym,j is sampled randomly from a Normal distribution: ym,j ∼ N(wT mxm,j, σ2 ). Let θ = (Φ, w1, w2, ..., wM ) represent the parameters of this system that needs to be estimated. The joint likelihood for all the variables in the probabilistic model, which includes the data and the parameters, is: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) For simplicity, we assume a, b, c, and σ are provided to the system. 4. MODEL PARAMETER LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple linear regression. Therefore, we will focus on estimating Φ. The maximum a priori solution of Φ is given by ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Finding the optimal solution for the above problem is challenging, since we need to integrate over all w = (w1, w2, ..., wM ), which are unobserved hidden variables. 4.1 EM Algorithm for Bayesian Hierarchical Linear Models In Equation 5, Φ is the parameter needs to be estimated, and the result depends on unobserved latent variables w. This kind of optimization problem is usually solved by the EM algorithm. Applying EM to the above problem, the set of user models w are the unobservable hidden variables and we have: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw Based on the derivation of the EM formulas presented in [24], we have the following Expectation-Maximization steps for finding the optimal hyperparameters. For space considerations, we omit the derivation in this paper since it is not the focus of our work. E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of the prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) where Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j M step: Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Many machine learning driven IR systems use a point estimate of the parameters at different stages in the system. However, we are estimating the posterior distribution of the variables at the E step. This avoids overfitting wm to a particular users data, which may be small and noisy. A detailed discussion about this subject appears in [10]. 4.2 New Algorithm: Modified EM Although the EM algorithm is widely studied and used in machine learning applications, using the above EM process to solve Bayesian hierarchical linear models in large-scale information retrieval systems is still too computationally expensive. In this section, we describe why the learning rate of the EM algorithm is slow in our application and introduce a new technique to make the learning of the Bayesian hierarchical linear model scalable. The derivation of the new learning algorithm will be based on the EM algorithm described in the previous section. First, the covariance matrices Σ2 , Σ2 m are usually too large to be computationally feasible. For simplicity, and as a common practice in IR, we do not model the correlation between features. Thus we approximate these matrices with K dimensional diagonal matrices. In the rest of the paper, we use these symbols to represent their diagonal approximations: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     Secondly, and most importantly, the input space is very sparse and there are many dimensions that are not related to a particular user in a real IR application. For example, let us consider a movie recommendation system, with the input variable x representing a particular movie. For the jth movie that the user m has seen, let xm,j,k = 1 if the director of the movie is Jean-Pierre Jeunet (indexed by k). Here we assume that whether or not that this director directed a specific movie is represented by the kth dimension. If the user m has never seen a movie directed by Jean-Pierre Jeunet, then the corresponding dimension is always zero (xm,j,k = 0 for all j) . One major drawback of the EM algorithm is that the importance of a feature, µk, may be greatly dominated by users who have never encountered this feature (i.e. j xm,j,k = 0) at the M step (Equation 8). Assume that 100 out of 1 million users have viewed the movie directed by Jean-Pierre Jeunet, and that the viewers have rated all of his movies as excellent. Intuitively, he is a good director and the weight for him (µk) should be high. Before the EM iteration, the initial value of µ is usually set to 0. Since the other 999,900 users have not seen this movie, their corresponding weights (w1,k, w2,k, ..., wm,k..., w999900,k) for that director would be very small initially. Thus the corresponding weight of the director in the prior µk at the first M step would be very low , and the variance σm,k will be large (Equations 8 and 7). It is undesirable that users who have never seen any movie produced by the director influence the importance of the director so much. This makes the convergence of the standard EM algorithm very slow. Now lets look at whether we can improve the learning speed of the algorithm. Without a loss of generality, let us assume that the kth dimension of the input variable x is not related to a particular user m. By which we mean, xm,j,k = 0 for all j = 1, ..., Jm. It is straightforward to prove that the kth row and kth column of Sxx,m are completely filled with zeros, and that the kth dimension of Sxy,m is zeroed as well. Thus the corresponding kth dimension of the user models mean, ¯wm, should be equal to that of the prior: ¯wm,k = µk, with the corresponding covariance of σm,k = σk. At the M step, the standard EM algorithm uses the numerical solution of the distribution P(wm|Dm, Φ) estimated at E step (Equation 8 and Equation 7). However, the numerical solutions are very unreliable for ¯wm,k and σm,k when the kth dimension is not related to the mth user. A better approach is using the analytical solutions ¯wm,k = µk, and σm,k = σk for the unrelated (m, k) pairs, along with the numerical solution estimated at E step for the other (m, k) pairs. Thus we get the following new EM-like algorithm: Modified E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) where sxx,m,k = j x2 m,j,k and sxy,m,k = j xm,j,kym,j Modified M Step Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step for related userfeature pairs. The M step implicitly uses the analytical solution for unrelated user-feature pairs. µk = 1 Mk m:related ¯wm,k (12) σ2 k = 1 Mk m:related σ2 m,k +( ¯wm,k − µk)( ¯wm,k − µk)T (13) where Mk is the number of users that are related to feature k We only estimate the diagonal of Σ2 m and Σ since we are using the diagonal approximation of the covariance matrices. To estimate ¯wm, we only need to calculate the numerical solutions for dimensions that are related to user m. To estimate σ2 k and µk, we only sum over users that are related to the kth feature. There are two major benefits of the new algorithm. First, because only the related (m, k) pairs are needed at the modified M step, the computational complexity in a single EM iteration is much smaller when the data is sparse, and many of (m, k) pairs are unrelated. Second, the parameters estimated at the modified M step (Equations 12 - 13) are more accurate than the standard M step described in Section 4.1 because the exact analytical solutions ¯wm,k = µk and σm,k = σk for the unrelated (m, k) pairs were used in the new algorithm instead of an approximate solution as in the standard algorithm. 5. EXPERIMENTAL METHODOLOGY 5.1 Evaluation Data Set To evaluate the proposed technique, we used the following three major data sets (Table 1): MovieLens Data: This data set was created by combining the relevance judgments from the MovieLens[9] data set with documents from the Internet Movie Database (IMDB). MovieLens allows users to rank how much he/she enjoyed a specific movie on a scale from 1 to 5. This likeability rating was used as a measurement of how relevant the document representing the corresponding movie is to the user. We considered documents with likeability scores of 4 or 5 as relevant, and documents with a score of 1 to 3 as irrelevant to the user. MovieLens provided relevance judgments on 3,057 documents from 6,040 separate users. On average, each user rated 151 movies, of these 87 were judged to be relevant. The average score for a document was 3.58. Documents representing each movie were constructed from the portion of the IMDB database that is available for public download[13]. Based on this database, we created one document per movie that contained the relevant information about it (e.g. directors, actors, etc.). Table 1: Data Set Statistics. On Reuters, the number of rating for a simulated user is the number of documents relevant to the corresponding topic. Data Users Docs Ratings per User MovieLens 6,040 3,057 151 Netflix-all 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Netflix Data: This data set was constructed by combining documents about movies crawled from the web with a set of actual movie rental customer relevance judgments from Netflix[19]. Netflix publicly provides the relevance judgments of 480,189 anonymous customers. There are around 100 million rating on a scale of 1 to 5 for 17,770 documents. Similar to MovieLens, we considered documents with likeability scores of 4 or 5 as relevant. This number was reduced to 1000 customers through random sampling. The average customer on the reduced data set provided 127 judgments, with 70 being deemed relevant. The average score for documents is 3.55. Reuters Data: This is the Reuters Corpus, Volume 1. It covers 810,000 Reuters English language news stories from August 20, 1996 to August 19, 1997. Only the first 100,000 news were used in our experiments. The Reuters corpus comes with a topic hierarchy. Each document is assigned to one of several locations on the hierarchical tree. The first level of the tree contains four topics, denoted as C, E, M, and G. For the experiments in this paper, the tree was cut at level 1 to create four smaller trees, each of which corresponds to one smaller data set: Reuters-E Reuters-C, ReutersM and Reuters-G. For each small data set, we created several profiles, one profile for each node in a sub-tree, to simulate multiple users, each with a related, yet separate definition of relevance. All the user profiles on a sub-tree are supposed to share the same prior model distribution. Since this corpus explicitly indicates only the relevant documents for a topic(user), all other documents are considered irrelevant. 5.2 Evaluation We designed the experiments to answer the following three questions: 1. Do we need to take the effort to use a Bayesian approach and learn a prior from other users? 2. Does the new algorithm work better than the standard EM algorithm for learning the Bayesian hierarchical linear model? 3. Can the new algorithm quickly learn many user models? To answer the first question, we compared the Bayesian hierarchical models with commonly used Norm-2 regularized linear regression models. In fact, the commonly used approach is equivalent to the model learned at the end of the first EM iteration. To answer the second question, we compared the proposed new algorithm with the standard EM algorithm to see whether the new learning algorithm is better. To answer the third question, we tested the efficiency of the new algorithm on the entire Netflix data set where about half a million user models need to be learned together. For the MovieLens and Netflix data sets, algorithm effectiveness was measured by mean square error, while on the Reuters data set classification error was used because it was more informative. We first evaluated the performance on each individual user, and then estimated the macro average over all users. Statistical tests (t-tests) were carried out to see whether the results are significant. For the experiments on the MovieLens and Netflix data sets, we used a random sample of 90% of each user for training, and the rest for testing. On Reuters data set, because there are too many relevant documents for each topic in the corpus, we used a random sample of 10% of each topic for training, and 10% of the remaining documents for testing. For all runs, we set (a, b, c, Σ ) = (0.1, 10, 0.1, 1) manually. 6. EXPERIMENTAL RESULTS Figure 2, Figure 3, and Figure 4 show that on all data sets, the Bayesian hierarchical modeling approach has a statistical significant improvement over the regularized linear regression model, which is equivalent to the Bayesian hierarchical models learned at the first iteration. Further analysis shows a negative correlation between the number of training data for a user and the improvement the system gets. This suggests that the borrowing information from other users has more significant improvements for users with less training data, which is as expected. However, the strength of the correlation differs over data sets, and the amount of training data is not the only characteristics that will influence the final performance. Figure 2 and Figure 3 show that the proposed new algorithm works better than the standard EM algorithm on the Netflix and MovieLens data sets. This is not surprising since the number of related feature-users pairs is much smaller than the number of unrelated feature-user pairs on these two data sets, and thus the proposed new algorithm is expected to work better. Figure 4 shows that the two algorithms work similarly on the Reuters-E data set. The accuracy of the new algorithm is similar to that of the standard EM algorithm at each iteration. The general patterns are very similar on other Reuters subsets. Further analysis shows that only 58% of the user-feature pairs are unrelated on this data set. Since the number of unrelated user-feature pairs is not extremely large, the sparseness is not a serious problem on the Reuters data set. Thus the two learning algorithms perform similarly. The results suggest that only on a corpus where the number of unrelated user-feature pairs is much larger than the number of related pairs, such as on the Netflix data set, the proposed technique will get a significant improvement over standard EM. However, the experiments also show that when the assumption does not hold, the new algorithm does not hurt performance. Although the proposed technique is faster than standard Figure 2: Performance on a Netflix subset with 1,000 users. The new algorithm is statistical significantly better than EM algorithm at iterations 2 - 10. Norm-2 regularized linear models are equivalent to the Bayesian hierarchical models learned at the first iteration, and are statistical significantly worse than the Bayesian hierarchical models. 0 2 4 6 8 10 1 1.05 1.1 1.15 1.2 1.25 1.3 1.35 1.4 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iterations ClassificationError New Algorithm Traditional EM Figure 3: Performance on a MovieLens subset with 1,000 users. The new algorithm is statistical significantly better than EM algorithm at iteration 2 to 17 (evaluated with mean square error). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iterations MeanSquareError New Algorithm Traditional EM 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iterations ClassificationError New Algorithm Traditional EM Figure 4: Performance on a Reuters-E subset with 26 profiles. Performances on Reuters-C, Reuters-M, Reuters-G are similar. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iterations ClassificationError New Algorithm Traditional EM EM, can it really learn millions of user models quickly? Our results show that the modified EM algorithm converges quickly, and 2 - 3 modified EM iterations would result in a reliable estimation. We evaluated the algorithm on the whole Netflix data set (480,189 users, 159,836 features, and 100 million ratings) running on a single CPU PC (2GB memory, P4 3GHz). The system finished one modified EM iteration in about 4 hours. This demonstrates that the proposed technique can efficiently handle large-scale system like Netflix. 7. CONCLUSION Content-based user profile learning is an important problem and is the key to providing personal recommendations to a user, especially for recommending new items with a small number of ratings. The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors. This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM. We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm. Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse, by which we mean the ratio of related user-feature pairs to unrelated pairs is small. Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold. In general, it is better to use the new algorithm since it is as simple as standard EM, the performance is either better or similar to EM, and the computation complexity is lower at each iteration. It is worth mentioning that even if the original problem space is not sparse, sparseness can be created artificially when a recommendation system uses user-specific feature selection techniques to reduce the noise and user model complexity. The proposed technique can also be adapted to improve the learning in such a scenario. We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU. The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear modeling approach to build a practical large scale system, even though the literature have demonstrated the effectiveness of the models in many applications. Our work is one major step on the road to make Bayesian hierarchical linear models more practical. The proposed new technique can be easily adapted to run on a cluster of machines, and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users. The research has much potential to benefit people using EM algorithm on many other IR problems as well as machine learning problems. EM algorithm is a commonly used machine learning technique. It is used to find model parameters in many IR problems where the training data is very sparse. Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering, the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems. 8. ACKNOWLEDGMENTS We thank Wei Xu, David Lewis and anonymous reviewers for valuable feedback on the work described in this paper. Part of the work was supported by Yahoo, Google, the Petascale Data Storage Institute and the Institute for Scalable Scientific Data Management. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors, and do not necessarily reflect those of the sponsors. 9. REFERENCES [1] C. Basu, H. Hirsh, and W. Cohen. Recommendation as classification: Using social and content-based information in recommendation. In Proceedings of the Fifteenth National Conference on Artificial Intelligence, 1998. [2] J. S. Breese, D. Heckerman, and C. Kadie. Empirical analysis of predictive algorithms for collaborative filtering. Technical report, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan. Document filtering with inference networks. In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor, and A. Vinokourov. Kernel method for document filtering. In The Eleventh Text REtrieval Conference (TREC11). National Institute of Standards and Technology, special publication 500-249, 2003. [5] C. Chelba and A. Acero. Adaptation of maximum entropy capitalizer: Little data can help a lot. In D. Lin and D. Wu, editors, Proceedings of EMNLP 2004, pages 285-292, Barcelona, Spain, July 2004. Association for Computational Linguistics. [6] B. Croft and J. Lafferty, editors. Language Modeling for Information Retrieval. Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov, and A. Genkin. Constructing informative prior distributions from domain knowledge in text classification. In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 493-500, New York, NY, USA, 2006. ACM Press. [8] J. Delgado and N. Ishii. Memory-based weightedmajority prediction for recommender systems. In ACM SIGIR99 Workshop on Recommender Systems, 1999. [9] GroupLens. Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman. A tutorial on learning with bayesian networks. In M. Jordan, editor, Learning in Graphical Models. Kluwer Academic, 1998. [11] J. L. Herlocker, J. A. Konstan, A. Borchers, and J. Riedl. An algorithmic framework for performing collaborative filtering. In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 230-237, New York, NY, USA, 1999. ACM Press. [12] T. Hofmann and J. Puzicha. Latent class models for collaborative filtering. In IJCAI 99: Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 688-693, San Francisco, CA, USA, 1999. Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB). Internet movie database. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai, and L. Si. An automatic weighting scheme for collaborative filtering. In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 337-344, New York, NY, USA, 2004. ACM Press. [15] J. A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl. GroupLens: Applying collaborative filtering to Usenet news. Communications of the ACM, 40(3):77-87, 1997. [16] D. Lewis. Applying support vector machines to the TREC-2001 batch filtering and routing tasks. In Proceedings of the Eleventh Text REtrieval Conference (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee, , and P. Yu. Text classification by labeling words. In Proceedings of The Nineteenth National Conference on Artificial Intelligence (AAAI-2004), July 25-29, 2004. [18] P. Melville, R. J. Mooney, and R. Nagarajan. Content-boosted collaborative filtering for improved recommendations. In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002), Edmonton, Canada, 2002. [19] Netflix. Netflix prize. http://www.netflixprize.com (visited on Nov. 30, 2006), 2006. [20] S. Robertson and K. Sparck-Jones. Relevance weighting of search terms. In Journal of the American Society for Information Science, volume 27, pages 129-146, 1976. [21] J. Wang, A. P. de Vries, and M. J. T. Reinders. Unifying user-based and item-based collaborative filtering approaches by similarity fusion. In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 501-508, New York, NY, USA, 2006. ACM Press. [22] X. Wu and R. K. Srihari. Incorporating prior knowledge with weighted margin support vector machines. In Proc. ACM Knowledge Discovery Data Mining Conf.(ACM SIGKDD 2004), Aug. 2004. [23] Y. Yang, S. Yoo, J. Zhang, and B. Kisiel. Robustness of adaptive filtering methods in a cross-benchmark evaluation. In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2005. [24] K. Yu, V. Tresp, and A. Schwaighofer. Learning gaussian processes from multiple tasks. In ICML 05: Proceedings of the 22nd international conference on Machine learning, pages 1012-1019, New York, NY, USA, 2005. ACM Press. [25] K. Yu, V. Tresp, and S. Yu. A nonparametric hierarchical bayesian framework for information filtering. In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 353-360. ACM Press, 2004. [26] X. Zhu. Semi-supervised learning literature survey. Technical report, University of Wisconsin - Madison, December 9, 2006. [27] P. Zigoris and Y. Zhang. Bayesian adaptive user profiling with explicit & implicit feedback. In Conference on Information and Knowledge Mangement 2006, 2006.",
    "original_translation": "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual. Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un modelo jerárquico bayesiano. Aprender los parámetros del modelo para optimizar la verosimilitud conjunta de los datos de millones de usuarios es muy costoso computacionalmente. El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de datos en aplicaciones de IR. Este documento propone una nueva técnica de aprendizaje rápido para aprender un gran número de perfiles de usuario individuales. La eficacia y eficiencia del algoritmo propuesto están justificadas por la teoría y demostradas en datos reales de usuarios de Netflix y MovieLens. Categorías y Descriptores de Asignaturas: B.3.3 [Búsqueda y Recuperación de Información]: Filtrado de información Términos Generales: Algoritmos 1. La personalización es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales. Por ejemplo, las tiendas en línea, como Amazon y Netflix, ofrecen recomendaciones personalizadas de productos o servicios adicionales basadas en el historial de un usuario. Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de un usuario a partir de su historial. Un tema importante de personalización estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados basados en el contenido. Estos sistemas aprenden perfiles específicos de usuario a partir de la retroalimentación del usuario para poder recomendar información adaptada a los intereses de cada usuario sin necesidad de que el usuario realice una consulta explícita. Aprender los perfiles de usuario es el problema central de estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica qué tan relevante es un documento para el usuario. Uno de los principales desafíos de construir un sistema de recomendación o personalización es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña. Esto se conoce como el problema de inicio en frío. Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente retroalimentación de ese usuario para aprender un perfil de usuario confiable. Se ha realizado mucha investigación sobre cómo mejorar la precisión de clasificación cuando la cantidad de datos de entrenamiento etiquetados es pequeña. El enfoque de aprendizaje semisupervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26]. Otro enfoque es utilizar el conocimiento del dominio. Los investigadores han modificado diferentes algoritmos de aprendizaje, como NaïveBayes [17], regresión logística [7] y SVMs [22], para integrar el conocimiento del dominio en un clasificador de texto. El tercer enfoque consiste en tomar datos de entrenamiento de otros recursos [5][7]. La efectividad de estos enfoques diferentes es mixta, debido a qué tan bien se ajusta la suposición del modelo subyacente a los datos. Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano. Varios investigadores han demostrado que este enfoque intercambia eficazmente entre la información compartida y la específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario[27][25]. Para aprender un modelo jerárquico bayesiano, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados. Un sistema de recomendación maduro generalmente funciona para millones de usuarios. Es bien sabido que aprender los parámetros óptimos de un modelo jerárquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios. El algoritmo EM es una técnica comúnmente utilizada para el aprendizaje de parámetros debido a su simplicidad y garantía de convergencia. Sin embargo, un sistema de recomendación basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso. Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM tering, o filtrado colaborativo basado en elementos. En este documento, las palabras filtrado y recomendación se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de las variables de entrada. También encontramos que actualizar el parámetro del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones. Este documento modifica el algoritmo EM estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos algoritmo EM modificado. La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M utilizamos la solución analítica en lugar de la solución numérica estimada en el paso E para esos parámetros. Esto reduce considerablemente la computación en una sola iteración de EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales. La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de regresión lineal jerárquica bayesiana utilizado para recomendaciones basadas en contenido. La sección 4 describe cómo aprender los parámetros del modelo utilizando el algoritmo EM estándar, junto con el uso de la nueva técnica propuesta en este artículo. La configuración experimental y los resultados utilizados para validar la técnica de aprendizaje propuesta se informan en las Secciones 5 y 6. La sección 7 resume y ofrece observaciones finales. 2. TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de IR desde la década de 1970. Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus filtrado colaborativo. El filtrado basado en contenido estudia el escenario en el que un sistema de recomendación monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente. El usuario puede leer los documentos entregados y proporcionar retroalimentación explícita de relevancia, la cual el sistema de filtrado utiliza para actualizar el perfil del usuario mediante modelos de recuperación de retroalimentación de relevancia (por ejemplo,). Modelos booleanos, modelos de espacio vectorial, modelos probabilísticos tradicionales [20], redes de inferencia [3] y modelos de lenguaje [6]) o algoritmos de aprendizaje automático (por ejemplo, Máquinas de Vectores de Soporte (SVM), agrupamiento de K vecinos más cercanos (K-NN), redes neuronales, regresión logística o Winnow [16] [4] [23]. El filtrado colaborativo va más allá de simplemente usar el contenido de un documento para recomendar elementos a un usuario, aprovechando la información de otros usuarios con gustos y preferencias similares en el pasado. Se han utilizado heurísticas basadas en memoria y enfoques basados en modelos en la tarea de filtrado colaborativo [15] [8] [2] [14] [12] [11]. Este artículo contribuye a la investigación de recomendaciones basadas en contenido al mejorar la eficiencia y efectividad de los modelos lineales jerárquicos bayesianos, los cuales tienen una sólida base teórica y un buen rendimiento empírico en tareas de recomendación[27][25]. Este artículo no tiene la intención de comparar el filtrado basado en contenido con el filtrado colaborativo ni de afirmar cuál es mejor. Creemos que cada uno complementa al otro, y que el filtrado basado en contenido es extremadamente útil para manejar nuevos documentos/artículos con poco o ningún feedback del usuario. Similar a otros investigadores[18][1][21], encontramos que un sistema de recomendación será más efectivo cuando se combinan ambas técnicas. Sin embargo, esto está fuera del alcance de este documento y, por lo tanto, no se discute aquí. 3. REGRESIÓN LINEAL HIERÁRQUICA BAYESIANA Suponga que hay M usuarios en el sistema. La tarea del sistema es recomendar documentos que sean relevantes para cada usuario. Para cada usuario, el sistema aprende un modelo de usuario a partir del historial de los usuarios. En el resto de este documento, utilizaremos las siguientes notaciones para representar las variables en el sistema. m = 1, 2, ..., M: El índice para cada usuario individual. M es el número total de usuarios. wm: El parámetro del modelo de usuario asociado con el usuario m. wm es un vector de dimensión K. j = 1, 2, ..., Jm: El índice para un conjunto de datos para el usuario m. Jm es el número de datos de entrenamiento para el usuario m. Dm = {(xm,j, ym,j)}: Un conjunto de datos asociado con el usuario m. xm,j es un vector de dimensión K que representa el j-ésimo documento de entrenamiento del usuario m. ym,j es un escalar que representa la etiqueta del documento xm,j. k = 1, 2, ..., K: El índice dimensional de la variable de entrada x. El enfoque de modelado jerárquico bayesiano ha sido ampliamente utilizado en aplicaciones reales de recuperación de información. Los modelos lineales jerárquicos bayesianos generalizados, uno de los modelos jerárquicos bayesianos más simples, son comúnmente utilizados y han logrado un buen rendimiento en tareas de filtrado colaborativo [25] y filtrado adaptativo basado en contenido [27]. La Figura 1 muestra la representación gráfica de un modelo jerárquico bayesiano. En este gráfico, cada modelo de usuario está representado por un vector aleatorio wm. Suponemos que un modelo de usuario se muestrea aleatoriamente de una distribución previa P(w|Φ). El sistema puede predecir la etiqueta de usuario y de un documento x dado una estimación de wm (o distribución de wms) utilizando una función y = f(x, w). El modelo se llama modelo lineal jerárquico bayesiano generalizado cuando y = f(wT x) es cualquier modelo lineal generalizado como regresión logística, SVM y regresión lineal. Para estimar de manera confiable el modelo de usuario wm, el sistema puede obtener información de otros usuarios a través de la prior Φ = (µ, Σ). Ahora observamos un modelo comúnmente utilizado donde y = wT x + , donde ∼ N(0, σ2 ) es un ruido aleatorio [25][27]. Suponga que cada modelo de usuario wm es una muestra independiente de una distribución poblacional P(w|Φ), la cual está regida por un hiperparámetro desconocido Φ. Que la distribución previa del modelo de usuario w sea una distribución gaussiana con parámetro Φ = (µ, Σ), que es la distribución previa comúnmente utilizada para modelos lineales. µ = (µ1, µ2, ..., µK) es un vector de K dimensiones que representa la media de la distribución gaussiana, y Σ es la matriz de covarianza de la gaussiana. Normalmente, se utiliza una distribución Normal N(0, aI) y una distribución Inverse Wishart P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) como hiperprior para modelar la distribución previa de µ y Σ respectivamente. Yo es la matriz identidad de dimensión K, y a, b y c son números reales. Con esta configuración, tenemos el siguiente modelo para el sistema: 1. µ y Σ se muestrean de N(0, aI) e IWν (aI), respectivamente. 2. La primera dimensión de x es una variable ficticia que siempre es igual a 1. Figura 1: Ilustración de las dependencias de variables en el modelo jerárquico. La calificación, y, para un documento, x, está condicionada al documento y al modelo de usuario, wm, asociado con el usuario m. Los usuarios comparten información sobre sus modelos a través de la prior, Φ = (µ, Σ). Para cada usuario m, wm se muestrea aleatoriamente de una distribución Normal: wm ∼ N(µ, Σ2 ) 3. Para cada elemento xm,j, ym,j se muestrea aleatoriamente de una distribución Normal: ym,j ∼ N(wT mxm,j, σ2). Que θ = (Φ, w1, w2, ..., wM) represente los parámetros de este sistema que necesitan ser estimados. La verosimilitud conjunta de todas las variables en el modelo probabilístico, que incluye los datos y los parámetros, es: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) Para simplificar, asumimos que a, b, c y σ son proporcionados al sistema. 4. APRENDIZAJE DE PARÁMETROS DEL MODELO Si se conoce el prior Φ, encontrar el óptimo wm es sencillo: se trata de una regresión lineal simple. Por lo tanto, nos enfocaremos en estimar Φ. La solución a priori máxima de Φ se da por ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Encontrar la solución óptima para el problema anterior es desafiante, ya que necesitamos integrar sobre todos los w = (w1, w2, ..., wM), que son variables ocultas no observadas. 4.1 Algoritmo EM para Modelos Lineales Jerárquicos Bayesianos En la Ecuación 5, Φ es el parámetro que necesita ser estimado, y el resultado depende de las variables latentes no observadas w. Este tipo de problema de optimización suele resolverse mediante el algoritmo EM. Aplicando EM al problema anterior, el conjunto de modelos de usuario w son las variables ocultas no observables y tenemos: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw. Basándonos en la derivación de las fórmulas EM presentadas en [24], tenemos los siguientes pasos de Expectation-Maximization para encontrar los hiperparámetros óptimos. Por razones de espacio, omitimos la derivación en este artículo ya que no es el enfoque de nuestro trabajo. Paso E: Para cada usuario m, estime la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual del prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) donde Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j Paso M: Optimice el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Muchos sistemas de IR impulsados por aprendizaje automático utilizan una estimación puntual de los parámetros en diferentes etapas del sistema. Sin embargo, estamos estimando la distribución posterior de las variables en el paso E. Esto evita el sobreajuste de wm a los datos de un usuario en particular, que pueden ser pequeños y ruidosos. Una discusión detallada sobre este tema aparece en [10]. 4.2 Nuevo Algoritmo: EM Modificado. Aunque el algoritmo EM es ampliamente estudiado y utilizado en aplicaciones de aprendizaje automático, utilizar el proceso EM mencionado anteriormente para resolver modelos lineales jerárquicos bayesianos en sistemas de recuperación de información a gran escala sigue siendo demasiado costoso computacionalmente. En esta sección, describimos por qué la tasa de aprendizaje del algoritmo EM es lenta en nuestra aplicación e introducimos una nueva técnica para hacer que el aprendizaje del modelo lineal jerárquico bayesiano sea escalable. La derivación del nuevo algoritmo de aprendizaje estará basada en el algoritmo EM descrito en la sección anterior. Primero, las matrices de covarianza Σ2 , Σ2 m suelen ser demasiado grandes para ser computacionalmente factibles. Por simplicidad, y como práctica común en IR, no modelamos la correlación entre características. Así aproximamos estas matrices con matrices diagonales de dimensión K. En el resto del documento, utilizamos estos símbolos para representar sus aproximaciones diagonales: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     En segundo lugar, y lo más importante, el espacio de entrada es muy disperso y hay muchas dimensiones que no están relacionadas con un usuario particular en una aplicación de recuperación de información real. Por ejemplo, consideremos un sistema de recomendación de películas, con la variable de entrada x representando una película en particular. Para la j-ésima película que el usuario m ha visto, sea xm,j,k = 1 si el director de la película es Jean-Pierre Jeunet (indexado por k). Aquí asumimos que si este director dirigió una película específica está representado por la k-ésima dimensión. Si el usuario m nunca ha visto una película dirigida por Jean-Pierre Jeunet, entonces la dimensión correspondiente siempre es cero (xm,j,k = 0 para todos los j). Una desventaja importante del algoritmo EM es que la importancia de una característica, µk, puede estar fuertemente dominada por usuarios que nunca han encontrado esta característica (es decir, j xm,j,k = 0) en el paso M (Ecuación 8). Suponga que 100 de cada 1 millón de usuarios han visto la película dirigida por Jean-Pierre Jeunet, y que los espectadores han calificado todas sus películas como excelentes. Intuitivamente, él es un buen director y el peso para él (µk) debería ser alto. Antes de la iteración de EM, el valor inicial de µ suele establecerse en 0. Dado que los otros 999,900 usuarios no han visto esta película, sus pesos correspondientes (w1,k, w2,k, ..., wm,k..., w999900,k) para ese director serían muy pequeños inicialmente. Por lo tanto, el peso correspondiente del director en el µk anterior en el primer paso M sería muy bajo, y la varianza σm,k será grande (Ecuaciones 8 y 7). Es indeseable que los usuarios que nunca han visto ninguna película producida por el director influyan tanto en la importancia del director. Esto hace que la convergencia del algoritmo EM estándar sea muy lenta. Ahora veamos si podemos mejorar la velocidad de aprendizaje del algoritmo. Sin pérdida de generalidad, asumamos que la k-ésima dimensión de la variable de entrada x no está relacionada con un usuario particular m. Lo que queremos decir es que xm,j,k = 0 para todo j = 1, ..., Jm. Es sencillo demostrar que la k-ésima fila y la k-ésima columna de Sxx,m están completamente llenas de ceros, y que la k-ésima dimensión de Sxy,m también se anula. Por lo tanto, la dimensión k correspondiente de la media de los modelos de usuario, ¯wm, debería ser igual a la del anterior: ¯wm,k = µk, con la covarianza correspondiente de σm,k = σk. En el paso M, el algoritmo EM estándar utiliza la solución numérica de la distribución P(wm|Dm, Φ) estimada en el paso E (Ecuación 8 y Ecuación 7). Sin embargo, las soluciones numéricas son muy poco confiables para ¯wm,k y σm,k cuando la k-ésima dimensión no está relacionada con el m-ésimo usuario. Un enfoque mejor es utilizar las soluciones analíticas ¯wm,k = µk, y σm,k = σk para los pares no relacionados (m, k), junto con la solución numérica estimada en el paso E para los otros pares (m, k). Así obtenemos el siguiente nuevo algoritmo EM similar: Paso E modificado: Para cada usuario m, estimar la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual de σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) donde sxx,m,k = j x2 m,j,k y sxy,m,k = j xm,j,kym,j Paso M modificado Optimizar el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E para pares de usuario-característica relacionados. El paso M utiliza implícitamente la solución analítica para pares de usuario-característica no relacionados. µk = 1 Mk m:relacionado ¯wm,k (12) σ2 k = 1 Mk m:relacionado σ2 m,k + ( ¯wm,k − µk)( ¯wm,k − µk)T (13) donde Mk es el número de usuarios relacionados con la característica k. Solo estimamos la diagonal de Σ2 m y Σ, ya que estamos utilizando la aproximación diagonal de las matrices de covarianza. Para estimar ¯wm, solo necesitamos calcular las soluciones numéricas para las dimensiones que están relacionadas con el usuario m. Para estimar σ2 k y µk, solo sumamos sobre los usuarios que están relacionados con la k-ésima característica. Hay dos beneficios principales del nuevo algoritmo. Primero, dado que solo se necesitan los pares relacionados (m, k) en el paso M modificado, la complejidad computacional en una sola iteración de EM es mucho menor cuando los datos son dispersos y muchos de los pares (m, k) no están relacionados. En segundo lugar, los parámetros estimados en el paso M modificado (Ecuaciones 12 - 13) son más precisos que el paso M estándar descrito en la Sección 4.1 porque se utilizaron soluciones analíticas exactas ¯wm,k = µk y σm,k = σk para los pares no relacionados (m, k) en el nuevo algoritmo en lugar de una solución aproximada como en el algoritmo estándar. METODOLOGÍA EXPERIMENTAL 5.1 Conjunto de Datos de Evaluación Para evaluar la técnica propuesta, utilizamos los siguientes tres conjuntos de datos principales (Tabla 1): Datos de MovieLens: Este conjunto de datos fue creado combinando las valoraciones de relevancia del conjunto de datos de MovieLens[9] con documentos de la Base de Datos de Películas en Internet (IMDB). MovieLens permite a los usuarios clasificar cuánto disfrutaron una película específica en una escala del 1 al 5. Esta calificación de simpatía se utilizó como una medida de cuán relevante es el documento que representa la película correspondiente para el usuario. Consideramos los documentos con puntuaciones de 4 o 5 como relevantes, y los documentos con una puntuación de 1 a 3 como irrelevantes para el usuario. MovieLens proporcionó juicios de relevancia sobre 3,057 documentos de 6,040 usuarios diferentes. En promedio, cada usuario calificó 151 películas, de las cuales 87 fueron consideradas relevantes. La puntuación promedio para un documento fue de 3.58. Los documentos que representan cada película fueron construidos a partir de la porción de la base de datos de IMDB que está disponible para descarga pública[13]. Basándonos en esta base de datos, creamos un documento por película que contenía la información relevante sobre ella (por ejemplo, directores, actores, etc.). Tabla 1: Estadísticas del conjunto de datos. En Reuters, el número de calificaciones para un usuario simulado es el número de documentos relevantes para el tema correspondiente. Datos Usuarios Documentos Calificaciones por Usuario MovieLens 6,040 3,057 151 Netflix-todos 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Datos de Netflix: Este conjunto de datos fue construido combinando documentos sobre películas obtenidos de la web con un conjunto de juicios de relevancia de clientes reales de alquiler de películas de Netflix[19]. Netflix proporciona públicamente las evaluaciones de relevancia de 480,189 clientes anónimos. Hay alrededor de 100 millones de calificaciones en una escala del 1 al 5 para 17,770 documentos. Similar a MovieLens, consideramos documentos con puntuaciones de 4 o 5 de agradabilidad como relevantes. Este número se redujo a 1000 clientes mediante muestreo aleatorio. El cliente promedio en el conjunto de datos reducido proporcionó 127 juicios, de los cuales 70 fueron considerados relevantes. La puntuación promedio de los documentos es de 3.55. Datos de Reuters: Este es el Corpus de Reuters, Volumen 1. Cubre 810,000 noticias en inglés de Reuters desde el 20 de agosto de 1996 hasta el 19 de agosto de 1997. Solo se utilizaron las primeras 100,000 noticias en nuestros experimentos. El corpus de Reuters viene con una jerarquía de temas. Cada documento se asigna a una de varias ubicaciones en el árbol jerárquico. El primer nivel del árbol contiene cuatro temas, denotados como C, E, M y G. Para los experimentos en este artículo, el árbol fue cortado en el nivel 1 para crear cuatro árboles más pequeños, cada uno de los cuales corresponde a un conjunto de datos más pequeño: Reuters-E, Reuters-C, Reuters-M y Reuters-G. Para cada conjunto de datos pequeño, creamos varios perfiles, un perfil para cada nodo en un subárbol, para simular múltiples usuarios, cada uno con una definición de relevancia relacionada pero separada. Todos los perfiles de usuario en una sub-rama se supone que comparten la misma distribución de modelo previo. Dado que este corpus indica explícitamente solo los documentos relevantes para un tema (usuario), todos los demás documentos se consideran irrelevantes. 5.2 Evaluación Diseñamos los experimentos para responder a las siguientes tres preguntas: 1. ¿Necesitamos hacer el esfuerzo de utilizar un enfoque bayesiano y aprender una distribución a priori de otros usuarios? 2. ¿El nuevo algoritmo funciona mejor que el algoritmo EM estándar para aprender el modelo lineal jerárquico bayesiano? 3. ¿Puede el nuevo algoritmo aprender rápidamente muchos modelos de usuario? Para responder a la primera pregunta, comparamos los modelos jerárquicos bayesianos con los modelos de regresión lineal regularizados Norm-2 comúnmente utilizados. De hecho, el enfoque comúnmente utilizado es equivalente al modelo aprendido al final de la primera iteración de EM. Para responder a la segunda pregunta, comparamos el nuevo algoritmo propuesto con el algoritmo EM estándar para ver si el nuevo algoritmo de aprendizaje es mejor. Para responder a la tercera pregunta, probamos la eficiencia del nuevo algoritmo en todo el conjunto de datos de Netflix, donde aproximadamente medio millón de modelos de usuario deben ser aprendidos juntos. Para los conjuntos de datos de MovieLens y Netflix, la efectividad del algoritmo se midió mediante el error cuadrático medio, mientras que en el conjunto de datos de Reuters se utilizó el error de clasificación porque era más informativo. Primero evaluamos el rendimiento en cada usuario individual, y luego estimamos el promedio macro sobre todos los usuarios. Se realizaron pruebas estadísticas (pruebas t) para determinar si los resultados son significativos. Para los experimentos en los conjuntos de datos de MovieLens y Netflix, utilizamos una muestra aleatoria del 90% de cada usuario para entrenamiento, y el resto para pruebas. En el conjunto de datos de Reuters, debido a que hay demasiados documentos relevantes para cada tema en el corpus, utilizamos una muestra aleatoria del 10% de cada tema para el entrenamiento, y el 10% de los documentos restantes para las pruebas. Para todas las ejecuciones, establecimos (a, b, c, Σ) = (0.1, 10, 0.1, 1) manualmente. 6. RESULTADOS EXPERIMENTALES Las Figuras 2, 3 y 4 muestran que en todos los conjuntos de datos, el enfoque de modelado jerárquico bayesiano tiene una mejora estadísticamente significativa sobre el modelo de regresión lineal regularizado, que es equivalente a los modelos jerárquicos bayesianos aprendidos en la primera iteración. Un análisis adicional muestra una correlación negativa entre la cantidad de datos de entrenamiento para un usuario y la mejora que obtiene el sistema. Esto sugiere que la información prestada de otros usuarios tiene mejoras más significativas para usuarios con menos datos de entrenamiento, lo cual es lo esperado. Sin embargo, la fuerza de la correlación varía entre los conjuntos de datos, y la cantidad de datos de entrenamiento no es la única característica que influirá en el rendimiento final. Las Figuras 2 y 3 muestran que el nuevo algoritmo propuesto funciona mejor que el algoritmo EM estándar en los conjuntos de datos de Netflix y MovieLens. Esto no es sorprendente ya que el número de pares de características-usuarios relacionados es mucho menor que el número de pares de características-usuarios no relacionados en estos dos conjuntos de datos, por lo que se espera que el nuevo algoritmo propuesto funcione mejor. La Figura 4 muestra que los dos algoritmos funcionan de manera similar en el conjunto de datos de Reuters-E. La precisión del nuevo algoritmo es similar a la del algoritmo EM estándar en cada iteración. Los patrones generales son muy similares en otros subconjuntos de Reuters. Un análisis adicional muestra que solo el 58% de los pares usuario-característica no están relacionados en este conjunto de datos. Dado que el número de pares usuario-característica no relacionados no es extremadamente grande, la dispersión no es un problema grave en el conjunto de datos de Reuters. Por lo tanto, los dos algoritmos de aprendizaje se desempeñan de manera similar. Los resultados sugieren que solo en un corpus donde el número de pares usuario-característica no relacionados es mucho mayor que el número de pares relacionados, como en el conjunto de datos de Netflix, la técnica propuesta obtendrá una mejora significativa sobre el EM estándar. Sin embargo, los experimentos también muestran que cuando la suposición no se cumple, el nuevo algoritmo no afecta el rendimiento. Aunque la técnica propuesta es más rápida que la estándar. Figura 2: Rendimiento en un subconjunto de Netflix con 1,000 usuarios. El nuevo algoritmo es estadísticamente significativamente mejor que el algoritmo EM en las iteraciones 2 a 10. Los modelos lineales regularizados con norma-2 son equivalentes a los modelos jerárquicos bayesianos aprendidos en la primera iteración, y son estadísticamente significativamente peores que los modelos jerárquicos bayesianos. Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional Figura 3: Rendimiento en un subconjunto de MovieLens con 1,000 usuarios. El nuevo algoritmo es significativamente mejor estadísticamente que el algoritmo EM en las iteraciones 2 a 17 (evaluado con error cuadrático medio). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iteraciones ErrorCuadráticoMedio Nuevo Algoritmo EM Tradicional 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iteraciones Error de Clasificación Nuevo Algoritmo EM Tradicional Figura 4: Rendimiento en un subconjunto de Reuters-E con 26 perfiles. Las actuaciones en Reuters-C, Reuters-M, Reuters-G son similares. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional EM, ¿realmente puede aprender rápidamente millones de modelos de usuario? Nuestros resultados muestran que el algoritmo EM modificado converge rápidamente, y 2-3 iteraciones del EM modificado darían como resultado una estimación confiable. Evaluamos el algoritmo en todo el conjunto de datos de Netflix (480,189 usuarios, 159,836 características y 100 millones de valoraciones) ejecutándolo en un solo PC con CPU (2GB de memoria, P4 3GHz). El sistema completó una iteración EM modificada en aproximadamente 4 horas. Esto demuestra que la técnica propuesta puede manejar eficientemente sistemas a gran escala como Netflix. CONCLUSIÓN El aprendizaje de perfiles de usuario basado en contenido es un problema importante y es clave para proporcionar recomendaciones personales a un usuario, especialmente para recomendar nuevos elementos con un pequeño número de calificaciones. El enfoque de modelado jerárquico bayesiano se está convirtiendo en un enfoque importante para el aprendizaje de perfiles de usuario debido a su capacidad teóricamente justificada para ayudar a un usuario a través de la transferencia de información de otros usuarios mediante hiperpriors. Este artículo examinó la debilidad del enfoque de aprendizaje basado en EM popular para modelos lineales jerárquicos bayesianos y propuso una técnica de aprendizaje mejorada llamada EM Modificado. Demostramos que la nueva técnica es teóricamente más eficiente computacionalmente que el algoritmo EM estándar. La evaluación en los conjuntos de datos de MovieLens y Netflix demostró la efectividad de la nueva técnica cuando los datos son dispersos, lo que significa que la proporción de pares de usuario-característica relacionados con respecto a los pares no relacionados es pequeña. La evaluación en el conjunto de datos de Reuters mostró que la nueva técnica tuvo un rendimiento similar al algoritmo EM estándar cuando la condición de dispersión no se cumple. En general, es mejor utilizar el nuevo algoritmo ya que es tan simple como el EM estándar, el rendimiento es igual o mejor que el del EM, y la complejidad computacional es menor en cada iteración. Vale la pena mencionar que aunque el espacio de problemas original no sea disperso, la dispersión puede crearse artificialmente cuando un sistema de recomendación utiliza técnicas de selección de características específicas del usuario para reducir el ruido y la complejidad del modelo del usuario. La técnica propuesta también puede adaptarse para mejorar el aprendizaje en dicho escenario. También demostramos que la técnica propuesta puede aprender medio millón de perfiles de usuario a partir de 100 millones de valoraciones en unas pocas horas con una sola CPU. La investigación es importante porque la escalabilidad es una preocupación importante para los investigadores al utilizar el enfoque de modelado lineal jerárquico bayesiano para construir un sistema a gran escala práctico, a pesar de que la literatura ha demostrado la efectividad de los modelos en muchas aplicaciones. Nuestro trabajo es un paso importante en el camino para hacer que los modelos lineales jerárquicos bayesianos sean más prácticos. La nueva técnica propuesta se puede adaptar fácilmente para ejecutarse en un clúster de máquinas, y así acelerar aún más el proceso de aprendizaje para manejar un sistema a mayor escala con cientos de millones de usuarios. La investigación tiene mucho potencial para beneficiar a las personas utilizando el algoritmo EM en muchos otros problemas de IR, así como en problemas de aprendizaje automático. El algoritmo EM es una técnica de aprendizaje automático comúnmente utilizada. Se utiliza para encontrar los parámetros del modelo en muchos problemas de IR donde los datos de entrenamiento son muy dispersos. Aunque nos estamos centrando en los modelos lineales jerárquicos bayesianos para recomendación y filtrado, la nueva idea de utilizar una solución analítica en lugar de una solución numérica para pares de usuario-característica no relacionados en el paso M podría adaptarse a muchos otros problemas. 8. AGRADECIMIENTOS Agradecemos a Wei Xu, David Lewis y a los revisores anónimos por sus valiosos comentarios sobre el trabajo descrito en este artículo. Parte del trabajo fue apoyado por Yahoo, Google, el Instituto de Almacenamiento de Datos a Escala Peta y el Instituto de Gestión de Datos Científicos Escalables. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las de los patrocinadores. REFERENCIAS [1] C. Basu, H. Hirsh y W. Cohen. Recomendación como clasificación: Utilizando información social y basada en contenido en la recomendación. En Actas de la Decimoquinta Conferencia Nacional de Inteligencia Artificial, 1998. [2] J. S. Breese, D. Heckerman y C. Kadie. Análisis empírico de algoritmos predictivos para filtrado colaborativo. Informe técnico, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan. Filtrado de documentos con redes de inferencia. En Actas de la Decimonovena Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor y A. Vinokourov. Método del núcleo para el filtrado de documentos. En la Undécima Conferencia de Recuperación de Información de Texto (TREC11). Instituto Nacional de Normas y Tecnología, publicación especial 500-249, 2003. [5] C. Chelba y A. Acero. Adaptación del capitalizador de entropía máxima: Poca información puede ayudar mucho. En D. Lin y D. Wu, editores, Actas de EMNLP 2004, páginas 285-292, Barcelona, España, julio de 2004. Asociación de Lingüística Computacional. [6] B. Croft y J. Lafferty, editores. Modelado de lenguaje para recuperación de información. Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov y A. Genkin. Construyendo distribuciones a priori informativas a partir del conocimiento del dominio en la clasificación de textos. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 493-500, Nueva York, NY, EE. UU., 2006. ACM Press. [8] J. Delgado y N. Ishii. Predicción basada en memoria ponderada para sistemas de recomendación. En el Taller ACM SIGIR99 sobre Sistemas de Recomendación, 1999. [9] GroupLens. Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman. Un tutorial sobre el aprendizaje con redes bayesianas. En M. Jordan, editor, Aprendizaje en Modelos Gráficos. Kluwer Academic, 1998. [11] J. L. Herlocker, J. \n\nKluwer Academic, 1998. [11] J. L. Herlocker, J. A. Konstan, A. Borchers y J. Riedl. Un marco algorítmico para realizar filtrado colaborativo. En SIGIR 99: Actas de la 22ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 230-237, Nueva York, NY, EE. UU., 1999. ACM Press. [12] T. Hofmann y J. Puzicha. Modelos de clases latentes para filtrado colaborativo. En IJCAI 99: Actas de la Decimosexta Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 688-693, San Francisco, CA, EE. UU., 1999. Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).\nMorgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB). Base de datos de películas en internet. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai y L. Si. Un esquema de ponderación automática para filtrado colaborativo. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 337-344, Nueva York, NY, EE. UU., 2004. ACM Press. [15] J. A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon y J. Riedl. GroupLens: Aplicando filtrado colaborativo a las noticias de Usenet. Comunicaciones de la ACM, 40(3):77-87, 1997. [16] D. Lewis. Aplicando máquinas de vectores de soporte a las tareas de filtrado y enrutamiento por lotes de TREC-2001. En Actas de la Undécima Conferencia de Recuperación de Texto (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee y P. Yu. Clasificación de texto mediante etiquetado de palabras. En Actas de la Decimonovena Conferencia Nacional de Inteligencia Artificial (AAAI-2004), 25-29 de julio de 2004. [18] P. Melville, R. J. Mooney y R. Nagarajan. Filtrado colaborativo potenciado por contenido para recomendaciones mejoradas. En Actas de la Decimoctava Conferencia Nacional de Inteligencia Artificial (AAAI-2002), Edmonton, Canadá, 2002. [19] Netflix. Premio Netflix. http://www.netflixprize.com (visitado el 30 de noviembre de 2006), 2006. [20] S. Robertson y K. Sparck-Jones. Ponderación de la relevancia de los términos de búsqueda. En Journal of the American Society for Information Science, volumen 27, páginas 129-146, 1976. [21] J. Wang, A. P. de Vries y M. J. T. Reinders. Unificando enfoques de filtrado colaborativo basados en usuarios y en elementos mediante la fusión de similitudes. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 501-508, Nueva York, NY, EE. UU., 2006. ACM Press. [22] X. Wu y R. K. Srihari. Incorporando conocimientos previos con máquinas de vectores de soporte de margen ponderado. En Proc. Conferencia de Minería de Datos y Descubrimiento de Conocimiento de ACM (ACM SIGKDD 2004), agosto de 2004. [23] Y. Yang, S. Yoo, J. Zhang y B. Kisiel. Robustez de los métodos de filtrado adaptativo en una evaluación de referencia cruzada. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 2005. [24] K. Yu, V. Tresp y A. Schwaighofer. Aprendiendo procesos gaussianos de múltiples tareas. En ICML 05: Actas de la 22ª conferencia internacional sobre aprendizaje automático, páginas 1012-1019, Nueva York, NY, EE. UU., 2005. ACM Press. [25] K. Yu, V. Tresp, y S. Yu. Un marco bayesiano jerárquico no paramétrico para el filtrado de información. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 353-360. ACM Press, 2004. [26] X. Zhu. \n\nACM Press, 2004. [26] X. Zhu. Revisión de la literatura sobre aprendizaje semisupervisado. Informe técnico, Universidad de Wisconsin - Madison, 9 de diciembre de 2006. [27] P. Zigoris y Y. Zhang. Perfilado de usuario bayesiano adaptativo con retroalimentación explícita e implícita. En la Conferencia sobre Gestión de la Información y el Conocimiento 2006, 2006.",
    "original_sentences": [
        "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
        "A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model.",
        "Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive.",
        "The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications.",
        "This paper proposes a new fast learning technique to learn a large number of individual user profiles.",
        "The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens.",
        "Categories and Subject Descriptors: B.3.3 [Information Search and Retrieval]: Information filtering General Terms: Algorithms 1.",
        "INTRODUCTION Personalization is the future of the Web, and it has achieved great success in industrial applications.",
        "For example, online stores, such as Amazon and Netflix, provide customized recommendations for additional products or services based on a users history.",
        "Recent offerings such as My MSN, My Yahoo!, My Google, and Google News have attracted much attention due to their potential ability to infer a users interests from his/her history.",
        "One major personalization topic studied in the information retrieval community is content-based personal recommendation systems1 .",
        "These systems learn user-specific profiles from user feedback so that they can recommend information tailored to each individual users interest without requiring the user to make an explicit query.",
        "Learning the user profiles is the core problem for these systems.",
        "A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user.",
        "One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small.",
        "This is known as the cold start problem.",
        "This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile.",
        "There has been much research on improving classification accuracy when the amount of labeled training data is small.",
        "The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal [26].",
        "Another approach is using domain knowledge.",
        "Researchers have modified different learning algorithms, such as Na¨ıveBayes [17], logistic regression [7], and SVMs [22], to integrate domain knowledge into a text classifier.",
        "The third approach is borrowing training data from other resources [5][7].",
        "The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data.",
        "One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach.",
        "Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial performance for each user[27][25].",
        "In order to learn a Bayesian hierarchical model, the system usually tries to find the most likely model parameters for the given data.",
        "A mature recommendation system usually works for millions of users.",
        "It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users.",
        "The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee.",
        "However, a content based recommendation system often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector.",
        "With careful analysis of the EM algorithm in this scenario (Section 4), we find that the EM tering, or item-based collaborative filtering.",
        "In this paper, the words filtering and recommendation are used interchangeably. algorithm converges very slowly due to the sparseness of the input variables.",
        "We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O(MK), where M is the number of users and K is the number of dimensions.",
        "This paper modifies the standard EM algorithm to create an improved learning algorithm, which we call the Modified EM algorithm.",
        "The basic idea is that instead of calculating the numerical solution for all the user profile parameters, we derive the analytical solution of the parameters for some feature dimensions, and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters.",
        "This greatly reduces the computation at a single EM iteration, and also has the benefit of increasing the convergence speed of the learning algorithm.",
        "The proposed technique is not only well supported by theory, but also by experimental results.",
        "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression modeling framework used for content-based recommendations.",
        "Section 4 describes how to learn the model parameters using the standard EM algorithm, along with using the new technique proposed in this paper.",
        "The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6.",
        "Section 7 summarizes and offers concluding remarks. 2.",
        "RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the IR community since the 1970s.",
        "The approaches that have been used to solve this problem can be roughly classified into two major categories: content based filtering versus collaborative filtering.",
        "Content-based filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user.",
        "The user may read the delivered documents and provide explicit relevance feedback, which the filtering system then uses to update the users profile using relevance feedback retrieval models (e.g.",
        "Boolean models, vector space models, traditional probabilistic models [20] , inference networks [3] and language models [6]) or machine learning algorithms (e.g.",
        "Support Vector Machines (SVM), K nearest neighbors (K-NN) clustering, neural networks, logistic regression, or Winnow [16] [4] [23]).",
        "Collaborative filtering goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past.",
        "Memorybased heuristics and model based approaches have been used in collaborative filtering task [15] [8] [2] [14] [12] [11].",
        "This paper contributes to the content-based recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks[27][25].",
        "This paper does not intend to compare content-based filtering with collaborative filtering or claim which one is a better.",
        "We think each complements the other, and that content-based filtering is extremely useful for handling new documents/items with little or no user feedback.",
        "Similar to some other researchers[18][1][21], we found that a recommendation system will be more effective when both techniques are combined.",
        "However, this is beyond the scope of this paper and thus not discussed here. 3.",
        "BAYESIAN HIERARCHICAL LINEAR REGRESSION Assume there are M users in the system.",
        "The task of the system is to recommend documents that are relevant to each user.",
        "For each user, the system learns a user model from the users history.",
        "In the rest of this paper, we will use the following notations to represent the variables in the system. m = 1, 2, ..., M: The index for each individual user.",
        "M is the total number of users. wm: The user model parameter associated with user m. wm is a K dimensional vector. j = 1, 2, ..., Jm: The index for a set of data for user m. Jm is the number of training data for user m. Dm = {(xm,j, ym,j)}: A set of data associated with user m. xm,j is a K dimensional vector that represents the mth users jth training document.2 ym,j is a scalar that represents the label of document xm,j. k = 1, 2, ..., K: The dimensional index of input variable x.",
        "The Bayesian hierarchical modeling approach has been widely used in real-world information retrieval applications.",
        "Generalized Bayesian hierarchical linear models, one of the simplest Bayesian hierarchical models, are commonly used and have achieved good performance on collaborative filtering [25] and content-based adaptive filtering [27] tasks.",
        "Figure 1 shows the graphical representation of a Bayesian hierarchical model.",
        "In this graph, each user model is represented by a random vector wm.",
        "We assume a user model is sampled randomly from a prior distribution P(w|Φ).",
        "The system can predict the user label y of a document x given an estimation of wm (or wms distribution) using a function y = f(x, w).",
        "The model is called generalized Bayesian hierarchical linear model when y = f(wT x) is any generalized linear model such as logistic regression, SVM, and linear regression.",
        "To reliably estimate the user model wm, the system can borrow information from other users through the prior Φ = (µ, Σ).",
        "Now we look at one commonly used model where y = wT x + , where ∼ N(0, σ2 ) is a random noise [25][27].",
        "Assume that each user model wm is an independent draw from a population distribution P(w|Φ), which is governed by some unknown hyperparameter Φ.",
        "Let the prior distribution of user model w be a Gaussian distribution with parameter Φ = (µ, Σ), which is the commonly used prior for linear models. µ = (µ1, µ2, ..., µK ) is a K dimensional vector that represents the mean of the Gaussian distribution, and Σ is the covariance matrix of the Gaussian.",
        "Usually, a Normal distribution N(0, aI) and an Inverse Wishart distribution P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) are used as hyperprior to model the prior distribution of µ and Σ respectively.",
        "I is the K dimensional identity matrix, and a, b, and c are real numbers.",
        "With these settings, we have the following model for the system: 1. µ and Σ are sampled from N(0, aI) and IWν (aI), respectively. 2 The first dimension of x is a dummy variable that always equals to 1.",
        "Figure 1: Illustration of dependencies of variables in the hierarchical model.",
        "The rating, y, for a document, x, is conditioned on the document and the user model, wm, associated with the user m. Users share information about their models through the prior, Φ = (µ, Σ). 2.",
        "For each user m, wm is sampled randomly from a Normal distribution: wm ∼ N(µ, Σ2 ) 3.",
        "For each item xm,j, ym,j is sampled randomly from a Normal distribution: ym,j ∼ N(wT mxm,j, σ2 ).",
        "Let θ = (Φ, w1, w2, ..., wM ) represent the parameters of this system that needs to be estimated.",
        "The joint likelihood for all the variables in the probabilistic model, which includes the data and the parameters, is: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) For simplicity, we assume a, b, c, and σ are provided to the system. 4.",
        "MODEL PARAMETER LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple linear regression.",
        "Therefore, we will focus on estimating Φ.",
        "The maximum a priori solution of Φ is given by ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Finding the optimal solution for the above problem is challenging, since we need to integrate over all w = (w1, w2, ..., wM ), which are unobserved hidden variables. 4.1 EM Algorithm for Bayesian Hierarchical Linear Models In Equation 5, Φ is the parameter needs to be estimated, and the result depends on unobserved latent variables w. This kind of optimization problem is usually solved by the EM algorithm.",
        "Applying EM to the above problem, the set of user models w are the unobservable hidden variables and we have: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw Based on the derivation of the EM formulas presented in [24], we have the following Expectation-Maximization steps for finding the optimal hyperparameters.",
        "For space considerations, we omit the derivation in this paper since it is not the focus of our work.",
        "E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of the prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) where Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j M step: Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Many machine learning driven IR systems use a point estimate of the parameters at different stages in the system.",
        "However, we are estimating the posterior distribution of the variables at the E step.",
        "This avoids overfitting wm to a particular users data, which may be small and noisy.",
        "A detailed discussion about this subject appears in [10]. 4.2 New Algorithm: Modified EM Although the EM algorithm is widely studied and used in machine learning applications, using the above EM process to solve Bayesian hierarchical linear models in large-scale information retrieval systems is still too computationally expensive.",
        "In this section, we describe why the learning rate of the EM algorithm is slow in our application and introduce a new technique to make the learning of the Bayesian hierarchical linear model scalable.",
        "The derivation of the new learning algorithm will be based on the EM algorithm described in the previous section.",
        "First, the covariance matrices Σ2 , Σ2 m are usually too large to be computationally feasible.",
        "For simplicity, and as a common practice in IR, we do not model the correlation between features.",
        "Thus we approximate these matrices with K dimensional diagonal matrices.",
        "In the rest of the paper, we use these symbols to represent their diagonal approximations: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     Secondly, and most importantly, the input space is very sparse and there are many dimensions that are not related to a particular user in a real IR application.",
        "For example, let us consider a movie recommendation system, with the input variable x representing a particular movie.",
        "For the jth movie that the user m has seen, let xm,j,k = 1 if the director of the movie is Jean-Pierre Jeunet (indexed by k).",
        "Here we assume that whether or not that this director directed a specific movie is represented by the kth dimension.",
        "If the user m has never seen a movie directed by Jean-Pierre Jeunet, then the corresponding dimension is always zero (xm,j,k = 0 for all j) .",
        "One major drawback of the EM algorithm is that the importance of a feature, µk, may be greatly dominated by users who have never encountered this feature (i.e. j xm,j,k = 0) at the M step (Equation 8).",
        "Assume that 100 out of 1 million users have viewed the movie directed by Jean-Pierre Jeunet, and that the viewers have rated all of his movies as excellent.",
        "Intuitively, he is a good director and the weight for him (µk) should be high.",
        "Before the EM iteration, the initial value of µ is usually set to 0.",
        "Since the other 999,900 users have not seen this movie, their corresponding weights (w1,k, w2,k, ..., wm,k..., w999900,k) for that director would be very small initially.",
        "Thus the corresponding weight of the director in the prior µk at the first M step would be very low , and the variance σm,k will be large (Equations 8 and 7).",
        "It is undesirable that users who have never seen any movie produced by the director influence the importance of the director so much.",
        "This makes the convergence of the standard EM algorithm very slow.",
        "Now lets look at whether we can improve the learning speed of the algorithm.",
        "Without a loss of generality, let us assume that the kth dimension of the input variable x is not related to a particular user m. By which we mean, xm,j,k = 0 for all j = 1, ..., Jm.",
        "It is straightforward to prove that the kth row and kth column of Sxx,m are completely filled with zeros, and that the kth dimension of Sxy,m is zeroed as well.",
        "Thus the corresponding kth dimension of the user models mean, ¯wm, should be equal to that of the prior: ¯wm,k = µk, with the corresponding covariance of σm,k = σk.",
        "At the M step, the standard EM algorithm uses the numerical solution of the distribution P(wm|Dm, Φ) estimated at E step (Equation 8 and Equation 7).",
        "However, the numerical solutions are very unreliable for ¯wm,k and σm,k when the kth dimension is not related to the mth user.",
        "A better approach is using the analytical solutions ¯wm,k = µk, and σm,k = σk for the unrelated (m, k) pairs, along with the numerical solution estimated at E step for the other (m, k) pairs.",
        "Thus we get the following new EM-like algorithm: Modified E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) where sxx,m,k = j x2 m,j,k and sxy,m,k = j xm,j,kym,j Modified M Step Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step for related userfeature pairs.",
        "The M step implicitly uses the analytical solution for unrelated user-feature pairs. µk = 1 Mk m:related ¯wm,k (12) σ2 k = 1 Mk m:related σ2 m,k +( ¯wm,k − µk)( ¯wm,k − µk)T (13) where Mk is the number of users that are related to feature k We only estimate the diagonal of Σ2 m and Σ since we are using the diagonal approximation of the covariance matrices.",
        "To estimate ¯wm, we only need to calculate the numerical solutions for dimensions that are related to user m. To estimate σ2 k and µk, we only sum over users that are related to the kth feature.",
        "There are two major benefits of the new algorithm.",
        "First, because only the related (m, k) pairs are needed at the modified M step, the computational complexity in a single EM iteration is much smaller when the data is sparse, and many of (m, k) pairs are unrelated.",
        "Second, the parameters estimated at the modified M step (Equations 12 - 13) are more accurate than the standard M step described in Section 4.1 because the exact analytical solutions ¯wm,k = µk and σm,k = σk for the unrelated (m, k) pairs were used in the new algorithm instead of an approximate solution as in the standard algorithm. 5.",
        "EXPERIMENTAL METHODOLOGY 5.1 Evaluation Data Set To evaluate the proposed technique, we used the following three major data sets (Table 1): MovieLens Data: This data set was created by combining the relevance judgments from the MovieLens[9] data set with documents from the Internet Movie Database (IMDB).",
        "MovieLens allows users to rank how much he/she enjoyed a specific movie on a scale from 1 to 5.",
        "This likeability rating was used as a measurement of how relevant the document representing the corresponding movie is to the user.",
        "We considered documents with likeability scores of 4 or 5 as relevant, and documents with a score of 1 to 3 as irrelevant to the user.",
        "MovieLens provided relevance judgments on 3,057 documents from 6,040 separate users.",
        "On average, each user rated 151 movies, of these 87 were judged to be relevant.",
        "The average score for a document was 3.58.",
        "Documents representing each movie were constructed from the portion of the IMDB database that is available for public download[13].",
        "Based on this database, we created one document per movie that contained the relevant information about it (e.g. directors, actors, etc.).",
        "Table 1: Data Set Statistics.",
        "On Reuters, the number of rating for a simulated user is the number of documents relevant to the corresponding topic.",
        "Data Users Docs Ratings per User MovieLens 6,040 3,057 151 Netflix-all 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Netflix Data: This data set was constructed by combining documents about movies crawled from the web with a set of actual movie rental customer relevance judgments from Netflix[19].",
        "Netflix publicly provides the relevance judgments of 480,189 anonymous customers.",
        "There are around 100 million rating on a scale of 1 to 5 for 17,770 documents.",
        "Similar to MovieLens, we considered documents with likeability scores of 4 or 5 as relevant.",
        "This number was reduced to 1000 customers through random sampling.",
        "The average customer on the reduced data set provided 127 judgments, with 70 being deemed relevant.",
        "The average score for documents is 3.55.",
        "Reuters Data: This is the Reuters Corpus, Volume 1.",
        "It covers 810,000 Reuters English language news stories from August 20, 1996 to August 19, 1997.",
        "Only the first 100,000 news were used in our experiments.",
        "The Reuters corpus comes with a topic hierarchy.",
        "Each document is assigned to one of several locations on the hierarchical tree.",
        "The first level of the tree contains four topics, denoted as C, E, M, and G. For the experiments in this paper, the tree was cut at level 1 to create four smaller trees, each of which corresponds to one smaller data set: Reuters-E Reuters-C, ReutersM and Reuters-G. For each small data set, we created several profiles, one profile for each node in a sub-tree, to simulate multiple users, each with a related, yet separate definition of relevance.",
        "All the user profiles on a sub-tree are supposed to share the same prior model distribution.",
        "Since this corpus explicitly indicates only the relevant documents for a topic(user), all other documents are considered irrelevant. 5.2 Evaluation We designed the experiments to answer the following three questions: 1.",
        "Do we need to take the effort to use a Bayesian approach and learn a prior from other users? 2.",
        "Does the new algorithm work better than the standard EM algorithm for learning the Bayesian hierarchical linear model? 3.",
        "Can the new algorithm quickly learn many user models?",
        "To answer the first question, we compared the Bayesian hierarchical models with commonly used Norm-2 regularized linear regression models.",
        "In fact, the commonly used approach is equivalent to the model learned at the end of the first EM iteration.",
        "To answer the second question, we compared the proposed new algorithm with the standard EM algorithm to see whether the new learning algorithm is better.",
        "To answer the third question, we tested the efficiency of the new algorithm on the entire Netflix data set where about half a million user models need to be learned together.",
        "For the MovieLens and Netflix data sets, algorithm effectiveness was measured by mean square error, while on the Reuters data set classification error was used because it was more informative.",
        "We first evaluated the performance on each individual user, and then estimated the macro average over all users.",
        "Statistical tests (t-tests) were carried out to see whether the results are significant.",
        "For the experiments on the MovieLens and Netflix data sets, we used a random sample of 90% of each user for training, and the rest for testing.",
        "On Reuters data set, because there are too many relevant documents for each topic in the corpus, we used a random sample of 10% of each topic for training, and 10% of the remaining documents for testing.",
        "For all runs, we set (a, b, c, Σ ) = (0.1, 10, 0.1, 1) manually. 6.",
        "EXPERIMENTAL RESULTS Figure 2, Figure 3, and Figure 4 show that on all data sets, the Bayesian hierarchical modeling approach has a statistical significant improvement over the regularized linear regression model, which is equivalent to the Bayesian hierarchical models learned at the first iteration.",
        "Further analysis shows a negative correlation between the number of training data for a user and the improvement the system gets.",
        "This suggests that the borrowing information from other users has more significant improvements for users with less training data, which is as expected.",
        "However, the strength of the correlation differs over data sets, and the amount of training data is not the only characteristics that will influence the final performance.",
        "Figure 2 and Figure 3 show that the proposed new algorithm works better than the standard EM algorithm on the Netflix and MovieLens data sets.",
        "This is not surprising since the number of related feature-users pairs is much smaller than the number of unrelated feature-user pairs on these two data sets, and thus the proposed new algorithm is expected to work better.",
        "Figure 4 shows that the two algorithms work similarly on the Reuters-E data set.",
        "The accuracy of the new algorithm is similar to that of the standard EM algorithm at each iteration.",
        "The general patterns are very similar on other Reuters subsets.",
        "Further analysis shows that only 58% of the user-feature pairs are unrelated on this data set.",
        "Since the number of unrelated user-feature pairs is not extremely large, the sparseness is not a serious problem on the Reuters data set.",
        "Thus the two learning algorithms perform similarly.",
        "The results suggest that only on a corpus where the number of unrelated user-feature pairs is much larger than the number of related pairs, such as on the Netflix data set, the proposed technique will get a significant improvement over standard EM.",
        "However, the experiments also show that when the assumption does not hold, the new algorithm does not hurt performance.",
        "Although the proposed technique is faster than standard Figure 2: Performance on a Netflix subset with 1,000 users.",
        "The new algorithm is statistical significantly better than EM algorithm at iterations 2 - 10.",
        "Norm-2 regularized linear models are equivalent to the Bayesian hierarchical models learned at the first iteration, and are statistical significantly worse than the Bayesian hierarchical models. 0 2 4 6 8 10 1 1.05 1.1 1.15 1.2 1.25 1.3 1.35 1.4 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iterations ClassificationError New Algorithm Traditional EM Figure 3: Performance on a MovieLens subset with 1,000 users.",
        "The new algorithm is statistical significantly better than EM algorithm at iteration 2 to 17 (evaluated with mean square error). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iterations MeanSquareError New Algorithm Traditional EM 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iterations ClassificationError New Algorithm Traditional EM Figure 4: Performance on a Reuters-E subset with 26 profiles.",
        "Performances on Reuters-C, Reuters-M, Reuters-G are similar. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iterations ClassificationError New Algorithm Traditional EM EM, can it really learn millions of user models quickly?",
        "Our results show that the modified EM algorithm converges quickly, and 2 - 3 modified EM iterations would result in a reliable estimation.",
        "We evaluated the algorithm on the whole Netflix data set (480,189 users, 159,836 features, and 100 million ratings) running on a single CPU PC (2GB memory, P4 3GHz).",
        "The system finished one modified EM iteration in about 4 hours.",
        "This demonstrates that the proposed technique can efficiently handle large-scale system like Netflix. 7.",
        "CONCLUSION Content-based user profile learning is an important problem and is the key to providing personal recommendations to a user, especially for recommending new items with a small number of ratings.",
        "The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors.",
        "This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM.",
        "We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm.",
        "Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse, by which we mean the ratio of related user-feature pairs to unrelated pairs is small.",
        "Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold.",
        "In general, it is better to use the new algorithm since it is as simple as standard EM, the performance is either better or similar to EM, and the computation complexity is lower at each iteration.",
        "It is worth mentioning that even if the original problem space is not sparse, sparseness can be created artificially when a recommendation system uses user-specific feature selection techniques to reduce the noise and user model complexity.",
        "The proposed technique can also be adapted to improve the learning in such a scenario.",
        "We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU.",
        "The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear modeling approach to build a practical large scale system, even though the literature have demonstrated the effectiveness of the models in many applications.",
        "Our work is one major step on the road to make Bayesian hierarchical linear models more practical.",
        "The proposed new technique can be easily adapted to run on a cluster of machines, and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users.",
        "The research has much potential to benefit people using EM algorithm on many other IR problems as well as machine learning problems.",
        "EM algorithm is a commonly used machine learning technique.",
        "It is used to find model parameters in many IR problems where the training data is very sparse.",
        "Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering, the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems. 8.",
        "ACKNOWLEDGMENTS We thank Wei Xu, David Lewis and anonymous reviewers for valuable feedback on the work described in this paper.",
        "Part of the work was supported by Yahoo, Google, the Petascale Data Storage Institute and the Institute for Scalable Scientific Data Management.",
        "Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors, and do not necessarily reflect those of the sponsors. 9.",
        "REFERENCES [1] C. Basu, H. Hirsh, and W. Cohen.",
        "Recommendation as classification: Using social and content-based information in recommendation.",
        "In Proceedings of the Fifteenth National Conference on Artificial Intelligence, 1998. [2] J. S. Breese, D. Heckerman, and C. Kadie.",
        "Empirical analysis of predictive algorithms for collaborative filtering.",
        "Technical report, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan.",
        "Document filtering with inference networks.",
        "In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor, and A. Vinokourov.",
        "Kernel method for document filtering.",
        "In The Eleventh Text REtrieval Conference (TREC11).",
        "National Institute of Standards and Technology, special publication 500-249, 2003. [5] C. Chelba and A. Acero.",
        "Adaptation of maximum entropy capitalizer: Little data can help a lot.",
        "In D. Lin and D. Wu, editors, Proceedings of EMNLP 2004, pages 285-292, Barcelona, Spain, July 2004.",
        "Association for Computational Linguistics. [6] B. Croft and J. Lafferty, editors.",
        "Language Modeling for Information Retrieval.",
        "Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov, and A. Genkin.",
        "Constructing informative prior distributions from domain knowledge in text classification.",
        "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 493-500, New York, NY, USA, 2006.",
        "ACM Press. [8] J. Delgado and N. Ishii.",
        "Memory-based weightedmajority prediction for recommender systems.",
        "In ACM SIGIR99 Workshop on Recommender Systems, 1999. [9] GroupLens.",
        "Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman.",
        "A tutorial on learning with bayesian networks.",
        "In M. Jordan, editor, Learning in Graphical Models.",
        "Kluwer Academic, 1998. [11] J. L. Herlocker, J.",
        "A. Konstan, A. Borchers, and J. Riedl.",
        "An algorithmic framework for performing collaborative filtering.",
        "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 230-237, New York, NY, USA, 1999.",
        "ACM Press. [12] T. Hofmann and J. Puzicha.",
        "Latent class models for collaborative filtering.",
        "In IJCAI 99: Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 688-693, San Francisco, CA, USA, 1999.",
        "Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).",
        "Internet movie database. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai, and L. Si.",
        "An automatic weighting scheme for collaborative filtering.",
        "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 337-344, New York, NY, USA, 2004.",
        "ACM Press. [15] J.",
        "A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl.",
        "GroupLens: Applying collaborative filtering to Usenet news.",
        "Communications of the ACM, 40(3):77-87, 1997. [16] D. Lewis.",
        "Applying support vector machines to the TREC-2001 batch filtering and routing tasks.",
        "In Proceedings of the Eleventh Text REtrieval Conference (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee, , and P. Yu.",
        "Text classification by labeling words.",
        "In Proceedings of The Nineteenth National Conference on Artificial Intelligence (AAAI-2004), July 25-29, 2004. [18] P. Melville, R. J. Mooney, and R. Nagarajan.",
        "Content-boosted collaborative filtering for improved recommendations.",
        "In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002), Edmonton, Canada, 2002. [19] Netflix.",
        "Netflix prize. http://www.netflixprize.com (visited on Nov. 30, 2006), 2006. [20] S. Robertson and K. Sparck-Jones.",
        "Relevance weighting of search terms.",
        "In Journal of the American Society for Information Science, volume 27, pages 129-146, 1976. [21] J. Wang, A. P. de Vries, and M. J. T. Reinders.",
        "Unifying user-based and item-based collaborative filtering approaches by similarity fusion.",
        "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 501-508, New York, NY, USA, 2006.",
        "ACM Press. [22] X. Wu and R. K. Srihari.",
        "Incorporating prior knowledge with weighted margin support vector machines.",
        "In Proc.",
        "ACM Knowledge Discovery Data Mining Conf. (ACM SIGKDD 2004), Aug. 2004. [23] Y. Yang, S. Yoo, J. Zhang, and B. Kisiel.",
        "Robustness of adaptive filtering methods in a cross-benchmark evaluation.",
        "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2005. [24] K. Yu, V. Tresp, and A. Schwaighofer.",
        "Learning gaussian processes from multiple tasks.",
        "In ICML 05: Proceedings of the 22nd international conference on Machine learning, pages 1012-1019, New York, NY, USA, 2005.",
        "ACM Press. [25] K. Yu, V. Tresp, and S. Yu.",
        "A nonparametric hierarchical bayesian framework for information filtering.",
        "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 353-360.",
        "ACM Press, 2004. [26] X. Zhu.",
        "Semi-supervised learning literature survey.",
        "Technical report, University of Wisconsin - Madison, December 9, 2006. [27] P. Zigoris and Y. Zhang.",
        "Bayesian adaptive user profiling with explicit & implicit feedback.",
        "In Conference on Information and Knowledge Mangement 2006, 2006."
    ],
    "translated_text_sentences": [
        "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual.",
        "Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un modelo jerárquico bayesiano.",
        "Aprender los parámetros del modelo para optimizar la verosimilitud conjunta de los datos de millones de usuarios es muy costoso computacionalmente.",
        "El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de datos en aplicaciones de IR.",
        "Este documento propone una nueva técnica de aprendizaje rápido para aprender un gran número de perfiles de usuario individuales.",
        "La eficacia y eficiencia del algoritmo propuesto están justificadas por la teoría y demostradas en datos reales de usuarios de Netflix y MovieLens.",
        "Categorías y Descriptores de Asignaturas: B.3.3 [Búsqueda y Recuperación de Información]: Filtrado de información Términos Generales: Algoritmos 1.",
        "La personalización es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales.",
        "Por ejemplo, las tiendas en línea, como Amazon y Netflix, ofrecen recomendaciones personalizadas de productos o servicios adicionales basadas en el historial de un usuario.",
        "Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de un usuario a partir de su historial.",
        "Un tema importante de personalización estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados basados en el contenido.",
        "Estos sistemas aprenden perfiles específicos de usuario a partir de la retroalimentación del usuario para poder recomendar información adaptada a los intereses de cada usuario sin necesidad de que el usuario realice una consulta explícita.",
        "Aprender los perfiles de usuario es el problema central de estos sistemas.",
        "Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica qué tan relevante es un documento para el usuario.",
        "Uno de los principales desafíos de construir un sistema de recomendación o personalización es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña.",
        "Esto se conoce como el problema de inicio en frío.",
        "Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente retroalimentación de ese usuario para aprender un perfil de usuario confiable.",
        "Se ha realizado mucha investigación sobre cómo mejorar la precisión de clasificación cuando la cantidad de datos de entrenamiento etiquetados es pequeña.",
        "El enfoque de aprendizaje semisupervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26].",
        "Otro enfoque es utilizar el conocimiento del dominio.",
        "Los investigadores han modificado diferentes algoritmos de aprendizaje, como NaïveBayes [17], regresión logística [7] y SVMs [22], para integrar el conocimiento del dominio en un clasificador de texto.",
        "El tercer enfoque consiste en tomar datos de entrenamiento de otros recursos [5][7].",
        "La efectividad de estos enfoques diferentes es mixta, debido a qué tan bien se ajusta la suposición del modelo subyacente a los datos.",
        "Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano.",
        "Varios investigadores han demostrado que este enfoque intercambia eficazmente entre la información compartida y la específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario[27][25].",
        "Para aprender un modelo jerárquico bayesiano, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados.",
        "Un sistema de recomendación maduro generalmente funciona para millones de usuarios.",
        "Es bien sabido que aprender los parámetros óptimos de un modelo jerárquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios.",
        "El algoritmo EM es una técnica comúnmente utilizada para el aprendizaje de parámetros debido a su simplicidad y garantía de convergencia.",
        "Sin embargo, un sistema de recomendación basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso.",
        "Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM tering, o filtrado colaborativo basado en elementos.",
        "En este documento, las palabras filtrado y recomendación se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de las variables de entrada.",
        "También encontramos que actualizar el parámetro del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones.",
        "Este documento modifica el algoritmo EM estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos algoritmo EM modificado.",
        "La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M utilizamos la solución analítica en lugar de la solución numérica estimada en el paso E para esos parámetros.",
        "Esto reduce considerablemente la computación en una sola iteración de EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje.",
        "La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales.",
        "La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de regresión lineal jerárquica bayesiana utilizado para recomendaciones basadas en contenido.",
        "La sección 4 describe cómo aprender los parámetros del modelo utilizando el algoritmo EM estándar, junto con el uso de la nueva técnica propuesta en este artículo.",
        "La configuración experimental y los resultados utilizados para validar la técnica de aprendizaje propuesta se informan en las Secciones 5 y 6.",
        "La sección 7 resume y ofrece observaciones finales. 2.",
        "TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de IR desde la década de 1970.",
        "Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus filtrado colaborativo.",
        "El filtrado basado en contenido estudia el escenario en el que un sistema de recomendación monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente.",
        "El usuario puede leer los documentos entregados y proporcionar retroalimentación explícita de relevancia, la cual el sistema de filtrado utiliza para actualizar el perfil del usuario mediante modelos de recuperación de retroalimentación de relevancia (por ejemplo,).",
        "Modelos booleanos, modelos de espacio vectorial, modelos probabilísticos tradicionales [20], redes de inferencia [3] y modelos de lenguaje [6]) o algoritmos de aprendizaje automático (por ejemplo,",
        "Máquinas de Vectores de Soporte (SVM), agrupamiento de K vecinos más cercanos (K-NN), redes neuronales, regresión logística o Winnow [16] [4] [23].",
        "El filtrado colaborativo va más allá de simplemente usar el contenido de un documento para recomendar elementos a un usuario, aprovechando la información de otros usuarios con gustos y preferencias similares en el pasado.",
        "Se han utilizado heurísticas basadas en memoria y enfoques basados en modelos en la tarea de filtrado colaborativo [15] [8] [2] [14] [12] [11].",
        "Este artículo contribuye a la investigación de recomendaciones basadas en contenido al mejorar la eficiencia y efectividad de los modelos lineales jerárquicos bayesianos, los cuales tienen una sólida base teórica y un buen rendimiento empírico en tareas de recomendación[27][25].",
        "Este artículo no tiene la intención de comparar el filtrado basado en contenido con el filtrado colaborativo ni de afirmar cuál es mejor.",
        "Creemos que cada uno complementa al otro, y que el filtrado basado en contenido es extremadamente útil para manejar nuevos documentos/artículos con poco o ningún feedback del usuario.",
        "Similar a otros investigadores[18][1][21], encontramos que un sistema de recomendación será más efectivo cuando se combinan ambas técnicas.",
        "Sin embargo, esto está fuera del alcance de este documento y, por lo tanto, no se discute aquí. 3.",
        "REGRESIÓN LINEAL HIERÁRQUICA BAYESIANA Suponga que hay M usuarios en el sistema.",
        "La tarea del sistema es recomendar documentos que sean relevantes para cada usuario.",
        "Para cada usuario, el sistema aprende un modelo de usuario a partir del historial de los usuarios.",
        "En el resto de este documento, utilizaremos las siguientes notaciones para representar las variables en el sistema. m = 1, 2, ..., M: El índice para cada usuario individual.",
        "M es el número total de usuarios. wm: El parámetro del modelo de usuario asociado con el usuario m. wm es un vector de dimensión K. j = 1, 2, ..., Jm: El índice para un conjunto de datos para el usuario m. Jm es el número de datos de entrenamiento para el usuario m. Dm = {(xm,j, ym,j)}: Un conjunto de datos asociado con el usuario m. xm,j es un vector de dimensión K que representa el j-ésimo documento de entrenamiento del usuario m. ym,j es un escalar que representa la etiqueta del documento xm,j. k = 1, 2, ..., K: El índice dimensional de la variable de entrada x.",
        "El enfoque de modelado jerárquico bayesiano ha sido ampliamente utilizado en aplicaciones reales de recuperación de información.",
        "Los modelos lineales jerárquicos bayesianos generalizados, uno de los modelos jerárquicos bayesianos más simples, son comúnmente utilizados y han logrado un buen rendimiento en tareas de filtrado colaborativo [25] y filtrado adaptativo basado en contenido [27].",
        "La Figura 1 muestra la representación gráfica de un modelo jerárquico bayesiano.",
        "En este gráfico, cada modelo de usuario está representado por un vector aleatorio wm.",
        "Suponemos que un modelo de usuario se muestrea aleatoriamente de una distribución previa P(w|Φ).",
        "El sistema puede predecir la etiqueta de usuario y de un documento x dado una estimación de wm (o distribución de wms) utilizando una función y = f(x, w).",
        "El modelo se llama modelo lineal jerárquico bayesiano generalizado cuando y = f(wT x) es cualquier modelo lineal generalizado como regresión logística, SVM y regresión lineal.",
        "Para estimar de manera confiable el modelo de usuario wm, el sistema puede obtener información de otros usuarios a través de la prior Φ = (µ, Σ).",
        "Ahora observamos un modelo comúnmente utilizado donde y = wT x + , donde ∼ N(0, σ2 ) es un ruido aleatorio [25][27].",
        "Suponga que cada modelo de usuario wm es una muestra independiente de una distribución poblacional P(w|Φ), la cual está regida por un hiperparámetro desconocido Φ.",
        "Que la distribución previa del modelo de usuario w sea una distribución gaussiana con parámetro Φ = (µ, Σ), que es la distribución previa comúnmente utilizada para modelos lineales. µ = (µ1, µ2, ..., µK) es un vector de K dimensiones que representa la media de la distribución gaussiana, y Σ es la matriz de covarianza de la gaussiana.",
        "Normalmente, se utiliza una distribución Normal N(0, aI) y una distribución Inverse Wishart P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) como hiperprior para modelar la distribución previa de µ y Σ respectivamente.",
        "Yo es la matriz identidad de dimensión K, y a, b y c son números reales.",
        "Con esta configuración, tenemos el siguiente modelo para el sistema: 1. µ y Σ se muestrean de N(0, aI) e IWν (aI), respectivamente. 2. La primera dimensión de x es una variable ficticia que siempre es igual a 1.",
        "Figura 1: Ilustración de las dependencias de variables en el modelo jerárquico.",
        "La calificación, y, para un documento, x, está condicionada al documento y al modelo de usuario, wm, asociado con el usuario m. Los usuarios comparten información sobre sus modelos a través de la prior, Φ = (µ, Σ).",
        "Para cada usuario m, wm se muestrea aleatoriamente de una distribución Normal: wm ∼ N(µ, Σ2 ) 3.",
        "Para cada elemento xm,j, ym,j se muestrea aleatoriamente de una distribución Normal: ym,j ∼ N(wT mxm,j, σ2).",
        "Que θ = (Φ, w1, w2, ..., wM) represente los parámetros de este sistema que necesitan ser estimados.",
        "La verosimilitud conjunta de todas las variables en el modelo probabilístico, que incluye los datos y los parámetros, es: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) Para simplificar, asumimos que a, b, c y σ son proporcionados al sistema. 4.",
        "APRENDIZAJE DE PARÁMETROS DEL MODELO Si se conoce el prior Φ, encontrar el óptimo wm es sencillo: se trata de una regresión lineal simple.",
        "Por lo tanto, nos enfocaremos en estimar Φ.",
        "La solución a priori máxima de Φ se da por ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Encontrar la solución óptima para el problema anterior es desafiante, ya que necesitamos integrar sobre todos los w = (w1, w2, ..., wM), que son variables ocultas no observadas. 4.1 Algoritmo EM para Modelos Lineales Jerárquicos Bayesianos En la Ecuación 5, Φ es el parámetro que necesita ser estimado, y el resultado depende de las variables latentes no observadas w. Este tipo de problema de optimización suele resolverse mediante el algoritmo EM.",
        "Aplicando EM al problema anterior, el conjunto de modelos de usuario w son las variables ocultas no observables y tenemos: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw. Basándonos en la derivación de las fórmulas EM presentadas en [24], tenemos los siguientes pasos de Expectation-Maximization para encontrar los hiperparámetros óptimos.",
        "Por razones de espacio, omitimos la derivación en este artículo ya que no es el enfoque de nuestro trabajo.",
        "Paso E: Para cada usuario m, estime la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual del prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) donde Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j Paso M: Optimice el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Muchos sistemas de IR impulsados por aprendizaje automático utilizan una estimación puntual de los parámetros en diferentes etapas del sistema.",
        "Sin embargo, estamos estimando la distribución posterior de las variables en el paso E.",
        "Esto evita el sobreajuste de wm a los datos de un usuario en particular, que pueden ser pequeños y ruidosos.",
        "Una discusión detallada sobre este tema aparece en [10]. 4.2 Nuevo Algoritmo: EM Modificado. Aunque el algoritmo EM es ampliamente estudiado y utilizado en aplicaciones de aprendizaje automático, utilizar el proceso EM mencionado anteriormente para resolver modelos lineales jerárquicos bayesianos en sistemas de recuperación de información a gran escala sigue siendo demasiado costoso computacionalmente.",
        "En esta sección, describimos por qué la tasa de aprendizaje del algoritmo EM es lenta en nuestra aplicación e introducimos una nueva técnica para hacer que el aprendizaje del modelo lineal jerárquico bayesiano sea escalable.",
        "La derivación del nuevo algoritmo de aprendizaje estará basada en el algoritmo EM descrito en la sección anterior.",
        "Primero, las matrices de covarianza Σ2 , Σ2 m suelen ser demasiado grandes para ser computacionalmente factibles.",
        "Por simplicidad, y como práctica común en IR, no modelamos la correlación entre características.",
        "Así aproximamos estas matrices con matrices diagonales de dimensión K.",
        "En el resto del documento, utilizamos estos símbolos para representar sus aproximaciones diagonales: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     En segundo lugar, y lo más importante, el espacio de entrada es muy disperso y hay muchas dimensiones que no están relacionadas con un usuario particular en una aplicación de recuperación de información real.",
        "Por ejemplo, consideremos un sistema de recomendación de películas, con la variable de entrada x representando una película en particular.",
        "Para la j-ésima película que el usuario m ha visto, sea xm,j,k = 1 si el director de la película es Jean-Pierre Jeunet (indexado por k).",
        "Aquí asumimos que si este director dirigió una película específica está representado por la k-ésima dimensión.",
        "Si el usuario m nunca ha visto una película dirigida por Jean-Pierre Jeunet, entonces la dimensión correspondiente siempre es cero (xm,j,k = 0 para todos los j).",
        "Una desventaja importante del algoritmo EM es que la importancia de una característica, µk, puede estar fuertemente dominada por usuarios que nunca han encontrado esta característica (es decir, j xm,j,k = 0) en el paso M (Ecuación 8).",
        "Suponga que 100 de cada 1 millón de usuarios han visto la película dirigida por Jean-Pierre Jeunet, y que los espectadores han calificado todas sus películas como excelentes.",
        "Intuitivamente, él es un buen director y el peso para él (µk) debería ser alto.",
        "Antes de la iteración de EM, el valor inicial de µ suele establecerse en 0.",
        "Dado que los otros 999,900 usuarios no han visto esta película, sus pesos correspondientes (w1,k, w2,k, ..., wm,k..., w999900,k) para ese director serían muy pequeños inicialmente.",
        "Por lo tanto, el peso correspondiente del director en el µk anterior en el primer paso M sería muy bajo, y la varianza σm,k será grande (Ecuaciones 8 y 7).",
        "Es indeseable que los usuarios que nunca han visto ninguna película producida por el director influyan tanto en la importancia del director.",
        "Esto hace que la convergencia del algoritmo EM estándar sea muy lenta.",
        "Ahora veamos si podemos mejorar la velocidad de aprendizaje del algoritmo.",
        "Sin pérdida de generalidad, asumamos que la k-ésima dimensión de la variable de entrada x no está relacionada con un usuario particular m. Lo que queremos decir es que xm,j,k = 0 para todo j = 1, ..., Jm.",
        "Es sencillo demostrar que la k-ésima fila y la k-ésima columna de Sxx,m están completamente llenas de ceros, y que la k-ésima dimensión de Sxy,m también se anula.",
        "Por lo tanto, la dimensión k correspondiente de la media de los modelos de usuario, ¯wm, debería ser igual a la del anterior: ¯wm,k = µk, con la covarianza correspondiente de σm,k = σk.",
        "En el paso M, el algoritmo EM estándar utiliza la solución numérica de la distribución P(wm|Dm, Φ) estimada en el paso E (Ecuación 8 y Ecuación 7).",
        "Sin embargo, las soluciones numéricas son muy poco confiables para ¯wm,k y σm,k cuando la k-ésima dimensión no está relacionada con el m-ésimo usuario.",
        "Un enfoque mejor es utilizar las soluciones analíticas ¯wm,k = µk, y σm,k = σk para los pares no relacionados (m, k), junto con la solución numérica estimada en el paso E para los otros pares (m, k).",
        "Así obtenemos el siguiente nuevo algoritmo EM similar: Paso E modificado: Para cada usuario m, estimar la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual de σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) donde sxx,m,k = j x2 m,j,k y sxy,m,k = j xm,j,kym,j Paso M modificado Optimizar el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E para pares de usuario-característica relacionados.",
        "El paso M utiliza implícitamente la solución analítica para pares de usuario-característica no relacionados. µk = 1 Mk m:relacionado ¯wm,k (12) σ2 k = 1 Mk m:relacionado σ2 m,k + ( ¯wm,k − µk)( ¯wm,k − µk)T (13) donde Mk es el número de usuarios relacionados con la característica k. Solo estimamos la diagonal de Σ2 m y Σ, ya que estamos utilizando la aproximación diagonal de las matrices de covarianza.",
        "Para estimar ¯wm, solo necesitamos calcular las soluciones numéricas para las dimensiones que están relacionadas con el usuario m. Para estimar σ2 k y µk, solo sumamos sobre los usuarios que están relacionados con la k-ésima característica.",
        "Hay dos beneficios principales del nuevo algoritmo.",
        "Primero, dado que solo se necesitan los pares relacionados (m, k) en el paso M modificado, la complejidad computacional en una sola iteración de EM es mucho menor cuando los datos son dispersos y muchos de los pares (m, k) no están relacionados.",
        "En segundo lugar, los parámetros estimados en el paso M modificado (Ecuaciones 12 - 13) son más precisos que el paso M estándar descrito en la Sección 4.1 porque se utilizaron soluciones analíticas exactas ¯wm,k = µk y σm,k = σk para los pares no relacionados (m, k) en el nuevo algoritmo en lugar de una solución aproximada como en el algoritmo estándar.",
        "METODOLOGÍA EXPERIMENTAL 5.1 Conjunto de Datos de Evaluación Para evaluar la técnica propuesta, utilizamos los siguientes tres conjuntos de datos principales (Tabla 1): Datos de MovieLens: Este conjunto de datos fue creado combinando las valoraciones de relevancia del conjunto de datos de MovieLens[9] con documentos de la Base de Datos de Películas en Internet (IMDB).",
        "MovieLens permite a los usuarios clasificar cuánto disfrutaron una película específica en una escala del 1 al 5.",
        "Esta calificación de simpatía se utilizó como una medida de cuán relevante es el documento que representa la película correspondiente para el usuario.",
        "Consideramos los documentos con puntuaciones de 4 o 5 como relevantes, y los documentos con una puntuación de 1 a 3 como irrelevantes para el usuario.",
        "MovieLens proporcionó juicios de relevancia sobre 3,057 documentos de 6,040 usuarios diferentes.",
        "En promedio, cada usuario calificó 151 películas, de las cuales 87 fueron consideradas relevantes.",
        "La puntuación promedio para un documento fue de 3.58.",
        "Los documentos que representan cada película fueron construidos a partir de la porción de la base de datos de IMDB que está disponible para descarga pública[13].",
        "Basándonos en esta base de datos, creamos un documento por película que contenía la información relevante sobre ella (por ejemplo, directores, actores, etc.).",
        "Tabla 1: Estadísticas del conjunto de datos.",
        "En Reuters, el número de calificaciones para un usuario simulado es el número de documentos relevantes para el tema correspondiente.",
        "Datos Usuarios Documentos Calificaciones por Usuario MovieLens 6,040 3,057 151 Netflix-todos 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Datos de Netflix: Este conjunto de datos fue construido combinando documentos sobre películas obtenidos de la web con un conjunto de juicios de relevancia de clientes reales de alquiler de películas de Netflix[19].",
        "Netflix proporciona públicamente las evaluaciones de relevancia de 480,189 clientes anónimos.",
        "Hay alrededor de 100 millones de calificaciones en una escala del 1 al 5 para 17,770 documentos.",
        "Similar a MovieLens, consideramos documentos con puntuaciones de 4 o 5 de agradabilidad como relevantes.",
        "Este número se redujo a 1000 clientes mediante muestreo aleatorio.",
        "El cliente promedio en el conjunto de datos reducido proporcionó 127 juicios, de los cuales 70 fueron considerados relevantes.",
        "La puntuación promedio de los documentos es de 3.55.",
        "Datos de Reuters: Este es el Corpus de Reuters, Volumen 1.",
        "Cubre 810,000 noticias en inglés de Reuters desde el 20 de agosto de 1996 hasta el 19 de agosto de 1997.",
        "Solo se utilizaron las primeras 100,000 noticias en nuestros experimentos.",
        "El corpus de Reuters viene con una jerarquía de temas.",
        "Cada documento se asigna a una de varias ubicaciones en el árbol jerárquico.",
        "El primer nivel del árbol contiene cuatro temas, denotados como C, E, M y G. Para los experimentos en este artículo, el árbol fue cortado en el nivel 1 para crear cuatro árboles más pequeños, cada uno de los cuales corresponde a un conjunto de datos más pequeño: Reuters-E, Reuters-C, Reuters-M y Reuters-G. Para cada conjunto de datos pequeño, creamos varios perfiles, un perfil para cada nodo en un subárbol, para simular múltiples usuarios, cada uno con una definición de relevancia relacionada pero separada.",
        "Todos los perfiles de usuario en una sub-rama se supone que comparten la misma distribución de modelo previo.",
        "Dado que este corpus indica explícitamente solo los documentos relevantes para un tema (usuario), todos los demás documentos se consideran irrelevantes. 5.2 Evaluación Diseñamos los experimentos para responder a las siguientes tres preguntas: 1.",
        "¿Necesitamos hacer el esfuerzo de utilizar un enfoque bayesiano y aprender una distribución a priori de otros usuarios? 2.",
        "¿El nuevo algoritmo funciona mejor que el algoritmo EM estándar para aprender el modelo lineal jerárquico bayesiano? 3.",
        "¿Puede el nuevo algoritmo aprender rápidamente muchos modelos de usuario?",
        "Para responder a la primera pregunta, comparamos los modelos jerárquicos bayesianos con los modelos de regresión lineal regularizados Norm-2 comúnmente utilizados.",
        "De hecho, el enfoque comúnmente utilizado es equivalente al modelo aprendido al final de la primera iteración de EM.",
        "Para responder a la segunda pregunta, comparamos el nuevo algoritmo propuesto con el algoritmo EM estándar para ver si el nuevo algoritmo de aprendizaje es mejor.",
        "Para responder a la tercera pregunta, probamos la eficiencia del nuevo algoritmo en todo el conjunto de datos de Netflix, donde aproximadamente medio millón de modelos de usuario deben ser aprendidos juntos.",
        "Para los conjuntos de datos de MovieLens y Netflix, la efectividad del algoritmo se midió mediante el error cuadrático medio, mientras que en el conjunto de datos de Reuters se utilizó el error de clasificación porque era más informativo.",
        "Primero evaluamos el rendimiento en cada usuario individual, y luego estimamos el promedio macro sobre todos los usuarios.",
        "Se realizaron pruebas estadísticas (pruebas t) para determinar si los resultados son significativos.",
        "Para los experimentos en los conjuntos de datos de MovieLens y Netflix, utilizamos una muestra aleatoria del 90% de cada usuario para entrenamiento, y el resto para pruebas.",
        "En el conjunto de datos de Reuters, debido a que hay demasiados documentos relevantes para cada tema en el corpus, utilizamos una muestra aleatoria del 10% de cada tema para el entrenamiento, y el 10% de los documentos restantes para las pruebas.",
        "Para todas las ejecuciones, establecimos (a, b, c, Σ) = (0.1, 10, 0.1, 1) manualmente. 6.",
        "RESULTADOS EXPERIMENTALES Las Figuras 2, 3 y 4 muestran que en todos los conjuntos de datos, el enfoque de modelado jerárquico bayesiano tiene una mejora estadísticamente significativa sobre el modelo de regresión lineal regularizado, que es equivalente a los modelos jerárquicos bayesianos aprendidos en la primera iteración.",
        "Un análisis adicional muestra una correlación negativa entre la cantidad de datos de entrenamiento para un usuario y la mejora que obtiene el sistema.",
        "Esto sugiere que la información prestada de otros usuarios tiene mejoras más significativas para usuarios con menos datos de entrenamiento, lo cual es lo esperado.",
        "Sin embargo, la fuerza de la correlación varía entre los conjuntos de datos, y la cantidad de datos de entrenamiento no es la única característica que influirá en el rendimiento final.",
        "Las Figuras 2 y 3 muestran que el nuevo algoritmo propuesto funciona mejor que el algoritmo EM estándar en los conjuntos de datos de Netflix y MovieLens.",
        "Esto no es sorprendente ya que el número de pares de características-usuarios relacionados es mucho menor que el número de pares de características-usuarios no relacionados en estos dos conjuntos de datos, por lo que se espera que el nuevo algoritmo propuesto funcione mejor.",
        "La Figura 4 muestra que los dos algoritmos funcionan de manera similar en el conjunto de datos de Reuters-E.",
        "La precisión del nuevo algoritmo es similar a la del algoritmo EM estándar en cada iteración.",
        "Los patrones generales son muy similares en otros subconjuntos de Reuters.",
        "Un análisis adicional muestra que solo el 58% de los pares usuario-característica no están relacionados en este conjunto de datos.",
        "Dado que el número de pares usuario-característica no relacionados no es extremadamente grande, la dispersión no es un problema grave en el conjunto de datos de Reuters.",
        "Por lo tanto, los dos algoritmos de aprendizaje se desempeñan de manera similar.",
        "Los resultados sugieren que solo en un corpus donde el número de pares usuario-característica no relacionados es mucho mayor que el número de pares relacionados, como en el conjunto de datos de Netflix, la técnica propuesta obtendrá una mejora significativa sobre el EM estándar.",
        "Sin embargo, los experimentos también muestran que cuando la suposición no se cumple, el nuevo algoritmo no afecta el rendimiento.",
        "Aunque la técnica propuesta es más rápida que la estándar. Figura 2: Rendimiento en un subconjunto de Netflix con 1,000 usuarios.",
        "El nuevo algoritmo es estadísticamente significativamente mejor que el algoritmo EM en las iteraciones 2 a 10.",
        "Los modelos lineales regularizados con norma-2 son equivalentes a los modelos jerárquicos bayesianos aprendidos en la primera iteración, y son estadísticamente significativamente peores que los modelos jerárquicos bayesianos. Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional Figura 3: Rendimiento en un subconjunto de MovieLens con 1,000 usuarios.",
        "El nuevo algoritmo es significativamente mejor estadísticamente que el algoritmo EM en las iteraciones 2 a 17 (evaluado con error cuadrático medio). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iteraciones ErrorCuadráticoMedio Nuevo Algoritmo EM Tradicional 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iteraciones Error de Clasificación Nuevo Algoritmo EM Tradicional Figura 4: Rendimiento en un subconjunto de Reuters-E con 26 perfiles.",
        "Las actuaciones en Reuters-C, Reuters-M, Reuters-G son similares. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional EM, ¿realmente puede aprender rápidamente millones de modelos de usuario?",
        "Nuestros resultados muestran que el algoritmo EM modificado converge rápidamente, y 2-3 iteraciones del EM modificado darían como resultado una estimación confiable.",
        "Evaluamos el algoritmo en todo el conjunto de datos de Netflix (480,189 usuarios, 159,836 características y 100 millones de valoraciones) ejecutándolo en un solo PC con CPU (2GB de memoria, P4 3GHz).",
        "El sistema completó una iteración EM modificada en aproximadamente 4 horas.",
        "Esto demuestra que la técnica propuesta puede manejar eficientemente sistemas a gran escala como Netflix.",
        "CONCLUSIÓN El aprendizaje de perfiles de usuario basado en contenido es un problema importante y es clave para proporcionar recomendaciones personales a un usuario, especialmente para recomendar nuevos elementos con un pequeño número de calificaciones.",
        "El enfoque de modelado jerárquico bayesiano se está convirtiendo en un enfoque importante para el aprendizaje de perfiles de usuario debido a su capacidad teóricamente justificada para ayudar a un usuario a través de la transferencia de información de otros usuarios mediante hiperpriors.",
        "Este artículo examinó la debilidad del enfoque de aprendizaje basado en EM popular para modelos lineales jerárquicos bayesianos y propuso una técnica de aprendizaje mejorada llamada EM Modificado.",
        "Demostramos que la nueva técnica es teóricamente más eficiente computacionalmente que el algoritmo EM estándar.",
        "La evaluación en los conjuntos de datos de MovieLens y Netflix demostró la efectividad de la nueva técnica cuando los datos son dispersos, lo que significa que la proporción de pares de usuario-característica relacionados con respecto a los pares no relacionados es pequeña.",
        "La evaluación en el conjunto de datos de Reuters mostró que la nueva técnica tuvo un rendimiento similar al algoritmo EM estándar cuando la condición de dispersión no se cumple.",
        "En general, es mejor utilizar el nuevo algoritmo ya que es tan simple como el EM estándar, el rendimiento es igual o mejor que el del EM, y la complejidad computacional es menor en cada iteración.",
        "Vale la pena mencionar que aunque el espacio de problemas original no sea disperso, la dispersión puede crearse artificialmente cuando un sistema de recomendación utiliza técnicas de selección de características específicas del usuario para reducir el ruido y la complejidad del modelo del usuario.",
        "La técnica propuesta también puede adaptarse para mejorar el aprendizaje en dicho escenario.",
        "También demostramos que la técnica propuesta puede aprender medio millón de perfiles de usuario a partir de 100 millones de valoraciones en unas pocas horas con una sola CPU.",
        "La investigación es importante porque la escalabilidad es una preocupación importante para los investigadores al utilizar el enfoque de modelado lineal jerárquico bayesiano para construir un sistema a gran escala práctico, a pesar de que la literatura ha demostrado la efectividad de los modelos en muchas aplicaciones.",
        "Nuestro trabajo es un paso importante en el camino para hacer que los modelos lineales jerárquicos bayesianos sean más prácticos.",
        "La nueva técnica propuesta se puede adaptar fácilmente para ejecutarse en un clúster de máquinas, y así acelerar aún más el proceso de aprendizaje para manejar un sistema a mayor escala con cientos de millones de usuarios.",
        "La investigación tiene mucho potencial para beneficiar a las personas utilizando el algoritmo EM en muchos otros problemas de IR, así como en problemas de aprendizaje automático.",
        "El algoritmo EM es una técnica de aprendizaje automático comúnmente utilizada.",
        "Se utiliza para encontrar los parámetros del modelo en muchos problemas de IR donde los datos de entrenamiento son muy dispersos.",
        "Aunque nos estamos centrando en los modelos lineales jerárquicos bayesianos para recomendación y filtrado, la nueva idea de utilizar una solución analítica en lugar de una solución numérica para pares de usuario-característica no relacionados en el paso M podría adaptarse a muchos otros problemas. 8.",
        "AGRADECIMIENTOS Agradecemos a Wei Xu, David Lewis y a los revisores anónimos por sus valiosos comentarios sobre el trabajo descrito en este artículo.",
        "Parte del trabajo fue apoyado por Yahoo, Google, el Instituto de Almacenamiento de Datos a Escala Peta y el Instituto de Gestión de Datos Científicos Escalables.",
        "Cualquier opinión, hallazgo, conclusión o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las de los patrocinadores.",
        "REFERENCIAS [1] C. Basu, H. Hirsh y W. Cohen.",
        "Recomendación como clasificación: Utilizando información social y basada en contenido en la recomendación.",
        "En Actas de la Decimoquinta Conferencia Nacional de Inteligencia Artificial, 1998. [2] J. S. Breese, D. Heckerman y C. Kadie.",
        "Análisis empírico de algoritmos predictivos para filtrado colaborativo.",
        "Informe técnico, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan.",
        "Filtrado de documentos con redes de inferencia.",
        "En Actas de la Decimonovena Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor y A. Vinokourov.",
        "Método del núcleo para el filtrado de documentos.",
        "En la Undécima Conferencia de Recuperación de Información de Texto (TREC11).",
        "Instituto Nacional de Normas y Tecnología, publicación especial 500-249, 2003. [5] C. Chelba y A. Acero.",
        "Adaptación del capitalizador de entropía máxima: Poca información puede ayudar mucho.",
        "En D. Lin y D. Wu, editores, Actas de EMNLP 2004, páginas 285-292, Barcelona, España, julio de 2004.",
        "Asociación de Lingüística Computacional. [6] B. Croft y J. Lafferty, editores.",
        "Modelado de lenguaje para recuperación de información.",
        "Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov y A. Genkin.",
        "Construyendo distribuciones a priori informativas a partir del conocimiento del dominio en la clasificación de textos.",
        "En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 493-500, Nueva York, NY, EE. UU., 2006.",
        "ACM Press. [8] J. Delgado y N. Ishii.",
        "Predicción basada en memoria ponderada para sistemas de recomendación.",
        "En el Taller ACM SIGIR99 sobre Sistemas de Recomendación, 1999. [9] GroupLens.",
        "Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman.",
        "Un tutorial sobre el aprendizaje con redes bayesianas.",
        "En M. Jordan, editor, Aprendizaje en Modelos Gráficos.",
        "Kluwer Academic, 1998. [11] J. L. Herlocker, J. \n\nKluwer Academic, 1998. [11] J. L. Herlocker, J.",
        "A. Konstan, A. Borchers y J. Riedl.",
        "Un marco algorítmico para realizar filtrado colaborativo.",
        "En SIGIR 99: Actas de la 22ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 230-237, Nueva York, NY, EE. UU., 1999.",
        "ACM Press. [12] T. Hofmann y J. Puzicha.",
        "Modelos de clases latentes para filtrado colaborativo.",
        "En IJCAI 99: Actas de la Decimosexta Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 688-693, San Francisco, CA, EE. UU., 1999.",
        "Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).\nMorgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).",
        "Base de datos de películas en internet. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai y L. Si.",
        "Un esquema de ponderación automática para filtrado colaborativo.",
        "En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 337-344, Nueva York, NY, EE. UU., 2004.",
        "ACM Press. [15] J.",
        "A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon y J. Riedl.",
        "GroupLens: Aplicando filtrado colaborativo a las noticias de Usenet.",
        "Comunicaciones de la ACM, 40(3):77-87, 1997. [16] D. Lewis.",
        "Aplicando máquinas de vectores de soporte a las tareas de filtrado y enrutamiento por lotes de TREC-2001.",
        "En Actas de la Undécima Conferencia de Recuperación de Texto (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee y P. Yu.",
        "Clasificación de texto mediante etiquetado de palabras.",
        "En Actas de la Decimonovena Conferencia Nacional de Inteligencia Artificial (AAAI-2004), 25-29 de julio de 2004. [18] P. Melville, R. J. Mooney y R. Nagarajan.",
        "Filtrado colaborativo potenciado por contenido para recomendaciones mejoradas.",
        "En Actas de la Decimoctava Conferencia Nacional de Inteligencia Artificial (AAAI-2002), Edmonton, Canadá, 2002. [19] Netflix.",
        "Premio Netflix. http://www.netflixprize.com (visitado el 30 de noviembre de 2006), 2006. [20] S. Robertson y K. Sparck-Jones.",
        "Ponderación de la relevancia de los términos de búsqueda.",
        "En Journal of the American Society for Information Science, volumen 27, páginas 129-146, 1976. [21] J. Wang, A. P. de Vries y M. J. T. Reinders.",
        "Unificando enfoques de filtrado colaborativo basados en usuarios y en elementos mediante la fusión de similitudes.",
        "En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 501-508, Nueva York, NY, EE. UU., 2006.",
        "ACM Press. [22] X. Wu y R. K. Srihari.",
        "Incorporando conocimientos previos con máquinas de vectores de soporte de margen ponderado.",
        "En Proc.",
        "Conferencia de Minería de Datos y Descubrimiento de Conocimiento de ACM (ACM SIGKDD 2004), agosto de 2004. [23] Y. Yang, S. Yoo, J. Zhang y B. Kisiel.",
        "Robustez de los métodos de filtrado adaptativo en una evaluación de referencia cruzada.",
        "En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 2005. [24] K. Yu, V. Tresp y A. Schwaighofer.",
        "Aprendiendo procesos gaussianos de múltiples tareas.",
        "En ICML 05: Actas de la 22ª conferencia internacional sobre aprendizaje automático, páginas 1012-1019, Nueva York, NY, EE. UU., 2005.",
        "ACM Press. [25] K. Yu, V. Tresp, y S. Yu.",
        "Un marco bayesiano jerárquico no paramétrico para el filtrado de información.",
        "En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 353-360.",
        "ACM Press, 2004. [26] X. Zhu. \n\nACM Press, 2004. [26] X. Zhu.",
        "Revisión de la literatura sobre aprendizaje semisupervisado.",
        "Informe técnico, Universidad de Wisconsin - Madison, 9 de diciembre de 2006. [27] P. Zigoris y Y. Zhang.",
        "Perfilado de usuario bayesiano adaptativo con retroalimentación explícita e implícita.",
        "En la Conferencia sobre Gestión de la Información y el Conocimiento 2006, 2006."
    ],
    "error_count": 0,
    "keys": {
        "modeling": {
            "translated_key": "modelado",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Efficient Bayesian Hierarchical User <br>modeling</br> for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
                "A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model.",
                "Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive.",
                "The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications.",
                "This paper proposes a new fast learning technique to learn a large number of individual user profiles.",
                "The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens.",
                "Categories and Subject Descriptors: B.3.3 [Information Search and Retrieval]: Information filtering General Terms: Algorithms 1.",
                "INTRODUCTION Personalization is the future of the Web, and it has achieved great success in industrial applications.",
                "For example, online stores, such as Amazon and Netflix, provide customized recommendations for additional products or services based on a users history.",
                "Recent offerings such as My MSN, My Yahoo!, My Google, and Google News have attracted much attention due to their potential ability to infer a users interests from his/her history.",
                "One major personalization topic studied in the information retrieval community is content-based personal recommendation systems1 .",
                "These systems learn user-specific profiles from user feedback so that they can recommend information tailored to each individual users interest without requiring the user to make an explicit query.",
                "Learning the user profiles is the core problem for these systems.",
                "A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user.",
                "One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small.",
                "This is known as the cold start problem.",
                "This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile.",
                "There has been much research on improving classification accuracy when the amount of labeled training data is small.",
                "The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal [26].",
                "Another approach is using domain knowledge.",
                "Researchers have modified different learning algorithms, such as Na¨ıveBayes [17], logistic regression [7], and SVMs [22], to integrate domain knowledge into a text classifier.",
                "The third approach is borrowing training data from other resources [5][7].",
                "The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data.",
                "One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical <br>modeling</br> approach.",
                "Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial performance for each user[27][25].",
                "In order to learn a Bayesian hierarchical model, the system usually tries to find the most likely model parameters for the given data.",
                "A mature recommendation system usually works for millions of users.",
                "It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users.",
                "The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee.",
                "However, a content based recommendation system often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector.",
                "With careful analysis of the EM algorithm in this scenario (Section 4), we find that the EM tering, or item-based collaborative filtering.",
                "In this paper, the words filtering and recommendation are used interchangeably. algorithm converges very slowly due to the sparseness of the input variables.",
                "We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O(MK), where M is the number of users and K is the number of dimensions.",
                "This paper modifies the standard EM algorithm to create an improved learning algorithm, which we call the Modified EM algorithm.",
                "The basic idea is that instead of calculating the numerical solution for all the user profile parameters, we derive the analytical solution of the parameters for some feature dimensions, and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters.",
                "This greatly reduces the computation at a single EM iteration, and also has the benefit of increasing the convergence speed of the learning algorithm.",
                "The proposed technique is not only well supported by theory, but also by experimental results.",
                "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression <br>modeling</br> framework used for content-based recommendations.",
                "Section 4 describes how to learn the model parameters using the standard EM algorithm, along with using the new technique proposed in this paper.",
                "The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6.",
                "Section 7 summarizes and offers concluding remarks. 2.",
                "RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the IR community since the 1970s.",
                "The approaches that have been used to solve this problem can be roughly classified into two major categories: content based filtering versus collaborative filtering.",
                "Content-based filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user.",
                "The user may read the delivered documents and provide explicit relevance feedback, which the filtering system then uses to update the users profile using relevance feedback retrieval models (e.g.",
                "Boolean models, vector space models, traditional probabilistic models [20] , inference networks [3] and language models [6]) or machine learning algorithms (e.g.",
                "Support Vector Machines (SVM), K nearest neighbors (K-NN) clustering, neural networks, logistic regression, or Winnow [16] [4] [23]).",
                "Collaborative filtering goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past.",
                "Memorybased heuristics and model based approaches have been used in collaborative filtering task [15] [8] [2] [14] [12] [11].",
                "This paper contributes to the content-based recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks[27][25].",
                "This paper does not intend to compare content-based filtering with collaborative filtering or claim which one is a better.",
                "We think each complements the other, and that content-based filtering is extremely useful for handling new documents/items with little or no user feedback.",
                "Similar to some other researchers[18][1][21], we found that a recommendation system will be more effective when both techniques are combined.",
                "However, this is beyond the scope of this paper and thus not discussed here. 3.",
                "BAYESIAN HIERARCHICAL LINEAR REGRESSION Assume there are M users in the system.",
                "The task of the system is to recommend documents that are relevant to each user.",
                "For each user, the system learns a user model from the users history.",
                "In the rest of this paper, we will use the following notations to represent the variables in the system. m = 1, 2, ..., M: The index for each individual user.",
                "M is the total number of users. wm: The user model parameter associated with user m. wm is a K dimensional vector. j = 1, 2, ..., Jm: The index for a set of data for user m. Jm is the number of training data for user m. Dm = {(xm,j, ym,j)}: A set of data associated with user m. xm,j is a K dimensional vector that represents the mth users jth training document.2 ym,j is a scalar that represents the label of document xm,j. k = 1, 2, ..., K: The dimensional index of input variable x.",
                "The Bayesian hierarchical <br>modeling</br> approach has been widely used in real-world information retrieval applications.",
                "Generalized Bayesian hierarchical linear models, one of the simplest Bayesian hierarchical models, are commonly used and have achieved good performance on collaborative filtering [25] and content-based adaptive filtering [27] tasks.",
                "Figure 1 shows the graphical representation of a Bayesian hierarchical model.",
                "In this graph, each user model is represented by a random vector wm.",
                "We assume a user model is sampled randomly from a prior distribution P(w|Φ).",
                "The system can predict the user label y of a document x given an estimation of wm (or wms distribution) using a function y = f(x, w).",
                "The model is called generalized Bayesian hierarchical linear model when y = f(wT x) is any generalized linear model such as logistic regression, SVM, and linear regression.",
                "To reliably estimate the user model wm, the system can borrow information from other users through the prior Φ = (µ, Σ).",
                "Now we look at one commonly used model where y = wT x + , where ∼ N(0, σ2 ) is a random noise [25][27].",
                "Assume that each user model wm is an independent draw from a population distribution P(w|Φ), which is governed by some unknown hyperparameter Φ.",
                "Let the prior distribution of user model w be a Gaussian distribution with parameter Φ = (µ, Σ), which is the commonly used prior for linear models. µ = (µ1, µ2, ..., µK ) is a K dimensional vector that represents the mean of the Gaussian distribution, and Σ is the covariance matrix of the Gaussian.",
                "Usually, a Normal distribution N(0, aI) and an Inverse Wishart distribution P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) are used as hyperprior to model the prior distribution of µ and Σ respectively.",
                "I is the K dimensional identity matrix, and a, b, and c are real numbers.",
                "With these settings, we have the following model for the system: 1. µ and Σ are sampled from N(0, aI) and IWν (aI), respectively. 2 The first dimension of x is a dummy variable that always equals to 1.",
                "Figure 1: Illustration of dependencies of variables in the hierarchical model.",
                "The rating, y, for a document, x, is conditioned on the document and the user model, wm, associated with the user m. Users share information about their models through the prior, Φ = (µ, Σ). 2.",
                "For each user m, wm is sampled randomly from a Normal distribution: wm ∼ N(µ, Σ2 ) 3.",
                "For each item xm,j, ym,j is sampled randomly from a Normal distribution: ym,j ∼ N(wT mxm,j, σ2 ).",
                "Let θ = (Φ, w1, w2, ..., wM ) represent the parameters of this system that needs to be estimated.",
                "The joint likelihood for all the variables in the probabilistic model, which includes the data and the parameters, is: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) For simplicity, we assume a, b, c, and σ are provided to the system. 4.",
                "MODEL PARAMETER LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple linear regression.",
                "Therefore, we will focus on estimating Φ.",
                "The maximum a priori solution of Φ is given by ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Finding the optimal solution for the above problem is challenging, since we need to integrate over all w = (w1, w2, ..., wM ), which are unobserved hidden variables. 4.1 EM Algorithm for Bayesian Hierarchical Linear Models In Equation 5, Φ is the parameter needs to be estimated, and the result depends on unobserved latent variables w. This kind of optimization problem is usually solved by the EM algorithm.",
                "Applying EM to the above problem, the set of user models w are the unobservable hidden variables and we have: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw Based on the derivation of the EM formulas presented in [24], we have the following Expectation-Maximization steps for finding the optimal hyperparameters.",
                "For space considerations, we omit the derivation in this paper since it is not the focus of our work.",
                "E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of the prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) where Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j M step: Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Many machine learning driven IR systems use a point estimate of the parameters at different stages in the system.",
                "However, we are estimating the posterior distribution of the variables at the E step.",
                "This avoids overfitting wm to a particular users data, which may be small and noisy.",
                "A detailed discussion about this subject appears in [10]. 4.2 New Algorithm: Modified EM Although the EM algorithm is widely studied and used in machine learning applications, using the above EM process to solve Bayesian hierarchical linear models in large-scale information retrieval systems is still too computationally expensive.",
                "In this section, we describe why the learning rate of the EM algorithm is slow in our application and introduce a new technique to make the learning of the Bayesian hierarchical linear model scalable.",
                "The derivation of the new learning algorithm will be based on the EM algorithm described in the previous section.",
                "First, the covariance matrices Σ2 , Σ2 m are usually too large to be computationally feasible.",
                "For simplicity, and as a common practice in IR, we do not model the correlation between features.",
                "Thus we approximate these matrices with K dimensional diagonal matrices.",
                "In the rest of the paper, we use these symbols to represent their diagonal approximations: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     Secondly, and most importantly, the input space is very sparse and there are many dimensions that are not related to a particular user in a real IR application.",
                "For example, let us consider a movie recommendation system, with the input variable x representing a particular movie.",
                "For the jth movie that the user m has seen, let xm,j,k = 1 if the director of the movie is Jean-Pierre Jeunet (indexed by k).",
                "Here we assume that whether or not that this director directed a specific movie is represented by the kth dimension.",
                "If the user m has never seen a movie directed by Jean-Pierre Jeunet, then the corresponding dimension is always zero (xm,j,k = 0 for all j) .",
                "One major drawback of the EM algorithm is that the importance of a feature, µk, may be greatly dominated by users who have never encountered this feature (i.e. j xm,j,k = 0) at the M step (Equation 8).",
                "Assume that 100 out of 1 million users have viewed the movie directed by Jean-Pierre Jeunet, and that the viewers have rated all of his movies as excellent.",
                "Intuitively, he is a good director and the weight for him (µk) should be high.",
                "Before the EM iteration, the initial value of µ is usually set to 0.",
                "Since the other 999,900 users have not seen this movie, their corresponding weights (w1,k, w2,k, ..., wm,k..., w999900,k) for that director would be very small initially.",
                "Thus the corresponding weight of the director in the prior µk at the first M step would be very low , and the variance σm,k will be large (Equations 8 and 7).",
                "It is undesirable that users who have never seen any movie produced by the director influence the importance of the director so much.",
                "This makes the convergence of the standard EM algorithm very slow.",
                "Now lets look at whether we can improve the learning speed of the algorithm.",
                "Without a loss of generality, let us assume that the kth dimension of the input variable x is not related to a particular user m. By which we mean, xm,j,k = 0 for all j = 1, ..., Jm.",
                "It is straightforward to prove that the kth row and kth column of Sxx,m are completely filled with zeros, and that the kth dimension of Sxy,m is zeroed as well.",
                "Thus the corresponding kth dimension of the user models mean, ¯wm, should be equal to that of the prior: ¯wm,k = µk, with the corresponding covariance of σm,k = σk.",
                "At the M step, the standard EM algorithm uses the numerical solution of the distribution P(wm|Dm, Φ) estimated at E step (Equation 8 and Equation 7).",
                "However, the numerical solutions are very unreliable for ¯wm,k and σm,k when the kth dimension is not related to the mth user.",
                "A better approach is using the analytical solutions ¯wm,k = µk, and σm,k = σk for the unrelated (m, k) pairs, along with the numerical solution estimated at E step for the other (m, k) pairs.",
                "Thus we get the following new EM-like algorithm: Modified E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) where sxx,m,k = j x2 m,j,k and sxy,m,k = j xm,j,kym,j Modified M Step Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step for related userfeature pairs.",
                "The M step implicitly uses the analytical solution for unrelated user-feature pairs. µk = 1 Mk m:related ¯wm,k (12) σ2 k = 1 Mk m:related σ2 m,k +( ¯wm,k − µk)( ¯wm,k − µk)T (13) where Mk is the number of users that are related to feature k We only estimate the diagonal of Σ2 m and Σ since we are using the diagonal approximation of the covariance matrices.",
                "To estimate ¯wm, we only need to calculate the numerical solutions for dimensions that are related to user m. To estimate σ2 k and µk, we only sum over users that are related to the kth feature.",
                "There are two major benefits of the new algorithm.",
                "First, because only the related (m, k) pairs are needed at the modified M step, the computational complexity in a single EM iteration is much smaller when the data is sparse, and many of (m, k) pairs are unrelated.",
                "Second, the parameters estimated at the modified M step (Equations 12 - 13) are more accurate than the standard M step described in Section 4.1 because the exact analytical solutions ¯wm,k = µk and σm,k = σk for the unrelated (m, k) pairs were used in the new algorithm instead of an approximate solution as in the standard algorithm. 5.",
                "EXPERIMENTAL METHODOLOGY 5.1 Evaluation Data Set To evaluate the proposed technique, we used the following three major data sets (Table 1): MovieLens Data: This data set was created by combining the relevance judgments from the MovieLens[9] data set with documents from the Internet Movie Database (IMDB).",
                "MovieLens allows users to rank how much he/she enjoyed a specific movie on a scale from 1 to 5.",
                "This likeability rating was used as a measurement of how relevant the document representing the corresponding movie is to the user.",
                "We considered documents with likeability scores of 4 or 5 as relevant, and documents with a score of 1 to 3 as irrelevant to the user.",
                "MovieLens provided relevance judgments on 3,057 documents from 6,040 separate users.",
                "On average, each user rated 151 movies, of these 87 were judged to be relevant.",
                "The average score for a document was 3.58.",
                "Documents representing each movie were constructed from the portion of the IMDB database that is available for public download[13].",
                "Based on this database, we created one document per movie that contained the relevant information about it (e.g. directors, actors, etc.).",
                "Table 1: Data Set Statistics.",
                "On Reuters, the number of rating for a simulated user is the number of documents relevant to the corresponding topic.",
                "Data Users Docs Ratings per User MovieLens 6,040 3,057 151 Netflix-all 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Netflix Data: This data set was constructed by combining documents about movies crawled from the web with a set of actual movie rental customer relevance judgments from Netflix[19].",
                "Netflix publicly provides the relevance judgments of 480,189 anonymous customers.",
                "There are around 100 million rating on a scale of 1 to 5 for 17,770 documents.",
                "Similar to MovieLens, we considered documents with likeability scores of 4 or 5 as relevant.",
                "This number was reduced to 1000 customers through random sampling.",
                "The average customer on the reduced data set provided 127 judgments, with 70 being deemed relevant.",
                "The average score for documents is 3.55.",
                "Reuters Data: This is the Reuters Corpus, Volume 1.",
                "It covers 810,000 Reuters English language news stories from August 20, 1996 to August 19, 1997.",
                "Only the first 100,000 news were used in our experiments.",
                "The Reuters corpus comes with a topic hierarchy.",
                "Each document is assigned to one of several locations on the hierarchical tree.",
                "The first level of the tree contains four topics, denoted as C, E, M, and G. For the experiments in this paper, the tree was cut at level 1 to create four smaller trees, each of which corresponds to one smaller data set: Reuters-E Reuters-C, ReutersM and Reuters-G. For each small data set, we created several profiles, one profile for each node in a sub-tree, to simulate multiple users, each with a related, yet separate definition of relevance.",
                "All the user profiles on a sub-tree are supposed to share the same prior model distribution.",
                "Since this corpus explicitly indicates only the relevant documents for a topic(user), all other documents are considered irrelevant. 5.2 Evaluation We designed the experiments to answer the following three questions: 1.",
                "Do we need to take the effort to use a Bayesian approach and learn a prior from other users? 2.",
                "Does the new algorithm work better than the standard EM algorithm for learning the Bayesian hierarchical linear model? 3.",
                "Can the new algorithm quickly learn many user models?",
                "To answer the first question, we compared the Bayesian hierarchical models with commonly used Norm-2 regularized linear regression models.",
                "In fact, the commonly used approach is equivalent to the model learned at the end of the first EM iteration.",
                "To answer the second question, we compared the proposed new algorithm with the standard EM algorithm to see whether the new learning algorithm is better.",
                "To answer the third question, we tested the efficiency of the new algorithm on the entire Netflix data set where about half a million user models need to be learned together.",
                "For the MovieLens and Netflix data sets, algorithm effectiveness was measured by mean square error, while on the Reuters data set classification error was used because it was more informative.",
                "We first evaluated the performance on each individual user, and then estimated the macro average over all users.",
                "Statistical tests (t-tests) were carried out to see whether the results are significant.",
                "For the experiments on the MovieLens and Netflix data sets, we used a random sample of 90% of each user for training, and the rest for testing.",
                "On Reuters data set, because there are too many relevant documents for each topic in the corpus, we used a random sample of 10% of each topic for training, and 10% of the remaining documents for testing.",
                "For all runs, we set (a, b, c, Σ ) = (0.1, 10, 0.1, 1) manually. 6.",
                "EXPERIMENTAL RESULTS Figure 2, Figure 3, and Figure 4 show that on all data sets, the Bayesian hierarchical <br>modeling</br> approach has a statistical significant improvement over the regularized linear regression model, which is equivalent to the Bayesian hierarchical models learned at the first iteration.",
                "Further analysis shows a negative correlation between the number of training data for a user and the improvement the system gets.",
                "This suggests that the borrowing information from other users has more significant improvements for users with less training data, which is as expected.",
                "However, the strength of the correlation differs over data sets, and the amount of training data is not the only characteristics that will influence the final performance.",
                "Figure 2 and Figure 3 show that the proposed new algorithm works better than the standard EM algorithm on the Netflix and MovieLens data sets.",
                "This is not surprising since the number of related feature-users pairs is much smaller than the number of unrelated feature-user pairs on these two data sets, and thus the proposed new algorithm is expected to work better.",
                "Figure 4 shows that the two algorithms work similarly on the Reuters-E data set.",
                "The accuracy of the new algorithm is similar to that of the standard EM algorithm at each iteration.",
                "The general patterns are very similar on other Reuters subsets.",
                "Further analysis shows that only 58% of the user-feature pairs are unrelated on this data set.",
                "Since the number of unrelated user-feature pairs is not extremely large, the sparseness is not a serious problem on the Reuters data set.",
                "Thus the two learning algorithms perform similarly.",
                "The results suggest that only on a corpus where the number of unrelated user-feature pairs is much larger than the number of related pairs, such as on the Netflix data set, the proposed technique will get a significant improvement over standard EM.",
                "However, the experiments also show that when the assumption does not hold, the new algorithm does not hurt performance.",
                "Although the proposed technique is faster than standard Figure 2: Performance on a Netflix subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iterations 2 - 10.",
                "Norm-2 regularized linear models are equivalent to the Bayesian hierarchical models learned at the first iteration, and are statistical significantly worse than the Bayesian hierarchical models. 0 2 4 6 8 10 1 1.05 1.1 1.15 1.2 1.25 1.3 1.35 1.4 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iterations ClassificationError New Algorithm Traditional EM Figure 3: Performance on a MovieLens subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iteration 2 to 17 (evaluated with mean square error). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iterations MeanSquareError New Algorithm Traditional EM 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iterations ClassificationError New Algorithm Traditional EM Figure 4: Performance on a Reuters-E subset with 26 profiles.",
                "Performances on Reuters-C, Reuters-M, Reuters-G are similar. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iterations ClassificationError New Algorithm Traditional EM EM, can it really learn millions of user models quickly?",
                "Our results show that the modified EM algorithm converges quickly, and 2 - 3 modified EM iterations would result in a reliable estimation.",
                "We evaluated the algorithm on the whole Netflix data set (480,189 users, 159,836 features, and 100 million ratings) running on a single CPU PC (2GB memory, P4 3GHz).",
                "The system finished one modified EM iteration in about 4 hours.",
                "This demonstrates that the proposed technique can efficiently handle large-scale system like Netflix. 7.",
                "CONCLUSION Content-based user profile learning is an important problem and is the key to providing personal recommendations to a user, especially for recommending new items with a small number of ratings.",
                "The Bayesian hierarchical <br>modeling</br> approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors.",
                "This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM.",
                "We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm.",
                "Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse, by which we mean the ratio of related user-feature pairs to unrelated pairs is small.",
                "Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold.",
                "In general, it is better to use the new algorithm since it is as simple as standard EM, the performance is either better or similar to EM, and the computation complexity is lower at each iteration.",
                "It is worth mentioning that even if the original problem space is not sparse, sparseness can be created artificially when a recommendation system uses user-specific feature selection techniques to reduce the noise and user model complexity.",
                "The proposed technique can also be adapted to improve the learning in such a scenario.",
                "We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU.",
                "The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear <br>modeling</br> approach to build a practical large scale system, even though the literature have demonstrated the effectiveness of the models in many applications.",
                "Our work is one major step on the road to make Bayesian hierarchical linear models more practical.",
                "The proposed new technique can be easily adapted to run on a cluster of machines, and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users.",
                "The research has much potential to benefit people using EM algorithm on many other IR problems as well as machine learning problems.",
                "EM algorithm is a commonly used machine learning technique.",
                "It is used to find model parameters in many IR problems where the training data is very sparse.",
                "Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering, the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems. 8.",
                "ACKNOWLEDGMENTS We thank Wei Xu, David Lewis and anonymous reviewers for valuable feedback on the work described in this paper.",
                "Part of the work was supported by Yahoo, Google, the Petascale Data Storage Institute and the Institute for Scalable Scientific Data Management.",
                "Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors, and do not necessarily reflect those of the sponsors. 9.",
                "REFERENCES [1] C. Basu, H. Hirsh, and W. Cohen.",
                "Recommendation as classification: Using social and content-based information in recommendation.",
                "In Proceedings of the Fifteenth National Conference on Artificial Intelligence, 1998. [2] J. S. Breese, D. Heckerman, and C. Kadie.",
                "Empirical analysis of predictive algorithms for collaborative filtering.",
                "Technical report, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan.",
                "Document filtering with inference networks.",
                "In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor, and A. Vinokourov.",
                "Kernel method for document filtering.",
                "In The Eleventh Text REtrieval Conference (TREC11).",
                "National Institute of Standards and Technology, special publication 500-249, 2003. [5] C. Chelba and A. Acero.",
                "Adaptation of maximum entropy capitalizer: Little data can help a lot.",
                "In D. Lin and D. Wu, editors, Proceedings of EMNLP 2004, pages 285-292, Barcelona, Spain, July 2004.",
                "Association for Computational Linguistics. [6] B. Croft and J. Lafferty, editors.",
                "Language <br>modeling</br> for Information Retrieval.",
                "Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov, and A. Genkin.",
                "Constructing informative prior distributions from domain knowledge in text classification.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 493-500, New York, NY, USA, 2006.",
                "ACM Press. [8] J. Delgado and N. Ishii.",
                "Memory-based weightedmajority prediction for recommender systems.",
                "In ACM SIGIR99 Workshop on Recommender Systems, 1999. [9] GroupLens.",
                "Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman.",
                "A tutorial on learning with bayesian networks.",
                "In M. Jordan, editor, Learning in Graphical Models.",
                "Kluwer Academic, 1998. [11] J. L. Herlocker, J.",
                "A. Konstan, A. Borchers, and J. Riedl.",
                "An algorithmic framework for performing collaborative filtering.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 230-237, New York, NY, USA, 1999.",
                "ACM Press. [12] T. Hofmann and J. Puzicha.",
                "Latent class models for collaborative filtering.",
                "In IJCAI 99: Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 688-693, San Francisco, CA, USA, 1999.",
                "Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).",
                "Internet movie database. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai, and L. Si.",
                "An automatic weighting scheme for collaborative filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 337-344, New York, NY, USA, 2004.",
                "ACM Press. [15] J.",
                "A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl.",
                "GroupLens: Applying collaborative filtering to Usenet news.",
                "Communications of the ACM, 40(3):77-87, 1997. [16] D. Lewis.",
                "Applying support vector machines to the TREC-2001 batch filtering and routing tasks.",
                "In Proceedings of the Eleventh Text REtrieval Conference (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee, , and P. Yu.",
                "Text classification by labeling words.",
                "In Proceedings of The Nineteenth National Conference on Artificial Intelligence (AAAI-2004), July 25-29, 2004. [18] P. Melville, R. J. Mooney, and R. Nagarajan.",
                "Content-boosted collaborative filtering for improved recommendations.",
                "In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002), Edmonton, Canada, 2002. [19] Netflix.",
                "Netflix prize. http://www.netflixprize.com (visited on Nov. 30, 2006), 2006. [20] S. Robertson and K. Sparck-Jones.",
                "Relevance weighting of search terms.",
                "In Journal of the American Society for Information Science, volume 27, pages 129-146, 1976. [21] J. Wang, A. P. de Vries, and M. J. T. Reinders.",
                "Unifying user-based and item-based collaborative filtering approaches by similarity fusion.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 501-508, New York, NY, USA, 2006.",
                "ACM Press. [22] X. Wu and R. K. Srihari.",
                "Incorporating prior knowledge with weighted margin support vector machines.",
                "In Proc.",
                "ACM Knowledge Discovery Data Mining Conf. (ACM SIGKDD 2004), Aug. 2004. [23] Y. Yang, S. Yoo, J. Zhang, and B. Kisiel.",
                "Robustness of adaptive filtering methods in a cross-benchmark evaluation.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2005. [24] K. Yu, V. Tresp, and A. Schwaighofer.",
                "Learning gaussian processes from multiple tasks.",
                "In ICML 05: Proceedings of the 22nd international conference on Machine learning, pages 1012-1019, New York, NY, USA, 2005.",
                "ACM Press. [25] K. Yu, V. Tresp, and S. Yu.",
                "A nonparametric hierarchical bayesian framework for information filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 353-360.",
                "ACM Press, 2004. [26] X. Zhu.",
                "Semi-supervised learning literature survey.",
                "Technical report, University of Wisconsin - Madison, December 9, 2006. [27] P. Zigoris and Y. Zhang.",
                "Bayesian adaptive user profiling with explicit & implicit feedback.",
                "In Conference on Information and Knowledge Mangement 2006, 2006."
            ],
            "original_annotated_samples": [
                "Efficient Bayesian Hierarchical User <br>modeling</br> for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
                "One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical <br>modeling</br> approach.",
                "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression <br>modeling</br> framework used for content-based recommendations.",
                "The Bayesian hierarchical <br>modeling</br> approach has been widely used in real-world information retrieval applications.",
                "EXPERIMENTAL RESULTS Figure 2, Figure 3, and Figure 4 show that on all data sets, the Bayesian hierarchical <br>modeling</br> approach has a statistical significant improvement over the regularized linear regression model, which is equivalent to the Bayesian hierarchical models learned at the first iteration."
            ],
            "translated_annotated_samples": [
                "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual.",
                "Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de <br>modelado</br> jerárquico bayesiano.",
                "La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de <br>modelado</br> de regresión lineal jerárquica bayesiana utilizado para recomendaciones basadas en contenido.",
                "El enfoque de <br>modelado</br> jerárquico bayesiano ha sido ampliamente utilizado en aplicaciones reales de recuperación de información.",
                "RESULTADOS EXPERIMENTALES Las Figuras 2, 3 y 4 muestran que en todos los conjuntos de datos, el enfoque de <br>modelado</br> jerárquico bayesiano tiene una mejora estadísticamente significativa sobre el modelo de regresión lineal regularizado, que es equivalente a los modelos jerárquicos bayesianos aprendidos en la primera iteración."
            ],
            "translated_text": "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual. Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un modelo jerárquico bayesiano. Aprender los parámetros del modelo para optimizar la verosimilitud conjunta de los datos de millones de usuarios es muy costoso computacionalmente. El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de datos en aplicaciones de IR. Este documento propone una nueva técnica de aprendizaje rápido para aprender un gran número de perfiles de usuario individuales. La eficacia y eficiencia del algoritmo propuesto están justificadas por la teoría y demostradas en datos reales de usuarios de Netflix y MovieLens. Categorías y Descriptores de Asignaturas: B.3.3 [Búsqueda y Recuperación de Información]: Filtrado de información Términos Generales: Algoritmos 1. La personalización es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales. Por ejemplo, las tiendas en línea, como Amazon y Netflix, ofrecen recomendaciones personalizadas de productos o servicios adicionales basadas en el historial de un usuario. Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de un usuario a partir de su historial. Un tema importante de personalización estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados basados en el contenido. Estos sistemas aprenden perfiles específicos de usuario a partir de la retroalimentación del usuario para poder recomendar información adaptada a los intereses de cada usuario sin necesidad de que el usuario realice una consulta explícita. Aprender los perfiles de usuario es el problema central de estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica qué tan relevante es un documento para el usuario. Uno de los principales desafíos de construir un sistema de recomendación o personalización es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña. Esto se conoce como el problema de inicio en frío. Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente retroalimentación de ese usuario para aprender un perfil de usuario confiable. Se ha realizado mucha investigación sobre cómo mejorar la precisión de clasificación cuando la cantidad de datos de entrenamiento etiquetados es pequeña. El enfoque de aprendizaje semisupervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26]. Otro enfoque es utilizar el conocimiento del dominio. Los investigadores han modificado diferentes algoritmos de aprendizaje, como NaïveBayes [17], regresión logística [7] y SVMs [22], para integrar el conocimiento del dominio en un clasificador de texto. El tercer enfoque consiste en tomar datos de entrenamiento de otros recursos [5][7]. La efectividad de estos enfoques diferentes es mixta, debido a qué tan bien se ajusta la suposición del modelo subyacente a los datos. Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de <br>modelado</br> jerárquico bayesiano. Varios investigadores han demostrado que este enfoque intercambia eficazmente entre la información compartida y la específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario[27][25]. Para aprender un modelo jerárquico bayesiano, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados. Un sistema de recomendación maduro generalmente funciona para millones de usuarios. Es bien sabido que aprender los parámetros óptimos de un modelo jerárquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios. El algoritmo EM es una técnica comúnmente utilizada para el aprendizaje de parámetros debido a su simplicidad y garantía de convergencia. Sin embargo, un sistema de recomendación basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso. Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM tering, o filtrado colaborativo basado en elementos. En este documento, las palabras filtrado y recomendación se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de las variables de entrada. También encontramos que actualizar el parámetro del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones. Este documento modifica el algoritmo EM estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos algoritmo EM modificado. La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M utilizamos la solución analítica en lugar de la solución numérica estimada en el paso E para esos parámetros. Esto reduce considerablemente la computación en una sola iteración de EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales. La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de <br>modelado</br> de regresión lineal jerárquica bayesiana utilizado para recomendaciones basadas en contenido. La sección 4 describe cómo aprender los parámetros del modelo utilizando el algoritmo EM estándar, junto con el uso de la nueva técnica propuesta en este artículo. La configuración experimental y los resultados utilizados para validar la técnica de aprendizaje propuesta se informan en las Secciones 5 y 6. La sección 7 resume y ofrece observaciones finales. 2. TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de IR desde la década de 1970. Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus filtrado colaborativo. El filtrado basado en contenido estudia el escenario en el que un sistema de recomendación monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente. El usuario puede leer los documentos entregados y proporcionar retroalimentación explícita de relevancia, la cual el sistema de filtrado utiliza para actualizar el perfil del usuario mediante modelos de recuperación de retroalimentación de relevancia (por ejemplo,). Modelos booleanos, modelos de espacio vectorial, modelos probabilísticos tradicionales [20], redes de inferencia [3] y modelos de lenguaje [6]) o algoritmos de aprendizaje automático (por ejemplo, Máquinas de Vectores de Soporte (SVM), agrupamiento de K vecinos más cercanos (K-NN), redes neuronales, regresión logística o Winnow [16] [4] [23]. El filtrado colaborativo va más allá de simplemente usar el contenido de un documento para recomendar elementos a un usuario, aprovechando la información de otros usuarios con gustos y preferencias similares en el pasado. Se han utilizado heurísticas basadas en memoria y enfoques basados en modelos en la tarea de filtrado colaborativo [15] [8] [2] [14] [12] [11]. Este artículo contribuye a la investigación de recomendaciones basadas en contenido al mejorar la eficiencia y efectividad de los modelos lineales jerárquicos bayesianos, los cuales tienen una sólida base teórica y un buen rendimiento empírico en tareas de recomendación[27][25]. Este artículo no tiene la intención de comparar el filtrado basado en contenido con el filtrado colaborativo ni de afirmar cuál es mejor. Creemos que cada uno complementa al otro, y que el filtrado basado en contenido es extremadamente útil para manejar nuevos documentos/artículos con poco o ningún feedback del usuario. Similar a otros investigadores[18][1][21], encontramos que un sistema de recomendación será más efectivo cuando se combinan ambas técnicas. Sin embargo, esto está fuera del alcance de este documento y, por lo tanto, no se discute aquí. 3. REGRESIÓN LINEAL HIERÁRQUICA BAYESIANA Suponga que hay M usuarios en el sistema. La tarea del sistema es recomendar documentos que sean relevantes para cada usuario. Para cada usuario, el sistema aprende un modelo de usuario a partir del historial de los usuarios. En el resto de este documento, utilizaremos las siguientes notaciones para representar las variables en el sistema. m = 1, 2, ..., M: El índice para cada usuario individual. M es el número total de usuarios. wm: El parámetro del modelo de usuario asociado con el usuario m. wm es un vector de dimensión K. j = 1, 2, ..., Jm: El índice para un conjunto de datos para el usuario m. Jm es el número de datos de entrenamiento para el usuario m. Dm = {(xm,j, ym,j)}: Un conjunto de datos asociado con el usuario m. xm,j es un vector de dimensión K que representa el j-ésimo documento de entrenamiento del usuario m. ym,j es un escalar que representa la etiqueta del documento xm,j. k = 1, 2, ..., K: El índice dimensional de la variable de entrada x. El enfoque de <br>modelado</br> jerárquico bayesiano ha sido ampliamente utilizado en aplicaciones reales de recuperación de información. Los modelos lineales jerárquicos bayesianos generalizados, uno de los modelos jerárquicos bayesianos más simples, son comúnmente utilizados y han logrado un buen rendimiento en tareas de filtrado colaborativo [25] y filtrado adaptativo basado en contenido [27]. La Figura 1 muestra la representación gráfica de un modelo jerárquico bayesiano. En este gráfico, cada modelo de usuario está representado por un vector aleatorio wm. Suponemos que un modelo de usuario se muestrea aleatoriamente de una distribución previa P(w|Φ). El sistema puede predecir la etiqueta de usuario y de un documento x dado una estimación de wm (o distribución de wms) utilizando una función y = f(x, w). El modelo se llama modelo lineal jerárquico bayesiano generalizado cuando y = f(wT x) es cualquier modelo lineal generalizado como regresión logística, SVM y regresión lineal. Para estimar de manera confiable el modelo de usuario wm, el sistema puede obtener información de otros usuarios a través de la prior Φ = (µ, Σ). Ahora observamos un modelo comúnmente utilizado donde y = wT x + , donde ∼ N(0, σ2 ) es un ruido aleatorio [25][27]. Suponga que cada modelo de usuario wm es una muestra independiente de una distribución poblacional P(w|Φ), la cual está regida por un hiperparámetro desconocido Φ. Que la distribución previa del modelo de usuario w sea una distribución gaussiana con parámetro Φ = (µ, Σ), que es la distribución previa comúnmente utilizada para modelos lineales. µ = (µ1, µ2, ..., µK) es un vector de K dimensiones que representa la media de la distribución gaussiana, y Σ es la matriz de covarianza de la gaussiana. Normalmente, se utiliza una distribución Normal N(0, aI) y una distribución Inverse Wishart P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) como hiperprior para modelar la distribución previa de µ y Σ respectivamente. Yo es la matriz identidad de dimensión K, y a, b y c son números reales. Con esta configuración, tenemos el siguiente modelo para el sistema: 1. µ y Σ se muestrean de N(0, aI) e IWν (aI), respectivamente. 2. La primera dimensión de x es una variable ficticia que siempre es igual a 1. Figura 1: Ilustración de las dependencias de variables en el modelo jerárquico. La calificación, y, para un documento, x, está condicionada al documento y al modelo de usuario, wm, asociado con el usuario m. Los usuarios comparten información sobre sus modelos a través de la prior, Φ = (µ, Σ). Para cada usuario m, wm se muestrea aleatoriamente de una distribución Normal: wm ∼ N(µ, Σ2 ) 3. Para cada elemento xm,j, ym,j se muestrea aleatoriamente de una distribución Normal: ym,j ∼ N(wT mxm,j, σ2). Que θ = (Φ, w1, w2, ..., wM) represente los parámetros de este sistema que necesitan ser estimados. La verosimilitud conjunta de todas las variables en el modelo probabilístico, que incluye los datos y los parámetros, es: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) Para simplificar, asumimos que a, b, c y σ son proporcionados al sistema. 4. APRENDIZAJE DE PARÁMETROS DEL MODELO Si se conoce el prior Φ, encontrar el óptimo wm es sencillo: se trata de una regresión lineal simple. Por lo tanto, nos enfocaremos en estimar Φ. La solución a priori máxima de Φ se da por ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Encontrar la solución óptima para el problema anterior es desafiante, ya que necesitamos integrar sobre todos los w = (w1, w2, ..., wM), que son variables ocultas no observadas. 4.1 Algoritmo EM para Modelos Lineales Jerárquicos Bayesianos En la Ecuación 5, Φ es el parámetro que necesita ser estimado, y el resultado depende de las variables latentes no observadas w. Este tipo de problema de optimización suele resolverse mediante el algoritmo EM. Aplicando EM al problema anterior, el conjunto de modelos de usuario w son las variables ocultas no observables y tenemos: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw. Basándonos en la derivación de las fórmulas EM presentadas en [24], tenemos los siguientes pasos de Expectation-Maximization para encontrar los hiperparámetros óptimos. Por razones de espacio, omitimos la derivación en este artículo ya que no es el enfoque de nuestro trabajo. Paso E: Para cada usuario m, estime la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual del prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) donde Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j Paso M: Optimice el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Muchos sistemas de IR impulsados por aprendizaje automático utilizan una estimación puntual de los parámetros en diferentes etapas del sistema. Sin embargo, estamos estimando la distribución posterior de las variables en el paso E. Esto evita el sobreajuste de wm a los datos de un usuario en particular, que pueden ser pequeños y ruidosos. Una discusión detallada sobre este tema aparece en [10]. 4.2 Nuevo Algoritmo: EM Modificado. Aunque el algoritmo EM es ampliamente estudiado y utilizado en aplicaciones de aprendizaje automático, utilizar el proceso EM mencionado anteriormente para resolver modelos lineales jerárquicos bayesianos en sistemas de recuperación de información a gran escala sigue siendo demasiado costoso computacionalmente. En esta sección, describimos por qué la tasa de aprendizaje del algoritmo EM es lenta en nuestra aplicación e introducimos una nueva técnica para hacer que el aprendizaje del modelo lineal jerárquico bayesiano sea escalable. La derivación del nuevo algoritmo de aprendizaje estará basada en el algoritmo EM descrito en la sección anterior. Primero, las matrices de covarianza Σ2 , Σ2 m suelen ser demasiado grandes para ser computacionalmente factibles. Por simplicidad, y como práctica común en IR, no modelamos la correlación entre características. Así aproximamos estas matrices con matrices diagonales de dimensión K. En el resto del documento, utilizamos estos símbolos para representar sus aproximaciones diagonales: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     En segundo lugar, y lo más importante, el espacio de entrada es muy disperso y hay muchas dimensiones que no están relacionadas con un usuario particular en una aplicación de recuperación de información real. Por ejemplo, consideremos un sistema de recomendación de películas, con la variable de entrada x representando una película en particular. Para la j-ésima película que el usuario m ha visto, sea xm,j,k = 1 si el director de la película es Jean-Pierre Jeunet (indexado por k). Aquí asumimos que si este director dirigió una película específica está representado por la k-ésima dimensión. Si el usuario m nunca ha visto una película dirigida por Jean-Pierre Jeunet, entonces la dimensión correspondiente siempre es cero (xm,j,k = 0 para todos los j). Una desventaja importante del algoritmo EM es que la importancia de una característica, µk, puede estar fuertemente dominada por usuarios que nunca han encontrado esta característica (es decir, j xm,j,k = 0) en el paso M (Ecuación 8). Suponga que 100 de cada 1 millón de usuarios han visto la película dirigida por Jean-Pierre Jeunet, y que los espectadores han calificado todas sus películas como excelentes. Intuitivamente, él es un buen director y el peso para él (µk) debería ser alto. Antes de la iteración de EM, el valor inicial de µ suele establecerse en 0. Dado que los otros 999,900 usuarios no han visto esta película, sus pesos correspondientes (w1,k, w2,k, ..., wm,k..., w999900,k) para ese director serían muy pequeños inicialmente. Por lo tanto, el peso correspondiente del director en el µk anterior en el primer paso M sería muy bajo, y la varianza σm,k será grande (Ecuaciones 8 y 7). Es indeseable que los usuarios que nunca han visto ninguna película producida por el director influyan tanto en la importancia del director. Esto hace que la convergencia del algoritmo EM estándar sea muy lenta. Ahora veamos si podemos mejorar la velocidad de aprendizaje del algoritmo. Sin pérdida de generalidad, asumamos que la k-ésima dimensión de la variable de entrada x no está relacionada con un usuario particular m. Lo que queremos decir es que xm,j,k = 0 para todo j = 1, ..., Jm. Es sencillo demostrar que la k-ésima fila y la k-ésima columna de Sxx,m están completamente llenas de ceros, y que la k-ésima dimensión de Sxy,m también se anula. Por lo tanto, la dimensión k correspondiente de la media de los modelos de usuario, ¯wm, debería ser igual a la del anterior: ¯wm,k = µk, con la covarianza correspondiente de σm,k = σk. En el paso M, el algoritmo EM estándar utiliza la solución numérica de la distribución P(wm|Dm, Φ) estimada en el paso E (Ecuación 8 y Ecuación 7). Sin embargo, las soluciones numéricas son muy poco confiables para ¯wm,k y σm,k cuando la k-ésima dimensión no está relacionada con el m-ésimo usuario. Un enfoque mejor es utilizar las soluciones analíticas ¯wm,k = µk, y σm,k = σk para los pares no relacionados (m, k), junto con la solución numérica estimada en el paso E para los otros pares (m, k). Así obtenemos el siguiente nuevo algoritmo EM similar: Paso E modificado: Para cada usuario m, estimar la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual de σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) donde sxx,m,k = j x2 m,j,k y sxy,m,k = j xm,j,kym,j Paso M modificado Optimizar el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E para pares de usuario-característica relacionados. El paso M utiliza implícitamente la solución analítica para pares de usuario-característica no relacionados. µk = 1 Mk m:relacionado ¯wm,k (12) σ2 k = 1 Mk m:relacionado σ2 m,k + ( ¯wm,k − µk)( ¯wm,k − µk)T (13) donde Mk es el número de usuarios relacionados con la característica k. Solo estimamos la diagonal de Σ2 m y Σ, ya que estamos utilizando la aproximación diagonal de las matrices de covarianza. Para estimar ¯wm, solo necesitamos calcular las soluciones numéricas para las dimensiones que están relacionadas con el usuario m. Para estimar σ2 k y µk, solo sumamos sobre los usuarios que están relacionados con la k-ésima característica. Hay dos beneficios principales del nuevo algoritmo. Primero, dado que solo se necesitan los pares relacionados (m, k) en el paso M modificado, la complejidad computacional en una sola iteración de EM es mucho menor cuando los datos son dispersos y muchos de los pares (m, k) no están relacionados. En segundo lugar, los parámetros estimados en el paso M modificado (Ecuaciones 12 - 13) son más precisos que el paso M estándar descrito en la Sección 4.1 porque se utilizaron soluciones analíticas exactas ¯wm,k = µk y σm,k = σk para los pares no relacionados (m, k) en el nuevo algoritmo en lugar de una solución aproximada como en el algoritmo estándar. METODOLOGÍA EXPERIMENTAL 5.1 Conjunto de Datos de Evaluación Para evaluar la técnica propuesta, utilizamos los siguientes tres conjuntos de datos principales (Tabla 1): Datos de MovieLens: Este conjunto de datos fue creado combinando las valoraciones de relevancia del conjunto de datos de MovieLens[9] con documentos de la Base de Datos de Películas en Internet (IMDB). MovieLens permite a los usuarios clasificar cuánto disfrutaron una película específica en una escala del 1 al 5. Esta calificación de simpatía se utilizó como una medida de cuán relevante es el documento que representa la película correspondiente para el usuario. Consideramos los documentos con puntuaciones de 4 o 5 como relevantes, y los documentos con una puntuación de 1 a 3 como irrelevantes para el usuario. MovieLens proporcionó juicios de relevancia sobre 3,057 documentos de 6,040 usuarios diferentes. En promedio, cada usuario calificó 151 películas, de las cuales 87 fueron consideradas relevantes. La puntuación promedio para un documento fue de 3.58. Los documentos que representan cada película fueron construidos a partir de la porción de la base de datos de IMDB que está disponible para descarga pública[13]. Basándonos en esta base de datos, creamos un documento por película que contenía la información relevante sobre ella (por ejemplo, directores, actores, etc.). Tabla 1: Estadísticas del conjunto de datos. En Reuters, el número de calificaciones para un usuario simulado es el número de documentos relevantes para el tema correspondiente. Datos Usuarios Documentos Calificaciones por Usuario MovieLens 6,040 3,057 151 Netflix-todos 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Datos de Netflix: Este conjunto de datos fue construido combinando documentos sobre películas obtenidos de la web con un conjunto de juicios de relevancia de clientes reales de alquiler de películas de Netflix[19]. Netflix proporciona públicamente las evaluaciones de relevancia de 480,189 clientes anónimos. Hay alrededor de 100 millones de calificaciones en una escala del 1 al 5 para 17,770 documentos. Similar a MovieLens, consideramos documentos con puntuaciones de 4 o 5 de agradabilidad como relevantes. Este número se redujo a 1000 clientes mediante muestreo aleatorio. El cliente promedio en el conjunto de datos reducido proporcionó 127 juicios, de los cuales 70 fueron considerados relevantes. La puntuación promedio de los documentos es de 3.55. Datos de Reuters: Este es el Corpus de Reuters, Volumen 1. Cubre 810,000 noticias en inglés de Reuters desde el 20 de agosto de 1996 hasta el 19 de agosto de 1997. Solo se utilizaron las primeras 100,000 noticias en nuestros experimentos. El corpus de Reuters viene con una jerarquía de temas. Cada documento se asigna a una de varias ubicaciones en el árbol jerárquico. El primer nivel del árbol contiene cuatro temas, denotados como C, E, M y G. Para los experimentos en este artículo, el árbol fue cortado en el nivel 1 para crear cuatro árboles más pequeños, cada uno de los cuales corresponde a un conjunto de datos más pequeño: Reuters-E, Reuters-C, Reuters-M y Reuters-G. Para cada conjunto de datos pequeño, creamos varios perfiles, un perfil para cada nodo en un subárbol, para simular múltiples usuarios, cada uno con una definición de relevancia relacionada pero separada. Todos los perfiles de usuario en una sub-rama se supone que comparten la misma distribución de modelo previo. Dado que este corpus indica explícitamente solo los documentos relevantes para un tema (usuario), todos los demás documentos se consideran irrelevantes. 5.2 Evaluación Diseñamos los experimentos para responder a las siguientes tres preguntas: 1. ¿Necesitamos hacer el esfuerzo de utilizar un enfoque bayesiano y aprender una distribución a priori de otros usuarios? 2. ¿El nuevo algoritmo funciona mejor que el algoritmo EM estándar para aprender el modelo lineal jerárquico bayesiano? 3. ¿Puede el nuevo algoritmo aprender rápidamente muchos modelos de usuario? Para responder a la primera pregunta, comparamos los modelos jerárquicos bayesianos con los modelos de regresión lineal regularizados Norm-2 comúnmente utilizados. De hecho, el enfoque comúnmente utilizado es equivalente al modelo aprendido al final de la primera iteración de EM. Para responder a la segunda pregunta, comparamos el nuevo algoritmo propuesto con el algoritmo EM estándar para ver si el nuevo algoritmo de aprendizaje es mejor. Para responder a la tercera pregunta, probamos la eficiencia del nuevo algoritmo en todo el conjunto de datos de Netflix, donde aproximadamente medio millón de modelos de usuario deben ser aprendidos juntos. Para los conjuntos de datos de MovieLens y Netflix, la efectividad del algoritmo se midió mediante el error cuadrático medio, mientras que en el conjunto de datos de Reuters se utilizó el error de clasificación porque era más informativo. Primero evaluamos el rendimiento en cada usuario individual, y luego estimamos el promedio macro sobre todos los usuarios. Se realizaron pruebas estadísticas (pruebas t) para determinar si los resultados son significativos. Para los experimentos en los conjuntos de datos de MovieLens y Netflix, utilizamos una muestra aleatoria del 90% de cada usuario para entrenamiento, y el resto para pruebas. En el conjunto de datos de Reuters, debido a que hay demasiados documentos relevantes para cada tema en el corpus, utilizamos una muestra aleatoria del 10% de cada tema para el entrenamiento, y el 10% de los documentos restantes para las pruebas. Para todas las ejecuciones, establecimos (a, b, c, Σ) = (0.1, 10, 0.1, 1) manualmente. 6. RESULTADOS EXPERIMENTALES Las Figuras 2, 3 y 4 muestran que en todos los conjuntos de datos, el enfoque de <br>modelado</br> jerárquico bayesiano tiene una mejora estadísticamente significativa sobre el modelo de regresión lineal regularizado, que es equivalente a los modelos jerárquicos bayesianos aprendidos en la primera iteración. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "content-based": {
            "translated_key": "basado en contenido",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A <br>content-based</br> personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
                "A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model.",
                "Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive.",
                "The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications.",
                "This paper proposes a new fast learning technique to learn a large number of individual user profiles.",
                "The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens.",
                "Categories and Subject Descriptors: B.3.3 [Information Search and Retrieval]: Information filtering General Terms: Algorithms 1.",
                "INTRODUCTION Personalization is the future of the Web, and it has achieved great success in industrial applications.",
                "For example, online stores, such as Amazon and Netflix, provide customized recommendations for additional products or services based on a users history.",
                "Recent offerings such as My MSN, My Yahoo!, My Google, and Google News have attracted much attention due to their potential ability to infer a users interests from his/her history.",
                "One major personalization topic studied in the information retrieval community is <br>content-based</br> personal recommendation systems1 .",
                "These systems learn user-specific profiles from user feedback so that they can recommend information tailored to each individual users interest without requiring the user to make an explicit query.",
                "Learning the user profiles is the core problem for these systems.",
                "A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user.",
                "One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small.",
                "This is known as the cold start problem.",
                "This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile.",
                "There has been much research on improving classification accuracy when the amount of labeled training data is small.",
                "The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal [26].",
                "Another approach is using domain knowledge.",
                "Researchers have modified different learning algorithms, such as Na¨ıveBayes [17], logistic regression [7], and SVMs [22], to integrate domain knowledge into a text classifier.",
                "The third approach is borrowing training data from other resources [5][7].",
                "The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data.",
                "One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach.",
                "Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial performance for each user[27][25].",
                "In order to learn a Bayesian hierarchical model, the system usually tries to find the most likely model parameters for the given data.",
                "A mature recommendation system usually works for millions of users.",
                "It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users.",
                "The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee.",
                "However, a content based recommendation system often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector.",
                "With careful analysis of the EM algorithm in this scenario (Section 4), we find that the EM tering, or item-based collaborative filtering.",
                "In this paper, the words filtering and recommendation are used interchangeably. algorithm converges very slowly due to the sparseness of the input variables.",
                "We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O(MK), where M is the number of users and K is the number of dimensions.",
                "This paper modifies the standard EM algorithm to create an improved learning algorithm, which we call the Modified EM algorithm.",
                "The basic idea is that instead of calculating the numerical solution for all the user profile parameters, we derive the analytical solution of the parameters for some feature dimensions, and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters.",
                "This greatly reduces the computation at a single EM iteration, and also has the benefit of increasing the convergence speed of the learning algorithm.",
                "The proposed technique is not only well supported by theory, but also by experimental results.",
                "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression modeling framework used for <br>content-based</br> recommendations.",
                "Section 4 describes how to learn the model parameters using the standard EM algorithm, along with using the new technique proposed in this paper.",
                "The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6.",
                "Section 7 summarizes and offers concluding remarks. 2.",
                "RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the IR community since the 1970s.",
                "The approaches that have been used to solve this problem can be roughly classified into two major categories: content based filtering versus collaborative filtering.",
                "<br>content-based</br> filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user.",
                "The user may read the delivered documents and provide explicit relevance feedback, which the filtering system then uses to update the users profile using relevance feedback retrieval models (e.g.",
                "Boolean models, vector space models, traditional probabilistic models [20] , inference networks [3] and language models [6]) or machine learning algorithms (e.g.",
                "Support Vector Machines (SVM), K nearest neighbors (K-NN) clustering, neural networks, logistic regression, or Winnow [16] [4] [23]).",
                "Collaborative filtering goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past.",
                "Memorybased heuristics and model based approaches have been used in collaborative filtering task [15] [8] [2] [14] [12] [11].",
                "This paper contributes to the <br>content-based</br> recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks[27][25].",
                "This paper does not intend to compare <br>content-based</br> filtering with collaborative filtering or claim which one is a better.",
                "We think each complements the other, and that <br>content-based</br> filtering is extremely useful for handling new documents/items with little or no user feedback.",
                "Similar to some other researchers[18][1][21], we found that a recommendation system will be more effective when both techniques are combined.",
                "However, this is beyond the scope of this paper and thus not discussed here. 3.",
                "BAYESIAN HIERARCHICAL LINEAR REGRESSION Assume there are M users in the system.",
                "The task of the system is to recommend documents that are relevant to each user.",
                "For each user, the system learns a user model from the users history.",
                "In the rest of this paper, we will use the following notations to represent the variables in the system. m = 1, 2, ..., M: The index for each individual user.",
                "M is the total number of users. wm: The user model parameter associated with user m. wm is a K dimensional vector. j = 1, 2, ..., Jm: The index for a set of data for user m. Jm is the number of training data for user m. Dm = {(xm,j, ym,j)}: A set of data associated with user m. xm,j is a K dimensional vector that represents the mth users jth training document.2 ym,j is a scalar that represents the label of document xm,j. k = 1, 2, ..., K: The dimensional index of input variable x.",
                "The Bayesian hierarchical modeling approach has been widely used in real-world information retrieval applications.",
                "Generalized Bayesian hierarchical linear models, one of the simplest Bayesian hierarchical models, are commonly used and have achieved good performance on collaborative filtering [25] and <br>content-based</br> adaptive filtering [27] tasks.",
                "Figure 1 shows the graphical representation of a Bayesian hierarchical model.",
                "In this graph, each user model is represented by a random vector wm.",
                "We assume a user model is sampled randomly from a prior distribution P(w|Φ).",
                "The system can predict the user label y of a document x given an estimation of wm (or wms distribution) using a function y = f(x, w).",
                "The model is called generalized Bayesian hierarchical linear model when y = f(wT x) is any generalized linear model such as logistic regression, SVM, and linear regression.",
                "To reliably estimate the user model wm, the system can borrow information from other users through the prior Φ = (µ, Σ).",
                "Now we look at one commonly used model where y = wT x + , where ∼ N(0, σ2 ) is a random noise [25][27].",
                "Assume that each user model wm is an independent draw from a population distribution P(w|Φ), which is governed by some unknown hyperparameter Φ.",
                "Let the prior distribution of user model w be a Gaussian distribution with parameter Φ = (µ, Σ), which is the commonly used prior for linear models. µ = (µ1, µ2, ..., µK ) is a K dimensional vector that represents the mean of the Gaussian distribution, and Σ is the covariance matrix of the Gaussian.",
                "Usually, a Normal distribution N(0, aI) and an Inverse Wishart distribution P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) are used as hyperprior to model the prior distribution of µ and Σ respectively.",
                "I is the K dimensional identity matrix, and a, b, and c are real numbers.",
                "With these settings, we have the following model for the system: 1. µ and Σ are sampled from N(0, aI) and IWν (aI), respectively. 2 The first dimension of x is a dummy variable that always equals to 1.",
                "Figure 1: Illustration of dependencies of variables in the hierarchical model.",
                "The rating, y, for a document, x, is conditioned on the document and the user model, wm, associated with the user m. Users share information about their models through the prior, Φ = (µ, Σ). 2.",
                "For each user m, wm is sampled randomly from a Normal distribution: wm ∼ N(µ, Σ2 ) 3.",
                "For each item xm,j, ym,j is sampled randomly from a Normal distribution: ym,j ∼ N(wT mxm,j, σ2 ).",
                "Let θ = (Φ, w1, w2, ..., wM ) represent the parameters of this system that needs to be estimated.",
                "The joint likelihood for all the variables in the probabilistic model, which includes the data and the parameters, is: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) For simplicity, we assume a, b, c, and σ are provided to the system. 4.",
                "MODEL PARAMETER LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple linear regression.",
                "Therefore, we will focus on estimating Φ.",
                "The maximum a priori solution of Φ is given by ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Finding the optimal solution for the above problem is challenging, since we need to integrate over all w = (w1, w2, ..., wM ), which are unobserved hidden variables. 4.1 EM Algorithm for Bayesian Hierarchical Linear Models In Equation 5, Φ is the parameter needs to be estimated, and the result depends on unobserved latent variables w. This kind of optimization problem is usually solved by the EM algorithm.",
                "Applying EM to the above problem, the set of user models w are the unobservable hidden variables and we have: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw Based on the derivation of the EM formulas presented in [24], we have the following Expectation-Maximization steps for finding the optimal hyperparameters.",
                "For space considerations, we omit the derivation in this paper since it is not the focus of our work.",
                "E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of the prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) where Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j M step: Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Many machine learning driven IR systems use a point estimate of the parameters at different stages in the system.",
                "However, we are estimating the posterior distribution of the variables at the E step.",
                "This avoids overfitting wm to a particular users data, which may be small and noisy.",
                "A detailed discussion about this subject appears in [10]. 4.2 New Algorithm: Modified EM Although the EM algorithm is widely studied and used in machine learning applications, using the above EM process to solve Bayesian hierarchical linear models in large-scale information retrieval systems is still too computationally expensive.",
                "In this section, we describe why the learning rate of the EM algorithm is slow in our application and introduce a new technique to make the learning of the Bayesian hierarchical linear model scalable.",
                "The derivation of the new learning algorithm will be based on the EM algorithm described in the previous section.",
                "First, the covariance matrices Σ2 , Σ2 m are usually too large to be computationally feasible.",
                "For simplicity, and as a common practice in IR, we do not model the correlation between features.",
                "Thus we approximate these matrices with K dimensional diagonal matrices.",
                "In the rest of the paper, we use these symbols to represent their diagonal approximations: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     Secondly, and most importantly, the input space is very sparse and there are many dimensions that are not related to a particular user in a real IR application.",
                "For example, let us consider a movie recommendation system, with the input variable x representing a particular movie.",
                "For the jth movie that the user m has seen, let xm,j,k = 1 if the director of the movie is Jean-Pierre Jeunet (indexed by k).",
                "Here we assume that whether or not that this director directed a specific movie is represented by the kth dimension.",
                "If the user m has never seen a movie directed by Jean-Pierre Jeunet, then the corresponding dimension is always zero (xm,j,k = 0 for all j) .",
                "One major drawback of the EM algorithm is that the importance of a feature, µk, may be greatly dominated by users who have never encountered this feature (i.e. j xm,j,k = 0) at the M step (Equation 8).",
                "Assume that 100 out of 1 million users have viewed the movie directed by Jean-Pierre Jeunet, and that the viewers have rated all of his movies as excellent.",
                "Intuitively, he is a good director and the weight for him (µk) should be high.",
                "Before the EM iteration, the initial value of µ is usually set to 0.",
                "Since the other 999,900 users have not seen this movie, their corresponding weights (w1,k, w2,k, ..., wm,k..., w999900,k) for that director would be very small initially.",
                "Thus the corresponding weight of the director in the prior µk at the first M step would be very low , and the variance σm,k will be large (Equations 8 and 7).",
                "It is undesirable that users who have never seen any movie produced by the director influence the importance of the director so much.",
                "This makes the convergence of the standard EM algorithm very slow.",
                "Now lets look at whether we can improve the learning speed of the algorithm.",
                "Without a loss of generality, let us assume that the kth dimension of the input variable x is not related to a particular user m. By which we mean, xm,j,k = 0 for all j = 1, ..., Jm.",
                "It is straightforward to prove that the kth row and kth column of Sxx,m are completely filled with zeros, and that the kth dimension of Sxy,m is zeroed as well.",
                "Thus the corresponding kth dimension of the user models mean, ¯wm, should be equal to that of the prior: ¯wm,k = µk, with the corresponding covariance of σm,k = σk.",
                "At the M step, the standard EM algorithm uses the numerical solution of the distribution P(wm|Dm, Φ) estimated at E step (Equation 8 and Equation 7).",
                "However, the numerical solutions are very unreliable for ¯wm,k and σm,k when the kth dimension is not related to the mth user.",
                "A better approach is using the analytical solutions ¯wm,k = µk, and σm,k = σk for the unrelated (m, k) pairs, along with the numerical solution estimated at E step for the other (m, k) pairs.",
                "Thus we get the following new EM-like algorithm: Modified E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) where sxx,m,k = j x2 m,j,k and sxy,m,k = j xm,j,kym,j Modified M Step Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step for related userfeature pairs.",
                "The M step implicitly uses the analytical solution for unrelated user-feature pairs. µk = 1 Mk m:related ¯wm,k (12) σ2 k = 1 Mk m:related σ2 m,k +( ¯wm,k − µk)( ¯wm,k − µk)T (13) where Mk is the number of users that are related to feature k We only estimate the diagonal of Σ2 m and Σ since we are using the diagonal approximation of the covariance matrices.",
                "To estimate ¯wm, we only need to calculate the numerical solutions for dimensions that are related to user m. To estimate σ2 k and µk, we only sum over users that are related to the kth feature.",
                "There are two major benefits of the new algorithm.",
                "First, because only the related (m, k) pairs are needed at the modified M step, the computational complexity in a single EM iteration is much smaller when the data is sparse, and many of (m, k) pairs are unrelated.",
                "Second, the parameters estimated at the modified M step (Equations 12 - 13) are more accurate than the standard M step described in Section 4.1 because the exact analytical solutions ¯wm,k = µk and σm,k = σk for the unrelated (m, k) pairs were used in the new algorithm instead of an approximate solution as in the standard algorithm. 5.",
                "EXPERIMENTAL METHODOLOGY 5.1 Evaluation Data Set To evaluate the proposed technique, we used the following three major data sets (Table 1): MovieLens Data: This data set was created by combining the relevance judgments from the MovieLens[9] data set with documents from the Internet Movie Database (IMDB).",
                "MovieLens allows users to rank how much he/she enjoyed a specific movie on a scale from 1 to 5.",
                "This likeability rating was used as a measurement of how relevant the document representing the corresponding movie is to the user.",
                "We considered documents with likeability scores of 4 or 5 as relevant, and documents with a score of 1 to 3 as irrelevant to the user.",
                "MovieLens provided relevance judgments on 3,057 documents from 6,040 separate users.",
                "On average, each user rated 151 movies, of these 87 were judged to be relevant.",
                "The average score for a document was 3.58.",
                "Documents representing each movie were constructed from the portion of the IMDB database that is available for public download[13].",
                "Based on this database, we created one document per movie that contained the relevant information about it (e.g. directors, actors, etc.).",
                "Table 1: Data Set Statistics.",
                "On Reuters, the number of rating for a simulated user is the number of documents relevant to the corresponding topic.",
                "Data Users Docs Ratings per User MovieLens 6,040 3,057 151 Netflix-all 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Netflix Data: This data set was constructed by combining documents about movies crawled from the web with a set of actual movie rental customer relevance judgments from Netflix[19].",
                "Netflix publicly provides the relevance judgments of 480,189 anonymous customers.",
                "There are around 100 million rating on a scale of 1 to 5 for 17,770 documents.",
                "Similar to MovieLens, we considered documents with likeability scores of 4 or 5 as relevant.",
                "This number was reduced to 1000 customers through random sampling.",
                "The average customer on the reduced data set provided 127 judgments, with 70 being deemed relevant.",
                "The average score for documents is 3.55.",
                "Reuters Data: This is the Reuters Corpus, Volume 1.",
                "It covers 810,000 Reuters English language news stories from August 20, 1996 to August 19, 1997.",
                "Only the first 100,000 news were used in our experiments.",
                "The Reuters corpus comes with a topic hierarchy.",
                "Each document is assigned to one of several locations on the hierarchical tree.",
                "The first level of the tree contains four topics, denoted as C, E, M, and G. For the experiments in this paper, the tree was cut at level 1 to create four smaller trees, each of which corresponds to one smaller data set: Reuters-E Reuters-C, ReutersM and Reuters-G. For each small data set, we created several profiles, one profile for each node in a sub-tree, to simulate multiple users, each with a related, yet separate definition of relevance.",
                "All the user profiles on a sub-tree are supposed to share the same prior model distribution.",
                "Since this corpus explicitly indicates only the relevant documents for a topic(user), all other documents are considered irrelevant. 5.2 Evaluation We designed the experiments to answer the following three questions: 1.",
                "Do we need to take the effort to use a Bayesian approach and learn a prior from other users? 2.",
                "Does the new algorithm work better than the standard EM algorithm for learning the Bayesian hierarchical linear model? 3.",
                "Can the new algorithm quickly learn many user models?",
                "To answer the first question, we compared the Bayesian hierarchical models with commonly used Norm-2 regularized linear regression models.",
                "In fact, the commonly used approach is equivalent to the model learned at the end of the first EM iteration.",
                "To answer the second question, we compared the proposed new algorithm with the standard EM algorithm to see whether the new learning algorithm is better.",
                "To answer the third question, we tested the efficiency of the new algorithm on the entire Netflix data set where about half a million user models need to be learned together.",
                "For the MovieLens and Netflix data sets, algorithm effectiveness was measured by mean square error, while on the Reuters data set classification error was used because it was more informative.",
                "We first evaluated the performance on each individual user, and then estimated the macro average over all users.",
                "Statistical tests (t-tests) were carried out to see whether the results are significant.",
                "For the experiments on the MovieLens and Netflix data sets, we used a random sample of 90% of each user for training, and the rest for testing.",
                "On Reuters data set, because there are too many relevant documents for each topic in the corpus, we used a random sample of 10% of each topic for training, and 10% of the remaining documents for testing.",
                "For all runs, we set (a, b, c, Σ ) = (0.1, 10, 0.1, 1) manually. 6.",
                "EXPERIMENTAL RESULTS Figure 2, Figure 3, and Figure 4 show that on all data sets, the Bayesian hierarchical modeling approach has a statistical significant improvement over the regularized linear regression model, which is equivalent to the Bayesian hierarchical models learned at the first iteration.",
                "Further analysis shows a negative correlation between the number of training data for a user and the improvement the system gets.",
                "This suggests that the borrowing information from other users has more significant improvements for users with less training data, which is as expected.",
                "However, the strength of the correlation differs over data sets, and the amount of training data is not the only characteristics that will influence the final performance.",
                "Figure 2 and Figure 3 show that the proposed new algorithm works better than the standard EM algorithm on the Netflix and MovieLens data sets.",
                "This is not surprising since the number of related feature-users pairs is much smaller than the number of unrelated feature-user pairs on these two data sets, and thus the proposed new algorithm is expected to work better.",
                "Figure 4 shows that the two algorithms work similarly on the Reuters-E data set.",
                "The accuracy of the new algorithm is similar to that of the standard EM algorithm at each iteration.",
                "The general patterns are very similar on other Reuters subsets.",
                "Further analysis shows that only 58% of the user-feature pairs are unrelated on this data set.",
                "Since the number of unrelated user-feature pairs is not extremely large, the sparseness is not a serious problem on the Reuters data set.",
                "Thus the two learning algorithms perform similarly.",
                "The results suggest that only on a corpus where the number of unrelated user-feature pairs is much larger than the number of related pairs, such as on the Netflix data set, the proposed technique will get a significant improvement over standard EM.",
                "However, the experiments also show that when the assumption does not hold, the new algorithm does not hurt performance.",
                "Although the proposed technique is faster than standard Figure 2: Performance on a Netflix subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iterations 2 - 10.",
                "Norm-2 regularized linear models are equivalent to the Bayesian hierarchical models learned at the first iteration, and are statistical significantly worse than the Bayesian hierarchical models. 0 2 4 6 8 10 1 1.05 1.1 1.15 1.2 1.25 1.3 1.35 1.4 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iterations ClassificationError New Algorithm Traditional EM Figure 3: Performance on a MovieLens subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iteration 2 to 17 (evaluated with mean square error). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iterations MeanSquareError New Algorithm Traditional EM 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iterations ClassificationError New Algorithm Traditional EM Figure 4: Performance on a Reuters-E subset with 26 profiles.",
                "Performances on Reuters-C, Reuters-M, Reuters-G are similar. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iterations ClassificationError New Algorithm Traditional EM EM, can it really learn millions of user models quickly?",
                "Our results show that the modified EM algorithm converges quickly, and 2 - 3 modified EM iterations would result in a reliable estimation.",
                "We evaluated the algorithm on the whole Netflix data set (480,189 users, 159,836 features, and 100 million ratings) running on a single CPU PC (2GB memory, P4 3GHz).",
                "The system finished one modified EM iteration in about 4 hours.",
                "This demonstrates that the proposed technique can efficiently handle large-scale system like Netflix. 7.",
                "CONCLUSION <br>content-based</br> user profile learning is an important problem and is the key to providing personal recommendations to a user, especially for recommending new items with a small number of ratings.",
                "The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors.",
                "This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM.",
                "We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm.",
                "Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse, by which we mean the ratio of related user-feature pairs to unrelated pairs is small.",
                "Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold.",
                "In general, it is better to use the new algorithm since it is as simple as standard EM, the performance is either better or similar to EM, and the computation complexity is lower at each iteration.",
                "It is worth mentioning that even if the original problem space is not sparse, sparseness can be created artificially when a recommendation system uses user-specific feature selection techniques to reduce the noise and user model complexity.",
                "The proposed technique can also be adapted to improve the learning in such a scenario.",
                "We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU.",
                "The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear modeling approach to build a practical large scale system, even though the literature have demonstrated the effectiveness of the models in many applications.",
                "Our work is one major step on the road to make Bayesian hierarchical linear models more practical.",
                "The proposed new technique can be easily adapted to run on a cluster of machines, and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users.",
                "The research has much potential to benefit people using EM algorithm on many other IR problems as well as machine learning problems.",
                "EM algorithm is a commonly used machine learning technique.",
                "It is used to find model parameters in many IR problems where the training data is very sparse.",
                "Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering, the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems. 8.",
                "ACKNOWLEDGMENTS We thank Wei Xu, David Lewis and anonymous reviewers for valuable feedback on the work described in this paper.",
                "Part of the work was supported by Yahoo, Google, the Petascale Data Storage Institute and the Institute for Scalable Scientific Data Management.",
                "Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors, and do not necessarily reflect those of the sponsors. 9.",
                "REFERENCES [1] C. Basu, H. Hirsh, and W. Cohen.",
                "Recommendation as classification: Using social and <br>content-based</br> information in recommendation.",
                "In Proceedings of the Fifteenth National Conference on Artificial Intelligence, 1998. [2] J. S. Breese, D. Heckerman, and C. Kadie.",
                "Empirical analysis of predictive algorithms for collaborative filtering.",
                "Technical report, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan.",
                "Document filtering with inference networks.",
                "In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor, and A. Vinokourov.",
                "Kernel method for document filtering.",
                "In The Eleventh Text REtrieval Conference (TREC11).",
                "National Institute of Standards and Technology, special publication 500-249, 2003. [5] C. Chelba and A. Acero.",
                "Adaptation of maximum entropy capitalizer: Little data can help a lot.",
                "In D. Lin and D. Wu, editors, Proceedings of EMNLP 2004, pages 285-292, Barcelona, Spain, July 2004.",
                "Association for Computational Linguistics. [6] B. Croft and J. Lafferty, editors.",
                "Language Modeling for Information Retrieval.",
                "Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov, and A. Genkin.",
                "Constructing informative prior distributions from domain knowledge in text classification.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 493-500, New York, NY, USA, 2006.",
                "ACM Press. [8] J. Delgado and N. Ishii.",
                "Memory-based weightedmajority prediction for recommender systems.",
                "In ACM SIGIR99 Workshop on Recommender Systems, 1999. [9] GroupLens.",
                "Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman.",
                "A tutorial on learning with bayesian networks.",
                "In M. Jordan, editor, Learning in Graphical Models.",
                "Kluwer Academic, 1998. [11] J. L. Herlocker, J.",
                "A. Konstan, A. Borchers, and J. Riedl.",
                "An algorithmic framework for performing collaborative filtering.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 230-237, New York, NY, USA, 1999.",
                "ACM Press. [12] T. Hofmann and J. Puzicha.",
                "Latent class models for collaborative filtering.",
                "In IJCAI 99: Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 688-693, San Francisco, CA, USA, 1999.",
                "Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).",
                "Internet movie database. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai, and L. Si.",
                "An automatic weighting scheme for collaborative filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 337-344, New York, NY, USA, 2004.",
                "ACM Press. [15] J.",
                "A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl.",
                "GroupLens: Applying collaborative filtering to Usenet news.",
                "Communications of the ACM, 40(3):77-87, 1997. [16] D. Lewis.",
                "Applying support vector machines to the TREC-2001 batch filtering and routing tasks.",
                "In Proceedings of the Eleventh Text REtrieval Conference (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee, , and P. Yu.",
                "Text classification by labeling words.",
                "In Proceedings of The Nineteenth National Conference on Artificial Intelligence (AAAI-2004), July 25-29, 2004. [18] P. Melville, R. J. Mooney, and R. Nagarajan.",
                "Content-boosted collaborative filtering for improved recommendations.",
                "In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002), Edmonton, Canada, 2002. [19] Netflix.",
                "Netflix prize. http://www.netflixprize.com (visited on Nov. 30, 2006), 2006. [20] S. Robertson and K. Sparck-Jones.",
                "Relevance weighting of search terms.",
                "In Journal of the American Society for Information Science, volume 27, pages 129-146, 1976. [21] J. Wang, A. P. de Vries, and M. J. T. Reinders.",
                "Unifying user-based and item-based collaborative filtering approaches by similarity fusion.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 501-508, New York, NY, USA, 2006.",
                "ACM Press. [22] X. Wu and R. K. Srihari.",
                "Incorporating prior knowledge with weighted margin support vector machines.",
                "In Proc.",
                "ACM Knowledge Discovery Data Mining Conf. (ACM SIGKDD 2004), Aug. 2004. [23] Y. Yang, S. Yoo, J. Zhang, and B. Kisiel.",
                "Robustness of adaptive filtering methods in a cross-benchmark evaluation.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2005. [24] K. Yu, V. Tresp, and A. Schwaighofer.",
                "Learning gaussian processes from multiple tasks.",
                "In ICML 05: Proceedings of the 22nd international conference on Machine learning, pages 1012-1019, New York, NY, USA, 2005.",
                "ACM Press. [25] K. Yu, V. Tresp, and S. Yu.",
                "A nonparametric hierarchical bayesian framework for information filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 353-360.",
                "ACM Press, 2004. [26] X. Zhu.",
                "Semi-supervised learning literature survey.",
                "Technical report, University of Wisconsin - Madison, December 9, 2006. [27] P. Zigoris and Y. Zhang.",
                "Bayesian adaptive user profiling with explicit & implicit feedback.",
                "In Conference on Information and Knowledge Mangement 2006, 2006."
            ],
            "original_annotated_samples": [
                "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A <br>content-based</br> personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
                "One major personalization topic studied in the information retrieval community is <br>content-based</br> personal recommendation systems1 .",
                "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression modeling framework used for <br>content-based</br> recommendations.",
                "<br>content-based</br> filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user.",
                "This paper contributes to the <br>content-based</br> recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks[27][25]."
            ],
            "translated_annotated_samples": [
                "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado <br>basado en contenido</br> aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual.",
                "Un tema importante de personalización estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados <br>basados en el contenido</br>.",
                "La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de regresión lineal jerárquica bayesiana utilizado para <br>recomendaciones basadas en contenido</br>.",
                "El <br>filtrado basado en contenido</br> estudia el escenario en el que un sistema de recomendación monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente.",
                "Este artículo contribuye a la investigación de recomendaciones basadas en contenido al mejorar la eficiencia y efectividad de los modelos lineales jerárquicos bayesianos, los cuales tienen una sólida base teórica y un buen rendimiento empírico en tareas de recomendación[27][25]."
            ],
            "translated_text": "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado <br>basado en contenido</br> aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual. Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un modelo jerárquico bayesiano. Aprender los parámetros del modelo para optimizar la verosimilitud conjunta de los datos de millones de usuarios es muy costoso computacionalmente. El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de datos en aplicaciones de IR. Este documento propone una nueva técnica de aprendizaje rápido para aprender un gran número de perfiles de usuario individuales. La eficacia y eficiencia del algoritmo propuesto están justificadas por la teoría y demostradas en datos reales de usuarios de Netflix y MovieLens. Categorías y Descriptores de Asignaturas: B.3.3 [Búsqueda y Recuperación de Información]: Filtrado de información Términos Generales: Algoritmos 1. La personalización es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales. Por ejemplo, las tiendas en línea, como Amazon y Netflix, ofrecen recomendaciones personalizadas de productos o servicios adicionales basadas en el historial de un usuario. Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de un usuario a partir de su historial. Un tema importante de personalización estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados <br>basados en el contenido</br>. Estos sistemas aprenden perfiles específicos de usuario a partir de la retroalimentación del usuario para poder recomendar información adaptada a los intereses de cada usuario sin necesidad de que el usuario realice una consulta explícita. Aprender los perfiles de usuario es el problema central de estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica qué tan relevante es un documento para el usuario. Uno de los principales desafíos de construir un sistema de recomendación o personalización es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña. Esto se conoce como el problema de inicio en frío. Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente retroalimentación de ese usuario para aprender un perfil de usuario confiable. Se ha realizado mucha investigación sobre cómo mejorar la precisión de clasificación cuando la cantidad de datos de entrenamiento etiquetados es pequeña. El enfoque de aprendizaje semisupervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26]. Otro enfoque es utilizar el conocimiento del dominio. Los investigadores han modificado diferentes algoritmos de aprendizaje, como NaïveBayes [17], regresión logística [7] y SVMs [22], para integrar el conocimiento del dominio en un clasificador de texto. El tercer enfoque consiste en tomar datos de entrenamiento de otros recursos [5][7]. La efectividad de estos enfoques diferentes es mixta, debido a qué tan bien se ajusta la suposición del modelo subyacente a los datos. Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano. Varios investigadores han demostrado que este enfoque intercambia eficazmente entre la información compartida y la específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario[27][25]. Para aprender un modelo jerárquico bayesiano, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados. Un sistema de recomendación maduro generalmente funciona para millones de usuarios. Es bien sabido que aprender los parámetros óptimos de un modelo jerárquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios. El algoritmo EM es una técnica comúnmente utilizada para el aprendizaje de parámetros debido a su simplicidad y garantía de convergencia. Sin embargo, un sistema de recomendación basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso. Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM tering, o filtrado colaborativo basado en elementos. En este documento, las palabras filtrado y recomendación se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de las variables de entrada. También encontramos que actualizar el parámetro del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones. Este documento modifica el algoritmo EM estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos algoritmo EM modificado. La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M utilizamos la solución analítica en lugar de la solución numérica estimada en el paso E para esos parámetros. Esto reduce considerablemente la computación en una sola iteración de EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales. La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de regresión lineal jerárquica bayesiana utilizado para <br>recomendaciones basadas en contenido</br>. La sección 4 describe cómo aprender los parámetros del modelo utilizando el algoritmo EM estándar, junto con el uso de la nueva técnica propuesta en este artículo. La configuración experimental y los resultados utilizados para validar la técnica de aprendizaje propuesta se informan en las Secciones 5 y 6. La sección 7 resume y ofrece observaciones finales. 2. TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de IR desde la década de 1970. Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus filtrado colaborativo. El <br>filtrado basado en contenido</br> estudia el escenario en el que un sistema de recomendación monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente. El usuario puede leer los documentos entregados y proporcionar retroalimentación explícita de relevancia, la cual el sistema de filtrado utiliza para actualizar el perfil del usuario mediante modelos de recuperación de retroalimentación de relevancia (por ejemplo,). Modelos booleanos, modelos de espacio vectorial, modelos probabilísticos tradicionales [20], redes de inferencia [3] y modelos de lenguaje [6]) o algoritmos de aprendizaje automático (por ejemplo, Máquinas de Vectores de Soporte (SVM), agrupamiento de K vecinos más cercanos (K-NN), redes neuronales, regresión logística o Winnow [16] [4] [23]. El filtrado colaborativo va más allá de simplemente usar el contenido de un documento para recomendar elementos a un usuario, aprovechando la información de otros usuarios con gustos y preferencias similares en el pasado. Se han utilizado heurísticas basadas en memoria y enfoques basados en modelos en la tarea de filtrado colaborativo [15] [8] [2] [14] [12] [11]. Este artículo contribuye a la investigación de recomendaciones basadas en contenido al mejorar la eficiencia y efectividad de los modelos lineales jerárquicos bayesianos, los cuales tienen una sólida base teórica y un buen rendimiento empírico en tareas de recomendación[27][25]. ",
            "candidates": [],
            "error": [
                [
                    "basado en contenido",
                    "basados en el contenido",
                    "recomendaciones basadas en contenido",
                    "filtrado basado en contenido"
                ]
            ]
        },
        "recommendation system": {
            "translated_key": "sistema de recomendación",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A content-based personalized <br>recommendation system</br> learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
                "A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model.",
                "Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive.",
                "The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications.",
                "This paper proposes a new fast learning technique to learn a large number of individual user profiles.",
                "The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens.",
                "Categories and Subject Descriptors: B.3.3 [Information Search and Retrieval]: Information filtering General Terms: Algorithms 1.",
                "INTRODUCTION Personalization is the future of the Web, and it has achieved great success in industrial applications.",
                "For example, online stores, such as Amazon and Netflix, provide customized recommendations for additional products or services based on a users history.",
                "Recent offerings such as My MSN, My Yahoo!, My Google, and Google News have attracted much attention due to their potential ability to infer a users interests from his/her history.",
                "One major personalization topic studied in the information retrieval community is content-based personal recommendation systems1 .",
                "These systems learn user-specific profiles from user feedback so that they can recommend information tailored to each individual users interest without requiring the user to make an explicit query.",
                "Learning the user profiles is the core problem for these systems.",
                "A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user.",
                "One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small.",
                "This is known as the cold start problem.",
                "This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile.",
                "There has been much research on improving classification accuracy when the amount of labeled training data is small.",
                "The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal [26].",
                "Another approach is using domain knowledge.",
                "Researchers have modified different learning algorithms, such as Na¨ıveBayes [17], logistic regression [7], and SVMs [22], to integrate domain knowledge into a text classifier.",
                "The third approach is borrowing training data from other resources [5][7].",
                "The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data.",
                "One well-received approach to improve <br>recommendation system</br> performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach.",
                "Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial performance for each user[27][25].",
                "In order to learn a Bayesian hierarchical model, the system usually tries to find the most likely model parameters for the given data.",
                "A mature <br>recommendation system</br> usually works for millions of users.",
                "It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users.",
                "The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee.",
                "However, a content based <br>recommendation system</br> often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector.",
                "With careful analysis of the EM algorithm in this scenario (Section 4), we find that the EM tering, or item-based collaborative filtering.",
                "In this paper, the words filtering and recommendation are used interchangeably. algorithm converges very slowly due to the sparseness of the input variables.",
                "We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O(MK), where M is the number of users and K is the number of dimensions.",
                "This paper modifies the standard EM algorithm to create an improved learning algorithm, which we call the Modified EM algorithm.",
                "The basic idea is that instead of calculating the numerical solution for all the user profile parameters, we derive the analytical solution of the parameters for some feature dimensions, and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters.",
                "This greatly reduces the computation at a single EM iteration, and also has the benefit of increasing the convergence speed of the learning algorithm.",
                "The proposed technique is not only well supported by theory, but also by experimental results.",
                "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression modeling framework used for content-based recommendations.",
                "Section 4 describes how to learn the model parameters using the standard EM algorithm, along with using the new technique proposed in this paper.",
                "The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6.",
                "Section 7 summarizes and offers concluding remarks. 2.",
                "RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the IR community since the 1970s.",
                "The approaches that have been used to solve this problem can be roughly classified into two major categories: content based filtering versus collaborative filtering.",
                "Content-based filtering studies the scenario where a <br>recommendation system</br> monitors a document stream and pushes documents that match a user profile to the corresponding user.",
                "The user may read the delivered documents and provide explicit relevance feedback, which the filtering system then uses to update the users profile using relevance feedback retrieval models (e.g.",
                "Boolean models, vector space models, traditional probabilistic models [20] , inference networks [3] and language models [6]) or machine learning algorithms (e.g.",
                "Support Vector Machines (SVM), K nearest neighbors (K-NN) clustering, neural networks, logistic regression, or Winnow [16] [4] [23]).",
                "Collaborative filtering goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past.",
                "Memorybased heuristics and model based approaches have been used in collaborative filtering task [15] [8] [2] [14] [12] [11].",
                "This paper contributes to the content-based recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks[27][25].",
                "This paper does not intend to compare content-based filtering with collaborative filtering or claim which one is a better.",
                "We think each complements the other, and that content-based filtering is extremely useful for handling new documents/items with little or no user feedback.",
                "Similar to some other researchers[18][1][21], we found that a <br>recommendation system</br> will be more effective when both techniques are combined.",
                "However, this is beyond the scope of this paper and thus not discussed here. 3.",
                "BAYESIAN HIERARCHICAL LINEAR REGRESSION Assume there are M users in the system.",
                "The task of the system is to recommend documents that are relevant to each user.",
                "For each user, the system learns a user model from the users history.",
                "In the rest of this paper, we will use the following notations to represent the variables in the system. m = 1, 2, ..., M: The index for each individual user.",
                "M is the total number of users. wm: The user model parameter associated with user m. wm is a K dimensional vector. j = 1, 2, ..., Jm: The index for a set of data for user m. Jm is the number of training data for user m. Dm = {(xm,j, ym,j)}: A set of data associated with user m. xm,j is a K dimensional vector that represents the mth users jth training document.2 ym,j is a scalar that represents the label of document xm,j. k = 1, 2, ..., K: The dimensional index of input variable x.",
                "The Bayesian hierarchical modeling approach has been widely used in real-world information retrieval applications.",
                "Generalized Bayesian hierarchical linear models, one of the simplest Bayesian hierarchical models, are commonly used and have achieved good performance on collaborative filtering [25] and content-based adaptive filtering [27] tasks.",
                "Figure 1 shows the graphical representation of a Bayesian hierarchical model.",
                "In this graph, each user model is represented by a random vector wm.",
                "We assume a user model is sampled randomly from a prior distribution P(w|Φ).",
                "The system can predict the user label y of a document x given an estimation of wm (or wms distribution) using a function y = f(x, w).",
                "The model is called generalized Bayesian hierarchical linear model when y = f(wT x) is any generalized linear model such as logistic regression, SVM, and linear regression.",
                "To reliably estimate the user model wm, the system can borrow information from other users through the prior Φ = (µ, Σ).",
                "Now we look at one commonly used model where y = wT x + , where ∼ N(0, σ2 ) is a random noise [25][27].",
                "Assume that each user model wm is an independent draw from a population distribution P(w|Φ), which is governed by some unknown hyperparameter Φ.",
                "Let the prior distribution of user model w be a Gaussian distribution with parameter Φ = (µ, Σ), which is the commonly used prior for linear models. µ = (µ1, µ2, ..., µK ) is a K dimensional vector that represents the mean of the Gaussian distribution, and Σ is the covariance matrix of the Gaussian.",
                "Usually, a Normal distribution N(0, aI) and an Inverse Wishart distribution P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) are used as hyperprior to model the prior distribution of µ and Σ respectively.",
                "I is the K dimensional identity matrix, and a, b, and c are real numbers.",
                "With these settings, we have the following model for the system: 1. µ and Σ are sampled from N(0, aI) and IWν (aI), respectively. 2 The first dimension of x is a dummy variable that always equals to 1.",
                "Figure 1: Illustration of dependencies of variables in the hierarchical model.",
                "The rating, y, for a document, x, is conditioned on the document and the user model, wm, associated with the user m. Users share information about their models through the prior, Φ = (µ, Σ). 2.",
                "For each user m, wm is sampled randomly from a Normal distribution: wm ∼ N(µ, Σ2 ) 3.",
                "For each item xm,j, ym,j is sampled randomly from a Normal distribution: ym,j ∼ N(wT mxm,j, σ2 ).",
                "Let θ = (Φ, w1, w2, ..., wM ) represent the parameters of this system that needs to be estimated.",
                "The joint likelihood for all the variables in the probabilistic model, which includes the data and the parameters, is: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) For simplicity, we assume a, b, c, and σ are provided to the system. 4.",
                "MODEL PARAMETER LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple linear regression.",
                "Therefore, we will focus on estimating Φ.",
                "The maximum a priori solution of Φ is given by ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Finding the optimal solution for the above problem is challenging, since we need to integrate over all w = (w1, w2, ..., wM ), which are unobserved hidden variables. 4.1 EM Algorithm for Bayesian Hierarchical Linear Models In Equation 5, Φ is the parameter needs to be estimated, and the result depends on unobserved latent variables w. This kind of optimization problem is usually solved by the EM algorithm.",
                "Applying EM to the above problem, the set of user models w are the unobservable hidden variables and we have: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw Based on the derivation of the EM formulas presented in [24], we have the following Expectation-Maximization steps for finding the optimal hyperparameters.",
                "For space considerations, we omit the derivation in this paper since it is not the focus of our work.",
                "E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of the prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) where Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j M step: Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Many machine learning driven IR systems use a point estimate of the parameters at different stages in the system.",
                "However, we are estimating the posterior distribution of the variables at the E step.",
                "This avoids overfitting wm to a particular users data, which may be small and noisy.",
                "A detailed discussion about this subject appears in [10]. 4.2 New Algorithm: Modified EM Although the EM algorithm is widely studied and used in machine learning applications, using the above EM process to solve Bayesian hierarchical linear models in large-scale information retrieval systems is still too computationally expensive.",
                "In this section, we describe why the learning rate of the EM algorithm is slow in our application and introduce a new technique to make the learning of the Bayesian hierarchical linear model scalable.",
                "The derivation of the new learning algorithm will be based on the EM algorithm described in the previous section.",
                "First, the covariance matrices Σ2 , Σ2 m are usually too large to be computationally feasible.",
                "For simplicity, and as a common practice in IR, we do not model the correlation between features.",
                "Thus we approximate these matrices with K dimensional diagonal matrices.",
                "In the rest of the paper, we use these symbols to represent their diagonal approximations: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     Secondly, and most importantly, the input space is very sparse and there are many dimensions that are not related to a particular user in a real IR application.",
                "For example, let us consider a movie <br>recommendation system</br>, with the input variable x representing a particular movie.",
                "For the jth movie that the user m has seen, let xm,j,k = 1 if the director of the movie is Jean-Pierre Jeunet (indexed by k).",
                "Here we assume that whether or not that this director directed a specific movie is represented by the kth dimension.",
                "If the user m has never seen a movie directed by Jean-Pierre Jeunet, then the corresponding dimension is always zero (xm,j,k = 0 for all j) .",
                "One major drawback of the EM algorithm is that the importance of a feature, µk, may be greatly dominated by users who have never encountered this feature (i.e. j xm,j,k = 0) at the M step (Equation 8).",
                "Assume that 100 out of 1 million users have viewed the movie directed by Jean-Pierre Jeunet, and that the viewers have rated all of his movies as excellent.",
                "Intuitively, he is a good director and the weight for him (µk) should be high.",
                "Before the EM iteration, the initial value of µ is usually set to 0.",
                "Since the other 999,900 users have not seen this movie, their corresponding weights (w1,k, w2,k, ..., wm,k..., w999900,k) for that director would be very small initially.",
                "Thus the corresponding weight of the director in the prior µk at the first M step would be very low , and the variance σm,k will be large (Equations 8 and 7).",
                "It is undesirable that users who have never seen any movie produced by the director influence the importance of the director so much.",
                "This makes the convergence of the standard EM algorithm very slow.",
                "Now lets look at whether we can improve the learning speed of the algorithm.",
                "Without a loss of generality, let us assume that the kth dimension of the input variable x is not related to a particular user m. By which we mean, xm,j,k = 0 for all j = 1, ..., Jm.",
                "It is straightforward to prove that the kth row and kth column of Sxx,m are completely filled with zeros, and that the kth dimension of Sxy,m is zeroed as well.",
                "Thus the corresponding kth dimension of the user models mean, ¯wm, should be equal to that of the prior: ¯wm,k = µk, with the corresponding covariance of σm,k = σk.",
                "At the M step, the standard EM algorithm uses the numerical solution of the distribution P(wm|Dm, Φ) estimated at E step (Equation 8 and Equation 7).",
                "However, the numerical solutions are very unreliable for ¯wm,k and σm,k when the kth dimension is not related to the mth user.",
                "A better approach is using the analytical solutions ¯wm,k = µk, and σm,k = σk for the unrelated (m, k) pairs, along with the numerical solution estimated at E step for the other (m, k) pairs.",
                "Thus we get the following new EM-like algorithm: Modified E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) where sxx,m,k = j x2 m,j,k and sxy,m,k = j xm,j,kym,j Modified M Step Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step for related userfeature pairs.",
                "The M step implicitly uses the analytical solution for unrelated user-feature pairs. µk = 1 Mk m:related ¯wm,k (12) σ2 k = 1 Mk m:related σ2 m,k +( ¯wm,k − µk)( ¯wm,k − µk)T (13) where Mk is the number of users that are related to feature k We only estimate the diagonal of Σ2 m and Σ since we are using the diagonal approximation of the covariance matrices.",
                "To estimate ¯wm, we only need to calculate the numerical solutions for dimensions that are related to user m. To estimate σ2 k and µk, we only sum over users that are related to the kth feature.",
                "There are two major benefits of the new algorithm.",
                "First, because only the related (m, k) pairs are needed at the modified M step, the computational complexity in a single EM iteration is much smaller when the data is sparse, and many of (m, k) pairs are unrelated.",
                "Second, the parameters estimated at the modified M step (Equations 12 - 13) are more accurate than the standard M step described in Section 4.1 because the exact analytical solutions ¯wm,k = µk and σm,k = σk for the unrelated (m, k) pairs were used in the new algorithm instead of an approximate solution as in the standard algorithm. 5.",
                "EXPERIMENTAL METHODOLOGY 5.1 Evaluation Data Set To evaluate the proposed technique, we used the following three major data sets (Table 1): MovieLens Data: This data set was created by combining the relevance judgments from the MovieLens[9] data set with documents from the Internet Movie Database (IMDB).",
                "MovieLens allows users to rank how much he/she enjoyed a specific movie on a scale from 1 to 5.",
                "This likeability rating was used as a measurement of how relevant the document representing the corresponding movie is to the user.",
                "We considered documents with likeability scores of 4 or 5 as relevant, and documents with a score of 1 to 3 as irrelevant to the user.",
                "MovieLens provided relevance judgments on 3,057 documents from 6,040 separate users.",
                "On average, each user rated 151 movies, of these 87 were judged to be relevant.",
                "The average score for a document was 3.58.",
                "Documents representing each movie were constructed from the portion of the IMDB database that is available for public download[13].",
                "Based on this database, we created one document per movie that contained the relevant information about it (e.g. directors, actors, etc.).",
                "Table 1: Data Set Statistics.",
                "On Reuters, the number of rating for a simulated user is the number of documents relevant to the corresponding topic.",
                "Data Users Docs Ratings per User MovieLens 6,040 3,057 151 Netflix-all 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Netflix Data: This data set was constructed by combining documents about movies crawled from the web with a set of actual movie rental customer relevance judgments from Netflix[19].",
                "Netflix publicly provides the relevance judgments of 480,189 anonymous customers.",
                "There are around 100 million rating on a scale of 1 to 5 for 17,770 documents.",
                "Similar to MovieLens, we considered documents with likeability scores of 4 or 5 as relevant.",
                "This number was reduced to 1000 customers through random sampling.",
                "The average customer on the reduced data set provided 127 judgments, with 70 being deemed relevant.",
                "The average score for documents is 3.55.",
                "Reuters Data: This is the Reuters Corpus, Volume 1.",
                "It covers 810,000 Reuters English language news stories from August 20, 1996 to August 19, 1997.",
                "Only the first 100,000 news were used in our experiments.",
                "The Reuters corpus comes with a topic hierarchy.",
                "Each document is assigned to one of several locations on the hierarchical tree.",
                "The first level of the tree contains four topics, denoted as C, E, M, and G. For the experiments in this paper, the tree was cut at level 1 to create four smaller trees, each of which corresponds to one smaller data set: Reuters-E Reuters-C, ReutersM and Reuters-G. For each small data set, we created several profiles, one profile for each node in a sub-tree, to simulate multiple users, each with a related, yet separate definition of relevance.",
                "All the user profiles on a sub-tree are supposed to share the same prior model distribution.",
                "Since this corpus explicitly indicates only the relevant documents for a topic(user), all other documents are considered irrelevant. 5.2 Evaluation We designed the experiments to answer the following three questions: 1.",
                "Do we need to take the effort to use a Bayesian approach and learn a prior from other users? 2.",
                "Does the new algorithm work better than the standard EM algorithm for learning the Bayesian hierarchical linear model? 3.",
                "Can the new algorithm quickly learn many user models?",
                "To answer the first question, we compared the Bayesian hierarchical models with commonly used Norm-2 regularized linear regression models.",
                "In fact, the commonly used approach is equivalent to the model learned at the end of the first EM iteration.",
                "To answer the second question, we compared the proposed new algorithm with the standard EM algorithm to see whether the new learning algorithm is better.",
                "To answer the third question, we tested the efficiency of the new algorithm on the entire Netflix data set where about half a million user models need to be learned together.",
                "For the MovieLens and Netflix data sets, algorithm effectiveness was measured by mean square error, while on the Reuters data set classification error was used because it was more informative.",
                "We first evaluated the performance on each individual user, and then estimated the macro average over all users.",
                "Statistical tests (t-tests) were carried out to see whether the results are significant.",
                "For the experiments on the MovieLens and Netflix data sets, we used a random sample of 90% of each user for training, and the rest for testing.",
                "On Reuters data set, because there are too many relevant documents for each topic in the corpus, we used a random sample of 10% of each topic for training, and 10% of the remaining documents for testing.",
                "For all runs, we set (a, b, c, Σ ) = (0.1, 10, 0.1, 1) manually. 6.",
                "EXPERIMENTAL RESULTS Figure 2, Figure 3, and Figure 4 show that on all data sets, the Bayesian hierarchical modeling approach has a statistical significant improvement over the regularized linear regression model, which is equivalent to the Bayesian hierarchical models learned at the first iteration.",
                "Further analysis shows a negative correlation between the number of training data for a user and the improvement the system gets.",
                "This suggests that the borrowing information from other users has more significant improvements for users with less training data, which is as expected.",
                "However, the strength of the correlation differs over data sets, and the amount of training data is not the only characteristics that will influence the final performance.",
                "Figure 2 and Figure 3 show that the proposed new algorithm works better than the standard EM algorithm on the Netflix and MovieLens data sets.",
                "This is not surprising since the number of related feature-users pairs is much smaller than the number of unrelated feature-user pairs on these two data sets, and thus the proposed new algorithm is expected to work better.",
                "Figure 4 shows that the two algorithms work similarly on the Reuters-E data set.",
                "The accuracy of the new algorithm is similar to that of the standard EM algorithm at each iteration.",
                "The general patterns are very similar on other Reuters subsets.",
                "Further analysis shows that only 58% of the user-feature pairs are unrelated on this data set.",
                "Since the number of unrelated user-feature pairs is not extremely large, the sparseness is not a serious problem on the Reuters data set.",
                "Thus the two learning algorithms perform similarly.",
                "The results suggest that only on a corpus where the number of unrelated user-feature pairs is much larger than the number of related pairs, such as on the Netflix data set, the proposed technique will get a significant improvement over standard EM.",
                "However, the experiments also show that when the assumption does not hold, the new algorithm does not hurt performance.",
                "Although the proposed technique is faster than standard Figure 2: Performance on a Netflix subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iterations 2 - 10.",
                "Norm-2 regularized linear models are equivalent to the Bayesian hierarchical models learned at the first iteration, and are statistical significantly worse than the Bayesian hierarchical models. 0 2 4 6 8 10 1 1.05 1.1 1.15 1.2 1.25 1.3 1.35 1.4 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iterations ClassificationError New Algorithm Traditional EM Figure 3: Performance on a MovieLens subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iteration 2 to 17 (evaluated with mean square error). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iterations MeanSquareError New Algorithm Traditional EM 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iterations ClassificationError New Algorithm Traditional EM Figure 4: Performance on a Reuters-E subset with 26 profiles.",
                "Performances on Reuters-C, Reuters-M, Reuters-G are similar. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iterations ClassificationError New Algorithm Traditional EM EM, can it really learn millions of user models quickly?",
                "Our results show that the modified EM algorithm converges quickly, and 2 - 3 modified EM iterations would result in a reliable estimation.",
                "We evaluated the algorithm on the whole Netflix data set (480,189 users, 159,836 features, and 100 million ratings) running on a single CPU PC (2GB memory, P4 3GHz).",
                "The system finished one modified EM iteration in about 4 hours.",
                "This demonstrates that the proposed technique can efficiently handle large-scale system like Netflix. 7.",
                "CONCLUSION Content-based user profile learning is an important problem and is the key to providing personal recommendations to a user, especially for recommending new items with a small number of ratings.",
                "The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors.",
                "This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM.",
                "We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm.",
                "Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse, by which we mean the ratio of related user-feature pairs to unrelated pairs is small.",
                "Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold.",
                "In general, it is better to use the new algorithm since it is as simple as standard EM, the performance is either better or similar to EM, and the computation complexity is lower at each iteration.",
                "It is worth mentioning that even if the original problem space is not sparse, sparseness can be created artificially when a <br>recommendation system</br> uses user-specific feature selection techniques to reduce the noise and user model complexity.",
                "The proposed technique can also be adapted to improve the learning in such a scenario.",
                "We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU.",
                "The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear modeling approach to build a practical large scale system, even though the literature have demonstrated the effectiveness of the models in many applications.",
                "Our work is one major step on the road to make Bayesian hierarchical linear models more practical.",
                "The proposed new technique can be easily adapted to run on a cluster of machines, and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users.",
                "The research has much potential to benefit people using EM algorithm on many other IR problems as well as machine learning problems.",
                "EM algorithm is a commonly used machine learning technique.",
                "It is used to find model parameters in many IR problems where the training data is very sparse.",
                "Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering, the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems. 8.",
                "ACKNOWLEDGMENTS We thank Wei Xu, David Lewis and anonymous reviewers for valuable feedback on the work described in this paper.",
                "Part of the work was supported by Yahoo, Google, the Petascale Data Storage Institute and the Institute for Scalable Scientific Data Management.",
                "Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors, and do not necessarily reflect those of the sponsors. 9.",
                "REFERENCES [1] C. Basu, H. Hirsh, and W. Cohen.",
                "Recommendation as classification: Using social and content-based information in recommendation.",
                "In Proceedings of the Fifteenth National Conference on Artificial Intelligence, 1998. [2] J. S. Breese, D. Heckerman, and C. Kadie.",
                "Empirical analysis of predictive algorithms for collaborative filtering.",
                "Technical report, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan.",
                "Document filtering with inference networks.",
                "In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor, and A. Vinokourov.",
                "Kernel method for document filtering.",
                "In The Eleventh Text REtrieval Conference (TREC11).",
                "National Institute of Standards and Technology, special publication 500-249, 2003. [5] C. Chelba and A. Acero.",
                "Adaptation of maximum entropy capitalizer: Little data can help a lot.",
                "In D. Lin and D. Wu, editors, Proceedings of EMNLP 2004, pages 285-292, Barcelona, Spain, July 2004.",
                "Association for Computational Linguistics. [6] B. Croft and J. Lafferty, editors.",
                "Language Modeling for Information Retrieval.",
                "Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov, and A. Genkin.",
                "Constructing informative prior distributions from domain knowledge in text classification.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 493-500, New York, NY, USA, 2006.",
                "ACM Press. [8] J. Delgado and N. Ishii.",
                "Memory-based weightedmajority prediction for recommender systems.",
                "In ACM SIGIR99 Workshop on Recommender Systems, 1999. [9] GroupLens.",
                "Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman.",
                "A tutorial on learning with bayesian networks.",
                "In M. Jordan, editor, Learning in Graphical Models.",
                "Kluwer Academic, 1998. [11] J. L. Herlocker, J.",
                "A. Konstan, A. Borchers, and J. Riedl.",
                "An algorithmic framework for performing collaborative filtering.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 230-237, New York, NY, USA, 1999.",
                "ACM Press. [12] T. Hofmann and J. Puzicha.",
                "Latent class models for collaborative filtering.",
                "In IJCAI 99: Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 688-693, San Francisco, CA, USA, 1999.",
                "Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).",
                "Internet movie database. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai, and L. Si.",
                "An automatic weighting scheme for collaborative filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 337-344, New York, NY, USA, 2004.",
                "ACM Press. [15] J.",
                "A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl.",
                "GroupLens: Applying collaborative filtering to Usenet news.",
                "Communications of the ACM, 40(3):77-87, 1997. [16] D. Lewis.",
                "Applying support vector machines to the TREC-2001 batch filtering and routing tasks.",
                "In Proceedings of the Eleventh Text REtrieval Conference (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee, , and P. Yu.",
                "Text classification by labeling words.",
                "In Proceedings of The Nineteenth National Conference on Artificial Intelligence (AAAI-2004), July 25-29, 2004. [18] P. Melville, R. J. Mooney, and R. Nagarajan.",
                "Content-boosted collaborative filtering for improved recommendations.",
                "In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002), Edmonton, Canada, 2002. [19] Netflix.",
                "Netflix prize. http://www.netflixprize.com (visited on Nov. 30, 2006), 2006. [20] S. Robertson and K. Sparck-Jones.",
                "Relevance weighting of search terms.",
                "In Journal of the American Society for Information Science, volume 27, pages 129-146, 1976. [21] J. Wang, A. P. de Vries, and M. J. T. Reinders.",
                "Unifying user-based and item-based collaborative filtering approaches by similarity fusion.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 501-508, New York, NY, USA, 2006.",
                "ACM Press. [22] X. Wu and R. K. Srihari.",
                "Incorporating prior knowledge with weighted margin support vector machines.",
                "In Proc.",
                "ACM Knowledge Discovery Data Mining Conf. (ACM SIGKDD 2004), Aug. 2004. [23] Y. Yang, S. Yoo, J. Zhang, and B. Kisiel.",
                "Robustness of adaptive filtering methods in a cross-benchmark evaluation.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2005. [24] K. Yu, V. Tresp, and A. Schwaighofer.",
                "Learning gaussian processes from multiple tasks.",
                "In ICML 05: Proceedings of the 22nd international conference on Machine learning, pages 1012-1019, New York, NY, USA, 2005.",
                "ACM Press. [25] K. Yu, V. Tresp, and S. Yu.",
                "A nonparametric hierarchical bayesian framework for information filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 353-360.",
                "ACM Press, 2004. [26] X. Zhu.",
                "Semi-supervised learning literature survey.",
                "Technical report, University of Wisconsin - Madison, December 9, 2006. [27] P. Zigoris and Y. Zhang.",
                "Bayesian adaptive user profiling with explicit & implicit feedback.",
                "In Conference on Information and Knowledge Mangement 2006, 2006."
            ],
            "original_annotated_samples": [
                "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A content-based personalized <br>recommendation system</br> learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
                "One well-received approach to improve <br>recommendation system</br> performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach.",
                "A mature <br>recommendation system</br> usually works for millions of users.",
                "However, a content based <br>recommendation system</br> often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector.",
                "Content-based filtering studies the scenario where a <br>recommendation system</br> monitors a document stream and pushes documents that match a user profile to the corresponding user."
            ],
            "translated_annotated_samples": [
                "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un <br>sistema de recomendación</br> personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual.",
                "Un enfoque bien recibido para mejorar el rendimiento del <br>sistema de recomendación</br> para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano.",
                "Un <br>sistema de recomendación</br> maduro generalmente funciona para millones de usuarios.",
                "Sin embargo, un <br>sistema de recomendación</br> basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso.",
                "El filtrado basado en contenido estudia el escenario en el que un <br>sistema de recomendación</br> monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente."
            ],
            "translated_text": "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un <br>sistema de recomendación</br> personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual. Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un modelo jerárquico bayesiano. Aprender los parámetros del modelo para optimizar la verosimilitud conjunta de los datos de millones de usuarios es muy costoso computacionalmente. El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de datos en aplicaciones de IR. Este documento propone una nueva técnica de aprendizaje rápido para aprender un gran número de perfiles de usuario individuales. La eficacia y eficiencia del algoritmo propuesto están justificadas por la teoría y demostradas en datos reales de usuarios de Netflix y MovieLens. Categorías y Descriptores de Asignaturas: B.3.3 [Búsqueda y Recuperación de Información]: Filtrado de información Términos Generales: Algoritmos 1. La personalización es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales. Por ejemplo, las tiendas en línea, como Amazon y Netflix, ofrecen recomendaciones personalizadas de productos o servicios adicionales basadas en el historial de un usuario. Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de un usuario a partir de su historial. Un tema importante de personalización estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados basados en el contenido. Estos sistemas aprenden perfiles específicos de usuario a partir de la retroalimentación del usuario para poder recomendar información adaptada a los intereses de cada usuario sin necesidad de que el usuario realice una consulta explícita. Aprender los perfiles de usuario es el problema central de estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica qué tan relevante es un documento para el usuario. Uno de los principales desafíos de construir un sistema de recomendación o personalización es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña. Esto se conoce como el problema de inicio en frío. Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente retroalimentación de ese usuario para aprender un perfil de usuario confiable. Se ha realizado mucha investigación sobre cómo mejorar la precisión de clasificación cuando la cantidad de datos de entrenamiento etiquetados es pequeña. El enfoque de aprendizaje semisupervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26]. Otro enfoque es utilizar el conocimiento del dominio. Los investigadores han modificado diferentes algoritmos de aprendizaje, como NaïveBayes [17], regresión logística [7] y SVMs [22], para integrar el conocimiento del dominio en un clasificador de texto. El tercer enfoque consiste en tomar datos de entrenamiento de otros recursos [5][7]. La efectividad de estos enfoques diferentes es mixta, debido a qué tan bien se ajusta la suposición del modelo subyacente a los datos. Un enfoque bien recibido para mejorar el rendimiento del <br>sistema de recomendación</br> para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano. Varios investigadores han demostrado que este enfoque intercambia eficazmente entre la información compartida y la específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario[27][25]. Para aprender un modelo jerárquico bayesiano, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados. Un <br>sistema de recomendación</br> maduro generalmente funciona para millones de usuarios. Es bien sabido que aprender los parámetros óptimos de un modelo jerárquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios. El algoritmo EM es una técnica comúnmente utilizada para el aprendizaje de parámetros debido a su simplicidad y garantía de convergencia. Sin embargo, un <br>sistema de recomendación</br> basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso. Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM tering, o filtrado colaborativo basado en elementos. En este documento, las palabras filtrado y recomendación se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de las variables de entrada. También encontramos que actualizar el parámetro del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones. Este documento modifica el algoritmo EM estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos algoritmo EM modificado. La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M utilizamos la solución analítica en lugar de la solución numérica estimada en el paso E para esos parámetros. Esto reduce considerablemente la computación en una sola iteración de EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales. La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de regresión lineal jerárquica bayesiana utilizado para recomendaciones basadas en contenido. La sección 4 describe cómo aprender los parámetros del modelo utilizando el algoritmo EM estándar, junto con el uso de la nueva técnica propuesta en este artículo. La configuración experimental y los resultados utilizados para validar la técnica de aprendizaje propuesta se informan en las Secciones 5 y 6. La sección 7 resume y ofrece observaciones finales. 2. TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de IR desde la década de 1970. Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus filtrado colaborativo. El filtrado basado en contenido estudia el escenario en el que un <br>sistema de recomendación</br> monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "linear regression": {
            "translated_key": "regresión lineal",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
                "A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model.",
                "Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive.",
                "The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications.",
                "This paper proposes a new fast learning technique to learn a large number of individual user profiles.",
                "The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens.",
                "Categories and Subject Descriptors: B.3.3 [Information Search and Retrieval]: Information filtering General Terms: Algorithms 1.",
                "INTRODUCTION Personalization is the future of the Web, and it has achieved great success in industrial applications.",
                "For example, online stores, such as Amazon and Netflix, provide customized recommendations for additional products or services based on a users history.",
                "Recent offerings such as My MSN, My Yahoo!, My Google, and Google News have attracted much attention due to their potential ability to infer a users interests from his/her history.",
                "One major personalization topic studied in the information retrieval community is content-based personal recommendation systems1 .",
                "These systems learn user-specific profiles from user feedback so that they can recommend information tailored to each individual users interest without requiring the user to make an explicit query.",
                "Learning the user profiles is the core problem for these systems.",
                "A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user.",
                "One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small.",
                "This is known as the cold start problem.",
                "This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile.",
                "There has been much research on improving classification accuracy when the amount of labeled training data is small.",
                "The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal [26].",
                "Another approach is using domain knowledge.",
                "Researchers have modified different learning algorithms, such as Na¨ıveBayes [17], logistic regression [7], and SVMs [22], to integrate domain knowledge into a text classifier.",
                "The third approach is borrowing training data from other resources [5][7].",
                "The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data.",
                "One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach.",
                "Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial performance for each user[27][25].",
                "In order to learn a Bayesian hierarchical model, the system usually tries to find the most likely model parameters for the given data.",
                "A mature recommendation system usually works for millions of users.",
                "It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users.",
                "The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee.",
                "However, a content based recommendation system often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector.",
                "With careful analysis of the EM algorithm in this scenario (Section 4), we find that the EM tering, or item-based collaborative filtering.",
                "In this paper, the words filtering and recommendation are used interchangeably. algorithm converges very slowly due to the sparseness of the input variables.",
                "We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O(MK), where M is the number of users and K is the number of dimensions.",
                "This paper modifies the standard EM algorithm to create an improved learning algorithm, which we call the Modified EM algorithm.",
                "The basic idea is that instead of calculating the numerical solution for all the user profile parameters, we derive the analytical solution of the parameters for some feature dimensions, and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters.",
                "This greatly reduces the computation at a single EM iteration, and also has the benefit of increasing the convergence speed of the learning algorithm.",
                "The proposed technique is not only well supported by theory, but also by experimental results.",
                "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical <br>linear regression</br> modeling framework used for content-based recommendations.",
                "Section 4 describes how to learn the model parameters using the standard EM algorithm, along with using the new technique proposed in this paper.",
                "The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6.",
                "Section 7 summarizes and offers concluding remarks. 2.",
                "RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the IR community since the 1970s.",
                "The approaches that have been used to solve this problem can be roughly classified into two major categories: content based filtering versus collaborative filtering.",
                "Content-based filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user.",
                "The user may read the delivered documents and provide explicit relevance feedback, which the filtering system then uses to update the users profile using relevance feedback retrieval models (e.g.",
                "Boolean models, vector space models, traditional probabilistic models [20] , inference networks [3] and language models [6]) or machine learning algorithms (e.g.",
                "Support Vector Machines (SVM), K nearest neighbors (K-NN) clustering, neural networks, logistic regression, or Winnow [16] [4] [23]).",
                "Collaborative filtering goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past.",
                "Memorybased heuristics and model based approaches have been used in collaborative filtering task [15] [8] [2] [14] [12] [11].",
                "This paper contributes to the content-based recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks[27][25].",
                "This paper does not intend to compare content-based filtering with collaborative filtering or claim which one is a better.",
                "We think each complements the other, and that content-based filtering is extremely useful for handling new documents/items with little or no user feedback.",
                "Similar to some other researchers[18][1][21], we found that a recommendation system will be more effective when both techniques are combined.",
                "However, this is beyond the scope of this paper and thus not discussed here. 3.",
                "BAYESIAN HIERARCHICAL <br>linear regression</br> Assume there are M users in the system.",
                "The task of the system is to recommend documents that are relevant to each user.",
                "For each user, the system learns a user model from the users history.",
                "In the rest of this paper, we will use the following notations to represent the variables in the system. m = 1, 2, ..., M: The index for each individual user.",
                "M is the total number of users. wm: The user model parameter associated with user m. wm is a K dimensional vector. j = 1, 2, ..., Jm: The index for a set of data for user m. Jm is the number of training data for user m. Dm = {(xm,j, ym,j)}: A set of data associated with user m. xm,j is a K dimensional vector that represents the mth users jth training document.2 ym,j is a scalar that represents the label of document xm,j. k = 1, 2, ..., K: The dimensional index of input variable x.",
                "The Bayesian hierarchical modeling approach has been widely used in real-world information retrieval applications.",
                "Generalized Bayesian hierarchical linear models, one of the simplest Bayesian hierarchical models, are commonly used and have achieved good performance on collaborative filtering [25] and content-based adaptive filtering [27] tasks.",
                "Figure 1 shows the graphical representation of a Bayesian hierarchical model.",
                "In this graph, each user model is represented by a random vector wm.",
                "We assume a user model is sampled randomly from a prior distribution P(w|Φ).",
                "The system can predict the user label y of a document x given an estimation of wm (or wms distribution) using a function y = f(x, w).",
                "The model is called generalized Bayesian hierarchical linear model when y = f(wT x) is any generalized linear model such as logistic regression, SVM, and <br>linear regression</br>.",
                "To reliably estimate the user model wm, the system can borrow information from other users through the prior Φ = (µ, Σ).",
                "Now we look at one commonly used model where y = wT x + , where ∼ N(0, σ2 ) is a random noise [25][27].",
                "Assume that each user model wm is an independent draw from a population distribution P(w|Φ), which is governed by some unknown hyperparameter Φ.",
                "Let the prior distribution of user model w be a Gaussian distribution with parameter Φ = (µ, Σ), which is the commonly used prior for linear models. µ = (µ1, µ2, ..., µK ) is a K dimensional vector that represents the mean of the Gaussian distribution, and Σ is the covariance matrix of the Gaussian.",
                "Usually, a Normal distribution N(0, aI) and an Inverse Wishart distribution P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) are used as hyperprior to model the prior distribution of µ and Σ respectively.",
                "I is the K dimensional identity matrix, and a, b, and c are real numbers.",
                "With these settings, we have the following model for the system: 1. µ and Σ are sampled from N(0, aI) and IWν (aI), respectively. 2 The first dimension of x is a dummy variable that always equals to 1.",
                "Figure 1: Illustration of dependencies of variables in the hierarchical model.",
                "The rating, y, for a document, x, is conditioned on the document and the user model, wm, associated with the user m. Users share information about their models through the prior, Φ = (µ, Σ). 2.",
                "For each user m, wm is sampled randomly from a Normal distribution: wm ∼ N(µ, Σ2 ) 3.",
                "For each item xm,j, ym,j is sampled randomly from a Normal distribution: ym,j ∼ N(wT mxm,j, σ2 ).",
                "Let θ = (Φ, w1, w2, ..., wM ) represent the parameters of this system that needs to be estimated.",
                "The joint likelihood for all the variables in the probabilistic model, which includes the data and the parameters, is: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) For simplicity, we assume a, b, c, and σ are provided to the system. 4.",
                "MODEL PARAMETER LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple <br>linear regression</br>.",
                "Therefore, we will focus on estimating Φ.",
                "The maximum a priori solution of Φ is given by ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Finding the optimal solution for the above problem is challenging, since we need to integrate over all w = (w1, w2, ..., wM ), which are unobserved hidden variables. 4.1 EM Algorithm for Bayesian Hierarchical Linear Models In Equation 5, Φ is the parameter needs to be estimated, and the result depends on unobserved latent variables w. This kind of optimization problem is usually solved by the EM algorithm.",
                "Applying EM to the above problem, the set of user models w are the unobservable hidden variables and we have: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw Based on the derivation of the EM formulas presented in [24], we have the following Expectation-Maximization steps for finding the optimal hyperparameters.",
                "For space considerations, we omit the derivation in this paper since it is not the focus of our work.",
                "E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of the prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) where Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j M step: Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Many machine learning driven IR systems use a point estimate of the parameters at different stages in the system.",
                "However, we are estimating the posterior distribution of the variables at the E step.",
                "This avoids overfitting wm to a particular users data, which may be small and noisy.",
                "A detailed discussion about this subject appears in [10]. 4.2 New Algorithm: Modified EM Although the EM algorithm is widely studied and used in machine learning applications, using the above EM process to solve Bayesian hierarchical linear models in large-scale information retrieval systems is still too computationally expensive.",
                "In this section, we describe why the learning rate of the EM algorithm is slow in our application and introduce a new technique to make the learning of the Bayesian hierarchical linear model scalable.",
                "The derivation of the new learning algorithm will be based on the EM algorithm described in the previous section.",
                "First, the covariance matrices Σ2 , Σ2 m are usually too large to be computationally feasible.",
                "For simplicity, and as a common practice in IR, we do not model the correlation between features.",
                "Thus we approximate these matrices with K dimensional diagonal matrices.",
                "In the rest of the paper, we use these symbols to represent their diagonal approximations: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     Secondly, and most importantly, the input space is very sparse and there are many dimensions that are not related to a particular user in a real IR application.",
                "For example, let us consider a movie recommendation system, with the input variable x representing a particular movie.",
                "For the jth movie that the user m has seen, let xm,j,k = 1 if the director of the movie is Jean-Pierre Jeunet (indexed by k).",
                "Here we assume that whether or not that this director directed a specific movie is represented by the kth dimension.",
                "If the user m has never seen a movie directed by Jean-Pierre Jeunet, then the corresponding dimension is always zero (xm,j,k = 0 for all j) .",
                "One major drawback of the EM algorithm is that the importance of a feature, µk, may be greatly dominated by users who have never encountered this feature (i.e. j xm,j,k = 0) at the M step (Equation 8).",
                "Assume that 100 out of 1 million users have viewed the movie directed by Jean-Pierre Jeunet, and that the viewers have rated all of his movies as excellent.",
                "Intuitively, he is a good director and the weight for him (µk) should be high.",
                "Before the EM iteration, the initial value of µ is usually set to 0.",
                "Since the other 999,900 users have not seen this movie, their corresponding weights (w1,k, w2,k, ..., wm,k..., w999900,k) for that director would be very small initially.",
                "Thus the corresponding weight of the director in the prior µk at the first M step would be very low , and the variance σm,k will be large (Equations 8 and 7).",
                "It is undesirable that users who have never seen any movie produced by the director influence the importance of the director so much.",
                "This makes the convergence of the standard EM algorithm very slow.",
                "Now lets look at whether we can improve the learning speed of the algorithm.",
                "Without a loss of generality, let us assume that the kth dimension of the input variable x is not related to a particular user m. By which we mean, xm,j,k = 0 for all j = 1, ..., Jm.",
                "It is straightforward to prove that the kth row and kth column of Sxx,m are completely filled with zeros, and that the kth dimension of Sxy,m is zeroed as well.",
                "Thus the corresponding kth dimension of the user models mean, ¯wm, should be equal to that of the prior: ¯wm,k = µk, with the corresponding covariance of σm,k = σk.",
                "At the M step, the standard EM algorithm uses the numerical solution of the distribution P(wm|Dm, Φ) estimated at E step (Equation 8 and Equation 7).",
                "However, the numerical solutions are very unreliable for ¯wm,k and σm,k when the kth dimension is not related to the mth user.",
                "A better approach is using the analytical solutions ¯wm,k = µk, and σm,k = σk for the unrelated (m, k) pairs, along with the numerical solution estimated at E step for the other (m, k) pairs.",
                "Thus we get the following new EM-like algorithm: Modified E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) where sxx,m,k = j x2 m,j,k and sxy,m,k = j xm,j,kym,j Modified M Step Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step for related userfeature pairs.",
                "The M step implicitly uses the analytical solution for unrelated user-feature pairs. µk = 1 Mk m:related ¯wm,k (12) σ2 k = 1 Mk m:related σ2 m,k +( ¯wm,k − µk)( ¯wm,k − µk)T (13) where Mk is the number of users that are related to feature k We only estimate the diagonal of Σ2 m and Σ since we are using the diagonal approximation of the covariance matrices.",
                "To estimate ¯wm, we only need to calculate the numerical solutions for dimensions that are related to user m. To estimate σ2 k and µk, we only sum over users that are related to the kth feature.",
                "There are two major benefits of the new algorithm.",
                "First, because only the related (m, k) pairs are needed at the modified M step, the computational complexity in a single EM iteration is much smaller when the data is sparse, and many of (m, k) pairs are unrelated.",
                "Second, the parameters estimated at the modified M step (Equations 12 - 13) are more accurate than the standard M step described in Section 4.1 because the exact analytical solutions ¯wm,k = µk and σm,k = σk for the unrelated (m, k) pairs were used in the new algorithm instead of an approximate solution as in the standard algorithm. 5.",
                "EXPERIMENTAL METHODOLOGY 5.1 Evaluation Data Set To evaluate the proposed technique, we used the following three major data sets (Table 1): MovieLens Data: This data set was created by combining the relevance judgments from the MovieLens[9] data set with documents from the Internet Movie Database (IMDB).",
                "MovieLens allows users to rank how much he/she enjoyed a specific movie on a scale from 1 to 5.",
                "This likeability rating was used as a measurement of how relevant the document representing the corresponding movie is to the user.",
                "We considered documents with likeability scores of 4 or 5 as relevant, and documents with a score of 1 to 3 as irrelevant to the user.",
                "MovieLens provided relevance judgments on 3,057 documents from 6,040 separate users.",
                "On average, each user rated 151 movies, of these 87 were judged to be relevant.",
                "The average score for a document was 3.58.",
                "Documents representing each movie were constructed from the portion of the IMDB database that is available for public download[13].",
                "Based on this database, we created one document per movie that contained the relevant information about it (e.g. directors, actors, etc.).",
                "Table 1: Data Set Statistics.",
                "On Reuters, the number of rating for a simulated user is the number of documents relevant to the corresponding topic.",
                "Data Users Docs Ratings per User MovieLens 6,040 3,057 151 Netflix-all 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Netflix Data: This data set was constructed by combining documents about movies crawled from the web with a set of actual movie rental customer relevance judgments from Netflix[19].",
                "Netflix publicly provides the relevance judgments of 480,189 anonymous customers.",
                "There are around 100 million rating on a scale of 1 to 5 for 17,770 documents.",
                "Similar to MovieLens, we considered documents with likeability scores of 4 or 5 as relevant.",
                "This number was reduced to 1000 customers through random sampling.",
                "The average customer on the reduced data set provided 127 judgments, with 70 being deemed relevant.",
                "The average score for documents is 3.55.",
                "Reuters Data: This is the Reuters Corpus, Volume 1.",
                "It covers 810,000 Reuters English language news stories from August 20, 1996 to August 19, 1997.",
                "Only the first 100,000 news were used in our experiments.",
                "The Reuters corpus comes with a topic hierarchy.",
                "Each document is assigned to one of several locations on the hierarchical tree.",
                "The first level of the tree contains four topics, denoted as C, E, M, and G. For the experiments in this paper, the tree was cut at level 1 to create four smaller trees, each of which corresponds to one smaller data set: Reuters-E Reuters-C, ReutersM and Reuters-G. For each small data set, we created several profiles, one profile for each node in a sub-tree, to simulate multiple users, each with a related, yet separate definition of relevance.",
                "All the user profiles on a sub-tree are supposed to share the same prior model distribution.",
                "Since this corpus explicitly indicates only the relevant documents for a topic(user), all other documents are considered irrelevant. 5.2 Evaluation We designed the experiments to answer the following three questions: 1.",
                "Do we need to take the effort to use a Bayesian approach and learn a prior from other users? 2.",
                "Does the new algorithm work better than the standard EM algorithm for learning the Bayesian hierarchical linear model? 3.",
                "Can the new algorithm quickly learn many user models?",
                "To answer the first question, we compared the Bayesian hierarchical models with commonly used Norm-2 regularized <br>linear regression</br> models.",
                "In fact, the commonly used approach is equivalent to the model learned at the end of the first EM iteration.",
                "To answer the second question, we compared the proposed new algorithm with the standard EM algorithm to see whether the new learning algorithm is better.",
                "To answer the third question, we tested the efficiency of the new algorithm on the entire Netflix data set where about half a million user models need to be learned together.",
                "For the MovieLens and Netflix data sets, algorithm effectiveness was measured by mean square error, while on the Reuters data set classification error was used because it was more informative.",
                "We first evaluated the performance on each individual user, and then estimated the macro average over all users.",
                "Statistical tests (t-tests) were carried out to see whether the results are significant.",
                "For the experiments on the MovieLens and Netflix data sets, we used a random sample of 90% of each user for training, and the rest for testing.",
                "On Reuters data set, because there are too many relevant documents for each topic in the corpus, we used a random sample of 10% of each topic for training, and 10% of the remaining documents for testing.",
                "For all runs, we set (a, b, c, Σ ) = (0.1, 10, 0.1, 1) manually. 6.",
                "EXPERIMENTAL RESULTS Figure 2, Figure 3, and Figure 4 show that on all data sets, the Bayesian hierarchical modeling approach has a statistical significant improvement over the regularized <br>linear regression</br> model, which is equivalent to the Bayesian hierarchical models learned at the first iteration.",
                "Further analysis shows a negative correlation between the number of training data for a user and the improvement the system gets.",
                "This suggests that the borrowing information from other users has more significant improvements for users with less training data, which is as expected.",
                "However, the strength of the correlation differs over data sets, and the amount of training data is not the only characteristics that will influence the final performance.",
                "Figure 2 and Figure 3 show that the proposed new algorithm works better than the standard EM algorithm on the Netflix and MovieLens data sets.",
                "This is not surprising since the number of related feature-users pairs is much smaller than the number of unrelated feature-user pairs on these two data sets, and thus the proposed new algorithm is expected to work better.",
                "Figure 4 shows that the two algorithms work similarly on the Reuters-E data set.",
                "The accuracy of the new algorithm is similar to that of the standard EM algorithm at each iteration.",
                "The general patterns are very similar on other Reuters subsets.",
                "Further analysis shows that only 58% of the user-feature pairs are unrelated on this data set.",
                "Since the number of unrelated user-feature pairs is not extremely large, the sparseness is not a serious problem on the Reuters data set.",
                "Thus the two learning algorithms perform similarly.",
                "The results suggest that only on a corpus where the number of unrelated user-feature pairs is much larger than the number of related pairs, such as on the Netflix data set, the proposed technique will get a significant improvement over standard EM.",
                "However, the experiments also show that when the assumption does not hold, the new algorithm does not hurt performance.",
                "Although the proposed technique is faster than standard Figure 2: Performance on a Netflix subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iterations 2 - 10.",
                "Norm-2 regularized linear models are equivalent to the Bayesian hierarchical models learned at the first iteration, and are statistical significantly worse than the Bayesian hierarchical models. 0 2 4 6 8 10 1 1.05 1.1 1.15 1.2 1.25 1.3 1.35 1.4 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iterations ClassificationError New Algorithm Traditional EM Figure 3: Performance on a MovieLens subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iteration 2 to 17 (evaluated with mean square error). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iterations MeanSquareError New Algorithm Traditional EM 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iterations ClassificationError New Algorithm Traditional EM Figure 4: Performance on a Reuters-E subset with 26 profiles.",
                "Performances on Reuters-C, Reuters-M, Reuters-G are similar. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iterations ClassificationError New Algorithm Traditional EM EM, can it really learn millions of user models quickly?",
                "Our results show that the modified EM algorithm converges quickly, and 2 - 3 modified EM iterations would result in a reliable estimation.",
                "We evaluated the algorithm on the whole Netflix data set (480,189 users, 159,836 features, and 100 million ratings) running on a single CPU PC (2GB memory, P4 3GHz).",
                "The system finished one modified EM iteration in about 4 hours.",
                "This demonstrates that the proposed technique can efficiently handle large-scale system like Netflix. 7.",
                "CONCLUSION Content-based user profile learning is an important problem and is the key to providing personal recommendations to a user, especially for recommending new items with a small number of ratings.",
                "The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors.",
                "This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM.",
                "We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm.",
                "Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse, by which we mean the ratio of related user-feature pairs to unrelated pairs is small.",
                "Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold.",
                "In general, it is better to use the new algorithm since it is as simple as standard EM, the performance is either better or similar to EM, and the computation complexity is lower at each iteration.",
                "It is worth mentioning that even if the original problem space is not sparse, sparseness can be created artificially when a recommendation system uses user-specific feature selection techniques to reduce the noise and user model complexity.",
                "The proposed technique can also be adapted to improve the learning in such a scenario.",
                "We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU.",
                "The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear modeling approach to build a practical large scale system, even though the literature have demonstrated the effectiveness of the models in many applications.",
                "Our work is one major step on the road to make Bayesian hierarchical linear models more practical.",
                "The proposed new technique can be easily adapted to run on a cluster of machines, and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users.",
                "The research has much potential to benefit people using EM algorithm on many other IR problems as well as machine learning problems.",
                "EM algorithm is a commonly used machine learning technique.",
                "It is used to find model parameters in many IR problems where the training data is very sparse.",
                "Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering, the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems. 8.",
                "ACKNOWLEDGMENTS We thank Wei Xu, David Lewis and anonymous reviewers for valuable feedback on the work described in this paper.",
                "Part of the work was supported by Yahoo, Google, the Petascale Data Storage Institute and the Institute for Scalable Scientific Data Management.",
                "Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors, and do not necessarily reflect those of the sponsors. 9.",
                "REFERENCES [1] C. Basu, H. Hirsh, and W. Cohen.",
                "Recommendation as classification: Using social and content-based information in recommendation.",
                "In Proceedings of the Fifteenth National Conference on Artificial Intelligence, 1998. [2] J. S. Breese, D. Heckerman, and C. Kadie.",
                "Empirical analysis of predictive algorithms for collaborative filtering.",
                "Technical report, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan.",
                "Document filtering with inference networks.",
                "In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor, and A. Vinokourov.",
                "Kernel method for document filtering.",
                "In The Eleventh Text REtrieval Conference (TREC11).",
                "National Institute of Standards and Technology, special publication 500-249, 2003. [5] C. Chelba and A. Acero.",
                "Adaptation of maximum entropy capitalizer: Little data can help a lot.",
                "In D. Lin and D. Wu, editors, Proceedings of EMNLP 2004, pages 285-292, Barcelona, Spain, July 2004.",
                "Association for Computational Linguistics. [6] B. Croft and J. Lafferty, editors.",
                "Language Modeling for Information Retrieval.",
                "Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov, and A. Genkin.",
                "Constructing informative prior distributions from domain knowledge in text classification.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 493-500, New York, NY, USA, 2006.",
                "ACM Press. [8] J. Delgado and N. Ishii.",
                "Memory-based weightedmajority prediction for recommender systems.",
                "In ACM SIGIR99 Workshop on Recommender Systems, 1999. [9] GroupLens.",
                "Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman.",
                "A tutorial on learning with bayesian networks.",
                "In M. Jordan, editor, Learning in Graphical Models.",
                "Kluwer Academic, 1998. [11] J. L. Herlocker, J.",
                "A. Konstan, A. Borchers, and J. Riedl.",
                "An algorithmic framework for performing collaborative filtering.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 230-237, New York, NY, USA, 1999.",
                "ACM Press. [12] T. Hofmann and J. Puzicha.",
                "Latent class models for collaborative filtering.",
                "In IJCAI 99: Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 688-693, San Francisco, CA, USA, 1999.",
                "Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).",
                "Internet movie database. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai, and L. Si.",
                "An automatic weighting scheme for collaborative filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 337-344, New York, NY, USA, 2004.",
                "ACM Press. [15] J.",
                "A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl.",
                "GroupLens: Applying collaborative filtering to Usenet news.",
                "Communications of the ACM, 40(3):77-87, 1997. [16] D. Lewis.",
                "Applying support vector machines to the TREC-2001 batch filtering and routing tasks.",
                "In Proceedings of the Eleventh Text REtrieval Conference (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee, , and P. Yu.",
                "Text classification by labeling words.",
                "In Proceedings of The Nineteenth National Conference on Artificial Intelligence (AAAI-2004), July 25-29, 2004. [18] P. Melville, R. J. Mooney, and R. Nagarajan.",
                "Content-boosted collaborative filtering for improved recommendations.",
                "In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002), Edmonton, Canada, 2002. [19] Netflix.",
                "Netflix prize. http://www.netflixprize.com (visited on Nov. 30, 2006), 2006. [20] S. Robertson and K. Sparck-Jones.",
                "Relevance weighting of search terms.",
                "In Journal of the American Society for Information Science, volume 27, pages 129-146, 1976. [21] J. Wang, A. P. de Vries, and M. J. T. Reinders.",
                "Unifying user-based and item-based collaborative filtering approaches by similarity fusion.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 501-508, New York, NY, USA, 2006.",
                "ACM Press. [22] X. Wu and R. K. Srihari.",
                "Incorporating prior knowledge with weighted margin support vector machines.",
                "In Proc.",
                "ACM Knowledge Discovery Data Mining Conf. (ACM SIGKDD 2004), Aug. 2004. [23] Y. Yang, S. Yoo, J. Zhang, and B. Kisiel.",
                "Robustness of adaptive filtering methods in a cross-benchmark evaluation.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2005. [24] K. Yu, V. Tresp, and A. Schwaighofer.",
                "Learning gaussian processes from multiple tasks.",
                "In ICML 05: Proceedings of the 22nd international conference on Machine learning, pages 1012-1019, New York, NY, USA, 2005.",
                "ACM Press. [25] K. Yu, V. Tresp, and S. Yu.",
                "A nonparametric hierarchical bayesian framework for information filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 353-360.",
                "ACM Press, 2004. [26] X. Zhu.",
                "Semi-supervised learning literature survey.",
                "Technical report, University of Wisconsin - Madison, December 9, 2006. [27] P. Zigoris and Y. Zhang.",
                "Bayesian adaptive user profiling with explicit & implicit feedback.",
                "In Conference on Information and Knowledge Mangement 2006, 2006."
            ],
            "original_annotated_samples": [
                "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical <br>linear regression</br> modeling framework used for content-based recommendations.",
                "BAYESIAN HIERARCHICAL <br>linear regression</br> Assume there are M users in the system.",
                "The model is called generalized Bayesian hierarchical linear model when y = f(wT x) is any generalized linear model such as logistic regression, SVM, and <br>linear regression</br>.",
                "MODEL PARAMETER LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple <br>linear regression</br>.",
                "To answer the first question, we compared the Bayesian hierarchical models with commonly used Norm-2 regularized <br>linear regression</br> models."
            ],
            "translated_annotated_samples": [
                "La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de <br>regresión lineal</br> jerárquica bayesiana utilizado para recomendaciones basadas en contenido.",
                "REGRESIÓN LINEAL HIERÁRQUICA BAYESIANA Suponga que hay M usuarios en el sistema.",
                "El modelo se llama modelo lineal jerárquico bayesiano generalizado cuando y = f(wT x) es cualquier modelo lineal generalizado como regresión logística, SVM y <br>regresión lineal</br>.",
                "APRENDIZAJE DE PARÁMETROS DEL MODELO Si se conoce el prior Φ, encontrar el óptimo wm es sencillo: se trata de una <br>regresión lineal</br> simple.",
                "Para responder a la primera pregunta, comparamos los modelos jerárquicos bayesianos con los modelos de <br>regresión lineal</br> regularizados Norm-2 comúnmente utilizados."
            ],
            "translated_text": "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual. Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un modelo jerárquico bayesiano. Aprender los parámetros del modelo para optimizar la verosimilitud conjunta de los datos de millones de usuarios es muy costoso computacionalmente. El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de datos en aplicaciones de IR. Este documento propone una nueva técnica de aprendizaje rápido para aprender un gran número de perfiles de usuario individuales. La eficacia y eficiencia del algoritmo propuesto están justificadas por la teoría y demostradas en datos reales de usuarios de Netflix y MovieLens. Categorías y Descriptores de Asignaturas: B.3.3 [Búsqueda y Recuperación de Información]: Filtrado de información Términos Generales: Algoritmos 1. La personalización es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales. Por ejemplo, las tiendas en línea, como Amazon y Netflix, ofrecen recomendaciones personalizadas de productos o servicios adicionales basadas en el historial de un usuario. Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de un usuario a partir de su historial. Un tema importante de personalización estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados basados en el contenido. Estos sistemas aprenden perfiles específicos de usuario a partir de la retroalimentación del usuario para poder recomendar información adaptada a los intereses de cada usuario sin necesidad de que el usuario realice una consulta explícita. Aprender los perfiles de usuario es el problema central de estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica qué tan relevante es un documento para el usuario. Uno de los principales desafíos de construir un sistema de recomendación o personalización es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña. Esto se conoce como el problema de inicio en frío. Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente retroalimentación de ese usuario para aprender un perfil de usuario confiable. Se ha realizado mucha investigación sobre cómo mejorar la precisión de clasificación cuando la cantidad de datos de entrenamiento etiquetados es pequeña. El enfoque de aprendizaje semisupervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26]. Otro enfoque es utilizar el conocimiento del dominio. Los investigadores han modificado diferentes algoritmos de aprendizaje, como NaïveBayes [17], regresión logística [7] y SVMs [22], para integrar el conocimiento del dominio en un clasificador de texto. El tercer enfoque consiste en tomar datos de entrenamiento de otros recursos [5][7]. La efectividad de estos enfoques diferentes es mixta, debido a qué tan bien se ajusta la suposición del modelo subyacente a los datos. Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano. Varios investigadores han demostrado que este enfoque intercambia eficazmente entre la información compartida y la específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario[27][25]. Para aprender un modelo jerárquico bayesiano, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados. Un sistema de recomendación maduro generalmente funciona para millones de usuarios. Es bien sabido que aprender los parámetros óptimos de un modelo jerárquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios. El algoritmo EM es una técnica comúnmente utilizada para el aprendizaje de parámetros debido a su simplicidad y garantía de convergencia. Sin embargo, un sistema de recomendación basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso. Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM tering, o filtrado colaborativo basado en elementos. En este documento, las palabras filtrado y recomendación se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de las variables de entrada. También encontramos que actualizar el parámetro del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones. Este documento modifica el algoritmo EM estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos algoritmo EM modificado. La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M utilizamos la solución analítica en lugar de la solución numérica estimada en el paso E para esos parámetros. Esto reduce considerablemente la computación en una sola iteración de EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales. La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de <br>regresión lineal</br> jerárquica bayesiana utilizado para recomendaciones basadas en contenido. La sección 4 describe cómo aprender los parámetros del modelo utilizando el algoritmo EM estándar, junto con el uso de la nueva técnica propuesta en este artículo. La configuración experimental y los resultados utilizados para validar la técnica de aprendizaje propuesta se informan en las Secciones 5 y 6. La sección 7 resume y ofrece observaciones finales. 2. TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de IR desde la década de 1970. Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus filtrado colaborativo. El filtrado basado en contenido estudia el escenario en el que un sistema de recomendación monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente. El usuario puede leer los documentos entregados y proporcionar retroalimentación explícita de relevancia, la cual el sistema de filtrado utiliza para actualizar el perfil del usuario mediante modelos de recuperación de retroalimentación de relevancia (por ejemplo,). Modelos booleanos, modelos de espacio vectorial, modelos probabilísticos tradicionales [20], redes de inferencia [3] y modelos de lenguaje [6]) o algoritmos de aprendizaje automático (por ejemplo, Máquinas de Vectores de Soporte (SVM), agrupamiento de K vecinos más cercanos (K-NN), redes neuronales, regresión logística o Winnow [16] [4] [23]. El filtrado colaborativo va más allá de simplemente usar el contenido de un documento para recomendar elementos a un usuario, aprovechando la información de otros usuarios con gustos y preferencias similares en el pasado. Se han utilizado heurísticas basadas en memoria y enfoques basados en modelos en la tarea de filtrado colaborativo [15] [8] [2] [14] [12] [11]. Este artículo contribuye a la investigación de recomendaciones basadas en contenido al mejorar la eficiencia y efectividad de los modelos lineales jerárquicos bayesianos, los cuales tienen una sólida base teórica y un buen rendimiento empírico en tareas de recomendación[27][25]. Este artículo no tiene la intención de comparar el filtrado basado en contenido con el filtrado colaborativo ni de afirmar cuál es mejor. Creemos que cada uno complementa al otro, y que el filtrado basado en contenido es extremadamente útil para manejar nuevos documentos/artículos con poco o ningún feedback del usuario. Similar a otros investigadores[18][1][21], encontramos que un sistema de recomendación será más efectivo cuando se combinan ambas técnicas. Sin embargo, esto está fuera del alcance de este documento y, por lo tanto, no se discute aquí. 3. REGRESIÓN LINEAL HIERÁRQUICA BAYESIANA Suponga que hay M usuarios en el sistema. La tarea del sistema es recomendar documentos que sean relevantes para cada usuario. Para cada usuario, el sistema aprende un modelo de usuario a partir del historial de los usuarios. En el resto de este documento, utilizaremos las siguientes notaciones para representar las variables en el sistema. m = 1, 2, ..., M: El índice para cada usuario individual. M es el número total de usuarios. wm: El parámetro del modelo de usuario asociado con el usuario m. wm es un vector de dimensión K. j = 1, 2, ..., Jm: El índice para un conjunto de datos para el usuario m. Jm es el número de datos de entrenamiento para el usuario m. Dm = {(xm,j, ym,j)}: Un conjunto de datos asociado con el usuario m. xm,j es un vector de dimensión K que representa el j-ésimo documento de entrenamiento del usuario m. ym,j es un escalar que representa la etiqueta del documento xm,j. k = 1, 2, ..., K: El índice dimensional de la variable de entrada x. El enfoque de modelado jerárquico bayesiano ha sido ampliamente utilizado en aplicaciones reales de recuperación de información. Los modelos lineales jerárquicos bayesianos generalizados, uno de los modelos jerárquicos bayesianos más simples, son comúnmente utilizados y han logrado un buen rendimiento en tareas de filtrado colaborativo [25] y filtrado adaptativo basado en contenido [27]. La Figura 1 muestra la representación gráfica de un modelo jerárquico bayesiano. En este gráfico, cada modelo de usuario está representado por un vector aleatorio wm. Suponemos que un modelo de usuario se muestrea aleatoriamente de una distribución previa P(w|Φ). El sistema puede predecir la etiqueta de usuario y de un documento x dado una estimación de wm (o distribución de wms) utilizando una función y = f(x, w). El modelo se llama modelo lineal jerárquico bayesiano generalizado cuando y = f(wT x) es cualquier modelo lineal generalizado como regresión logística, SVM y <br>regresión lineal</br>. Para estimar de manera confiable el modelo de usuario wm, el sistema puede obtener información de otros usuarios a través de la prior Φ = (µ, Σ). Ahora observamos un modelo comúnmente utilizado donde y = wT x + , donde ∼ N(0, σ2 ) es un ruido aleatorio [25][27]. Suponga que cada modelo de usuario wm es una muestra independiente de una distribución poblacional P(w|Φ), la cual está regida por un hiperparámetro desconocido Φ. Que la distribución previa del modelo de usuario w sea una distribución gaussiana con parámetro Φ = (µ, Σ), que es la distribución previa comúnmente utilizada para modelos lineales. µ = (µ1, µ2, ..., µK) es un vector de K dimensiones que representa la media de la distribución gaussiana, y Σ es la matriz de covarianza de la gaussiana. Normalmente, se utiliza una distribución Normal N(0, aI) y una distribución Inverse Wishart P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) como hiperprior para modelar la distribución previa de µ y Σ respectivamente. Yo es la matriz identidad de dimensión K, y a, b y c son números reales. Con esta configuración, tenemos el siguiente modelo para el sistema: 1. µ y Σ se muestrean de N(0, aI) e IWν (aI), respectivamente. 2. La primera dimensión de x es una variable ficticia que siempre es igual a 1. Figura 1: Ilustración de las dependencias de variables en el modelo jerárquico. La calificación, y, para un documento, x, está condicionada al documento y al modelo de usuario, wm, asociado con el usuario m. Los usuarios comparten información sobre sus modelos a través de la prior, Φ = (µ, Σ). Para cada usuario m, wm se muestrea aleatoriamente de una distribución Normal: wm ∼ N(µ, Σ2 ) 3. Para cada elemento xm,j, ym,j se muestrea aleatoriamente de una distribución Normal: ym,j ∼ N(wT mxm,j, σ2). Que θ = (Φ, w1, w2, ..., wM) represente los parámetros de este sistema que necesitan ser estimados. La verosimilitud conjunta de todas las variables en el modelo probabilístico, que incluye los datos y los parámetros, es: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) Para simplificar, asumimos que a, b, c y σ son proporcionados al sistema. 4. APRENDIZAJE DE PARÁMETROS DEL MODELO Si se conoce el prior Φ, encontrar el óptimo wm es sencillo: se trata de una <br>regresión lineal</br> simple. Por lo tanto, nos enfocaremos en estimar Φ. La solución a priori máxima de Φ se da por ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Encontrar la solución óptima para el problema anterior es desafiante, ya que necesitamos integrar sobre todos los w = (w1, w2, ..., wM), que son variables ocultas no observadas. 4.1 Algoritmo EM para Modelos Lineales Jerárquicos Bayesianos En la Ecuación 5, Φ es el parámetro que necesita ser estimado, y el resultado depende de las variables latentes no observadas w. Este tipo de problema de optimización suele resolverse mediante el algoritmo EM. Aplicando EM al problema anterior, el conjunto de modelos de usuario w son las variables ocultas no observables y tenemos: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw. Basándonos en la derivación de las fórmulas EM presentadas en [24], tenemos los siguientes pasos de Expectation-Maximization para encontrar los hiperparámetros óptimos. Por razones de espacio, omitimos la derivación en este artículo ya que no es el enfoque de nuestro trabajo. Paso E: Para cada usuario m, estime la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual del prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) donde Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j Paso M: Optimice el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Muchos sistemas de IR impulsados por aprendizaje automático utilizan una estimación puntual de los parámetros en diferentes etapas del sistema. Sin embargo, estamos estimando la distribución posterior de las variables en el paso E. Esto evita el sobreajuste de wm a los datos de un usuario en particular, que pueden ser pequeños y ruidosos. Una discusión detallada sobre este tema aparece en [10]. 4.2 Nuevo Algoritmo: EM Modificado. Aunque el algoritmo EM es ampliamente estudiado y utilizado en aplicaciones de aprendizaje automático, utilizar el proceso EM mencionado anteriormente para resolver modelos lineales jerárquicos bayesianos en sistemas de recuperación de información a gran escala sigue siendo demasiado costoso computacionalmente. En esta sección, describimos por qué la tasa de aprendizaje del algoritmo EM es lenta en nuestra aplicación e introducimos una nueva técnica para hacer que el aprendizaje del modelo lineal jerárquico bayesiano sea escalable. La derivación del nuevo algoritmo de aprendizaje estará basada en el algoritmo EM descrito en la sección anterior. Primero, las matrices de covarianza Σ2 , Σ2 m suelen ser demasiado grandes para ser computacionalmente factibles. Por simplicidad, y como práctica común en IR, no modelamos la correlación entre características. Así aproximamos estas matrices con matrices diagonales de dimensión K. En el resto del documento, utilizamos estos símbolos para representar sus aproximaciones diagonales: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     En segundo lugar, y lo más importante, el espacio de entrada es muy disperso y hay muchas dimensiones que no están relacionadas con un usuario particular en una aplicación de recuperación de información real. Por ejemplo, consideremos un sistema de recomendación de películas, con la variable de entrada x representando una película en particular. Para la j-ésima película que el usuario m ha visto, sea xm,j,k = 1 si el director de la película es Jean-Pierre Jeunet (indexado por k). Aquí asumimos que si este director dirigió una película específica está representado por la k-ésima dimensión. Si el usuario m nunca ha visto una película dirigida por Jean-Pierre Jeunet, entonces la dimensión correspondiente siempre es cero (xm,j,k = 0 para todos los j). Una desventaja importante del algoritmo EM es que la importancia de una característica, µk, puede estar fuertemente dominada por usuarios que nunca han encontrado esta característica (es decir, j xm,j,k = 0) en el paso M (Ecuación 8). Suponga que 100 de cada 1 millón de usuarios han visto la película dirigida por Jean-Pierre Jeunet, y que los espectadores han calificado todas sus películas como excelentes. Intuitivamente, él es un buen director y el peso para él (µk) debería ser alto. Antes de la iteración de EM, el valor inicial de µ suele establecerse en 0. Dado que los otros 999,900 usuarios no han visto esta película, sus pesos correspondientes (w1,k, w2,k, ..., wm,k..., w999900,k) para ese director serían muy pequeños inicialmente. Por lo tanto, el peso correspondiente del director en el µk anterior en el primer paso M sería muy bajo, y la varianza σm,k será grande (Ecuaciones 8 y 7). Es indeseable que los usuarios que nunca han visto ninguna película producida por el director influyan tanto en la importancia del director. Esto hace que la convergencia del algoritmo EM estándar sea muy lenta. Ahora veamos si podemos mejorar la velocidad de aprendizaje del algoritmo. Sin pérdida de generalidad, asumamos que la k-ésima dimensión de la variable de entrada x no está relacionada con un usuario particular m. Lo que queremos decir es que xm,j,k = 0 para todo j = 1, ..., Jm. Es sencillo demostrar que la k-ésima fila y la k-ésima columna de Sxx,m están completamente llenas de ceros, y que la k-ésima dimensión de Sxy,m también se anula. Por lo tanto, la dimensión k correspondiente de la media de los modelos de usuario, ¯wm, debería ser igual a la del anterior: ¯wm,k = µk, con la covarianza correspondiente de σm,k = σk. En el paso M, el algoritmo EM estándar utiliza la solución numérica de la distribución P(wm|Dm, Φ) estimada en el paso E (Ecuación 8 y Ecuación 7). Sin embargo, las soluciones numéricas son muy poco confiables para ¯wm,k y σm,k cuando la k-ésima dimensión no está relacionada con el m-ésimo usuario. Un enfoque mejor es utilizar las soluciones analíticas ¯wm,k = µk, y σm,k = σk para los pares no relacionados (m, k), junto con la solución numérica estimada en el paso E para los otros pares (m, k). Así obtenemos el siguiente nuevo algoritmo EM similar: Paso E modificado: Para cada usuario m, estimar la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual de σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) donde sxx,m,k = j x2 m,j,k y sxy,m,k = j xm,j,kym,j Paso M modificado Optimizar el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E para pares de usuario-característica relacionados. El paso M utiliza implícitamente la solución analítica para pares de usuario-característica no relacionados. µk = 1 Mk m:relacionado ¯wm,k (12) σ2 k = 1 Mk m:relacionado σ2 m,k + ( ¯wm,k − µk)( ¯wm,k − µk)T (13) donde Mk es el número de usuarios relacionados con la característica k. Solo estimamos la diagonal de Σ2 m y Σ, ya que estamos utilizando la aproximación diagonal de las matrices de covarianza. Para estimar ¯wm, solo necesitamos calcular las soluciones numéricas para las dimensiones que están relacionadas con el usuario m. Para estimar σ2 k y µk, solo sumamos sobre los usuarios que están relacionados con la k-ésima característica. Hay dos beneficios principales del nuevo algoritmo. Primero, dado que solo se necesitan los pares relacionados (m, k) en el paso M modificado, la complejidad computacional en una sola iteración de EM es mucho menor cuando los datos son dispersos y muchos de los pares (m, k) no están relacionados. En segundo lugar, los parámetros estimados en el paso M modificado (Ecuaciones 12 - 13) son más precisos que el paso M estándar descrito en la Sección 4.1 porque se utilizaron soluciones analíticas exactas ¯wm,k = µk y σm,k = σk para los pares no relacionados (m, k) en el nuevo algoritmo en lugar de una solución aproximada como en el algoritmo estándar. METODOLOGÍA EXPERIMENTAL 5.1 Conjunto de Datos de Evaluación Para evaluar la técnica propuesta, utilizamos los siguientes tres conjuntos de datos principales (Tabla 1): Datos de MovieLens: Este conjunto de datos fue creado combinando las valoraciones de relevancia del conjunto de datos de MovieLens[9] con documentos de la Base de Datos de Películas en Internet (IMDB). MovieLens permite a los usuarios clasificar cuánto disfrutaron una película específica en una escala del 1 al 5. Esta calificación de simpatía se utilizó como una medida de cuán relevante es el documento que representa la película correspondiente para el usuario. Consideramos los documentos con puntuaciones de 4 o 5 como relevantes, y los documentos con una puntuación de 1 a 3 como irrelevantes para el usuario. MovieLens proporcionó juicios de relevancia sobre 3,057 documentos de 6,040 usuarios diferentes. En promedio, cada usuario calificó 151 películas, de las cuales 87 fueron consideradas relevantes. La puntuación promedio para un documento fue de 3.58. Los documentos que representan cada película fueron construidos a partir de la porción de la base de datos de IMDB que está disponible para descarga pública[13]. Basándonos en esta base de datos, creamos un documento por película que contenía la información relevante sobre ella (por ejemplo, directores, actores, etc.). Tabla 1: Estadísticas del conjunto de datos. En Reuters, el número de calificaciones para un usuario simulado es el número de documentos relevantes para el tema correspondiente. Datos Usuarios Documentos Calificaciones por Usuario MovieLens 6,040 3,057 151 Netflix-todos 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Datos de Netflix: Este conjunto de datos fue construido combinando documentos sobre películas obtenidos de la web con un conjunto de juicios de relevancia de clientes reales de alquiler de películas de Netflix[19]. Netflix proporciona públicamente las evaluaciones de relevancia de 480,189 clientes anónimos. Hay alrededor de 100 millones de calificaciones en una escala del 1 al 5 para 17,770 documentos. Similar a MovieLens, consideramos documentos con puntuaciones de 4 o 5 de agradabilidad como relevantes. Este número se redujo a 1000 clientes mediante muestreo aleatorio. El cliente promedio en el conjunto de datos reducido proporcionó 127 juicios, de los cuales 70 fueron considerados relevantes. La puntuación promedio de los documentos es de 3.55. Datos de Reuters: Este es el Corpus de Reuters, Volumen 1. Cubre 810,000 noticias en inglés de Reuters desde el 20 de agosto de 1996 hasta el 19 de agosto de 1997. Solo se utilizaron las primeras 100,000 noticias en nuestros experimentos. El corpus de Reuters viene con una jerarquía de temas. Cada documento se asigna a una de varias ubicaciones en el árbol jerárquico. El primer nivel del árbol contiene cuatro temas, denotados como C, E, M y G. Para los experimentos en este artículo, el árbol fue cortado en el nivel 1 para crear cuatro árboles más pequeños, cada uno de los cuales corresponde a un conjunto de datos más pequeño: Reuters-E, Reuters-C, Reuters-M y Reuters-G. Para cada conjunto de datos pequeño, creamos varios perfiles, un perfil para cada nodo en un subárbol, para simular múltiples usuarios, cada uno con una definición de relevancia relacionada pero separada. Todos los perfiles de usuario en una sub-rama se supone que comparten la misma distribución de modelo previo. Dado que este corpus indica explícitamente solo los documentos relevantes para un tema (usuario), todos los demás documentos se consideran irrelevantes. 5.2 Evaluación Diseñamos los experimentos para responder a las siguientes tres preguntas: 1. ¿Necesitamos hacer el esfuerzo de utilizar un enfoque bayesiano y aprender una distribución a priori de otros usuarios? 2. ¿El nuevo algoritmo funciona mejor que el algoritmo EM estándar para aprender el modelo lineal jerárquico bayesiano? 3. ¿Puede el nuevo algoritmo aprender rápidamente muchos modelos de usuario? Para responder a la primera pregunta, comparamos los modelos jerárquicos bayesianos con los modelos de <br>regresión lineal</br> regularizados Norm-2 comúnmente utilizados. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "collaborative filtering": {
            "translated_key": "filtrado colaborativo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
                "A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model.",
                "Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive.",
                "The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications.",
                "This paper proposes a new fast learning technique to learn a large number of individual user profiles.",
                "The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens.",
                "Categories and Subject Descriptors: B.3.3 [Information Search and Retrieval]: Information filtering General Terms: Algorithms 1.",
                "INTRODUCTION Personalization is the future of the Web, and it has achieved great success in industrial applications.",
                "For example, online stores, such as Amazon and Netflix, provide customized recommendations for additional products or services based on a users history.",
                "Recent offerings such as My MSN, My Yahoo!, My Google, and Google News have attracted much attention due to their potential ability to infer a users interests from his/her history.",
                "One major personalization topic studied in the information retrieval community is content-based personal recommendation systems1 .",
                "These systems learn user-specific profiles from user feedback so that they can recommend information tailored to each individual users interest without requiring the user to make an explicit query.",
                "Learning the user profiles is the core problem for these systems.",
                "A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user.",
                "One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small.",
                "This is known as the cold start problem.",
                "This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile.",
                "There has been much research on improving classification accuracy when the amount of labeled training data is small.",
                "The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal [26].",
                "Another approach is using domain knowledge.",
                "Researchers have modified different learning algorithms, such as Na¨ıveBayes [17], logistic regression [7], and SVMs [22], to integrate domain knowledge into a text classifier.",
                "The third approach is borrowing training data from other resources [5][7].",
                "The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data.",
                "One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach.",
                "Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial performance for each user[27][25].",
                "In order to learn a Bayesian hierarchical model, the system usually tries to find the most likely model parameters for the given data.",
                "A mature recommendation system usually works for millions of users.",
                "It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users.",
                "The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee.",
                "However, a content based recommendation system often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector.",
                "With careful analysis of the EM algorithm in this scenario (Section 4), we find that the EM tering, or item-based <br>collaborative filtering</br>.",
                "In this paper, the words filtering and recommendation are used interchangeably. algorithm converges very slowly due to the sparseness of the input variables.",
                "We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O(MK), where M is the number of users and K is the number of dimensions.",
                "This paper modifies the standard EM algorithm to create an improved learning algorithm, which we call the Modified EM algorithm.",
                "The basic idea is that instead of calculating the numerical solution for all the user profile parameters, we derive the analytical solution of the parameters for some feature dimensions, and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters.",
                "This greatly reduces the computation at a single EM iteration, and also has the benefit of increasing the convergence speed of the learning algorithm.",
                "The proposed technique is not only well supported by theory, but also by experimental results.",
                "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression modeling framework used for content-based recommendations.",
                "Section 4 describes how to learn the model parameters using the standard EM algorithm, along with using the new technique proposed in this paper.",
                "The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6.",
                "Section 7 summarizes and offers concluding remarks. 2.",
                "RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the IR community since the 1970s.",
                "The approaches that have been used to solve this problem can be roughly classified into two major categories: content based filtering versus <br>collaborative filtering</br>.",
                "Content-based filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user.",
                "The user may read the delivered documents and provide explicit relevance feedback, which the filtering system then uses to update the users profile using relevance feedback retrieval models (e.g.",
                "Boolean models, vector space models, traditional probabilistic models [20] , inference networks [3] and language models [6]) or machine learning algorithms (e.g.",
                "Support Vector Machines (SVM), K nearest neighbors (K-NN) clustering, neural networks, logistic regression, or Winnow [16] [4] [23]).",
                "<br>collaborative filtering</br> goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past.",
                "Memorybased heuristics and model based approaches have been used in <br>collaborative filtering</br> task [15] [8] [2] [14] [12] [11].",
                "This paper contributes to the content-based recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks[27][25].",
                "This paper does not intend to compare content-based filtering with <br>collaborative filtering</br> or claim which one is a better.",
                "We think each complements the other, and that content-based filtering is extremely useful for handling new documents/items with little or no user feedback.",
                "Similar to some other researchers[18][1][21], we found that a recommendation system will be more effective when both techniques are combined.",
                "However, this is beyond the scope of this paper and thus not discussed here. 3.",
                "BAYESIAN HIERARCHICAL LINEAR REGRESSION Assume there are M users in the system.",
                "The task of the system is to recommend documents that are relevant to each user.",
                "For each user, the system learns a user model from the users history.",
                "In the rest of this paper, we will use the following notations to represent the variables in the system. m = 1, 2, ..., M: The index for each individual user.",
                "M is the total number of users. wm: The user model parameter associated with user m. wm is a K dimensional vector. j = 1, 2, ..., Jm: The index for a set of data for user m. Jm is the number of training data for user m. Dm = {(xm,j, ym,j)}: A set of data associated with user m. xm,j is a K dimensional vector that represents the mth users jth training document.2 ym,j is a scalar that represents the label of document xm,j. k = 1, 2, ..., K: The dimensional index of input variable x.",
                "The Bayesian hierarchical modeling approach has been widely used in real-world information retrieval applications.",
                "Generalized Bayesian hierarchical linear models, one of the simplest Bayesian hierarchical models, are commonly used and have achieved good performance on <br>collaborative filtering</br> [25] and content-based adaptive filtering [27] tasks.",
                "Figure 1 shows the graphical representation of a Bayesian hierarchical model.",
                "In this graph, each user model is represented by a random vector wm.",
                "We assume a user model is sampled randomly from a prior distribution P(w|Φ).",
                "The system can predict the user label y of a document x given an estimation of wm (or wms distribution) using a function y = f(x, w).",
                "The model is called generalized Bayesian hierarchical linear model when y = f(wT x) is any generalized linear model such as logistic regression, SVM, and linear regression.",
                "To reliably estimate the user model wm, the system can borrow information from other users through the prior Φ = (µ, Σ).",
                "Now we look at one commonly used model where y = wT x + , where ∼ N(0, σ2 ) is a random noise [25][27].",
                "Assume that each user model wm is an independent draw from a population distribution P(w|Φ), which is governed by some unknown hyperparameter Φ.",
                "Let the prior distribution of user model w be a Gaussian distribution with parameter Φ = (µ, Σ), which is the commonly used prior for linear models. µ = (µ1, µ2, ..., µK ) is a K dimensional vector that represents the mean of the Gaussian distribution, and Σ is the covariance matrix of the Gaussian.",
                "Usually, a Normal distribution N(0, aI) and an Inverse Wishart distribution P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) are used as hyperprior to model the prior distribution of µ and Σ respectively.",
                "I is the K dimensional identity matrix, and a, b, and c are real numbers.",
                "With these settings, we have the following model for the system: 1. µ and Σ are sampled from N(0, aI) and IWν (aI), respectively. 2 The first dimension of x is a dummy variable that always equals to 1.",
                "Figure 1: Illustration of dependencies of variables in the hierarchical model.",
                "The rating, y, for a document, x, is conditioned on the document and the user model, wm, associated with the user m. Users share information about their models through the prior, Φ = (µ, Σ). 2.",
                "For each user m, wm is sampled randomly from a Normal distribution: wm ∼ N(µ, Σ2 ) 3.",
                "For each item xm,j, ym,j is sampled randomly from a Normal distribution: ym,j ∼ N(wT mxm,j, σ2 ).",
                "Let θ = (Φ, w1, w2, ..., wM ) represent the parameters of this system that needs to be estimated.",
                "The joint likelihood for all the variables in the probabilistic model, which includes the data and the parameters, is: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) For simplicity, we assume a, b, c, and σ are provided to the system. 4.",
                "MODEL PARAMETER LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple linear regression.",
                "Therefore, we will focus on estimating Φ.",
                "The maximum a priori solution of Φ is given by ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Finding the optimal solution for the above problem is challenging, since we need to integrate over all w = (w1, w2, ..., wM ), which are unobserved hidden variables. 4.1 EM Algorithm for Bayesian Hierarchical Linear Models In Equation 5, Φ is the parameter needs to be estimated, and the result depends on unobserved latent variables w. This kind of optimization problem is usually solved by the EM algorithm.",
                "Applying EM to the above problem, the set of user models w are the unobservable hidden variables and we have: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw Based on the derivation of the EM formulas presented in [24], we have the following Expectation-Maximization steps for finding the optimal hyperparameters.",
                "For space considerations, we omit the derivation in this paper since it is not the focus of our work.",
                "E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of the prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) where Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j M step: Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Many machine learning driven IR systems use a point estimate of the parameters at different stages in the system.",
                "However, we are estimating the posterior distribution of the variables at the E step.",
                "This avoids overfitting wm to a particular users data, which may be small and noisy.",
                "A detailed discussion about this subject appears in [10]. 4.2 New Algorithm: Modified EM Although the EM algorithm is widely studied and used in machine learning applications, using the above EM process to solve Bayesian hierarchical linear models in large-scale information retrieval systems is still too computationally expensive.",
                "In this section, we describe why the learning rate of the EM algorithm is slow in our application and introduce a new technique to make the learning of the Bayesian hierarchical linear model scalable.",
                "The derivation of the new learning algorithm will be based on the EM algorithm described in the previous section.",
                "First, the covariance matrices Σ2 , Σ2 m are usually too large to be computationally feasible.",
                "For simplicity, and as a common practice in IR, we do not model the correlation between features.",
                "Thus we approximate these matrices with K dimensional diagonal matrices.",
                "In the rest of the paper, we use these symbols to represent their diagonal approximations: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     Secondly, and most importantly, the input space is very sparse and there are many dimensions that are not related to a particular user in a real IR application.",
                "For example, let us consider a movie recommendation system, with the input variable x representing a particular movie.",
                "For the jth movie that the user m has seen, let xm,j,k = 1 if the director of the movie is Jean-Pierre Jeunet (indexed by k).",
                "Here we assume that whether or not that this director directed a specific movie is represented by the kth dimension.",
                "If the user m has never seen a movie directed by Jean-Pierre Jeunet, then the corresponding dimension is always zero (xm,j,k = 0 for all j) .",
                "One major drawback of the EM algorithm is that the importance of a feature, µk, may be greatly dominated by users who have never encountered this feature (i.e. j xm,j,k = 0) at the M step (Equation 8).",
                "Assume that 100 out of 1 million users have viewed the movie directed by Jean-Pierre Jeunet, and that the viewers have rated all of his movies as excellent.",
                "Intuitively, he is a good director and the weight for him (µk) should be high.",
                "Before the EM iteration, the initial value of µ is usually set to 0.",
                "Since the other 999,900 users have not seen this movie, their corresponding weights (w1,k, w2,k, ..., wm,k..., w999900,k) for that director would be very small initially.",
                "Thus the corresponding weight of the director in the prior µk at the first M step would be very low , and the variance σm,k will be large (Equations 8 and 7).",
                "It is undesirable that users who have never seen any movie produced by the director influence the importance of the director so much.",
                "This makes the convergence of the standard EM algorithm very slow.",
                "Now lets look at whether we can improve the learning speed of the algorithm.",
                "Without a loss of generality, let us assume that the kth dimension of the input variable x is not related to a particular user m. By which we mean, xm,j,k = 0 for all j = 1, ..., Jm.",
                "It is straightforward to prove that the kth row and kth column of Sxx,m are completely filled with zeros, and that the kth dimension of Sxy,m is zeroed as well.",
                "Thus the corresponding kth dimension of the user models mean, ¯wm, should be equal to that of the prior: ¯wm,k = µk, with the corresponding covariance of σm,k = σk.",
                "At the M step, the standard EM algorithm uses the numerical solution of the distribution P(wm|Dm, Φ) estimated at E step (Equation 8 and Equation 7).",
                "However, the numerical solutions are very unreliable for ¯wm,k and σm,k when the kth dimension is not related to the mth user.",
                "A better approach is using the analytical solutions ¯wm,k = µk, and σm,k = σk for the unrelated (m, k) pairs, along with the numerical solution estimated at E step for the other (m, k) pairs.",
                "Thus we get the following new EM-like algorithm: Modified E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) where sxx,m,k = j x2 m,j,k and sxy,m,k = j xm,j,kym,j Modified M Step Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step for related userfeature pairs.",
                "The M step implicitly uses the analytical solution for unrelated user-feature pairs. µk = 1 Mk m:related ¯wm,k (12) σ2 k = 1 Mk m:related σ2 m,k +( ¯wm,k − µk)( ¯wm,k − µk)T (13) where Mk is the number of users that are related to feature k We only estimate the diagonal of Σ2 m and Σ since we are using the diagonal approximation of the covariance matrices.",
                "To estimate ¯wm, we only need to calculate the numerical solutions for dimensions that are related to user m. To estimate σ2 k and µk, we only sum over users that are related to the kth feature.",
                "There are two major benefits of the new algorithm.",
                "First, because only the related (m, k) pairs are needed at the modified M step, the computational complexity in a single EM iteration is much smaller when the data is sparse, and many of (m, k) pairs are unrelated.",
                "Second, the parameters estimated at the modified M step (Equations 12 - 13) are more accurate than the standard M step described in Section 4.1 because the exact analytical solutions ¯wm,k = µk and σm,k = σk for the unrelated (m, k) pairs were used in the new algorithm instead of an approximate solution as in the standard algorithm. 5.",
                "EXPERIMENTAL METHODOLOGY 5.1 Evaluation Data Set To evaluate the proposed technique, we used the following three major data sets (Table 1): MovieLens Data: This data set was created by combining the relevance judgments from the MovieLens[9] data set with documents from the Internet Movie Database (IMDB).",
                "MovieLens allows users to rank how much he/she enjoyed a specific movie on a scale from 1 to 5.",
                "This likeability rating was used as a measurement of how relevant the document representing the corresponding movie is to the user.",
                "We considered documents with likeability scores of 4 or 5 as relevant, and documents with a score of 1 to 3 as irrelevant to the user.",
                "MovieLens provided relevance judgments on 3,057 documents from 6,040 separate users.",
                "On average, each user rated 151 movies, of these 87 were judged to be relevant.",
                "The average score for a document was 3.58.",
                "Documents representing each movie were constructed from the portion of the IMDB database that is available for public download[13].",
                "Based on this database, we created one document per movie that contained the relevant information about it (e.g. directors, actors, etc.).",
                "Table 1: Data Set Statistics.",
                "On Reuters, the number of rating for a simulated user is the number of documents relevant to the corresponding topic.",
                "Data Users Docs Ratings per User MovieLens 6,040 3,057 151 Netflix-all 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Netflix Data: This data set was constructed by combining documents about movies crawled from the web with a set of actual movie rental customer relevance judgments from Netflix[19].",
                "Netflix publicly provides the relevance judgments of 480,189 anonymous customers.",
                "There are around 100 million rating on a scale of 1 to 5 for 17,770 documents.",
                "Similar to MovieLens, we considered documents with likeability scores of 4 or 5 as relevant.",
                "This number was reduced to 1000 customers through random sampling.",
                "The average customer on the reduced data set provided 127 judgments, with 70 being deemed relevant.",
                "The average score for documents is 3.55.",
                "Reuters Data: This is the Reuters Corpus, Volume 1.",
                "It covers 810,000 Reuters English language news stories from August 20, 1996 to August 19, 1997.",
                "Only the first 100,000 news were used in our experiments.",
                "The Reuters corpus comes with a topic hierarchy.",
                "Each document is assigned to one of several locations on the hierarchical tree.",
                "The first level of the tree contains four topics, denoted as C, E, M, and G. For the experiments in this paper, the tree was cut at level 1 to create four smaller trees, each of which corresponds to one smaller data set: Reuters-E Reuters-C, ReutersM and Reuters-G. For each small data set, we created several profiles, one profile for each node in a sub-tree, to simulate multiple users, each with a related, yet separate definition of relevance.",
                "All the user profiles on a sub-tree are supposed to share the same prior model distribution.",
                "Since this corpus explicitly indicates only the relevant documents for a topic(user), all other documents are considered irrelevant. 5.2 Evaluation We designed the experiments to answer the following three questions: 1.",
                "Do we need to take the effort to use a Bayesian approach and learn a prior from other users? 2.",
                "Does the new algorithm work better than the standard EM algorithm for learning the Bayesian hierarchical linear model? 3.",
                "Can the new algorithm quickly learn many user models?",
                "To answer the first question, we compared the Bayesian hierarchical models with commonly used Norm-2 regularized linear regression models.",
                "In fact, the commonly used approach is equivalent to the model learned at the end of the first EM iteration.",
                "To answer the second question, we compared the proposed new algorithm with the standard EM algorithm to see whether the new learning algorithm is better.",
                "To answer the third question, we tested the efficiency of the new algorithm on the entire Netflix data set where about half a million user models need to be learned together.",
                "For the MovieLens and Netflix data sets, algorithm effectiveness was measured by mean square error, while on the Reuters data set classification error was used because it was more informative.",
                "We first evaluated the performance on each individual user, and then estimated the macro average over all users.",
                "Statistical tests (t-tests) were carried out to see whether the results are significant.",
                "For the experiments on the MovieLens and Netflix data sets, we used a random sample of 90% of each user for training, and the rest for testing.",
                "On Reuters data set, because there are too many relevant documents for each topic in the corpus, we used a random sample of 10% of each topic for training, and 10% of the remaining documents for testing.",
                "For all runs, we set (a, b, c, Σ ) = (0.1, 10, 0.1, 1) manually. 6.",
                "EXPERIMENTAL RESULTS Figure 2, Figure 3, and Figure 4 show that on all data sets, the Bayesian hierarchical modeling approach has a statistical significant improvement over the regularized linear regression model, which is equivalent to the Bayesian hierarchical models learned at the first iteration.",
                "Further analysis shows a negative correlation between the number of training data for a user and the improvement the system gets.",
                "This suggests that the borrowing information from other users has more significant improvements for users with less training data, which is as expected.",
                "However, the strength of the correlation differs over data sets, and the amount of training data is not the only characteristics that will influence the final performance.",
                "Figure 2 and Figure 3 show that the proposed new algorithm works better than the standard EM algorithm on the Netflix and MovieLens data sets.",
                "This is not surprising since the number of related feature-users pairs is much smaller than the number of unrelated feature-user pairs on these two data sets, and thus the proposed new algorithm is expected to work better.",
                "Figure 4 shows that the two algorithms work similarly on the Reuters-E data set.",
                "The accuracy of the new algorithm is similar to that of the standard EM algorithm at each iteration.",
                "The general patterns are very similar on other Reuters subsets.",
                "Further analysis shows that only 58% of the user-feature pairs are unrelated on this data set.",
                "Since the number of unrelated user-feature pairs is not extremely large, the sparseness is not a serious problem on the Reuters data set.",
                "Thus the two learning algorithms perform similarly.",
                "The results suggest that only on a corpus where the number of unrelated user-feature pairs is much larger than the number of related pairs, such as on the Netflix data set, the proposed technique will get a significant improvement over standard EM.",
                "However, the experiments also show that when the assumption does not hold, the new algorithm does not hurt performance.",
                "Although the proposed technique is faster than standard Figure 2: Performance on a Netflix subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iterations 2 - 10.",
                "Norm-2 regularized linear models are equivalent to the Bayesian hierarchical models learned at the first iteration, and are statistical significantly worse than the Bayesian hierarchical models. 0 2 4 6 8 10 1 1.05 1.1 1.15 1.2 1.25 1.3 1.35 1.4 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iterations ClassificationError New Algorithm Traditional EM Figure 3: Performance on a MovieLens subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iteration 2 to 17 (evaluated with mean square error). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iterations MeanSquareError New Algorithm Traditional EM 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iterations ClassificationError New Algorithm Traditional EM Figure 4: Performance on a Reuters-E subset with 26 profiles.",
                "Performances on Reuters-C, Reuters-M, Reuters-G are similar. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iterations ClassificationError New Algorithm Traditional EM EM, can it really learn millions of user models quickly?",
                "Our results show that the modified EM algorithm converges quickly, and 2 - 3 modified EM iterations would result in a reliable estimation.",
                "We evaluated the algorithm on the whole Netflix data set (480,189 users, 159,836 features, and 100 million ratings) running on a single CPU PC (2GB memory, P4 3GHz).",
                "The system finished one modified EM iteration in about 4 hours.",
                "This demonstrates that the proposed technique can efficiently handle large-scale system like Netflix. 7.",
                "CONCLUSION Content-based user profile learning is an important problem and is the key to providing personal recommendations to a user, especially for recommending new items with a small number of ratings.",
                "The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors.",
                "This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM.",
                "We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm.",
                "Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse, by which we mean the ratio of related user-feature pairs to unrelated pairs is small.",
                "Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold.",
                "In general, it is better to use the new algorithm since it is as simple as standard EM, the performance is either better or similar to EM, and the computation complexity is lower at each iteration.",
                "It is worth mentioning that even if the original problem space is not sparse, sparseness can be created artificially when a recommendation system uses user-specific feature selection techniques to reduce the noise and user model complexity.",
                "The proposed technique can also be adapted to improve the learning in such a scenario.",
                "We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU.",
                "The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear modeling approach to build a practical large scale system, even though the literature have demonstrated the effectiveness of the models in many applications.",
                "Our work is one major step on the road to make Bayesian hierarchical linear models more practical.",
                "The proposed new technique can be easily adapted to run on a cluster of machines, and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users.",
                "The research has much potential to benefit people using EM algorithm on many other IR problems as well as machine learning problems.",
                "EM algorithm is a commonly used machine learning technique.",
                "It is used to find model parameters in many IR problems where the training data is very sparse.",
                "Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering, the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems. 8.",
                "ACKNOWLEDGMENTS We thank Wei Xu, David Lewis and anonymous reviewers for valuable feedback on the work described in this paper.",
                "Part of the work was supported by Yahoo, Google, the Petascale Data Storage Institute and the Institute for Scalable Scientific Data Management.",
                "Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors, and do not necessarily reflect those of the sponsors. 9.",
                "REFERENCES [1] C. Basu, H. Hirsh, and W. Cohen.",
                "Recommendation as classification: Using social and content-based information in recommendation.",
                "In Proceedings of the Fifteenth National Conference on Artificial Intelligence, 1998. [2] J. S. Breese, D. Heckerman, and C. Kadie.",
                "Empirical analysis of predictive algorithms for <br>collaborative filtering</br>.",
                "Technical report, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan.",
                "Document filtering with inference networks.",
                "In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor, and A. Vinokourov.",
                "Kernel method for document filtering.",
                "In The Eleventh Text REtrieval Conference (TREC11).",
                "National Institute of Standards and Technology, special publication 500-249, 2003. [5] C. Chelba and A. Acero.",
                "Adaptation of maximum entropy capitalizer: Little data can help a lot.",
                "In D. Lin and D. Wu, editors, Proceedings of EMNLP 2004, pages 285-292, Barcelona, Spain, July 2004.",
                "Association for Computational Linguistics. [6] B. Croft and J. Lafferty, editors.",
                "Language Modeling for Information Retrieval.",
                "Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov, and A. Genkin.",
                "Constructing informative prior distributions from domain knowledge in text classification.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 493-500, New York, NY, USA, 2006.",
                "ACM Press. [8] J. Delgado and N. Ishii.",
                "Memory-based weightedmajority prediction for recommender systems.",
                "In ACM SIGIR99 Workshop on Recommender Systems, 1999. [9] GroupLens.",
                "Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman.",
                "A tutorial on learning with bayesian networks.",
                "In M. Jordan, editor, Learning in Graphical Models.",
                "Kluwer Academic, 1998. [11] J. L. Herlocker, J.",
                "A. Konstan, A. Borchers, and J. Riedl.",
                "An algorithmic framework for performing <br>collaborative filtering</br>.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 230-237, New York, NY, USA, 1999.",
                "ACM Press. [12] T. Hofmann and J. Puzicha.",
                "Latent class models for <br>collaborative filtering</br>.",
                "In IJCAI 99: Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 688-693, San Francisco, CA, USA, 1999.",
                "Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).",
                "Internet movie database. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai, and L. Si.",
                "An automatic weighting scheme for <br>collaborative filtering</br>.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 337-344, New York, NY, USA, 2004.",
                "ACM Press. [15] J.",
                "A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl.",
                "GroupLens: Applying <br>collaborative filtering</br> to Usenet news.",
                "Communications of the ACM, 40(3):77-87, 1997. [16] D. Lewis.",
                "Applying support vector machines to the TREC-2001 batch filtering and routing tasks.",
                "In Proceedings of the Eleventh Text REtrieval Conference (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee, , and P. Yu.",
                "Text classification by labeling words.",
                "In Proceedings of The Nineteenth National Conference on Artificial Intelligence (AAAI-2004), July 25-29, 2004. [18] P. Melville, R. J. Mooney, and R. Nagarajan.",
                "Content-boosted <br>collaborative filtering</br> for improved recommendations.",
                "In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002), Edmonton, Canada, 2002. [19] Netflix.",
                "Netflix prize. http://www.netflixprize.com (visited on Nov. 30, 2006), 2006. [20] S. Robertson and K. Sparck-Jones.",
                "Relevance weighting of search terms.",
                "In Journal of the American Society for Information Science, volume 27, pages 129-146, 1976. [21] J. Wang, A. P. de Vries, and M. J. T. Reinders.",
                "Unifying user-based and item-based <br>collaborative filtering</br> approaches by similarity fusion.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 501-508, New York, NY, USA, 2006.",
                "ACM Press. [22] X. Wu and R. K. Srihari.",
                "Incorporating prior knowledge with weighted margin support vector machines.",
                "In Proc.",
                "ACM Knowledge Discovery Data Mining Conf. (ACM SIGKDD 2004), Aug. 2004. [23] Y. Yang, S. Yoo, J. Zhang, and B. Kisiel.",
                "Robustness of adaptive filtering methods in a cross-benchmark evaluation.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2005. [24] K. Yu, V. Tresp, and A. Schwaighofer.",
                "Learning gaussian processes from multiple tasks.",
                "In ICML 05: Proceedings of the 22nd international conference on Machine learning, pages 1012-1019, New York, NY, USA, 2005.",
                "ACM Press. [25] K. Yu, V. Tresp, and S. Yu.",
                "A nonparametric hierarchical bayesian framework for information filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 353-360.",
                "ACM Press, 2004. [26] X. Zhu.",
                "Semi-supervised learning literature survey.",
                "Technical report, University of Wisconsin - Madison, December 9, 2006. [27] P. Zigoris and Y. Zhang.",
                "Bayesian adaptive user profiling with explicit & implicit feedback.",
                "In Conference on Information and Knowledge Mangement 2006, 2006."
            ],
            "original_annotated_samples": [
                "With careful analysis of the EM algorithm in this scenario (Section 4), we find that the EM tering, or item-based <br>collaborative filtering</br>.",
                "The approaches that have been used to solve this problem can be roughly classified into two major categories: content based filtering versus <br>collaborative filtering</br>.",
                "<br>collaborative filtering</br> goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past.",
                "Memorybased heuristics and model based approaches have been used in <br>collaborative filtering</br> task [15] [8] [2] [14] [12] [11].",
                "This paper does not intend to compare content-based filtering with <br>collaborative filtering</br> or claim which one is a better."
            ],
            "translated_annotated_samples": [
                "Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM tering, o <br>filtrado colaborativo</br> basado en elementos.",
                "Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus <br>filtrado colaborativo</br>.",
                "El <br>filtrado colaborativo</br> va más allá de simplemente usar el contenido de un documento para recomendar elementos a un usuario, aprovechando la información de otros usuarios con gustos y preferencias similares en el pasado.",
                "Se han utilizado heurísticas basadas en memoria y enfoques basados en modelos en la tarea de <br>filtrado colaborativo</br> [15] [8] [2] [14] [12] [11].",
                "Este artículo no tiene la intención de comparar el filtrado basado en contenido con el <br>filtrado colaborativo</br> ni de afirmar cuál es mejor."
            ],
            "translated_text": "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual. Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un modelo jerárquico bayesiano. Aprender los parámetros del modelo para optimizar la verosimilitud conjunta de los datos de millones de usuarios es muy costoso computacionalmente. El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de datos en aplicaciones de IR. Este documento propone una nueva técnica de aprendizaje rápido para aprender un gran número de perfiles de usuario individuales. La eficacia y eficiencia del algoritmo propuesto están justificadas por la teoría y demostradas en datos reales de usuarios de Netflix y MovieLens. Categorías y Descriptores de Asignaturas: B.3.3 [Búsqueda y Recuperación de Información]: Filtrado de información Términos Generales: Algoritmos 1. La personalización es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales. Por ejemplo, las tiendas en línea, como Amazon y Netflix, ofrecen recomendaciones personalizadas de productos o servicios adicionales basadas en el historial de un usuario. Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de un usuario a partir de su historial. Un tema importante de personalización estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados basados en el contenido. Estos sistemas aprenden perfiles específicos de usuario a partir de la retroalimentación del usuario para poder recomendar información adaptada a los intereses de cada usuario sin necesidad de que el usuario realice una consulta explícita. Aprender los perfiles de usuario es el problema central de estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica qué tan relevante es un documento para el usuario. Uno de los principales desafíos de construir un sistema de recomendación o personalización es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña. Esto se conoce como el problema de inicio en frío. Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente retroalimentación de ese usuario para aprender un perfil de usuario confiable. Se ha realizado mucha investigación sobre cómo mejorar la precisión de clasificación cuando la cantidad de datos de entrenamiento etiquetados es pequeña. El enfoque de aprendizaje semisupervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26]. Otro enfoque es utilizar el conocimiento del dominio. Los investigadores han modificado diferentes algoritmos de aprendizaje, como NaïveBayes [17], regresión logística [7] y SVMs [22], para integrar el conocimiento del dominio en un clasificador de texto. El tercer enfoque consiste en tomar datos de entrenamiento de otros recursos [5][7]. La efectividad de estos enfoques diferentes es mixta, debido a qué tan bien se ajusta la suposición del modelo subyacente a los datos. Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano. Varios investigadores han demostrado que este enfoque intercambia eficazmente entre la información compartida y la específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario[27][25]. Para aprender un modelo jerárquico bayesiano, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados. Un sistema de recomendación maduro generalmente funciona para millones de usuarios. Es bien sabido que aprender los parámetros óptimos de un modelo jerárquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios. El algoritmo EM es una técnica comúnmente utilizada para el aprendizaje de parámetros debido a su simplicidad y garantía de convergencia. Sin embargo, un sistema de recomendación basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso. Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM tering, o <br>filtrado colaborativo</br> basado en elementos. En este documento, las palabras filtrado y recomendación se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de las variables de entrada. También encontramos que actualizar el parámetro del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones. Este documento modifica el algoritmo EM estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos algoritmo EM modificado. La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M utilizamos la solución analítica en lugar de la solución numérica estimada en el paso E para esos parámetros. Esto reduce considerablemente la computación en una sola iteración de EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales. La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de regresión lineal jerárquica bayesiana utilizado para recomendaciones basadas en contenido. La sección 4 describe cómo aprender los parámetros del modelo utilizando el algoritmo EM estándar, junto con el uso de la nueva técnica propuesta en este artículo. La configuración experimental y los resultados utilizados para validar la técnica de aprendizaje propuesta se informan en las Secciones 5 y 6. La sección 7 resume y ofrece observaciones finales. 2. TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de IR desde la década de 1970. Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus <br>filtrado colaborativo</br>. El filtrado basado en contenido estudia el escenario en el que un sistema de recomendación monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente. El usuario puede leer los documentos entregados y proporcionar retroalimentación explícita de relevancia, la cual el sistema de filtrado utiliza para actualizar el perfil del usuario mediante modelos de recuperación de retroalimentación de relevancia (por ejemplo,). Modelos booleanos, modelos de espacio vectorial, modelos probabilísticos tradicionales [20], redes de inferencia [3] y modelos de lenguaje [6]) o algoritmos de aprendizaje automático (por ejemplo, Máquinas de Vectores de Soporte (SVM), agrupamiento de K vecinos más cercanos (K-NN), redes neuronales, regresión logística o Winnow [16] [4] [23]. El <br>filtrado colaborativo</br> va más allá de simplemente usar el contenido de un documento para recomendar elementos a un usuario, aprovechando la información de otros usuarios con gustos y preferencias similares en el pasado. Se han utilizado heurísticas basadas en memoria y enfoques basados en modelos en la tarea de <br>filtrado colaborativo</br> [15] [8] [2] [14] [12] [11]. Este artículo contribuye a la investigación de recomendaciones basadas en contenido al mejorar la eficiencia y efectividad de los modelos lineales jerárquicos bayesianos, los cuales tienen una sólida base teórica y un buen rendimiento empírico en tareas de recomendación[27][25]. Este artículo no tiene la intención de comparar el filtrado basado en contenido con el <br>filtrado colaborativo</br> ni de afirmar cuál es mejor. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "parameter": {
            "translated_key": "parámetro",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
                "A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model.",
                "Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive.",
                "The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications.",
                "This paper proposes a new fast learning technique to learn a large number of individual user profiles.",
                "The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens.",
                "Categories and Subject Descriptors: B.3.3 [Information Search and Retrieval]: Information filtering General Terms: Algorithms 1.",
                "INTRODUCTION Personalization is the future of the Web, and it has achieved great success in industrial applications.",
                "For example, online stores, such as Amazon and Netflix, provide customized recommendations for additional products or services based on a users history.",
                "Recent offerings such as My MSN, My Yahoo!, My Google, and Google News have attracted much attention due to their potential ability to infer a users interests from his/her history.",
                "One major personalization topic studied in the information retrieval community is content-based personal recommendation systems1 .",
                "These systems learn user-specific profiles from user feedback so that they can recommend information tailored to each individual users interest without requiring the user to make an explicit query.",
                "Learning the user profiles is the core problem for these systems.",
                "A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user.",
                "One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small.",
                "This is known as the cold start problem.",
                "This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile.",
                "There has been much research on improving classification accuracy when the amount of labeled training data is small.",
                "The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal [26].",
                "Another approach is using domain knowledge.",
                "Researchers have modified different learning algorithms, such as Na¨ıveBayes [17], logistic regression [7], and SVMs [22], to integrate domain knowledge into a text classifier.",
                "The third approach is borrowing training data from other resources [5][7].",
                "The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data.",
                "One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach.",
                "Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial performance for each user[27][25].",
                "In order to learn a Bayesian hierarchical model, the system usually tries to find the most likely model parameters for the given data.",
                "A mature recommendation system usually works for millions of users.",
                "It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users.",
                "The EM algorithm is a commonly used technique for <br>parameter</br> learning due to its simplicity and convergence guarantee.",
                "However, a content based recommendation system often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector.",
                "With careful analysis of the EM algorithm in this scenario (Section 4), we find that the EM tering, or item-based collaborative filtering.",
                "In this paper, the words filtering and recommendation are used interchangeably. algorithm converges very slowly due to the sparseness of the input variables.",
                "We also find that updating the model <br>parameter</br> at each EM iteration is also expensive with computational complexity of O(MK), where M is the number of users and K is the number of dimensions.",
                "This paper modifies the standard EM algorithm to create an improved learning algorithm, which we call the Modified EM algorithm.",
                "The basic idea is that instead of calculating the numerical solution for all the user profile parameters, we derive the analytical solution of the parameters for some feature dimensions, and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters.",
                "This greatly reduces the computation at a single EM iteration, and also has the benefit of increasing the convergence speed of the learning algorithm.",
                "The proposed technique is not only well supported by theory, but also by experimental results.",
                "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression modeling framework used for content-based recommendations.",
                "Section 4 describes how to learn the model parameters using the standard EM algorithm, along with using the new technique proposed in this paper.",
                "The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6.",
                "Section 7 summarizes and offers concluding remarks. 2.",
                "RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the IR community since the 1970s.",
                "The approaches that have been used to solve this problem can be roughly classified into two major categories: content based filtering versus collaborative filtering.",
                "Content-based filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user.",
                "The user may read the delivered documents and provide explicit relevance feedback, which the filtering system then uses to update the users profile using relevance feedback retrieval models (e.g.",
                "Boolean models, vector space models, traditional probabilistic models [20] , inference networks [3] and language models [6]) or machine learning algorithms (e.g.",
                "Support Vector Machines (SVM), K nearest neighbors (K-NN) clustering, neural networks, logistic regression, or Winnow [16] [4] [23]).",
                "Collaborative filtering goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past.",
                "Memorybased heuristics and model based approaches have been used in collaborative filtering task [15] [8] [2] [14] [12] [11].",
                "This paper contributes to the content-based recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks[27][25].",
                "This paper does not intend to compare content-based filtering with collaborative filtering or claim which one is a better.",
                "We think each complements the other, and that content-based filtering is extremely useful for handling new documents/items with little or no user feedback.",
                "Similar to some other researchers[18][1][21], we found that a recommendation system will be more effective when both techniques are combined.",
                "However, this is beyond the scope of this paper and thus not discussed here. 3.",
                "BAYESIAN HIERARCHICAL LINEAR REGRESSION Assume there are M users in the system.",
                "The task of the system is to recommend documents that are relevant to each user.",
                "For each user, the system learns a user model from the users history.",
                "In the rest of this paper, we will use the following notations to represent the variables in the system. m = 1, 2, ..., M: The index for each individual user.",
                "M is the total number of users. wm: The user model <br>parameter</br> associated with user m. wm is a K dimensional vector. j = 1, 2, ..., Jm: The index for a set of data for user m. Jm is the number of training data for user m. Dm = {(xm,j, ym,j)}: A set of data associated with user m. xm,j is a K dimensional vector that represents the mth users jth training document.2 ym,j is a scalar that represents the label of document xm,j. k = 1, 2, ..., K: The dimensional index of input variable x.",
                "The Bayesian hierarchical modeling approach has been widely used in real-world information retrieval applications.",
                "Generalized Bayesian hierarchical linear models, one of the simplest Bayesian hierarchical models, are commonly used and have achieved good performance on collaborative filtering [25] and content-based adaptive filtering [27] tasks.",
                "Figure 1 shows the graphical representation of a Bayesian hierarchical model.",
                "In this graph, each user model is represented by a random vector wm.",
                "We assume a user model is sampled randomly from a prior distribution P(w|Φ).",
                "The system can predict the user label y of a document x given an estimation of wm (or wms distribution) using a function y = f(x, w).",
                "The model is called generalized Bayesian hierarchical linear model when y = f(wT x) is any generalized linear model such as logistic regression, SVM, and linear regression.",
                "To reliably estimate the user model wm, the system can borrow information from other users through the prior Φ = (µ, Σ).",
                "Now we look at one commonly used model where y = wT x + , where ∼ N(0, σ2 ) is a random noise [25][27].",
                "Assume that each user model wm is an independent draw from a population distribution P(w|Φ), which is governed by some unknown hyperparameter Φ.",
                "Let the prior distribution of user model w be a Gaussian distribution with <br>parameter</br> Φ = (µ, Σ), which is the commonly used prior for linear models. µ = (µ1, µ2, ..., µK ) is a K dimensional vector that represents the mean of the Gaussian distribution, and Σ is the covariance matrix of the Gaussian.",
                "Usually, a Normal distribution N(0, aI) and an Inverse Wishart distribution P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) are used as hyperprior to model the prior distribution of µ and Σ respectively.",
                "I is the K dimensional identity matrix, and a, b, and c are real numbers.",
                "With these settings, we have the following model for the system: 1. µ and Σ are sampled from N(0, aI) and IWν (aI), respectively. 2 The first dimension of x is a dummy variable that always equals to 1.",
                "Figure 1: Illustration of dependencies of variables in the hierarchical model.",
                "The rating, y, for a document, x, is conditioned on the document and the user model, wm, associated with the user m. Users share information about their models through the prior, Φ = (µ, Σ). 2.",
                "For each user m, wm is sampled randomly from a Normal distribution: wm ∼ N(µ, Σ2 ) 3.",
                "For each item xm,j, ym,j is sampled randomly from a Normal distribution: ym,j ∼ N(wT mxm,j, σ2 ).",
                "Let θ = (Φ, w1, w2, ..., wM ) represent the parameters of this system that needs to be estimated.",
                "The joint likelihood for all the variables in the probabilistic model, which includes the data and the parameters, is: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) For simplicity, we assume a, b, c, and σ are provided to the system. 4.",
                "MODEL <br>parameter</br> LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple linear regression.",
                "Therefore, we will focus on estimating Φ.",
                "The maximum a priori solution of Φ is given by ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Finding the optimal solution for the above problem is challenging, since we need to integrate over all w = (w1, w2, ..., wM ), which are unobserved hidden variables. 4.1 EM Algorithm for Bayesian Hierarchical Linear Models In Equation 5, Φ is the <br>parameter</br> needs to be estimated, and the result depends on unobserved latent variables w. This kind of optimization problem is usually solved by the EM algorithm.",
                "Applying EM to the above problem, the set of user models w are the unobservable hidden variables and we have: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw Based on the derivation of the EM formulas presented in [24], we have the following Expectation-Maximization steps for finding the optimal hyperparameters.",
                "For space considerations, we omit the derivation in this paper since it is not the focus of our work.",
                "E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of the prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) where Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j M step: Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Many machine learning driven IR systems use a point estimate of the parameters at different stages in the system.",
                "However, we are estimating the posterior distribution of the variables at the E step.",
                "This avoids overfitting wm to a particular users data, which may be small and noisy.",
                "A detailed discussion about this subject appears in [10]. 4.2 New Algorithm: Modified EM Although the EM algorithm is widely studied and used in machine learning applications, using the above EM process to solve Bayesian hierarchical linear models in large-scale information retrieval systems is still too computationally expensive.",
                "In this section, we describe why the learning rate of the EM algorithm is slow in our application and introduce a new technique to make the learning of the Bayesian hierarchical linear model scalable.",
                "The derivation of the new learning algorithm will be based on the EM algorithm described in the previous section.",
                "First, the covariance matrices Σ2 , Σ2 m are usually too large to be computationally feasible.",
                "For simplicity, and as a common practice in IR, we do not model the correlation between features.",
                "Thus we approximate these matrices with K dimensional diagonal matrices.",
                "In the rest of the paper, we use these symbols to represent their diagonal approximations: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     Secondly, and most importantly, the input space is very sparse and there are many dimensions that are not related to a particular user in a real IR application.",
                "For example, let us consider a movie recommendation system, with the input variable x representing a particular movie.",
                "For the jth movie that the user m has seen, let xm,j,k = 1 if the director of the movie is Jean-Pierre Jeunet (indexed by k).",
                "Here we assume that whether or not that this director directed a specific movie is represented by the kth dimension.",
                "If the user m has never seen a movie directed by Jean-Pierre Jeunet, then the corresponding dimension is always zero (xm,j,k = 0 for all j) .",
                "One major drawback of the EM algorithm is that the importance of a feature, µk, may be greatly dominated by users who have never encountered this feature (i.e. j xm,j,k = 0) at the M step (Equation 8).",
                "Assume that 100 out of 1 million users have viewed the movie directed by Jean-Pierre Jeunet, and that the viewers have rated all of his movies as excellent.",
                "Intuitively, he is a good director and the weight for him (µk) should be high.",
                "Before the EM iteration, the initial value of µ is usually set to 0.",
                "Since the other 999,900 users have not seen this movie, their corresponding weights (w1,k, w2,k, ..., wm,k..., w999900,k) for that director would be very small initially.",
                "Thus the corresponding weight of the director in the prior µk at the first M step would be very low , and the variance σm,k will be large (Equations 8 and 7).",
                "It is undesirable that users who have never seen any movie produced by the director influence the importance of the director so much.",
                "This makes the convergence of the standard EM algorithm very slow.",
                "Now lets look at whether we can improve the learning speed of the algorithm.",
                "Without a loss of generality, let us assume that the kth dimension of the input variable x is not related to a particular user m. By which we mean, xm,j,k = 0 for all j = 1, ..., Jm.",
                "It is straightforward to prove that the kth row and kth column of Sxx,m are completely filled with zeros, and that the kth dimension of Sxy,m is zeroed as well.",
                "Thus the corresponding kth dimension of the user models mean, ¯wm, should be equal to that of the prior: ¯wm,k = µk, with the corresponding covariance of σm,k = σk.",
                "At the M step, the standard EM algorithm uses the numerical solution of the distribution P(wm|Dm, Φ) estimated at E step (Equation 8 and Equation 7).",
                "However, the numerical solutions are very unreliable for ¯wm,k and σm,k when the kth dimension is not related to the mth user.",
                "A better approach is using the analytical solutions ¯wm,k = µk, and σm,k = σk for the unrelated (m, k) pairs, along with the numerical solution estimated at E step for the other (m, k) pairs.",
                "Thus we get the following new EM-like algorithm: Modified E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) where sxx,m,k = j x2 m,j,k and sxy,m,k = j xm,j,kym,j Modified M Step Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step for related userfeature pairs.",
                "The M step implicitly uses the analytical solution for unrelated user-feature pairs. µk = 1 Mk m:related ¯wm,k (12) σ2 k = 1 Mk m:related σ2 m,k +( ¯wm,k − µk)( ¯wm,k − µk)T (13) where Mk is the number of users that are related to feature k We only estimate the diagonal of Σ2 m and Σ since we are using the diagonal approximation of the covariance matrices.",
                "To estimate ¯wm, we only need to calculate the numerical solutions for dimensions that are related to user m. To estimate σ2 k and µk, we only sum over users that are related to the kth feature.",
                "There are two major benefits of the new algorithm.",
                "First, because only the related (m, k) pairs are needed at the modified M step, the computational complexity in a single EM iteration is much smaller when the data is sparse, and many of (m, k) pairs are unrelated.",
                "Second, the parameters estimated at the modified M step (Equations 12 - 13) are more accurate than the standard M step described in Section 4.1 because the exact analytical solutions ¯wm,k = µk and σm,k = σk for the unrelated (m, k) pairs were used in the new algorithm instead of an approximate solution as in the standard algorithm. 5.",
                "EXPERIMENTAL METHODOLOGY 5.1 Evaluation Data Set To evaluate the proposed technique, we used the following three major data sets (Table 1): MovieLens Data: This data set was created by combining the relevance judgments from the MovieLens[9] data set with documents from the Internet Movie Database (IMDB).",
                "MovieLens allows users to rank how much he/she enjoyed a specific movie on a scale from 1 to 5.",
                "This likeability rating was used as a measurement of how relevant the document representing the corresponding movie is to the user.",
                "We considered documents with likeability scores of 4 or 5 as relevant, and documents with a score of 1 to 3 as irrelevant to the user.",
                "MovieLens provided relevance judgments on 3,057 documents from 6,040 separate users.",
                "On average, each user rated 151 movies, of these 87 were judged to be relevant.",
                "The average score for a document was 3.58.",
                "Documents representing each movie were constructed from the portion of the IMDB database that is available for public download[13].",
                "Based on this database, we created one document per movie that contained the relevant information about it (e.g. directors, actors, etc.).",
                "Table 1: Data Set Statistics.",
                "On Reuters, the number of rating for a simulated user is the number of documents relevant to the corresponding topic.",
                "Data Users Docs Ratings per User MovieLens 6,040 3,057 151 Netflix-all 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Netflix Data: This data set was constructed by combining documents about movies crawled from the web with a set of actual movie rental customer relevance judgments from Netflix[19].",
                "Netflix publicly provides the relevance judgments of 480,189 anonymous customers.",
                "There are around 100 million rating on a scale of 1 to 5 for 17,770 documents.",
                "Similar to MovieLens, we considered documents with likeability scores of 4 or 5 as relevant.",
                "This number was reduced to 1000 customers through random sampling.",
                "The average customer on the reduced data set provided 127 judgments, with 70 being deemed relevant.",
                "The average score for documents is 3.55.",
                "Reuters Data: This is the Reuters Corpus, Volume 1.",
                "It covers 810,000 Reuters English language news stories from August 20, 1996 to August 19, 1997.",
                "Only the first 100,000 news were used in our experiments.",
                "The Reuters corpus comes with a topic hierarchy.",
                "Each document is assigned to one of several locations on the hierarchical tree.",
                "The first level of the tree contains four topics, denoted as C, E, M, and G. For the experiments in this paper, the tree was cut at level 1 to create four smaller trees, each of which corresponds to one smaller data set: Reuters-E Reuters-C, ReutersM and Reuters-G. For each small data set, we created several profiles, one profile for each node in a sub-tree, to simulate multiple users, each with a related, yet separate definition of relevance.",
                "All the user profiles on a sub-tree are supposed to share the same prior model distribution.",
                "Since this corpus explicitly indicates only the relevant documents for a topic(user), all other documents are considered irrelevant. 5.2 Evaluation We designed the experiments to answer the following three questions: 1.",
                "Do we need to take the effort to use a Bayesian approach and learn a prior from other users? 2.",
                "Does the new algorithm work better than the standard EM algorithm for learning the Bayesian hierarchical linear model? 3.",
                "Can the new algorithm quickly learn many user models?",
                "To answer the first question, we compared the Bayesian hierarchical models with commonly used Norm-2 regularized linear regression models.",
                "In fact, the commonly used approach is equivalent to the model learned at the end of the first EM iteration.",
                "To answer the second question, we compared the proposed new algorithm with the standard EM algorithm to see whether the new learning algorithm is better.",
                "To answer the third question, we tested the efficiency of the new algorithm on the entire Netflix data set where about half a million user models need to be learned together.",
                "For the MovieLens and Netflix data sets, algorithm effectiveness was measured by mean square error, while on the Reuters data set classification error was used because it was more informative.",
                "We first evaluated the performance on each individual user, and then estimated the macro average over all users.",
                "Statistical tests (t-tests) were carried out to see whether the results are significant.",
                "For the experiments on the MovieLens and Netflix data sets, we used a random sample of 90% of each user for training, and the rest for testing.",
                "On Reuters data set, because there are too many relevant documents for each topic in the corpus, we used a random sample of 10% of each topic for training, and 10% of the remaining documents for testing.",
                "For all runs, we set (a, b, c, Σ ) = (0.1, 10, 0.1, 1) manually. 6.",
                "EXPERIMENTAL RESULTS Figure 2, Figure 3, and Figure 4 show that on all data sets, the Bayesian hierarchical modeling approach has a statistical significant improvement over the regularized linear regression model, which is equivalent to the Bayesian hierarchical models learned at the first iteration.",
                "Further analysis shows a negative correlation between the number of training data for a user and the improvement the system gets.",
                "This suggests that the borrowing information from other users has more significant improvements for users with less training data, which is as expected.",
                "However, the strength of the correlation differs over data sets, and the amount of training data is not the only characteristics that will influence the final performance.",
                "Figure 2 and Figure 3 show that the proposed new algorithm works better than the standard EM algorithm on the Netflix and MovieLens data sets.",
                "This is not surprising since the number of related feature-users pairs is much smaller than the number of unrelated feature-user pairs on these two data sets, and thus the proposed new algorithm is expected to work better.",
                "Figure 4 shows that the two algorithms work similarly on the Reuters-E data set.",
                "The accuracy of the new algorithm is similar to that of the standard EM algorithm at each iteration.",
                "The general patterns are very similar on other Reuters subsets.",
                "Further analysis shows that only 58% of the user-feature pairs are unrelated on this data set.",
                "Since the number of unrelated user-feature pairs is not extremely large, the sparseness is not a serious problem on the Reuters data set.",
                "Thus the two learning algorithms perform similarly.",
                "The results suggest that only on a corpus where the number of unrelated user-feature pairs is much larger than the number of related pairs, such as on the Netflix data set, the proposed technique will get a significant improvement over standard EM.",
                "However, the experiments also show that when the assumption does not hold, the new algorithm does not hurt performance.",
                "Although the proposed technique is faster than standard Figure 2: Performance on a Netflix subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iterations 2 - 10.",
                "Norm-2 regularized linear models are equivalent to the Bayesian hierarchical models learned at the first iteration, and are statistical significantly worse than the Bayesian hierarchical models. 0 2 4 6 8 10 1 1.05 1.1 1.15 1.2 1.25 1.3 1.35 1.4 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iterations ClassificationError New Algorithm Traditional EM Figure 3: Performance on a MovieLens subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iteration 2 to 17 (evaluated with mean square error). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iterations MeanSquareError New Algorithm Traditional EM 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iterations ClassificationError New Algorithm Traditional EM Figure 4: Performance on a Reuters-E subset with 26 profiles.",
                "Performances on Reuters-C, Reuters-M, Reuters-G are similar. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iterations ClassificationError New Algorithm Traditional EM EM, can it really learn millions of user models quickly?",
                "Our results show that the modified EM algorithm converges quickly, and 2 - 3 modified EM iterations would result in a reliable estimation.",
                "We evaluated the algorithm on the whole Netflix data set (480,189 users, 159,836 features, and 100 million ratings) running on a single CPU PC (2GB memory, P4 3GHz).",
                "The system finished one modified EM iteration in about 4 hours.",
                "This demonstrates that the proposed technique can efficiently handle large-scale system like Netflix. 7.",
                "CONCLUSION Content-based user profile learning is an important problem and is the key to providing personal recommendations to a user, especially for recommending new items with a small number of ratings.",
                "The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors.",
                "This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM.",
                "We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm.",
                "Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse, by which we mean the ratio of related user-feature pairs to unrelated pairs is small.",
                "Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold.",
                "In general, it is better to use the new algorithm since it is as simple as standard EM, the performance is either better or similar to EM, and the computation complexity is lower at each iteration.",
                "It is worth mentioning that even if the original problem space is not sparse, sparseness can be created artificially when a recommendation system uses user-specific feature selection techniques to reduce the noise and user model complexity.",
                "The proposed technique can also be adapted to improve the learning in such a scenario.",
                "We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU.",
                "The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear modeling approach to build a practical large scale system, even though the literature have demonstrated the effectiveness of the models in many applications.",
                "Our work is one major step on the road to make Bayesian hierarchical linear models more practical.",
                "The proposed new technique can be easily adapted to run on a cluster of machines, and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users.",
                "The research has much potential to benefit people using EM algorithm on many other IR problems as well as machine learning problems.",
                "EM algorithm is a commonly used machine learning technique.",
                "It is used to find model parameters in many IR problems where the training data is very sparse.",
                "Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering, the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems. 8.",
                "ACKNOWLEDGMENTS We thank Wei Xu, David Lewis and anonymous reviewers for valuable feedback on the work described in this paper.",
                "Part of the work was supported by Yahoo, Google, the Petascale Data Storage Institute and the Institute for Scalable Scientific Data Management.",
                "Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors, and do not necessarily reflect those of the sponsors. 9.",
                "REFERENCES [1] C. Basu, H. Hirsh, and W. Cohen.",
                "Recommendation as classification: Using social and content-based information in recommendation.",
                "In Proceedings of the Fifteenth National Conference on Artificial Intelligence, 1998. [2] J. S. Breese, D. Heckerman, and C. Kadie.",
                "Empirical analysis of predictive algorithms for collaborative filtering.",
                "Technical report, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan.",
                "Document filtering with inference networks.",
                "In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor, and A. Vinokourov.",
                "Kernel method for document filtering.",
                "In The Eleventh Text REtrieval Conference (TREC11).",
                "National Institute of Standards and Technology, special publication 500-249, 2003. [5] C. Chelba and A. Acero.",
                "Adaptation of maximum entropy capitalizer: Little data can help a lot.",
                "In D. Lin and D. Wu, editors, Proceedings of EMNLP 2004, pages 285-292, Barcelona, Spain, July 2004.",
                "Association for Computational Linguistics. [6] B. Croft and J. Lafferty, editors.",
                "Language Modeling for Information Retrieval.",
                "Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov, and A. Genkin.",
                "Constructing informative prior distributions from domain knowledge in text classification.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 493-500, New York, NY, USA, 2006.",
                "ACM Press. [8] J. Delgado and N. Ishii.",
                "Memory-based weightedmajority prediction for recommender systems.",
                "In ACM SIGIR99 Workshop on Recommender Systems, 1999. [9] GroupLens.",
                "Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman.",
                "A tutorial on learning with bayesian networks.",
                "In M. Jordan, editor, Learning in Graphical Models.",
                "Kluwer Academic, 1998. [11] J. L. Herlocker, J.",
                "A. Konstan, A. Borchers, and J. Riedl.",
                "An algorithmic framework for performing collaborative filtering.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 230-237, New York, NY, USA, 1999.",
                "ACM Press. [12] T. Hofmann and J. Puzicha.",
                "Latent class models for collaborative filtering.",
                "In IJCAI 99: Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 688-693, San Francisco, CA, USA, 1999.",
                "Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).",
                "Internet movie database. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai, and L. Si.",
                "An automatic weighting scheme for collaborative filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 337-344, New York, NY, USA, 2004.",
                "ACM Press. [15] J.",
                "A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl.",
                "GroupLens: Applying collaborative filtering to Usenet news.",
                "Communications of the ACM, 40(3):77-87, 1997. [16] D. Lewis.",
                "Applying support vector machines to the TREC-2001 batch filtering and routing tasks.",
                "In Proceedings of the Eleventh Text REtrieval Conference (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee, , and P. Yu.",
                "Text classification by labeling words.",
                "In Proceedings of The Nineteenth National Conference on Artificial Intelligence (AAAI-2004), July 25-29, 2004. [18] P. Melville, R. J. Mooney, and R. Nagarajan.",
                "Content-boosted collaborative filtering for improved recommendations.",
                "In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002), Edmonton, Canada, 2002. [19] Netflix.",
                "Netflix prize. http://www.netflixprize.com (visited on Nov. 30, 2006), 2006. [20] S. Robertson and K. Sparck-Jones.",
                "Relevance weighting of search terms.",
                "In Journal of the American Society for Information Science, volume 27, pages 129-146, 1976. [21] J. Wang, A. P. de Vries, and M. J. T. Reinders.",
                "Unifying user-based and item-based collaborative filtering approaches by similarity fusion.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 501-508, New York, NY, USA, 2006.",
                "ACM Press. [22] X. Wu and R. K. Srihari.",
                "Incorporating prior knowledge with weighted margin support vector machines.",
                "In Proc.",
                "ACM Knowledge Discovery Data Mining Conf. (ACM SIGKDD 2004), Aug. 2004. [23] Y. Yang, S. Yoo, J. Zhang, and B. Kisiel.",
                "Robustness of adaptive filtering methods in a cross-benchmark evaluation.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2005. [24] K. Yu, V. Tresp, and A. Schwaighofer.",
                "Learning gaussian processes from multiple tasks.",
                "In ICML 05: Proceedings of the 22nd international conference on Machine learning, pages 1012-1019, New York, NY, USA, 2005.",
                "ACM Press. [25] K. Yu, V. Tresp, and S. Yu.",
                "A nonparametric hierarchical bayesian framework for information filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 353-360.",
                "ACM Press, 2004. [26] X. Zhu.",
                "Semi-supervised learning literature survey.",
                "Technical report, University of Wisconsin - Madison, December 9, 2006. [27] P. Zigoris and Y. Zhang.",
                "Bayesian adaptive user profiling with explicit & implicit feedback.",
                "In Conference on Information and Knowledge Mangement 2006, 2006."
            ],
            "original_annotated_samples": [
                "The EM algorithm is a commonly used technique for <br>parameter</br> learning due to its simplicity and convergence guarantee.",
                "We also find that updating the model <br>parameter</br> at each EM iteration is also expensive with computational complexity of O(MK), where M is the number of users and K is the number of dimensions.",
                "M is the total number of users. wm: The user model <br>parameter</br> associated with user m. wm is a K dimensional vector. j = 1, 2, ..., Jm: The index for a set of data for user m. Jm is the number of training data for user m. Dm = {(xm,j, ym,j)}: A set of data associated with user m. xm,j is a K dimensional vector that represents the mth users jth training document.2 ym,j is a scalar that represents the label of document xm,j. k = 1, 2, ..., K: The dimensional index of input variable x.",
                "Let the prior distribution of user model w be a Gaussian distribution with <br>parameter</br> Φ = (µ, Σ), which is the commonly used prior for linear models. µ = (µ1, µ2, ..., µK ) is a K dimensional vector that represents the mean of the Gaussian distribution, and Σ is the covariance matrix of the Gaussian.",
                "MODEL <br>parameter</br> LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple linear regression."
            ],
            "translated_annotated_samples": [
                "El algoritmo EM es una técnica comúnmente utilizada para el aprendizaje de <br>parámetros</br> debido a su simplicidad y garantía de convergencia.",
                "También encontramos que actualizar el <br>parámetro</br> del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones.",
                "M es el número total de usuarios. wm: El <br>parámetro</br> del modelo de usuario asociado con el usuario m. wm es un vector de dimensión K. j = 1, 2, ..., Jm: El índice para un conjunto de datos para el usuario m. Jm es el número de datos de entrenamiento para el usuario m. Dm = {(xm,j, ym,j)}: Un conjunto de datos asociado con el usuario m. xm,j es un vector de dimensión K que representa el j-ésimo documento de entrenamiento del usuario m. ym,j es un escalar que representa la etiqueta del documento xm,j. k = 1, 2, ..., K: El índice dimensional de la variable de entrada x.",
                "Que la distribución previa del modelo de usuario w sea una distribución gaussiana con <br>parámetro</br> Φ = (µ, Σ), que es la distribución previa comúnmente utilizada para modelos lineales. µ = (µ1, µ2, ..., µK) es un vector de K dimensiones que representa la media de la distribución gaussiana, y Σ es la matriz de covarianza de la gaussiana.",
                "APRENDIZAJE DE PARÁMETROS DEL MODELO Si se conoce el prior Φ, encontrar el óptimo wm es sencillo: se trata de una regresión lineal simple."
            ],
            "translated_text": "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual. Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un modelo jerárquico bayesiano. Aprender los parámetros del modelo para optimizar la verosimilitud conjunta de los datos de millones de usuarios es muy costoso computacionalmente. El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de datos en aplicaciones de IR. Este documento propone una nueva técnica de aprendizaje rápido para aprender un gran número de perfiles de usuario individuales. La eficacia y eficiencia del algoritmo propuesto están justificadas por la teoría y demostradas en datos reales de usuarios de Netflix y MovieLens. Categorías y Descriptores de Asignaturas: B.3.3 [Búsqueda y Recuperación de Información]: Filtrado de información Términos Generales: Algoritmos 1. La personalización es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales. Por ejemplo, las tiendas en línea, como Amazon y Netflix, ofrecen recomendaciones personalizadas de productos o servicios adicionales basadas en el historial de un usuario. Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de un usuario a partir de su historial. Un tema importante de personalización estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados basados en el contenido. Estos sistemas aprenden perfiles específicos de usuario a partir de la retroalimentación del usuario para poder recomendar información adaptada a los intereses de cada usuario sin necesidad de que el usuario realice una consulta explícita. Aprender los perfiles de usuario es el problema central de estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica qué tan relevante es un documento para el usuario. Uno de los principales desafíos de construir un sistema de recomendación o personalización es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña. Esto se conoce como el problema de inicio en frío. Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente retroalimentación de ese usuario para aprender un perfil de usuario confiable. Se ha realizado mucha investigación sobre cómo mejorar la precisión de clasificación cuando la cantidad de datos de entrenamiento etiquetados es pequeña. El enfoque de aprendizaje semisupervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26]. Otro enfoque es utilizar el conocimiento del dominio. Los investigadores han modificado diferentes algoritmos de aprendizaje, como NaïveBayes [17], regresión logística [7] y SVMs [22], para integrar el conocimiento del dominio en un clasificador de texto. El tercer enfoque consiste en tomar datos de entrenamiento de otros recursos [5][7]. La efectividad de estos enfoques diferentes es mixta, debido a qué tan bien se ajusta la suposición del modelo subyacente a los datos. Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano. Varios investigadores han demostrado que este enfoque intercambia eficazmente entre la información compartida y la específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario[27][25]. Para aprender un modelo jerárquico bayesiano, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados. Un sistema de recomendación maduro generalmente funciona para millones de usuarios. Es bien sabido que aprender los parámetros óptimos de un modelo jerárquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios. El algoritmo EM es una técnica comúnmente utilizada para el aprendizaje de <br>parámetros</br> debido a su simplicidad y garantía de convergencia. Sin embargo, un sistema de recomendación basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso. Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM tering, o filtrado colaborativo basado en elementos. En este documento, las palabras filtrado y recomendación se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de las variables de entrada. También encontramos que actualizar el <br>parámetro</br> del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones. Este documento modifica el algoritmo EM estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos algoritmo EM modificado. La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M utilizamos la solución analítica en lugar de la solución numérica estimada en el paso E para esos parámetros. Esto reduce considerablemente la computación en una sola iteración de EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales. La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de regresión lineal jerárquica bayesiana utilizado para recomendaciones basadas en contenido. La sección 4 describe cómo aprender los parámetros del modelo utilizando el algoritmo EM estándar, junto con el uso de la nueva técnica propuesta en este artículo. La configuración experimental y los resultados utilizados para validar la técnica de aprendizaje propuesta se informan en las Secciones 5 y 6. La sección 7 resume y ofrece observaciones finales. 2. TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de IR desde la década de 1970. Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus filtrado colaborativo. El filtrado basado en contenido estudia el escenario en el que un sistema de recomendación monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente. El usuario puede leer los documentos entregados y proporcionar retroalimentación explícita de relevancia, la cual el sistema de filtrado utiliza para actualizar el perfil del usuario mediante modelos de recuperación de retroalimentación de relevancia (por ejemplo,). Modelos booleanos, modelos de espacio vectorial, modelos probabilísticos tradicionales [20], redes de inferencia [3] y modelos de lenguaje [6]) o algoritmos de aprendizaje automático (por ejemplo, Máquinas de Vectores de Soporte (SVM), agrupamiento de K vecinos más cercanos (K-NN), redes neuronales, regresión logística o Winnow [16] [4] [23]. El filtrado colaborativo va más allá de simplemente usar el contenido de un documento para recomendar elementos a un usuario, aprovechando la información de otros usuarios con gustos y preferencias similares en el pasado. Se han utilizado heurísticas basadas en memoria y enfoques basados en modelos en la tarea de filtrado colaborativo [15] [8] [2] [14] [12] [11]. Este artículo contribuye a la investigación de recomendaciones basadas en contenido al mejorar la eficiencia y efectividad de los modelos lineales jerárquicos bayesianos, los cuales tienen una sólida base teórica y un buen rendimiento empírico en tareas de recomendación[27][25]. Este artículo no tiene la intención de comparar el filtrado basado en contenido con el filtrado colaborativo ni de afirmar cuál es mejor. Creemos que cada uno complementa al otro, y que el filtrado basado en contenido es extremadamente útil para manejar nuevos documentos/artículos con poco o ningún feedback del usuario. Similar a otros investigadores[18][1][21], encontramos que un sistema de recomendación será más efectivo cuando se combinan ambas técnicas. Sin embargo, esto está fuera del alcance de este documento y, por lo tanto, no se discute aquí. 3. REGRESIÓN LINEAL HIERÁRQUICA BAYESIANA Suponga que hay M usuarios en el sistema. La tarea del sistema es recomendar documentos que sean relevantes para cada usuario. Para cada usuario, el sistema aprende un modelo de usuario a partir del historial de los usuarios. En el resto de este documento, utilizaremos las siguientes notaciones para representar las variables en el sistema. m = 1, 2, ..., M: El índice para cada usuario individual. M es el número total de usuarios. wm: El <br>parámetro</br> del modelo de usuario asociado con el usuario m. wm es un vector de dimensión K. j = 1, 2, ..., Jm: El índice para un conjunto de datos para el usuario m. Jm es el número de datos de entrenamiento para el usuario m. Dm = {(xm,j, ym,j)}: Un conjunto de datos asociado con el usuario m. xm,j es un vector de dimensión K que representa el j-ésimo documento de entrenamiento del usuario m. ym,j es un escalar que representa la etiqueta del documento xm,j. k = 1, 2, ..., K: El índice dimensional de la variable de entrada x. El enfoque de modelado jerárquico bayesiano ha sido ampliamente utilizado en aplicaciones reales de recuperación de información. Los modelos lineales jerárquicos bayesianos generalizados, uno de los modelos jerárquicos bayesianos más simples, son comúnmente utilizados y han logrado un buen rendimiento en tareas de filtrado colaborativo [25] y filtrado adaptativo basado en contenido [27]. La Figura 1 muestra la representación gráfica de un modelo jerárquico bayesiano. En este gráfico, cada modelo de usuario está representado por un vector aleatorio wm. Suponemos que un modelo de usuario se muestrea aleatoriamente de una distribución previa P(w|Φ). El sistema puede predecir la etiqueta de usuario y de un documento x dado una estimación de wm (o distribución de wms) utilizando una función y = f(x, w). El modelo se llama modelo lineal jerárquico bayesiano generalizado cuando y = f(wT x) es cualquier modelo lineal generalizado como regresión logística, SVM y regresión lineal. Para estimar de manera confiable el modelo de usuario wm, el sistema puede obtener información de otros usuarios a través de la prior Φ = (µ, Σ). Ahora observamos un modelo comúnmente utilizado donde y = wT x + , donde ∼ N(0, σ2 ) es un ruido aleatorio [25][27]. Suponga que cada modelo de usuario wm es una muestra independiente de una distribución poblacional P(w|Φ), la cual está regida por un hiperparámetro desconocido Φ. Que la distribución previa del modelo de usuario w sea una distribución gaussiana con <br>parámetro</br> Φ = (µ, Σ), que es la distribución previa comúnmente utilizada para modelos lineales. µ = (µ1, µ2, ..., µK) es un vector de K dimensiones que representa la media de la distribución gaussiana, y Σ es la matriz de covarianza de la gaussiana. Normalmente, se utiliza una distribución Normal N(0, aI) y una distribución Inverse Wishart P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) como hiperprior para modelar la distribución previa de µ y Σ respectivamente. Yo es la matriz identidad de dimensión K, y a, b y c son números reales. Con esta configuración, tenemos el siguiente modelo para el sistema: 1. µ y Σ se muestrean de N(0, aI) e IWν (aI), respectivamente. 2. La primera dimensión de x es una variable ficticia que siempre es igual a 1. Figura 1: Ilustración de las dependencias de variables en el modelo jerárquico. La calificación, y, para un documento, x, está condicionada al documento y al modelo de usuario, wm, asociado con el usuario m. Los usuarios comparten información sobre sus modelos a través de la prior, Φ = (µ, Σ). Para cada usuario m, wm se muestrea aleatoriamente de una distribución Normal: wm ∼ N(µ, Σ2 ) 3. Para cada elemento xm,j, ym,j se muestrea aleatoriamente de una distribución Normal: ym,j ∼ N(wT mxm,j, σ2). Que θ = (Φ, w1, w2, ..., wM) represente los parámetros de este sistema que necesitan ser estimados. La verosimilitud conjunta de todas las variables en el modelo probabilístico, que incluye los datos y los parámetros, es: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) Para simplificar, asumimos que a, b, c y σ son proporcionados al sistema. 4. APRENDIZAJE DE PARÁMETROS DEL MODELO Si se conoce el prior Φ, encontrar el óptimo wm es sencillo: se trata de una regresión lineal simple. ",
            "candidates": [],
            "error": [
                [
                    "parámetros",
                    "parámetro",
                    "parámetro",
                    "parámetro"
                ]
            ]
        },
        "learning technique": {
            "translated_key": "técnica de aprendizaje",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
                "A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model.",
                "Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive.",
                "The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications.",
                "This paper proposes a new fast <br>learning technique</br> to learn a large number of individual user profiles.",
                "The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens.",
                "Categories and Subject Descriptors: B.3.3 [Information Search and Retrieval]: Information filtering General Terms: Algorithms 1.",
                "INTRODUCTION Personalization is the future of the Web, and it has achieved great success in industrial applications.",
                "For example, online stores, such as Amazon and Netflix, provide customized recommendations for additional products or services based on a users history.",
                "Recent offerings such as My MSN, My Yahoo!, My Google, and Google News have attracted much attention due to their potential ability to infer a users interests from his/her history.",
                "One major personalization topic studied in the information retrieval community is content-based personal recommendation systems1 .",
                "These systems learn user-specific profiles from user feedback so that they can recommend information tailored to each individual users interest without requiring the user to make an explicit query.",
                "Learning the user profiles is the core problem for these systems.",
                "A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user.",
                "One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small.",
                "This is known as the cold start problem.",
                "This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile.",
                "There has been much research on improving classification accuracy when the amount of labeled training data is small.",
                "The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal [26].",
                "Another approach is using domain knowledge.",
                "Researchers have modified different learning algorithms, such as Na¨ıveBayes [17], logistic regression [7], and SVMs [22], to integrate domain knowledge into a text classifier.",
                "The third approach is borrowing training data from other resources [5][7].",
                "The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data.",
                "One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach.",
                "Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial performance for each user[27][25].",
                "In order to learn a Bayesian hierarchical model, the system usually tries to find the most likely model parameters for the given data.",
                "A mature recommendation system usually works for millions of users.",
                "It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users.",
                "The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee.",
                "However, a content based recommendation system often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector.",
                "With careful analysis of the EM algorithm in this scenario (Section 4), we find that the EM tering, or item-based collaborative filtering.",
                "In this paper, the words filtering and recommendation are used interchangeably. algorithm converges very slowly due to the sparseness of the input variables.",
                "We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O(MK), where M is the number of users and K is the number of dimensions.",
                "This paper modifies the standard EM algorithm to create an improved learning algorithm, which we call the Modified EM algorithm.",
                "The basic idea is that instead of calculating the numerical solution for all the user profile parameters, we derive the analytical solution of the parameters for some feature dimensions, and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters.",
                "This greatly reduces the computation at a single EM iteration, and also has the benefit of increasing the convergence speed of the learning algorithm.",
                "The proposed technique is not only well supported by theory, but also by experimental results.",
                "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression modeling framework used for content-based recommendations.",
                "Section 4 describes how to learn the model parameters using the standard EM algorithm, along with using the new technique proposed in this paper.",
                "The experimental setting and results used to validate the proposed <br>learning technique</br> are reported in Sections 5 and 6.",
                "Section 7 summarizes and offers concluding remarks. 2.",
                "RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the IR community since the 1970s.",
                "The approaches that have been used to solve this problem can be roughly classified into two major categories: content based filtering versus collaborative filtering.",
                "Content-based filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user.",
                "The user may read the delivered documents and provide explicit relevance feedback, which the filtering system then uses to update the users profile using relevance feedback retrieval models (e.g.",
                "Boolean models, vector space models, traditional probabilistic models [20] , inference networks [3] and language models [6]) or machine learning algorithms (e.g.",
                "Support Vector Machines (SVM), K nearest neighbors (K-NN) clustering, neural networks, logistic regression, or Winnow [16] [4] [23]).",
                "Collaborative filtering goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past.",
                "Memorybased heuristics and model based approaches have been used in collaborative filtering task [15] [8] [2] [14] [12] [11].",
                "This paper contributes to the content-based recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks[27][25].",
                "This paper does not intend to compare content-based filtering with collaborative filtering or claim which one is a better.",
                "We think each complements the other, and that content-based filtering is extremely useful for handling new documents/items with little or no user feedback.",
                "Similar to some other researchers[18][1][21], we found that a recommendation system will be more effective when both techniques are combined.",
                "However, this is beyond the scope of this paper and thus not discussed here. 3.",
                "BAYESIAN HIERARCHICAL LINEAR REGRESSION Assume there are M users in the system.",
                "The task of the system is to recommend documents that are relevant to each user.",
                "For each user, the system learns a user model from the users history.",
                "In the rest of this paper, we will use the following notations to represent the variables in the system. m = 1, 2, ..., M: The index for each individual user.",
                "M is the total number of users. wm: The user model parameter associated with user m. wm is a K dimensional vector. j = 1, 2, ..., Jm: The index for a set of data for user m. Jm is the number of training data for user m. Dm = {(xm,j, ym,j)}: A set of data associated with user m. xm,j is a K dimensional vector that represents the mth users jth training document.2 ym,j is a scalar that represents the label of document xm,j. k = 1, 2, ..., K: The dimensional index of input variable x.",
                "The Bayesian hierarchical modeling approach has been widely used in real-world information retrieval applications.",
                "Generalized Bayesian hierarchical linear models, one of the simplest Bayesian hierarchical models, are commonly used and have achieved good performance on collaborative filtering [25] and content-based adaptive filtering [27] tasks.",
                "Figure 1 shows the graphical representation of a Bayesian hierarchical model.",
                "In this graph, each user model is represented by a random vector wm.",
                "We assume a user model is sampled randomly from a prior distribution P(w|Φ).",
                "The system can predict the user label y of a document x given an estimation of wm (or wms distribution) using a function y = f(x, w).",
                "The model is called generalized Bayesian hierarchical linear model when y = f(wT x) is any generalized linear model such as logistic regression, SVM, and linear regression.",
                "To reliably estimate the user model wm, the system can borrow information from other users through the prior Φ = (µ, Σ).",
                "Now we look at one commonly used model where y = wT x + , where ∼ N(0, σ2 ) is a random noise [25][27].",
                "Assume that each user model wm is an independent draw from a population distribution P(w|Φ), which is governed by some unknown hyperparameter Φ.",
                "Let the prior distribution of user model w be a Gaussian distribution with parameter Φ = (µ, Σ), which is the commonly used prior for linear models. µ = (µ1, µ2, ..., µK ) is a K dimensional vector that represents the mean of the Gaussian distribution, and Σ is the covariance matrix of the Gaussian.",
                "Usually, a Normal distribution N(0, aI) and an Inverse Wishart distribution P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) are used as hyperprior to model the prior distribution of µ and Σ respectively.",
                "I is the K dimensional identity matrix, and a, b, and c are real numbers.",
                "With these settings, we have the following model for the system: 1. µ and Σ are sampled from N(0, aI) and IWν (aI), respectively. 2 The first dimension of x is a dummy variable that always equals to 1.",
                "Figure 1: Illustration of dependencies of variables in the hierarchical model.",
                "The rating, y, for a document, x, is conditioned on the document and the user model, wm, associated with the user m. Users share information about their models through the prior, Φ = (µ, Σ). 2.",
                "For each user m, wm is sampled randomly from a Normal distribution: wm ∼ N(µ, Σ2 ) 3.",
                "For each item xm,j, ym,j is sampled randomly from a Normal distribution: ym,j ∼ N(wT mxm,j, σ2 ).",
                "Let θ = (Φ, w1, w2, ..., wM ) represent the parameters of this system that needs to be estimated.",
                "The joint likelihood for all the variables in the probabilistic model, which includes the data and the parameters, is: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) For simplicity, we assume a, b, c, and σ are provided to the system. 4.",
                "MODEL PARAMETER LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple linear regression.",
                "Therefore, we will focus on estimating Φ.",
                "The maximum a priori solution of Φ is given by ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Finding the optimal solution for the above problem is challenging, since we need to integrate over all w = (w1, w2, ..., wM ), which are unobserved hidden variables. 4.1 EM Algorithm for Bayesian Hierarchical Linear Models In Equation 5, Φ is the parameter needs to be estimated, and the result depends on unobserved latent variables w. This kind of optimization problem is usually solved by the EM algorithm.",
                "Applying EM to the above problem, the set of user models w are the unobservable hidden variables and we have: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw Based on the derivation of the EM formulas presented in [24], we have the following Expectation-Maximization steps for finding the optimal hyperparameters.",
                "For space considerations, we omit the derivation in this paper since it is not the focus of our work.",
                "E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of the prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) where Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j M step: Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Many machine learning driven IR systems use a point estimate of the parameters at different stages in the system.",
                "However, we are estimating the posterior distribution of the variables at the E step.",
                "This avoids overfitting wm to a particular users data, which may be small and noisy.",
                "A detailed discussion about this subject appears in [10]. 4.2 New Algorithm: Modified EM Although the EM algorithm is widely studied and used in machine learning applications, using the above EM process to solve Bayesian hierarchical linear models in large-scale information retrieval systems is still too computationally expensive.",
                "In this section, we describe why the learning rate of the EM algorithm is slow in our application and introduce a new technique to make the learning of the Bayesian hierarchical linear model scalable.",
                "The derivation of the new learning algorithm will be based on the EM algorithm described in the previous section.",
                "First, the covariance matrices Σ2 , Σ2 m are usually too large to be computationally feasible.",
                "For simplicity, and as a common practice in IR, we do not model the correlation between features.",
                "Thus we approximate these matrices with K dimensional diagonal matrices.",
                "In the rest of the paper, we use these symbols to represent their diagonal approximations: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     Secondly, and most importantly, the input space is very sparse and there are many dimensions that are not related to a particular user in a real IR application.",
                "For example, let us consider a movie recommendation system, with the input variable x representing a particular movie.",
                "For the jth movie that the user m has seen, let xm,j,k = 1 if the director of the movie is Jean-Pierre Jeunet (indexed by k).",
                "Here we assume that whether or not that this director directed a specific movie is represented by the kth dimension.",
                "If the user m has never seen a movie directed by Jean-Pierre Jeunet, then the corresponding dimension is always zero (xm,j,k = 0 for all j) .",
                "One major drawback of the EM algorithm is that the importance of a feature, µk, may be greatly dominated by users who have never encountered this feature (i.e. j xm,j,k = 0) at the M step (Equation 8).",
                "Assume that 100 out of 1 million users have viewed the movie directed by Jean-Pierre Jeunet, and that the viewers have rated all of his movies as excellent.",
                "Intuitively, he is a good director and the weight for him (µk) should be high.",
                "Before the EM iteration, the initial value of µ is usually set to 0.",
                "Since the other 999,900 users have not seen this movie, their corresponding weights (w1,k, w2,k, ..., wm,k..., w999900,k) for that director would be very small initially.",
                "Thus the corresponding weight of the director in the prior µk at the first M step would be very low , and the variance σm,k will be large (Equations 8 and 7).",
                "It is undesirable that users who have never seen any movie produced by the director influence the importance of the director so much.",
                "This makes the convergence of the standard EM algorithm very slow.",
                "Now lets look at whether we can improve the learning speed of the algorithm.",
                "Without a loss of generality, let us assume that the kth dimension of the input variable x is not related to a particular user m. By which we mean, xm,j,k = 0 for all j = 1, ..., Jm.",
                "It is straightforward to prove that the kth row and kth column of Sxx,m are completely filled with zeros, and that the kth dimension of Sxy,m is zeroed as well.",
                "Thus the corresponding kth dimension of the user models mean, ¯wm, should be equal to that of the prior: ¯wm,k = µk, with the corresponding covariance of σm,k = σk.",
                "At the M step, the standard EM algorithm uses the numerical solution of the distribution P(wm|Dm, Φ) estimated at E step (Equation 8 and Equation 7).",
                "However, the numerical solutions are very unreliable for ¯wm,k and σm,k when the kth dimension is not related to the mth user.",
                "A better approach is using the analytical solutions ¯wm,k = µk, and σm,k = σk for the unrelated (m, k) pairs, along with the numerical solution estimated at E step for the other (m, k) pairs.",
                "Thus we get the following new EM-like algorithm: Modified E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) where sxx,m,k = j x2 m,j,k and sxy,m,k = j xm,j,kym,j Modified M Step Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step for related userfeature pairs.",
                "The M step implicitly uses the analytical solution for unrelated user-feature pairs. µk = 1 Mk m:related ¯wm,k (12) σ2 k = 1 Mk m:related σ2 m,k +( ¯wm,k − µk)( ¯wm,k − µk)T (13) where Mk is the number of users that are related to feature k We only estimate the diagonal of Σ2 m and Σ since we are using the diagonal approximation of the covariance matrices.",
                "To estimate ¯wm, we only need to calculate the numerical solutions for dimensions that are related to user m. To estimate σ2 k and µk, we only sum over users that are related to the kth feature.",
                "There are two major benefits of the new algorithm.",
                "First, because only the related (m, k) pairs are needed at the modified M step, the computational complexity in a single EM iteration is much smaller when the data is sparse, and many of (m, k) pairs are unrelated.",
                "Second, the parameters estimated at the modified M step (Equations 12 - 13) are more accurate than the standard M step described in Section 4.1 because the exact analytical solutions ¯wm,k = µk and σm,k = σk for the unrelated (m, k) pairs were used in the new algorithm instead of an approximate solution as in the standard algorithm. 5.",
                "EXPERIMENTAL METHODOLOGY 5.1 Evaluation Data Set To evaluate the proposed technique, we used the following three major data sets (Table 1): MovieLens Data: This data set was created by combining the relevance judgments from the MovieLens[9] data set with documents from the Internet Movie Database (IMDB).",
                "MovieLens allows users to rank how much he/she enjoyed a specific movie on a scale from 1 to 5.",
                "This likeability rating was used as a measurement of how relevant the document representing the corresponding movie is to the user.",
                "We considered documents with likeability scores of 4 or 5 as relevant, and documents with a score of 1 to 3 as irrelevant to the user.",
                "MovieLens provided relevance judgments on 3,057 documents from 6,040 separate users.",
                "On average, each user rated 151 movies, of these 87 were judged to be relevant.",
                "The average score for a document was 3.58.",
                "Documents representing each movie were constructed from the portion of the IMDB database that is available for public download[13].",
                "Based on this database, we created one document per movie that contained the relevant information about it (e.g. directors, actors, etc.).",
                "Table 1: Data Set Statistics.",
                "On Reuters, the number of rating for a simulated user is the number of documents relevant to the corresponding topic.",
                "Data Users Docs Ratings per User MovieLens 6,040 3,057 151 Netflix-all 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Netflix Data: This data set was constructed by combining documents about movies crawled from the web with a set of actual movie rental customer relevance judgments from Netflix[19].",
                "Netflix publicly provides the relevance judgments of 480,189 anonymous customers.",
                "There are around 100 million rating on a scale of 1 to 5 for 17,770 documents.",
                "Similar to MovieLens, we considered documents with likeability scores of 4 or 5 as relevant.",
                "This number was reduced to 1000 customers through random sampling.",
                "The average customer on the reduced data set provided 127 judgments, with 70 being deemed relevant.",
                "The average score for documents is 3.55.",
                "Reuters Data: This is the Reuters Corpus, Volume 1.",
                "It covers 810,000 Reuters English language news stories from August 20, 1996 to August 19, 1997.",
                "Only the first 100,000 news were used in our experiments.",
                "The Reuters corpus comes with a topic hierarchy.",
                "Each document is assigned to one of several locations on the hierarchical tree.",
                "The first level of the tree contains four topics, denoted as C, E, M, and G. For the experiments in this paper, the tree was cut at level 1 to create four smaller trees, each of which corresponds to one smaller data set: Reuters-E Reuters-C, ReutersM and Reuters-G. For each small data set, we created several profiles, one profile for each node in a sub-tree, to simulate multiple users, each with a related, yet separate definition of relevance.",
                "All the user profiles on a sub-tree are supposed to share the same prior model distribution.",
                "Since this corpus explicitly indicates only the relevant documents for a topic(user), all other documents are considered irrelevant. 5.2 Evaluation We designed the experiments to answer the following three questions: 1.",
                "Do we need to take the effort to use a Bayesian approach and learn a prior from other users? 2.",
                "Does the new algorithm work better than the standard EM algorithm for learning the Bayesian hierarchical linear model? 3.",
                "Can the new algorithm quickly learn many user models?",
                "To answer the first question, we compared the Bayesian hierarchical models with commonly used Norm-2 regularized linear regression models.",
                "In fact, the commonly used approach is equivalent to the model learned at the end of the first EM iteration.",
                "To answer the second question, we compared the proposed new algorithm with the standard EM algorithm to see whether the new learning algorithm is better.",
                "To answer the third question, we tested the efficiency of the new algorithm on the entire Netflix data set where about half a million user models need to be learned together.",
                "For the MovieLens and Netflix data sets, algorithm effectiveness was measured by mean square error, while on the Reuters data set classification error was used because it was more informative.",
                "We first evaluated the performance on each individual user, and then estimated the macro average over all users.",
                "Statistical tests (t-tests) were carried out to see whether the results are significant.",
                "For the experiments on the MovieLens and Netflix data sets, we used a random sample of 90% of each user for training, and the rest for testing.",
                "On Reuters data set, because there are too many relevant documents for each topic in the corpus, we used a random sample of 10% of each topic for training, and 10% of the remaining documents for testing.",
                "For all runs, we set (a, b, c, Σ ) = (0.1, 10, 0.1, 1) manually. 6.",
                "EXPERIMENTAL RESULTS Figure 2, Figure 3, and Figure 4 show that on all data sets, the Bayesian hierarchical modeling approach has a statistical significant improvement over the regularized linear regression model, which is equivalent to the Bayesian hierarchical models learned at the first iteration.",
                "Further analysis shows a negative correlation between the number of training data for a user and the improvement the system gets.",
                "This suggests that the borrowing information from other users has more significant improvements for users with less training data, which is as expected.",
                "However, the strength of the correlation differs over data sets, and the amount of training data is not the only characteristics that will influence the final performance.",
                "Figure 2 and Figure 3 show that the proposed new algorithm works better than the standard EM algorithm on the Netflix and MovieLens data sets.",
                "This is not surprising since the number of related feature-users pairs is much smaller than the number of unrelated feature-user pairs on these two data sets, and thus the proposed new algorithm is expected to work better.",
                "Figure 4 shows that the two algorithms work similarly on the Reuters-E data set.",
                "The accuracy of the new algorithm is similar to that of the standard EM algorithm at each iteration.",
                "The general patterns are very similar on other Reuters subsets.",
                "Further analysis shows that only 58% of the user-feature pairs are unrelated on this data set.",
                "Since the number of unrelated user-feature pairs is not extremely large, the sparseness is not a serious problem on the Reuters data set.",
                "Thus the two learning algorithms perform similarly.",
                "The results suggest that only on a corpus where the number of unrelated user-feature pairs is much larger than the number of related pairs, such as on the Netflix data set, the proposed technique will get a significant improvement over standard EM.",
                "However, the experiments also show that when the assumption does not hold, the new algorithm does not hurt performance.",
                "Although the proposed technique is faster than standard Figure 2: Performance on a Netflix subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iterations 2 - 10.",
                "Norm-2 regularized linear models are equivalent to the Bayesian hierarchical models learned at the first iteration, and are statistical significantly worse than the Bayesian hierarchical models. 0 2 4 6 8 10 1 1.05 1.1 1.15 1.2 1.25 1.3 1.35 1.4 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iterations ClassificationError New Algorithm Traditional EM Figure 3: Performance on a MovieLens subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iteration 2 to 17 (evaluated with mean square error). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iterations MeanSquareError New Algorithm Traditional EM 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iterations ClassificationError New Algorithm Traditional EM Figure 4: Performance on a Reuters-E subset with 26 profiles.",
                "Performances on Reuters-C, Reuters-M, Reuters-G are similar. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iterations ClassificationError New Algorithm Traditional EM EM, can it really learn millions of user models quickly?",
                "Our results show that the modified EM algorithm converges quickly, and 2 - 3 modified EM iterations would result in a reliable estimation.",
                "We evaluated the algorithm on the whole Netflix data set (480,189 users, 159,836 features, and 100 million ratings) running on a single CPU PC (2GB memory, P4 3GHz).",
                "The system finished one modified EM iteration in about 4 hours.",
                "This demonstrates that the proposed technique can efficiently handle large-scale system like Netflix. 7.",
                "CONCLUSION Content-based user profile learning is an important problem and is the key to providing personal recommendations to a user, especially for recommending new items with a small number of ratings.",
                "The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors.",
                "This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better <br>learning technique</br> called Modified EM.",
                "We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm.",
                "Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse, by which we mean the ratio of related user-feature pairs to unrelated pairs is small.",
                "Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold.",
                "In general, it is better to use the new algorithm since it is as simple as standard EM, the performance is either better or similar to EM, and the computation complexity is lower at each iteration.",
                "It is worth mentioning that even if the original problem space is not sparse, sparseness can be created artificially when a recommendation system uses user-specific feature selection techniques to reduce the noise and user model complexity.",
                "The proposed technique can also be adapted to improve the learning in such a scenario.",
                "We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU.",
                "The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear modeling approach to build a practical large scale system, even though the literature have demonstrated the effectiveness of the models in many applications.",
                "Our work is one major step on the road to make Bayesian hierarchical linear models more practical.",
                "The proposed new technique can be easily adapted to run on a cluster of machines, and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users.",
                "The research has much potential to benefit people using EM algorithm on many other IR problems as well as machine learning problems.",
                "EM algorithm is a commonly used machine <br>learning technique</br>.",
                "It is used to find model parameters in many IR problems where the training data is very sparse.",
                "Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering, the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems. 8.",
                "ACKNOWLEDGMENTS We thank Wei Xu, David Lewis and anonymous reviewers for valuable feedback on the work described in this paper.",
                "Part of the work was supported by Yahoo, Google, the Petascale Data Storage Institute and the Institute for Scalable Scientific Data Management.",
                "Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors, and do not necessarily reflect those of the sponsors. 9.",
                "REFERENCES [1] C. Basu, H. Hirsh, and W. Cohen.",
                "Recommendation as classification: Using social and content-based information in recommendation.",
                "In Proceedings of the Fifteenth National Conference on Artificial Intelligence, 1998. [2] J. S. Breese, D. Heckerman, and C. Kadie.",
                "Empirical analysis of predictive algorithms for collaborative filtering.",
                "Technical report, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan.",
                "Document filtering with inference networks.",
                "In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor, and A. Vinokourov.",
                "Kernel method for document filtering.",
                "In The Eleventh Text REtrieval Conference (TREC11).",
                "National Institute of Standards and Technology, special publication 500-249, 2003. [5] C. Chelba and A. Acero.",
                "Adaptation of maximum entropy capitalizer: Little data can help a lot.",
                "In D. Lin and D. Wu, editors, Proceedings of EMNLP 2004, pages 285-292, Barcelona, Spain, July 2004.",
                "Association for Computational Linguistics. [6] B. Croft and J. Lafferty, editors.",
                "Language Modeling for Information Retrieval.",
                "Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov, and A. Genkin.",
                "Constructing informative prior distributions from domain knowledge in text classification.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 493-500, New York, NY, USA, 2006.",
                "ACM Press. [8] J. Delgado and N. Ishii.",
                "Memory-based weightedmajority prediction for recommender systems.",
                "In ACM SIGIR99 Workshop on Recommender Systems, 1999. [9] GroupLens.",
                "Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman.",
                "A tutorial on learning with bayesian networks.",
                "In M. Jordan, editor, Learning in Graphical Models.",
                "Kluwer Academic, 1998. [11] J. L. Herlocker, J.",
                "A. Konstan, A. Borchers, and J. Riedl.",
                "An algorithmic framework for performing collaborative filtering.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 230-237, New York, NY, USA, 1999.",
                "ACM Press. [12] T. Hofmann and J. Puzicha.",
                "Latent class models for collaborative filtering.",
                "In IJCAI 99: Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 688-693, San Francisco, CA, USA, 1999.",
                "Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).",
                "Internet movie database. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai, and L. Si.",
                "An automatic weighting scheme for collaborative filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 337-344, New York, NY, USA, 2004.",
                "ACM Press. [15] J.",
                "A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl.",
                "GroupLens: Applying collaborative filtering to Usenet news.",
                "Communications of the ACM, 40(3):77-87, 1997. [16] D. Lewis.",
                "Applying support vector machines to the TREC-2001 batch filtering and routing tasks.",
                "In Proceedings of the Eleventh Text REtrieval Conference (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee, , and P. Yu.",
                "Text classification by labeling words.",
                "In Proceedings of The Nineteenth National Conference on Artificial Intelligence (AAAI-2004), July 25-29, 2004. [18] P. Melville, R. J. Mooney, and R. Nagarajan.",
                "Content-boosted collaborative filtering for improved recommendations.",
                "In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002), Edmonton, Canada, 2002. [19] Netflix.",
                "Netflix prize. http://www.netflixprize.com (visited on Nov. 30, 2006), 2006. [20] S. Robertson and K. Sparck-Jones.",
                "Relevance weighting of search terms.",
                "In Journal of the American Society for Information Science, volume 27, pages 129-146, 1976. [21] J. Wang, A. P. de Vries, and M. J. T. Reinders.",
                "Unifying user-based and item-based collaborative filtering approaches by similarity fusion.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 501-508, New York, NY, USA, 2006.",
                "ACM Press. [22] X. Wu and R. K. Srihari.",
                "Incorporating prior knowledge with weighted margin support vector machines.",
                "In Proc.",
                "ACM Knowledge Discovery Data Mining Conf. (ACM SIGKDD 2004), Aug. 2004. [23] Y. Yang, S. Yoo, J. Zhang, and B. Kisiel.",
                "Robustness of adaptive filtering methods in a cross-benchmark evaluation.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2005. [24] K. Yu, V. Tresp, and A. Schwaighofer.",
                "Learning gaussian processes from multiple tasks.",
                "In ICML 05: Proceedings of the 22nd international conference on Machine learning, pages 1012-1019, New York, NY, USA, 2005.",
                "ACM Press. [25] K. Yu, V. Tresp, and S. Yu.",
                "A nonparametric hierarchical bayesian framework for information filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 353-360.",
                "ACM Press, 2004. [26] X. Zhu.",
                "Semi-supervised learning literature survey.",
                "Technical report, University of Wisconsin - Madison, December 9, 2006. [27] P. Zigoris and Y. Zhang.",
                "Bayesian adaptive user profiling with explicit & implicit feedback.",
                "In Conference on Information and Knowledge Mangement 2006, 2006."
            ],
            "original_annotated_samples": [
                "This paper proposes a new fast <br>learning technique</br> to learn a large number of individual user profiles.",
                "The experimental setting and results used to validate the proposed <br>learning technique</br> are reported in Sections 5 and 6.",
                "This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better <br>learning technique</br> called Modified EM.",
                "EM algorithm is a commonly used machine <br>learning technique</br>."
            ],
            "translated_annotated_samples": [
                "Este documento propone una nueva <br>técnica de aprendizaje</br> rápido para aprender un gran número de perfiles de usuario individuales.",
                "La configuración experimental y los resultados utilizados para validar la <br>técnica de aprendizaje</br> propuesta se informan en las Secciones 5 y 6.",
                "Este artículo examinó la debilidad del enfoque de aprendizaje basado en EM popular para modelos lineales jerárquicos bayesianos y propuso una <br>técnica de aprendizaje</br> mejorada llamada EM Modificado.",
                "El algoritmo EM es una <br>técnica de aprendizaje</br> automático comúnmente utilizada."
            ],
            "translated_text": "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual. Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un modelo jerárquico bayesiano. Aprender los parámetros del modelo para optimizar la verosimilitud conjunta de los datos de millones de usuarios es muy costoso computacionalmente. El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de datos en aplicaciones de IR. Este documento propone una nueva <br>técnica de aprendizaje</br> rápido para aprender un gran número de perfiles de usuario individuales. La eficacia y eficiencia del algoritmo propuesto están justificadas por la teoría y demostradas en datos reales de usuarios de Netflix y MovieLens. Categorías y Descriptores de Asignaturas: B.3.3 [Búsqueda y Recuperación de Información]: Filtrado de información Términos Generales: Algoritmos 1. La personalización es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales. Por ejemplo, las tiendas en línea, como Amazon y Netflix, ofrecen recomendaciones personalizadas de productos o servicios adicionales basadas en el historial de un usuario. Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de un usuario a partir de su historial. Un tema importante de personalización estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados basados en el contenido. Estos sistemas aprenden perfiles específicos de usuario a partir de la retroalimentación del usuario para poder recomendar información adaptada a los intereses de cada usuario sin necesidad de que el usuario realice una consulta explícita. Aprender los perfiles de usuario es el problema central de estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica qué tan relevante es un documento para el usuario. Uno de los principales desafíos de construir un sistema de recomendación o personalización es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña. Esto se conoce como el problema de inicio en frío. Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente retroalimentación de ese usuario para aprender un perfil de usuario confiable. Se ha realizado mucha investigación sobre cómo mejorar la precisión de clasificación cuando la cantidad de datos de entrenamiento etiquetados es pequeña. El enfoque de aprendizaje semisupervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26]. Otro enfoque es utilizar el conocimiento del dominio. Los investigadores han modificado diferentes algoritmos de aprendizaje, como NaïveBayes [17], regresión logística [7] y SVMs [22], para integrar el conocimiento del dominio en un clasificador de texto. El tercer enfoque consiste en tomar datos de entrenamiento de otros recursos [5][7]. La efectividad de estos enfoques diferentes es mixta, debido a qué tan bien se ajusta la suposición del modelo subyacente a los datos. Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano. Varios investigadores han demostrado que este enfoque intercambia eficazmente entre la información compartida y la específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario[27][25]. Para aprender un modelo jerárquico bayesiano, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados. Un sistema de recomendación maduro generalmente funciona para millones de usuarios. Es bien sabido que aprender los parámetros óptimos de un modelo jerárquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios. El algoritmo EM es una técnica comúnmente utilizada para el aprendizaje de parámetros debido a su simplicidad y garantía de convergencia. Sin embargo, un sistema de recomendación basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso. Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM tering, o filtrado colaborativo basado en elementos. En este documento, las palabras filtrado y recomendación se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de las variables de entrada. También encontramos que actualizar el parámetro del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones. Este documento modifica el algoritmo EM estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos algoritmo EM modificado. La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M utilizamos la solución analítica en lugar de la solución numérica estimada en el paso E para esos parámetros. Esto reduce considerablemente la computación en una sola iteración de EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales. La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de regresión lineal jerárquica bayesiana utilizado para recomendaciones basadas en contenido. La sección 4 describe cómo aprender los parámetros del modelo utilizando el algoritmo EM estándar, junto con el uso de la nueva técnica propuesta en este artículo. La configuración experimental y los resultados utilizados para validar la <br>técnica de aprendizaje</br> propuesta se informan en las Secciones 5 y 6. La sección 7 resume y ofrece observaciones finales. 2. TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de IR desde la década de 1970. Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus filtrado colaborativo. El filtrado basado en contenido estudia el escenario en el que un sistema de recomendación monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente. El usuario puede leer los documentos entregados y proporcionar retroalimentación explícita de relevancia, la cual el sistema de filtrado utiliza para actualizar el perfil del usuario mediante modelos de recuperación de retroalimentación de relevancia (por ejemplo,). Modelos booleanos, modelos de espacio vectorial, modelos probabilísticos tradicionales [20], redes de inferencia [3] y modelos de lenguaje [6]) o algoritmos de aprendizaje automático (por ejemplo, Máquinas de Vectores de Soporte (SVM), agrupamiento de K vecinos más cercanos (K-NN), redes neuronales, regresión logística o Winnow [16] [4] [23]. El filtrado colaborativo va más allá de simplemente usar el contenido de un documento para recomendar elementos a un usuario, aprovechando la información de otros usuarios con gustos y preferencias similares en el pasado. Se han utilizado heurísticas basadas en memoria y enfoques basados en modelos en la tarea de filtrado colaborativo [15] [8] [2] [14] [12] [11]. Este artículo contribuye a la investigación de recomendaciones basadas en contenido al mejorar la eficiencia y efectividad de los modelos lineales jerárquicos bayesianos, los cuales tienen una sólida base teórica y un buen rendimiento empírico en tareas de recomendación[27][25]. Este artículo no tiene la intención de comparar el filtrado basado en contenido con el filtrado colaborativo ni de afirmar cuál es mejor. Creemos que cada uno complementa al otro, y que el filtrado basado en contenido es extremadamente útil para manejar nuevos documentos/artículos con poco o ningún feedback del usuario. Similar a otros investigadores[18][1][21], encontramos que un sistema de recomendación será más efectivo cuando se combinan ambas técnicas. Sin embargo, esto está fuera del alcance de este documento y, por lo tanto, no se discute aquí. 3. REGRESIÓN LINEAL HIERÁRQUICA BAYESIANA Suponga que hay M usuarios en el sistema. La tarea del sistema es recomendar documentos que sean relevantes para cada usuario. Para cada usuario, el sistema aprende un modelo de usuario a partir del historial de los usuarios. En el resto de este documento, utilizaremos las siguientes notaciones para representar las variables en el sistema. m = 1, 2, ..., M: El índice para cada usuario individual. M es el número total de usuarios. wm: El parámetro del modelo de usuario asociado con el usuario m. wm es un vector de dimensión K. j = 1, 2, ..., Jm: El índice para un conjunto de datos para el usuario m. Jm es el número de datos de entrenamiento para el usuario m. Dm = {(xm,j, ym,j)}: Un conjunto de datos asociado con el usuario m. xm,j es un vector de dimensión K que representa el j-ésimo documento de entrenamiento del usuario m. ym,j es un escalar que representa la etiqueta del documento xm,j. k = 1, 2, ..., K: El índice dimensional de la variable de entrada x. El enfoque de modelado jerárquico bayesiano ha sido ampliamente utilizado en aplicaciones reales de recuperación de información. Los modelos lineales jerárquicos bayesianos generalizados, uno de los modelos jerárquicos bayesianos más simples, son comúnmente utilizados y han logrado un buen rendimiento en tareas de filtrado colaborativo [25] y filtrado adaptativo basado en contenido [27]. La Figura 1 muestra la representación gráfica de un modelo jerárquico bayesiano. En este gráfico, cada modelo de usuario está representado por un vector aleatorio wm. Suponemos que un modelo de usuario se muestrea aleatoriamente de una distribución previa P(w|Φ). El sistema puede predecir la etiqueta de usuario y de un documento x dado una estimación de wm (o distribución de wms) utilizando una función y = f(x, w). El modelo se llama modelo lineal jerárquico bayesiano generalizado cuando y = f(wT x) es cualquier modelo lineal generalizado como regresión logística, SVM y regresión lineal. Para estimar de manera confiable el modelo de usuario wm, el sistema puede obtener información de otros usuarios a través de la prior Φ = (µ, Σ). Ahora observamos un modelo comúnmente utilizado donde y = wT x + , donde ∼ N(0, σ2 ) es un ruido aleatorio [25][27]. Suponga que cada modelo de usuario wm es una muestra independiente de una distribución poblacional P(w|Φ), la cual está regida por un hiperparámetro desconocido Φ. Que la distribución previa del modelo de usuario w sea una distribución gaussiana con parámetro Φ = (µ, Σ), que es la distribución previa comúnmente utilizada para modelos lineales. µ = (µ1, µ2, ..., µK) es un vector de K dimensiones que representa la media de la distribución gaussiana, y Σ es la matriz de covarianza de la gaussiana. Normalmente, se utiliza una distribución Normal N(0, aI) y una distribución Inverse Wishart P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) como hiperprior para modelar la distribución previa de µ y Σ respectivamente. Yo es la matriz identidad de dimensión K, y a, b y c son números reales. Con esta configuración, tenemos el siguiente modelo para el sistema: 1. µ y Σ se muestrean de N(0, aI) e IWν (aI), respectivamente. 2. La primera dimensión de x es una variable ficticia que siempre es igual a 1. Figura 1: Ilustración de las dependencias de variables en el modelo jerárquico. La calificación, y, para un documento, x, está condicionada al documento y al modelo de usuario, wm, asociado con el usuario m. Los usuarios comparten información sobre sus modelos a través de la prior, Φ = (µ, Σ). Para cada usuario m, wm se muestrea aleatoriamente de una distribución Normal: wm ∼ N(µ, Σ2 ) 3. Para cada elemento xm,j, ym,j se muestrea aleatoriamente de una distribución Normal: ym,j ∼ N(wT mxm,j, σ2). Que θ = (Φ, w1, w2, ..., wM) represente los parámetros de este sistema que necesitan ser estimados. La verosimilitud conjunta de todas las variables en el modelo probabilístico, que incluye los datos y los parámetros, es: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) Para simplificar, asumimos que a, b, c y σ son proporcionados al sistema. 4. APRENDIZAJE DE PARÁMETROS DEL MODELO Si se conoce el prior Φ, encontrar el óptimo wm es sencillo: se trata de una regresión lineal simple. Por lo tanto, nos enfocaremos en estimar Φ. La solución a priori máxima de Φ se da por ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Encontrar la solución óptima para el problema anterior es desafiante, ya que necesitamos integrar sobre todos los w = (w1, w2, ..., wM), que son variables ocultas no observadas. 4.1 Algoritmo EM para Modelos Lineales Jerárquicos Bayesianos En la Ecuación 5, Φ es el parámetro que necesita ser estimado, y el resultado depende de las variables latentes no observadas w. Este tipo de problema de optimización suele resolverse mediante el algoritmo EM. Aplicando EM al problema anterior, el conjunto de modelos de usuario w son las variables ocultas no observables y tenemos: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw. Basándonos en la derivación de las fórmulas EM presentadas en [24], tenemos los siguientes pasos de Expectation-Maximization para encontrar los hiperparámetros óptimos. Por razones de espacio, omitimos la derivación en este artículo ya que no es el enfoque de nuestro trabajo. Paso E: Para cada usuario m, estime la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual del prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) donde Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j Paso M: Optimice el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Muchos sistemas de IR impulsados por aprendizaje automático utilizan una estimación puntual de los parámetros en diferentes etapas del sistema. Sin embargo, estamos estimando la distribución posterior de las variables en el paso E. Esto evita el sobreajuste de wm a los datos de un usuario en particular, que pueden ser pequeños y ruidosos. Una discusión detallada sobre este tema aparece en [10]. 4.2 Nuevo Algoritmo: EM Modificado. Aunque el algoritmo EM es ampliamente estudiado y utilizado en aplicaciones de aprendizaje automático, utilizar el proceso EM mencionado anteriormente para resolver modelos lineales jerárquicos bayesianos en sistemas de recuperación de información a gran escala sigue siendo demasiado costoso computacionalmente. En esta sección, describimos por qué la tasa de aprendizaje del algoritmo EM es lenta en nuestra aplicación e introducimos una nueva técnica para hacer que el aprendizaje del modelo lineal jerárquico bayesiano sea escalable. La derivación del nuevo algoritmo de aprendizaje estará basada en el algoritmo EM descrito en la sección anterior. Primero, las matrices de covarianza Σ2 , Σ2 m suelen ser demasiado grandes para ser computacionalmente factibles. Por simplicidad, y como práctica común en IR, no modelamos la correlación entre características. Así aproximamos estas matrices con matrices diagonales de dimensión K. En el resto del documento, utilizamos estos símbolos para representar sus aproximaciones diagonales: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     En segundo lugar, y lo más importante, el espacio de entrada es muy disperso y hay muchas dimensiones que no están relacionadas con un usuario particular en una aplicación de recuperación de información real. Por ejemplo, consideremos un sistema de recomendación de películas, con la variable de entrada x representando una película en particular. Para la j-ésima película que el usuario m ha visto, sea xm,j,k = 1 si el director de la película es Jean-Pierre Jeunet (indexado por k). Aquí asumimos que si este director dirigió una película específica está representado por la k-ésima dimensión. Si el usuario m nunca ha visto una película dirigida por Jean-Pierre Jeunet, entonces la dimensión correspondiente siempre es cero (xm,j,k = 0 para todos los j). Una desventaja importante del algoritmo EM es que la importancia de una característica, µk, puede estar fuertemente dominada por usuarios que nunca han encontrado esta característica (es decir, j xm,j,k = 0) en el paso M (Ecuación 8). Suponga que 100 de cada 1 millón de usuarios han visto la película dirigida por Jean-Pierre Jeunet, y que los espectadores han calificado todas sus películas como excelentes. Intuitivamente, él es un buen director y el peso para él (µk) debería ser alto. Antes de la iteración de EM, el valor inicial de µ suele establecerse en 0. Dado que los otros 999,900 usuarios no han visto esta película, sus pesos correspondientes (w1,k, w2,k, ..., wm,k..., w999900,k) para ese director serían muy pequeños inicialmente. Por lo tanto, el peso correspondiente del director en el µk anterior en el primer paso M sería muy bajo, y la varianza σm,k será grande (Ecuaciones 8 y 7). Es indeseable que los usuarios que nunca han visto ninguna película producida por el director influyan tanto en la importancia del director. Esto hace que la convergencia del algoritmo EM estándar sea muy lenta. Ahora veamos si podemos mejorar la velocidad de aprendizaje del algoritmo. Sin pérdida de generalidad, asumamos que la k-ésima dimensión de la variable de entrada x no está relacionada con un usuario particular m. Lo que queremos decir es que xm,j,k = 0 para todo j = 1, ..., Jm. Es sencillo demostrar que la k-ésima fila y la k-ésima columna de Sxx,m están completamente llenas de ceros, y que la k-ésima dimensión de Sxy,m también se anula. Por lo tanto, la dimensión k correspondiente de la media de los modelos de usuario, ¯wm, debería ser igual a la del anterior: ¯wm,k = µk, con la covarianza correspondiente de σm,k = σk. En el paso M, el algoritmo EM estándar utiliza la solución numérica de la distribución P(wm|Dm, Φ) estimada en el paso E (Ecuación 8 y Ecuación 7). Sin embargo, las soluciones numéricas son muy poco confiables para ¯wm,k y σm,k cuando la k-ésima dimensión no está relacionada con el m-ésimo usuario. Un enfoque mejor es utilizar las soluciones analíticas ¯wm,k = µk, y σm,k = σk para los pares no relacionados (m, k), junto con la solución numérica estimada en el paso E para los otros pares (m, k). Así obtenemos el siguiente nuevo algoritmo EM similar: Paso E modificado: Para cada usuario m, estimar la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual de σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) donde sxx,m,k = j x2 m,j,k y sxy,m,k = j xm,j,kym,j Paso M modificado Optimizar el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E para pares de usuario-característica relacionados. El paso M utiliza implícitamente la solución analítica para pares de usuario-característica no relacionados. µk = 1 Mk m:relacionado ¯wm,k (12) σ2 k = 1 Mk m:relacionado σ2 m,k + ( ¯wm,k − µk)( ¯wm,k − µk)T (13) donde Mk es el número de usuarios relacionados con la característica k. Solo estimamos la diagonal de Σ2 m y Σ, ya que estamos utilizando la aproximación diagonal de las matrices de covarianza. Para estimar ¯wm, solo necesitamos calcular las soluciones numéricas para las dimensiones que están relacionadas con el usuario m. Para estimar σ2 k y µk, solo sumamos sobre los usuarios que están relacionados con la k-ésima característica. Hay dos beneficios principales del nuevo algoritmo. Primero, dado que solo se necesitan los pares relacionados (m, k) en el paso M modificado, la complejidad computacional en una sola iteración de EM es mucho menor cuando los datos son dispersos y muchos de los pares (m, k) no están relacionados. En segundo lugar, los parámetros estimados en el paso M modificado (Ecuaciones 12 - 13) son más precisos que el paso M estándar descrito en la Sección 4.1 porque se utilizaron soluciones analíticas exactas ¯wm,k = µk y σm,k = σk para los pares no relacionados (m, k) en el nuevo algoritmo en lugar de una solución aproximada como en el algoritmo estándar. METODOLOGÍA EXPERIMENTAL 5.1 Conjunto de Datos de Evaluación Para evaluar la técnica propuesta, utilizamos los siguientes tres conjuntos de datos principales (Tabla 1): Datos de MovieLens: Este conjunto de datos fue creado combinando las valoraciones de relevancia del conjunto de datos de MovieLens[9] con documentos de la Base de Datos de Películas en Internet (IMDB). MovieLens permite a los usuarios clasificar cuánto disfrutaron una película específica en una escala del 1 al 5. Esta calificación de simpatía se utilizó como una medida de cuán relevante es el documento que representa la película correspondiente para el usuario. Consideramos los documentos con puntuaciones de 4 o 5 como relevantes, y los documentos con una puntuación de 1 a 3 como irrelevantes para el usuario. MovieLens proporcionó juicios de relevancia sobre 3,057 documentos de 6,040 usuarios diferentes. En promedio, cada usuario calificó 151 películas, de las cuales 87 fueron consideradas relevantes. La puntuación promedio para un documento fue de 3.58. Los documentos que representan cada película fueron construidos a partir de la porción de la base de datos de IMDB que está disponible para descarga pública[13]. Basándonos en esta base de datos, creamos un documento por película que contenía la información relevante sobre ella (por ejemplo, directores, actores, etc.). Tabla 1: Estadísticas del conjunto de datos. En Reuters, el número de calificaciones para un usuario simulado es el número de documentos relevantes para el tema correspondiente. Datos Usuarios Documentos Calificaciones por Usuario MovieLens 6,040 3,057 151 Netflix-todos 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Datos de Netflix: Este conjunto de datos fue construido combinando documentos sobre películas obtenidos de la web con un conjunto de juicios de relevancia de clientes reales de alquiler de películas de Netflix[19]. Netflix proporciona públicamente las evaluaciones de relevancia de 480,189 clientes anónimos. Hay alrededor de 100 millones de calificaciones en una escala del 1 al 5 para 17,770 documentos. Similar a MovieLens, consideramos documentos con puntuaciones de 4 o 5 de agradabilidad como relevantes. Este número se redujo a 1000 clientes mediante muestreo aleatorio. El cliente promedio en el conjunto de datos reducido proporcionó 127 juicios, de los cuales 70 fueron considerados relevantes. La puntuación promedio de los documentos es de 3.55. Datos de Reuters: Este es el Corpus de Reuters, Volumen 1. Cubre 810,000 noticias en inglés de Reuters desde el 20 de agosto de 1996 hasta el 19 de agosto de 1997. Solo se utilizaron las primeras 100,000 noticias en nuestros experimentos. El corpus de Reuters viene con una jerarquía de temas. Cada documento se asigna a una de varias ubicaciones en el árbol jerárquico. El primer nivel del árbol contiene cuatro temas, denotados como C, E, M y G. Para los experimentos en este artículo, el árbol fue cortado en el nivel 1 para crear cuatro árboles más pequeños, cada uno de los cuales corresponde a un conjunto de datos más pequeño: Reuters-E, Reuters-C, Reuters-M y Reuters-G. Para cada conjunto de datos pequeño, creamos varios perfiles, un perfil para cada nodo en un subárbol, para simular múltiples usuarios, cada uno con una definición de relevancia relacionada pero separada. Todos los perfiles de usuario en una sub-rama se supone que comparten la misma distribución de modelo previo. Dado que este corpus indica explícitamente solo los documentos relevantes para un tema (usuario), todos los demás documentos se consideran irrelevantes. 5.2 Evaluación Diseñamos los experimentos para responder a las siguientes tres preguntas: 1. ¿Necesitamos hacer el esfuerzo de utilizar un enfoque bayesiano y aprender una distribución a priori de otros usuarios? 2. ¿El nuevo algoritmo funciona mejor que el algoritmo EM estándar para aprender el modelo lineal jerárquico bayesiano? 3. ¿Puede el nuevo algoritmo aprender rápidamente muchos modelos de usuario? Para responder a la primera pregunta, comparamos los modelos jerárquicos bayesianos con los modelos de regresión lineal regularizados Norm-2 comúnmente utilizados. De hecho, el enfoque comúnmente utilizado es equivalente al modelo aprendido al final de la primera iteración de EM. Para responder a la segunda pregunta, comparamos el nuevo algoritmo propuesto con el algoritmo EM estándar para ver si el nuevo algoritmo de aprendizaje es mejor. Para responder a la tercera pregunta, probamos la eficiencia del nuevo algoritmo en todo el conjunto de datos de Netflix, donde aproximadamente medio millón de modelos de usuario deben ser aprendidos juntos. Para los conjuntos de datos de MovieLens y Netflix, la efectividad del algoritmo se midió mediante el error cuadrático medio, mientras que en el conjunto de datos de Reuters se utilizó el error de clasificación porque era más informativo. Primero evaluamos el rendimiento en cada usuario individual, y luego estimamos el promedio macro sobre todos los usuarios. Se realizaron pruebas estadísticas (pruebas t) para determinar si los resultados son significativos. Para los experimentos en los conjuntos de datos de MovieLens y Netflix, utilizamos una muestra aleatoria del 90% de cada usuario para entrenamiento, y el resto para pruebas. En el conjunto de datos de Reuters, debido a que hay demasiados documentos relevantes para cada tema en el corpus, utilizamos una muestra aleatoria del 10% de cada tema para el entrenamiento, y el 10% de los documentos restantes para las pruebas. Para todas las ejecuciones, establecimos (a, b, c, Σ) = (0.1, 10, 0.1, 1) manualmente. 6. RESULTADOS EXPERIMENTALES Las Figuras 2, 3 y 4 muestran que en todos los conjuntos de datos, el enfoque de modelado jerárquico bayesiano tiene una mejora estadísticamente significativa sobre el modelo de regresión lineal regularizado, que es equivalente a los modelos jerárquicos bayesianos aprendidos en la primera iteración. Un análisis adicional muestra una correlación negativa entre la cantidad de datos de entrenamiento para un usuario y la mejora que obtiene el sistema. Esto sugiere que la información prestada de otros usuarios tiene mejoras más significativas para usuarios con menos datos de entrenamiento, lo cual es lo esperado. Sin embargo, la fuerza de la correlación varía entre los conjuntos de datos, y la cantidad de datos de entrenamiento no es la única característica que influirá en el rendimiento final. Las Figuras 2 y 3 muestran que el nuevo algoritmo propuesto funciona mejor que el algoritmo EM estándar en los conjuntos de datos de Netflix y MovieLens. Esto no es sorprendente ya que el número de pares de características-usuarios relacionados es mucho menor que el número de pares de características-usuarios no relacionados en estos dos conjuntos de datos, por lo que se espera que el nuevo algoritmo propuesto funcione mejor. La Figura 4 muestra que los dos algoritmos funcionan de manera similar en el conjunto de datos de Reuters-E. La precisión del nuevo algoritmo es similar a la del algoritmo EM estándar en cada iteración. Los patrones generales son muy similares en otros subconjuntos de Reuters. Un análisis adicional muestra que solo el 58% de los pares usuario-característica no están relacionados en este conjunto de datos. Dado que el número de pares usuario-característica no relacionados no es extremadamente grande, la dispersión no es un problema grave en el conjunto de datos de Reuters. Por lo tanto, los dos algoritmos de aprendizaje se desempeñan de manera similar. Los resultados sugieren que solo en un corpus donde el número de pares usuario-característica no relacionados es mucho mayor que el número de pares relacionados, como en el conjunto de datos de Netflix, la técnica propuesta obtendrá una mejora significativa sobre el EM estándar. Sin embargo, los experimentos también muestran que cuando la suposición no se cumple, el nuevo algoritmo no afecta el rendimiento. Aunque la técnica propuesta es más rápida que la estándar. Figura 2: Rendimiento en un subconjunto de Netflix con 1,000 usuarios. El nuevo algoritmo es estadísticamente significativamente mejor que el algoritmo EM en las iteraciones 2 a 10. Los modelos lineales regularizados con norma-2 son equivalentes a los modelos jerárquicos bayesianos aprendidos en la primera iteración, y son estadísticamente significativamente peores que los modelos jerárquicos bayesianos. Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional Figura 3: Rendimiento en un subconjunto de MovieLens con 1,000 usuarios. El nuevo algoritmo es significativamente mejor estadísticamente que el algoritmo EM en las iteraciones 2 a 17 (evaluado con error cuadrático medio). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iteraciones ErrorCuadráticoMedio Nuevo Algoritmo EM Tradicional 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iteraciones Error de Clasificación Nuevo Algoritmo EM Tradicional Figura 4: Rendimiento en un subconjunto de Reuters-E con 26 perfiles. Las actuaciones en Reuters-C, Reuters-M, Reuters-G son similares. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional EM, ¿realmente puede aprender rápidamente millones de modelos de usuario? Nuestros resultados muestran que el algoritmo EM modificado converge rápidamente, y 2-3 iteraciones del EM modificado darían como resultado una estimación confiable. Evaluamos el algoritmo en todo el conjunto de datos de Netflix (480,189 usuarios, 159,836 características y 100 millones de valoraciones) ejecutándolo en un solo PC con CPU (2GB de memoria, P4 3GHz). El sistema completó una iteración EM modificada en aproximadamente 4 horas. Esto demuestra que la técnica propuesta puede manejar eficientemente sistemas a gran escala como Netflix. CONCLUSIÓN El aprendizaje de perfiles de usuario basado en contenido es un problema importante y es clave para proporcionar recomendaciones personales a un usuario, especialmente para recomendar nuevos elementos con un pequeño número de calificaciones. El enfoque de modelado jerárquico bayesiano se está convirtiendo en un enfoque importante para el aprendizaje de perfiles de usuario debido a su capacidad teóricamente justificada para ayudar a un usuario a través de la transferencia de información de otros usuarios mediante hiperpriors. Este artículo examinó la debilidad del enfoque de aprendizaje basado en EM popular para modelos lineales jerárquicos bayesianos y propuso una <br>técnica de aprendizaje</br> mejorada llamada EM Modificado. Demostramos que la nueva técnica es teóricamente más eficiente computacionalmente que el algoritmo EM estándar. La evaluación en los conjuntos de datos de MovieLens y Netflix demostró la efectividad de la nueva técnica cuando los datos son dispersos, lo que significa que la proporción de pares de usuario-característica relacionados con respecto a los pares no relacionados es pequeña. La evaluación en el conjunto de datos de Reuters mostró que la nueva técnica tuvo un rendimiento similar al algoritmo EM estándar cuando la condición de dispersión no se cumple. En general, es mejor utilizar el nuevo algoritmo ya que es tan simple como el EM estándar, el rendimiento es igual o mejor que el del EM, y la complejidad computacional es menor en cada iteración. Vale la pena mencionar que aunque el espacio de problemas original no sea disperso, la dispersión puede crearse artificialmente cuando un sistema de recomendación utiliza técnicas de selección de características específicas del usuario para reducir el ruido y la complejidad del modelo del usuario. La técnica propuesta también puede adaptarse para mejorar el aprendizaje en dicho escenario. También demostramos que la técnica propuesta puede aprender medio millón de perfiles de usuario a partir de 100 millones de valoraciones en unas pocas horas con una sola CPU. La investigación es importante porque la escalabilidad es una preocupación importante para los investigadores al utilizar el enfoque de modelado lineal jerárquico bayesiano para construir un sistema a gran escala práctico, a pesar de que la literatura ha demostrado la efectividad de los modelos en muchas aplicaciones. Nuestro trabajo es un paso importante en el camino para hacer que los modelos lineales jerárquicos bayesianos sean más prácticos. La nueva técnica propuesta se puede adaptar fácilmente para ejecutarse en un clúster de máquinas, y así acelerar aún más el proceso de aprendizaje para manejar un sistema a mayor escala con cientos de millones de usuarios. La investigación tiene mucho potencial para beneficiar a las personas utilizando el algoritmo EM en muchos otros problemas de IR, así como en problemas de aprendizaje automático. El algoritmo EM es una <br>técnica de aprendizaje</br> automático comúnmente utilizada. Se utiliza para encontrar los parámetros del modelo en muchos problemas de IR donde los datos de entrenamiento son muy dispersos. Aunque nos estamos centrando en los modelos lineales jerárquicos bayesianos para recomendación y filtrado, la nueva idea de utilizar una solución analítica en lugar de una solución numérica para pares de usuario-característica no relacionados en el paso M podría adaptarse a muchos otros problemas. 8. AGRADECIMIENTOS Agradecemos a Wei Xu, David Lewis y a los revisores anónimos por sus valiosos comentarios sobre el trabajo descrito en este artículo. Parte del trabajo fue apoyado por Yahoo, Google, el Instituto de Almacenamiento de Datos a Escala Peta y el Instituto de Gestión de Datos Científicos Escalables. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las de los patrocinadores. REFERENCIAS [1] C. Basu, H. Hirsh y W. Cohen. Recomendación como clasificación: Utilizando información social y basada en contenido en la recomendación. En Actas de la Decimoquinta Conferencia Nacional de Inteligencia Artificial, 1998. [2] J. S. Breese, D. Heckerman y C. Kadie. Análisis empírico de algoritmos predictivos para filtrado colaborativo. Informe técnico, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan. Filtrado de documentos con redes de inferencia. En Actas de la Decimonovena Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor y A. Vinokourov. Método del núcleo para el filtrado de documentos. En la Undécima Conferencia de Recuperación de Información de Texto (TREC11). Instituto Nacional de Normas y Tecnología, publicación especial 500-249, 2003. [5] C. Chelba y A. Acero. Adaptación del capitalizador de entropía máxima: Poca información puede ayudar mucho. En D. Lin y D. Wu, editores, Actas de EMNLP 2004, páginas 285-292, Barcelona, España, julio de 2004. Asociación de Lingüística Computacional. [6] B. Croft y J. Lafferty, editores. Modelado de lenguaje para recuperación de información. Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov y A. Genkin. Construyendo distribuciones a priori informativas a partir del conocimiento del dominio en la clasificación de textos. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 493-500, Nueva York, NY, EE. UU., 2006. ACM Press. [8] J. Delgado y N. Ishii. Predicción basada en memoria ponderada para sistemas de recomendación. En el Taller ACM SIGIR99 sobre Sistemas de Recomendación, 1999. [9] GroupLens. Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman. Un tutorial sobre el aprendizaje con redes bayesianas. En M. Jordan, editor, Aprendizaje en Modelos Gráficos. Kluwer Academic, 1998. [11] J. L. Herlocker, J. \n\nKluwer Academic, 1998. [11] J. L. Herlocker, J. A. Konstan, A. Borchers y J. Riedl. Un marco algorítmico para realizar filtrado colaborativo. En SIGIR 99: Actas de la 22ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 230-237, Nueva York, NY, EE. UU., 1999. ACM Press. [12] T. Hofmann y J. Puzicha. Modelos de clases latentes para filtrado colaborativo. En IJCAI 99: Actas de la Decimosexta Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 688-693, San Francisco, CA, EE. UU., 1999. Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).\nMorgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB). Base de datos de películas en internet. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai y L. Si. Un esquema de ponderación automática para filtrado colaborativo. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 337-344, Nueva York, NY, EE. UU., 2004. ACM Press. [15] J. A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon y J. Riedl. GroupLens: Aplicando filtrado colaborativo a las noticias de Usenet. Comunicaciones de la ACM, 40(3):77-87, 1997. [16] D. Lewis. Aplicando máquinas de vectores de soporte a las tareas de filtrado y enrutamiento por lotes de TREC-2001. En Actas de la Undécima Conferencia de Recuperación de Texto (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee y P. Yu. Clasificación de texto mediante etiquetado de palabras. En Actas de la Decimonovena Conferencia Nacional de Inteligencia Artificial (AAAI-2004), 25-29 de julio de 2004. [18] P. Melville, R. J. Mooney y R. Nagarajan. Filtrado colaborativo potenciado por contenido para recomendaciones mejoradas. En Actas de la Decimoctava Conferencia Nacional de Inteligencia Artificial (AAAI-2002), Edmonton, Canadá, 2002. [19] Netflix. Premio Netflix. http://www.netflixprize.com (visitado el 30 de noviembre de 2006), 2006. [20] S. Robertson y K. Sparck-Jones. Ponderación de la relevancia de los términos de búsqueda. En Journal of the American Society for Information Science, volumen 27, páginas 129-146, 1976. [21] J. Wang, A. P. de Vries y M. J. T. Reinders. Unificando enfoques de filtrado colaborativo basados en usuarios y en elementos mediante la fusión de similitudes. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 501-508, Nueva York, NY, EE. UU., 2006. ACM Press. [22] X. Wu y R. K. Srihari. Incorporando conocimientos previos con máquinas de vectores de soporte de margen ponderado. En Proc. Conferencia de Minería de Datos y Descubrimiento de Conocimiento de ACM (ACM SIGKDD 2004), agosto de 2004. [23] Y. Yang, S. Yoo, J. Zhang y B. Kisiel. Robustez de los métodos de filtrado adaptativo en una evaluación de referencia cruzada. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 2005. [24] K. Yu, V. Tresp y A. Schwaighofer. Aprendiendo procesos gaussianos de múltiples tareas. En ICML 05: Actas de la 22ª conferencia internacional sobre aprendizaje automático, páginas 1012-1019, Nueva York, NY, EE. UU., 2005. ACM Press. [25] K. Yu, V. Tresp, y S. Yu. Un marco bayesiano jerárquico no paramétrico para el filtrado de información. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 353-360. ACM Press, 2004. [26] X. Zhu. \n\nACM Press, 2004. [26] X. Zhu. Revisión de la literatura sobre aprendizaje semisupervisado. Informe técnico, Universidad de Wisconsin - Madison, 9 de diciembre de 2006. [27] P. Zigoris y Y. Zhang. Perfilado de usuario bayesiano adaptativo con retroalimentación explícita e implícita. En la Conferencia sobre Gestión de la Información y el Conocimiento 2006, 2006. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "ir": {
            "translated_key": "ir",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
                "A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model.",
                "Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive.",
                "The commonly used EM algorithm converges very slowly due to the sparseness of the data in <br>ir</br> applications.",
                "This paper proposes a new fast learning technique to learn a large number of individual user profiles.",
                "The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens.",
                "Categories and Subject Descriptors: B.3.3 [Information Search and Retrieval]: Information filtering General Terms: Algorithms 1.",
                "INTRODUCTION Personalization is the future of the Web, and it has achieved great success in industrial applications.",
                "For example, online stores, such as Amazon and Netflix, provide customized recommendations for additional products or services based on a users history.",
                "Recent offerings such as My MSN, My Yahoo!, My Google, and Google News have attracted much attention due to their potential ability to infer a users interests from his/her history.",
                "One major personalization topic studied in the information retrieval community is content-based personal recommendation systems1 .",
                "These systems learn user-specific profiles from user feedback so that they can recommend information tailored to each individual users interest without requiring the user to make an explicit query.",
                "Learning the user profiles is the core problem for these systems.",
                "A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user.",
                "One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small.",
                "This is known as the cold start problem.",
                "This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile.",
                "There has been much research on improving classification accuracy when the amount of labeled training data is small.",
                "The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal [26].",
                "Another approach is using domain knowledge.",
                "Researchers have modified different learning algorithms, such as Na¨ıveBayes [17], logistic regression [7], and SVMs [22], to integrate domain knowledge into a text classifier.",
                "The third approach is borrowing training data from other resources [5][7].",
                "The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data.",
                "One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach.",
                "Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial performance for each user[27][25].",
                "In order to learn a Bayesian hierarchical model, the system usually tries to find the most likely model parameters for the given data.",
                "A mature recommendation system usually works for millions of users.",
                "It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users.",
                "The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee.",
                "However, a content based recommendation system often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector.",
                "With careful analysis of the EM algorithm in this scenario (Section 4), we find that the EM tering, or item-based collaborative filtering.",
                "In this paper, the words filtering and recommendation are used interchangeably. algorithm converges very slowly due to the sparseness of the input variables.",
                "We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O(MK), where M is the number of users and K is the number of dimensions.",
                "This paper modifies the standard EM algorithm to create an improved learning algorithm, which we call the Modified EM algorithm.",
                "The basic idea is that instead of calculating the numerical solution for all the user profile parameters, we derive the analytical solution of the parameters for some feature dimensions, and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters.",
                "This greatly reduces the computation at a single EM iteration, and also has the benefit of increasing the convergence speed of the learning algorithm.",
                "The proposed technique is not only well supported by theory, but also by experimental results.",
                "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression modeling framework used for content-based recommendations.",
                "Section 4 describes how to learn the model parameters using the standard EM algorithm, along with using the new technique proposed in this paper.",
                "The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6.",
                "Section 7 summarizes and offers concluding remarks. 2.",
                "RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the <br>ir</br> community since the 1970s.",
                "The approaches that have been used to solve this problem can be roughly classified into two major categories: content based filtering versus collaborative filtering.",
                "Content-based filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user.",
                "The user may read the delivered documents and provide explicit relevance feedback, which the filtering system then uses to update the users profile using relevance feedback retrieval models (e.g.",
                "Boolean models, vector space models, traditional probabilistic models [20] , inference networks [3] and language models [6]) or machine learning algorithms (e.g.",
                "Support Vector Machines (SVM), K nearest neighbors (K-NN) clustering, neural networks, logistic regression, or Winnow [16] [4] [23]).",
                "Collaborative filtering goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past.",
                "Memorybased heuristics and model based approaches have been used in collaborative filtering task [15] [8] [2] [14] [12] [11].",
                "This paper contributes to the content-based recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks[27][25].",
                "This paper does not intend to compare content-based filtering with collaborative filtering or claim which one is a better.",
                "We think each complements the other, and that content-based filtering is extremely useful for handling new documents/items with little or no user feedback.",
                "Similar to some other researchers[18][1][21], we found that a recommendation system will be more effective when both techniques are combined.",
                "However, this is beyond the scope of this paper and thus not discussed here. 3.",
                "BAYESIAN HIERARCHICAL LINEAR REGRESSION Assume there are M users in the system.",
                "The task of the system is to recommend documents that are relevant to each user.",
                "For each user, the system learns a user model from the users history.",
                "In the rest of this paper, we will use the following notations to represent the variables in the system. m = 1, 2, ..., M: The index for each individual user.",
                "M is the total number of users. wm: The user model parameter associated with user m. wm is a K dimensional vector. j = 1, 2, ..., Jm: The index for a set of data for user m. Jm is the number of training data for user m. Dm = {(xm,j, ym,j)}: A set of data associated with user m. xm,j is a K dimensional vector that represents the mth users jth training document.2 ym,j is a scalar that represents the label of document xm,j. k = 1, 2, ..., K: The dimensional index of input variable x.",
                "The Bayesian hierarchical modeling approach has been widely used in real-world information retrieval applications.",
                "Generalized Bayesian hierarchical linear models, one of the simplest Bayesian hierarchical models, are commonly used and have achieved good performance on collaborative filtering [25] and content-based adaptive filtering [27] tasks.",
                "Figure 1 shows the graphical representation of a Bayesian hierarchical model.",
                "In this graph, each user model is represented by a random vector wm.",
                "We assume a user model is sampled randomly from a prior distribution P(w|Φ).",
                "The system can predict the user label y of a document x given an estimation of wm (or wms distribution) using a function y = f(x, w).",
                "The model is called generalized Bayesian hierarchical linear model when y = f(wT x) is any generalized linear model such as logistic regression, SVM, and linear regression.",
                "To reliably estimate the user model wm, the system can borrow information from other users through the prior Φ = (µ, Σ).",
                "Now we look at one commonly used model where y = wT x + , where ∼ N(0, σ2 ) is a random noise [25][27].",
                "Assume that each user model wm is an independent draw from a population distribution P(w|Φ), which is governed by some unknown hyperparameter Φ.",
                "Let the prior distribution of user model w be a Gaussian distribution with parameter Φ = (µ, Σ), which is the commonly used prior for linear models. µ = (µ1, µ2, ..., µK ) is a K dimensional vector that represents the mean of the Gaussian distribution, and Σ is the covariance matrix of the Gaussian.",
                "Usually, a Normal distribution N(0, aI) and an Inverse Wishart distribution P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) are used as hyperprior to model the prior distribution of µ and Σ respectively.",
                "I is the K dimensional identity matrix, and a, b, and c are real numbers.",
                "With these settings, we have the following model for the system: 1. µ and Σ are sampled from N(0, aI) and IWν (aI), respectively. 2 The first dimension of x is a dummy variable that always equals to 1.",
                "Figure 1: Illustration of dependencies of variables in the hierarchical model.",
                "The rating, y, for a document, x, is conditioned on the document and the user model, wm, associated with the user m. Users share information about their models through the prior, Φ = (µ, Σ). 2.",
                "For each user m, wm is sampled randomly from a Normal distribution: wm ∼ N(µ, Σ2 ) 3.",
                "For each item xm,j, ym,j is sampled randomly from a Normal distribution: ym,j ∼ N(wT mxm,j, σ2 ).",
                "Let θ = (Φ, w1, w2, ..., wM ) represent the parameters of this system that needs to be estimated.",
                "The joint likelihood for all the variables in the probabilistic model, which includes the data and the parameters, is: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) For simplicity, we assume a, b, c, and σ are provided to the system. 4.",
                "MODEL PARAMETER LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple linear regression.",
                "Therefore, we will focus on estimating Φ.",
                "The maximum a priori solution of Φ is given by ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Finding the optimal solution for the above problem is challenging, since we need to integrate over all w = (w1, w2, ..., wM ), which are unobserved hidden variables. 4.1 EM Algorithm for Bayesian Hierarchical Linear Models In Equation 5, Φ is the parameter needs to be estimated, and the result depends on unobserved latent variables w. This kind of optimization problem is usually solved by the EM algorithm.",
                "Applying EM to the above problem, the set of user models w are the unobservable hidden variables and we have: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw Based on the derivation of the EM formulas presented in [24], we have the following Expectation-Maximization steps for finding the optimal hyperparameters.",
                "For space considerations, we omit the derivation in this paper since it is not the focus of our work.",
                "E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of the prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) where Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j M step: Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Many machine learning driven <br>ir</br> systems use a point estimate of the parameters at different stages in the system.",
                "However, we are estimating the posterior distribution of the variables at the E step.",
                "This avoids overfitting wm to a particular users data, which may be small and noisy.",
                "A detailed discussion about this subject appears in [10]. 4.2 New Algorithm: Modified EM Although the EM algorithm is widely studied and used in machine learning applications, using the above EM process to solve Bayesian hierarchical linear models in large-scale information retrieval systems is still too computationally expensive.",
                "In this section, we describe why the learning rate of the EM algorithm is slow in our application and introduce a new technique to make the learning of the Bayesian hierarchical linear model scalable.",
                "The derivation of the new learning algorithm will be based on the EM algorithm described in the previous section.",
                "First, the covariance matrices Σ2 , Σ2 m are usually too large to be computationally feasible.",
                "For simplicity, and as a common practice in <br>ir</br>, we do not model the correlation between features.",
                "Thus we approximate these matrices with K dimensional diagonal matrices.",
                "In the rest of the paper, we use these symbols to represent their diagonal approximations: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     Secondly, and most importantly, the input space is very sparse and there are many dimensions that are not related to a particular user in a real <br>ir</br> application.",
                "For example, let us consider a movie recommendation system, with the input variable x representing a particular movie.",
                "For the jth movie that the user m has seen, let xm,j,k = 1 if the director of the movie is Jean-Pierre Jeunet (indexed by k).",
                "Here we assume that whether or not that this director directed a specific movie is represented by the kth dimension.",
                "If the user m has never seen a movie directed by Jean-Pierre Jeunet, then the corresponding dimension is always zero (xm,j,k = 0 for all j) .",
                "One major drawback of the EM algorithm is that the importance of a feature, µk, may be greatly dominated by users who have never encountered this feature (i.e. j xm,j,k = 0) at the M step (Equation 8).",
                "Assume that 100 out of 1 million users have viewed the movie directed by Jean-Pierre Jeunet, and that the viewers have rated all of his movies as excellent.",
                "Intuitively, he is a good director and the weight for him (µk) should be high.",
                "Before the EM iteration, the initial value of µ is usually set to 0.",
                "Since the other 999,900 users have not seen this movie, their corresponding weights (w1,k, w2,k, ..., wm,k..., w999900,k) for that director would be very small initially.",
                "Thus the corresponding weight of the director in the prior µk at the first M step would be very low , and the variance σm,k will be large (Equations 8 and 7).",
                "It is undesirable that users who have never seen any movie produced by the director influence the importance of the director so much.",
                "This makes the convergence of the standard EM algorithm very slow.",
                "Now lets look at whether we can improve the learning speed of the algorithm.",
                "Without a loss of generality, let us assume that the kth dimension of the input variable x is not related to a particular user m. By which we mean, xm,j,k = 0 for all j = 1, ..., Jm.",
                "It is straightforward to prove that the kth row and kth column of Sxx,m are completely filled with zeros, and that the kth dimension of Sxy,m is zeroed as well.",
                "Thus the corresponding kth dimension of the user models mean, ¯wm, should be equal to that of the prior: ¯wm,k = µk, with the corresponding covariance of σm,k = σk.",
                "At the M step, the standard EM algorithm uses the numerical solution of the distribution P(wm|Dm, Φ) estimated at E step (Equation 8 and Equation 7).",
                "However, the numerical solutions are very unreliable for ¯wm,k and σm,k when the kth dimension is not related to the mth user.",
                "A better approach is using the analytical solutions ¯wm,k = µk, and σm,k = σk for the unrelated (m, k) pairs, along with the numerical solution estimated at E step for the other (m, k) pairs.",
                "Thus we get the following new EM-like algorithm: Modified E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) where sxx,m,k = j x2 m,j,k and sxy,m,k = j xm,j,kym,j Modified M Step Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step for related userfeature pairs.",
                "The M step implicitly uses the analytical solution for unrelated user-feature pairs. µk = 1 Mk m:related ¯wm,k (12) σ2 k = 1 Mk m:related σ2 m,k +( ¯wm,k − µk)( ¯wm,k − µk)T (13) where Mk is the number of users that are related to feature k We only estimate the diagonal of Σ2 m and Σ since we are using the diagonal approximation of the covariance matrices.",
                "To estimate ¯wm, we only need to calculate the numerical solutions for dimensions that are related to user m. To estimate σ2 k and µk, we only sum over users that are related to the kth feature.",
                "There are two major benefits of the new algorithm.",
                "First, because only the related (m, k) pairs are needed at the modified M step, the computational complexity in a single EM iteration is much smaller when the data is sparse, and many of (m, k) pairs are unrelated.",
                "Second, the parameters estimated at the modified M step (Equations 12 - 13) are more accurate than the standard M step described in Section 4.1 because the exact analytical solutions ¯wm,k = µk and σm,k = σk for the unrelated (m, k) pairs were used in the new algorithm instead of an approximate solution as in the standard algorithm. 5.",
                "EXPERIMENTAL METHODOLOGY 5.1 Evaluation Data Set To evaluate the proposed technique, we used the following three major data sets (Table 1): MovieLens Data: This data set was created by combining the relevance judgments from the MovieLens[9] data set with documents from the Internet Movie Database (IMDB).",
                "MovieLens allows users to rank how much he/she enjoyed a specific movie on a scale from 1 to 5.",
                "This likeability rating was used as a measurement of how relevant the document representing the corresponding movie is to the user.",
                "We considered documents with likeability scores of 4 or 5 as relevant, and documents with a score of 1 to 3 as irrelevant to the user.",
                "MovieLens provided relevance judgments on 3,057 documents from 6,040 separate users.",
                "On average, each user rated 151 movies, of these 87 were judged to be relevant.",
                "The average score for a document was 3.58.",
                "Documents representing each movie were constructed from the portion of the IMDB database that is available for public download[13].",
                "Based on this database, we created one document per movie that contained the relevant information about it (e.g. directors, actors, etc.).",
                "Table 1: Data Set Statistics.",
                "On Reuters, the number of rating for a simulated user is the number of documents relevant to the corresponding topic.",
                "Data Users Docs Ratings per User MovieLens 6,040 3,057 151 Netflix-all 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Netflix Data: This data set was constructed by combining documents about movies crawled from the web with a set of actual movie rental customer relevance judgments from Netflix[19].",
                "Netflix publicly provides the relevance judgments of 480,189 anonymous customers.",
                "There are around 100 million rating on a scale of 1 to 5 for 17,770 documents.",
                "Similar to MovieLens, we considered documents with likeability scores of 4 or 5 as relevant.",
                "This number was reduced to 1000 customers through random sampling.",
                "The average customer on the reduced data set provided 127 judgments, with 70 being deemed relevant.",
                "The average score for documents is 3.55.",
                "Reuters Data: This is the Reuters Corpus, Volume 1.",
                "It covers 810,000 Reuters English language news stories from August 20, 1996 to August 19, 1997.",
                "Only the first 100,000 news were used in our experiments.",
                "The Reuters corpus comes with a topic hierarchy.",
                "Each document is assigned to one of several locations on the hierarchical tree.",
                "The first level of the tree contains four topics, denoted as C, E, M, and G. For the experiments in this paper, the tree was cut at level 1 to create four smaller trees, each of which corresponds to one smaller data set: Reuters-E Reuters-C, ReutersM and Reuters-G. For each small data set, we created several profiles, one profile for each node in a sub-tree, to simulate multiple users, each with a related, yet separate definition of relevance.",
                "All the user profiles on a sub-tree are supposed to share the same prior model distribution.",
                "Since this corpus explicitly indicates only the relevant documents for a topic(user), all other documents are considered irrelevant. 5.2 Evaluation We designed the experiments to answer the following three questions: 1.",
                "Do we need to take the effort to use a Bayesian approach and learn a prior from other users? 2.",
                "Does the new algorithm work better than the standard EM algorithm for learning the Bayesian hierarchical linear model? 3.",
                "Can the new algorithm quickly learn many user models?",
                "To answer the first question, we compared the Bayesian hierarchical models with commonly used Norm-2 regularized linear regression models.",
                "In fact, the commonly used approach is equivalent to the model learned at the end of the first EM iteration.",
                "To answer the second question, we compared the proposed new algorithm with the standard EM algorithm to see whether the new learning algorithm is better.",
                "To answer the third question, we tested the efficiency of the new algorithm on the entire Netflix data set where about half a million user models need to be learned together.",
                "For the MovieLens and Netflix data sets, algorithm effectiveness was measured by mean square error, while on the Reuters data set classification error was used because it was more informative.",
                "We first evaluated the performance on each individual user, and then estimated the macro average over all users.",
                "Statistical tests (t-tests) were carried out to see whether the results are significant.",
                "For the experiments on the MovieLens and Netflix data sets, we used a random sample of 90% of each user for training, and the rest for testing.",
                "On Reuters data set, because there are too many relevant documents for each topic in the corpus, we used a random sample of 10% of each topic for training, and 10% of the remaining documents for testing.",
                "For all runs, we set (a, b, c, Σ ) = (0.1, 10, 0.1, 1) manually. 6.",
                "EXPERIMENTAL RESULTS Figure 2, Figure 3, and Figure 4 show that on all data sets, the Bayesian hierarchical modeling approach has a statistical significant improvement over the regularized linear regression model, which is equivalent to the Bayesian hierarchical models learned at the first iteration.",
                "Further analysis shows a negative correlation between the number of training data for a user and the improvement the system gets.",
                "This suggests that the borrowing information from other users has more significant improvements for users with less training data, which is as expected.",
                "However, the strength of the correlation differs over data sets, and the amount of training data is not the only characteristics that will influence the final performance.",
                "Figure 2 and Figure 3 show that the proposed new algorithm works better than the standard EM algorithm on the Netflix and MovieLens data sets.",
                "This is not surprising since the number of related feature-users pairs is much smaller than the number of unrelated feature-user pairs on these two data sets, and thus the proposed new algorithm is expected to work better.",
                "Figure 4 shows that the two algorithms work similarly on the Reuters-E data set.",
                "The accuracy of the new algorithm is similar to that of the standard EM algorithm at each iteration.",
                "The general patterns are very similar on other Reuters subsets.",
                "Further analysis shows that only 58% of the user-feature pairs are unrelated on this data set.",
                "Since the number of unrelated user-feature pairs is not extremely large, the sparseness is not a serious problem on the Reuters data set.",
                "Thus the two learning algorithms perform similarly.",
                "The results suggest that only on a corpus where the number of unrelated user-feature pairs is much larger than the number of related pairs, such as on the Netflix data set, the proposed technique will get a significant improvement over standard EM.",
                "However, the experiments also show that when the assumption does not hold, the new algorithm does not hurt performance.",
                "Although the proposed technique is faster than standard Figure 2: Performance on a Netflix subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iterations 2 - 10.",
                "Norm-2 regularized linear models are equivalent to the Bayesian hierarchical models learned at the first iteration, and are statistical significantly worse than the Bayesian hierarchical models. 0 2 4 6 8 10 1 1.05 1.1 1.15 1.2 1.25 1.3 1.35 1.4 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iterations ClassificationError New Algorithm Traditional EM Figure 3: Performance on a MovieLens subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iteration 2 to 17 (evaluated with mean square error). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iterations MeanSquareError New Algorithm Traditional EM 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iterations ClassificationError New Algorithm Traditional EM Figure 4: Performance on a Reuters-E subset with 26 profiles.",
                "Performances on Reuters-C, Reuters-M, Reuters-G are similar. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iterations ClassificationError New Algorithm Traditional EM EM, can it really learn millions of user models quickly?",
                "Our results show that the modified EM algorithm converges quickly, and 2 - 3 modified EM iterations would result in a reliable estimation.",
                "We evaluated the algorithm on the whole Netflix data set (480,189 users, 159,836 features, and 100 million ratings) running on a single CPU PC (2GB memory, P4 3GHz).",
                "The system finished one modified EM iteration in about 4 hours.",
                "This demonstrates that the proposed technique can efficiently handle large-scale system like Netflix. 7.",
                "CONCLUSION Content-based user profile learning is an important problem and is the key to providing personal recommendations to a user, especially for recommending new items with a small number of ratings.",
                "The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors.",
                "This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM.",
                "We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm.",
                "Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse, by which we mean the ratio of related user-feature pairs to unrelated pairs is small.",
                "Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold.",
                "In general, it is better to use the new algorithm since it is as simple as standard EM, the performance is either better or similar to EM, and the computation complexity is lower at each iteration.",
                "It is worth mentioning that even if the original problem space is not sparse, sparseness can be created artificially when a recommendation system uses user-specific feature selection techniques to reduce the noise and user model complexity.",
                "The proposed technique can also be adapted to improve the learning in such a scenario.",
                "We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU.",
                "The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear modeling approach to build a practical large scale system, even though the literature have demonstrated the effectiveness of the models in many applications.",
                "Our work is one major step on the road to make Bayesian hierarchical linear models more practical.",
                "The proposed new technique can be easily adapted to run on a cluster of machines, and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users.",
                "The research has much potential to benefit people using EM algorithm on many other <br>ir</br> problems as well as machine learning problems.",
                "EM algorithm is a commonly used machine learning technique.",
                "It is used to find model parameters in many <br>ir</br> problems where the training data is very sparse.",
                "Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering, the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems. 8.",
                "ACKNOWLEDGMENTS We thank Wei Xu, David Lewis and anonymous reviewers for valuable feedback on the work described in this paper.",
                "Part of the work was supported by Yahoo, Google, the Petascale Data Storage Institute and the Institute for Scalable Scientific Data Management.",
                "Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors, and do not necessarily reflect those of the sponsors. 9.",
                "REFERENCES [1] C. Basu, H. Hirsh, and W. Cohen.",
                "Recommendation as classification: Using social and content-based information in recommendation.",
                "In Proceedings of the Fifteenth National Conference on Artificial Intelligence, 1998. [2] J. S. Breese, D. Heckerman, and C. Kadie.",
                "Empirical analysis of predictive algorithms for collaborative filtering.",
                "Technical report, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan.",
                "Document filtering with inference networks.",
                "In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor, and A. Vinokourov.",
                "Kernel method for document filtering.",
                "In The Eleventh Text REtrieval Conference (TREC11).",
                "National Institute of Standards and Technology, special publication 500-249, 2003. [5] C. Chelba and A. Acero.",
                "Adaptation of maximum entropy capitalizer: Little data can help a lot.",
                "In D. Lin and D. Wu, editors, Proceedings of EMNLP 2004, pages 285-292, Barcelona, Spain, July 2004.",
                "Association for Computational Linguistics. [6] B. Croft and J. Lafferty, editors.",
                "Language Modeling for Information Retrieval.",
                "Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov, and A. Genkin.",
                "Constructing informative prior distributions from domain knowledge in text classification.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 493-500, New York, NY, USA, 2006.",
                "ACM Press. [8] J. Delgado and N. Ishii.",
                "Memory-based weightedmajority prediction for recommender systems.",
                "In ACM SIGIR99 Workshop on Recommender Systems, 1999. [9] GroupLens.",
                "Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman.",
                "A tutorial on learning with bayesian networks.",
                "In M. Jordan, editor, Learning in Graphical Models.",
                "Kluwer Academic, 1998. [11] J. L. Herlocker, J.",
                "A. Konstan, A. Borchers, and J. Riedl.",
                "An algorithmic framework for performing collaborative filtering.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 230-237, New York, NY, USA, 1999.",
                "ACM Press. [12] T. Hofmann and J. Puzicha.",
                "Latent class models for collaborative filtering.",
                "In IJCAI 99: Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 688-693, San Francisco, CA, USA, 1999.",
                "Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).",
                "Internet movie database. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai, and L. Si.",
                "An automatic weighting scheme for collaborative filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 337-344, New York, NY, USA, 2004.",
                "ACM Press. [15] J.",
                "A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl.",
                "GroupLens: Applying collaborative filtering to Usenet news.",
                "Communications of the ACM, 40(3):77-87, 1997. [16] D. Lewis.",
                "Applying support vector machines to the TREC-2001 batch filtering and routing tasks.",
                "In Proceedings of the Eleventh Text REtrieval Conference (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee, , and P. Yu.",
                "Text classification by labeling words.",
                "In Proceedings of The Nineteenth National Conference on Artificial Intelligence (AAAI-2004), July 25-29, 2004. [18] P. Melville, R. J. Mooney, and R. Nagarajan.",
                "Content-boosted collaborative filtering for improved recommendations.",
                "In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002), Edmonton, Canada, 2002. [19] Netflix.",
                "Netflix prize. http://www.netflixprize.com (visited on Nov. 30, 2006), 2006. [20] S. Robertson and K. Sparck-Jones.",
                "Relevance weighting of search terms.",
                "In Journal of the American Society for Information Science, volume 27, pages 129-146, 1976. [21] J. Wang, A. P. de Vries, and M. J. T. Reinders.",
                "Unifying user-based and item-based collaborative filtering approaches by similarity fusion.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 501-508, New York, NY, USA, 2006.",
                "ACM Press. [22] X. Wu and R. K. Srihari.",
                "Incorporating prior knowledge with weighted margin support vector machines.",
                "In Proc.",
                "ACM Knowledge Discovery Data Mining Conf. (ACM SIGKDD 2004), Aug. 2004. [23] Y. Yang, S. Yoo, J. Zhang, and B. Kisiel.",
                "Robustness of adaptive filtering methods in a cross-benchmark evaluation.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2005. [24] K. Yu, V. Tresp, and A. Schwaighofer.",
                "Learning gaussian processes from multiple tasks.",
                "In ICML 05: Proceedings of the 22nd international conference on Machine learning, pages 1012-1019, New York, NY, USA, 2005.",
                "ACM Press. [25] K. Yu, V. Tresp, and S. Yu.",
                "A nonparametric hierarchical bayesian framework for information filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 353-360.",
                "ACM Press, 2004. [26] X. Zhu.",
                "Semi-supervised learning literature survey.",
                "Technical report, University of Wisconsin - Madison, December 9, 2006. [27] P. Zigoris and Y. Zhang.",
                "Bayesian adaptive user profiling with explicit & implicit feedback.",
                "In Conference on Information and Knowledge Mangement 2006, 2006."
            ],
            "original_annotated_samples": [
                "The commonly used EM algorithm converges very slowly due to the sparseness of the data in <br>ir</br> applications.",
                "RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the <br>ir</br> community since the 1970s.",
                "E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of the prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) where Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j M step: Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Many machine learning driven <br>ir</br> systems use a point estimate of the parameters at different stages in the system.",
                "For simplicity, and as a common practice in <br>ir</br>, we do not model the correlation between features.",
                "In the rest of the paper, we use these symbols to represent their diagonal approximations: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     Secondly, and most importantly, the input space is very sparse and there are many dimensions that are not related to a particular user in a real <br>ir</br> application."
            ],
            "translated_annotated_samples": [
                "El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de datos en <br>aplicaciones de IR</br>.",
                "TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de <br>IR</br> desde la década de 1970.",
                "Paso E: Para cada usuario m, estime la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual del prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) donde Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j Paso M: Optimice el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Muchos sistemas de IR impulsados por aprendizaje automático utilizan una estimación puntual de los <br>parámetros</br> en diferentes etapas del sistema.",
                "Por simplicidad, y como práctica común en <br>IR</br>, no modelamos la correlación entre características.",
                "En el resto del documento, utilizamos estos símbolos para representar sus aproximaciones diagonales: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     En segundo lugar, y lo más importante, el espacio de entrada es muy disperso y hay muchas dimensiones que no están relacionadas con un usuario particular en una <br>aplicación de recuperación de información</br> real."
            ],
            "translated_text": "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual. Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un modelo jerárquico bayesiano. Aprender los parámetros del modelo para optimizar la verosimilitud conjunta de los datos de millones de usuarios es muy costoso computacionalmente. El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de datos en <br>aplicaciones de IR</br>. Este documento propone una nueva técnica de aprendizaje rápido para aprender un gran número de perfiles de usuario individuales. La eficacia y eficiencia del algoritmo propuesto están justificadas por la teoría y demostradas en datos reales de usuarios de Netflix y MovieLens. Categorías y Descriptores de Asignaturas: B.3.3 [Búsqueda y Recuperación de Información]: Filtrado de información Términos Generales: Algoritmos 1. La personalización es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales. Por ejemplo, las tiendas en línea, como Amazon y Netflix, ofrecen recomendaciones personalizadas de productos o servicios adicionales basadas en el historial de un usuario. Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de un usuario a partir de su historial. Un tema importante de personalización estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados basados en el contenido. Estos sistemas aprenden perfiles específicos de usuario a partir de la retroalimentación del usuario para poder recomendar información adaptada a los intereses de cada usuario sin necesidad de que el usuario realice una consulta explícita. Aprender los perfiles de usuario es el problema central de estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica qué tan relevante es un documento para el usuario. Uno de los principales desafíos de construir un sistema de recomendación o personalización es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña. Esto se conoce como el problema de inicio en frío. Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente retroalimentación de ese usuario para aprender un perfil de usuario confiable. Se ha realizado mucha investigación sobre cómo mejorar la precisión de clasificación cuando la cantidad de datos de entrenamiento etiquetados es pequeña. El enfoque de aprendizaje semisupervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26]. Otro enfoque es utilizar el conocimiento del dominio. Los investigadores han modificado diferentes algoritmos de aprendizaje, como NaïveBayes [17], regresión logística [7] y SVMs [22], para integrar el conocimiento del dominio en un clasificador de texto. El tercer enfoque consiste en tomar datos de entrenamiento de otros recursos [5][7]. La efectividad de estos enfoques diferentes es mixta, debido a qué tan bien se ajusta la suposición del modelo subyacente a los datos. Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano. Varios investigadores han demostrado que este enfoque intercambia eficazmente entre la información compartida y la específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario[27][25]. Para aprender un modelo jerárquico bayesiano, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados. Un sistema de recomendación maduro generalmente funciona para millones de usuarios. Es bien sabido que aprender los parámetros óptimos de un modelo jerárquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios. El algoritmo EM es una técnica comúnmente utilizada para el aprendizaje de parámetros debido a su simplicidad y garantía de convergencia. Sin embargo, un sistema de recomendación basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso. Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM tering, o filtrado colaborativo basado en elementos. En este documento, las palabras filtrado y recomendación se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de las variables de entrada. También encontramos que actualizar el parámetro del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones. Este documento modifica el algoritmo EM estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos algoritmo EM modificado. La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M utilizamos la solución analítica en lugar de la solución numérica estimada en el paso E para esos parámetros. Esto reduce considerablemente la computación en una sola iteración de EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales. La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de regresión lineal jerárquica bayesiana utilizado para recomendaciones basadas en contenido. La sección 4 describe cómo aprender los parámetros del modelo utilizando el algoritmo EM estándar, junto con el uso de la nueva técnica propuesta en este artículo. La configuración experimental y los resultados utilizados para validar la técnica de aprendizaje propuesta se informan en las Secciones 5 y 6. La sección 7 resume y ofrece observaciones finales. 2. TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de <br>IR</br> desde la década de 1970. Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus filtrado colaborativo. El filtrado basado en contenido estudia el escenario en el que un sistema de recomendación monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente. El usuario puede leer los documentos entregados y proporcionar retroalimentación explícita de relevancia, la cual el sistema de filtrado utiliza para actualizar el perfil del usuario mediante modelos de recuperación de retroalimentación de relevancia (por ejemplo,). Modelos booleanos, modelos de espacio vectorial, modelos probabilísticos tradicionales [20], redes de inferencia [3] y modelos de lenguaje [6]) o algoritmos de aprendizaje automático (por ejemplo, Máquinas de Vectores de Soporte (SVM), agrupamiento de K vecinos más cercanos (K-NN), redes neuronales, regresión logística o Winnow [16] [4] [23]. El filtrado colaborativo va más allá de simplemente usar el contenido de un documento para recomendar elementos a un usuario, aprovechando la información de otros usuarios con gustos y preferencias similares en el pasado. Se han utilizado heurísticas basadas en memoria y enfoques basados en modelos en la tarea de filtrado colaborativo [15] [8] [2] [14] [12] [11]. Este artículo contribuye a la investigación de recomendaciones basadas en contenido al mejorar la eficiencia y efectividad de los modelos lineales jerárquicos bayesianos, los cuales tienen una sólida base teórica y un buen rendimiento empírico en tareas de recomendación[27][25]. Este artículo no tiene la intención de comparar el filtrado basado en contenido con el filtrado colaborativo ni de afirmar cuál es mejor. Creemos que cada uno complementa al otro, y que el filtrado basado en contenido es extremadamente útil para manejar nuevos documentos/artículos con poco o ningún feedback del usuario. Similar a otros investigadores[18][1][21], encontramos que un sistema de recomendación será más efectivo cuando se combinan ambas técnicas. Sin embargo, esto está fuera del alcance de este documento y, por lo tanto, no se discute aquí. 3. REGRESIÓN LINEAL HIERÁRQUICA BAYESIANA Suponga que hay M usuarios en el sistema. La tarea del sistema es recomendar documentos que sean relevantes para cada usuario. Para cada usuario, el sistema aprende un modelo de usuario a partir del historial de los usuarios. En el resto de este documento, utilizaremos las siguientes notaciones para representar las variables en el sistema. m = 1, 2, ..., M: El índice para cada usuario individual. M es el número total de usuarios. wm: El parámetro del modelo de usuario asociado con el usuario m. wm es un vector de dimensión K. j = 1, 2, ..., Jm: El índice para un conjunto de datos para el usuario m. Jm es el número de datos de entrenamiento para el usuario m. Dm = {(xm,j, ym,j)}: Un conjunto de datos asociado con el usuario m. xm,j es un vector de dimensión K que representa el j-ésimo documento de entrenamiento del usuario m. ym,j es un escalar que representa la etiqueta del documento xm,j. k = 1, 2, ..., K: El índice dimensional de la variable de entrada x. El enfoque de modelado jerárquico bayesiano ha sido ampliamente utilizado en aplicaciones reales de recuperación de información. Los modelos lineales jerárquicos bayesianos generalizados, uno de los modelos jerárquicos bayesianos más simples, son comúnmente utilizados y han logrado un buen rendimiento en tareas de filtrado colaborativo [25] y filtrado adaptativo basado en contenido [27]. La Figura 1 muestra la representación gráfica de un modelo jerárquico bayesiano. En este gráfico, cada modelo de usuario está representado por un vector aleatorio wm. Suponemos que un modelo de usuario se muestrea aleatoriamente de una distribución previa P(w|Φ). El sistema puede predecir la etiqueta de usuario y de un documento x dado una estimación de wm (o distribución de wms) utilizando una función y = f(x, w). El modelo se llama modelo lineal jerárquico bayesiano generalizado cuando y = f(wT x) es cualquier modelo lineal generalizado como regresión logística, SVM y regresión lineal. Para estimar de manera confiable el modelo de usuario wm, el sistema puede obtener información de otros usuarios a través de la prior Φ = (µ, Σ). Ahora observamos un modelo comúnmente utilizado donde y = wT x + , donde ∼ N(0, σ2 ) es un ruido aleatorio [25][27]. Suponga que cada modelo de usuario wm es una muestra independiente de una distribución poblacional P(w|Φ), la cual está regida por un hiperparámetro desconocido Φ. Que la distribución previa del modelo de usuario w sea una distribución gaussiana con parámetro Φ = (µ, Σ), que es la distribución previa comúnmente utilizada para modelos lineales. µ = (µ1, µ2, ..., µK) es un vector de K dimensiones que representa la media de la distribución gaussiana, y Σ es la matriz de covarianza de la gaussiana. Normalmente, se utiliza una distribución Normal N(0, aI) y una distribución Inverse Wishart P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) como hiperprior para modelar la distribución previa de µ y Σ respectivamente. Yo es la matriz identidad de dimensión K, y a, b y c son números reales. Con esta configuración, tenemos el siguiente modelo para el sistema: 1. µ y Σ se muestrean de N(0, aI) e IWν (aI), respectivamente. 2. La primera dimensión de x es una variable ficticia que siempre es igual a 1. Figura 1: Ilustración de las dependencias de variables en el modelo jerárquico. La calificación, y, para un documento, x, está condicionada al documento y al modelo de usuario, wm, asociado con el usuario m. Los usuarios comparten información sobre sus modelos a través de la prior, Φ = (µ, Σ). Para cada usuario m, wm se muestrea aleatoriamente de una distribución Normal: wm ∼ N(µ, Σ2 ) 3. Para cada elemento xm,j, ym,j se muestrea aleatoriamente de una distribución Normal: ym,j ∼ N(wT mxm,j, σ2). Que θ = (Φ, w1, w2, ..., wM) represente los parámetros de este sistema que necesitan ser estimados. La verosimilitud conjunta de todas las variables en el modelo probabilístico, que incluye los datos y los parámetros, es: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) Para simplificar, asumimos que a, b, c y σ son proporcionados al sistema. 4. APRENDIZAJE DE PARÁMETROS DEL MODELO Si se conoce el prior Φ, encontrar el óptimo wm es sencillo: se trata de una regresión lineal simple. Por lo tanto, nos enfocaremos en estimar Φ. La solución a priori máxima de Φ se da por ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Encontrar la solución óptima para el problema anterior es desafiante, ya que necesitamos integrar sobre todos los w = (w1, w2, ..., wM), que son variables ocultas no observadas. 4.1 Algoritmo EM para Modelos Lineales Jerárquicos Bayesianos En la Ecuación 5, Φ es el parámetro que necesita ser estimado, y el resultado depende de las variables latentes no observadas w. Este tipo de problema de optimización suele resolverse mediante el algoritmo EM. Aplicando EM al problema anterior, el conjunto de modelos de usuario w son las variables ocultas no observables y tenemos: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw. Basándonos en la derivación de las fórmulas EM presentadas en [24], tenemos los siguientes pasos de Expectation-Maximization para encontrar los hiperparámetros óptimos. Por razones de espacio, omitimos la derivación en este artículo ya que no es el enfoque de nuestro trabajo. Paso E: Para cada usuario m, estime la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual del prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) donde Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j Paso M: Optimice el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Muchos sistemas de IR impulsados por aprendizaje automático utilizan una estimación puntual de los <br>parámetros</br> en diferentes etapas del sistema. Sin embargo, estamos estimando la distribución posterior de las variables en el paso E. Esto evita el sobreajuste de wm a los datos de un usuario en particular, que pueden ser pequeños y ruidosos. Una discusión detallada sobre este tema aparece en [10]. 4.2 Nuevo Algoritmo: EM Modificado. Aunque el algoritmo EM es ampliamente estudiado y utilizado en aplicaciones de aprendizaje automático, utilizar el proceso EM mencionado anteriormente para resolver modelos lineales jerárquicos bayesianos en sistemas de recuperación de información a gran escala sigue siendo demasiado costoso computacionalmente. En esta sección, describimos por qué la tasa de aprendizaje del algoritmo EM es lenta en nuestra aplicación e introducimos una nueva técnica para hacer que el aprendizaje del modelo lineal jerárquico bayesiano sea escalable. La derivación del nuevo algoritmo de aprendizaje estará basada en el algoritmo EM descrito en la sección anterior. Primero, las matrices de covarianza Σ2 , Σ2 m suelen ser demasiado grandes para ser computacionalmente factibles. Por simplicidad, y como práctica común en <br>IR</br>, no modelamos la correlación entre características. Así aproximamos estas matrices con matrices diagonales de dimensión K. En el resto del documento, utilizamos estos símbolos para representar sus aproximaciones diagonales: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     En segundo lugar, y lo más importante, el espacio de entrada es muy disperso y hay muchas dimensiones que no están relacionadas con un usuario particular en una <br>aplicación de recuperación de información</br> real. ",
            "candidates": [],
            "error": [
                [
                    "aplicaciones de IR",
                    "IR",
                    "parámetros",
                    "IR",
                    "aplicación de recuperación de información"
                ]
            ]
        },
        "em algorithm": {
            "translated_key": "algoritmo EM",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
                "A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model.",
                "Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive.",
                "The commonly used <br>em algorithm</br> converges very slowly due to the sparseness of the data in IR applications.",
                "This paper proposes a new fast learning technique to learn a large number of individual user profiles.",
                "The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens.",
                "Categories and Subject Descriptors: B.3.3 [Information Search and Retrieval]: Information filtering General Terms: Algorithms 1.",
                "INTRODUCTION Personalization is the future of the Web, and it has achieved great success in industrial applications.",
                "For example, online stores, such as Amazon and Netflix, provide customized recommendations for additional products or services based on a users history.",
                "Recent offerings such as My MSN, My Yahoo!, My Google, and Google News have attracted much attention due to their potential ability to infer a users interests from his/her history.",
                "One major personalization topic studied in the information retrieval community is content-based personal recommendation systems1 .",
                "These systems learn user-specific profiles from user feedback so that they can recommend information tailored to each individual users interest without requiring the user to make an explicit query.",
                "Learning the user profiles is the core problem for these systems.",
                "A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user.",
                "One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small.",
                "This is known as the cold start problem.",
                "This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile.",
                "There has been much research on improving classification accuracy when the amount of labeled training data is small.",
                "The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal [26].",
                "Another approach is using domain knowledge.",
                "Researchers have modified different learning algorithms, such as Na¨ıveBayes [17], logistic regression [7], and SVMs [22], to integrate domain knowledge into a text classifier.",
                "The third approach is borrowing training data from other resources [5][7].",
                "The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data.",
                "One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach.",
                "Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial performance for each user[27][25].",
                "In order to learn a Bayesian hierarchical model, the system usually tries to find the most likely model parameters for the given data.",
                "A mature recommendation system usually works for millions of users.",
                "It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users.",
                "The <br>em algorithm</br> is a commonly used technique for parameter learning due to its simplicity and convergence guarantee.",
                "However, a content based recommendation system often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector.",
                "With careful analysis of the <br>em algorithm</br> in this scenario (Section 4), we find that the EM tering, or item-based collaborative filtering.",
                "In this paper, the words filtering and recommendation are used interchangeably. algorithm converges very slowly due to the sparseness of the input variables.",
                "We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O(MK), where M is the number of users and K is the number of dimensions.",
                "This paper modifies the standard <br>em algorithm</br> to create an improved learning algorithm, which we call the Modified <br>em algorithm</br>.",
                "The basic idea is that instead of calculating the numerical solution for all the user profile parameters, we derive the analytical solution of the parameters for some feature dimensions, and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters.",
                "This greatly reduces the computation at a single EM iteration, and also has the benefit of increasing the convergence speed of the learning algorithm.",
                "The proposed technique is not only well supported by theory, but also by experimental results.",
                "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression modeling framework used for content-based recommendations.",
                "Section 4 describes how to learn the model parameters using the standard <br>em algorithm</br>, along with using the new technique proposed in this paper.",
                "The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6.",
                "Section 7 summarizes and offers concluding remarks. 2.",
                "RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the IR community since the 1970s.",
                "The approaches that have been used to solve this problem can be roughly classified into two major categories: content based filtering versus collaborative filtering.",
                "Content-based filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user.",
                "The user may read the delivered documents and provide explicit relevance feedback, which the filtering system then uses to update the users profile using relevance feedback retrieval models (e.g.",
                "Boolean models, vector space models, traditional probabilistic models [20] , inference networks [3] and language models [6]) or machine learning algorithms (e.g.",
                "Support Vector Machines (SVM), K nearest neighbors (K-NN) clustering, neural networks, logistic regression, or Winnow [16] [4] [23]).",
                "Collaborative filtering goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past.",
                "Memorybased heuristics and model based approaches have been used in collaborative filtering task [15] [8] [2] [14] [12] [11].",
                "This paper contributes to the content-based recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks[27][25].",
                "This paper does not intend to compare content-based filtering with collaborative filtering or claim which one is a better.",
                "We think each complements the other, and that content-based filtering is extremely useful for handling new documents/items with little or no user feedback.",
                "Similar to some other researchers[18][1][21], we found that a recommendation system will be more effective when both techniques are combined.",
                "However, this is beyond the scope of this paper and thus not discussed here. 3.",
                "BAYESIAN HIERARCHICAL LINEAR REGRESSION Assume there are M users in the system.",
                "The task of the system is to recommend documents that are relevant to each user.",
                "For each user, the system learns a user model from the users history.",
                "In the rest of this paper, we will use the following notations to represent the variables in the system. m = 1, 2, ..., M: The index for each individual user.",
                "M is the total number of users. wm: The user model parameter associated with user m. wm is a K dimensional vector. j = 1, 2, ..., Jm: The index for a set of data for user m. Jm is the number of training data for user m. Dm = {(xm,j, ym,j)}: A set of data associated with user m. xm,j is a K dimensional vector that represents the mth users jth training document.2 ym,j is a scalar that represents the label of document xm,j. k = 1, 2, ..., K: The dimensional index of input variable x.",
                "The Bayesian hierarchical modeling approach has been widely used in real-world information retrieval applications.",
                "Generalized Bayesian hierarchical linear models, one of the simplest Bayesian hierarchical models, are commonly used and have achieved good performance on collaborative filtering [25] and content-based adaptive filtering [27] tasks.",
                "Figure 1 shows the graphical representation of a Bayesian hierarchical model.",
                "In this graph, each user model is represented by a random vector wm.",
                "We assume a user model is sampled randomly from a prior distribution P(w|Φ).",
                "The system can predict the user label y of a document x given an estimation of wm (or wms distribution) using a function y = f(x, w).",
                "The model is called generalized Bayesian hierarchical linear model when y = f(wT x) is any generalized linear model such as logistic regression, SVM, and linear regression.",
                "To reliably estimate the user model wm, the system can borrow information from other users through the prior Φ = (µ, Σ).",
                "Now we look at one commonly used model where y = wT x + , where ∼ N(0, σ2 ) is a random noise [25][27].",
                "Assume that each user model wm is an independent draw from a population distribution P(w|Φ), which is governed by some unknown hyperparameter Φ.",
                "Let the prior distribution of user model w be a Gaussian distribution with parameter Φ = (µ, Σ), which is the commonly used prior for linear models. µ = (µ1, µ2, ..., µK ) is a K dimensional vector that represents the mean of the Gaussian distribution, and Σ is the covariance matrix of the Gaussian.",
                "Usually, a Normal distribution N(0, aI) and an Inverse Wishart distribution P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) are used as hyperprior to model the prior distribution of µ and Σ respectively.",
                "I is the K dimensional identity matrix, and a, b, and c are real numbers.",
                "With these settings, we have the following model for the system: 1. µ and Σ are sampled from N(0, aI) and IWν (aI), respectively. 2 The first dimension of x is a dummy variable that always equals to 1.",
                "Figure 1: Illustration of dependencies of variables in the hierarchical model.",
                "The rating, y, for a document, x, is conditioned on the document and the user model, wm, associated with the user m. Users share information about their models through the prior, Φ = (µ, Σ). 2.",
                "For each user m, wm is sampled randomly from a Normal distribution: wm ∼ N(µ, Σ2 ) 3.",
                "For each item xm,j, ym,j is sampled randomly from a Normal distribution: ym,j ∼ N(wT mxm,j, σ2 ).",
                "Let θ = (Φ, w1, w2, ..., wM ) represent the parameters of this system that needs to be estimated.",
                "The joint likelihood for all the variables in the probabilistic model, which includes the data and the parameters, is: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) For simplicity, we assume a, b, c, and σ are provided to the system. 4.",
                "MODEL PARAMETER LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple linear regression.",
                "Therefore, we will focus on estimating Φ.",
                "The maximum a priori solution of Φ is given by ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Finding the optimal solution for the above problem is challenging, since we need to integrate over all w = (w1, w2, ..., wM ), which are unobserved hidden variables. 4.1 <br>em algorithm</br> for Bayesian Hierarchical Linear Models In Equation 5, Φ is the parameter needs to be estimated, and the result depends on unobserved latent variables w. This kind of optimization problem is usually solved by the <br>em algorithm</br>.",
                "Applying EM to the above problem, the set of user models w are the unobservable hidden variables and we have: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw Based on the derivation of the EM formulas presented in [24], we have the following Expectation-Maximization steps for finding the optimal hyperparameters.",
                "For space considerations, we omit the derivation in this paper since it is not the focus of our work.",
                "E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of the prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) where Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j M step: Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Many machine learning driven IR systems use a point estimate of the parameters at different stages in the system.",
                "However, we are estimating the posterior distribution of the variables at the E step.",
                "This avoids overfitting wm to a particular users data, which may be small and noisy.",
                "A detailed discussion about this subject appears in [10]. 4.2 New Algorithm: Modified EM Although the <br>em algorithm</br> is widely studied and used in machine learning applications, using the above EM process to solve Bayesian hierarchical linear models in large-scale information retrieval systems is still too computationally expensive.",
                "In this section, we describe why the learning rate of the <br>em algorithm</br> is slow in our application and introduce a new technique to make the learning of the Bayesian hierarchical linear model scalable.",
                "The derivation of the new learning algorithm will be based on the <br>em algorithm</br> described in the previous section.",
                "First, the covariance matrices Σ2 , Σ2 m are usually too large to be computationally feasible.",
                "For simplicity, and as a common practice in IR, we do not model the correlation between features.",
                "Thus we approximate these matrices with K dimensional diagonal matrices.",
                "In the rest of the paper, we use these symbols to represent their diagonal approximations: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     Secondly, and most importantly, the input space is very sparse and there are many dimensions that are not related to a particular user in a real IR application.",
                "For example, let us consider a movie recommendation system, with the input variable x representing a particular movie.",
                "For the jth movie that the user m has seen, let xm,j,k = 1 if the director of the movie is Jean-Pierre Jeunet (indexed by k).",
                "Here we assume that whether or not that this director directed a specific movie is represented by the kth dimension.",
                "If the user m has never seen a movie directed by Jean-Pierre Jeunet, then the corresponding dimension is always zero (xm,j,k = 0 for all j) .",
                "One major drawback of the <br>em algorithm</br> is that the importance of a feature, µk, may be greatly dominated by users who have never encountered this feature (i.e. j xm,j,k = 0) at the M step (Equation 8).",
                "Assume that 100 out of 1 million users have viewed the movie directed by Jean-Pierre Jeunet, and that the viewers have rated all of his movies as excellent.",
                "Intuitively, he is a good director and the weight for him (µk) should be high.",
                "Before the EM iteration, the initial value of µ is usually set to 0.",
                "Since the other 999,900 users have not seen this movie, their corresponding weights (w1,k, w2,k, ..., wm,k..., w999900,k) for that director would be very small initially.",
                "Thus the corresponding weight of the director in the prior µk at the first M step would be very low , and the variance σm,k will be large (Equations 8 and 7).",
                "It is undesirable that users who have never seen any movie produced by the director influence the importance of the director so much.",
                "This makes the convergence of the standard <br>em algorithm</br> very slow.",
                "Now lets look at whether we can improve the learning speed of the algorithm.",
                "Without a loss of generality, let us assume that the kth dimension of the input variable x is not related to a particular user m. By which we mean, xm,j,k = 0 for all j = 1, ..., Jm.",
                "It is straightforward to prove that the kth row and kth column of Sxx,m are completely filled with zeros, and that the kth dimension of Sxy,m is zeroed as well.",
                "Thus the corresponding kth dimension of the user models mean, ¯wm, should be equal to that of the prior: ¯wm,k = µk, with the corresponding covariance of σm,k = σk.",
                "At the M step, the standard <br>em algorithm</br> uses the numerical solution of the distribution P(wm|Dm, Φ) estimated at E step (Equation 8 and Equation 7).",
                "However, the numerical solutions are very unreliable for ¯wm,k and σm,k when the kth dimension is not related to the mth user.",
                "A better approach is using the analytical solutions ¯wm,k = µk, and σm,k = σk for the unrelated (m, k) pairs, along with the numerical solution estimated at E step for the other (m, k) pairs.",
                "Thus we get the following new EM-like algorithm: Modified E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) where sxx,m,k = j x2 m,j,k and sxy,m,k = j xm,j,kym,j Modified M Step Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step for related userfeature pairs.",
                "The M step implicitly uses the analytical solution for unrelated user-feature pairs. µk = 1 Mk m:related ¯wm,k (12) σ2 k = 1 Mk m:related σ2 m,k +( ¯wm,k − µk)( ¯wm,k − µk)T (13) where Mk is the number of users that are related to feature k We only estimate the diagonal of Σ2 m and Σ since we are using the diagonal approximation of the covariance matrices.",
                "To estimate ¯wm, we only need to calculate the numerical solutions for dimensions that are related to user m. To estimate σ2 k and µk, we only sum over users that are related to the kth feature.",
                "There are two major benefits of the new algorithm.",
                "First, because only the related (m, k) pairs are needed at the modified M step, the computational complexity in a single EM iteration is much smaller when the data is sparse, and many of (m, k) pairs are unrelated.",
                "Second, the parameters estimated at the modified M step (Equations 12 - 13) are more accurate than the standard M step described in Section 4.1 because the exact analytical solutions ¯wm,k = µk and σm,k = σk for the unrelated (m, k) pairs were used in the new algorithm instead of an approximate solution as in the standard algorithm. 5.",
                "EXPERIMENTAL METHODOLOGY 5.1 Evaluation Data Set To evaluate the proposed technique, we used the following three major data sets (Table 1): MovieLens Data: This data set was created by combining the relevance judgments from the MovieLens[9] data set with documents from the Internet Movie Database (IMDB).",
                "MovieLens allows users to rank how much he/she enjoyed a specific movie on a scale from 1 to 5.",
                "This likeability rating was used as a measurement of how relevant the document representing the corresponding movie is to the user.",
                "We considered documents with likeability scores of 4 or 5 as relevant, and documents with a score of 1 to 3 as irrelevant to the user.",
                "MovieLens provided relevance judgments on 3,057 documents from 6,040 separate users.",
                "On average, each user rated 151 movies, of these 87 were judged to be relevant.",
                "The average score for a document was 3.58.",
                "Documents representing each movie were constructed from the portion of the IMDB database that is available for public download[13].",
                "Based on this database, we created one document per movie that contained the relevant information about it (e.g. directors, actors, etc.).",
                "Table 1: Data Set Statistics.",
                "On Reuters, the number of rating for a simulated user is the number of documents relevant to the corresponding topic.",
                "Data Users Docs Ratings per User MovieLens 6,040 3,057 151 Netflix-all 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Netflix Data: This data set was constructed by combining documents about movies crawled from the web with a set of actual movie rental customer relevance judgments from Netflix[19].",
                "Netflix publicly provides the relevance judgments of 480,189 anonymous customers.",
                "There are around 100 million rating on a scale of 1 to 5 for 17,770 documents.",
                "Similar to MovieLens, we considered documents with likeability scores of 4 or 5 as relevant.",
                "This number was reduced to 1000 customers through random sampling.",
                "The average customer on the reduced data set provided 127 judgments, with 70 being deemed relevant.",
                "The average score for documents is 3.55.",
                "Reuters Data: This is the Reuters Corpus, Volume 1.",
                "It covers 810,000 Reuters English language news stories from August 20, 1996 to August 19, 1997.",
                "Only the first 100,000 news were used in our experiments.",
                "The Reuters corpus comes with a topic hierarchy.",
                "Each document is assigned to one of several locations on the hierarchical tree.",
                "The first level of the tree contains four topics, denoted as C, E, M, and G. For the experiments in this paper, the tree was cut at level 1 to create four smaller trees, each of which corresponds to one smaller data set: Reuters-E Reuters-C, ReutersM and Reuters-G. For each small data set, we created several profiles, one profile for each node in a sub-tree, to simulate multiple users, each with a related, yet separate definition of relevance.",
                "All the user profiles on a sub-tree are supposed to share the same prior model distribution.",
                "Since this corpus explicitly indicates only the relevant documents for a topic(user), all other documents are considered irrelevant. 5.2 Evaluation We designed the experiments to answer the following three questions: 1.",
                "Do we need to take the effort to use a Bayesian approach and learn a prior from other users? 2.",
                "Does the new algorithm work better than the standard <br>em algorithm</br> for learning the Bayesian hierarchical linear model? 3.",
                "Can the new algorithm quickly learn many user models?",
                "To answer the first question, we compared the Bayesian hierarchical models with commonly used Norm-2 regularized linear regression models.",
                "In fact, the commonly used approach is equivalent to the model learned at the end of the first EM iteration.",
                "To answer the second question, we compared the proposed new algorithm with the standard <br>em algorithm</br> to see whether the new learning algorithm is better.",
                "To answer the third question, we tested the efficiency of the new algorithm on the entire Netflix data set where about half a million user models need to be learned together.",
                "For the MovieLens and Netflix data sets, algorithm effectiveness was measured by mean square error, while on the Reuters data set classification error was used because it was more informative.",
                "We first evaluated the performance on each individual user, and then estimated the macro average over all users.",
                "Statistical tests (t-tests) were carried out to see whether the results are significant.",
                "For the experiments on the MovieLens and Netflix data sets, we used a random sample of 90% of each user for training, and the rest for testing.",
                "On Reuters data set, because there are too many relevant documents for each topic in the corpus, we used a random sample of 10% of each topic for training, and 10% of the remaining documents for testing.",
                "For all runs, we set (a, b, c, Σ ) = (0.1, 10, 0.1, 1) manually. 6.",
                "EXPERIMENTAL RESULTS Figure 2, Figure 3, and Figure 4 show that on all data sets, the Bayesian hierarchical modeling approach has a statistical significant improvement over the regularized linear regression model, which is equivalent to the Bayesian hierarchical models learned at the first iteration.",
                "Further analysis shows a negative correlation between the number of training data for a user and the improvement the system gets.",
                "This suggests that the borrowing information from other users has more significant improvements for users with less training data, which is as expected.",
                "However, the strength of the correlation differs over data sets, and the amount of training data is not the only characteristics that will influence the final performance.",
                "Figure 2 and Figure 3 show that the proposed new algorithm works better than the standard <br>em algorithm</br> on the Netflix and MovieLens data sets.",
                "This is not surprising since the number of related feature-users pairs is much smaller than the number of unrelated feature-user pairs on these two data sets, and thus the proposed new algorithm is expected to work better.",
                "Figure 4 shows that the two algorithms work similarly on the Reuters-E data set.",
                "The accuracy of the new algorithm is similar to that of the standard <br>em algorithm</br> at each iteration.",
                "The general patterns are very similar on other Reuters subsets.",
                "Further analysis shows that only 58% of the user-feature pairs are unrelated on this data set.",
                "Since the number of unrelated user-feature pairs is not extremely large, the sparseness is not a serious problem on the Reuters data set.",
                "Thus the two learning algorithms perform similarly.",
                "The results suggest that only on a corpus where the number of unrelated user-feature pairs is much larger than the number of related pairs, such as on the Netflix data set, the proposed technique will get a significant improvement over standard EM.",
                "However, the experiments also show that when the assumption does not hold, the new algorithm does not hurt performance.",
                "Although the proposed technique is faster than standard Figure 2: Performance on a Netflix subset with 1,000 users.",
                "The new algorithm is statistical significantly better than <br>em algorithm</br> at iterations 2 - 10.",
                "Norm-2 regularized linear models are equivalent to the Bayesian hierarchical models learned at the first iteration, and are statistical significantly worse than the Bayesian hierarchical models. 0 2 4 6 8 10 1 1.05 1.1 1.15 1.2 1.25 1.3 1.35 1.4 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iterations ClassificationError New Algorithm Traditional EM Figure 3: Performance on a MovieLens subset with 1,000 users.",
                "The new algorithm is statistical significantly better than <br>em algorithm</br> at iteration 2 to 17 (evaluated with mean square error). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iterations MeanSquareError New Algorithm Traditional EM 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iterations ClassificationError New Algorithm Traditional EM Figure 4: Performance on a Reuters-E subset with 26 profiles.",
                "Performances on Reuters-C, Reuters-M, Reuters-G are similar. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iterations ClassificationError New Algorithm Traditional EM EM, can it really learn millions of user models quickly?",
                "Our results show that the modified <br>em algorithm</br> converges quickly, and 2 - 3 modified EM iterations would result in a reliable estimation.",
                "We evaluated the algorithm on the whole Netflix data set (480,189 users, 159,836 features, and 100 million ratings) running on a single CPU PC (2GB memory, P4 3GHz).",
                "The system finished one modified EM iteration in about 4 hours.",
                "This demonstrates that the proposed technique can efficiently handle large-scale system like Netflix. 7.",
                "CONCLUSION Content-based user profile learning is an important problem and is the key to providing personal recommendations to a user, especially for recommending new items with a small number of ratings.",
                "The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors.",
                "This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM.",
                "We showed that the new technique is theoretically more computationally efficient than the standard <br>em algorithm</br>.",
                "Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse, by which we mean the ratio of related user-feature pairs to unrelated pairs is small.",
                "Evaluation on the Reuters data set showed that the new technique performed similar to the standard <br>em algorithm</br> when the sparseness condition does not hold.",
                "In general, it is better to use the new algorithm since it is as simple as standard EM, the performance is either better or similar to EM, and the computation complexity is lower at each iteration.",
                "It is worth mentioning that even if the original problem space is not sparse, sparseness can be created artificially when a recommendation system uses user-specific feature selection techniques to reduce the noise and user model complexity.",
                "The proposed technique can also be adapted to improve the learning in such a scenario.",
                "We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU.",
                "The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear modeling approach to build a practical large scale system, even though the literature have demonstrated the effectiveness of the models in many applications.",
                "Our work is one major step on the road to make Bayesian hierarchical linear models more practical.",
                "The proposed new technique can be easily adapted to run on a cluster of machines, and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users.",
                "The research has much potential to benefit people using <br>em algorithm</br> on many other IR problems as well as machine learning problems.",
                "<br>em algorithm</br> is a commonly used machine learning technique.",
                "It is used to find model parameters in many IR problems where the training data is very sparse.",
                "Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering, the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems. 8.",
                "ACKNOWLEDGMENTS We thank Wei Xu, David Lewis and anonymous reviewers for valuable feedback on the work described in this paper.",
                "Part of the work was supported by Yahoo, Google, the Petascale Data Storage Institute and the Institute for Scalable Scientific Data Management.",
                "Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors, and do not necessarily reflect those of the sponsors. 9.",
                "REFERENCES [1] C. Basu, H. Hirsh, and W. Cohen.",
                "Recommendation as classification: Using social and content-based information in recommendation.",
                "In Proceedings of the Fifteenth National Conference on Artificial Intelligence, 1998. [2] J. S. Breese, D. Heckerman, and C. Kadie.",
                "Empirical analysis of predictive algorithms for collaborative filtering.",
                "Technical report, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan.",
                "Document filtering with inference networks.",
                "In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor, and A. Vinokourov.",
                "Kernel method for document filtering.",
                "In The Eleventh Text REtrieval Conference (TREC11).",
                "National Institute of Standards and Technology, special publication 500-249, 2003. [5] C. Chelba and A. Acero.",
                "Adaptation of maximum entropy capitalizer: Little data can help a lot.",
                "In D. Lin and D. Wu, editors, Proceedings of EMNLP 2004, pages 285-292, Barcelona, Spain, July 2004.",
                "Association for Computational Linguistics. [6] B. Croft and J. Lafferty, editors.",
                "Language Modeling for Information Retrieval.",
                "Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov, and A. Genkin.",
                "Constructing informative prior distributions from domain knowledge in text classification.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 493-500, New York, NY, USA, 2006.",
                "ACM Press. [8] J. Delgado and N. Ishii.",
                "Memory-based weightedmajority prediction for recommender systems.",
                "In ACM SIGIR99 Workshop on Recommender Systems, 1999. [9] GroupLens.",
                "Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman.",
                "A tutorial on learning with bayesian networks.",
                "In M. Jordan, editor, Learning in Graphical Models.",
                "Kluwer Academic, 1998. [11] J. L. Herlocker, J.",
                "A. Konstan, A. Borchers, and J. Riedl.",
                "An algorithmic framework for performing collaborative filtering.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 230-237, New York, NY, USA, 1999.",
                "ACM Press. [12] T. Hofmann and J. Puzicha.",
                "Latent class models for collaborative filtering.",
                "In IJCAI 99: Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 688-693, San Francisco, CA, USA, 1999.",
                "Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).",
                "Internet movie database. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai, and L. Si.",
                "An automatic weighting scheme for collaborative filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 337-344, New York, NY, USA, 2004.",
                "ACM Press. [15] J.",
                "A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl.",
                "GroupLens: Applying collaborative filtering to Usenet news.",
                "Communications of the ACM, 40(3):77-87, 1997. [16] D. Lewis.",
                "Applying support vector machines to the TREC-2001 batch filtering and routing tasks.",
                "In Proceedings of the Eleventh Text REtrieval Conference (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee, , and P. Yu.",
                "Text classification by labeling words.",
                "In Proceedings of The Nineteenth National Conference on Artificial Intelligence (AAAI-2004), July 25-29, 2004. [18] P. Melville, R. J. Mooney, and R. Nagarajan.",
                "Content-boosted collaborative filtering for improved recommendations.",
                "In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002), Edmonton, Canada, 2002. [19] Netflix.",
                "Netflix prize. http://www.netflixprize.com (visited on Nov. 30, 2006), 2006. [20] S. Robertson and K. Sparck-Jones.",
                "Relevance weighting of search terms.",
                "In Journal of the American Society for Information Science, volume 27, pages 129-146, 1976. [21] J. Wang, A. P. de Vries, and M. J. T. Reinders.",
                "Unifying user-based and item-based collaborative filtering approaches by similarity fusion.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 501-508, New York, NY, USA, 2006.",
                "ACM Press. [22] X. Wu and R. K. Srihari.",
                "Incorporating prior knowledge with weighted margin support vector machines.",
                "In Proc.",
                "ACM Knowledge Discovery Data Mining Conf. (ACM SIGKDD 2004), Aug. 2004. [23] Y. Yang, S. Yoo, J. Zhang, and B. Kisiel.",
                "Robustness of adaptive filtering methods in a cross-benchmark evaluation.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2005. [24] K. Yu, V. Tresp, and A. Schwaighofer.",
                "Learning gaussian processes from multiple tasks.",
                "In ICML 05: Proceedings of the 22nd international conference on Machine learning, pages 1012-1019, New York, NY, USA, 2005.",
                "ACM Press. [25] K. Yu, V. Tresp, and S. Yu.",
                "A nonparametric hierarchical bayesian framework for information filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 353-360.",
                "ACM Press, 2004. [26] X. Zhu.",
                "Semi-supervised learning literature survey.",
                "Technical report, University of Wisconsin - Madison, December 9, 2006. [27] P. Zigoris and Y. Zhang.",
                "Bayesian adaptive user profiling with explicit & implicit feedback.",
                "In Conference on Information and Knowledge Mangement 2006, 2006."
            ],
            "original_annotated_samples": [
                "The commonly used <br>em algorithm</br> converges very slowly due to the sparseness of the data in IR applications.",
                "The <br>em algorithm</br> is a commonly used technique for parameter learning due to its simplicity and convergence guarantee.",
                "With careful analysis of the <br>em algorithm</br> in this scenario (Section 4), we find that the EM tering, or item-based collaborative filtering.",
                "This paper modifies the standard <br>em algorithm</br> to create an improved learning algorithm, which we call the Modified <br>em algorithm</br>.",
                "Section 4 describes how to learn the model parameters using the standard <br>em algorithm</br>, along with using the new technique proposed in this paper."
            ],
            "translated_annotated_samples": [
                "El <br>algoritmo EM</br> comúnmente utilizado converge muy lentamente debido a la escasez de datos en aplicaciones de IR.",
                "El <br>algoritmo EM</br> es una técnica comúnmente utilizada para el aprendizaje de parámetros debido a su simplicidad y garantía de convergencia.",
                "Con un análisis cuidadoso del <br>algoritmo EM</br> en este escenario (Sección 4), encontramos que el EM tering, o filtrado colaborativo basado en elementos.",
                "Este documento modifica el <br>algoritmo EM</br> estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos <br>algoritmo EM</br> modificado.",
                "La sección 4 describe cómo aprender los parámetros del modelo utilizando el <br>algoritmo EM</br> estándar, junto con el uso de la nueva técnica propuesta en este artículo."
            ],
            "translated_text": "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual. Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un modelo jerárquico bayesiano. Aprender los parámetros del modelo para optimizar la verosimilitud conjunta de los datos de millones de usuarios es muy costoso computacionalmente. El <br>algoritmo EM</br> comúnmente utilizado converge muy lentamente debido a la escasez de datos en aplicaciones de IR. Este documento propone una nueva técnica de aprendizaje rápido para aprender un gran número de perfiles de usuario individuales. La eficacia y eficiencia del algoritmo propuesto están justificadas por la teoría y demostradas en datos reales de usuarios de Netflix y MovieLens. Categorías y Descriptores de Asignaturas: B.3.3 [Búsqueda y Recuperación de Información]: Filtrado de información Términos Generales: Algoritmos 1. La personalización es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales. Por ejemplo, las tiendas en línea, como Amazon y Netflix, ofrecen recomendaciones personalizadas de productos o servicios adicionales basadas en el historial de un usuario. Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de un usuario a partir de su historial. Un tema importante de personalización estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados basados en el contenido. Estos sistemas aprenden perfiles específicos de usuario a partir de la retroalimentación del usuario para poder recomendar información adaptada a los intereses de cada usuario sin necesidad de que el usuario realice una consulta explícita. Aprender los perfiles de usuario es el problema central de estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica qué tan relevante es un documento para el usuario. Uno de los principales desafíos de construir un sistema de recomendación o personalización es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña. Esto se conoce como el problema de inicio en frío. Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente retroalimentación de ese usuario para aprender un perfil de usuario confiable. Se ha realizado mucha investigación sobre cómo mejorar la precisión de clasificación cuando la cantidad de datos de entrenamiento etiquetados es pequeña. El enfoque de aprendizaje semisupervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26]. Otro enfoque es utilizar el conocimiento del dominio. Los investigadores han modificado diferentes algoritmos de aprendizaje, como NaïveBayes [17], regresión logística [7] y SVMs [22], para integrar el conocimiento del dominio en un clasificador de texto. El tercer enfoque consiste en tomar datos de entrenamiento de otros recursos [5][7]. La efectividad de estos enfoques diferentes es mixta, debido a qué tan bien se ajusta la suposición del modelo subyacente a los datos. Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano. Varios investigadores han demostrado que este enfoque intercambia eficazmente entre la información compartida y la específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario[27][25]. Para aprender un modelo jerárquico bayesiano, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados. Un sistema de recomendación maduro generalmente funciona para millones de usuarios. Es bien sabido que aprender los parámetros óptimos de un modelo jerárquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios. El <br>algoritmo EM</br> es una técnica comúnmente utilizada para el aprendizaje de parámetros debido a su simplicidad y garantía de convergencia. Sin embargo, un sistema de recomendación basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso. Con un análisis cuidadoso del <br>algoritmo EM</br> en este escenario (Sección 4), encontramos que el EM tering, o filtrado colaborativo basado en elementos. En este documento, las palabras filtrado y recomendación se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de las variables de entrada. También encontramos que actualizar el parámetro del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones. Este documento modifica el <br>algoritmo EM</br> estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos <br>algoritmo EM</br> modificado. La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M utilizamos la solución analítica en lugar de la solución numérica estimada en el paso E para esos parámetros. Esto reduce considerablemente la computación en una sola iteración de EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales. La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de regresión lineal jerárquica bayesiana utilizado para recomendaciones basadas en contenido. La sección 4 describe cómo aprender los parámetros del modelo utilizando el <br>algoritmo EM</br> estándar, junto con el uso de la nueva técnica propuesta en este artículo. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "classification": {
            "translated_key": "clasificación",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
                "A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model.",
                "Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive.",
                "The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications.",
                "This paper proposes a new fast learning technique to learn a large number of individual user profiles.",
                "The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens.",
                "Categories and Subject Descriptors: B.3.3 [Information Search and Retrieval]: Information filtering General Terms: Algorithms 1.",
                "INTRODUCTION Personalization is the future of the Web, and it has achieved great success in industrial applications.",
                "For example, online stores, such as Amazon and Netflix, provide customized recommendations for additional products or services based on a users history.",
                "Recent offerings such as My MSN, My Yahoo!, My Google, and Google News have attracted much attention due to their potential ability to infer a users interests from his/her history.",
                "One major personalization topic studied in the information retrieval community is content-based personal recommendation systems1 .",
                "These systems learn user-specific profiles from user feedback so that they can recommend information tailored to each individual users interest without requiring the user to make an explicit query.",
                "Learning the user profiles is the core problem for these systems.",
                "A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user.",
                "One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small.",
                "This is known as the cold start problem.",
                "This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile.",
                "There has been much research on improving <br>classification</br> accuracy when the amount of labeled training data is small.",
                "The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal [26].",
                "Another approach is using domain knowledge.",
                "Researchers have modified different learning algorithms, such as Na¨ıveBayes [17], logistic regression [7], and SVMs [22], to integrate domain knowledge into a text classifier.",
                "The third approach is borrowing training data from other resources [5][7].",
                "The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data.",
                "One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach.",
                "Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial performance for each user[27][25].",
                "In order to learn a Bayesian hierarchical model, the system usually tries to find the most likely model parameters for the given data.",
                "A mature recommendation system usually works for millions of users.",
                "It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users.",
                "The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee.",
                "However, a content based recommendation system often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector.",
                "With careful analysis of the EM algorithm in this scenario (Section 4), we find that the EM tering, or item-based collaborative filtering.",
                "In this paper, the words filtering and recommendation are used interchangeably. algorithm converges very slowly due to the sparseness of the input variables.",
                "We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O(MK), where M is the number of users and K is the number of dimensions.",
                "This paper modifies the standard EM algorithm to create an improved learning algorithm, which we call the Modified EM algorithm.",
                "The basic idea is that instead of calculating the numerical solution for all the user profile parameters, we derive the analytical solution of the parameters for some feature dimensions, and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters.",
                "This greatly reduces the computation at a single EM iteration, and also has the benefit of increasing the convergence speed of the learning algorithm.",
                "The proposed technique is not only well supported by theory, but also by experimental results.",
                "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression modeling framework used for content-based recommendations.",
                "Section 4 describes how to learn the model parameters using the standard EM algorithm, along with using the new technique proposed in this paper.",
                "The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6.",
                "Section 7 summarizes and offers concluding remarks. 2.",
                "RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the IR community since the 1970s.",
                "The approaches that have been used to solve this problem can be roughly classified into two major categories: content based filtering versus collaborative filtering.",
                "Content-based filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user.",
                "The user may read the delivered documents and provide explicit relevance feedback, which the filtering system then uses to update the users profile using relevance feedback retrieval models (e.g.",
                "Boolean models, vector space models, traditional probabilistic models [20] , inference networks [3] and language models [6]) or machine learning algorithms (e.g.",
                "Support Vector Machines (SVM), K nearest neighbors (K-NN) clustering, neural networks, logistic regression, or Winnow [16] [4] [23]).",
                "Collaborative filtering goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past.",
                "Memorybased heuristics and model based approaches have been used in collaborative filtering task [15] [8] [2] [14] [12] [11].",
                "This paper contributes to the content-based recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks[27][25].",
                "This paper does not intend to compare content-based filtering with collaborative filtering or claim which one is a better.",
                "We think each complements the other, and that content-based filtering is extremely useful for handling new documents/items with little or no user feedback.",
                "Similar to some other researchers[18][1][21], we found that a recommendation system will be more effective when both techniques are combined.",
                "However, this is beyond the scope of this paper and thus not discussed here. 3.",
                "BAYESIAN HIERARCHICAL LINEAR REGRESSION Assume there are M users in the system.",
                "The task of the system is to recommend documents that are relevant to each user.",
                "For each user, the system learns a user model from the users history.",
                "In the rest of this paper, we will use the following notations to represent the variables in the system. m = 1, 2, ..., M: The index for each individual user.",
                "M is the total number of users. wm: The user model parameter associated with user m. wm is a K dimensional vector. j = 1, 2, ..., Jm: The index for a set of data for user m. Jm is the number of training data for user m. Dm = {(xm,j, ym,j)}: A set of data associated with user m. xm,j is a K dimensional vector that represents the mth users jth training document.2 ym,j is a scalar that represents the label of document xm,j. k = 1, 2, ..., K: The dimensional index of input variable x.",
                "The Bayesian hierarchical modeling approach has been widely used in real-world information retrieval applications.",
                "Generalized Bayesian hierarchical linear models, one of the simplest Bayesian hierarchical models, are commonly used and have achieved good performance on collaborative filtering [25] and content-based adaptive filtering [27] tasks.",
                "Figure 1 shows the graphical representation of a Bayesian hierarchical model.",
                "In this graph, each user model is represented by a random vector wm.",
                "We assume a user model is sampled randomly from a prior distribution P(w|Φ).",
                "The system can predict the user label y of a document x given an estimation of wm (or wms distribution) using a function y = f(x, w).",
                "The model is called generalized Bayesian hierarchical linear model when y = f(wT x) is any generalized linear model such as logistic regression, SVM, and linear regression.",
                "To reliably estimate the user model wm, the system can borrow information from other users through the prior Φ = (µ, Σ).",
                "Now we look at one commonly used model where y = wT x + , where ∼ N(0, σ2 ) is a random noise [25][27].",
                "Assume that each user model wm is an independent draw from a population distribution P(w|Φ), which is governed by some unknown hyperparameter Φ.",
                "Let the prior distribution of user model w be a Gaussian distribution with parameter Φ = (µ, Σ), which is the commonly used prior for linear models. µ = (µ1, µ2, ..., µK ) is a K dimensional vector that represents the mean of the Gaussian distribution, and Σ is the covariance matrix of the Gaussian.",
                "Usually, a Normal distribution N(0, aI) and an Inverse Wishart distribution P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) are used as hyperprior to model the prior distribution of µ and Σ respectively.",
                "I is the K dimensional identity matrix, and a, b, and c are real numbers.",
                "With these settings, we have the following model for the system: 1. µ and Σ are sampled from N(0, aI) and IWν (aI), respectively. 2 The first dimension of x is a dummy variable that always equals to 1.",
                "Figure 1: Illustration of dependencies of variables in the hierarchical model.",
                "The rating, y, for a document, x, is conditioned on the document and the user model, wm, associated with the user m. Users share information about their models through the prior, Φ = (µ, Σ). 2.",
                "For each user m, wm is sampled randomly from a Normal distribution: wm ∼ N(µ, Σ2 ) 3.",
                "For each item xm,j, ym,j is sampled randomly from a Normal distribution: ym,j ∼ N(wT mxm,j, σ2 ).",
                "Let θ = (Φ, w1, w2, ..., wM ) represent the parameters of this system that needs to be estimated.",
                "The joint likelihood for all the variables in the probabilistic model, which includes the data and the parameters, is: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) For simplicity, we assume a, b, c, and σ are provided to the system. 4.",
                "MODEL PARAMETER LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple linear regression.",
                "Therefore, we will focus on estimating Φ.",
                "The maximum a priori solution of Φ is given by ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Finding the optimal solution for the above problem is challenging, since we need to integrate over all w = (w1, w2, ..., wM ), which are unobserved hidden variables. 4.1 EM Algorithm for Bayesian Hierarchical Linear Models In Equation 5, Φ is the parameter needs to be estimated, and the result depends on unobserved latent variables w. This kind of optimization problem is usually solved by the EM algorithm.",
                "Applying EM to the above problem, the set of user models w are the unobservable hidden variables and we have: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw Based on the derivation of the EM formulas presented in [24], we have the following Expectation-Maximization steps for finding the optimal hyperparameters.",
                "For space considerations, we omit the derivation in this paper since it is not the focus of our work.",
                "E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of the prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) where Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j M step: Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Many machine learning driven IR systems use a point estimate of the parameters at different stages in the system.",
                "However, we are estimating the posterior distribution of the variables at the E step.",
                "This avoids overfitting wm to a particular users data, which may be small and noisy.",
                "A detailed discussion about this subject appears in [10]. 4.2 New Algorithm: Modified EM Although the EM algorithm is widely studied and used in machine learning applications, using the above EM process to solve Bayesian hierarchical linear models in large-scale information retrieval systems is still too computationally expensive.",
                "In this section, we describe why the learning rate of the EM algorithm is slow in our application and introduce a new technique to make the learning of the Bayesian hierarchical linear model scalable.",
                "The derivation of the new learning algorithm will be based on the EM algorithm described in the previous section.",
                "First, the covariance matrices Σ2 , Σ2 m are usually too large to be computationally feasible.",
                "For simplicity, and as a common practice in IR, we do not model the correlation between features.",
                "Thus we approximate these matrices with K dimensional diagonal matrices.",
                "In the rest of the paper, we use these symbols to represent their diagonal approximations: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     Secondly, and most importantly, the input space is very sparse and there are many dimensions that are not related to a particular user in a real IR application.",
                "For example, let us consider a movie recommendation system, with the input variable x representing a particular movie.",
                "For the jth movie that the user m has seen, let xm,j,k = 1 if the director of the movie is Jean-Pierre Jeunet (indexed by k).",
                "Here we assume that whether or not that this director directed a specific movie is represented by the kth dimension.",
                "If the user m has never seen a movie directed by Jean-Pierre Jeunet, then the corresponding dimension is always zero (xm,j,k = 0 for all j) .",
                "One major drawback of the EM algorithm is that the importance of a feature, µk, may be greatly dominated by users who have never encountered this feature (i.e. j xm,j,k = 0) at the M step (Equation 8).",
                "Assume that 100 out of 1 million users have viewed the movie directed by Jean-Pierre Jeunet, and that the viewers have rated all of his movies as excellent.",
                "Intuitively, he is a good director and the weight for him (µk) should be high.",
                "Before the EM iteration, the initial value of µ is usually set to 0.",
                "Since the other 999,900 users have not seen this movie, their corresponding weights (w1,k, w2,k, ..., wm,k..., w999900,k) for that director would be very small initially.",
                "Thus the corresponding weight of the director in the prior µk at the first M step would be very low , and the variance σm,k will be large (Equations 8 and 7).",
                "It is undesirable that users who have never seen any movie produced by the director influence the importance of the director so much.",
                "This makes the convergence of the standard EM algorithm very slow.",
                "Now lets look at whether we can improve the learning speed of the algorithm.",
                "Without a loss of generality, let us assume that the kth dimension of the input variable x is not related to a particular user m. By which we mean, xm,j,k = 0 for all j = 1, ..., Jm.",
                "It is straightforward to prove that the kth row and kth column of Sxx,m are completely filled with zeros, and that the kth dimension of Sxy,m is zeroed as well.",
                "Thus the corresponding kth dimension of the user models mean, ¯wm, should be equal to that of the prior: ¯wm,k = µk, with the corresponding covariance of σm,k = σk.",
                "At the M step, the standard EM algorithm uses the numerical solution of the distribution P(wm|Dm, Φ) estimated at E step (Equation 8 and Equation 7).",
                "However, the numerical solutions are very unreliable for ¯wm,k and σm,k when the kth dimension is not related to the mth user.",
                "A better approach is using the analytical solutions ¯wm,k = µk, and σm,k = σk for the unrelated (m, k) pairs, along with the numerical solution estimated at E step for the other (m, k) pairs.",
                "Thus we get the following new EM-like algorithm: Modified E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) where sxx,m,k = j x2 m,j,k and sxy,m,k = j xm,j,kym,j Modified M Step Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step for related userfeature pairs.",
                "The M step implicitly uses the analytical solution for unrelated user-feature pairs. µk = 1 Mk m:related ¯wm,k (12) σ2 k = 1 Mk m:related σ2 m,k +( ¯wm,k − µk)( ¯wm,k − µk)T (13) where Mk is the number of users that are related to feature k We only estimate the diagonal of Σ2 m and Σ since we are using the diagonal approximation of the covariance matrices.",
                "To estimate ¯wm, we only need to calculate the numerical solutions for dimensions that are related to user m. To estimate σ2 k and µk, we only sum over users that are related to the kth feature.",
                "There are two major benefits of the new algorithm.",
                "First, because only the related (m, k) pairs are needed at the modified M step, the computational complexity in a single EM iteration is much smaller when the data is sparse, and many of (m, k) pairs are unrelated.",
                "Second, the parameters estimated at the modified M step (Equations 12 - 13) are more accurate than the standard M step described in Section 4.1 because the exact analytical solutions ¯wm,k = µk and σm,k = σk for the unrelated (m, k) pairs were used in the new algorithm instead of an approximate solution as in the standard algorithm. 5.",
                "EXPERIMENTAL METHODOLOGY 5.1 Evaluation Data Set To evaluate the proposed technique, we used the following three major data sets (Table 1): MovieLens Data: This data set was created by combining the relevance judgments from the MovieLens[9] data set with documents from the Internet Movie Database (IMDB).",
                "MovieLens allows users to rank how much he/she enjoyed a specific movie on a scale from 1 to 5.",
                "This likeability rating was used as a measurement of how relevant the document representing the corresponding movie is to the user.",
                "We considered documents with likeability scores of 4 or 5 as relevant, and documents with a score of 1 to 3 as irrelevant to the user.",
                "MovieLens provided relevance judgments on 3,057 documents from 6,040 separate users.",
                "On average, each user rated 151 movies, of these 87 were judged to be relevant.",
                "The average score for a document was 3.58.",
                "Documents representing each movie were constructed from the portion of the IMDB database that is available for public download[13].",
                "Based on this database, we created one document per movie that contained the relevant information about it (e.g. directors, actors, etc.).",
                "Table 1: Data Set Statistics.",
                "On Reuters, the number of rating for a simulated user is the number of documents relevant to the corresponding topic.",
                "Data Users Docs Ratings per User MovieLens 6,040 3,057 151 Netflix-all 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Netflix Data: This data set was constructed by combining documents about movies crawled from the web with a set of actual movie rental customer relevance judgments from Netflix[19].",
                "Netflix publicly provides the relevance judgments of 480,189 anonymous customers.",
                "There are around 100 million rating on a scale of 1 to 5 for 17,770 documents.",
                "Similar to MovieLens, we considered documents with likeability scores of 4 or 5 as relevant.",
                "This number was reduced to 1000 customers through random sampling.",
                "The average customer on the reduced data set provided 127 judgments, with 70 being deemed relevant.",
                "The average score for documents is 3.55.",
                "Reuters Data: This is the Reuters Corpus, Volume 1.",
                "It covers 810,000 Reuters English language news stories from August 20, 1996 to August 19, 1997.",
                "Only the first 100,000 news were used in our experiments.",
                "The Reuters corpus comes with a topic hierarchy.",
                "Each document is assigned to one of several locations on the hierarchical tree.",
                "The first level of the tree contains four topics, denoted as C, E, M, and G. For the experiments in this paper, the tree was cut at level 1 to create four smaller trees, each of which corresponds to one smaller data set: Reuters-E Reuters-C, ReutersM and Reuters-G. For each small data set, we created several profiles, one profile for each node in a sub-tree, to simulate multiple users, each with a related, yet separate definition of relevance.",
                "All the user profiles on a sub-tree are supposed to share the same prior model distribution.",
                "Since this corpus explicitly indicates only the relevant documents for a topic(user), all other documents are considered irrelevant. 5.2 Evaluation We designed the experiments to answer the following three questions: 1.",
                "Do we need to take the effort to use a Bayesian approach and learn a prior from other users? 2.",
                "Does the new algorithm work better than the standard EM algorithm for learning the Bayesian hierarchical linear model? 3.",
                "Can the new algorithm quickly learn many user models?",
                "To answer the first question, we compared the Bayesian hierarchical models with commonly used Norm-2 regularized linear regression models.",
                "In fact, the commonly used approach is equivalent to the model learned at the end of the first EM iteration.",
                "To answer the second question, we compared the proposed new algorithm with the standard EM algorithm to see whether the new learning algorithm is better.",
                "To answer the third question, we tested the efficiency of the new algorithm on the entire Netflix data set where about half a million user models need to be learned together.",
                "For the MovieLens and Netflix data sets, algorithm effectiveness was measured by mean square error, while on the Reuters data set <br>classification</br> error was used because it was more informative.",
                "We first evaluated the performance on each individual user, and then estimated the macro average over all users.",
                "Statistical tests (t-tests) were carried out to see whether the results are significant.",
                "For the experiments on the MovieLens and Netflix data sets, we used a random sample of 90% of each user for training, and the rest for testing.",
                "On Reuters data set, because there are too many relevant documents for each topic in the corpus, we used a random sample of 10% of each topic for training, and 10% of the remaining documents for testing.",
                "For all runs, we set (a, b, c, Σ ) = (0.1, 10, 0.1, 1) manually. 6.",
                "EXPERIMENTAL RESULTS Figure 2, Figure 3, and Figure 4 show that on all data sets, the Bayesian hierarchical modeling approach has a statistical significant improvement over the regularized linear regression model, which is equivalent to the Bayesian hierarchical models learned at the first iteration.",
                "Further analysis shows a negative correlation between the number of training data for a user and the improvement the system gets.",
                "This suggests that the borrowing information from other users has more significant improvements for users with less training data, which is as expected.",
                "However, the strength of the correlation differs over data sets, and the amount of training data is not the only characteristics that will influence the final performance.",
                "Figure 2 and Figure 3 show that the proposed new algorithm works better than the standard EM algorithm on the Netflix and MovieLens data sets.",
                "This is not surprising since the number of related feature-users pairs is much smaller than the number of unrelated feature-user pairs on these two data sets, and thus the proposed new algorithm is expected to work better.",
                "Figure 4 shows that the two algorithms work similarly on the Reuters-E data set.",
                "The accuracy of the new algorithm is similar to that of the standard EM algorithm at each iteration.",
                "The general patterns are very similar on other Reuters subsets.",
                "Further analysis shows that only 58% of the user-feature pairs are unrelated on this data set.",
                "Since the number of unrelated user-feature pairs is not extremely large, the sparseness is not a serious problem on the Reuters data set.",
                "Thus the two learning algorithms perform similarly.",
                "The results suggest that only on a corpus where the number of unrelated user-feature pairs is much larger than the number of related pairs, such as on the Netflix data set, the proposed technique will get a significant improvement over standard EM.",
                "However, the experiments also show that when the assumption does not hold, the new algorithm does not hurt performance.",
                "Although the proposed technique is faster than standard Figure 2: Performance on a Netflix subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iterations 2 - 10.",
                "Norm-2 regularized linear models are equivalent to the Bayesian hierarchical models learned at the first iteration, and are statistical significantly worse than the Bayesian hierarchical models. 0 2 4 6 8 10 1 1.05 1.1 1.15 1.2 1.25 1.3 1.35 1.4 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iterations ClassificationError New Algorithm Traditional EM Figure 3: Performance on a MovieLens subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iteration 2 to 17 (evaluated with mean square error). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iterations MeanSquareError New Algorithm Traditional EM 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iterations ClassificationError New Algorithm Traditional EM Figure 4: Performance on a Reuters-E subset with 26 profiles.",
                "Performances on Reuters-C, Reuters-M, Reuters-G are similar. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iterations ClassificationError New Algorithm Traditional EM EM, can it really learn millions of user models quickly?",
                "Our results show that the modified EM algorithm converges quickly, and 2 - 3 modified EM iterations would result in a reliable estimation.",
                "We evaluated the algorithm on the whole Netflix data set (480,189 users, 159,836 features, and 100 million ratings) running on a single CPU PC (2GB memory, P4 3GHz).",
                "The system finished one modified EM iteration in about 4 hours.",
                "This demonstrates that the proposed technique can efficiently handle large-scale system like Netflix. 7.",
                "CONCLUSION Content-based user profile learning is an important problem and is the key to providing personal recommendations to a user, especially for recommending new items with a small number of ratings.",
                "The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors.",
                "This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM.",
                "We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm.",
                "Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse, by which we mean the ratio of related user-feature pairs to unrelated pairs is small.",
                "Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold.",
                "In general, it is better to use the new algorithm since it is as simple as standard EM, the performance is either better or similar to EM, and the computation complexity is lower at each iteration.",
                "It is worth mentioning that even if the original problem space is not sparse, sparseness can be created artificially when a recommendation system uses user-specific feature selection techniques to reduce the noise and user model complexity.",
                "The proposed technique can also be adapted to improve the learning in such a scenario.",
                "We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU.",
                "The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear modeling approach to build a practical large scale system, even though the literature have demonstrated the effectiveness of the models in many applications.",
                "Our work is one major step on the road to make Bayesian hierarchical linear models more practical.",
                "The proposed new technique can be easily adapted to run on a cluster of machines, and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users.",
                "The research has much potential to benefit people using EM algorithm on many other IR problems as well as machine learning problems.",
                "EM algorithm is a commonly used machine learning technique.",
                "It is used to find model parameters in many IR problems where the training data is very sparse.",
                "Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering, the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems. 8.",
                "ACKNOWLEDGMENTS We thank Wei Xu, David Lewis and anonymous reviewers for valuable feedback on the work described in this paper.",
                "Part of the work was supported by Yahoo, Google, the Petascale Data Storage Institute and the Institute for Scalable Scientific Data Management.",
                "Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors, and do not necessarily reflect those of the sponsors. 9.",
                "REFERENCES [1] C. Basu, H. Hirsh, and W. Cohen.",
                "Recommendation as <br>classification</br>: Using social and content-based information in recommendation.",
                "In Proceedings of the Fifteenth National Conference on Artificial Intelligence, 1998. [2] J. S. Breese, D. Heckerman, and C. Kadie.",
                "Empirical analysis of predictive algorithms for collaborative filtering.",
                "Technical report, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan.",
                "Document filtering with inference networks.",
                "In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor, and A. Vinokourov.",
                "Kernel method for document filtering.",
                "In The Eleventh Text REtrieval Conference (TREC11).",
                "National Institute of Standards and Technology, special publication 500-249, 2003. [5] C. Chelba and A. Acero.",
                "Adaptation of maximum entropy capitalizer: Little data can help a lot.",
                "In D. Lin and D. Wu, editors, Proceedings of EMNLP 2004, pages 285-292, Barcelona, Spain, July 2004.",
                "Association for Computational Linguistics. [6] B. Croft and J. Lafferty, editors.",
                "Language Modeling for Information Retrieval.",
                "Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov, and A. Genkin.",
                "Constructing informative prior distributions from domain knowledge in text <br>classification</br>.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 493-500, New York, NY, USA, 2006.",
                "ACM Press. [8] J. Delgado and N. Ishii.",
                "Memory-based weightedmajority prediction for recommender systems.",
                "In ACM SIGIR99 Workshop on Recommender Systems, 1999. [9] GroupLens.",
                "Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman.",
                "A tutorial on learning with bayesian networks.",
                "In M. Jordan, editor, Learning in Graphical Models.",
                "Kluwer Academic, 1998. [11] J. L. Herlocker, J.",
                "A. Konstan, A. Borchers, and J. Riedl.",
                "An algorithmic framework for performing collaborative filtering.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 230-237, New York, NY, USA, 1999.",
                "ACM Press. [12] T. Hofmann and J. Puzicha.",
                "Latent class models for collaborative filtering.",
                "In IJCAI 99: Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 688-693, San Francisco, CA, USA, 1999.",
                "Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).",
                "Internet movie database. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai, and L. Si.",
                "An automatic weighting scheme for collaborative filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 337-344, New York, NY, USA, 2004.",
                "ACM Press. [15] J.",
                "A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl.",
                "GroupLens: Applying collaborative filtering to Usenet news.",
                "Communications of the ACM, 40(3):77-87, 1997. [16] D. Lewis.",
                "Applying support vector machines to the TREC-2001 batch filtering and routing tasks.",
                "In Proceedings of the Eleventh Text REtrieval Conference (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee, , and P. Yu.",
                "Text <br>classification</br> by labeling words.",
                "In Proceedings of The Nineteenth National Conference on Artificial Intelligence (AAAI-2004), July 25-29, 2004. [18] P. Melville, R. J. Mooney, and R. Nagarajan.",
                "Content-boosted collaborative filtering for improved recommendations.",
                "In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002), Edmonton, Canada, 2002. [19] Netflix.",
                "Netflix prize. http://www.netflixprize.com (visited on Nov. 30, 2006), 2006. [20] S. Robertson and K. Sparck-Jones.",
                "Relevance weighting of search terms.",
                "In Journal of the American Society for Information Science, volume 27, pages 129-146, 1976. [21] J. Wang, A. P. de Vries, and M. J. T. Reinders.",
                "Unifying user-based and item-based collaborative filtering approaches by similarity fusion.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 501-508, New York, NY, USA, 2006.",
                "ACM Press. [22] X. Wu and R. K. Srihari.",
                "Incorporating prior knowledge with weighted margin support vector machines.",
                "In Proc.",
                "ACM Knowledge Discovery Data Mining Conf. (ACM SIGKDD 2004), Aug. 2004. [23] Y. Yang, S. Yoo, J. Zhang, and B. Kisiel.",
                "Robustness of adaptive filtering methods in a cross-benchmark evaluation.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2005. [24] K. Yu, V. Tresp, and A. Schwaighofer.",
                "Learning gaussian processes from multiple tasks.",
                "In ICML 05: Proceedings of the 22nd international conference on Machine learning, pages 1012-1019, New York, NY, USA, 2005.",
                "ACM Press. [25] K. Yu, V. Tresp, and S. Yu.",
                "A nonparametric hierarchical bayesian framework for information filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 353-360.",
                "ACM Press, 2004. [26] X. Zhu.",
                "Semi-supervised learning literature survey.",
                "Technical report, University of Wisconsin - Madison, December 9, 2006. [27] P. Zigoris and Y. Zhang.",
                "Bayesian adaptive user profiling with explicit & implicit feedback.",
                "In Conference on Information and Knowledge Mangement 2006, 2006."
            ],
            "original_annotated_samples": [
                "There has been much research on improving <br>classification</br> accuracy when the amount of labeled training data is small.",
                "For the MovieLens and Netflix data sets, algorithm effectiveness was measured by mean square error, while on the Reuters data set <br>classification</br> error was used because it was more informative.",
                "Recommendation as <br>classification</br>: Using social and content-based information in recommendation.",
                "Constructing informative prior distributions from domain knowledge in text <br>classification</br>.",
                "Text <br>classification</br> by labeling words."
            ],
            "translated_annotated_samples": [
                "Se ha realizado mucha investigación sobre cómo mejorar la <br>precisión de clasificación</br> cuando la cantidad de datos de entrenamiento etiquetados es pequeña.",
                "Para los conjuntos de datos de MovieLens y Netflix, la efectividad del algoritmo se midió mediante el error cuadrático medio, mientras que en el conjunto de datos de Reuters se utilizó el <br>error de clasificación</br> porque era más informativo.",
                "Recomendación como <br>clasificación</br>: Utilizando información social y basada en contenido en la recomendación.",
                "Construyendo distribuciones a priori informativas a partir del conocimiento del dominio en la <br>clasificación</br> de textos.",
                "Clasificación de texto mediante etiquetado de palabras."
            ],
            "translated_text": "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual. Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un modelo jerárquico bayesiano. Aprender los parámetros del modelo para optimizar la verosimilitud conjunta de los datos de millones de usuarios es muy costoso computacionalmente. El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de datos en aplicaciones de IR. Este documento propone una nueva técnica de aprendizaje rápido para aprender un gran número de perfiles de usuario individuales. La eficacia y eficiencia del algoritmo propuesto están justificadas por la teoría y demostradas en datos reales de usuarios de Netflix y MovieLens. Categorías y Descriptores de Asignaturas: B.3.3 [Búsqueda y Recuperación de Información]: Filtrado de información Términos Generales: Algoritmos 1. La personalización es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales. Por ejemplo, las tiendas en línea, como Amazon y Netflix, ofrecen recomendaciones personalizadas de productos o servicios adicionales basadas en el historial de un usuario. Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de un usuario a partir de su historial. Un tema importante de personalización estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados basados en el contenido. Estos sistemas aprenden perfiles específicos de usuario a partir de la retroalimentación del usuario para poder recomendar información adaptada a los intereses de cada usuario sin necesidad de que el usuario realice una consulta explícita. Aprender los perfiles de usuario es el problema central de estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica qué tan relevante es un documento para el usuario. Uno de los principales desafíos de construir un sistema de recomendación o personalización es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña. Esto se conoce como el problema de inicio en frío. Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente retroalimentación de ese usuario para aprender un perfil de usuario confiable. Se ha realizado mucha investigación sobre cómo mejorar la <br>precisión de clasificación</br> cuando la cantidad de datos de entrenamiento etiquetados es pequeña. El enfoque de aprendizaje semisupervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26]. Otro enfoque es utilizar el conocimiento del dominio. Los investigadores han modificado diferentes algoritmos de aprendizaje, como NaïveBayes [17], regresión logística [7] y SVMs [22], para integrar el conocimiento del dominio en un clasificador de texto. El tercer enfoque consiste en tomar datos de entrenamiento de otros recursos [5][7]. La efectividad de estos enfoques diferentes es mixta, debido a qué tan bien se ajusta la suposición del modelo subyacente a los datos. Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano. Varios investigadores han demostrado que este enfoque intercambia eficazmente entre la información compartida y la específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario[27][25]. Para aprender un modelo jerárquico bayesiano, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados. Un sistema de recomendación maduro generalmente funciona para millones de usuarios. Es bien sabido que aprender los parámetros óptimos de un modelo jerárquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios. El algoritmo EM es una técnica comúnmente utilizada para el aprendizaje de parámetros debido a su simplicidad y garantía de convergencia. Sin embargo, un sistema de recomendación basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso. Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM tering, o filtrado colaborativo basado en elementos. En este documento, las palabras filtrado y recomendación se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de las variables de entrada. También encontramos que actualizar el parámetro del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones. Este documento modifica el algoritmo EM estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos algoritmo EM modificado. La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M utilizamos la solución analítica en lugar de la solución numérica estimada en el paso E para esos parámetros. Esto reduce considerablemente la computación en una sola iteración de EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales. La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de regresión lineal jerárquica bayesiana utilizado para recomendaciones basadas en contenido. La sección 4 describe cómo aprender los parámetros del modelo utilizando el algoritmo EM estándar, junto con el uso de la nueva técnica propuesta en este artículo. La configuración experimental y los resultados utilizados para validar la técnica de aprendizaje propuesta se informan en las Secciones 5 y 6. La sección 7 resume y ofrece observaciones finales. 2. TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de IR desde la década de 1970. Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus filtrado colaborativo. El filtrado basado en contenido estudia el escenario en el que un sistema de recomendación monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente. El usuario puede leer los documentos entregados y proporcionar retroalimentación explícita de relevancia, la cual el sistema de filtrado utiliza para actualizar el perfil del usuario mediante modelos de recuperación de retroalimentación de relevancia (por ejemplo,). Modelos booleanos, modelos de espacio vectorial, modelos probabilísticos tradicionales [20], redes de inferencia [3] y modelos de lenguaje [6]) o algoritmos de aprendizaje automático (por ejemplo, Máquinas de Vectores de Soporte (SVM), agrupamiento de K vecinos más cercanos (K-NN), redes neuronales, regresión logística o Winnow [16] [4] [23]. El filtrado colaborativo va más allá de simplemente usar el contenido de un documento para recomendar elementos a un usuario, aprovechando la información de otros usuarios con gustos y preferencias similares en el pasado. Se han utilizado heurísticas basadas en memoria y enfoques basados en modelos en la tarea de filtrado colaborativo [15] [8] [2] [14] [12] [11]. Este artículo contribuye a la investigación de recomendaciones basadas en contenido al mejorar la eficiencia y efectividad de los modelos lineales jerárquicos bayesianos, los cuales tienen una sólida base teórica y un buen rendimiento empírico en tareas de recomendación[27][25]. Este artículo no tiene la intención de comparar el filtrado basado en contenido con el filtrado colaborativo ni de afirmar cuál es mejor. Creemos que cada uno complementa al otro, y que el filtrado basado en contenido es extremadamente útil para manejar nuevos documentos/artículos con poco o ningún feedback del usuario. Similar a otros investigadores[18][1][21], encontramos que un sistema de recomendación será más efectivo cuando se combinan ambas técnicas. Sin embargo, esto está fuera del alcance de este documento y, por lo tanto, no se discute aquí. 3. REGRESIÓN LINEAL HIERÁRQUICA BAYESIANA Suponga que hay M usuarios en el sistema. La tarea del sistema es recomendar documentos que sean relevantes para cada usuario. Para cada usuario, el sistema aprende un modelo de usuario a partir del historial de los usuarios. En el resto de este documento, utilizaremos las siguientes notaciones para representar las variables en el sistema. m = 1, 2, ..., M: El índice para cada usuario individual. M es el número total de usuarios. wm: El parámetro del modelo de usuario asociado con el usuario m. wm es un vector de dimensión K. j = 1, 2, ..., Jm: El índice para un conjunto de datos para el usuario m. Jm es el número de datos de entrenamiento para el usuario m. Dm = {(xm,j, ym,j)}: Un conjunto de datos asociado con el usuario m. xm,j es un vector de dimensión K que representa el j-ésimo documento de entrenamiento del usuario m. ym,j es un escalar que representa la etiqueta del documento xm,j. k = 1, 2, ..., K: El índice dimensional de la variable de entrada x. El enfoque de modelado jerárquico bayesiano ha sido ampliamente utilizado en aplicaciones reales de recuperación de información. Los modelos lineales jerárquicos bayesianos generalizados, uno de los modelos jerárquicos bayesianos más simples, son comúnmente utilizados y han logrado un buen rendimiento en tareas de filtrado colaborativo [25] y filtrado adaptativo basado en contenido [27]. La Figura 1 muestra la representación gráfica de un modelo jerárquico bayesiano. En este gráfico, cada modelo de usuario está representado por un vector aleatorio wm. Suponemos que un modelo de usuario se muestrea aleatoriamente de una distribución previa P(w|Φ). El sistema puede predecir la etiqueta de usuario y de un documento x dado una estimación de wm (o distribución de wms) utilizando una función y = f(x, w). El modelo se llama modelo lineal jerárquico bayesiano generalizado cuando y = f(wT x) es cualquier modelo lineal generalizado como regresión logística, SVM y regresión lineal. Para estimar de manera confiable el modelo de usuario wm, el sistema puede obtener información de otros usuarios a través de la prior Φ = (µ, Σ). Ahora observamos un modelo comúnmente utilizado donde y = wT x + , donde ∼ N(0, σ2 ) es un ruido aleatorio [25][27]. Suponga que cada modelo de usuario wm es una muestra independiente de una distribución poblacional P(w|Φ), la cual está regida por un hiperparámetro desconocido Φ. Que la distribución previa del modelo de usuario w sea una distribución gaussiana con parámetro Φ = (µ, Σ), que es la distribución previa comúnmente utilizada para modelos lineales. µ = (µ1, µ2, ..., µK) es un vector de K dimensiones que representa la media de la distribución gaussiana, y Σ es la matriz de covarianza de la gaussiana. Normalmente, se utiliza una distribución Normal N(0, aI) y una distribución Inverse Wishart P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) como hiperprior para modelar la distribución previa de µ y Σ respectivamente. Yo es la matriz identidad de dimensión K, y a, b y c son números reales. Con esta configuración, tenemos el siguiente modelo para el sistema: 1. µ y Σ se muestrean de N(0, aI) e IWν (aI), respectivamente. 2. La primera dimensión de x es una variable ficticia que siempre es igual a 1. Figura 1: Ilustración de las dependencias de variables en el modelo jerárquico. La calificación, y, para un documento, x, está condicionada al documento y al modelo de usuario, wm, asociado con el usuario m. Los usuarios comparten información sobre sus modelos a través de la prior, Φ = (µ, Σ). Para cada usuario m, wm se muestrea aleatoriamente de una distribución Normal: wm ∼ N(µ, Σ2 ) 3. Para cada elemento xm,j, ym,j se muestrea aleatoriamente de una distribución Normal: ym,j ∼ N(wT mxm,j, σ2). Que θ = (Φ, w1, w2, ..., wM) represente los parámetros de este sistema que necesitan ser estimados. La verosimilitud conjunta de todas las variables en el modelo probabilístico, que incluye los datos y los parámetros, es: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) Para simplificar, asumimos que a, b, c y σ son proporcionados al sistema. 4. APRENDIZAJE DE PARÁMETROS DEL MODELO Si se conoce el prior Φ, encontrar el óptimo wm es sencillo: se trata de una regresión lineal simple. Por lo tanto, nos enfocaremos en estimar Φ. La solución a priori máxima de Φ se da por ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Encontrar la solución óptima para el problema anterior es desafiante, ya que necesitamos integrar sobre todos los w = (w1, w2, ..., wM), que son variables ocultas no observadas. 4.1 Algoritmo EM para Modelos Lineales Jerárquicos Bayesianos En la Ecuación 5, Φ es el parámetro que necesita ser estimado, y el resultado depende de las variables latentes no observadas w. Este tipo de problema de optimización suele resolverse mediante el algoritmo EM. Aplicando EM al problema anterior, el conjunto de modelos de usuario w son las variables ocultas no observables y tenemos: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw. Basándonos en la derivación de las fórmulas EM presentadas en [24], tenemos los siguientes pasos de Expectation-Maximization para encontrar los hiperparámetros óptimos. Por razones de espacio, omitimos la derivación en este artículo ya que no es el enfoque de nuestro trabajo. Paso E: Para cada usuario m, estime la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual del prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) donde Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j Paso M: Optimice el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Muchos sistemas de IR impulsados por aprendizaje automático utilizan una estimación puntual de los parámetros en diferentes etapas del sistema. Sin embargo, estamos estimando la distribución posterior de las variables en el paso E. Esto evita el sobreajuste de wm a los datos de un usuario en particular, que pueden ser pequeños y ruidosos. Una discusión detallada sobre este tema aparece en [10]. 4.2 Nuevo Algoritmo: EM Modificado. Aunque el algoritmo EM es ampliamente estudiado y utilizado en aplicaciones de aprendizaje automático, utilizar el proceso EM mencionado anteriormente para resolver modelos lineales jerárquicos bayesianos en sistemas de recuperación de información a gran escala sigue siendo demasiado costoso computacionalmente. En esta sección, describimos por qué la tasa de aprendizaje del algoritmo EM es lenta en nuestra aplicación e introducimos una nueva técnica para hacer que el aprendizaje del modelo lineal jerárquico bayesiano sea escalable. La derivación del nuevo algoritmo de aprendizaje estará basada en el algoritmo EM descrito en la sección anterior. Primero, las matrices de covarianza Σ2 , Σ2 m suelen ser demasiado grandes para ser computacionalmente factibles. Por simplicidad, y como práctica común en IR, no modelamos la correlación entre características. Así aproximamos estas matrices con matrices diagonales de dimensión K. En el resto del documento, utilizamos estos símbolos para representar sus aproximaciones diagonales: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     En segundo lugar, y lo más importante, el espacio de entrada es muy disperso y hay muchas dimensiones que no están relacionadas con un usuario particular en una aplicación de recuperación de información real. Por ejemplo, consideremos un sistema de recomendación de películas, con la variable de entrada x representando una película en particular. Para la j-ésima película que el usuario m ha visto, sea xm,j,k = 1 si el director de la película es Jean-Pierre Jeunet (indexado por k). Aquí asumimos que si este director dirigió una película específica está representado por la k-ésima dimensión. Si el usuario m nunca ha visto una película dirigida por Jean-Pierre Jeunet, entonces la dimensión correspondiente siempre es cero (xm,j,k = 0 para todos los j). Una desventaja importante del algoritmo EM es que la importancia de una característica, µk, puede estar fuertemente dominada por usuarios que nunca han encontrado esta característica (es decir, j xm,j,k = 0) en el paso M (Ecuación 8). Suponga que 100 de cada 1 millón de usuarios han visto la película dirigida por Jean-Pierre Jeunet, y que los espectadores han calificado todas sus películas como excelentes. Intuitivamente, él es un buen director y el peso para él (µk) debería ser alto. Antes de la iteración de EM, el valor inicial de µ suele establecerse en 0. Dado que los otros 999,900 usuarios no han visto esta película, sus pesos correspondientes (w1,k, w2,k, ..., wm,k..., w999900,k) para ese director serían muy pequeños inicialmente. Por lo tanto, el peso correspondiente del director en el µk anterior en el primer paso M sería muy bajo, y la varianza σm,k será grande (Ecuaciones 8 y 7). Es indeseable que los usuarios que nunca han visto ninguna película producida por el director influyan tanto en la importancia del director. Esto hace que la convergencia del algoritmo EM estándar sea muy lenta. Ahora veamos si podemos mejorar la velocidad de aprendizaje del algoritmo. Sin pérdida de generalidad, asumamos que la k-ésima dimensión de la variable de entrada x no está relacionada con un usuario particular m. Lo que queremos decir es que xm,j,k = 0 para todo j = 1, ..., Jm. Es sencillo demostrar que la k-ésima fila y la k-ésima columna de Sxx,m están completamente llenas de ceros, y que la k-ésima dimensión de Sxy,m también se anula. Por lo tanto, la dimensión k correspondiente de la media de los modelos de usuario, ¯wm, debería ser igual a la del anterior: ¯wm,k = µk, con la covarianza correspondiente de σm,k = σk. En el paso M, el algoritmo EM estándar utiliza la solución numérica de la distribución P(wm|Dm, Φ) estimada en el paso E (Ecuación 8 y Ecuación 7). Sin embargo, las soluciones numéricas son muy poco confiables para ¯wm,k y σm,k cuando la k-ésima dimensión no está relacionada con el m-ésimo usuario. Un enfoque mejor es utilizar las soluciones analíticas ¯wm,k = µk, y σm,k = σk para los pares no relacionados (m, k), junto con la solución numérica estimada en el paso E para los otros pares (m, k). Así obtenemos el siguiente nuevo algoritmo EM similar: Paso E modificado: Para cada usuario m, estimar la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual de σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) donde sxx,m,k = j x2 m,j,k y sxy,m,k = j xm,j,kym,j Paso M modificado Optimizar el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E para pares de usuario-característica relacionados. El paso M utiliza implícitamente la solución analítica para pares de usuario-característica no relacionados. µk = 1 Mk m:relacionado ¯wm,k (12) σ2 k = 1 Mk m:relacionado σ2 m,k + ( ¯wm,k − µk)( ¯wm,k − µk)T (13) donde Mk es el número de usuarios relacionados con la característica k. Solo estimamos la diagonal de Σ2 m y Σ, ya que estamos utilizando la aproximación diagonal de las matrices de covarianza. Para estimar ¯wm, solo necesitamos calcular las soluciones numéricas para las dimensiones que están relacionadas con el usuario m. Para estimar σ2 k y µk, solo sumamos sobre los usuarios que están relacionados con la k-ésima característica. Hay dos beneficios principales del nuevo algoritmo. Primero, dado que solo se necesitan los pares relacionados (m, k) en el paso M modificado, la complejidad computacional en una sola iteración de EM es mucho menor cuando los datos son dispersos y muchos de los pares (m, k) no están relacionados. En segundo lugar, los parámetros estimados en el paso M modificado (Ecuaciones 12 - 13) son más precisos que el paso M estándar descrito en la Sección 4.1 porque se utilizaron soluciones analíticas exactas ¯wm,k = µk y σm,k = σk para los pares no relacionados (m, k) en el nuevo algoritmo en lugar de una solución aproximada como en el algoritmo estándar. METODOLOGÍA EXPERIMENTAL 5.1 Conjunto de Datos de Evaluación Para evaluar la técnica propuesta, utilizamos los siguientes tres conjuntos de datos principales (Tabla 1): Datos de MovieLens: Este conjunto de datos fue creado combinando las valoraciones de relevancia del conjunto de datos de MovieLens[9] con documentos de la Base de Datos de Películas en Internet (IMDB). MovieLens permite a los usuarios clasificar cuánto disfrutaron una película específica en una escala del 1 al 5. Esta calificación de simpatía se utilizó como una medida de cuán relevante es el documento que representa la película correspondiente para el usuario. Consideramos los documentos con puntuaciones de 4 o 5 como relevantes, y los documentos con una puntuación de 1 a 3 como irrelevantes para el usuario. MovieLens proporcionó juicios de relevancia sobre 3,057 documentos de 6,040 usuarios diferentes. En promedio, cada usuario calificó 151 películas, de las cuales 87 fueron consideradas relevantes. La puntuación promedio para un documento fue de 3.58. Los documentos que representan cada película fueron construidos a partir de la porción de la base de datos de IMDB que está disponible para descarga pública[13]. Basándonos en esta base de datos, creamos un documento por película que contenía la información relevante sobre ella (por ejemplo, directores, actores, etc.). Tabla 1: Estadísticas del conjunto de datos. En Reuters, el número de calificaciones para un usuario simulado es el número de documentos relevantes para el tema correspondiente. Datos Usuarios Documentos Calificaciones por Usuario MovieLens 6,040 3,057 151 Netflix-todos 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Datos de Netflix: Este conjunto de datos fue construido combinando documentos sobre películas obtenidos de la web con un conjunto de juicios de relevancia de clientes reales de alquiler de películas de Netflix[19]. Netflix proporciona públicamente las evaluaciones de relevancia de 480,189 clientes anónimos. Hay alrededor de 100 millones de calificaciones en una escala del 1 al 5 para 17,770 documentos. Similar a MovieLens, consideramos documentos con puntuaciones de 4 o 5 de agradabilidad como relevantes. Este número se redujo a 1000 clientes mediante muestreo aleatorio. El cliente promedio en el conjunto de datos reducido proporcionó 127 juicios, de los cuales 70 fueron considerados relevantes. La puntuación promedio de los documentos es de 3.55. Datos de Reuters: Este es el Corpus de Reuters, Volumen 1. Cubre 810,000 noticias en inglés de Reuters desde el 20 de agosto de 1996 hasta el 19 de agosto de 1997. Solo se utilizaron las primeras 100,000 noticias en nuestros experimentos. El corpus de Reuters viene con una jerarquía de temas. Cada documento se asigna a una de varias ubicaciones en el árbol jerárquico. El primer nivel del árbol contiene cuatro temas, denotados como C, E, M y G. Para los experimentos en este artículo, el árbol fue cortado en el nivel 1 para crear cuatro árboles más pequeños, cada uno de los cuales corresponde a un conjunto de datos más pequeño: Reuters-E, Reuters-C, Reuters-M y Reuters-G. Para cada conjunto de datos pequeño, creamos varios perfiles, un perfil para cada nodo en un subárbol, para simular múltiples usuarios, cada uno con una definición de relevancia relacionada pero separada. Todos los perfiles de usuario en una sub-rama se supone que comparten la misma distribución de modelo previo. Dado que este corpus indica explícitamente solo los documentos relevantes para un tema (usuario), todos los demás documentos se consideran irrelevantes. 5.2 Evaluación Diseñamos los experimentos para responder a las siguientes tres preguntas: 1. ¿Necesitamos hacer el esfuerzo de utilizar un enfoque bayesiano y aprender una distribución a priori de otros usuarios? 2. ¿El nuevo algoritmo funciona mejor que el algoritmo EM estándar para aprender el modelo lineal jerárquico bayesiano? 3. ¿Puede el nuevo algoritmo aprender rápidamente muchos modelos de usuario? Para responder a la primera pregunta, comparamos los modelos jerárquicos bayesianos con los modelos de regresión lineal regularizados Norm-2 comúnmente utilizados. De hecho, el enfoque comúnmente utilizado es equivalente al modelo aprendido al final de la primera iteración de EM. Para responder a la segunda pregunta, comparamos el nuevo algoritmo propuesto con el algoritmo EM estándar para ver si el nuevo algoritmo de aprendizaje es mejor. Para responder a la tercera pregunta, probamos la eficiencia del nuevo algoritmo en todo el conjunto de datos de Netflix, donde aproximadamente medio millón de modelos de usuario deben ser aprendidos juntos. Para los conjuntos de datos de MovieLens y Netflix, la efectividad del algoritmo se midió mediante el error cuadrático medio, mientras que en el conjunto de datos de Reuters se utilizó el <br>error de clasificación</br> porque era más informativo. Primero evaluamos el rendimiento en cada usuario individual, y luego estimamos el promedio macro sobre todos los usuarios. Se realizaron pruebas estadísticas (pruebas t) para determinar si los resultados son significativos. Para los experimentos en los conjuntos de datos de MovieLens y Netflix, utilizamos una muestra aleatoria del 90% de cada usuario para entrenamiento, y el resto para pruebas. En el conjunto de datos de Reuters, debido a que hay demasiados documentos relevantes para cada tema en el corpus, utilizamos una muestra aleatoria del 10% de cada tema para el entrenamiento, y el 10% de los documentos restantes para las pruebas. Para todas las ejecuciones, establecimos (a, b, c, Σ) = (0.1, 10, 0.1, 1) manualmente. 6. RESULTADOS EXPERIMENTALES Las Figuras 2, 3 y 4 muestran que en todos los conjuntos de datos, el enfoque de modelado jerárquico bayesiano tiene una mejora estadísticamente significativa sobre el modelo de regresión lineal regularizado, que es equivalente a los modelos jerárquicos bayesianos aprendidos en la primera iteración. Un análisis adicional muestra una correlación negativa entre la cantidad de datos de entrenamiento para un usuario y la mejora que obtiene el sistema. Esto sugiere que la información prestada de otros usuarios tiene mejoras más significativas para usuarios con menos datos de entrenamiento, lo cual es lo esperado. Sin embargo, la fuerza de la correlación varía entre los conjuntos de datos, y la cantidad de datos de entrenamiento no es la única característica que influirá en el rendimiento final. Las Figuras 2 y 3 muestran que el nuevo algoritmo propuesto funciona mejor que el algoritmo EM estándar en los conjuntos de datos de Netflix y MovieLens. Esto no es sorprendente ya que el número de pares de características-usuarios relacionados es mucho menor que el número de pares de características-usuarios no relacionados en estos dos conjuntos de datos, por lo que se espera que el nuevo algoritmo propuesto funcione mejor. La Figura 4 muestra que los dos algoritmos funcionan de manera similar en el conjunto de datos de Reuters-E. La precisión del nuevo algoritmo es similar a la del algoritmo EM estándar en cada iteración. Los patrones generales son muy similares en otros subconjuntos de Reuters. Un análisis adicional muestra que solo el 58% de los pares usuario-característica no están relacionados en este conjunto de datos. Dado que el número de pares usuario-característica no relacionados no es extremadamente grande, la dispersión no es un problema grave en el conjunto de datos de Reuters. Por lo tanto, los dos algoritmos de aprendizaje se desempeñan de manera similar. Los resultados sugieren que solo en un corpus donde el número de pares usuario-característica no relacionados es mucho mayor que el número de pares relacionados, como en el conjunto de datos de Netflix, la técnica propuesta obtendrá una mejora significativa sobre el EM estándar. Sin embargo, los experimentos también muestran que cuando la suposición no se cumple, el nuevo algoritmo no afecta el rendimiento. Aunque la técnica propuesta es más rápida que la estándar. Figura 2: Rendimiento en un subconjunto de Netflix con 1,000 usuarios. El nuevo algoritmo es estadísticamente significativamente mejor que el algoritmo EM en las iteraciones 2 a 10. Los modelos lineales regularizados con norma-2 son equivalentes a los modelos jerárquicos bayesianos aprendidos en la primera iteración, y son estadísticamente significativamente peores que los modelos jerárquicos bayesianos. Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional Figura 3: Rendimiento en un subconjunto de MovieLens con 1,000 usuarios. El nuevo algoritmo es significativamente mejor estadísticamente que el algoritmo EM en las iteraciones 2 a 17 (evaluado con error cuadrático medio). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iteraciones ErrorCuadráticoMedio Nuevo Algoritmo EM Tradicional 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iteraciones Error de Clasificación Nuevo Algoritmo EM Tradicional Figura 4: Rendimiento en un subconjunto de Reuters-E con 26 perfiles. Las actuaciones en Reuters-C, Reuters-M, Reuters-G son similares. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional EM, ¿realmente puede aprender rápidamente millones de modelos de usuario? Nuestros resultados muestran que el algoritmo EM modificado converge rápidamente, y 2-3 iteraciones del EM modificado darían como resultado una estimación confiable. Evaluamos el algoritmo en todo el conjunto de datos de Netflix (480,189 usuarios, 159,836 características y 100 millones de valoraciones) ejecutándolo en un solo PC con CPU (2GB de memoria, P4 3GHz). El sistema completó una iteración EM modificada en aproximadamente 4 horas. Esto demuestra que la técnica propuesta puede manejar eficientemente sistemas a gran escala como Netflix. CONCLUSIÓN El aprendizaje de perfiles de usuario basado en contenido es un problema importante y es clave para proporcionar recomendaciones personales a un usuario, especialmente para recomendar nuevos elementos con un pequeño número de calificaciones. El enfoque de modelado jerárquico bayesiano se está convirtiendo en un enfoque importante para el aprendizaje de perfiles de usuario debido a su capacidad teóricamente justificada para ayudar a un usuario a través de la transferencia de información de otros usuarios mediante hiperpriors. Este artículo examinó la debilidad del enfoque de aprendizaje basado en EM popular para modelos lineales jerárquicos bayesianos y propuso una técnica de aprendizaje mejorada llamada EM Modificado. Demostramos que la nueva técnica es teóricamente más eficiente computacionalmente que el algoritmo EM estándar. La evaluación en los conjuntos de datos de MovieLens y Netflix demostró la efectividad de la nueva técnica cuando los datos son dispersos, lo que significa que la proporción de pares de usuario-característica relacionados con respecto a los pares no relacionados es pequeña. La evaluación en el conjunto de datos de Reuters mostró que la nueva técnica tuvo un rendimiento similar al algoritmo EM estándar cuando la condición de dispersión no se cumple. En general, es mejor utilizar el nuevo algoritmo ya que es tan simple como el EM estándar, el rendimiento es igual o mejor que el del EM, y la complejidad computacional es menor en cada iteración. Vale la pena mencionar que aunque el espacio de problemas original no sea disperso, la dispersión puede crearse artificialmente cuando un sistema de recomendación utiliza técnicas de selección de características específicas del usuario para reducir el ruido y la complejidad del modelo del usuario. La técnica propuesta también puede adaptarse para mejorar el aprendizaje en dicho escenario. También demostramos que la técnica propuesta puede aprender medio millón de perfiles de usuario a partir de 100 millones de valoraciones en unas pocas horas con una sola CPU. La investigación es importante porque la escalabilidad es una preocupación importante para los investigadores al utilizar el enfoque de modelado lineal jerárquico bayesiano para construir un sistema a gran escala práctico, a pesar de que la literatura ha demostrado la efectividad de los modelos en muchas aplicaciones. Nuestro trabajo es un paso importante en el camino para hacer que los modelos lineales jerárquicos bayesianos sean más prácticos. La nueva técnica propuesta se puede adaptar fácilmente para ejecutarse en un clúster de máquinas, y así acelerar aún más el proceso de aprendizaje para manejar un sistema a mayor escala con cientos de millones de usuarios. La investigación tiene mucho potencial para beneficiar a las personas utilizando el algoritmo EM en muchos otros problemas de IR, así como en problemas de aprendizaje automático. El algoritmo EM es una técnica de aprendizaje automático comúnmente utilizada. Se utiliza para encontrar los parámetros del modelo en muchos problemas de IR donde los datos de entrenamiento son muy dispersos. Aunque nos estamos centrando en los modelos lineales jerárquicos bayesianos para recomendación y filtrado, la nueva idea de utilizar una solución analítica en lugar de una solución numérica para pares de usuario-característica no relacionados en el paso M podría adaptarse a muchos otros problemas. 8. AGRADECIMIENTOS Agradecemos a Wei Xu, David Lewis y a los revisores anónimos por sus valiosos comentarios sobre el trabajo descrito en este artículo. Parte del trabajo fue apoyado por Yahoo, Google, el Instituto de Almacenamiento de Datos a Escala Peta y el Instituto de Gestión de Datos Científicos Escalables. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las de los patrocinadores. REFERENCIAS [1] C. Basu, H. Hirsh y W. Cohen. Recomendación como <br>clasificación</br>: Utilizando información social y basada en contenido en la recomendación. En Actas de la Decimoquinta Conferencia Nacional de Inteligencia Artificial, 1998. [2] J. S. Breese, D. Heckerman y C. Kadie. Análisis empírico de algoritmos predictivos para filtrado colaborativo. Informe técnico, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan. Filtrado de documentos con redes de inferencia. En Actas de la Decimonovena Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor y A. Vinokourov. Método del núcleo para el filtrado de documentos. En la Undécima Conferencia de Recuperación de Información de Texto (TREC11). Instituto Nacional de Normas y Tecnología, publicación especial 500-249, 2003. [5] C. Chelba y A. Acero. Adaptación del capitalizador de entropía máxima: Poca información puede ayudar mucho. En D. Lin y D. Wu, editores, Actas de EMNLP 2004, páginas 285-292, Barcelona, España, julio de 2004. Asociación de Lingüística Computacional. [6] B. Croft y J. Lafferty, editores. Modelado de lenguaje para recuperación de información. Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov y A. Genkin. Construyendo distribuciones a priori informativas a partir del conocimiento del dominio en la <br>clasificación</br> de textos. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 493-500, Nueva York, NY, EE. UU., 2006. ACM Press. [8] J. Delgado y N. Ishii. Predicción basada en memoria ponderada para sistemas de recomendación. En el Taller ACM SIGIR99 sobre Sistemas de Recomendación, 1999. [9] GroupLens. Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman. Un tutorial sobre el aprendizaje con redes bayesianas. En M. Jordan, editor, Aprendizaje en Modelos Gráficos. Kluwer Academic, 1998. [11] J. L. Herlocker, J. \n\nKluwer Academic, 1998. [11] J. L. Herlocker, J. A. Konstan, A. Borchers y J. Riedl. Un marco algorítmico para realizar filtrado colaborativo. En SIGIR 99: Actas de la 22ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 230-237, Nueva York, NY, EE. UU., 1999. ACM Press. [12] T. Hofmann y J. Puzicha. Modelos de clases latentes para filtrado colaborativo. En IJCAI 99: Actas de la Decimosexta Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 688-693, San Francisco, CA, EE. UU., 1999. Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).\nMorgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB). Base de datos de películas en internet. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai y L. Si. Un esquema de ponderación automática para filtrado colaborativo. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 337-344, Nueva York, NY, EE. UU., 2004. ACM Press. [15] J. A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon y J. Riedl. GroupLens: Aplicando filtrado colaborativo a las noticias de Usenet. Comunicaciones de la ACM, 40(3):77-87, 1997. [16] D. Lewis. Aplicando máquinas de vectores de soporte a las tareas de filtrado y enrutamiento por lotes de TREC-2001. En Actas de la Undécima Conferencia de Recuperación de Texto (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee y P. Yu. Clasificación de texto mediante etiquetado de palabras. ",
            "candidates": [],
            "error": [
                [
                    "precisión de clasificación",
                    "error de clasificación",
                    "clasificación",
                    "clasificación"
                ]
            ]
        },
        "rating": {
            "translated_key": "calificación",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
                "A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model.",
                "Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive.",
                "The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications.",
                "This paper proposes a new fast learning technique to learn a large number of individual user profiles.",
                "The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens.",
                "Categories and Subject Descriptors: B.3.3 [Information Search and Retrieval]: Information filtering General Terms: Algorithms 1.",
                "INTRODUCTION Personalization is the future of the Web, and it has achieved great success in industrial applications.",
                "For example, online stores, such as Amazon and Netflix, provide customized recommendations for additional products or services based on a users history.",
                "Recent offerings such as My MSN, My Yahoo!, My Google, and Google News have attracted much attention due to their potential ability to infer a users interests from his/her history.",
                "One major personalization topic studied in the information retrieval community is content-based personal recommendation systems1 .",
                "These systems learn user-specific profiles from user feedback so that they can recommend information tailored to each individual users interest without requiring the user to make an explicit query.",
                "Learning the user profiles is the core problem for these systems.",
                "A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user.",
                "One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small.",
                "This is known as the cold start problem.",
                "This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile.",
                "There has been much research on improving classification accuracy when the amount of labeled training data is small.",
                "The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal [26].",
                "Another approach is using domain knowledge.",
                "Researchers have modified different learning algorithms, such as Na¨ıveBayes [17], logistic regression [7], and SVMs [22], to integrate domain knowledge into a text classifier.",
                "The third approach is borrowing training data from other resources [5][7].",
                "The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data.",
                "One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach.",
                "Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial performance for each user[27][25].",
                "In order to learn a Bayesian hierarchical model, the system usually tries to find the most likely model parameters for the given data.",
                "A mature recommendation system usually works for millions of users.",
                "It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users.",
                "The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee.",
                "However, a content based recommendation system often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector.",
                "With careful analysis of the EM algorithm in this scenario (Section 4), we find that the EM tering, or item-based collaborative filtering.",
                "In this paper, the words filtering and recommendation are used interchangeably. algorithm converges very slowly due to the sparseness of the input variables.",
                "We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O(MK), where M is the number of users and K is the number of dimensions.",
                "This paper modifies the standard EM algorithm to create an improved learning algorithm, which we call the Modified EM algorithm.",
                "The basic idea is that instead of calculating the numerical solution for all the user profile parameters, we derive the analytical solution of the parameters for some feature dimensions, and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters.",
                "This greatly reduces the computation at a single EM iteration, and also has the benefit of increasing the convergence speed of the learning algorithm.",
                "The proposed technique is not only well supported by theory, but also by experimental results.",
                "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression modeling framework used for content-based recommendations.",
                "Section 4 describes how to learn the model parameters using the standard EM algorithm, along with using the new technique proposed in this paper.",
                "The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6.",
                "Section 7 summarizes and offers concluding remarks. 2.",
                "RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the IR community since the 1970s.",
                "The approaches that have been used to solve this problem can be roughly classified into two major categories: content based filtering versus collaborative filtering.",
                "Content-based filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user.",
                "The user may read the delivered documents and provide explicit relevance feedback, which the filtering system then uses to update the users profile using relevance feedback retrieval models (e.g.",
                "Boolean models, vector space models, traditional probabilistic models [20] , inference networks [3] and language models [6]) or machine learning algorithms (e.g.",
                "Support Vector Machines (SVM), K nearest neighbors (K-NN) clustering, neural networks, logistic regression, or Winnow [16] [4] [23]).",
                "Collaborative filtering goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past.",
                "Memorybased heuristics and model based approaches have been used in collaborative filtering task [15] [8] [2] [14] [12] [11].",
                "This paper contributes to the content-based recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks[27][25].",
                "This paper does not intend to compare content-based filtering with collaborative filtering or claim which one is a better.",
                "We think each complements the other, and that content-based filtering is extremely useful for handling new documents/items with little or no user feedback.",
                "Similar to some other researchers[18][1][21], we found that a recommendation system will be more effective when both techniques are combined.",
                "However, this is beyond the scope of this paper and thus not discussed here. 3.",
                "BAYESIAN HIERARCHICAL LINEAR REGRESSION Assume there are M users in the system.",
                "The task of the system is to recommend documents that are relevant to each user.",
                "For each user, the system learns a user model from the users history.",
                "In the rest of this paper, we will use the following notations to represent the variables in the system. m = 1, 2, ..., M: The index for each individual user.",
                "M is the total number of users. wm: The user model parameter associated with user m. wm is a K dimensional vector. j = 1, 2, ..., Jm: The index for a set of data for user m. Jm is the number of training data for user m. Dm = {(xm,j, ym,j)}: A set of data associated with user m. xm,j is a K dimensional vector that represents the mth users jth training document.2 ym,j is a scalar that represents the label of document xm,j. k = 1, 2, ..., K: The dimensional index of input variable x.",
                "The Bayesian hierarchical modeling approach has been widely used in real-world information retrieval applications.",
                "Generalized Bayesian hierarchical linear models, one of the simplest Bayesian hierarchical models, are commonly used and have achieved good performance on collaborative filtering [25] and content-based adaptive filtering [27] tasks.",
                "Figure 1 shows the graphical representation of a Bayesian hierarchical model.",
                "In this graph, each user model is represented by a random vector wm.",
                "We assume a user model is sampled randomly from a prior distribution P(w|Φ).",
                "The system can predict the user label y of a document x given an estimation of wm (or wms distribution) using a function y = f(x, w).",
                "The model is called generalized Bayesian hierarchical linear model when y = f(wT x) is any generalized linear model such as logistic regression, SVM, and linear regression.",
                "To reliably estimate the user model wm, the system can borrow information from other users through the prior Φ = (µ, Σ).",
                "Now we look at one commonly used model where y = wT x + , where ∼ N(0, σ2 ) is a random noise [25][27].",
                "Assume that each user model wm is an independent draw from a population distribution P(w|Φ), which is governed by some unknown hyperparameter Φ.",
                "Let the prior distribution of user model w be a Gaussian distribution with parameter Φ = (µ, Σ), which is the commonly used prior for linear models. µ = (µ1, µ2, ..., µK ) is a K dimensional vector that represents the mean of the Gaussian distribution, and Σ is the covariance matrix of the Gaussian.",
                "Usually, a Normal distribution N(0, aI) and an Inverse Wishart distribution P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) are used as hyperprior to model the prior distribution of µ and Σ respectively.",
                "I is the K dimensional identity matrix, and a, b, and c are real numbers.",
                "With these settings, we have the following model for the system: 1. µ and Σ are sampled from N(0, aI) and IWν (aI), respectively. 2 The first dimension of x is a dummy variable that always equals to 1.",
                "Figure 1: Illustration of dependencies of variables in the hierarchical model.",
                "The <br>rating</br>, y, for a document, x, is conditioned on the document and the user model, wm, associated with the user m. Users share information about their models through the prior, Φ = (µ, Σ). 2.",
                "For each user m, wm is sampled randomly from a Normal distribution: wm ∼ N(µ, Σ2 ) 3.",
                "For each item xm,j, ym,j is sampled randomly from a Normal distribution: ym,j ∼ N(wT mxm,j, σ2 ).",
                "Let θ = (Φ, w1, w2, ..., wM ) represent the parameters of this system that needs to be estimated.",
                "The joint likelihood for all the variables in the probabilistic model, which includes the data and the parameters, is: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) For simplicity, we assume a, b, c, and σ are provided to the system. 4.",
                "MODEL PARAMETER LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple linear regression.",
                "Therefore, we will focus on estimating Φ.",
                "The maximum a priori solution of Φ is given by ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Finding the optimal solution for the above problem is challenging, since we need to integrate over all w = (w1, w2, ..., wM ), which are unobserved hidden variables. 4.1 EM Algorithm for Bayesian Hierarchical Linear Models In Equation 5, Φ is the parameter needs to be estimated, and the result depends on unobserved latent variables w. This kind of optimization problem is usually solved by the EM algorithm.",
                "Applying EM to the above problem, the set of user models w are the unobservable hidden variables and we have: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw Based on the derivation of the EM formulas presented in [24], we have the following Expectation-Maximization steps for finding the optimal hyperparameters.",
                "For space considerations, we omit the derivation in this paper since it is not the focus of our work.",
                "E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of the prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) where Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j M step: Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Many machine learning driven IR systems use a point estimate of the parameters at different stages in the system.",
                "However, we are estimating the posterior distribution of the variables at the E step.",
                "This avoids overfitting wm to a particular users data, which may be small and noisy.",
                "A detailed discussion about this subject appears in [10]. 4.2 New Algorithm: Modified EM Although the EM algorithm is widely studied and used in machine learning applications, using the above EM process to solve Bayesian hierarchical linear models in large-scale information retrieval systems is still too computationally expensive.",
                "In this section, we describe why the learning rate of the EM algorithm is slow in our application and introduce a new technique to make the learning of the Bayesian hierarchical linear model scalable.",
                "The derivation of the new learning algorithm will be based on the EM algorithm described in the previous section.",
                "First, the covariance matrices Σ2 , Σ2 m are usually too large to be computationally feasible.",
                "For simplicity, and as a common practice in IR, we do not model the correlation between features.",
                "Thus we approximate these matrices with K dimensional diagonal matrices.",
                "In the rest of the paper, we use these symbols to represent their diagonal approximations: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     Secondly, and most importantly, the input space is very sparse and there are many dimensions that are not related to a particular user in a real IR application.",
                "For example, let us consider a movie recommendation system, with the input variable x representing a particular movie.",
                "For the jth movie that the user m has seen, let xm,j,k = 1 if the director of the movie is Jean-Pierre Jeunet (indexed by k).",
                "Here we assume that whether or not that this director directed a specific movie is represented by the kth dimension.",
                "If the user m has never seen a movie directed by Jean-Pierre Jeunet, then the corresponding dimension is always zero (xm,j,k = 0 for all j) .",
                "One major drawback of the EM algorithm is that the importance of a feature, µk, may be greatly dominated by users who have never encountered this feature (i.e. j xm,j,k = 0) at the M step (Equation 8).",
                "Assume that 100 out of 1 million users have viewed the movie directed by Jean-Pierre Jeunet, and that the viewers have rated all of his movies as excellent.",
                "Intuitively, he is a good director and the weight for him (µk) should be high.",
                "Before the EM iteration, the initial value of µ is usually set to 0.",
                "Since the other 999,900 users have not seen this movie, their corresponding weights (w1,k, w2,k, ..., wm,k..., w999900,k) for that director would be very small initially.",
                "Thus the corresponding weight of the director in the prior µk at the first M step would be very low , and the variance σm,k will be large (Equations 8 and 7).",
                "It is undesirable that users who have never seen any movie produced by the director influence the importance of the director so much.",
                "This makes the convergence of the standard EM algorithm very slow.",
                "Now lets look at whether we can improve the learning speed of the algorithm.",
                "Without a loss of generality, let us assume that the kth dimension of the input variable x is not related to a particular user m. By which we mean, xm,j,k = 0 for all j = 1, ..., Jm.",
                "It is straightforward to prove that the kth row and kth column of Sxx,m are completely filled with zeros, and that the kth dimension of Sxy,m is zeroed as well.",
                "Thus the corresponding kth dimension of the user models mean, ¯wm, should be equal to that of the prior: ¯wm,k = µk, with the corresponding covariance of σm,k = σk.",
                "At the M step, the standard EM algorithm uses the numerical solution of the distribution P(wm|Dm, Φ) estimated at E step (Equation 8 and Equation 7).",
                "However, the numerical solutions are very unreliable for ¯wm,k and σm,k when the kth dimension is not related to the mth user.",
                "A better approach is using the analytical solutions ¯wm,k = µk, and σm,k = σk for the unrelated (m, k) pairs, along with the numerical solution estimated at E step for the other (m, k) pairs.",
                "Thus we get the following new EM-like algorithm: Modified E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) where sxx,m,k = j x2 m,j,k and sxy,m,k = j xm,j,kym,j Modified M Step Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step for related userfeature pairs.",
                "The M step implicitly uses the analytical solution for unrelated user-feature pairs. µk = 1 Mk m:related ¯wm,k (12) σ2 k = 1 Mk m:related σ2 m,k +( ¯wm,k − µk)( ¯wm,k − µk)T (13) where Mk is the number of users that are related to feature k We only estimate the diagonal of Σ2 m and Σ since we are using the diagonal approximation of the covariance matrices.",
                "To estimate ¯wm, we only need to calculate the numerical solutions for dimensions that are related to user m. To estimate σ2 k and µk, we only sum over users that are related to the kth feature.",
                "There are two major benefits of the new algorithm.",
                "First, because only the related (m, k) pairs are needed at the modified M step, the computational complexity in a single EM iteration is much smaller when the data is sparse, and many of (m, k) pairs are unrelated.",
                "Second, the parameters estimated at the modified M step (Equations 12 - 13) are more accurate than the standard M step described in Section 4.1 because the exact analytical solutions ¯wm,k = µk and σm,k = σk for the unrelated (m, k) pairs were used in the new algorithm instead of an approximate solution as in the standard algorithm. 5.",
                "EXPERIMENTAL METHODOLOGY 5.1 Evaluation Data Set To evaluate the proposed technique, we used the following three major data sets (Table 1): MovieLens Data: This data set was created by combining the relevance judgments from the MovieLens[9] data set with documents from the Internet Movie Database (IMDB).",
                "MovieLens allows users to rank how much he/she enjoyed a specific movie on a scale from 1 to 5.",
                "This likeability <br>rating</br> was used as a measurement of how relevant the document representing the corresponding movie is to the user.",
                "We considered documents with likeability scores of 4 or 5 as relevant, and documents with a score of 1 to 3 as irrelevant to the user.",
                "MovieLens provided relevance judgments on 3,057 documents from 6,040 separate users.",
                "On average, each user rated 151 movies, of these 87 were judged to be relevant.",
                "The average score for a document was 3.58.",
                "Documents representing each movie were constructed from the portion of the IMDB database that is available for public download[13].",
                "Based on this database, we created one document per movie that contained the relevant information about it (e.g. directors, actors, etc.).",
                "Table 1: Data Set Statistics.",
                "On Reuters, the number of <br>rating</br> for a simulated user is the number of documents relevant to the corresponding topic.",
                "Data Users Docs Ratings per User MovieLens 6,040 3,057 151 Netflix-all 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Netflix Data: This data set was constructed by combining documents about movies crawled from the web with a set of actual movie rental customer relevance judgments from Netflix[19].",
                "Netflix publicly provides the relevance judgments of 480,189 anonymous customers.",
                "There are around 100 million <br>rating</br> on a scale of 1 to 5 for 17,770 documents.",
                "Similar to MovieLens, we considered documents with likeability scores of 4 or 5 as relevant.",
                "This number was reduced to 1000 customers through random sampling.",
                "The average customer on the reduced data set provided 127 judgments, with 70 being deemed relevant.",
                "The average score for documents is 3.55.",
                "Reuters Data: This is the Reuters Corpus, Volume 1.",
                "It covers 810,000 Reuters English language news stories from August 20, 1996 to August 19, 1997.",
                "Only the first 100,000 news were used in our experiments.",
                "The Reuters corpus comes with a topic hierarchy.",
                "Each document is assigned to one of several locations on the hierarchical tree.",
                "The first level of the tree contains four topics, denoted as C, E, M, and G. For the experiments in this paper, the tree was cut at level 1 to create four smaller trees, each of which corresponds to one smaller data set: Reuters-E Reuters-C, ReutersM and Reuters-G. For each small data set, we created several profiles, one profile for each node in a sub-tree, to simulate multiple users, each with a related, yet separate definition of relevance.",
                "All the user profiles on a sub-tree are supposed to share the same prior model distribution.",
                "Since this corpus explicitly indicates only the relevant documents for a topic(user), all other documents are considered irrelevant. 5.2 Evaluation We designed the experiments to answer the following three questions: 1.",
                "Do we need to take the effort to use a Bayesian approach and learn a prior from other users? 2.",
                "Does the new algorithm work better than the standard EM algorithm for learning the Bayesian hierarchical linear model? 3.",
                "Can the new algorithm quickly learn many user models?",
                "To answer the first question, we compared the Bayesian hierarchical models with commonly used Norm-2 regularized linear regression models.",
                "In fact, the commonly used approach is equivalent to the model learned at the end of the first EM iteration.",
                "To answer the second question, we compared the proposed new algorithm with the standard EM algorithm to see whether the new learning algorithm is better.",
                "To answer the third question, we tested the efficiency of the new algorithm on the entire Netflix data set where about half a million user models need to be learned together.",
                "For the MovieLens and Netflix data sets, algorithm effectiveness was measured by mean square error, while on the Reuters data set classification error was used because it was more informative.",
                "We first evaluated the performance on each individual user, and then estimated the macro average over all users.",
                "Statistical tests (t-tests) were carried out to see whether the results are significant.",
                "For the experiments on the MovieLens and Netflix data sets, we used a random sample of 90% of each user for training, and the rest for testing.",
                "On Reuters data set, because there are too many relevant documents for each topic in the corpus, we used a random sample of 10% of each topic for training, and 10% of the remaining documents for testing.",
                "For all runs, we set (a, b, c, Σ ) = (0.1, 10, 0.1, 1) manually. 6.",
                "EXPERIMENTAL RESULTS Figure 2, Figure 3, and Figure 4 show that on all data sets, the Bayesian hierarchical modeling approach has a statistical significant improvement over the regularized linear regression model, which is equivalent to the Bayesian hierarchical models learned at the first iteration.",
                "Further analysis shows a negative correlation between the number of training data for a user and the improvement the system gets.",
                "This suggests that the borrowing information from other users has more significant improvements for users with less training data, which is as expected.",
                "However, the strength of the correlation differs over data sets, and the amount of training data is not the only characteristics that will influence the final performance.",
                "Figure 2 and Figure 3 show that the proposed new algorithm works better than the standard EM algorithm on the Netflix and MovieLens data sets.",
                "This is not surprising since the number of related feature-users pairs is much smaller than the number of unrelated feature-user pairs on these two data sets, and thus the proposed new algorithm is expected to work better.",
                "Figure 4 shows that the two algorithms work similarly on the Reuters-E data set.",
                "The accuracy of the new algorithm is similar to that of the standard EM algorithm at each iteration.",
                "The general patterns are very similar on other Reuters subsets.",
                "Further analysis shows that only 58% of the user-feature pairs are unrelated on this data set.",
                "Since the number of unrelated user-feature pairs is not extremely large, the sparseness is not a serious problem on the Reuters data set.",
                "Thus the two learning algorithms perform similarly.",
                "The results suggest that only on a corpus where the number of unrelated user-feature pairs is much larger than the number of related pairs, such as on the Netflix data set, the proposed technique will get a significant improvement over standard EM.",
                "However, the experiments also show that when the assumption does not hold, the new algorithm does not hurt performance.",
                "Although the proposed technique is faster than standard Figure 2: Performance on a Netflix subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iterations 2 - 10.",
                "Norm-2 regularized linear models are equivalent to the Bayesian hierarchical models learned at the first iteration, and are statistical significantly worse than the Bayesian hierarchical models. 0 2 4 6 8 10 1 1.05 1.1 1.15 1.2 1.25 1.3 1.35 1.4 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iterations ClassificationError New Algorithm Traditional EM Figure 3: Performance on a MovieLens subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iteration 2 to 17 (evaluated with mean square error). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iterations MeanSquareError New Algorithm Traditional EM 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iterations ClassificationError New Algorithm Traditional EM Figure 4: Performance on a Reuters-E subset with 26 profiles.",
                "Performances on Reuters-C, Reuters-M, Reuters-G are similar. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iterations ClassificationError New Algorithm Traditional EM EM, can it really learn millions of user models quickly?",
                "Our results show that the modified EM algorithm converges quickly, and 2 - 3 modified EM iterations would result in a reliable estimation.",
                "We evaluated the algorithm on the whole Netflix data set (480,189 users, 159,836 features, and 100 million ratings) running on a single CPU PC (2GB memory, P4 3GHz).",
                "The system finished one modified EM iteration in about 4 hours.",
                "This demonstrates that the proposed technique can efficiently handle large-scale system like Netflix. 7.",
                "CONCLUSION Content-based user profile learning is an important problem and is the key to providing personal recommendations to a user, especially for recommending new items with a small number of ratings.",
                "The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors.",
                "This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM.",
                "We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm.",
                "Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse, by which we mean the ratio of related user-feature pairs to unrelated pairs is small.",
                "Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold.",
                "In general, it is better to use the new algorithm since it is as simple as standard EM, the performance is either better or similar to EM, and the computation complexity is lower at each iteration.",
                "It is worth mentioning that even if the original problem space is not sparse, sparseness can be created artificially when a recommendation system uses user-specific feature selection techniques to reduce the noise and user model complexity.",
                "The proposed technique can also be adapted to improve the learning in such a scenario.",
                "We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU.",
                "The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear modeling approach to build a practical large scale system, even though the literature have demonstrated the effectiveness of the models in many applications.",
                "Our work is one major step on the road to make Bayesian hierarchical linear models more practical.",
                "The proposed new technique can be easily adapted to run on a cluster of machines, and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users.",
                "The research has much potential to benefit people using EM algorithm on many other IR problems as well as machine learning problems.",
                "EM algorithm is a commonly used machine learning technique.",
                "It is used to find model parameters in many IR problems where the training data is very sparse.",
                "Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering, the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems. 8.",
                "ACKNOWLEDGMENTS We thank Wei Xu, David Lewis and anonymous reviewers for valuable feedback on the work described in this paper.",
                "Part of the work was supported by Yahoo, Google, the Petascale Data Storage Institute and the Institute for Scalable Scientific Data Management.",
                "Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors, and do not necessarily reflect those of the sponsors. 9.",
                "REFERENCES [1] C. Basu, H. Hirsh, and W. Cohen.",
                "Recommendation as classification: Using social and content-based information in recommendation.",
                "In Proceedings of the Fifteenth National Conference on Artificial Intelligence, 1998. [2] J. S. Breese, D. Heckerman, and C. Kadie.",
                "Empirical analysis of predictive algorithms for collaborative filtering.",
                "Technical report, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan.",
                "Document filtering with inference networks.",
                "In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor, and A. Vinokourov.",
                "Kernel method for document filtering.",
                "In The Eleventh Text REtrieval Conference (TREC11).",
                "National Institute of Standards and Technology, special publication 500-249, 2003. [5] C. Chelba and A. Acero.",
                "Adaptation of maximum entropy capitalizer: Little data can help a lot.",
                "In D. Lin and D. Wu, editors, Proceedings of EMNLP 2004, pages 285-292, Barcelona, Spain, July 2004.",
                "Association for Computational Linguistics. [6] B. Croft and J. Lafferty, editors.",
                "Language Modeling for Information Retrieval.",
                "Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov, and A. Genkin.",
                "Constructing informative prior distributions from domain knowledge in text classification.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 493-500, New York, NY, USA, 2006.",
                "ACM Press. [8] J. Delgado and N. Ishii.",
                "Memory-based weightedmajority prediction for recommender systems.",
                "In ACM SIGIR99 Workshop on Recommender Systems, 1999. [9] GroupLens.",
                "Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman.",
                "A tutorial on learning with bayesian networks.",
                "In M. Jordan, editor, Learning in Graphical Models.",
                "Kluwer Academic, 1998. [11] J. L. Herlocker, J.",
                "A. Konstan, A. Borchers, and J. Riedl.",
                "An algorithmic framework for performing collaborative filtering.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 230-237, New York, NY, USA, 1999.",
                "ACM Press. [12] T. Hofmann and J. Puzicha.",
                "Latent class models for collaborative filtering.",
                "In IJCAI 99: Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 688-693, San Francisco, CA, USA, 1999.",
                "Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).",
                "Internet movie database. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai, and L. Si.",
                "An automatic weighting scheme for collaborative filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 337-344, New York, NY, USA, 2004.",
                "ACM Press. [15] J.",
                "A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl.",
                "GroupLens: Applying collaborative filtering to Usenet news.",
                "Communications of the ACM, 40(3):77-87, 1997. [16] D. Lewis.",
                "Applying support vector machines to the TREC-2001 batch filtering and routing tasks.",
                "In Proceedings of the Eleventh Text REtrieval Conference (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee, , and P. Yu.",
                "Text classification by labeling words.",
                "In Proceedings of The Nineteenth National Conference on Artificial Intelligence (AAAI-2004), July 25-29, 2004. [18] P. Melville, R. J. Mooney, and R. Nagarajan.",
                "Content-boosted collaborative filtering for improved recommendations.",
                "In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002), Edmonton, Canada, 2002. [19] Netflix.",
                "Netflix prize. http://www.netflixprize.com (visited on Nov. 30, 2006), 2006. [20] S. Robertson and K. Sparck-Jones.",
                "Relevance weighting of search terms.",
                "In Journal of the American Society for Information Science, volume 27, pages 129-146, 1976. [21] J. Wang, A. P. de Vries, and M. J. T. Reinders.",
                "Unifying user-based and item-based collaborative filtering approaches by similarity fusion.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 501-508, New York, NY, USA, 2006.",
                "ACM Press. [22] X. Wu and R. K. Srihari.",
                "Incorporating prior knowledge with weighted margin support vector machines.",
                "In Proc.",
                "ACM Knowledge Discovery Data Mining Conf. (ACM SIGKDD 2004), Aug. 2004. [23] Y. Yang, S. Yoo, J. Zhang, and B. Kisiel.",
                "Robustness of adaptive filtering methods in a cross-benchmark evaluation.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2005. [24] K. Yu, V. Tresp, and A. Schwaighofer.",
                "Learning gaussian processes from multiple tasks.",
                "In ICML 05: Proceedings of the 22nd international conference on Machine learning, pages 1012-1019, New York, NY, USA, 2005.",
                "ACM Press. [25] K. Yu, V. Tresp, and S. Yu.",
                "A nonparametric hierarchical bayesian framework for information filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 353-360.",
                "ACM Press, 2004. [26] X. Zhu.",
                "Semi-supervised learning literature survey.",
                "Technical report, University of Wisconsin - Madison, December 9, 2006. [27] P. Zigoris and Y. Zhang.",
                "Bayesian adaptive user profiling with explicit & implicit feedback.",
                "In Conference on Information and Knowledge Mangement 2006, 2006."
            ],
            "original_annotated_samples": [
                "The <br>rating</br>, y, for a document, x, is conditioned on the document and the user model, wm, associated with the user m. Users share information about their models through the prior, Φ = (µ, Σ). 2.",
                "This likeability <br>rating</br> was used as a measurement of how relevant the document representing the corresponding movie is to the user.",
                "On Reuters, the number of <br>rating</br> for a simulated user is the number of documents relevant to the corresponding topic.",
                "There are around 100 million <br>rating</br> on a scale of 1 to 5 for 17,770 documents."
            ],
            "translated_annotated_samples": [
                "La <br>calificación</br>, y, para un documento, x, está condicionada al documento y al modelo de usuario, wm, asociado con el usuario m. Los usuarios comparten información sobre sus modelos a través de la prior, Φ = (µ, Σ).",
                "Esta <br>calificación de simpatía</br> se utilizó como una medida de cuán relevante es el documento que representa la película correspondiente para el usuario.",
                "En Reuters, el número de <br>calificaciones</br> para un usuario simulado es el número de documentos relevantes para el tema correspondiente.",
                "Hay alrededor de 100 millones de <br>calificaciones</br> en una escala del 1 al 5 para 17,770 documentos."
            ],
            "translated_text": "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual. Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un modelo jerárquico bayesiano. Aprender los parámetros del modelo para optimizar la verosimilitud conjunta de los datos de millones de usuarios es muy costoso computacionalmente. El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de datos en aplicaciones de IR. Este documento propone una nueva técnica de aprendizaje rápido para aprender un gran número de perfiles de usuario individuales. La eficacia y eficiencia del algoritmo propuesto están justificadas por la teoría y demostradas en datos reales de usuarios de Netflix y MovieLens. Categorías y Descriptores de Asignaturas: B.3.3 [Búsqueda y Recuperación de Información]: Filtrado de información Términos Generales: Algoritmos 1. La personalización es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales. Por ejemplo, las tiendas en línea, como Amazon y Netflix, ofrecen recomendaciones personalizadas de productos o servicios adicionales basadas en el historial de un usuario. Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de un usuario a partir de su historial. Un tema importante de personalización estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados basados en el contenido. Estos sistemas aprenden perfiles específicos de usuario a partir de la retroalimentación del usuario para poder recomendar información adaptada a los intereses de cada usuario sin necesidad de que el usuario realice una consulta explícita. Aprender los perfiles de usuario es el problema central de estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica qué tan relevante es un documento para el usuario. Uno de los principales desafíos de construir un sistema de recomendación o personalización es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña. Esto se conoce como el problema de inicio en frío. Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente retroalimentación de ese usuario para aprender un perfil de usuario confiable. Se ha realizado mucha investigación sobre cómo mejorar la precisión de clasificación cuando la cantidad de datos de entrenamiento etiquetados es pequeña. El enfoque de aprendizaje semisupervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26]. Otro enfoque es utilizar el conocimiento del dominio. Los investigadores han modificado diferentes algoritmos de aprendizaje, como NaïveBayes [17], regresión logística [7] y SVMs [22], para integrar el conocimiento del dominio en un clasificador de texto. El tercer enfoque consiste en tomar datos de entrenamiento de otros recursos [5][7]. La efectividad de estos enfoques diferentes es mixta, debido a qué tan bien se ajusta la suposición del modelo subyacente a los datos. Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano. Varios investigadores han demostrado que este enfoque intercambia eficazmente entre la información compartida y la específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario[27][25]. Para aprender un modelo jerárquico bayesiano, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados. Un sistema de recomendación maduro generalmente funciona para millones de usuarios. Es bien sabido que aprender los parámetros óptimos de un modelo jerárquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios. El algoritmo EM es una técnica comúnmente utilizada para el aprendizaje de parámetros debido a su simplicidad y garantía de convergencia. Sin embargo, un sistema de recomendación basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso. Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM tering, o filtrado colaborativo basado en elementos. En este documento, las palabras filtrado y recomendación se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de las variables de entrada. También encontramos que actualizar el parámetro del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones. Este documento modifica el algoritmo EM estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos algoritmo EM modificado. La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M utilizamos la solución analítica en lugar de la solución numérica estimada en el paso E para esos parámetros. Esto reduce considerablemente la computación en una sola iteración de EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales. La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de regresión lineal jerárquica bayesiana utilizado para recomendaciones basadas en contenido. La sección 4 describe cómo aprender los parámetros del modelo utilizando el algoritmo EM estándar, junto con el uso de la nueva técnica propuesta en este artículo. La configuración experimental y los resultados utilizados para validar la técnica de aprendizaje propuesta se informan en las Secciones 5 y 6. La sección 7 resume y ofrece observaciones finales. 2. TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de IR desde la década de 1970. Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus filtrado colaborativo. El filtrado basado en contenido estudia el escenario en el que un sistema de recomendación monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente. El usuario puede leer los documentos entregados y proporcionar retroalimentación explícita de relevancia, la cual el sistema de filtrado utiliza para actualizar el perfil del usuario mediante modelos de recuperación de retroalimentación de relevancia (por ejemplo,). Modelos booleanos, modelos de espacio vectorial, modelos probabilísticos tradicionales [20], redes de inferencia [3] y modelos de lenguaje [6]) o algoritmos de aprendizaje automático (por ejemplo, Máquinas de Vectores de Soporte (SVM), agrupamiento de K vecinos más cercanos (K-NN), redes neuronales, regresión logística o Winnow [16] [4] [23]. El filtrado colaborativo va más allá de simplemente usar el contenido de un documento para recomendar elementos a un usuario, aprovechando la información de otros usuarios con gustos y preferencias similares en el pasado. Se han utilizado heurísticas basadas en memoria y enfoques basados en modelos en la tarea de filtrado colaborativo [15] [8] [2] [14] [12] [11]. Este artículo contribuye a la investigación de recomendaciones basadas en contenido al mejorar la eficiencia y efectividad de los modelos lineales jerárquicos bayesianos, los cuales tienen una sólida base teórica y un buen rendimiento empírico en tareas de recomendación[27][25]. Este artículo no tiene la intención de comparar el filtrado basado en contenido con el filtrado colaborativo ni de afirmar cuál es mejor. Creemos que cada uno complementa al otro, y que el filtrado basado en contenido es extremadamente útil para manejar nuevos documentos/artículos con poco o ningún feedback del usuario. Similar a otros investigadores[18][1][21], encontramos que un sistema de recomendación será más efectivo cuando se combinan ambas técnicas. Sin embargo, esto está fuera del alcance de este documento y, por lo tanto, no se discute aquí. 3. REGRESIÓN LINEAL HIERÁRQUICA BAYESIANA Suponga que hay M usuarios en el sistema. La tarea del sistema es recomendar documentos que sean relevantes para cada usuario. Para cada usuario, el sistema aprende un modelo de usuario a partir del historial de los usuarios. En el resto de este documento, utilizaremos las siguientes notaciones para representar las variables en el sistema. m = 1, 2, ..., M: El índice para cada usuario individual. M es el número total de usuarios. wm: El parámetro del modelo de usuario asociado con el usuario m. wm es un vector de dimensión K. j = 1, 2, ..., Jm: El índice para un conjunto de datos para el usuario m. Jm es el número de datos de entrenamiento para el usuario m. Dm = {(xm,j, ym,j)}: Un conjunto de datos asociado con el usuario m. xm,j es un vector de dimensión K que representa el j-ésimo documento de entrenamiento del usuario m. ym,j es un escalar que representa la etiqueta del documento xm,j. k = 1, 2, ..., K: El índice dimensional de la variable de entrada x. El enfoque de modelado jerárquico bayesiano ha sido ampliamente utilizado en aplicaciones reales de recuperación de información. Los modelos lineales jerárquicos bayesianos generalizados, uno de los modelos jerárquicos bayesianos más simples, son comúnmente utilizados y han logrado un buen rendimiento en tareas de filtrado colaborativo [25] y filtrado adaptativo basado en contenido [27]. La Figura 1 muestra la representación gráfica de un modelo jerárquico bayesiano. En este gráfico, cada modelo de usuario está representado por un vector aleatorio wm. Suponemos que un modelo de usuario se muestrea aleatoriamente de una distribución previa P(w|Φ). El sistema puede predecir la etiqueta de usuario y de un documento x dado una estimación de wm (o distribución de wms) utilizando una función y = f(x, w). El modelo se llama modelo lineal jerárquico bayesiano generalizado cuando y = f(wT x) es cualquier modelo lineal generalizado como regresión logística, SVM y regresión lineal. Para estimar de manera confiable el modelo de usuario wm, el sistema puede obtener información de otros usuarios a través de la prior Φ = (µ, Σ). Ahora observamos un modelo comúnmente utilizado donde y = wT x + , donde ∼ N(0, σ2 ) es un ruido aleatorio [25][27]. Suponga que cada modelo de usuario wm es una muestra independiente de una distribución poblacional P(w|Φ), la cual está regida por un hiperparámetro desconocido Φ. Que la distribución previa del modelo de usuario w sea una distribución gaussiana con parámetro Φ = (µ, Σ), que es la distribución previa comúnmente utilizada para modelos lineales. µ = (µ1, µ2, ..., µK) es un vector de K dimensiones que representa la media de la distribución gaussiana, y Σ es la matriz de covarianza de la gaussiana. Normalmente, se utiliza una distribución Normal N(0, aI) y una distribución Inverse Wishart P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) como hiperprior para modelar la distribución previa de µ y Σ respectivamente. Yo es la matriz identidad de dimensión K, y a, b y c son números reales. Con esta configuración, tenemos el siguiente modelo para el sistema: 1. µ y Σ se muestrean de N(0, aI) e IWν (aI), respectivamente. 2. La primera dimensión de x es una variable ficticia que siempre es igual a 1. Figura 1: Ilustración de las dependencias de variables en el modelo jerárquico. La <br>calificación</br>, y, para un documento, x, está condicionada al documento y al modelo de usuario, wm, asociado con el usuario m. Los usuarios comparten información sobre sus modelos a través de la prior, Φ = (µ, Σ). Para cada usuario m, wm se muestrea aleatoriamente de una distribución Normal: wm ∼ N(µ, Σ2 ) 3. Para cada elemento xm,j, ym,j se muestrea aleatoriamente de una distribución Normal: ym,j ∼ N(wT mxm,j, σ2). Que θ = (Φ, w1, w2, ..., wM) represente los parámetros de este sistema que necesitan ser estimados. La verosimilitud conjunta de todas las variables en el modelo probabilístico, que incluye los datos y los parámetros, es: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) Para simplificar, asumimos que a, b, c y σ son proporcionados al sistema. 4. APRENDIZAJE DE PARÁMETROS DEL MODELO Si se conoce el prior Φ, encontrar el óptimo wm es sencillo: se trata de una regresión lineal simple. Por lo tanto, nos enfocaremos en estimar Φ. La solución a priori máxima de Φ se da por ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Encontrar la solución óptima para el problema anterior es desafiante, ya que necesitamos integrar sobre todos los w = (w1, w2, ..., wM), que son variables ocultas no observadas. 4.1 Algoritmo EM para Modelos Lineales Jerárquicos Bayesianos En la Ecuación 5, Φ es el parámetro que necesita ser estimado, y el resultado depende de las variables latentes no observadas w. Este tipo de problema de optimización suele resolverse mediante el algoritmo EM. Aplicando EM al problema anterior, el conjunto de modelos de usuario w son las variables ocultas no observables y tenemos: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw. Basándonos en la derivación de las fórmulas EM presentadas en [24], tenemos los siguientes pasos de Expectation-Maximization para encontrar los hiperparámetros óptimos. Por razones de espacio, omitimos la derivación en este artículo ya que no es el enfoque de nuestro trabajo. Paso E: Para cada usuario m, estime la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual del prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) donde Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j Paso M: Optimice el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Muchos sistemas de IR impulsados por aprendizaje automático utilizan una estimación puntual de los parámetros en diferentes etapas del sistema. Sin embargo, estamos estimando la distribución posterior de las variables en el paso E. Esto evita el sobreajuste de wm a los datos de un usuario en particular, que pueden ser pequeños y ruidosos. Una discusión detallada sobre este tema aparece en [10]. 4.2 Nuevo Algoritmo: EM Modificado. Aunque el algoritmo EM es ampliamente estudiado y utilizado en aplicaciones de aprendizaje automático, utilizar el proceso EM mencionado anteriormente para resolver modelos lineales jerárquicos bayesianos en sistemas de recuperación de información a gran escala sigue siendo demasiado costoso computacionalmente. En esta sección, describimos por qué la tasa de aprendizaje del algoritmo EM es lenta en nuestra aplicación e introducimos una nueva técnica para hacer que el aprendizaje del modelo lineal jerárquico bayesiano sea escalable. La derivación del nuevo algoritmo de aprendizaje estará basada en el algoritmo EM descrito en la sección anterior. Primero, las matrices de covarianza Σ2 , Σ2 m suelen ser demasiado grandes para ser computacionalmente factibles. Por simplicidad, y como práctica común en IR, no modelamos la correlación entre características. Así aproximamos estas matrices con matrices diagonales de dimensión K. En el resto del documento, utilizamos estos símbolos para representar sus aproximaciones diagonales: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     En segundo lugar, y lo más importante, el espacio de entrada es muy disperso y hay muchas dimensiones que no están relacionadas con un usuario particular en una aplicación de recuperación de información real. Por ejemplo, consideremos un sistema de recomendación de películas, con la variable de entrada x representando una película en particular. Para la j-ésima película que el usuario m ha visto, sea xm,j,k = 1 si el director de la película es Jean-Pierre Jeunet (indexado por k). Aquí asumimos que si este director dirigió una película específica está representado por la k-ésima dimensión. Si el usuario m nunca ha visto una película dirigida por Jean-Pierre Jeunet, entonces la dimensión correspondiente siempre es cero (xm,j,k = 0 para todos los j). Una desventaja importante del algoritmo EM es que la importancia de una característica, µk, puede estar fuertemente dominada por usuarios que nunca han encontrado esta característica (es decir, j xm,j,k = 0) en el paso M (Ecuación 8). Suponga que 100 de cada 1 millón de usuarios han visto la película dirigida por Jean-Pierre Jeunet, y que los espectadores han calificado todas sus películas como excelentes. Intuitivamente, él es un buen director y el peso para él (µk) debería ser alto. Antes de la iteración de EM, el valor inicial de µ suele establecerse en 0. Dado que los otros 999,900 usuarios no han visto esta película, sus pesos correspondientes (w1,k, w2,k, ..., wm,k..., w999900,k) para ese director serían muy pequeños inicialmente. Por lo tanto, el peso correspondiente del director en el µk anterior en el primer paso M sería muy bajo, y la varianza σm,k será grande (Ecuaciones 8 y 7). Es indeseable que los usuarios que nunca han visto ninguna película producida por el director influyan tanto en la importancia del director. Esto hace que la convergencia del algoritmo EM estándar sea muy lenta. Ahora veamos si podemos mejorar la velocidad de aprendizaje del algoritmo. Sin pérdida de generalidad, asumamos que la k-ésima dimensión de la variable de entrada x no está relacionada con un usuario particular m. Lo que queremos decir es que xm,j,k = 0 para todo j = 1, ..., Jm. Es sencillo demostrar que la k-ésima fila y la k-ésima columna de Sxx,m están completamente llenas de ceros, y que la k-ésima dimensión de Sxy,m también se anula. Por lo tanto, la dimensión k correspondiente de la media de los modelos de usuario, ¯wm, debería ser igual a la del anterior: ¯wm,k = µk, con la covarianza correspondiente de σm,k = σk. En el paso M, el algoritmo EM estándar utiliza la solución numérica de la distribución P(wm|Dm, Φ) estimada en el paso E (Ecuación 8 y Ecuación 7). Sin embargo, las soluciones numéricas son muy poco confiables para ¯wm,k y σm,k cuando la k-ésima dimensión no está relacionada con el m-ésimo usuario. Un enfoque mejor es utilizar las soluciones analíticas ¯wm,k = µk, y σm,k = σk para los pares no relacionados (m, k), junto con la solución numérica estimada en el paso E para los otros pares (m, k). Así obtenemos el siguiente nuevo algoritmo EM similar: Paso E modificado: Para cada usuario m, estimar la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual de σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) donde sxx,m,k = j x2 m,j,k y sxy,m,k = j xm,j,kym,j Paso M modificado Optimizar el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E para pares de usuario-característica relacionados. El paso M utiliza implícitamente la solución analítica para pares de usuario-característica no relacionados. µk = 1 Mk m:relacionado ¯wm,k (12) σ2 k = 1 Mk m:relacionado σ2 m,k + ( ¯wm,k − µk)( ¯wm,k − µk)T (13) donde Mk es el número de usuarios relacionados con la característica k. Solo estimamos la diagonal de Σ2 m y Σ, ya que estamos utilizando la aproximación diagonal de las matrices de covarianza. Para estimar ¯wm, solo necesitamos calcular las soluciones numéricas para las dimensiones que están relacionadas con el usuario m. Para estimar σ2 k y µk, solo sumamos sobre los usuarios que están relacionados con la k-ésima característica. Hay dos beneficios principales del nuevo algoritmo. Primero, dado que solo se necesitan los pares relacionados (m, k) en el paso M modificado, la complejidad computacional en una sola iteración de EM es mucho menor cuando los datos son dispersos y muchos de los pares (m, k) no están relacionados. En segundo lugar, los parámetros estimados en el paso M modificado (Ecuaciones 12 - 13) son más precisos que el paso M estándar descrito en la Sección 4.1 porque se utilizaron soluciones analíticas exactas ¯wm,k = µk y σm,k = σk para los pares no relacionados (m, k) en el nuevo algoritmo en lugar de una solución aproximada como en el algoritmo estándar. METODOLOGÍA EXPERIMENTAL 5.1 Conjunto de Datos de Evaluación Para evaluar la técnica propuesta, utilizamos los siguientes tres conjuntos de datos principales (Tabla 1): Datos de MovieLens: Este conjunto de datos fue creado combinando las valoraciones de relevancia del conjunto de datos de MovieLens[9] con documentos de la Base de Datos de Películas en Internet (IMDB). MovieLens permite a los usuarios clasificar cuánto disfrutaron una película específica en una escala del 1 al 5. Esta <br>calificación de simpatía</br> se utilizó como una medida de cuán relevante es el documento que representa la película correspondiente para el usuario. Consideramos los documentos con puntuaciones de 4 o 5 como relevantes, y los documentos con una puntuación de 1 a 3 como irrelevantes para el usuario. MovieLens proporcionó juicios de relevancia sobre 3,057 documentos de 6,040 usuarios diferentes. En promedio, cada usuario calificó 151 películas, de las cuales 87 fueron consideradas relevantes. La puntuación promedio para un documento fue de 3.58. Los documentos que representan cada película fueron construidos a partir de la porción de la base de datos de IMDB que está disponible para descarga pública[13]. Basándonos en esta base de datos, creamos un documento por película que contenía la información relevante sobre ella (por ejemplo, directores, actores, etc.). Tabla 1: Estadísticas del conjunto de datos. En Reuters, el número de <br>calificaciones</br> para un usuario simulado es el número de documentos relevantes para el tema correspondiente. Datos Usuarios Documentos Calificaciones por Usuario MovieLens 6,040 3,057 151 Netflix-todos 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Datos de Netflix: Este conjunto de datos fue construido combinando documentos sobre películas obtenidos de la web con un conjunto de juicios de relevancia de clientes reales de alquiler de películas de Netflix[19]. Netflix proporciona públicamente las evaluaciones de relevancia de 480,189 clientes anónimos. Hay alrededor de 100 millones de <br>calificaciones</br> en una escala del 1 al 5 para 17,770 documentos. Similar a MovieLens, consideramos documentos con puntuaciones de 4 o 5 de agradabilidad como relevantes. Este número se redujo a 1000 clientes mediante muestreo aleatorio. El cliente promedio en el conjunto de datos reducido proporcionó 127 juicios, de los cuales 70 fueron considerados relevantes. La puntuación promedio de los documentos es de 3.55. Datos de Reuters: Este es el Corpus de Reuters, Volumen 1. Cubre 810,000 noticias en inglés de Reuters desde el 20 de agosto de 1996 hasta el 19 de agosto de 1997. Solo se utilizaron las primeras 100,000 noticias en nuestros experimentos. El corpus de Reuters viene con una jerarquía de temas. Cada documento se asigna a una de varias ubicaciones en el árbol jerárquico. El primer nivel del árbol contiene cuatro temas, denotados como C, E, M y G. Para los experimentos en este artículo, el árbol fue cortado en el nivel 1 para crear cuatro árboles más pequeños, cada uno de los cuales corresponde a un conjunto de datos más pequeño: Reuters-E, Reuters-C, Reuters-M y Reuters-G. Para cada conjunto de datos pequeño, creamos varios perfiles, un perfil para cada nodo en un subárbol, para simular múltiples usuarios, cada uno con una definición de relevancia relacionada pero separada. Todos los perfiles de usuario en una sub-rama se supone que comparten la misma distribución de modelo previo. Dado que este corpus indica explícitamente solo los documentos relevantes para un tema (usuario), todos los demás documentos se consideran irrelevantes. 5.2 Evaluación Diseñamos los experimentos para responder a las siguientes tres preguntas: 1. ¿Necesitamos hacer el esfuerzo de utilizar un enfoque bayesiano y aprender una distribución a priori de otros usuarios? 2. ¿El nuevo algoritmo funciona mejor que el algoritmo EM estándar para aprender el modelo lineal jerárquico bayesiano? 3. ¿Puede el nuevo algoritmo aprender rápidamente muchos modelos de usuario? Para responder a la primera pregunta, comparamos los modelos jerárquicos bayesianos con los modelos de regresión lineal regularizados Norm-2 comúnmente utilizados. De hecho, el enfoque comúnmente utilizado es equivalente al modelo aprendido al final de la primera iteración de EM. Para responder a la segunda pregunta, comparamos el nuevo algoritmo propuesto con el algoritmo EM estándar para ver si el nuevo algoritmo de aprendizaje es mejor. Para responder a la tercera pregunta, probamos la eficiencia del nuevo algoritmo en todo el conjunto de datos de Netflix, donde aproximadamente medio millón de modelos de usuario deben ser aprendidos juntos. Para los conjuntos de datos de MovieLens y Netflix, la efectividad del algoritmo se midió mediante el error cuadrático medio, mientras que en el conjunto de datos de Reuters se utilizó el error de clasificación porque era más informativo. Primero evaluamos el rendimiento en cada usuario individual, y luego estimamos el promedio macro sobre todos los usuarios. Se realizaron pruebas estadísticas (pruebas t) para determinar si los resultados son significativos. Para los experimentos en los conjuntos de datos de MovieLens y Netflix, utilizamos una muestra aleatoria del 90% de cada usuario para entrenamiento, y el resto para pruebas. En el conjunto de datos de Reuters, debido a que hay demasiados documentos relevantes para cada tema en el corpus, utilizamos una muestra aleatoria del 10% de cada tema para el entrenamiento, y el 10% de los documentos restantes para las pruebas. Para todas las ejecuciones, establecimos (a, b, c, Σ) = (0.1, 10, 0.1, 1) manualmente. 6. RESULTADOS EXPERIMENTALES Las Figuras 2, 3 y 4 muestran que en todos los conjuntos de datos, el enfoque de modelado jerárquico bayesiano tiene una mejora estadísticamente significativa sobre el modelo de regresión lineal regularizado, que es equivalente a los modelos jerárquicos bayesianos aprendidos en la primera iteración. Un análisis adicional muestra una correlación negativa entre la cantidad de datos de entrenamiento para un usuario y la mejora que obtiene el sistema. Esto sugiere que la información prestada de otros usuarios tiene mejoras más significativas para usuarios con menos datos de entrenamiento, lo cual es lo esperado. Sin embargo, la fuerza de la correlación varía entre los conjuntos de datos, y la cantidad de datos de entrenamiento no es la única característica que influirá en el rendimiento final. Las Figuras 2 y 3 muestran que el nuevo algoritmo propuesto funciona mejor que el algoritmo EM estándar en los conjuntos de datos de Netflix y MovieLens. Esto no es sorprendente ya que el número de pares de características-usuarios relacionados es mucho menor que el número de pares de características-usuarios no relacionados en estos dos conjuntos de datos, por lo que se espera que el nuevo algoritmo propuesto funcione mejor. La Figura 4 muestra que los dos algoritmos funcionan de manera similar en el conjunto de datos de Reuters-E. La precisión del nuevo algoritmo es similar a la del algoritmo EM estándar en cada iteración. Los patrones generales son muy similares en otros subconjuntos de Reuters. Un análisis adicional muestra que solo el 58% de los pares usuario-característica no están relacionados en este conjunto de datos. Dado que el número de pares usuario-característica no relacionados no es extremadamente grande, la dispersión no es un problema grave en el conjunto de datos de Reuters. Por lo tanto, los dos algoritmos de aprendizaje se desempeñan de manera similar. Los resultados sugieren que solo en un corpus donde el número de pares usuario-característica no relacionados es mucho mayor que el número de pares relacionados, como en el conjunto de datos de Netflix, la técnica propuesta obtendrá una mejora significativa sobre el EM estándar. Sin embargo, los experimentos también muestran que cuando la suposición no se cumple, el nuevo algoritmo no afecta el rendimiento. Aunque la técnica propuesta es más rápida que la estándar. Figura 2: Rendimiento en un subconjunto de Netflix con 1,000 usuarios. El nuevo algoritmo es estadísticamente significativamente mejor que el algoritmo EM en las iteraciones 2 a 10. Los modelos lineales regularizados con norma-2 son equivalentes a los modelos jerárquicos bayesianos aprendidos en la primera iteración, y son estadísticamente significativamente peores que los modelos jerárquicos bayesianos. Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional Figura 3: Rendimiento en un subconjunto de MovieLens con 1,000 usuarios. El nuevo algoritmo es significativamente mejor estadísticamente que el algoritmo EM en las iteraciones 2 a 17 (evaluado con error cuadrático medio). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iteraciones ErrorCuadráticoMedio Nuevo Algoritmo EM Tradicional 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iteraciones Error de Clasificación Nuevo Algoritmo EM Tradicional Figura 4: Rendimiento en un subconjunto de Reuters-E con 26 perfiles. Las actuaciones en Reuters-C, Reuters-M, Reuters-G son similares. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional EM, ¿realmente puede aprender rápidamente millones de modelos de usuario? Nuestros resultados muestran que el algoritmo EM modificado converge rápidamente, y 2-3 iteraciones del EM modificado darían como resultado una estimación confiable. Evaluamos el algoritmo en todo el conjunto de datos de Netflix (480,189 usuarios, 159,836 características y 100 millones de valoraciones) ejecutándolo en un solo PC con CPU (2GB de memoria, P4 3GHz). El sistema completó una iteración EM modificada en aproximadamente 4 horas. Esto demuestra que la técnica propuesta puede manejar eficientemente sistemas a gran escala como Netflix. CONCLUSIÓN El aprendizaje de perfiles de usuario basado en contenido es un problema importante y es clave para proporcionar recomendaciones personales a un usuario, especialmente para recomendar nuevos elementos con un pequeño número de calificaciones. El enfoque de modelado jerárquico bayesiano se está convirtiendo en un enfoque importante para el aprendizaje de perfiles de usuario debido a su capacidad teóricamente justificada para ayudar a un usuario a través de la transferencia de información de otros usuarios mediante hiperpriors. Este artículo examinó la debilidad del enfoque de aprendizaje basado en EM popular para modelos lineales jerárquicos bayesianos y propuso una técnica de aprendizaje mejorada llamada EM Modificado. Demostramos que la nueva técnica es teóricamente más eficiente computacionalmente que el algoritmo EM estándar. La evaluación en los conjuntos de datos de MovieLens y Netflix demostró la efectividad de la nueva técnica cuando los datos son dispersos, lo que significa que la proporción de pares de usuario-característica relacionados con respecto a los pares no relacionados es pequeña. La evaluación en el conjunto de datos de Reuters mostró que la nueva técnica tuvo un rendimiento similar al algoritmo EM estándar cuando la condición de dispersión no se cumple. En general, es mejor utilizar el nuevo algoritmo ya que es tan simple como el EM estándar, el rendimiento es igual o mejor que el del EM, y la complejidad computacional es menor en cada iteración. Vale la pena mencionar que aunque el espacio de problemas original no sea disperso, la dispersión puede crearse artificialmente cuando un sistema de recomendación utiliza técnicas de selección de características específicas del usuario para reducir el ruido y la complejidad del modelo del usuario. La técnica propuesta también puede adaptarse para mejorar el aprendizaje en dicho escenario. También demostramos que la técnica propuesta puede aprender medio millón de perfiles de usuario a partir de 100 millones de valoraciones en unas pocas horas con una sola CPU. La investigación es importante porque la escalabilidad es una preocupación importante para los investigadores al utilizar el enfoque de modelado lineal jerárquico bayesiano para construir un sistema a gran escala práctico, a pesar de que la literatura ha demostrado la efectividad de los modelos en muchas aplicaciones. Nuestro trabajo es un paso importante en el camino para hacer que los modelos lineales jerárquicos bayesianos sean más prácticos. La nueva técnica propuesta se puede adaptar fácilmente para ejecutarse en un clúster de máquinas, y así acelerar aún más el proceso de aprendizaje para manejar un sistema a mayor escala con cientos de millones de usuarios. La investigación tiene mucho potencial para beneficiar a las personas utilizando el algoritmo EM en muchos otros problemas de IR, así como en problemas de aprendizaje automático. El algoritmo EM es una técnica de aprendizaje automático comúnmente utilizada. Se utiliza para encontrar los parámetros del modelo en muchos problemas de IR donde los datos de entrenamiento son muy dispersos. Aunque nos estamos centrando en los modelos lineales jerárquicos bayesianos para recomendación y filtrado, la nueva idea de utilizar una solución analítica en lugar de una solución numérica para pares de usuario-característica no relacionados en el paso M podría adaptarse a muchos otros problemas. 8. AGRADECIMIENTOS Agradecemos a Wei Xu, David Lewis y a los revisores anónimos por sus valiosos comentarios sobre el trabajo descrito en este artículo. Parte del trabajo fue apoyado por Yahoo, Google, el Instituto de Almacenamiento de Datos a Escala Peta y el Instituto de Gestión de Datos Científicos Escalables. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las de los patrocinadores. REFERENCIAS [1] C. Basu, H. Hirsh y W. Cohen. Recomendación como clasificación: Utilizando información social y basada en contenido en la recomendación. En Actas de la Decimoquinta Conferencia Nacional de Inteligencia Artificial, 1998. [2] J. S. Breese, D. Heckerman y C. Kadie. Análisis empírico de algoritmos predictivos para filtrado colaborativo. Informe técnico, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan. Filtrado de documentos con redes de inferencia. En Actas de la Decimonovena Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor y A. Vinokourov. Método del núcleo para el filtrado de documentos. En la Undécima Conferencia de Recuperación de Información de Texto (TREC11). Instituto Nacional de Normas y Tecnología, publicación especial 500-249, 2003. [5] C. Chelba y A. Acero. Adaptación del capitalizador de entropía máxima: Poca información puede ayudar mucho. En D. Lin y D. Wu, editores, Actas de EMNLP 2004, páginas 285-292, Barcelona, España, julio de 2004. Asociación de Lingüística Computacional. [6] B. Croft y J. Lafferty, editores. Modelado de lenguaje para recuperación de información. Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov y A. Genkin. Construyendo distribuciones a priori informativas a partir del conocimiento del dominio en la clasificación de textos. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 493-500, Nueva York, NY, EE. UU., 2006. ACM Press. [8] J. Delgado y N. Ishii. Predicción basada en memoria ponderada para sistemas de recomendación. En el Taller ACM SIGIR99 sobre Sistemas de Recomendación, 1999. [9] GroupLens. Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman. Un tutorial sobre el aprendizaje con redes bayesianas. En M. Jordan, editor, Aprendizaje en Modelos Gráficos. Kluwer Academic, 1998. [11] J. L. Herlocker, J. \n\nKluwer Academic, 1998. [11] J. L. Herlocker, J. A. Konstan, A. Borchers y J. Riedl. Un marco algorítmico para realizar filtrado colaborativo. En SIGIR 99: Actas de la 22ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 230-237, Nueva York, NY, EE. UU., 1999. ACM Press. [12] T. Hofmann y J. Puzicha. Modelos de clases latentes para filtrado colaborativo. En IJCAI 99: Actas de la Decimosexta Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 688-693, San Francisco, CA, EE. UU., 1999. Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).\nMorgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB). Base de datos de películas en internet. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai y L. Si. Un esquema de ponderación automática para filtrado colaborativo. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 337-344, Nueva York, NY, EE. UU., 2004. ACM Press. [15] J. A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon y J. Riedl. GroupLens: Aplicando filtrado colaborativo a las noticias de Usenet. Comunicaciones de la ACM, 40(3):77-87, 1997. [16] D. Lewis. Aplicando máquinas de vectores de soporte a las tareas de filtrado y enrutamiento por lotes de TREC-2001. En Actas de la Undécima Conferencia de Recuperación de Texto (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee y P. Yu. Clasificación de texto mediante etiquetado de palabras. En Actas de la Decimonovena Conferencia Nacional de Inteligencia Artificial (AAAI-2004), 25-29 de julio de 2004. [18] P. Melville, R. J. Mooney y R. Nagarajan. Filtrado colaborativo potenciado por contenido para recomendaciones mejoradas. En Actas de la Decimoctava Conferencia Nacional de Inteligencia Artificial (AAAI-2002), Edmonton, Canadá, 2002. [19] Netflix. Premio Netflix. http://www.netflixprize.com (visitado el 30 de noviembre de 2006), 2006. [20] S. Robertson y K. Sparck-Jones. Ponderación de la relevancia de los términos de búsqueda. En Journal of the American Society for Information Science, volumen 27, páginas 129-146, 1976. [21] J. Wang, A. P. de Vries y M. J. T. Reinders. Unificando enfoques de filtrado colaborativo basados en usuarios y en elementos mediante la fusión de similitudes. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 501-508, Nueva York, NY, EE. UU., 2006. ACM Press. [22] X. Wu y R. K. Srihari. Incorporando conocimientos previos con máquinas de vectores de soporte de margen ponderado. En Proc. Conferencia de Minería de Datos y Descubrimiento de Conocimiento de ACM (ACM SIGKDD 2004), agosto de 2004. [23] Y. Yang, S. Yoo, J. Zhang y B. Kisiel. Robustez de los métodos de filtrado adaptativo en una evaluación de referencia cruzada. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 2005. [24] K. Yu, V. Tresp y A. Schwaighofer. Aprendiendo procesos gaussianos de múltiples tareas. En ICML 05: Actas de la 22ª conferencia internacional sobre aprendizaje automático, páginas 1012-1019, Nueva York, NY, EE. UU., 2005. ACM Press. [25] K. Yu, V. Tresp, y S. Yu. Un marco bayesiano jerárquico no paramétrico para el filtrado de información. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 353-360. ACM Press, 2004. [26] X. Zhu. \n\nACM Press, 2004. [26] X. Zhu. Revisión de la literatura sobre aprendizaje semisupervisado. Informe técnico, Universidad de Wisconsin - Madison, 9 de diciembre de 2006. [27] P. Zigoris y Y. Zhang. Perfilado de usuario bayesiano adaptativo con retroalimentación explícita e implícita. En la Conferencia sobre Gestión de la Información y el Conocimiento 2006, 2006. ",
            "candidates": [],
            "error": [
                [
                    "calificación",
                    "calificación de simpatía",
                    "calificaciones",
                    "calificaciones"
                ]
            ]
        },
        "recommender system": {
            "translated_key": "sistemas de recomendación",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
                "A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model.",
                "Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive.",
                "The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications.",
                "This paper proposes a new fast learning technique to learn a large number of individual user profiles.",
                "The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens.",
                "Categories and Subject Descriptors: B.3.3 [Information Search and Retrieval]: Information filtering General Terms: Algorithms 1.",
                "INTRODUCTION Personalization is the future of the Web, and it has achieved great success in industrial applications.",
                "For example, online stores, such as Amazon and Netflix, provide customized recommendations for additional products or services based on a users history.",
                "Recent offerings such as My MSN, My Yahoo!, My Google, and Google News have attracted much attention due to their potential ability to infer a users interests from his/her history.",
                "One major personalization topic studied in the information retrieval community is content-based personal recommendation systems1 .",
                "These systems learn user-specific profiles from user feedback so that they can recommend information tailored to each individual users interest without requiring the user to make an explicit query.",
                "Learning the user profiles is the core problem for these systems.",
                "A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user.",
                "One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small.",
                "This is known as the cold start problem.",
                "This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile.",
                "There has been much research on improving classification accuracy when the amount of labeled training data is small.",
                "The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal [26].",
                "Another approach is using domain knowledge.",
                "Researchers have modified different learning algorithms, such as Na¨ıveBayes [17], logistic regression [7], and SVMs [22], to integrate domain knowledge into a text classifier.",
                "The third approach is borrowing training data from other resources [5][7].",
                "The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data.",
                "One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach.",
                "Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial performance for each user[27][25].",
                "In order to learn a Bayesian hierarchical model, the system usually tries to find the most likely model parameters for the given data.",
                "A mature recommendation system usually works for millions of users.",
                "It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users.",
                "The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee.",
                "However, a content based recommendation system often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector.",
                "With careful analysis of the EM algorithm in this scenario (Section 4), we find that the EM tering, or item-based collaborative filtering.",
                "In this paper, the words filtering and recommendation are used interchangeably. algorithm converges very slowly due to the sparseness of the input variables.",
                "We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O(MK), where M is the number of users and K is the number of dimensions.",
                "This paper modifies the standard EM algorithm to create an improved learning algorithm, which we call the Modified EM algorithm.",
                "The basic idea is that instead of calculating the numerical solution for all the user profile parameters, we derive the analytical solution of the parameters for some feature dimensions, and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters.",
                "This greatly reduces the computation at a single EM iteration, and also has the benefit of increasing the convergence speed of the learning algorithm.",
                "The proposed technique is not only well supported by theory, but also by experimental results.",
                "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression modeling framework used for content-based recommendations.",
                "Section 4 describes how to learn the model parameters using the standard EM algorithm, along with using the new technique proposed in this paper.",
                "The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6.",
                "Section 7 summarizes and offers concluding remarks. 2.",
                "RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the IR community since the 1970s.",
                "The approaches that have been used to solve this problem can be roughly classified into two major categories: content based filtering versus collaborative filtering.",
                "Content-based filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user.",
                "The user may read the delivered documents and provide explicit relevance feedback, which the filtering system then uses to update the users profile using relevance feedback retrieval models (e.g.",
                "Boolean models, vector space models, traditional probabilistic models [20] , inference networks [3] and language models [6]) or machine learning algorithms (e.g.",
                "Support Vector Machines (SVM), K nearest neighbors (K-NN) clustering, neural networks, logistic regression, or Winnow [16] [4] [23]).",
                "Collaborative filtering goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past.",
                "Memorybased heuristics and model based approaches have been used in collaborative filtering task [15] [8] [2] [14] [12] [11].",
                "This paper contributes to the content-based recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks[27][25].",
                "This paper does not intend to compare content-based filtering with collaborative filtering or claim which one is a better.",
                "We think each complements the other, and that content-based filtering is extremely useful for handling new documents/items with little or no user feedback.",
                "Similar to some other researchers[18][1][21], we found that a recommendation system will be more effective when both techniques are combined.",
                "However, this is beyond the scope of this paper and thus not discussed here. 3.",
                "BAYESIAN HIERARCHICAL LINEAR REGRESSION Assume there are M users in the system.",
                "The task of the system is to recommend documents that are relevant to each user.",
                "For each user, the system learns a user model from the users history.",
                "In the rest of this paper, we will use the following notations to represent the variables in the system. m = 1, 2, ..., M: The index for each individual user.",
                "M is the total number of users. wm: The user model parameter associated with user m. wm is a K dimensional vector. j = 1, 2, ..., Jm: The index for a set of data for user m. Jm is the number of training data for user m. Dm = {(xm,j, ym,j)}: A set of data associated with user m. xm,j is a K dimensional vector that represents the mth users jth training document.2 ym,j is a scalar that represents the label of document xm,j. k = 1, 2, ..., K: The dimensional index of input variable x.",
                "The Bayesian hierarchical modeling approach has been widely used in real-world information retrieval applications.",
                "Generalized Bayesian hierarchical linear models, one of the simplest Bayesian hierarchical models, are commonly used and have achieved good performance on collaborative filtering [25] and content-based adaptive filtering [27] tasks.",
                "Figure 1 shows the graphical representation of a Bayesian hierarchical model.",
                "In this graph, each user model is represented by a random vector wm.",
                "We assume a user model is sampled randomly from a prior distribution P(w|Φ).",
                "The system can predict the user label y of a document x given an estimation of wm (or wms distribution) using a function y = f(x, w).",
                "The model is called generalized Bayesian hierarchical linear model when y = f(wT x) is any generalized linear model such as logistic regression, SVM, and linear regression.",
                "To reliably estimate the user model wm, the system can borrow information from other users through the prior Φ = (µ, Σ).",
                "Now we look at one commonly used model where y = wT x + , where ∼ N(0, σ2 ) is a random noise [25][27].",
                "Assume that each user model wm is an independent draw from a population distribution P(w|Φ), which is governed by some unknown hyperparameter Φ.",
                "Let the prior distribution of user model w be a Gaussian distribution with parameter Φ = (µ, Σ), which is the commonly used prior for linear models. µ = (µ1, µ2, ..., µK ) is a K dimensional vector that represents the mean of the Gaussian distribution, and Σ is the covariance matrix of the Gaussian.",
                "Usually, a Normal distribution N(0, aI) and an Inverse Wishart distribution P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) are used as hyperprior to model the prior distribution of µ and Σ respectively.",
                "I is the K dimensional identity matrix, and a, b, and c are real numbers.",
                "With these settings, we have the following model for the system: 1. µ and Σ are sampled from N(0, aI) and IWν (aI), respectively. 2 The first dimension of x is a dummy variable that always equals to 1.",
                "Figure 1: Illustration of dependencies of variables in the hierarchical model.",
                "The rating, y, for a document, x, is conditioned on the document and the user model, wm, associated with the user m. Users share information about their models through the prior, Φ = (µ, Σ). 2.",
                "For each user m, wm is sampled randomly from a Normal distribution: wm ∼ N(µ, Σ2 ) 3.",
                "For each item xm,j, ym,j is sampled randomly from a Normal distribution: ym,j ∼ N(wT mxm,j, σ2 ).",
                "Let θ = (Φ, w1, w2, ..., wM ) represent the parameters of this system that needs to be estimated.",
                "The joint likelihood for all the variables in the probabilistic model, which includes the data and the parameters, is: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) For simplicity, we assume a, b, c, and σ are provided to the system. 4.",
                "MODEL PARAMETER LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple linear regression.",
                "Therefore, we will focus on estimating Φ.",
                "The maximum a priori solution of Φ is given by ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Finding the optimal solution for the above problem is challenging, since we need to integrate over all w = (w1, w2, ..., wM ), which are unobserved hidden variables. 4.1 EM Algorithm for Bayesian Hierarchical Linear Models In Equation 5, Φ is the parameter needs to be estimated, and the result depends on unobserved latent variables w. This kind of optimization problem is usually solved by the EM algorithm.",
                "Applying EM to the above problem, the set of user models w are the unobservable hidden variables and we have: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw Based on the derivation of the EM formulas presented in [24], we have the following Expectation-Maximization steps for finding the optimal hyperparameters.",
                "For space considerations, we omit the derivation in this paper since it is not the focus of our work.",
                "E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of the prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) where Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j M step: Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Many machine learning driven IR systems use a point estimate of the parameters at different stages in the system.",
                "However, we are estimating the posterior distribution of the variables at the E step.",
                "This avoids overfitting wm to a particular users data, which may be small and noisy.",
                "A detailed discussion about this subject appears in [10]. 4.2 New Algorithm: Modified EM Although the EM algorithm is widely studied and used in machine learning applications, using the above EM process to solve Bayesian hierarchical linear models in large-scale information retrieval systems is still too computationally expensive.",
                "In this section, we describe why the learning rate of the EM algorithm is slow in our application and introduce a new technique to make the learning of the Bayesian hierarchical linear model scalable.",
                "The derivation of the new learning algorithm will be based on the EM algorithm described in the previous section.",
                "First, the covariance matrices Σ2 , Σ2 m are usually too large to be computationally feasible.",
                "For simplicity, and as a common practice in IR, we do not model the correlation between features.",
                "Thus we approximate these matrices with K dimensional diagonal matrices.",
                "In the rest of the paper, we use these symbols to represent their diagonal approximations: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     Secondly, and most importantly, the input space is very sparse and there are many dimensions that are not related to a particular user in a real IR application.",
                "For example, let us consider a movie recommendation system, with the input variable x representing a particular movie.",
                "For the jth movie that the user m has seen, let xm,j,k = 1 if the director of the movie is Jean-Pierre Jeunet (indexed by k).",
                "Here we assume that whether or not that this director directed a specific movie is represented by the kth dimension.",
                "If the user m has never seen a movie directed by Jean-Pierre Jeunet, then the corresponding dimension is always zero (xm,j,k = 0 for all j) .",
                "One major drawback of the EM algorithm is that the importance of a feature, µk, may be greatly dominated by users who have never encountered this feature (i.e. j xm,j,k = 0) at the M step (Equation 8).",
                "Assume that 100 out of 1 million users have viewed the movie directed by Jean-Pierre Jeunet, and that the viewers have rated all of his movies as excellent.",
                "Intuitively, he is a good director and the weight for him (µk) should be high.",
                "Before the EM iteration, the initial value of µ is usually set to 0.",
                "Since the other 999,900 users have not seen this movie, their corresponding weights (w1,k, w2,k, ..., wm,k..., w999900,k) for that director would be very small initially.",
                "Thus the corresponding weight of the director in the prior µk at the first M step would be very low , and the variance σm,k will be large (Equations 8 and 7).",
                "It is undesirable that users who have never seen any movie produced by the director influence the importance of the director so much.",
                "This makes the convergence of the standard EM algorithm very slow.",
                "Now lets look at whether we can improve the learning speed of the algorithm.",
                "Without a loss of generality, let us assume that the kth dimension of the input variable x is not related to a particular user m. By which we mean, xm,j,k = 0 for all j = 1, ..., Jm.",
                "It is straightforward to prove that the kth row and kth column of Sxx,m are completely filled with zeros, and that the kth dimension of Sxy,m is zeroed as well.",
                "Thus the corresponding kth dimension of the user models mean, ¯wm, should be equal to that of the prior: ¯wm,k = µk, with the corresponding covariance of σm,k = σk.",
                "At the M step, the standard EM algorithm uses the numerical solution of the distribution P(wm|Dm, Φ) estimated at E step (Equation 8 and Equation 7).",
                "However, the numerical solutions are very unreliable for ¯wm,k and σm,k when the kth dimension is not related to the mth user.",
                "A better approach is using the analytical solutions ¯wm,k = µk, and σm,k = σk for the unrelated (m, k) pairs, along with the numerical solution estimated at E step for the other (m, k) pairs.",
                "Thus we get the following new EM-like algorithm: Modified E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) where sxx,m,k = j x2 m,j,k and sxy,m,k = j xm,j,kym,j Modified M Step Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step for related userfeature pairs.",
                "The M step implicitly uses the analytical solution for unrelated user-feature pairs. µk = 1 Mk m:related ¯wm,k (12) σ2 k = 1 Mk m:related σ2 m,k +( ¯wm,k − µk)( ¯wm,k − µk)T (13) where Mk is the number of users that are related to feature k We only estimate the diagonal of Σ2 m and Σ since we are using the diagonal approximation of the covariance matrices.",
                "To estimate ¯wm, we only need to calculate the numerical solutions for dimensions that are related to user m. To estimate σ2 k and µk, we only sum over users that are related to the kth feature.",
                "There are two major benefits of the new algorithm.",
                "First, because only the related (m, k) pairs are needed at the modified M step, the computational complexity in a single EM iteration is much smaller when the data is sparse, and many of (m, k) pairs are unrelated.",
                "Second, the parameters estimated at the modified M step (Equations 12 - 13) are more accurate than the standard M step described in Section 4.1 because the exact analytical solutions ¯wm,k = µk and σm,k = σk for the unrelated (m, k) pairs were used in the new algorithm instead of an approximate solution as in the standard algorithm. 5.",
                "EXPERIMENTAL METHODOLOGY 5.1 Evaluation Data Set To evaluate the proposed technique, we used the following three major data sets (Table 1): MovieLens Data: This data set was created by combining the relevance judgments from the MovieLens[9] data set with documents from the Internet Movie Database (IMDB).",
                "MovieLens allows users to rank how much he/she enjoyed a specific movie on a scale from 1 to 5.",
                "This likeability rating was used as a measurement of how relevant the document representing the corresponding movie is to the user.",
                "We considered documents with likeability scores of 4 or 5 as relevant, and documents with a score of 1 to 3 as irrelevant to the user.",
                "MovieLens provided relevance judgments on 3,057 documents from 6,040 separate users.",
                "On average, each user rated 151 movies, of these 87 were judged to be relevant.",
                "The average score for a document was 3.58.",
                "Documents representing each movie were constructed from the portion of the IMDB database that is available for public download[13].",
                "Based on this database, we created one document per movie that contained the relevant information about it (e.g. directors, actors, etc.).",
                "Table 1: Data Set Statistics.",
                "On Reuters, the number of rating for a simulated user is the number of documents relevant to the corresponding topic.",
                "Data Users Docs Ratings per User MovieLens 6,040 3,057 151 Netflix-all 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Netflix Data: This data set was constructed by combining documents about movies crawled from the web with a set of actual movie rental customer relevance judgments from Netflix[19].",
                "Netflix publicly provides the relevance judgments of 480,189 anonymous customers.",
                "There are around 100 million rating on a scale of 1 to 5 for 17,770 documents.",
                "Similar to MovieLens, we considered documents with likeability scores of 4 or 5 as relevant.",
                "This number was reduced to 1000 customers through random sampling.",
                "The average customer on the reduced data set provided 127 judgments, with 70 being deemed relevant.",
                "The average score for documents is 3.55.",
                "Reuters Data: This is the Reuters Corpus, Volume 1.",
                "It covers 810,000 Reuters English language news stories from August 20, 1996 to August 19, 1997.",
                "Only the first 100,000 news were used in our experiments.",
                "The Reuters corpus comes with a topic hierarchy.",
                "Each document is assigned to one of several locations on the hierarchical tree.",
                "The first level of the tree contains four topics, denoted as C, E, M, and G. For the experiments in this paper, the tree was cut at level 1 to create four smaller trees, each of which corresponds to one smaller data set: Reuters-E Reuters-C, ReutersM and Reuters-G. For each small data set, we created several profiles, one profile for each node in a sub-tree, to simulate multiple users, each with a related, yet separate definition of relevance.",
                "All the user profiles on a sub-tree are supposed to share the same prior model distribution.",
                "Since this corpus explicitly indicates only the relevant documents for a topic(user), all other documents are considered irrelevant. 5.2 Evaluation We designed the experiments to answer the following three questions: 1.",
                "Do we need to take the effort to use a Bayesian approach and learn a prior from other users? 2.",
                "Does the new algorithm work better than the standard EM algorithm for learning the Bayesian hierarchical linear model? 3.",
                "Can the new algorithm quickly learn many user models?",
                "To answer the first question, we compared the Bayesian hierarchical models with commonly used Norm-2 regularized linear regression models.",
                "In fact, the commonly used approach is equivalent to the model learned at the end of the first EM iteration.",
                "To answer the second question, we compared the proposed new algorithm with the standard EM algorithm to see whether the new learning algorithm is better.",
                "To answer the third question, we tested the efficiency of the new algorithm on the entire Netflix data set where about half a million user models need to be learned together.",
                "For the MovieLens and Netflix data sets, algorithm effectiveness was measured by mean square error, while on the Reuters data set classification error was used because it was more informative.",
                "We first evaluated the performance on each individual user, and then estimated the macro average over all users.",
                "Statistical tests (t-tests) were carried out to see whether the results are significant.",
                "For the experiments on the MovieLens and Netflix data sets, we used a random sample of 90% of each user for training, and the rest for testing.",
                "On Reuters data set, because there are too many relevant documents for each topic in the corpus, we used a random sample of 10% of each topic for training, and 10% of the remaining documents for testing.",
                "For all runs, we set (a, b, c, Σ ) = (0.1, 10, 0.1, 1) manually. 6.",
                "EXPERIMENTAL RESULTS Figure 2, Figure 3, and Figure 4 show that on all data sets, the Bayesian hierarchical modeling approach has a statistical significant improvement over the regularized linear regression model, which is equivalent to the Bayesian hierarchical models learned at the first iteration.",
                "Further analysis shows a negative correlation between the number of training data for a user and the improvement the system gets.",
                "This suggests that the borrowing information from other users has more significant improvements for users with less training data, which is as expected.",
                "However, the strength of the correlation differs over data sets, and the amount of training data is not the only characteristics that will influence the final performance.",
                "Figure 2 and Figure 3 show that the proposed new algorithm works better than the standard EM algorithm on the Netflix and MovieLens data sets.",
                "This is not surprising since the number of related feature-users pairs is much smaller than the number of unrelated feature-user pairs on these two data sets, and thus the proposed new algorithm is expected to work better.",
                "Figure 4 shows that the two algorithms work similarly on the Reuters-E data set.",
                "The accuracy of the new algorithm is similar to that of the standard EM algorithm at each iteration.",
                "The general patterns are very similar on other Reuters subsets.",
                "Further analysis shows that only 58% of the user-feature pairs are unrelated on this data set.",
                "Since the number of unrelated user-feature pairs is not extremely large, the sparseness is not a serious problem on the Reuters data set.",
                "Thus the two learning algorithms perform similarly.",
                "The results suggest that only on a corpus where the number of unrelated user-feature pairs is much larger than the number of related pairs, such as on the Netflix data set, the proposed technique will get a significant improvement over standard EM.",
                "However, the experiments also show that when the assumption does not hold, the new algorithm does not hurt performance.",
                "Although the proposed technique is faster than standard Figure 2: Performance on a Netflix subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iterations 2 - 10.",
                "Norm-2 regularized linear models are equivalent to the Bayesian hierarchical models learned at the first iteration, and are statistical significantly worse than the Bayesian hierarchical models. 0 2 4 6 8 10 1 1.05 1.1 1.15 1.2 1.25 1.3 1.35 1.4 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iterations ClassificationError New Algorithm Traditional EM Figure 3: Performance on a MovieLens subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iteration 2 to 17 (evaluated with mean square error). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iterations MeanSquareError New Algorithm Traditional EM 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iterations ClassificationError New Algorithm Traditional EM Figure 4: Performance on a Reuters-E subset with 26 profiles.",
                "Performances on Reuters-C, Reuters-M, Reuters-G are similar. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iterations ClassificationError New Algorithm Traditional EM EM, can it really learn millions of user models quickly?",
                "Our results show that the modified EM algorithm converges quickly, and 2 - 3 modified EM iterations would result in a reliable estimation.",
                "We evaluated the algorithm on the whole Netflix data set (480,189 users, 159,836 features, and 100 million ratings) running on a single CPU PC (2GB memory, P4 3GHz).",
                "The system finished one modified EM iteration in about 4 hours.",
                "This demonstrates that the proposed technique can efficiently handle large-scale system like Netflix. 7.",
                "CONCLUSION Content-based user profile learning is an important problem and is the key to providing personal recommendations to a user, especially for recommending new items with a small number of ratings.",
                "The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors.",
                "This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM.",
                "We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm.",
                "Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse, by which we mean the ratio of related user-feature pairs to unrelated pairs is small.",
                "Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold.",
                "In general, it is better to use the new algorithm since it is as simple as standard EM, the performance is either better or similar to EM, and the computation complexity is lower at each iteration.",
                "It is worth mentioning that even if the original problem space is not sparse, sparseness can be created artificially when a recommendation system uses user-specific feature selection techniques to reduce the noise and user model complexity.",
                "The proposed technique can also be adapted to improve the learning in such a scenario.",
                "We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU.",
                "The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear modeling approach to build a practical large scale system, even though the literature have demonstrated the effectiveness of the models in many applications.",
                "Our work is one major step on the road to make Bayesian hierarchical linear models more practical.",
                "The proposed new technique can be easily adapted to run on a cluster of machines, and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users.",
                "The research has much potential to benefit people using EM algorithm on many other IR problems as well as machine learning problems.",
                "EM algorithm is a commonly used machine learning technique.",
                "It is used to find model parameters in many IR problems where the training data is very sparse.",
                "Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering, the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems. 8.",
                "ACKNOWLEDGMENTS We thank Wei Xu, David Lewis and anonymous reviewers for valuable feedback on the work described in this paper.",
                "Part of the work was supported by Yahoo, Google, the Petascale Data Storage Institute and the Institute for Scalable Scientific Data Management.",
                "Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors, and do not necessarily reflect those of the sponsors. 9.",
                "REFERENCES [1] C. Basu, H. Hirsh, and W. Cohen.",
                "Recommendation as classification: Using social and content-based information in recommendation.",
                "In Proceedings of the Fifteenth National Conference on Artificial Intelligence, 1998. [2] J. S. Breese, D. Heckerman, and C. Kadie.",
                "Empirical analysis of predictive algorithms for collaborative filtering.",
                "Technical report, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan.",
                "Document filtering with inference networks.",
                "In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor, and A. Vinokourov.",
                "Kernel method for document filtering.",
                "In The Eleventh Text REtrieval Conference (TREC11).",
                "National Institute of Standards and Technology, special publication 500-249, 2003. [5] C. Chelba and A. Acero.",
                "Adaptation of maximum entropy capitalizer: Little data can help a lot.",
                "In D. Lin and D. Wu, editors, Proceedings of EMNLP 2004, pages 285-292, Barcelona, Spain, July 2004.",
                "Association for Computational Linguistics. [6] B. Croft and J. Lafferty, editors.",
                "Language Modeling for Information Retrieval.",
                "Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov, and A. Genkin.",
                "Constructing informative prior distributions from domain knowledge in text classification.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 493-500, New York, NY, USA, 2006.",
                "ACM Press. [8] J. Delgado and N. Ishii.",
                "Memory-based weightedmajority prediction for <br>recommender system</br>s.",
                "In ACM SIGIR99 Workshop on Recommender Systems, 1999. [9] GroupLens.",
                "Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman.",
                "A tutorial on learning with bayesian networks.",
                "In M. Jordan, editor, Learning in Graphical Models.",
                "Kluwer Academic, 1998. [11] J. L. Herlocker, J.",
                "A. Konstan, A. Borchers, and J. Riedl.",
                "An algorithmic framework for performing collaborative filtering.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 230-237, New York, NY, USA, 1999.",
                "ACM Press. [12] T. Hofmann and J. Puzicha.",
                "Latent class models for collaborative filtering.",
                "In IJCAI 99: Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 688-693, San Francisco, CA, USA, 1999.",
                "Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).",
                "Internet movie database. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai, and L. Si.",
                "An automatic weighting scheme for collaborative filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 337-344, New York, NY, USA, 2004.",
                "ACM Press. [15] J.",
                "A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl.",
                "GroupLens: Applying collaborative filtering to Usenet news.",
                "Communications of the ACM, 40(3):77-87, 1997. [16] D. Lewis.",
                "Applying support vector machines to the TREC-2001 batch filtering and routing tasks.",
                "In Proceedings of the Eleventh Text REtrieval Conference (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee, , and P. Yu.",
                "Text classification by labeling words.",
                "In Proceedings of The Nineteenth National Conference on Artificial Intelligence (AAAI-2004), July 25-29, 2004. [18] P. Melville, R. J. Mooney, and R. Nagarajan.",
                "Content-boosted collaborative filtering for improved recommendations.",
                "In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002), Edmonton, Canada, 2002. [19] Netflix.",
                "Netflix prize. http://www.netflixprize.com (visited on Nov. 30, 2006), 2006. [20] S. Robertson and K. Sparck-Jones.",
                "Relevance weighting of search terms.",
                "In Journal of the American Society for Information Science, volume 27, pages 129-146, 1976. [21] J. Wang, A. P. de Vries, and M. J. T. Reinders.",
                "Unifying user-based and item-based collaborative filtering approaches by similarity fusion.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 501-508, New York, NY, USA, 2006.",
                "ACM Press. [22] X. Wu and R. K. Srihari.",
                "Incorporating prior knowledge with weighted margin support vector machines.",
                "In Proc.",
                "ACM Knowledge Discovery Data Mining Conf. (ACM SIGKDD 2004), Aug. 2004. [23] Y. Yang, S. Yoo, J. Zhang, and B. Kisiel.",
                "Robustness of adaptive filtering methods in a cross-benchmark evaluation.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2005. [24] K. Yu, V. Tresp, and A. Schwaighofer.",
                "Learning gaussian processes from multiple tasks.",
                "In ICML 05: Proceedings of the 22nd international conference on Machine learning, pages 1012-1019, New York, NY, USA, 2005.",
                "ACM Press. [25] K. Yu, V. Tresp, and S. Yu.",
                "A nonparametric hierarchical bayesian framework for information filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 353-360.",
                "ACM Press, 2004. [26] X. Zhu.",
                "Semi-supervised learning literature survey.",
                "Technical report, University of Wisconsin - Madison, December 9, 2006. [27] P. Zigoris and Y. Zhang.",
                "Bayesian adaptive user profiling with explicit & implicit feedback.",
                "In Conference on Information and Knowledge Mangement 2006, 2006."
            ],
            "original_annotated_samples": [
                "Memory-based weightedmajority prediction for <br>recommender system</br>s."
            ],
            "translated_annotated_samples": [
                "Predicción basada en memoria ponderada para <br>sistemas de recomendación</br>."
            ],
            "translated_text": "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual. Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un modelo jerárquico bayesiano. Aprender los parámetros del modelo para optimizar la verosimilitud conjunta de los datos de millones de usuarios es muy costoso computacionalmente. El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de datos en aplicaciones de IR. Este documento propone una nueva técnica de aprendizaje rápido para aprender un gran número de perfiles de usuario individuales. La eficacia y eficiencia del algoritmo propuesto están justificadas por la teoría y demostradas en datos reales de usuarios de Netflix y MovieLens. Categorías y Descriptores de Asignaturas: B.3.3 [Búsqueda y Recuperación de Información]: Filtrado de información Términos Generales: Algoritmos 1. La personalización es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales. Por ejemplo, las tiendas en línea, como Amazon y Netflix, ofrecen recomendaciones personalizadas de productos o servicios adicionales basadas en el historial de un usuario. Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de un usuario a partir de su historial. Un tema importante de personalización estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados basados en el contenido. Estos sistemas aprenden perfiles específicos de usuario a partir de la retroalimentación del usuario para poder recomendar información adaptada a los intereses de cada usuario sin necesidad de que el usuario realice una consulta explícita. Aprender los perfiles de usuario es el problema central de estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica qué tan relevante es un documento para el usuario. Uno de los principales desafíos de construir un sistema de recomendación o personalización es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña. Esto se conoce como el problema de inicio en frío. Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente retroalimentación de ese usuario para aprender un perfil de usuario confiable. Se ha realizado mucha investigación sobre cómo mejorar la precisión de clasificación cuando la cantidad de datos de entrenamiento etiquetados es pequeña. El enfoque de aprendizaje semisupervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26]. Otro enfoque es utilizar el conocimiento del dominio. Los investigadores han modificado diferentes algoritmos de aprendizaje, como NaïveBayes [17], regresión logística [7] y SVMs [22], para integrar el conocimiento del dominio en un clasificador de texto. El tercer enfoque consiste en tomar datos de entrenamiento de otros recursos [5][7]. La efectividad de estos enfoques diferentes es mixta, debido a qué tan bien se ajusta la suposición del modelo subyacente a los datos. Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano. Varios investigadores han demostrado que este enfoque intercambia eficazmente entre la información compartida y la específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario[27][25]. Para aprender un modelo jerárquico bayesiano, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados. Un sistema de recomendación maduro generalmente funciona para millones de usuarios. Es bien sabido que aprender los parámetros óptimos de un modelo jerárquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios. El algoritmo EM es una técnica comúnmente utilizada para el aprendizaje de parámetros debido a su simplicidad y garantía de convergencia. Sin embargo, un sistema de recomendación basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso. Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM tering, o filtrado colaborativo basado en elementos. En este documento, las palabras filtrado y recomendación se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de las variables de entrada. También encontramos que actualizar el parámetro del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones. Este documento modifica el algoritmo EM estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos algoritmo EM modificado. La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M utilizamos la solución analítica en lugar de la solución numérica estimada en el paso E para esos parámetros. Esto reduce considerablemente la computación en una sola iteración de EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales. La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de regresión lineal jerárquica bayesiana utilizado para recomendaciones basadas en contenido. La sección 4 describe cómo aprender los parámetros del modelo utilizando el algoritmo EM estándar, junto con el uso de la nueva técnica propuesta en este artículo. La configuración experimental y los resultados utilizados para validar la técnica de aprendizaje propuesta se informan en las Secciones 5 y 6. La sección 7 resume y ofrece observaciones finales. 2. TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de IR desde la década de 1970. Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus filtrado colaborativo. El filtrado basado en contenido estudia el escenario en el que un sistema de recomendación monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente. El usuario puede leer los documentos entregados y proporcionar retroalimentación explícita de relevancia, la cual el sistema de filtrado utiliza para actualizar el perfil del usuario mediante modelos de recuperación de retroalimentación de relevancia (por ejemplo,). Modelos booleanos, modelos de espacio vectorial, modelos probabilísticos tradicionales [20], redes de inferencia [3] y modelos de lenguaje [6]) o algoritmos de aprendizaje automático (por ejemplo, Máquinas de Vectores de Soporte (SVM), agrupamiento de K vecinos más cercanos (K-NN), redes neuronales, regresión logística o Winnow [16] [4] [23]. El filtrado colaborativo va más allá de simplemente usar el contenido de un documento para recomendar elementos a un usuario, aprovechando la información de otros usuarios con gustos y preferencias similares en el pasado. Se han utilizado heurísticas basadas en memoria y enfoques basados en modelos en la tarea de filtrado colaborativo [15] [8] [2] [14] [12] [11]. Este artículo contribuye a la investigación de recomendaciones basadas en contenido al mejorar la eficiencia y efectividad de los modelos lineales jerárquicos bayesianos, los cuales tienen una sólida base teórica y un buen rendimiento empírico en tareas de recomendación[27][25]. Este artículo no tiene la intención de comparar el filtrado basado en contenido con el filtrado colaborativo ni de afirmar cuál es mejor. Creemos que cada uno complementa al otro, y que el filtrado basado en contenido es extremadamente útil para manejar nuevos documentos/artículos con poco o ningún feedback del usuario. Similar a otros investigadores[18][1][21], encontramos que un sistema de recomendación será más efectivo cuando se combinan ambas técnicas. Sin embargo, esto está fuera del alcance de este documento y, por lo tanto, no se discute aquí. 3. REGRESIÓN LINEAL HIERÁRQUICA BAYESIANA Suponga que hay M usuarios en el sistema. La tarea del sistema es recomendar documentos que sean relevantes para cada usuario. Para cada usuario, el sistema aprende un modelo de usuario a partir del historial de los usuarios. En el resto de este documento, utilizaremos las siguientes notaciones para representar las variables en el sistema. m = 1, 2, ..., M: El índice para cada usuario individual. M es el número total de usuarios. wm: El parámetro del modelo de usuario asociado con el usuario m. wm es un vector de dimensión K. j = 1, 2, ..., Jm: El índice para un conjunto de datos para el usuario m. Jm es el número de datos de entrenamiento para el usuario m. Dm = {(xm,j, ym,j)}: Un conjunto de datos asociado con el usuario m. xm,j es un vector de dimensión K que representa el j-ésimo documento de entrenamiento del usuario m. ym,j es un escalar que representa la etiqueta del documento xm,j. k = 1, 2, ..., K: El índice dimensional de la variable de entrada x. El enfoque de modelado jerárquico bayesiano ha sido ampliamente utilizado en aplicaciones reales de recuperación de información. Los modelos lineales jerárquicos bayesianos generalizados, uno de los modelos jerárquicos bayesianos más simples, son comúnmente utilizados y han logrado un buen rendimiento en tareas de filtrado colaborativo [25] y filtrado adaptativo basado en contenido [27]. La Figura 1 muestra la representación gráfica de un modelo jerárquico bayesiano. En este gráfico, cada modelo de usuario está representado por un vector aleatorio wm. Suponemos que un modelo de usuario se muestrea aleatoriamente de una distribución previa P(w|Φ). El sistema puede predecir la etiqueta de usuario y de un documento x dado una estimación de wm (o distribución de wms) utilizando una función y = f(x, w). El modelo se llama modelo lineal jerárquico bayesiano generalizado cuando y = f(wT x) es cualquier modelo lineal generalizado como regresión logística, SVM y regresión lineal. Para estimar de manera confiable el modelo de usuario wm, el sistema puede obtener información de otros usuarios a través de la prior Φ = (µ, Σ). Ahora observamos un modelo comúnmente utilizado donde y = wT x + , donde ∼ N(0, σ2 ) es un ruido aleatorio [25][27]. Suponga que cada modelo de usuario wm es una muestra independiente de una distribución poblacional P(w|Φ), la cual está regida por un hiperparámetro desconocido Φ. Que la distribución previa del modelo de usuario w sea una distribución gaussiana con parámetro Φ = (µ, Σ), que es la distribución previa comúnmente utilizada para modelos lineales. µ = (µ1, µ2, ..., µK) es un vector de K dimensiones que representa la media de la distribución gaussiana, y Σ es la matriz de covarianza de la gaussiana. Normalmente, se utiliza una distribución Normal N(0, aI) y una distribución Inverse Wishart P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) como hiperprior para modelar la distribución previa de µ y Σ respectivamente. Yo es la matriz identidad de dimensión K, y a, b y c son números reales. Con esta configuración, tenemos el siguiente modelo para el sistema: 1. µ y Σ se muestrean de N(0, aI) e IWν (aI), respectivamente. 2. La primera dimensión de x es una variable ficticia que siempre es igual a 1. Figura 1: Ilustración de las dependencias de variables en el modelo jerárquico. La calificación, y, para un documento, x, está condicionada al documento y al modelo de usuario, wm, asociado con el usuario m. Los usuarios comparten información sobre sus modelos a través de la prior, Φ = (µ, Σ). Para cada usuario m, wm se muestrea aleatoriamente de una distribución Normal: wm ∼ N(µ, Σ2 ) 3. Para cada elemento xm,j, ym,j se muestrea aleatoriamente de una distribución Normal: ym,j ∼ N(wT mxm,j, σ2). Que θ = (Φ, w1, w2, ..., wM) represente los parámetros de este sistema que necesitan ser estimados. La verosimilitud conjunta de todas las variables en el modelo probabilístico, que incluye los datos y los parámetros, es: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) Para simplificar, asumimos que a, b, c y σ son proporcionados al sistema. 4. APRENDIZAJE DE PARÁMETROS DEL MODELO Si se conoce el prior Φ, encontrar el óptimo wm es sencillo: se trata de una regresión lineal simple. Por lo tanto, nos enfocaremos en estimar Φ. La solución a priori máxima de Φ se da por ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Encontrar la solución óptima para el problema anterior es desafiante, ya que necesitamos integrar sobre todos los w = (w1, w2, ..., wM), que son variables ocultas no observadas. 4.1 Algoritmo EM para Modelos Lineales Jerárquicos Bayesianos En la Ecuación 5, Φ es el parámetro que necesita ser estimado, y el resultado depende de las variables latentes no observadas w. Este tipo de problema de optimización suele resolverse mediante el algoritmo EM. Aplicando EM al problema anterior, el conjunto de modelos de usuario w son las variables ocultas no observables y tenemos: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw. Basándonos en la derivación de las fórmulas EM presentadas en [24], tenemos los siguientes pasos de Expectation-Maximization para encontrar los hiperparámetros óptimos. Por razones de espacio, omitimos la derivación en este artículo ya que no es el enfoque de nuestro trabajo. Paso E: Para cada usuario m, estime la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual del prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) donde Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j Paso M: Optimice el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Muchos sistemas de IR impulsados por aprendizaje automático utilizan una estimación puntual de los parámetros en diferentes etapas del sistema. Sin embargo, estamos estimando la distribución posterior de las variables en el paso E. Esto evita el sobreajuste de wm a los datos de un usuario en particular, que pueden ser pequeños y ruidosos. Una discusión detallada sobre este tema aparece en [10]. 4.2 Nuevo Algoritmo: EM Modificado. Aunque el algoritmo EM es ampliamente estudiado y utilizado en aplicaciones de aprendizaje automático, utilizar el proceso EM mencionado anteriormente para resolver modelos lineales jerárquicos bayesianos en sistemas de recuperación de información a gran escala sigue siendo demasiado costoso computacionalmente. En esta sección, describimos por qué la tasa de aprendizaje del algoritmo EM es lenta en nuestra aplicación e introducimos una nueva técnica para hacer que el aprendizaje del modelo lineal jerárquico bayesiano sea escalable. La derivación del nuevo algoritmo de aprendizaje estará basada en el algoritmo EM descrito en la sección anterior. Primero, las matrices de covarianza Σ2 , Σ2 m suelen ser demasiado grandes para ser computacionalmente factibles. Por simplicidad, y como práctica común en IR, no modelamos la correlación entre características. Así aproximamos estas matrices con matrices diagonales de dimensión K. En el resto del documento, utilizamos estos símbolos para representar sus aproximaciones diagonales: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     En segundo lugar, y lo más importante, el espacio de entrada es muy disperso y hay muchas dimensiones que no están relacionadas con un usuario particular en una aplicación de recuperación de información real. Por ejemplo, consideremos un sistema de recomendación de películas, con la variable de entrada x representando una película en particular. Para la j-ésima película que el usuario m ha visto, sea xm,j,k = 1 si el director de la película es Jean-Pierre Jeunet (indexado por k). Aquí asumimos que si este director dirigió una película específica está representado por la k-ésima dimensión. Si el usuario m nunca ha visto una película dirigida por Jean-Pierre Jeunet, entonces la dimensión correspondiente siempre es cero (xm,j,k = 0 para todos los j). Una desventaja importante del algoritmo EM es que la importancia de una característica, µk, puede estar fuertemente dominada por usuarios que nunca han encontrado esta característica (es decir, j xm,j,k = 0) en el paso M (Ecuación 8). Suponga que 100 de cada 1 millón de usuarios han visto la película dirigida por Jean-Pierre Jeunet, y que los espectadores han calificado todas sus películas como excelentes. Intuitivamente, él es un buen director y el peso para él (µk) debería ser alto. Antes de la iteración de EM, el valor inicial de µ suele establecerse en 0. Dado que los otros 999,900 usuarios no han visto esta película, sus pesos correspondientes (w1,k, w2,k, ..., wm,k..., w999900,k) para ese director serían muy pequeños inicialmente. Por lo tanto, el peso correspondiente del director en el µk anterior en el primer paso M sería muy bajo, y la varianza σm,k será grande (Ecuaciones 8 y 7). Es indeseable que los usuarios que nunca han visto ninguna película producida por el director influyan tanto en la importancia del director. Esto hace que la convergencia del algoritmo EM estándar sea muy lenta. Ahora veamos si podemos mejorar la velocidad de aprendizaje del algoritmo. Sin pérdida de generalidad, asumamos que la k-ésima dimensión de la variable de entrada x no está relacionada con un usuario particular m. Lo que queremos decir es que xm,j,k = 0 para todo j = 1, ..., Jm. Es sencillo demostrar que la k-ésima fila y la k-ésima columna de Sxx,m están completamente llenas de ceros, y que la k-ésima dimensión de Sxy,m también se anula. Por lo tanto, la dimensión k correspondiente de la media de los modelos de usuario, ¯wm, debería ser igual a la del anterior: ¯wm,k = µk, con la covarianza correspondiente de σm,k = σk. En el paso M, el algoritmo EM estándar utiliza la solución numérica de la distribución P(wm|Dm, Φ) estimada en el paso E (Ecuación 8 y Ecuación 7). Sin embargo, las soluciones numéricas son muy poco confiables para ¯wm,k y σm,k cuando la k-ésima dimensión no está relacionada con el m-ésimo usuario. Un enfoque mejor es utilizar las soluciones analíticas ¯wm,k = µk, y σm,k = σk para los pares no relacionados (m, k), junto con la solución numérica estimada en el paso E para los otros pares (m, k). Así obtenemos el siguiente nuevo algoritmo EM similar: Paso E modificado: Para cada usuario m, estimar la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual de σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) donde sxx,m,k = j x2 m,j,k y sxy,m,k = j xm,j,kym,j Paso M modificado Optimizar el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E para pares de usuario-característica relacionados. El paso M utiliza implícitamente la solución analítica para pares de usuario-característica no relacionados. µk = 1 Mk m:relacionado ¯wm,k (12) σ2 k = 1 Mk m:relacionado σ2 m,k + ( ¯wm,k − µk)( ¯wm,k − µk)T (13) donde Mk es el número de usuarios relacionados con la característica k. Solo estimamos la diagonal de Σ2 m y Σ, ya que estamos utilizando la aproximación diagonal de las matrices de covarianza. Para estimar ¯wm, solo necesitamos calcular las soluciones numéricas para las dimensiones que están relacionadas con el usuario m. Para estimar σ2 k y µk, solo sumamos sobre los usuarios que están relacionados con la k-ésima característica. Hay dos beneficios principales del nuevo algoritmo. Primero, dado que solo se necesitan los pares relacionados (m, k) en el paso M modificado, la complejidad computacional en una sola iteración de EM es mucho menor cuando los datos son dispersos y muchos de los pares (m, k) no están relacionados. En segundo lugar, los parámetros estimados en el paso M modificado (Ecuaciones 12 - 13) son más precisos que el paso M estándar descrito en la Sección 4.1 porque se utilizaron soluciones analíticas exactas ¯wm,k = µk y σm,k = σk para los pares no relacionados (m, k) en el nuevo algoritmo en lugar de una solución aproximada como en el algoritmo estándar. METODOLOGÍA EXPERIMENTAL 5.1 Conjunto de Datos de Evaluación Para evaluar la técnica propuesta, utilizamos los siguientes tres conjuntos de datos principales (Tabla 1): Datos de MovieLens: Este conjunto de datos fue creado combinando las valoraciones de relevancia del conjunto de datos de MovieLens[9] con documentos de la Base de Datos de Películas en Internet (IMDB). MovieLens permite a los usuarios clasificar cuánto disfrutaron una película específica en una escala del 1 al 5. Esta calificación de simpatía se utilizó como una medida de cuán relevante es el documento que representa la película correspondiente para el usuario. Consideramos los documentos con puntuaciones de 4 o 5 como relevantes, y los documentos con una puntuación de 1 a 3 como irrelevantes para el usuario. MovieLens proporcionó juicios de relevancia sobre 3,057 documentos de 6,040 usuarios diferentes. En promedio, cada usuario calificó 151 películas, de las cuales 87 fueron consideradas relevantes. La puntuación promedio para un documento fue de 3.58. Los documentos que representan cada película fueron construidos a partir de la porción de la base de datos de IMDB que está disponible para descarga pública[13]. Basándonos en esta base de datos, creamos un documento por película que contenía la información relevante sobre ella (por ejemplo, directores, actores, etc.). Tabla 1: Estadísticas del conjunto de datos. En Reuters, el número de calificaciones para un usuario simulado es el número de documentos relevantes para el tema correspondiente. Datos Usuarios Documentos Calificaciones por Usuario MovieLens 6,040 3,057 151 Netflix-todos 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Datos de Netflix: Este conjunto de datos fue construido combinando documentos sobre películas obtenidos de la web con un conjunto de juicios de relevancia de clientes reales de alquiler de películas de Netflix[19]. Netflix proporciona públicamente las evaluaciones de relevancia de 480,189 clientes anónimos. Hay alrededor de 100 millones de calificaciones en una escala del 1 al 5 para 17,770 documentos. Similar a MovieLens, consideramos documentos con puntuaciones de 4 o 5 de agradabilidad como relevantes. Este número se redujo a 1000 clientes mediante muestreo aleatorio. El cliente promedio en el conjunto de datos reducido proporcionó 127 juicios, de los cuales 70 fueron considerados relevantes. La puntuación promedio de los documentos es de 3.55. Datos de Reuters: Este es el Corpus de Reuters, Volumen 1. Cubre 810,000 noticias en inglés de Reuters desde el 20 de agosto de 1996 hasta el 19 de agosto de 1997. Solo se utilizaron las primeras 100,000 noticias en nuestros experimentos. El corpus de Reuters viene con una jerarquía de temas. Cada documento se asigna a una de varias ubicaciones en el árbol jerárquico. El primer nivel del árbol contiene cuatro temas, denotados como C, E, M y G. Para los experimentos en este artículo, el árbol fue cortado en el nivel 1 para crear cuatro árboles más pequeños, cada uno de los cuales corresponde a un conjunto de datos más pequeño: Reuters-E, Reuters-C, Reuters-M y Reuters-G. Para cada conjunto de datos pequeño, creamos varios perfiles, un perfil para cada nodo en un subárbol, para simular múltiples usuarios, cada uno con una definición de relevancia relacionada pero separada. Todos los perfiles de usuario en una sub-rama se supone que comparten la misma distribución de modelo previo. Dado que este corpus indica explícitamente solo los documentos relevantes para un tema (usuario), todos los demás documentos se consideran irrelevantes. 5.2 Evaluación Diseñamos los experimentos para responder a las siguientes tres preguntas: 1. ¿Necesitamos hacer el esfuerzo de utilizar un enfoque bayesiano y aprender una distribución a priori de otros usuarios? 2. ¿El nuevo algoritmo funciona mejor que el algoritmo EM estándar para aprender el modelo lineal jerárquico bayesiano? 3. ¿Puede el nuevo algoritmo aprender rápidamente muchos modelos de usuario? Para responder a la primera pregunta, comparamos los modelos jerárquicos bayesianos con los modelos de regresión lineal regularizados Norm-2 comúnmente utilizados. De hecho, el enfoque comúnmente utilizado es equivalente al modelo aprendido al final de la primera iteración de EM. Para responder a la segunda pregunta, comparamos el nuevo algoritmo propuesto con el algoritmo EM estándar para ver si el nuevo algoritmo de aprendizaje es mejor. Para responder a la tercera pregunta, probamos la eficiencia del nuevo algoritmo en todo el conjunto de datos de Netflix, donde aproximadamente medio millón de modelos de usuario deben ser aprendidos juntos. Para los conjuntos de datos de MovieLens y Netflix, la efectividad del algoritmo se midió mediante el error cuadrático medio, mientras que en el conjunto de datos de Reuters se utilizó el error de clasificación porque era más informativo. Primero evaluamos el rendimiento en cada usuario individual, y luego estimamos el promedio macro sobre todos los usuarios. Se realizaron pruebas estadísticas (pruebas t) para determinar si los resultados son significativos. Para los experimentos en los conjuntos de datos de MovieLens y Netflix, utilizamos una muestra aleatoria del 90% de cada usuario para entrenamiento, y el resto para pruebas. En el conjunto de datos de Reuters, debido a que hay demasiados documentos relevantes para cada tema en el corpus, utilizamos una muestra aleatoria del 10% de cada tema para el entrenamiento, y el 10% de los documentos restantes para las pruebas. Para todas las ejecuciones, establecimos (a, b, c, Σ) = (0.1, 10, 0.1, 1) manualmente. 6. RESULTADOS EXPERIMENTALES Las Figuras 2, 3 y 4 muestran que en todos los conjuntos de datos, el enfoque de modelado jerárquico bayesiano tiene una mejora estadísticamente significativa sobre el modelo de regresión lineal regularizado, que es equivalente a los modelos jerárquicos bayesianos aprendidos en la primera iteración. Un análisis adicional muestra una correlación negativa entre la cantidad de datos de entrenamiento para un usuario y la mejora que obtiene el sistema. Esto sugiere que la información prestada de otros usuarios tiene mejoras más significativas para usuarios con menos datos de entrenamiento, lo cual es lo esperado. Sin embargo, la fuerza de la correlación varía entre los conjuntos de datos, y la cantidad de datos de entrenamiento no es la única característica que influirá en el rendimiento final. Las Figuras 2 y 3 muestran que el nuevo algoritmo propuesto funciona mejor que el algoritmo EM estándar en los conjuntos de datos de Netflix y MovieLens. Esto no es sorprendente ya que el número de pares de características-usuarios relacionados es mucho menor que el número de pares de características-usuarios no relacionados en estos dos conjuntos de datos, por lo que se espera que el nuevo algoritmo propuesto funcione mejor. La Figura 4 muestra que los dos algoritmos funcionan de manera similar en el conjunto de datos de Reuters-E. La precisión del nuevo algoritmo es similar a la del algoritmo EM estándar en cada iteración. Los patrones generales son muy similares en otros subconjuntos de Reuters. Un análisis adicional muestra que solo el 58% de los pares usuario-característica no están relacionados en este conjunto de datos. Dado que el número de pares usuario-característica no relacionados no es extremadamente grande, la dispersión no es un problema grave en el conjunto de datos de Reuters. Por lo tanto, los dos algoritmos de aprendizaje se desempeñan de manera similar. Los resultados sugieren que solo en un corpus donde el número de pares usuario-característica no relacionados es mucho mayor que el número de pares relacionados, como en el conjunto de datos de Netflix, la técnica propuesta obtendrá una mejora significativa sobre el EM estándar. Sin embargo, los experimentos también muestran que cuando la suposición no se cumple, el nuevo algoritmo no afecta el rendimiento. Aunque la técnica propuesta es más rápida que la estándar. Figura 2: Rendimiento en un subconjunto de Netflix con 1,000 usuarios. El nuevo algoritmo es estadísticamente significativamente mejor que el algoritmo EM en las iteraciones 2 a 10. Los modelos lineales regularizados con norma-2 son equivalentes a los modelos jerárquicos bayesianos aprendidos en la primera iteración, y son estadísticamente significativamente peores que los modelos jerárquicos bayesianos. Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional Figura 3: Rendimiento en un subconjunto de MovieLens con 1,000 usuarios. El nuevo algoritmo es significativamente mejor estadísticamente que el algoritmo EM en las iteraciones 2 a 17 (evaluado con error cuadrático medio). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iteraciones ErrorCuadráticoMedio Nuevo Algoritmo EM Tradicional 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iteraciones Error de Clasificación Nuevo Algoritmo EM Tradicional Figura 4: Rendimiento en un subconjunto de Reuters-E con 26 perfiles. Las actuaciones en Reuters-C, Reuters-M, Reuters-G son similares. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional EM, ¿realmente puede aprender rápidamente millones de modelos de usuario? Nuestros resultados muestran que el algoritmo EM modificado converge rápidamente, y 2-3 iteraciones del EM modificado darían como resultado una estimación confiable. Evaluamos el algoritmo en todo el conjunto de datos de Netflix (480,189 usuarios, 159,836 características y 100 millones de valoraciones) ejecutándolo en un solo PC con CPU (2GB de memoria, P4 3GHz). El sistema completó una iteración EM modificada en aproximadamente 4 horas. Esto demuestra que la técnica propuesta puede manejar eficientemente sistemas a gran escala como Netflix. CONCLUSIÓN El aprendizaje de perfiles de usuario basado en contenido es un problema importante y es clave para proporcionar recomendaciones personales a un usuario, especialmente para recomendar nuevos elementos con un pequeño número de calificaciones. El enfoque de modelado jerárquico bayesiano se está convirtiendo en un enfoque importante para el aprendizaje de perfiles de usuario debido a su capacidad teóricamente justificada para ayudar a un usuario a través de la transferencia de información de otros usuarios mediante hiperpriors. Este artículo examinó la debilidad del enfoque de aprendizaje basado en EM popular para modelos lineales jerárquicos bayesianos y propuso una técnica de aprendizaje mejorada llamada EM Modificado. Demostramos que la nueva técnica es teóricamente más eficiente computacionalmente que el algoritmo EM estándar. La evaluación en los conjuntos de datos de MovieLens y Netflix demostró la efectividad de la nueva técnica cuando los datos son dispersos, lo que significa que la proporción de pares de usuario-característica relacionados con respecto a los pares no relacionados es pequeña. La evaluación en el conjunto de datos de Reuters mostró que la nueva técnica tuvo un rendimiento similar al algoritmo EM estándar cuando la condición de dispersión no se cumple. En general, es mejor utilizar el nuevo algoritmo ya que es tan simple como el EM estándar, el rendimiento es igual o mejor que el del EM, y la complejidad computacional es menor en cada iteración. Vale la pena mencionar que aunque el espacio de problemas original no sea disperso, la dispersión puede crearse artificialmente cuando un sistema de recomendación utiliza técnicas de selección de características específicas del usuario para reducir el ruido y la complejidad del modelo del usuario. La técnica propuesta también puede adaptarse para mejorar el aprendizaje en dicho escenario. También demostramos que la técnica propuesta puede aprender medio millón de perfiles de usuario a partir de 100 millones de valoraciones en unas pocas horas con una sola CPU. La investigación es importante porque la escalabilidad es una preocupación importante para los investigadores al utilizar el enfoque de modelado lineal jerárquico bayesiano para construir un sistema a gran escala práctico, a pesar de que la literatura ha demostrado la efectividad de los modelos en muchas aplicaciones. Nuestro trabajo es un paso importante en el camino para hacer que los modelos lineales jerárquicos bayesianos sean más prácticos. La nueva técnica propuesta se puede adaptar fácilmente para ejecutarse en un clúster de máquinas, y así acelerar aún más el proceso de aprendizaje para manejar un sistema a mayor escala con cientos de millones de usuarios. La investigación tiene mucho potencial para beneficiar a las personas utilizando el algoritmo EM en muchos otros problemas de IR, así como en problemas de aprendizaje automático. El algoritmo EM es una técnica de aprendizaje automático comúnmente utilizada. Se utiliza para encontrar los parámetros del modelo en muchos problemas de IR donde los datos de entrenamiento son muy dispersos. Aunque nos estamos centrando en los modelos lineales jerárquicos bayesianos para recomendación y filtrado, la nueva idea de utilizar una solución analítica en lugar de una solución numérica para pares de usuario-característica no relacionados en el paso M podría adaptarse a muchos otros problemas. 8. AGRADECIMIENTOS Agradecemos a Wei Xu, David Lewis y a los revisores anónimos por sus valiosos comentarios sobre el trabajo descrito en este artículo. Parte del trabajo fue apoyado por Yahoo, Google, el Instituto de Almacenamiento de Datos a Escala Peta y el Instituto de Gestión de Datos Científicos Escalables. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las de los patrocinadores. REFERENCIAS [1] C. Basu, H. Hirsh y W. Cohen. Recomendación como clasificación: Utilizando información social y basada en contenido en la recomendación. En Actas de la Decimoquinta Conferencia Nacional de Inteligencia Artificial, 1998. [2] J. S. Breese, D. Heckerman y C. Kadie. Análisis empírico de algoritmos predictivos para filtrado colaborativo. Informe técnico, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan. Filtrado de documentos con redes de inferencia. En Actas de la Decimonovena Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor y A. Vinokourov. Método del núcleo para el filtrado de documentos. En la Undécima Conferencia de Recuperación de Información de Texto (TREC11). Instituto Nacional de Normas y Tecnología, publicación especial 500-249, 2003. [5] C. Chelba y A. Acero. Adaptación del capitalizador de entropía máxima: Poca información puede ayudar mucho. En D. Lin y D. Wu, editores, Actas de EMNLP 2004, páginas 285-292, Barcelona, España, julio de 2004. Asociación de Lingüística Computacional. [6] B. Croft y J. Lafferty, editores. Modelado de lenguaje para recuperación de información. Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov y A. Genkin. Construyendo distribuciones a priori informativas a partir del conocimiento del dominio en la clasificación de textos. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 493-500, Nueva York, NY, EE. UU., 2006. ACM Press. [8] J. Delgado y N. Ishii. Predicción basada en memoria ponderada para <br>sistemas de recomendación</br>. En el Taller ACM SIGIR99 sobre Sistemas de Recomendación, 1999. [9] GroupLens. Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman. Un tutorial sobre el aprendizaje con redes bayesianas. En M. Jordan, editor, Aprendizaje en Modelos Gráficos. Kluwer Academic, 1998. [11] J. L. Herlocker, J. \n\nKluwer Academic, 1998. [11] J. L. Herlocker, J. A. Konstan, A. Borchers y J. Riedl. Un marco algorítmico para realizar filtrado colaborativo. En SIGIR 99: Actas de la 22ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 230-237, Nueva York, NY, EE. UU., 1999. ACM Press. [12] T. Hofmann y J. Puzicha. Modelos de clases latentes para filtrado colaborativo. En IJCAI 99: Actas de la Decimosexta Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 688-693, San Francisco, CA, EE. UU., 1999. Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).\nMorgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB). Base de datos de películas en internet. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai y L. Si. Un esquema de ponderación automática para filtrado colaborativo. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 337-344, Nueva York, NY, EE. UU., 2004. ACM Press. [15] J. A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon y J. Riedl. GroupLens: Aplicando filtrado colaborativo a las noticias de Usenet. Comunicaciones de la ACM, 40(3):77-87, 1997. [16] D. Lewis. Aplicando máquinas de vectores de soporte a las tareas de filtrado y enrutamiento por lotes de TREC-2001. En Actas de la Undécima Conferencia de Recuperación de Texto (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee y P. Yu. Clasificación de texto mediante etiquetado de palabras. En Actas de la Decimonovena Conferencia Nacional de Inteligencia Artificial (AAAI-2004), 25-29 de julio de 2004. [18] P. Melville, R. J. Mooney y R. Nagarajan. Filtrado colaborativo potenciado por contenido para recomendaciones mejoradas. En Actas de la Decimoctava Conferencia Nacional de Inteligencia Artificial (AAAI-2002), Edmonton, Canadá, 2002. [19] Netflix. Premio Netflix. http://www.netflixprize.com (visitado el 30 de noviembre de 2006), 2006. [20] S. Robertson y K. Sparck-Jones. Ponderación de la relevancia de los términos de búsqueda. En Journal of the American Society for Information Science, volumen 27, páginas 129-146, 1976. [21] J. Wang, A. P. de Vries y M. J. T. Reinders. Unificando enfoques de filtrado colaborativo basados en usuarios y en elementos mediante la fusión de similitudes. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 501-508, Nueva York, NY, EE. UU., 2006. ACM Press. [22] X. Wu y R. K. Srihari. Incorporando conocimientos previos con máquinas de vectores de soporte de margen ponderado. En Proc. Conferencia de Minería de Datos y Descubrimiento de Conocimiento de ACM (ACM SIGKDD 2004), agosto de 2004. [23] Y. Yang, S. Yoo, J. Zhang y B. Kisiel. Robustez de los métodos de filtrado adaptativo en una evaluación de referencia cruzada. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 2005. [24] K. Yu, V. Tresp y A. Schwaighofer. Aprendiendo procesos gaussianos de múltiples tareas. En ICML 05: Actas de la 22ª conferencia internacional sobre aprendizaje automático, páginas 1012-1019, Nueva York, NY, EE. UU., 2005. ACM Press. [25] K. Yu, V. Tresp, y S. Yu. Un marco bayesiano jerárquico no paramétrico para el filtrado de información. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 353-360. ACM Press, 2004. [26] X. Zhu. \n\nACM Press, 2004. [26] X. Zhu. Revisión de la literatura sobre aprendizaje semisupervisado. Informe técnico, Universidad de Wisconsin - Madison, 9 de diciembre de 2006. [27] P. Zigoris y Y. Zhang. Perfilado de usuario bayesiano adaptativo con retroalimentación explícita e implícita. En la Conferencia sobre Gestión de la Información y el Conocimiento 2006, 2006. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "information filter": {
            "translated_key": "filtrado de información",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
                "A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model.",
                "Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive.",
                "The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications.",
                "This paper proposes a new fast learning technique to learn a large number of individual user profiles.",
                "The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens.",
                "Categories and Subject Descriptors: B.3.3 [Information Search and Retrieval]: Information filtering General Terms: Algorithms 1.",
                "INTRODUCTION Personalization is the future of the Web, and it has achieved great success in industrial applications.",
                "For example, online stores, such as Amazon and Netflix, provide customized recommendations for additional products or services based on a users history.",
                "Recent offerings such as My MSN, My Yahoo!, My Google, and Google News have attracted much attention due to their potential ability to infer a users interests from his/her history.",
                "One major personalization topic studied in the information retrieval community is content-based personal recommendation systems1 .",
                "These systems learn user-specific profiles from user feedback so that they can recommend information tailored to each individual users interest without requiring the user to make an explicit query.",
                "Learning the user profiles is the core problem for these systems.",
                "A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user.",
                "One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small.",
                "This is known as the cold start problem.",
                "This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile.",
                "There has been much research on improving classification accuracy when the amount of labeled training data is small.",
                "The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal [26].",
                "Another approach is using domain knowledge.",
                "Researchers have modified different learning algorithms, such as Na¨ıveBayes [17], logistic regression [7], and SVMs [22], to integrate domain knowledge into a text classifier.",
                "The third approach is borrowing training data from other resources [5][7].",
                "The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data.",
                "One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach.",
                "Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial performance for each user[27][25].",
                "In order to learn a Bayesian hierarchical model, the system usually tries to find the most likely model parameters for the given data.",
                "A mature recommendation system usually works for millions of users.",
                "It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users.",
                "The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee.",
                "However, a content based recommendation system often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector.",
                "With careful analysis of the EM algorithm in this scenario (Section 4), we find that the EM tering, or item-based collaborative filtering.",
                "In this paper, the words filtering and recommendation are used interchangeably. algorithm converges very slowly due to the sparseness of the input variables.",
                "We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O(MK), where M is the number of users and K is the number of dimensions.",
                "This paper modifies the standard EM algorithm to create an improved learning algorithm, which we call the Modified EM algorithm.",
                "The basic idea is that instead of calculating the numerical solution for all the user profile parameters, we derive the analytical solution of the parameters for some feature dimensions, and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters.",
                "This greatly reduces the computation at a single EM iteration, and also has the benefit of increasing the convergence speed of the learning algorithm.",
                "The proposed technique is not only well supported by theory, but also by experimental results.",
                "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression modeling framework used for content-based recommendations.",
                "Section 4 describes how to learn the model parameters using the standard EM algorithm, along with using the new technique proposed in this paper.",
                "The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6.",
                "Section 7 summarizes and offers concluding remarks. 2.",
                "RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the IR community since the 1970s.",
                "The approaches that have been used to solve this problem can be roughly classified into two major categories: content based filtering versus collaborative filtering.",
                "Content-based filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user.",
                "The user may read the delivered documents and provide explicit relevance feedback, which the filtering system then uses to update the users profile using relevance feedback retrieval models (e.g.",
                "Boolean models, vector space models, traditional probabilistic models [20] , inference networks [3] and language models [6]) or machine learning algorithms (e.g.",
                "Support Vector Machines (SVM), K nearest neighbors (K-NN) clustering, neural networks, logistic regression, or Winnow [16] [4] [23]).",
                "Collaborative filtering goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past.",
                "Memorybased heuristics and model based approaches have been used in collaborative filtering task [15] [8] [2] [14] [12] [11].",
                "This paper contributes to the content-based recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks[27][25].",
                "This paper does not intend to compare content-based filtering with collaborative filtering or claim which one is a better.",
                "We think each complements the other, and that content-based filtering is extremely useful for handling new documents/items with little or no user feedback.",
                "Similar to some other researchers[18][1][21], we found that a recommendation system will be more effective when both techniques are combined.",
                "However, this is beyond the scope of this paper and thus not discussed here. 3.",
                "BAYESIAN HIERARCHICAL LINEAR REGRESSION Assume there are M users in the system.",
                "The task of the system is to recommend documents that are relevant to each user.",
                "For each user, the system learns a user model from the users history.",
                "In the rest of this paper, we will use the following notations to represent the variables in the system. m = 1, 2, ..., M: The index for each individual user.",
                "M is the total number of users. wm: The user model parameter associated with user m. wm is a K dimensional vector. j = 1, 2, ..., Jm: The index for a set of data for user m. Jm is the number of training data for user m. Dm = {(xm,j, ym,j)}: A set of data associated with user m. xm,j is a K dimensional vector that represents the mth users jth training document.2 ym,j is a scalar that represents the label of document xm,j. k = 1, 2, ..., K: The dimensional index of input variable x.",
                "The Bayesian hierarchical modeling approach has been widely used in real-world information retrieval applications.",
                "Generalized Bayesian hierarchical linear models, one of the simplest Bayesian hierarchical models, are commonly used and have achieved good performance on collaborative filtering [25] and content-based adaptive filtering [27] tasks.",
                "Figure 1 shows the graphical representation of a Bayesian hierarchical model.",
                "In this graph, each user model is represented by a random vector wm.",
                "We assume a user model is sampled randomly from a prior distribution P(w|Φ).",
                "The system can predict the user label y of a document x given an estimation of wm (or wms distribution) using a function y = f(x, w).",
                "The model is called generalized Bayesian hierarchical linear model when y = f(wT x) is any generalized linear model such as logistic regression, SVM, and linear regression.",
                "To reliably estimate the user model wm, the system can borrow information from other users through the prior Φ = (µ, Σ).",
                "Now we look at one commonly used model where y = wT x + , where ∼ N(0, σ2 ) is a random noise [25][27].",
                "Assume that each user model wm is an independent draw from a population distribution P(w|Φ), which is governed by some unknown hyperparameter Φ.",
                "Let the prior distribution of user model w be a Gaussian distribution with parameter Φ = (µ, Σ), which is the commonly used prior for linear models. µ = (µ1, µ2, ..., µK ) is a K dimensional vector that represents the mean of the Gaussian distribution, and Σ is the covariance matrix of the Gaussian.",
                "Usually, a Normal distribution N(0, aI) and an Inverse Wishart distribution P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) are used as hyperprior to model the prior distribution of µ and Σ respectively.",
                "I is the K dimensional identity matrix, and a, b, and c are real numbers.",
                "With these settings, we have the following model for the system: 1. µ and Σ are sampled from N(0, aI) and IWν (aI), respectively. 2 The first dimension of x is a dummy variable that always equals to 1.",
                "Figure 1: Illustration of dependencies of variables in the hierarchical model.",
                "The rating, y, for a document, x, is conditioned on the document and the user model, wm, associated with the user m. Users share information about their models through the prior, Φ = (µ, Σ). 2.",
                "For each user m, wm is sampled randomly from a Normal distribution: wm ∼ N(µ, Σ2 ) 3.",
                "For each item xm,j, ym,j is sampled randomly from a Normal distribution: ym,j ∼ N(wT mxm,j, σ2 ).",
                "Let θ = (Φ, w1, w2, ..., wM ) represent the parameters of this system that needs to be estimated.",
                "The joint likelihood for all the variables in the probabilistic model, which includes the data and the parameters, is: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) For simplicity, we assume a, b, c, and σ are provided to the system. 4.",
                "MODEL PARAMETER LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple linear regression.",
                "Therefore, we will focus on estimating Φ.",
                "The maximum a priori solution of Φ is given by ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Finding the optimal solution for the above problem is challenging, since we need to integrate over all w = (w1, w2, ..., wM ), which are unobserved hidden variables. 4.1 EM Algorithm for Bayesian Hierarchical Linear Models In Equation 5, Φ is the parameter needs to be estimated, and the result depends on unobserved latent variables w. This kind of optimization problem is usually solved by the EM algorithm.",
                "Applying EM to the above problem, the set of user models w are the unobservable hidden variables and we have: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw Based on the derivation of the EM formulas presented in [24], we have the following Expectation-Maximization steps for finding the optimal hyperparameters.",
                "For space considerations, we omit the derivation in this paper since it is not the focus of our work.",
                "E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of the prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) where Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j M step: Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Many machine learning driven IR systems use a point estimate of the parameters at different stages in the system.",
                "However, we are estimating the posterior distribution of the variables at the E step.",
                "This avoids overfitting wm to a particular users data, which may be small and noisy.",
                "A detailed discussion about this subject appears in [10]. 4.2 New Algorithm: Modified EM Although the EM algorithm is widely studied and used in machine learning applications, using the above EM process to solve Bayesian hierarchical linear models in large-scale information retrieval systems is still too computationally expensive.",
                "In this section, we describe why the learning rate of the EM algorithm is slow in our application and introduce a new technique to make the learning of the Bayesian hierarchical linear model scalable.",
                "The derivation of the new learning algorithm will be based on the EM algorithm described in the previous section.",
                "First, the covariance matrices Σ2 , Σ2 m are usually too large to be computationally feasible.",
                "For simplicity, and as a common practice in IR, we do not model the correlation between features.",
                "Thus we approximate these matrices with K dimensional diagonal matrices.",
                "In the rest of the paper, we use these symbols to represent their diagonal approximations: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     Secondly, and most importantly, the input space is very sparse and there are many dimensions that are not related to a particular user in a real IR application.",
                "For example, let us consider a movie recommendation system, with the input variable x representing a particular movie.",
                "For the jth movie that the user m has seen, let xm,j,k = 1 if the director of the movie is Jean-Pierre Jeunet (indexed by k).",
                "Here we assume that whether or not that this director directed a specific movie is represented by the kth dimension.",
                "If the user m has never seen a movie directed by Jean-Pierre Jeunet, then the corresponding dimension is always zero (xm,j,k = 0 for all j) .",
                "One major drawback of the EM algorithm is that the importance of a feature, µk, may be greatly dominated by users who have never encountered this feature (i.e. j xm,j,k = 0) at the M step (Equation 8).",
                "Assume that 100 out of 1 million users have viewed the movie directed by Jean-Pierre Jeunet, and that the viewers have rated all of his movies as excellent.",
                "Intuitively, he is a good director and the weight for him (µk) should be high.",
                "Before the EM iteration, the initial value of µ is usually set to 0.",
                "Since the other 999,900 users have not seen this movie, their corresponding weights (w1,k, w2,k, ..., wm,k..., w999900,k) for that director would be very small initially.",
                "Thus the corresponding weight of the director in the prior µk at the first M step would be very low , and the variance σm,k will be large (Equations 8 and 7).",
                "It is undesirable that users who have never seen any movie produced by the director influence the importance of the director so much.",
                "This makes the convergence of the standard EM algorithm very slow.",
                "Now lets look at whether we can improve the learning speed of the algorithm.",
                "Without a loss of generality, let us assume that the kth dimension of the input variable x is not related to a particular user m. By which we mean, xm,j,k = 0 for all j = 1, ..., Jm.",
                "It is straightforward to prove that the kth row and kth column of Sxx,m are completely filled with zeros, and that the kth dimension of Sxy,m is zeroed as well.",
                "Thus the corresponding kth dimension of the user models mean, ¯wm, should be equal to that of the prior: ¯wm,k = µk, with the corresponding covariance of σm,k = σk.",
                "At the M step, the standard EM algorithm uses the numerical solution of the distribution P(wm|Dm, Φ) estimated at E step (Equation 8 and Equation 7).",
                "However, the numerical solutions are very unreliable for ¯wm,k and σm,k when the kth dimension is not related to the mth user.",
                "A better approach is using the analytical solutions ¯wm,k = µk, and σm,k = σk for the unrelated (m, k) pairs, along with the numerical solution estimated at E step for the other (m, k) pairs.",
                "Thus we get the following new EM-like algorithm: Modified E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) where sxx,m,k = j x2 m,j,k and sxy,m,k = j xm,j,kym,j Modified M Step Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step for related userfeature pairs.",
                "The M step implicitly uses the analytical solution for unrelated user-feature pairs. µk = 1 Mk m:related ¯wm,k (12) σ2 k = 1 Mk m:related σ2 m,k +( ¯wm,k − µk)( ¯wm,k − µk)T (13) where Mk is the number of users that are related to feature k We only estimate the diagonal of Σ2 m and Σ since we are using the diagonal approximation of the covariance matrices.",
                "To estimate ¯wm, we only need to calculate the numerical solutions for dimensions that are related to user m. To estimate σ2 k and µk, we only sum over users that are related to the kth feature.",
                "There are two major benefits of the new algorithm.",
                "First, because only the related (m, k) pairs are needed at the modified M step, the computational complexity in a single EM iteration is much smaller when the data is sparse, and many of (m, k) pairs are unrelated.",
                "Second, the parameters estimated at the modified M step (Equations 12 - 13) are more accurate than the standard M step described in Section 4.1 because the exact analytical solutions ¯wm,k = µk and σm,k = σk for the unrelated (m, k) pairs were used in the new algorithm instead of an approximate solution as in the standard algorithm. 5.",
                "EXPERIMENTAL METHODOLOGY 5.1 Evaluation Data Set To evaluate the proposed technique, we used the following three major data sets (Table 1): MovieLens Data: This data set was created by combining the relevance judgments from the MovieLens[9] data set with documents from the Internet Movie Database (IMDB).",
                "MovieLens allows users to rank how much he/she enjoyed a specific movie on a scale from 1 to 5.",
                "This likeability rating was used as a measurement of how relevant the document representing the corresponding movie is to the user.",
                "We considered documents with likeability scores of 4 or 5 as relevant, and documents with a score of 1 to 3 as irrelevant to the user.",
                "MovieLens provided relevance judgments on 3,057 documents from 6,040 separate users.",
                "On average, each user rated 151 movies, of these 87 were judged to be relevant.",
                "The average score for a document was 3.58.",
                "Documents representing each movie were constructed from the portion of the IMDB database that is available for public download[13].",
                "Based on this database, we created one document per movie that contained the relevant information about it (e.g. directors, actors, etc.).",
                "Table 1: Data Set Statistics.",
                "On Reuters, the number of rating for a simulated user is the number of documents relevant to the corresponding topic.",
                "Data Users Docs Ratings per User MovieLens 6,040 3,057 151 Netflix-all 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Netflix Data: This data set was constructed by combining documents about movies crawled from the web with a set of actual movie rental customer relevance judgments from Netflix[19].",
                "Netflix publicly provides the relevance judgments of 480,189 anonymous customers.",
                "There are around 100 million rating on a scale of 1 to 5 for 17,770 documents.",
                "Similar to MovieLens, we considered documents with likeability scores of 4 or 5 as relevant.",
                "This number was reduced to 1000 customers through random sampling.",
                "The average customer on the reduced data set provided 127 judgments, with 70 being deemed relevant.",
                "The average score for documents is 3.55.",
                "Reuters Data: This is the Reuters Corpus, Volume 1.",
                "It covers 810,000 Reuters English language news stories from August 20, 1996 to August 19, 1997.",
                "Only the first 100,000 news were used in our experiments.",
                "The Reuters corpus comes with a topic hierarchy.",
                "Each document is assigned to one of several locations on the hierarchical tree.",
                "The first level of the tree contains four topics, denoted as C, E, M, and G. For the experiments in this paper, the tree was cut at level 1 to create four smaller trees, each of which corresponds to one smaller data set: Reuters-E Reuters-C, ReutersM and Reuters-G. For each small data set, we created several profiles, one profile for each node in a sub-tree, to simulate multiple users, each with a related, yet separate definition of relevance.",
                "All the user profiles on a sub-tree are supposed to share the same prior model distribution.",
                "Since this corpus explicitly indicates only the relevant documents for a topic(user), all other documents are considered irrelevant. 5.2 Evaluation We designed the experiments to answer the following three questions: 1.",
                "Do we need to take the effort to use a Bayesian approach and learn a prior from other users? 2.",
                "Does the new algorithm work better than the standard EM algorithm for learning the Bayesian hierarchical linear model? 3.",
                "Can the new algorithm quickly learn many user models?",
                "To answer the first question, we compared the Bayesian hierarchical models with commonly used Norm-2 regularized linear regression models.",
                "In fact, the commonly used approach is equivalent to the model learned at the end of the first EM iteration.",
                "To answer the second question, we compared the proposed new algorithm with the standard EM algorithm to see whether the new learning algorithm is better.",
                "To answer the third question, we tested the efficiency of the new algorithm on the entire Netflix data set where about half a million user models need to be learned together.",
                "For the MovieLens and Netflix data sets, algorithm effectiveness was measured by mean square error, while on the Reuters data set classification error was used because it was more informative.",
                "We first evaluated the performance on each individual user, and then estimated the macro average over all users.",
                "Statistical tests (t-tests) were carried out to see whether the results are significant.",
                "For the experiments on the MovieLens and Netflix data sets, we used a random sample of 90% of each user for training, and the rest for testing.",
                "On Reuters data set, because there are too many relevant documents for each topic in the corpus, we used a random sample of 10% of each topic for training, and 10% of the remaining documents for testing.",
                "For all runs, we set (a, b, c, Σ ) = (0.1, 10, 0.1, 1) manually. 6.",
                "EXPERIMENTAL RESULTS Figure 2, Figure 3, and Figure 4 show that on all data sets, the Bayesian hierarchical modeling approach has a statistical significant improvement over the regularized linear regression model, which is equivalent to the Bayesian hierarchical models learned at the first iteration.",
                "Further analysis shows a negative correlation between the number of training data for a user and the improvement the system gets.",
                "This suggests that the borrowing information from other users has more significant improvements for users with less training data, which is as expected.",
                "However, the strength of the correlation differs over data sets, and the amount of training data is not the only characteristics that will influence the final performance.",
                "Figure 2 and Figure 3 show that the proposed new algorithm works better than the standard EM algorithm on the Netflix and MovieLens data sets.",
                "This is not surprising since the number of related feature-users pairs is much smaller than the number of unrelated feature-user pairs on these two data sets, and thus the proposed new algorithm is expected to work better.",
                "Figure 4 shows that the two algorithms work similarly on the Reuters-E data set.",
                "The accuracy of the new algorithm is similar to that of the standard EM algorithm at each iteration.",
                "The general patterns are very similar on other Reuters subsets.",
                "Further analysis shows that only 58% of the user-feature pairs are unrelated on this data set.",
                "Since the number of unrelated user-feature pairs is not extremely large, the sparseness is not a serious problem on the Reuters data set.",
                "Thus the two learning algorithms perform similarly.",
                "The results suggest that only on a corpus where the number of unrelated user-feature pairs is much larger than the number of related pairs, such as on the Netflix data set, the proposed technique will get a significant improvement over standard EM.",
                "However, the experiments also show that when the assumption does not hold, the new algorithm does not hurt performance.",
                "Although the proposed technique is faster than standard Figure 2: Performance on a Netflix subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iterations 2 - 10.",
                "Norm-2 regularized linear models are equivalent to the Bayesian hierarchical models learned at the first iteration, and are statistical significantly worse than the Bayesian hierarchical models. 0 2 4 6 8 10 1 1.05 1.1 1.15 1.2 1.25 1.3 1.35 1.4 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iterations ClassificationError New Algorithm Traditional EM Figure 3: Performance on a MovieLens subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iteration 2 to 17 (evaluated with mean square error). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iterations MeanSquareError New Algorithm Traditional EM 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iterations ClassificationError New Algorithm Traditional EM Figure 4: Performance on a Reuters-E subset with 26 profiles.",
                "Performances on Reuters-C, Reuters-M, Reuters-G are similar. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iterations ClassificationError New Algorithm Traditional EM EM, can it really learn millions of user models quickly?",
                "Our results show that the modified EM algorithm converges quickly, and 2 - 3 modified EM iterations would result in a reliable estimation.",
                "We evaluated the algorithm on the whole Netflix data set (480,189 users, 159,836 features, and 100 million ratings) running on a single CPU PC (2GB memory, P4 3GHz).",
                "The system finished one modified EM iteration in about 4 hours.",
                "This demonstrates that the proposed technique can efficiently handle large-scale system like Netflix. 7.",
                "CONCLUSION Content-based user profile learning is an important problem and is the key to providing personal recommendations to a user, especially for recommending new items with a small number of ratings.",
                "The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors.",
                "This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM.",
                "We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm.",
                "Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse, by which we mean the ratio of related user-feature pairs to unrelated pairs is small.",
                "Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold.",
                "In general, it is better to use the new algorithm since it is as simple as standard EM, the performance is either better or similar to EM, and the computation complexity is lower at each iteration.",
                "It is worth mentioning that even if the original problem space is not sparse, sparseness can be created artificially when a recommendation system uses user-specific feature selection techniques to reduce the noise and user model complexity.",
                "The proposed technique can also be adapted to improve the learning in such a scenario.",
                "We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU.",
                "The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear modeling approach to build a practical large scale system, even though the literature have demonstrated the effectiveness of the models in many applications.",
                "Our work is one major step on the road to make Bayesian hierarchical linear models more practical.",
                "The proposed new technique can be easily adapted to run on a cluster of machines, and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users.",
                "The research has much potential to benefit people using EM algorithm on many other IR problems as well as machine learning problems.",
                "EM algorithm is a commonly used machine learning technique.",
                "It is used to find model parameters in many IR problems where the training data is very sparse.",
                "Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering, the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems. 8.",
                "ACKNOWLEDGMENTS We thank Wei Xu, David Lewis and anonymous reviewers for valuable feedback on the work described in this paper.",
                "Part of the work was supported by Yahoo, Google, the Petascale Data Storage Institute and the Institute for Scalable Scientific Data Management.",
                "Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors, and do not necessarily reflect those of the sponsors. 9.",
                "REFERENCES [1] C. Basu, H. Hirsh, and W. Cohen.",
                "Recommendation as classification: Using social and content-based information in recommendation.",
                "In Proceedings of the Fifteenth National Conference on Artificial Intelligence, 1998. [2] J. S. Breese, D. Heckerman, and C. Kadie.",
                "Empirical analysis of predictive algorithms for collaborative filtering.",
                "Technical report, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan.",
                "Document filtering with inference networks.",
                "In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor, and A. Vinokourov.",
                "Kernel method for document filtering.",
                "In The Eleventh Text REtrieval Conference (TREC11).",
                "National Institute of Standards and Technology, special publication 500-249, 2003. [5] C. Chelba and A. Acero.",
                "Adaptation of maximum entropy capitalizer: Little data can help a lot.",
                "In D. Lin and D. Wu, editors, Proceedings of EMNLP 2004, pages 285-292, Barcelona, Spain, July 2004.",
                "Association for Computational Linguistics. [6] B. Croft and J. Lafferty, editors.",
                "Language Modeling for Information Retrieval.",
                "Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov, and A. Genkin.",
                "Constructing informative prior distributions from domain knowledge in text classification.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 493-500, New York, NY, USA, 2006.",
                "ACM Press. [8] J. Delgado and N. Ishii.",
                "Memory-based weightedmajority prediction for recommender systems.",
                "In ACM SIGIR99 Workshop on Recommender Systems, 1999. [9] GroupLens.",
                "Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman.",
                "A tutorial on learning with bayesian networks.",
                "In M. Jordan, editor, Learning in Graphical Models.",
                "Kluwer Academic, 1998. [11] J. L. Herlocker, J.",
                "A. Konstan, A. Borchers, and J. Riedl.",
                "An algorithmic framework for performing collaborative filtering.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 230-237, New York, NY, USA, 1999.",
                "ACM Press. [12] T. Hofmann and J. Puzicha.",
                "Latent class models for collaborative filtering.",
                "In IJCAI 99: Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 688-693, San Francisco, CA, USA, 1999.",
                "Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).",
                "Internet movie database. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai, and L. Si.",
                "An automatic weighting scheme for collaborative filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 337-344, New York, NY, USA, 2004.",
                "ACM Press. [15] J.",
                "A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl.",
                "GroupLens: Applying collaborative filtering to Usenet news.",
                "Communications of the ACM, 40(3):77-87, 1997. [16] D. Lewis.",
                "Applying support vector machines to the TREC-2001 batch filtering and routing tasks.",
                "In Proceedings of the Eleventh Text REtrieval Conference (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee, , and P. Yu.",
                "Text classification by labeling words.",
                "In Proceedings of The Nineteenth National Conference on Artificial Intelligence (AAAI-2004), July 25-29, 2004. [18] P. Melville, R. J. Mooney, and R. Nagarajan.",
                "Content-boosted collaborative filtering for improved recommendations.",
                "In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002), Edmonton, Canada, 2002. [19] Netflix.",
                "Netflix prize. http://www.netflixprize.com (visited on Nov. 30, 2006), 2006. [20] S. Robertson and K. Sparck-Jones.",
                "Relevance weighting of search terms.",
                "In Journal of the American Society for Information Science, volume 27, pages 129-146, 1976. [21] J. Wang, A. P. de Vries, and M. J. T. Reinders.",
                "Unifying user-based and item-based collaborative filtering approaches by similarity fusion.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 501-508, New York, NY, USA, 2006.",
                "ACM Press. [22] X. Wu and R. K. Srihari.",
                "Incorporating prior knowledge with weighted margin support vector machines.",
                "In Proc.",
                "ACM Knowledge Discovery Data Mining Conf. (ACM SIGKDD 2004), Aug. 2004. [23] Y. Yang, S. Yoo, J. Zhang, and B. Kisiel.",
                "Robustness of adaptive filtering methods in a cross-benchmark evaluation.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2005. [24] K. Yu, V. Tresp, and A. Schwaighofer.",
                "Learning gaussian processes from multiple tasks.",
                "In ICML 05: Proceedings of the 22nd international conference on Machine learning, pages 1012-1019, New York, NY, USA, 2005.",
                "ACM Press. [25] K. Yu, V. Tresp, and S. Yu.",
                "A nonparametric hierarchical bayesian framework for <br>information filter</br>ing.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 353-360.",
                "ACM Press, 2004. [26] X. Zhu.",
                "Semi-supervised learning literature survey.",
                "Technical report, University of Wisconsin - Madison, December 9, 2006. [27] P. Zigoris and Y. Zhang.",
                "Bayesian adaptive user profiling with explicit & implicit feedback.",
                "In Conference on Information and Knowledge Mangement 2006, 2006."
            ],
            "original_annotated_samples": [
                "A nonparametric hierarchical bayesian framework for <br>information filter</br>ing."
            ],
            "translated_annotated_samples": [
                "Un marco bayesiano jerárquico no paramétrico para el <br>filtrado de información</br>."
            ],
            "translated_text": "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual. Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un modelo jerárquico bayesiano. Aprender los parámetros del modelo para optimizar la verosimilitud conjunta de los datos de millones de usuarios es muy costoso computacionalmente. El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de datos en aplicaciones de IR. Este documento propone una nueva técnica de aprendizaje rápido para aprender un gran número de perfiles de usuario individuales. La eficacia y eficiencia del algoritmo propuesto están justificadas por la teoría y demostradas en datos reales de usuarios de Netflix y MovieLens. Categorías y Descriptores de Asignaturas: B.3.3 [Búsqueda y Recuperación de Información]: Filtrado de información Términos Generales: Algoritmos 1. La personalización es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales. Por ejemplo, las tiendas en línea, como Amazon y Netflix, ofrecen recomendaciones personalizadas de productos o servicios adicionales basadas en el historial de un usuario. Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de un usuario a partir de su historial. Un tema importante de personalización estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados basados en el contenido. Estos sistemas aprenden perfiles específicos de usuario a partir de la retroalimentación del usuario para poder recomendar información adaptada a los intereses de cada usuario sin necesidad de que el usuario realice una consulta explícita. Aprender los perfiles de usuario es el problema central de estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica qué tan relevante es un documento para el usuario. Uno de los principales desafíos de construir un sistema de recomendación o personalización es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña. Esto se conoce como el problema de inicio en frío. Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente retroalimentación de ese usuario para aprender un perfil de usuario confiable. Se ha realizado mucha investigación sobre cómo mejorar la precisión de clasificación cuando la cantidad de datos de entrenamiento etiquetados es pequeña. El enfoque de aprendizaje semisupervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26]. Otro enfoque es utilizar el conocimiento del dominio. Los investigadores han modificado diferentes algoritmos de aprendizaje, como NaïveBayes [17], regresión logística [7] y SVMs [22], para integrar el conocimiento del dominio en un clasificador de texto. El tercer enfoque consiste en tomar datos de entrenamiento de otros recursos [5][7]. La efectividad de estos enfoques diferentes es mixta, debido a qué tan bien se ajusta la suposición del modelo subyacente a los datos. Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano. Varios investigadores han demostrado que este enfoque intercambia eficazmente entre la información compartida y la específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario[27][25]. Para aprender un modelo jerárquico bayesiano, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados. Un sistema de recomendación maduro generalmente funciona para millones de usuarios. Es bien sabido que aprender los parámetros óptimos de un modelo jerárquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios. El algoritmo EM es una técnica comúnmente utilizada para el aprendizaje de parámetros debido a su simplicidad y garantía de convergencia. Sin embargo, un sistema de recomendación basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso. Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM tering, o filtrado colaborativo basado en elementos. En este documento, las palabras filtrado y recomendación se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de las variables de entrada. También encontramos que actualizar el parámetro del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones. Este documento modifica el algoritmo EM estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos algoritmo EM modificado. La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M utilizamos la solución analítica en lugar de la solución numérica estimada en el paso E para esos parámetros. Esto reduce considerablemente la computación en una sola iteración de EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales. La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de regresión lineal jerárquica bayesiana utilizado para recomendaciones basadas en contenido. La sección 4 describe cómo aprender los parámetros del modelo utilizando el algoritmo EM estándar, junto con el uso de la nueva técnica propuesta en este artículo. La configuración experimental y los resultados utilizados para validar la técnica de aprendizaje propuesta se informan en las Secciones 5 y 6. La sección 7 resume y ofrece observaciones finales. 2. TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de IR desde la década de 1970. Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus filtrado colaborativo. El filtrado basado en contenido estudia el escenario en el que un sistema de recomendación monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente. El usuario puede leer los documentos entregados y proporcionar retroalimentación explícita de relevancia, la cual el sistema de filtrado utiliza para actualizar el perfil del usuario mediante modelos de recuperación de retroalimentación de relevancia (por ejemplo,). Modelos booleanos, modelos de espacio vectorial, modelos probabilísticos tradicionales [20], redes de inferencia [3] y modelos de lenguaje [6]) o algoritmos de aprendizaje automático (por ejemplo, Máquinas de Vectores de Soporte (SVM), agrupamiento de K vecinos más cercanos (K-NN), redes neuronales, regresión logística o Winnow [16] [4] [23]. El filtrado colaborativo va más allá de simplemente usar el contenido de un documento para recomendar elementos a un usuario, aprovechando la información de otros usuarios con gustos y preferencias similares en el pasado. Se han utilizado heurísticas basadas en memoria y enfoques basados en modelos en la tarea de filtrado colaborativo [15] [8] [2] [14] [12] [11]. Este artículo contribuye a la investigación de recomendaciones basadas en contenido al mejorar la eficiencia y efectividad de los modelos lineales jerárquicos bayesianos, los cuales tienen una sólida base teórica y un buen rendimiento empírico en tareas de recomendación[27][25]. Este artículo no tiene la intención de comparar el filtrado basado en contenido con el filtrado colaborativo ni de afirmar cuál es mejor. Creemos que cada uno complementa al otro, y que el filtrado basado en contenido es extremadamente útil para manejar nuevos documentos/artículos con poco o ningún feedback del usuario. Similar a otros investigadores[18][1][21], encontramos que un sistema de recomendación será más efectivo cuando se combinan ambas técnicas. Sin embargo, esto está fuera del alcance de este documento y, por lo tanto, no se discute aquí. 3. REGRESIÓN LINEAL HIERÁRQUICA BAYESIANA Suponga que hay M usuarios en el sistema. La tarea del sistema es recomendar documentos que sean relevantes para cada usuario. Para cada usuario, el sistema aprende un modelo de usuario a partir del historial de los usuarios. En el resto de este documento, utilizaremos las siguientes notaciones para representar las variables en el sistema. m = 1, 2, ..., M: El índice para cada usuario individual. M es el número total de usuarios. wm: El parámetro del modelo de usuario asociado con el usuario m. wm es un vector de dimensión K. j = 1, 2, ..., Jm: El índice para un conjunto de datos para el usuario m. Jm es el número de datos de entrenamiento para el usuario m. Dm = {(xm,j, ym,j)}: Un conjunto de datos asociado con el usuario m. xm,j es un vector de dimensión K que representa el j-ésimo documento de entrenamiento del usuario m. ym,j es un escalar que representa la etiqueta del documento xm,j. k = 1, 2, ..., K: El índice dimensional de la variable de entrada x. El enfoque de modelado jerárquico bayesiano ha sido ampliamente utilizado en aplicaciones reales de recuperación de información. Los modelos lineales jerárquicos bayesianos generalizados, uno de los modelos jerárquicos bayesianos más simples, son comúnmente utilizados y han logrado un buen rendimiento en tareas de filtrado colaborativo [25] y filtrado adaptativo basado en contenido [27]. La Figura 1 muestra la representación gráfica de un modelo jerárquico bayesiano. En este gráfico, cada modelo de usuario está representado por un vector aleatorio wm. Suponemos que un modelo de usuario se muestrea aleatoriamente de una distribución previa P(w|Φ). El sistema puede predecir la etiqueta de usuario y de un documento x dado una estimación de wm (o distribución de wms) utilizando una función y = f(x, w). El modelo se llama modelo lineal jerárquico bayesiano generalizado cuando y = f(wT x) es cualquier modelo lineal generalizado como regresión logística, SVM y regresión lineal. Para estimar de manera confiable el modelo de usuario wm, el sistema puede obtener información de otros usuarios a través de la prior Φ = (µ, Σ). Ahora observamos un modelo comúnmente utilizado donde y = wT x + , donde ∼ N(0, σ2 ) es un ruido aleatorio [25][27]. Suponga que cada modelo de usuario wm es una muestra independiente de una distribución poblacional P(w|Φ), la cual está regida por un hiperparámetro desconocido Φ. Que la distribución previa del modelo de usuario w sea una distribución gaussiana con parámetro Φ = (µ, Σ), que es la distribución previa comúnmente utilizada para modelos lineales. µ = (µ1, µ2, ..., µK) es un vector de K dimensiones que representa la media de la distribución gaussiana, y Σ es la matriz de covarianza de la gaussiana. Normalmente, se utiliza una distribución Normal N(0, aI) y una distribución Inverse Wishart P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) como hiperprior para modelar la distribución previa de µ y Σ respectivamente. Yo es la matriz identidad de dimensión K, y a, b y c son números reales. Con esta configuración, tenemos el siguiente modelo para el sistema: 1. µ y Σ se muestrean de N(0, aI) e IWν (aI), respectivamente. 2. La primera dimensión de x es una variable ficticia que siempre es igual a 1. Figura 1: Ilustración de las dependencias de variables en el modelo jerárquico. La calificación, y, para un documento, x, está condicionada al documento y al modelo de usuario, wm, asociado con el usuario m. Los usuarios comparten información sobre sus modelos a través de la prior, Φ = (µ, Σ). Para cada usuario m, wm se muestrea aleatoriamente de una distribución Normal: wm ∼ N(µ, Σ2 ) 3. Para cada elemento xm,j, ym,j se muestrea aleatoriamente de una distribución Normal: ym,j ∼ N(wT mxm,j, σ2). Que θ = (Φ, w1, w2, ..., wM) represente los parámetros de este sistema que necesitan ser estimados. La verosimilitud conjunta de todas las variables en el modelo probabilístico, que incluye los datos y los parámetros, es: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) Para simplificar, asumimos que a, b, c y σ son proporcionados al sistema. 4. APRENDIZAJE DE PARÁMETROS DEL MODELO Si se conoce el prior Φ, encontrar el óptimo wm es sencillo: se trata de una regresión lineal simple. Por lo tanto, nos enfocaremos en estimar Φ. La solución a priori máxima de Φ se da por ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Encontrar la solución óptima para el problema anterior es desafiante, ya que necesitamos integrar sobre todos los w = (w1, w2, ..., wM), que son variables ocultas no observadas. 4.1 Algoritmo EM para Modelos Lineales Jerárquicos Bayesianos En la Ecuación 5, Φ es el parámetro que necesita ser estimado, y el resultado depende de las variables latentes no observadas w. Este tipo de problema de optimización suele resolverse mediante el algoritmo EM. Aplicando EM al problema anterior, el conjunto de modelos de usuario w son las variables ocultas no observables y tenemos: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw. Basándonos en la derivación de las fórmulas EM presentadas en [24], tenemos los siguientes pasos de Expectation-Maximization para encontrar los hiperparámetros óptimos. Por razones de espacio, omitimos la derivación en este artículo ya que no es el enfoque de nuestro trabajo. Paso E: Para cada usuario m, estime la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual del prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) donde Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j Paso M: Optimice el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Muchos sistemas de IR impulsados por aprendizaje automático utilizan una estimación puntual de los parámetros en diferentes etapas del sistema. Sin embargo, estamos estimando la distribución posterior de las variables en el paso E. Esto evita el sobreajuste de wm a los datos de un usuario en particular, que pueden ser pequeños y ruidosos. Una discusión detallada sobre este tema aparece en [10]. 4.2 Nuevo Algoritmo: EM Modificado. Aunque el algoritmo EM es ampliamente estudiado y utilizado en aplicaciones de aprendizaje automático, utilizar el proceso EM mencionado anteriormente para resolver modelos lineales jerárquicos bayesianos en sistemas de recuperación de información a gran escala sigue siendo demasiado costoso computacionalmente. En esta sección, describimos por qué la tasa de aprendizaje del algoritmo EM es lenta en nuestra aplicación e introducimos una nueva técnica para hacer que el aprendizaje del modelo lineal jerárquico bayesiano sea escalable. La derivación del nuevo algoritmo de aprendizaje estará basada en el algoritmo EM descrito en la sección anterior. Primero, las matrices de covarianza Σ2 , Σ2 m suelen ser demasiado grandes para ser computacionalmente factibles. Por simplicidad, y como práctica común en IR, no modelamos la correlación entre características. Así aproximamos estas matrices con matrices diagonales de dimensión K. En el resto del documento, utilizamos estos símbolos para representar sus aproximaciones diagonales: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     En segundo lugar, y lo más importante, el espacio de entrada es muy disperso y hay muchas dimensiones que no están relacionadas con un usuario particular en una aplicación de recuperación de información real. Por ejemplo, consideremos un sistema de recomendación de películas, con la variable de entrada x representando una película en particular. Para la j-ésima película que el usuario m ha visto, sea xm,j,k = 1 si el director de la película es Jean-Pierre Jeunet (indexado por k). Aquí asumimos que si este director dirigió una película específica está representado por la k-ésima dimensión. Si el usuario m nunca ha visto una película dirigida por Jean-Pierre Jeunet, entonces la dimensión correspondiente siempre es cero (xm,j,k = 0 para todos los j). Una desventaja importante del algoritmo EM es que la importancia de una característica, µk, puede estar fuertemente dominada por usuarios que nunca han encontrado esta característica (es decir, j xm,j,k = 0) en el paso M (Ecuación 8). Suponga que 100 de cada 1 millón de usuarios han visto la película dirigida por Jean-Pierre Jeunet, y que los espectadores han calificado todas sus películas como excelentes. Intuitivamente, él es un buen director y el peso para él (µk) debería ser alto. Antes de la iteración de EM, el valor inicial de µ suele establecerse en 0. Dado que los otros 999,900 usuarios no han visto esta película, sus pesos correspondientes (w1,k, w2,k, ..., wm,k..., w999900,k) para ese director serían muy pequeños inicialmente. Por lo tanto, el peso correspondiente del director en el µk anterior en el primer paso M sería muy bajo, y la varianza σm,k será grande (Ecuaciones 8 y 7). Es indeseable que los usuarios que nunca han visto ninguna película producida por el director influyan tanto en la importancia del director. Esto hace que la convergencia del algoritmo EM estándar sea muy lenta. Ahora veamos si podemos mejorar la velocidad de aprendizaje del algoritmo. Sin pérdida de generalidad, asumamos que la k-ésima dimensión de la variable de entrada x no está relacionada con un usuario particular m. Lo que queremos decir es que xm,j,k = 0 para todo j = 1, ..., Jm. Es sencillo demostrar que la k-ésima fila y la k-ésima columna de Sxx,m están completamente llenas de ceros, y que la k-ésima dimensión de Sxy,m también se anula. Por lo tanto, la dimensión k correspondiente de la media de los modelos de usuario, ¯wm, debería ser igual a la del anterior: ¯wm,k = µk, con la covarianza correspondiente de σm,k = σk. En el paso M, el algoritmo EM estándar utiliza la solución numérica de la distribución P(wm|Dm, Φ) estimada en el paso E (Ecuación 8 y Ecuación 7). Sin embargo, las soluciones numéricas son muy poco confiables para ¯wm,k y σm,k cuando la k-ésima dimensión no está relacionada con el m-ésimo usuario. Un enfoque mejor es utilizar las soluciones analíticas ¯wm,k = µk, y σm,k = σk para los pares no relacionados (m, k), junto con la solución numérica estimada en el paso E para los otros pares (m, k). Así obtenemos el siguiente nuevo algoritmo EM similar: Paso E modificado: Para cada usuario m, estimar la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual de σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) donde sxx,m,k = j x2 m,j,k y sxy,m,k = j xm,j,kym,j Paso M modificado Optimizar el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E para pares de usuario-característica relacionados. El paso M utiliza implícitamente la solución analítica para pares de usuario-característica no relacionados. µk = 1 Mk m:relacionado ¯wm,k (12) σ2 k = 1 Mk m:relacionado σ2 m,k + ( ¯wm,k − µk)( ¯wm,k − µk)T (13) donde Mk es el número de usuarios relacionados con la característica k. Solo estimamos la diagonal de Σ2 m y Σ, ya que estamos utilizando la aproximación diagonal de las matrices de covarianza. Para estimar ¯wm, solo necesitamos calcular las soluciones numéricas para las dimensiones que están relacionadas con el usuario m. Para estimar σ2 k y µk, solo sumamos sobre los usuarios que están relacionados con la k-ésima característica. Hay dos beneficios principales del nuevo algoritmo. Primero, dado que solo se necesitan los pares relacionados (m, k) en el paso M modificado, la complejidad computacional en una sola iteración de EM es mucho menor cuando los datos son dispersos y muchos de los pares (m, k) no están relacionados. En segundo lugar, los parámetros estimados en el paso M modificado (Ecuaciones 12 - 13) son más precisos que el paso M estándar descrito en la Sección 4.1 porque se utilizaron soluciones analíticas exactas ¯wm,k = µk y σm,k = σk para los pares no relacionados (m, k) en el nuevo algoritmo en lugar de una solución aproximada como en el algoritmo estándar. METODOLOGÍA EXPERIMENTAL 5.1 Conjunto de Datos de Evaluación Para evaluar la técnica propuesta, utilizamos los siguientes tres conjuntos de datos principales (Tabla 1): Datos de MovieLens: Este conjunto de datos fue creado combinando las valoraciones de relevancia del conjunto de datos de MovieLens[9] con documentos de la Base de Datos de Películas en Internet (IMDB). MovieLens permite a los usuarios clasificar cuánto disfrutaron una película específica en una escala del 1 al 5. Esta calificación de simpatía se utilizó como una medida de cuán relevante es el documento que representa la película correspondiente para el usuario. Consideramos los documentos con puntuaciones de 4 o 5 como relevantes, y los documentos con una puntuación de 1 a 3 como irrelevantes para el usuario. MovieLens proporcionó juicios de relevancia sobre 3,057 documentos de 6,040 usuarios diferentes. En promedio, cada usuario calificó 151 películas, de las cuales 87 fueron consideradas relevantes. La puntuación promedio para un documento fue de 3.58. Los documentos que representan cada película fueron construidos a partir de la porción de la base de datos de IMDB que está disponible para descarga pública[13]. Basándonos en esta base de datos, creamos un documento por película que contenía la información relevante sobre ella (por ejemplo, directores, actores, etc.). Tabla 1: Estadísticas del conjunto de datos. En Reuters, el número de calificaciones para un usuario simulado es el número de documentos relevantes para el tema correspondiente. Datos Usuarios Documentos Calificaciones por Usuario MovieLens 6,040 3,057 151 Netflix-todos 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Datos de Netflix: Este conjunto de datos fue construido combinando documentos sobre películas obtenidos de la web con un conjunto de juicios de relevancia de clientes reales de alquiler de películas de Netflix[19]. Netflix proporciona públicamente las evaluaciones de relevancia de 480,189 clientes anónimos. Hay alrededor de 100 millones de calificaciones en una escala del 1 al 5 para 17,770 documentos. Similar a MovieLens, consideramos documentos con puntuaciones de 4 o 5 de agradabilidad como relevantes. Este número se redujo a 1000 clientes mediante muestreo aleatorio. El cliente promedio en el conjunto de datos reducido proporcionó 127 juicios, de los cuales 70 fueron considerados relevantes. La puntuación promedio de los documentos es de 3.55. Datos de Reuters: Este es el Corpus de Reuters, Volumen 1. Cubre 810,000 noticias en inglés de Reuters desde el 20 de agosto de 1996 hasta el 19 de agosto de 1997. Solo se utilizaron las primeras 100,000 noticias en nuestros experimentos. El corpus de Reuters viene con una jerarquía de temas. Cada documento se asigna a una de varias ubicaciones en el árbol jerárquico. El primer nivel del árbol contiene cuatro temas, denotados como C, E, M y G. Para los experimentos en este artículo, el árbol fue cortado en el nivel 1 para crear cuatro árboles más pequeños, cada uno de los cuales corresponde a un conjunto de datos más pequeño: Reuters-E, Reuters-C, Reuters-M y Reuters-G. Para cada conjunto de datos pequeño, creamos varios perfiles, un perfil para cada nodo en un subárbol, para simular múltiples usuarios, cada uno con una definición de relevancia relacionada pero separada. Todos los perfiles de usuario en una sub-rama se supone que comparten la misma distribución de modelo previo. Dado que este corpus indica explícitamente solo los documentos relevantes para un tema (usuario), todos los demás documentos se consideran irrelevantes. 5.2 Evaluación Diseñamos los experimentos para responder a las siguientes tres preguntas: 1. ¿Necesitamos hacer el esfuerzo de utilizar un enfoque bayesiano y aprender una distribución a priori de otros usuarios? 2. ¿El nuevo algoritmo funciona mejor que el algoritmo EM estándar para aprender el modelo lineal jerárquico bayesiano? 3. ¿Puede el nuevo algoritmo aprender rápidamente muchos modelos de usuario? Para responder a la primera pregunta, comparamos los modelos jerárquicos bayesianos con los modelos de regresión lineal regularizados Norm-2 comúnmente utilizados. De hecho, el enfoque comúnmente utilizado es equivalente al modelo aprendido al final de la primera iteración de EM. Para responder a la segunda pregunta, comparamos el nuevo algoritmo propuesto con el algoritmo EM estándar para ver si el nuevo algoritmo de aprendizaje es mejor. Para responder a la tercera pregunta, probamos la eficiencia del nuevo algoritmo en todo el conjunto de datos de Netflix, donde aproximadamente medio millón de modelos de usuario deben ser aprendidos juntos. Para los conjuntos de datos de MovieLens y Netflix, la efectividad del algoritmo se midió mediante el error cuadrático medio, mientras que en el conjunto de datos de Reuters se utilizó el error de clasificación porque era más informativo. Primero evaluamos el rendimiento en cada usuario individual, y luego estimamos el promedio macro sobre todos los usuarios. Se realizaron pruebas estadísticas (pruebas t) para determinar si los resultados son significativos. Para los experimentos en los conjuntos de datos de MovieLens y Netflix, utilizamos una muestra aleatoria del 90% de cada usuario para entrenamiento, y el resto para pruebas. En el conjunto de datos de Reuters, debido a que hay demasiados documentos relevantes para cada tema en el corpus, utilizamos una muestra aleatoria del 10% de cada tema para el entrenamiento, y el 10% de los documentos restantes para las pruebas. Para todas las ejecuciones, establecimos (a, b, c, Σ) = (0.1, 10, 0.1, 1) manualmente. 6. RESULTADOS EXPERIMENTALES Las Figuras 2, 3 y 4 muestran que en todos los conjuntos de datos, el enfoque de modelado jerárquico bayesiano tiene una mejora estadísticamente significativa sobre el modelo de regresión lineal regularizado, que es equivalente a los modelos jerárquicos bayesianos aprendidos en la primera iteración. Un análisis adicional muestra una correlación negativa entre la cantidad de datos de entrenamiento para un usuario y la mejora que obtiene el sistema. Esto sugiere que la información prestada de otros usuarios tiene mejoras más significativas para usuarios con menos datos de entrenamiento, lo cual es lo esperado. Sin embargo, la fuerza de la correlación varía entre los conjuntos de datos, y la cantidad de datos de entrenamiento no es la única característica que influirá en el rendimiento final. Las Figuras 2 y 3 muestran que el nuevo algoritmo propuesto funciona mejor que el algoritmo EM estándar en los conjuntos de datos de Netflix y MovieLens. Esto no es sorprendente ya que el número de pares de características-usuarios relacionados es mucho menor que el número de pares de características-usuarios no relacionados en estos dos conjuntos de datos, por lo que se espera que el nuevo algoritmo propuesto funcione mejor. La Figura 4 muestra que los dos algoritmos funcionan de manera similar en el conjunto de datos de Reuters-E. La precisión del nuevo algoritmo es similar a la del algoritmo EM estándar en cada iteración. Los patrones generales son muy similares en otros subconjuntos de Reuters. Un análisis adicional muestra que solo el 58% de los pares usuario-característica no están relacionados en este conjunto de datos. Dado que el número de pares usuario-característica no relacionados no es extremadamente grande, la dispersión no es un problema grave en el conjunto de datos de Reuters. Por lo tanto, los dos algoritmos de aprendizaje se desempeñan de manera similar. Los resultados sugieren que solo en un corpus donde el número de pares usuario-característica no relacionados es mucho mayor que el número de pares relacionados, como en el conjunto de datos de Netflix, la técnica propuesta obtendrá una mejora significativa sobre el EM estándar. Sin embargo, los experimentos también muestran que cuando la suposición no se cumple, el nuevo algoritmo no afecta el rendimiento. Aunque la técnica propuesta es más rápida que la estándar. Figura 2: Rendimiento en un subconjunto de Netflix con 1,000 usuarios. El nuevo algoritmo es estadísticamente significativamente mejor que el algoritmo EM en las iteraciones 2 a 10. Los modelos lineales regularizados con norma-2 son equivalentes a los modelos jerárquicos bayesianos aprendidos en la primera iteración, y son estadísticamente significativamente peores que los modelos jerárquicos bayesianos. Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional Figura 3: Rendimiento en un subconjunto de MovieLens con 1,000 usuarios. El nuevo algoritmo es significativamente mejor estadísticamente que el algoritmo EM en las iteraciones 2 a 17 (evaluado con error cuadrático medio). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iteraciones ErrorCuadráticoMedio Nuevo Algoritmo EM Tradicional 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iteraciones Error de Clasificación Nuevo Algoritmo EM Tradicional Figura 4: Rendimiento en un subconjunto de Reuters-E con 26 perfiles. Las actuaciones en Reuters-C, Reuters-M, Reuters-G son similares. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional EM, ¿realmente puede aprender rápidamente millones de modelos de usuario? Nuestros resultados muestran que el algoritmo EM modificado converge rápidamente, y 2-3 iteraciones del EM modificado darían como resultado una estimación confiable. Evaluamos el algoritmo en todo el conjunto de datos de Netflix (480,189 usuarios, 159,836 características y 100 millones de valoraciones) ejecutándolo en un solo PC con CPU (2GB de memoria, P4 3GHz). El sistema completó una iteración EM modificada en aproximadamente 4 horas. Esto demuestra que la técnica propuesta puede manejar eficientemente sistemas a gran escala como Netflix. CONCLUSIÓN El aprendizaje de perfiles de usuario basado en contenido es un problema importante y es clave para proporcionar recomendaciones personales a un usuario, especialmente para recomendar nuevos elementos con un pequeño número de calificaciones. El enfoque de modelado jerárquico bayesiano se está convirtiendo en un enfoque importante para el aprendizaje de perfiles de usuario debido a su capacidad teóricamente justificada para ayudar a un usuario a través de la transferencia de información de otros usuarios mediante hiperpriors. Este artículo examinó la debilidad del enfoque de aprendizaje basado en EM popular para modelos lineales jerárquicos bayesianos y propuso una técnica de aprendizaje mejorada llamada EM Modificado. Demostramos que la nueva técnica es teóricamente más eficiente computacionalmente que el algoritmo EM estándar. La evaluación en los conjuntos de datos de MovieLens y Netflix demostró la efectividad de la nueva técnica cuando los datos son dispersos, lo que significa que la proporción de pares de usuario-característica relacionados con respecto a los pares no relacionados es pequeña. La evaluación en el conjunto de datos de Reuters mostró que la nueva técnica tuvo un rendimiento similar al algoritmo EM estándar cuando la condición de dispersión no se cumple. En general, es mejor utilizar el nuevo algoritmo ya que es tan simple como el EM estándar, el rendimiento es igual o mejor que el del EM, y la complejidad computacional es menor en cada iteración. Vale la pena mencionar que aunque el espacio de problemas original no sea disperso, la dispersión puede crearse artificialmente cuando un sistema de recomendación utiliza técnicas de selección de características específicas del usuario para reducir el ruido y la complejidad del modelo del usuario. La técnica propuesta también puede adaptarse para mejorar el aprendizaje en dicho escenario. También demostramos que la técnica propuesta puede aprender medio millón de perfiles de usuario a partir de 100 millones de valoraciones en unas pocas horas con una sola CPU. La investigación es importante porque la escalabilidad es una preocupación importante para los investigadores al utilizar el enfoque de modelado lineal jerárquico bayesiano para construir un sistema a gran escala práctico, a pesar de que la literatura ha demostrado la efectividad de los modelos en muchas aplicaciones. Nuestro trabajo es un paso importante en el camino para hacer que los modelos lineales jerárquicos bayesianos sean más prácticos. La nueva técnica propuesta se puede adaptar fácilmente para ejecutarse en un clúster de máquinas, y así acelerar aún más el proceso de aprendizaje para manejar un sistema a mayor escala con cientos de millones de usuarios. La investigación tiene mucho potencial para beneficiar a las personas utilizando el algoritmo EM en muchos otros problemas de IR, así como en problemas de aprendizaje automático. El algoritmo EM es una técnica de aprendizaje automático comúnmente utilizada. Se utiliza para encontrar los parámetros del modelo en muchos problemas de IR donde los datos de entrenamiento son muy dispersos. Aunque nos estamos centrando en los modelos lineales jerárquicos bayesianos para recomendación y filtrado, la nueva idea de utilizar una solución analítica en lugar de una solución numérica para pares de usuario-característica no relacionados en el paso M podría adaptarse a muchos otros problemas. 8. AGRADECIMIENTOS Agradecemos a Wei Xu, David Lewis y a los revisores anónimos por sus valiosos comentarios sobre el trabajo descrito en este artículo. Parte del trabajo fue apoyado por Yahoo, Google, el Instituto de Almacenamiento de Datos a Escala Peta y el Instituto de Gestión de Datos Científicos Escalables. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las de los patrocinadores. REFERENCIAS [1] C. Basu, H. Hirsh y W. Cohen. Recomendación como clasificación: Utilizando información social y basada en contenido en la recomendación. En Actas de la Decimoquinta Conferencia Nacional de Inteligencia Artificial, 1998. [2] J. S. Breese, D. Heckerman y C. Kadie. Análisis empírico de algoritmos predictivos para filtrado colaborativo. Informe técnico, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan. Filtrado de documentos con redes de inferencia. En Actas de la Decimonovena Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor y A. Vinokourov. Método del núcleo para el filtrado de documentos. En la Undécima Conferencia de Recuperación de Información de Texto (TREC11). Instituto Nacional de Normas y Tecnología, publicación especial 500-249, 2003. [5] C. Chelba y A. Acero. Adaptación del capitalizador de entropía máxima: Poca información puede ayudar mucho. En D. Lin y D. Wu, editores, Actas de EMNLP 2004, páginas 285-292, Barcelona, España, julio de 2004. Asociación de Lingüística Computacional. [6] B. Croft y J. Lafferty, editores. Modelado de lenguaje para recuperación de información. Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov y A. Genkin. Construyendo distribuciones a priori informativas a partir del conocimiento del dominio en la clasificación de textos. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 493-500, Nueva York, NY, EE. UU., 2006. ACM Press. [8] J. Delgado y N. Ishii. Predicción basada en memoria ponderada para sistemas de recomendación. En el Taller ACM SIGIR99 sobre Sistemas de Recomendación, 1999. [9] GroupLens. Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman. Un tutorial sobre el aprendizaje con redes bayesianas. En M. Jordan, editor, Aprendizaje en Modelos Gráficos. Kluwer Academic, 1998. [11] J. L. Herlocker, J. \n\nKluwer Academic, 1998. [11] J. L. Herlocker, J. A. Konstan, A. Borchers y J. Riedl. Un marco algorítmico para realizar filtrado colaborativo. En SIGIR 99: Actas de la 22ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 230-237, Nueva York, NY, EE. UU., 1999. ACM Press. [12] T. Hofmann y J. Puzicha. Modelos de clases latentes para filtrado colaborativo. En IJCAI 99: Actas de la Decimosexta Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 688-693, San Francisco, CA, EE. UU., 1999. Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).\nMorgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB). Base de datos de películas en internet. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai y L. Si. Un esquema de ponderación automática para filtrado colaborativo. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 337-344, Nueva York, NY, EE. UU., 2004. ACM Press. [15] J. A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon y J. Riedl. GroupLens: Aplicando filtrado colaborativo a las noticias de Usenet. Comunicaciones de la ACM, 40(3):77-87, 1997. [16] D. Lewis. Aplicando máquinas de vectores de soporte a las tareas de filtrado y enrutamiento por lotes de TREC-2001. En Actas de la Undécima Conferencia de Recuperación de Texto (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee y P. Yu. Clasificación de texto mediante etiquetado de palabras. En Actas de la Decimonovena Conferencia Nacional de Inteligencia Artificial (AAAI-2004), 25-29 de julio de 2004. [18] P. Melville, R. J. Mooney y R. Nagarajan. Filtrado colaborativo potenciado por contenido para recomendaciones mejoradas. En Actas de la Decimoctava Conferencia Nacional de Inteligencia Artificial (AAAI-2002), Edmonton, Canadá, 2002. [19] Netflix. Premio Netflix. http://www.netflixprize.com (visitado el 30 de noviembre de 2006), 2006. [20] S. Robertson y K. Sparck-Jones. Ponderación de la relevancia de los términos de búsqueda. En Journal of the American Society for Information Science, volumen 27, páginas 129-146, 1976. [21] J. Wang, A. P. de Vries y M. J. T. Reinders. Unificando enfoques de filtrado colaborativo basados en usuarios y en elementos mediante la fusión de similitudes. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 501-508, Nueva York, NY, EE. UU., 2006. ACM Press. [22] X. Wu y R. K. Srihari. Incorporando conocimientos previos con máquinas de vectores de soporte de margen ponderado. En Proc. Conferencia de Minería de Datos y Descubrimiento de Conocimiento de ACM (ACM SIGKDD 2004), agosto de 2004. [23] Y. Yang, S. Yoo, J. Zhang y B. Kisiel. Robustez de los métodos de filtrado adaptativo en una evaluación de referencia cruzada. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 2005. [24] K. Yu, V. Tresp y A. Schwaighofer. Aprendiendo procesos gaussianos de múltiples tareas. En ICML 05: Actas de la 22ª conferencia internacional sobre aprendizaje automático, páginas 1012-1019, Nueva York, NY, EE. UU., 2005. ACM Press. [25] K. Yu, V. Tresp, y S. Yu. Un marco bayesiano jerárquico no paramétrico para el <br>filtrado de información</br>. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 353-360. ACM Press, 2004. [26] X. Zhu. \n\nACM Press, 2004. [26] X. Zhu. Revisión de la literatura sobre aprendizaje semisupervisado. Informe técnico, Universidad de Wisconsin - Madison, 9 de diciembre de 2006. [27] P. Zigoris y Y. Zhang. Perfilado de usuario bayesiano adaptativo con retroalimentación explícita e implícita. En la Conferencia sobre Gestión de la Información y el Conocimiento 2006, 2006. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "personalization": {
            "translated_key": "personalización",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
                "A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model.",
                "Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive.",
                "The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications.",
                "This paper proposes a new fast learning technique to learn a large number of individual user profiles.",
                "The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens.",
                "Categories and Subject Descriptors: B.3.3 [Information Search and Retrieval]: Information filtering General Terms: Algorithms 1.",
                "INTRODUCTION <br>personalization</br> is the future of the Web, and it has achieved great success in industrial applications.",
                "For example, online stores, such as Amazon and Netflix, provide customized recommendations for additional products or services based on a users history.",
                "Recent offerings such as My MSN, My Yahoo!, My Google, and Google News have attracted much attention due to their potential ability to infer a users interests from his/her history.",
                "One major <br>personalization</br> topic studied in the information retrieval community is content-based personal recommendation systems1 .",
                "These systems learn user-specific profiles from user feedback so that they can recommend information tailored to each individual users interest without requiring the user to make an explicit query.",
                "Learning the user profiles is the core problem for these systems.",
                "A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user.",
                "One major challenge of building a recommendation or <br>personalization</br> system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small.",
                "This is known as the cold start problem.",
                "This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile.",
                "There has been much research on improving classification accuracy when the amount of labeled training data is small.",
                "The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal [26].",
                "Another approach is using domain knowledge.",
                "Researchers have modified different learning algorithms, such as Na¨ıveBayes [17], logistic regression [7], and SVMs [22], to integrate domain knowledge into a text classifier.",
                "The third approach is borrowing training data from other resources [5][7].",
                "The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data.",
                "One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach.",
                "Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial performance for each user[27][25].",
                "In order to learn a Bayesian hierarchical model, the system usually tries to find the most likely model parameters for the given data.",
                "A mature recommendation system usually works for millions of users.",
                "It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users.",
                "The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee.",
                "However, a content based recommendation system often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector.",
                "With careful analysis of the EM algorithm in this scenario (Section 4), we find that the EM tering, or item-based collaborative filtering.",
                "In this paper, the words filtering and recommendation are used interchangeably. algorithm converges very slowly due to the sparseness of the input variables.",
                "We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O(MK), where M is the number of users and K is the number of dimensions.",
                "This paper modifies the standard EM algorithm to create an improved learning algorithm, which we call the Modified EM algorithm.",
                "The basic idea is that instead of calculating the numerical solution for all the user profile parameters, we derive the analytical solution of the parameters for some feature dimensions, and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters.",
                "This greatly reduces the computation at a single EM iteration, and also has the benefit of increasing the convergence speed of the learning algorithm.",
                "The proposed technique is not only well supported by theory, but also by experimental results.",
                "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression modeling framework used for content-based recommendations.",
                "Section 4 describes how to learn the model parameters using the standard EM algorithm, along with using the new technique proposed in this paper.",
                "The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6.",
                "Section 7 summarizes and offers concluding remarks. 2.",
                "RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the IR community since the 1970s.",
                "The approaches that have been used to solve this problem can be roughly classified into two major categories: content based filtering versus collaborative filtering.",
                "Content-based filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user.",
                "The user may read the delivered documents and provide explicit relevance feedback, which the filtering system then uses to update the users profile using relevance feedback retrieval models (e.g.",
                "Boolean models, vector space models, traditional probabilistic models [20] , inference networks [3] and language models [6]) or machine learning algorithms (e.g.",
                "Support Vector Machines (SVM), K nearest neighbors (K-NN) clustering, neural networks, logistic regression, or Winnow [16] [4] [23]).",
                "Collaborative filtering goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past.",
                "Memorybased heuristics and model based approaches have been used in collaborative filtering task [15] [8] [2] [14] [12] [11].",
                "This paper contributes to the content-based recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks[27][25].",
                "This paper does not intend to compare content-based filtering with collaborative filtering or claim which one is a better.",
                "We think each complements the other, and that content-based filtering is extremely useful for handling new documents/items with little or no user feedback.",
                "Similar to some other researchers[18][1][21], we found that a recommendation system will be more effective when both techniques are combined.",
                "However, this is beyond the scope of this paper and thus not discussed here. 3.",
                "BAYESIAN HIERARCHICAL LINEAR REGRESSION Assume there are M users in the system.",
                "The task of the system is to recommend documents that are relevant to each user.",
                "For each user, the system learns a user model from the users history.",
                "In the rest of this paper, we will use the following notations to represent the variables in the system. m = 1, 2, ..., M: The index for each individual user.",
                "M is the total number of users. wm: The user model parameter associated with user m. wm is a K dimensional vector. j = 1, 2, ..., Jm: The index for a set of data for user m. Jm is the number of training data for user m. Dm = {(xm,j, ym,j)}: A set of data associated with user m. xm,j is a K dimensional vector that represents the mth users jth training document.2 ym,j is a scalar that represents the label of document xm,j. k = 1, 2, ..., K: The dimensional index of input variable x.",
                "The Bayesian hierarchical modeling approach has been widely used in real-world information retrieval applications.",
                "Generalized Bayesian hierarchical linear models, one of the simplest Bayesian hierarchical models, are commonly used and have achieved good performance on collaborative filtering [25] and content-based adaptive filtering [27] tasks.",
                "Figure 1 shows the graphical representation of a Bayesian hierarchical model.",
                "In this graph, each user model is represented by a random vector wm.",
                "We assume a user model is sampled randomly from a prior distribution P(w|Φ).",
                "The system can predict the user label y of a document x given an estimation of wm (or wms distribution) using a function y = f(x, w).",
                "The model is called generalized Bayesian hierarchical linear model when y = f(wT x) is any generalized linear model such as logistic regression, SVM, and linear regression.",
                "To reliably estimate the user model wm, the system can borrow information from other users through the prior Φ = (µ, Σ).",
                "Now we look at one commonly used model where y = wT x + , where ∼ N(0, σ2 ) is a random noise [25][27].",
                "Assume that each user model wm is an independent draw from a population distribution P(w|Φ), which is governed by some unknown hyperparameter Φ.",
                "Let the prior distribution of user model w be a Gaussian distribution with parameter Φ = (µ, Σ), which is the commonly used prior for linear models. µ = (µ1, µ2, ..., µK ) is a K dimensional vector that represents the mean of the Gaussian distribution, and Σ is the covariance matrix of the Gaussian.",
                "Usually, a Normal distribution N(0, aI) and an Inverse Wishart distribution P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) are used as hyperprior to model the prior distribution of µ and Σ respectively.",
                "I is the K dimensional identity matrix, and a, b, and c are real numbers.",
                "With these settings, we have the following model for the system: 1. µ and Σ are sampled from N(0, aI) and IWν (aI), respectively. 2 The first dimension of x is a dummy variable that always equals to 1.",
                "Figure 1: Illustration of dependencies of variables in the hierarchical model.",
                "The rating, y, for a document, x, is conditioned on the document and the user model, wm, associated with the user m. Users share information about their models through the prior, Φ = (µ, Σ). 2.",
                "For each user m, wm is sampled randomly from a Normal distribution: wm ∼ N(µ, Σ2 ) 3.",
                "For each item xm,j, ym,j is sampled randomly from a Normal distribution: ym,j ∼ N(wT mxm,j, σ2 ).",
                "Let θ = (Φ, w1, w2, ..., wM ) represent the parameters of this system that needs to be estimated.",
                "The joint likelihood for all the variables in the probabilistic model, which includes the data and the parameters, is: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) For simplicity, we assume a, b, c, and σ are provided to the system. 4.",
                "MODEL PARAMETER LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple linear regression.",
                "Therefore, we will focus on estimating Φ.",
                "The maximum a priori solution of Φ is given by ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Finding the optimal solution for the above problem is challenging, since we need to integrate over all w = (w1, w2, ..., wM ), which are unobserved hidden variables. 4.1 EM Algorithm for Bayesian Hierarchical Linear Models In Equation 5, Φ is the parameter needs to be estimated, and the result depends on unobserved latent variables w. This kind of optimization problem is usually solved by the EM algorithm.",
                "Applying EM to the above problem, the set of user models w are the unobservable hidden variables and we have: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw Based on the derivation of the EM formulas presented in [24], we have the following Expectation-Maximization steps for finding the optimal hyperparameters.",
                "For space considerations, we omit the derivation in this paper since it is not the focus of our work.",
                "E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of the prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) where Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j M step: Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Many machine learning driven IR systems use a point estimate of the parameters at different stages in the system.",
                "However, we are estimating the posterior distribution of the variables at the E step.",
                "This avoids overfitting wm to a particular users data, which may be small and noisy.",
                "A detailed discussion about this subject appears in [10]. 4.2 New Algorithm: Modified EM Although the EM algorithm is widely studied and used in machine learning applications, using the above EM process to solve Bayesian hierarchical linear models in large-scale information retrieval systems is still too computationally expensive.",
                "In this section, we describe why the learning rate of the EM algorithm is slow in our application and introduce a new technique to make the learning of the Bayesian hierarchical linear model scalable.",
                "The derivation of the new learning algorithm will be based on the EM algorithm described in the previous section.",
                "First, the covariance matrices Σ2 , Σ2 m are usually too large to be computationally feasible.",
                "For simplicity, and as a common practice in IR, we do not model the correlation between features.",
                "Thus we approximate these matrices with K dimensional diagonal matrices.",
                "In the rest of the paper, we use these symbols to represent their diagonal approximations: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     Secondly, and most importantly, the input space is very sparse and there are many dimensions that are not related to a particular user in a real IR application.",
                "For example, let us consider a movie recommendation system, with the input variable x representing a particular movie.",
                "For the jth movie that the user m has seen, let xm,j,k = 1 if the director of the movie is Jean-Pierre Jeunet (indexed by k).",
                "Here we assume that whether or not that this director directed a specific movie is represented by the kth dimension.",
                "If the user m has never seen a movie directed by Jean-Pierre Jeunet, then the corresponding dimension is always zero (xm,j,k = 0 for all j) .",
                "One major drawback of the EM algorithm is that the importance of a feature, µk, may be greatly dominated by users who have never encountered this feature (i.e. j xm,j,k = 0) at the M step (Equation 8).",
                "Assume that 100 out of 1 million users have viewed the movie directed by Jean-Pierre Jeunet, and that the viewers have rated all of his movies as excellent.",
                "Intuitively, he is a good director and the weight for him (µk) should be high.",
                "Before the EM iteration, the initial value of µ is usually set to 0.",
                "Since the other 999,900 users have not seen this movie, their corresponding weights (w1,k, w2,k, ..., wm,k..., w999900,k) for that director would be very small initially.",
                "Thus the corresponding weight of the director in the prior µk at the first M step would be very low , and the variance σm,k will be large (Equations 8 and 7).",
                "It is undesirable that users who have never seen any movie produced by the director influence the importance of the director so much.",
                "This makes the convergence of the standard EM algorithm very slow.",
                "Now lets look at whether we can improve the learning speed of the algorithm.",
                "Without a loss of generality, let us assume that the kth dimension of the input variable x is not related to a particular user m. By which we mean, xm,j,k = 0 for all j = 1, ..., Jm.",
                "It is straightforward to prove that the kth row and kth column of Sxx,m are completely filled with zeros, and that the kth dimension of Sxy,m is zeroed as well.",
                "Thus the corresponding kth dimension of the user models mean, ¯wm, should be equal to that of the prior: ¯wm,k = µk, with the corresponding covariance of σm,k = σk.",
                "At the M step, the standard EM algorithm uses the numerical solution of the distribution P(wm|Dm, Φ) estimated at E step (Equation 8 and Equation 7).",
                "However, the numerical solutions are very unreliable for ¯wm,k and σm,k when the kth dimension is not related to the mth user.",
                "A better approach is using the analytical solutions ¯wm,k = µk, and σm,k = σk for the unrelated (m, k) pairs, along with the numerical solution estimated at E step for the other (m, k) pairs.",
                "Thus we get the following new EM-like algorithm: Modified E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) where sxx,m,k = j x2 m,j,k and sxy,m,k = j xm,j,kym,j Modified M Step Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step for related userfeature pairs.",
                "The M step implicitly uses the analytical solution for unrelated user-feature pairs. µk = 1 Mk m:related ¯wm,k (12) σ2 k = 1 Mk m:related σ2 m,k +( ¯wm,k − µk)( ¯wm,k − µk)T (13) where Mk is the number of users that are related to feature k We only estimate the diagonal of Σ2 m and Σ since we are using the diagonal approximation of the covariance matrices.",
                "To estimate ¯wm, we only need to calculate the numerical solutions for dimensions that are related to user m. To estimate σ2 k and µk, we only sum over users that are related to the kth feature.",
                "There are two major benefits of the new algorithm.",
                "First, because only the related (m, k) pairs are needed at the modified M step, the computational complexity in a single EM iteration is much smaller when the data is sparse, and many of (m, k) pairs are unrelated.",
                "Second, the parameters estimated at the modified M step (Equations 12 - 13) are more accurate than the standard M step described in Section 4.1 because the exact analytical solutions ¯wm,k = µk and σm,k = σk for the unrelated (m, k) pairs were used in the new algorithm instead of an approximate solution as in the standard algorithm. 5.",
                "EXPERIMENTAL METHODOLOGY 5.1 Evaluation Data Set To evaluate the proposed technique, we used the following three major data sets (Table 1): MovieLens Data: This data set was created by combining the relevance judgments from the MovieLens[9] data set with documents from the Internet Movie Database (IMDB).",
                "MovieLens allows users to rank how much he/she enjoyed a specific movie on a scale from 1 to 5.",
                "This likeability rating was used as a measurement of how relevant the document representing the corresponding movie is to the user.",
                "We considered documents with likeability scores of 4 or 5 as relevant, and documents with a score of 1 to 3 as irrelevant to the user.",
                "MovieLens provided relevance judgments on 3,057 documents from 6,040 separate users.",
                "On average, each user rated 151 movies, of these 87 were judged to be relevant.",
                "The average score for a document was 3.58.",
                "Documents representing each movie were constructed from the portion of the IMDB database that is available for public download[13].",
                "Based on this database, we created one document per movie that contained the relevant information about it (e.g. directors, actors, etc.).",
                "Table 1: Data Set Statistics.",
                "On Reuters, the number of rating for a simulated user is the number of documents relevant to the corresponding topic.",
                "Data Users Docs Ratings per User MovieLens 6,040 3,057 151 Netflix-all 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Netflix Data: This data set was constructed by combining documents about movies crawled from the web with a set of actual movie rental customer relevance judgments from Netflix[19].",
                "Netflix publicly provides the relevance judgments of 480,189 anonymous customers.",
                "There are around 100 million rating on a scale of 1 to 5 for 17,770 documents.",
                "Similar to MovieLens, we considered documents with likeability scores of 4 or 5 as relevant.",
                "This number was reduced to 1000 customers through random sampling.",
                "The average customer on the reduced data set provided 127 judgments, with 70 being deemed relevant.",
                "The average score for documents is 3.55.",
                "Reuters Data: This is the Reuters Corpus, Volume 1.",
                "It covers 810,000 Reuters English language news stories from August 20, 1996 to August 19, 1997.",
                "Only the first 100,000 news were used in our experiments.",
                "The Reuters corpus comes with a topic hierarchy.",
                "Each document is assigned to one of several locations on the hierarchical tree.",
                "The first level of the tree contains four topics, denoted as C, E, M, and G. For the experiments in this paper, the tree was cut at level 1 to create four smaller trees, each of which corresponds to one smaller data set: Reuters-E Reuters-C, ReutersM and Reuters-G. For each small data set, we created several profiles, one profile for each node in a sub-tree, to simulate multiple users, each with a related, yet separate definition of relevance.",
                "All the user profiles on a sub-tree are supposed to share the same prior model distribution.",
                "Since this corpus explicitly indicates only the relevant documents for a topic(user), all other documents are considered irrelevant. 5.2 Evaluation We designed the experiments to answer the following three questions: 1.",
                "Do we need to take the effort to use a Bayesian approach and learn a prior from other users? 2.",
                "Does the new algorithm work better than the standard EM algorithm for learning the Bayesian hierarchical linear model? 3.",
                "Can the new algorithm quickly learn many user models?",
                "To answer the first question, we compared the Bayesian hierarchical models with commonly used Norm-2 regularized linear regression models.",
                "In fact, the commonly used approach is equivalent to the model learned at the end of the first EM iteration.",
                "To answer the second question, we compared the proposed new algorithm with the standard EM algorithm to see whether the new learning algorithm is better.",
                "To answer the third question, we tested the efficiency of the new algorithm on the entire Netflix data set where about half a million user models need to be learned together.",
                "For the MovieLens and Netflix data sets, algorithm effectiveness was measured by mean square error, while on the Reuters data set classification error was used because it was more informative.",
                "We first evaluated the performance on each individual user, and then estimated the macro average over all users.",
                "Statistical tests (t-tests) were carried out to see whether the results are significant.",
                "For the experiments on the MovieLens and Netflix data sets, we used a random sample of 90% of each user for training, and the rest for testing.",
                "On Reuters data set, because there are too many relevant documents for each topic in the corpus, we used a random sample of 10% of each topic for training, and 10% of the remaining documents for testing.",
                "For all runs, we set (a, b, c, Σ ) = (0.1, 10, 0.1, 1) manually. 6.",
                "EXPERIMENTAL RESULTS Figure 2, Figure 3, and Figure 4 show that on all data sets, the Bayesian hierarchical modeling approach has a statistical significant improvement over the regularized linear regression model, which is equivalent to the Bayesian hierarchical models learned at the first iteration.",
                "Further analysis shows a negative correlation between the number of training data for a user and the improvement the system gets.",
                "This suggests that the borrowing information from other users has more significant improvements for users with less training data, which is as expected.",
                "However, the strength of the correlation differs over data sets, and the amount of training data is not the only characteristics that will influence the final performance.",
                "Figure 2 and Figure 3 show that the proposed new algorithm works better than the standard EM algorithm on the Netflix and MovieLens data sets.",
                "This is not surprising since the number of related feature-users pairs is much smaller than the number of unrelated feature-user pairs on these two data sets, and thus the proposed new algorithm is expected to work better.",
                "Figure 4 shows that the two algorithms work similarly on the Reuters-E data set.",
                "The accuracy of the new algorithm is similar to that of the standard EM algorithm at each iteration.",
                "The general patterns are very similar on other Reuters subsets.",
                "Further analysis shows that only 58% of the user-feature pairs are unrelated on this data set.",
                "Since the number of unrelated user-feature pairs is not extremely large, the sparseness is not a serious problem on the Reuters data set.",
                "Thus the two learning algorithms perform similarly.",
                "The results suggest that only on a corpus where the number of unrelated user-feature pairs is much larger than the number of related pairs, such as on the Netflix data set, the proposed technique will get a significant improvement over standard EM.",
                "However, the experiments also show that when the assumption does not hold, the new algorithm does not hurt performance.",
                "Although the proposed technique is faster than standard Figure 2: Performance on a Netflix subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iterations 2 - 10.",
                "Norm-2 regularized linear models are equivalent to the Bayesian hierarchical models learned at the first iteration, and are statistical significantly worse than the Bayesian hierarchical models. 0 2 4 6 8 10 1 1.05 1.1 1.15 1.2 1.25 1.3 1.35 1.4 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iterations ClassificationError New Algorithm Traditional EM Figure 3: Performance on a MovieLens subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iteration 2 to 17 (evaluated with mean square error). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iterations MeanSquareError New Algorithm Traditional EM 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iterations ClassificationError New Algorithm Traditional EM Figure 4: Performance on a Reuters-E subset with 26 profiles.",
                "Performances on Reuters-C, Reuters-M, Reuters-G are similar. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iterations ClassificationError New Algorithm Traditional EM EM, can it really learn millions of user models quickly?",
                "Our results show that the modified EM algorithm converges quickly, and 2 - 3 modified EM iterations would result in a reliable estimation.",
                "We evaluated the algorithm on the whole Netflix data set (480,189 users, 159,836 features, and 100 million ratings) running on a single CPU PC (2GB memory, P4 3GHz).",
                "The system finished one modified EM iteration in about 4 hours.",
                "This demonstrates that the proposed technique can efficiently handle large-scale system like Netflix. 7.",
                "CONCLUSION Content-based user profile learning is an important problem and is the key to providing personal recommendations to a user, especially for recommending new items with a small number of ratings.",
                "The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors.",
                "This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM.",
                "We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm.",
                "Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse, by which we mean the ratio of related user-feature pairs to unrelated pairs is small.",
                "Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold.",
                "In general, it is better to use the new algorithm since it is as simple as standard EM, the performance is either better or similar to EM, and the computation complexity is lower at each iteration.",
                "It is worth mentioning that even if the original problem space is not sparse, sparseness can be created artificially when a recommendation system uses user-specific feature selection techniques to reduce the noise and user model complexity.",
                "The proposed technique can also be adapted to improve the learning in such a scenario.",
                "We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU.",
                "The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear modeling approach to build a practical large scale system, even though the literature have demonstrated the effectiveness of the models in many applications.",
                "Our work is one major step on the road to make Bayesian hierarchical linear models more practical.",
                "The proposed new technique can be easily adapted to run on a cluster of machines, and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users.",
                "The research has much potential to benefit people using EM algorithm on many other IR problems as well as machine learning problems.",
                "EM algorithm is a commonly used machine learning technique.",
                "It is used to find model parameters in many IR problems where the training data is very sparse.",
                "Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering, the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems. 8.",
                "ACKNOWLEDGMENTS We thank Wei Xu, David Lewis and anonymous reviewers for valuable feedback on the work described in this paper.",
                "Part of the work was supported by Yahoo, Google, the Petascale Data Storage Institute and the Institute for Scalable Scientific Data Management.",
                "Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors, and do not necessarily reflect those of the sponsors. 9.",
                "REFERENCES [1] C. Basu, H. Hirsh, and W. Cohen.",
                "Recommendation as classification: Using social and content-based information in recommendation.",
                "In Proceedings of the Fifteenth National Conference on Artificial Intelligence, 1998. [2] J. S. Breese, D. Heckerman, and C. Kadie.",
                "Empirical analysis of predictive algorithms for collaborative filtering.",
                "Technical report, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan.",
                "Document filtering with inference networks.",
                "In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor, and A. Vinokourov.",
                "Kernel method for document filtering.",
                "In The Eleventh Text REtrieval Conference (TREC11).",
                "National Institute of Standards and Technology, special publication 500-249, 2003. [5] C. Chelba and A. Acero.",
                "Adaptation of maximum entropy capitalizer: Little data can help a lot.",
                "In D. Lin and D. Wu, editors, Proceedings of EMNLP 2004, pages 285-292, Barcelona, Spain, July 2004.",
                "Association for Computational Linguistics. [6] B. Croft and J. Lafferty, editors.",
                "Language Modeling for Information Retrieval.",
                "Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov, and A. Genkin.",
                "Constructing informative prior distributions from domain knowledge in text classification.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 493-500, New York, NY, USA, 2006.",
                "ACM Press. [8] J. Delgado and N. Ishii.",
                "Memory-based weightedmajority prediction for recommender systems.",
                "In ACM SIGIR99 Workshop on Recommender Systems, 1999. [9] GroupLens.",
                "Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman.",
                "A tutorial on learning with bayesian networks.",
                "In M. Jordan, editor, Learning in Graphical Models.",
                "Kluwer Academic, 1998. [11] J. L. Herlocker, J.",
                "A. Konstan, A. Borchers, and J. Riedl.",
                "An algorithmic framework for performing collaborative filtering.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 230-237, New York, NY, USA, 1999.",
                "ACM Press. [12] T. Hofmann and J. Puzicha.",
                "Latent class models for collaborative filtering.",
                "In IJCAI 99: Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 688-693, San Francisco, CA, USA, 1999.",
                "Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).",
                "Internet movie database. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai, and L. Si.",
                "An automatic weighting scheme for collaborative filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 337-344, New York, NY, USA, 2004.",
                "ACM Press. [15] J.",
                "A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl.",
                "GroupLens: Applying collaborative filtering to Usenet news.",
                "Communications of the ACM, 40(3):77-87, 1997. [16] D. Lewis.",
                "Applying support vector machines to the TREC-2001 batch filtering and routing tasks.",
                "In Proceedings of the Eleventh Text REtrieval Conference (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee, , and P. Yu.",
                "Text classification by labeling words.",
                "In Proceedings of The Nineteenth National Conference on Artificial Intelligence (AAAI-2004), July 25-29, 2004. [18] P. Melville, R. J. Mooney, and R. Nagarajan.",
                "Content-boosted collaborative filtering for improved recommendations.",
                "In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002), Edmonton, Canada, 2002. [19] Netflix.",
                "Netflix prize. http://www.netflixprize.com (visited on Nov. 30, 2006), 2006. [20] S. Robertson and K. Sparck-Jones.",
                "Relevance weighting of search terms.",
                "In Journal of the American Society for Information Science, volume 27, pages 129-146, 1976. [21] J. Wang, A. P. de Vries, and M. J. T. Reinders.",
                "Unifying user-based and item-based collaborative filtering approaches by similarity fusion.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 501-508, New York, NY, USA, 2006.",
                "ACM Press. [22] X. Wu and R. K. Srihari.",
                "Incorporating prior knowledge with weighted margin support vector machines.",
                "In Proc.",
                "ACM Knowledge Discovery Data Mining Conf. (ACM SIGKDD 2004), Aug. 2004. [23] Y. Yang, S. Yoo, J. Zhang, and B. Kisiel.",
                "Robustness of adaptive filtering methods in a cross-benchmark evaluation.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2005. [24] K. Yu, V. Tresp, and A. Schwaighofer.",
                "Learning gaussian processes from multiple tasks.",
                "In ICML 05: Proceedings of the 22nd international conference on Machine learning, pages 1012-1019, New York, NY, USA, 2005.",
                "ACM Press. [25] K. Yu, V. Tresp, and S. Yu.",
                "A nonparametric hierarchical bayesian framework for information filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 353-360.",
                "ACM Press, 2004. [26] X. Zhu.",
                "Semi-supervised learning literature survey.",
                "Technical report, University of Wisconsin - Madison, December 9, 2006. [27] P. Zigoris and Y. Zhang.",
                "Bayesian adaptive user profiling with explicit & implicit feedback.",
                "In Conference on Information and Knowledge Mangement 2006, 2006."
            ],
            "original_annotated_samples": [
                "INTRODUCTION <br>personalization</br> is the future of the Web, and it has achieved great success in industrial applications.",
                "One major <br>personalization</br> topic studied in the information retrieval community is content-based personal recommendation systems1 .",
                "One major challenge of building a recommendation or <br>personalization</br> system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small."
            ],
            "translated_annotated_samples": [
                "La <br>personalización</br> es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales.",
                "Un tema importante de <br>personalización</br> estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados basados en el contenido.",
                "Uno de los principales desafíos de construir un sistema de recomendación o <br>personalización</br> es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña."
            ],
            "translated_text": "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual. Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un modelo jerárquico bayesiano. Aprender los parámetros del modelo para optimizar la verosimilitud conjunta de los datos de millones de usuarios es muy costoso computacionalmente. El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de datos en aplicaciones de IR. Este documento propone una nueva técnica de aprendizaje rápido para aprender un gran número de perfiles de usuario individuales. La eficacia y eficiencia del algoritmo propuesto están justificadas por la teoría y demostradas en datos reales de usuarios de Netflix y MovieLens. Categorías y Descriptores de Asignaturas: B.3.3 [Búsqueda y Recuperación de Información]: Filtrado de información Términos Generales: Algoritmos 1. La <br>personalización</br> es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales. Por ejemplo, las tiendas en línea, como Amazon y Netflix, ofrecen recomendaciones personalizadas de productos o servicios adicionales basadas en el historial de un usuario. Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de un usuario a partir de su historial. Un tema importante de <br>personalización</br> estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados basados en el contenido. Estos sistemas aprenden perfiles específicos de usuario a partir de la retroalimentación del usuario para poder recomendar información adaptada a los intereses de cada usuario sin necesidad de que el usuario realice una consulta explícita. Aprender los perfiles de usuario es el problema central de estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica qué tan relevante es un documento para el usuario. Uno de los principales desafíos de construir un sistema de recomendación o <br>personalización</br> es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña. Esto se conoce como el problema de inicio en frío. Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente retroalimentación de ese usuario para aprender un perfil de usuario confiable. Se ha realizado mucha investigación sobre cómo mejorar la precisión de clasificación cuando la cantidad de datos de entrenamiento etiquetados es pequeña. El enfoque de aprendizaje semisupervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26]. Otro enfoque es utilizar el conocimiento del dominio. Los investigadores han modificado diferentes algoritmos de aprendizaje, como NaïveBayes [17], regresión logística [7] y SVMs [22], para integrar el conocimiento del dominio en un clasificador de texto. El tercer enfoque consiste en tomar datos de entrenamiento de otros recursos [5][7]. La efectividad de estos enfoques diferentes es mixta, debido a qué tan bien se ajusta la suposición del modelo subyacente a los datos. Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano. Varios investigadores han demostrado que este enfoque intercambia eficazmente entre la información compartida y la específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario[27][25]. Para aprender un modelo jerárquico bayesiano, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados. Un sistema de recomendación maduro generalmente funciona para millones de usuarios. Es bien sabido que aprender los parámetros óptimos de un modelo jerárquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios. El algoritmo EM es una técnica comúnmente utilizada para el aprendizaje de parámetros debido a su simplicidad y garantía de convergencia. Sin embargo, un sistema de recomendación basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso. Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM tering, o filtrado colaborativo basado en elementos. En este documento, las palabras filtrado y recomendación se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de las variables de entrada. También encontramos que actualizar el parámetro del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones. Este documento modifica el algoritmo EM estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos algoritmo EM modificado. La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M utilizamos la solución analítica en lugar de la solución numérica estimada en el paso E para esos parámetros. Esto reduce considerablemente la computación en una sola iteración de EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales. La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de regresión lineal jerárquica bayesiana utilizado para recomendaciones basadas en contenido. La sección 4 describe cómo aprender los parámetros del modelo utilizando el algoritmo EM estándar, junto con el uso de la nueva técnica propuesta en este artículo. La configuración experimental y los resultados utilizados para validar la técnica de aprendizaje propuesta se informan en las Secciones 5 y 6. La sección 7 resume y ofrece observaciones finales. 2. TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de IR desde la década de 1970. Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus filtrado colaborativo. El filtrado basado en contenido estudia el escenario en el que un sistema de recomendación monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente. El usuario puede leer los documentos entregados y proporcionar retroalimentación explícita de relevancia, la cual el sistema de filtrado utiliza para actualizar el perfil del usuario mediante modelos de recuperación de retroalimentación de relevancia (por ejemplo,). Modelos booleanos, modelos de espacio vectorial, modelos probabilísticos tradicionales [20], redes de inferencia [3] y modelos de lenguaje [6]) o algoritmos de aprendizaje automático (por ejemplo, Máquinas de Vectores de Soporte (SVM), agrupamiento de K vecinos más cercanos (K-NN), redes neuronales, regresión logística o Winnow [16] [4] [23]. El filtrado colaborativo va más allá de simplemente usar el contenido de un documento para recomendar elementos a un usuario, aprovechando la información de otros usuarios con gustos y preferencias similares en el pasado. Se han utilizado heurísticas basadas en memoria y enfoques basados en modelos en la tarea de filtrado colaborativo [15] [8] [2] [14] [12] [11]. Este artículo contribuye a la investigación de recomendaciones basadas en contenido al mejorar la eficiencia y efectividad de los modelos lineales jerárquicos bayesianos, los cuales tienen una sólida base teórica y un buen rendimiento empírico en tareas de recomendación[27][25]. Este artículo no tiene la intención de comparar el filtrado basado en contenido con el filtrado colaborativo ni de afirmar cuál es mejor. Creemos que cada uno complementa al otro, y que el filtrado basado en contenido es extremadamente útil para manejar nuevos documentos/artículos con poco o ningún feedback del usuario. Similar a otros investigadores[18][1][21], encontramos que un sistema de recomendación será más efectivo cuando se combinan ambas técnicas. Sin embargo, esto está fuera del alcance de este documento y, por lo tanto, no se discute aquí. 3. REGRESIÓN LINEAL HIERÁRQUICA BAYESIANA Suponga que hay M usuarios en el sistema. La tarea del sistema es recomendar documentos que sean relevantes para cada usuario. Para cada usuario, el sistema aprende un modelo de usuario a partir del historial de los usuarios. En el resto de este documento, utilizaremos las siguientes notaciones para representar las variables en el sistema. m = 1, 2, ..., M: El índice para cada usuario individual. M es el número total de usuarios. wm: El parámetro del modelo de usuario asociado con el usuario m. wm es un vector de dimensión K. j = 1, 2, ..., Jm: El índice para un conjunto de datos para el usuario m. Jm es el número de datos de entrenamiento para el usuario m. Dm = {(xm,j, ym,j)}: Un conjunto de datos asociado con el usuario m. xm,j es un vector de dimensión K que representa el j-ésimo documento de entrenamiento del usuario m. ym,j es un escalar que representa la etiqueta del documento xm,j. k = 1, 2, ..., K: El índice dimensional de la variable de entrada x. El enfoque de modelado jerárquico bayesiano ha sido ampliamente utilizado en aplicaciones reales de recuperación de información. Los modelos lineales jerárquicos bayesianos generalizados, uno de los modelos jerárquicos bayesianos más simples, son comúnmente utilizados y han logrado un buen rendimiento en tareas de filtrado colaborativo [25] y filtrado adaptativo basado en contenido [27]. La Figura 1 muestra la representación gráfica de un modelo jerárquico bayesiano. En este gráfico, cada modelo de usuario está representado por un vector aleatorio wm. Suponemos que un modelo de usuario se muestrea aleatoriamente de una distribución previa P(w|Φ). El sistema puede predecir la etiqueta de usuario y de un documento x dado una estimación de wm (o distribución de wms) utilizando una función y = f(x, w). El modelo se llama modelo lineal jerárquico bayesiano generalizado cuando y = f(wT x) es cualquier modelo lineal generalizado como regresión logística, SVM y regresión lineal. Para estimar de manera confiable el modelo de usuario wm, el sistema puede obtener información de otros usuarios a través de la prior Φ = (µ, Σ). Ahora observamos un modelo comúnmente utilizado donde y = wT x + , donde ∼ N(0, σ2 ) es un ruido aleatorio [25][27]. Suponga que cada modelo de usuario wm es una muestra independiente de una distribución poblacional P(w|Φ), la cual está regida por un hiperparámetro desconocido Φ. Que la distribución previa del modelo de usuario w sea una distribución gaussiana con parámetro Φ = (µ, Σ), que es la distribución previa comúnmente utilizada para modelos lineales. µ = (µ1, µ2, ..., µK) es un vector de K dimensiones que representa la media de la distribución gaussiana, y Σ es la matriz de covarianza de la gaussiana. Normalmente, se utiliza una distribución Normal N(0, aI) y una distribución Inverse Wishart P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) como hiperprior para modelar la distribución previa de µ y Σ respectivamente. Yo es la matriz identidad de dimensión K, y a, b y c son números reales. Con esta configuración, tenemos el siguiente modelo para el sistema: 1. µ y Σ se muestrean de N(0, aI) e IWν (aI), respectivamente. 2. La primera dimensión de x es una variable ficticia que siempre es igual a 1. Figura 1: Ilustración de las dependencias de variables en el modelo jerárquico. La calificación, y, para un documento, x, está condicionada al documento y al modelo de usuario, wm, asociado con el usuario m. Los usuarios comparten información sobre sus modelos a través de la prior, Φ = (µ, Σ). Para cada usuario m, wm se muestrea aleatoriamente de una distribución Normal: wm ∼ N(µ, Σ2 ) 3. Para cada elemento xm,j, ym,j se muestrea aleatoriamente de una distribución Normal: ym,j ∼ N(wT mxm,j, σ2). Que θ = (Φ, w1, w2, ..., wM) represente los parámetros de este sistema que necesitan ser estimados. La verosimilitud conjunta de todas las variables en el modelo probabilístico, que incluye los datos y los parámetros, es: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) Para simplificar, asumimos que a, b, c y σ son proporcionados al sistema. 4. APRENDIZAJE DE PARÁMETROS DEL MODELO Si se conoce el prior Φ, encontrar el óptimo wm es sencillo: se trata de una regresión lineal simple. Por lo tanto, nos enfocaremos en estimar Φ. La solución a priori máxima de Φ se da por ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Encontrar la solución óptima para el problema anterior es desafiante, ya que necesitamos integrar sobre todos los w = (w1, w2, ..., wM), que son variables ocultas no observadas. 4.1 Algoritmo EM para Modelos Lineales Jerárquicos Bayesianos En la Ecuación 5, Φ es el parámetro que necesita ser estimado, y el resultado depende de las variables latentes no observadas w. Este tipo de problema de optimización suele resolverse mediante el algoritmo EM. Aplicando EM al problema anterior, el conjunto de modelos de usuario w son las variables ocultas no observables y tenemos: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw. Basándonos en la derivación de las fórmulas EM presentadas en [24], tenemos los siguientes pasos de Expectation-Maximization para encontrar los hiperparámetros óptimos. Por razones de espacio, omitimos la derivación en este artículo ya que no es el enfoque de nuestro trabajo. Paso E: Para cada usuario m, estime la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual del prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) donde Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j Paso M: Optimice el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Muchos sistemas de IR impulsados por aprendizaje automático utilizan una estimación puntual de los parámetros en diferentes etapas del sistema. Sin embargo, estamos estimando la distribución posterior de las variables en el paso E. Esto evita el sobreajuste de wm a los datos de un usuario en particular, que pueden ser pequeños y ruidosos. Una discusión detallada sobre este tema aparece en [10]. 4.2 Nuevo Algoritmo: EM Modificado. Aunque el algoritmo EM es ampliamente estudiado y utilizado en aplicaciones de aprendizaje automático, utilizar el proceso EM mencionado anteriormente para resolver modelos lineales jerárquicos bayesianos en sistemas de recuperación de información a gran escala sigue siendo demasiado costoso computacionalmente. En esta sección, describimos por qué la tasa de aprendizaje del algoritmo EM es lenta en nuestra aplicación e introducimos una nueva técnica para hacer que el aprendizaje del modelo lineal jerárquico bayesiano sea escalable. La derivación del nuevo algoritmo de aprendizaje estará basada en el algoritmo EM descrito en la sección anterior. Primero, las matrices de covarianza Σ2 , Σ2 m suelen ser demasiado grandes para ser computacionalmente factibles. Por simplicidad, y como práctica común en IR, no modelamos la correlación entre características. Así aproximamos estas matrices con matrices diagonales de dimensión K. En el resto del documento, utilizamos estos símbolos para representar sus aproximaciones diagonales: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     En segundo lugar, y lo más importante, el espacio de entrada es muy disperso y hay muchas dimensiones que no están relacionadas con un usuario particular en una aplicación de recuperación de información real. Por ejemplo, consideremos un sistema de recomendación de películas, con la variable de entrada x representando una película en particular. Para la j-ésima película que el usuario m ha visto, sea xm,j,k = 1 si el director de la película es Jean-Pierre Jeunet (indexado por k). Aquí asumimos que si este director dirigió una película específica está representado por la k-ésima dimensión. Si el usuario m nunca ha visto una película dirigida por Jean-Pierre Jeunet, entonces la dimensión correspondiente siempre es cero (xm,j,k = 0 para todos los j). Una desventaja importante del algoritmo EM es que la importancia de una característica, µk, puede estar fuertemente dominada por usuarios que nunca han encontrado esta característica (es decir, j xm,j,k = 0) en el paso M (Ecuación 8). Suponga que 100 de cada 1 millón de usuarios han visto la película dirigida por Jean-Pierre Jeunet, y que los espectadores han calificado todas sus películas como excelentes. Intuitivamente, él es un buen director y el peso para él (µk) debería ser alto. Antes de la iteración de EM, el valor inicial de µ suele establecerse en 0. Dado que los otros 999,900 usuarios no han visto esta película, sus pesos correspondientes (w1,k, w2,k, ..., wm,k..., w999900,k) para ese director serían muy pequeños inicialmente. Por lo tanto, el peso correspondiente del director en el µk anterior en el primer paso M sería muy bajo, y la varianza σm,k será grande (Ecuaciones 8 y 7). Es indeseable que los usuarios que nunca han visto ninguna película producida por el director influyan tanto en la importancia del director. Esto hace que la convergencia del algoritmo EM estándar sea muy lenta. Ahora veamos si podemos mejorar la velocidad de aprendizaje del algoritmo. Sin pérdida de generalidad, asumamos que la k-ésima dimensión de la variable de entrada x no está relacionada con un usuario particular m. Lo que queremos decir es que xm,j,k = 0 para todo j = 1, ..., Jm. Es sencillo demostrar que la k-ésima fila y la k-ésima columna de Sxx,m están completamente llenas de ceros, y que la k-ésima dimensión de Sxy,m también se anula. Por lo tanto, la dimensión k correspondiente de la media de los modelos de usuario, ¯wm, debería ser igual a la del anterior: ¯wm,k = µk, con la covarianza correspondiente de σm,k = σk. En el paso M, el algoritmo EM estándar utiliza la solución numérica de la distribución P(wm|Dm, Φ) estimada en el paso E (Ecuación 8 y Ecuación 7). Sin embargo, las soluciones numéricas son muy poco confiables para ¯wm,k y σm,k cuando la k-ésima dimensión no está relacionada con el m-ésimo usuario. Un enfoque mejor es utilizar las soluciones analíticas ¯wm,k = µk, y σm,k = σk para los pares no relacionados (m, k), junto con la solución numérica estimada en el paso E para los otros pares (m, k). Así obtenemos el siguiente nuevo algoritmo EM similar: Paso E modificado: Para cada usuario m, estimar la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual de σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) donde sxx,m,k = j x2 m,j,k y sxy,m,k = j xm,j,kym,j Paso M modificado Optimizar el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E para pares de usuario-característica relacionados. El paso M utiliza implícitamente la solución analítica para pares de usuario-característica no relacionados. µk = 1 Mk m:relacionado ¯wm,k (12) σ2 k = 1 Mk m:relacionado σ2 m,k + ( ¯wm,k − µk)( ¯wm,k − µk)T (13) donde Mk es el número de usuarios relacionados con la característica k. Solo estimamos la diagonal de Σ2 m y Σ, ya que estamos utilizando la aproximación diagonal de las matrices de covarianza. Para estimar ¯wm, solo necesitamos calcular las soluciones numéricas para las dimensiones que están relacionadas con el usuario m. Para estimar σ2 k y µk, solo sumamos sobre los usuarios que están relacionados con la k-ésima característica. Hay dos beneficios principales del nuevo algoritmo. Primero, dado que solo se necesitan los pares relacionados (m, k) en el paso M modificado, la complejidad computacional en una sola iteración de EM es mucho menor cuando los datos son dispersos y muchos de los pares (m, k) no están relacionados. En segundo lugar, los parámetros estimados en el paso M modificado (Ecuaciones 12 - 13) son más precisos que el paso M estándar descrito en la Sección 4.1 porque se utilizaron soluciones analíticas exactas ¯wm,k = µk y σm,k = σk para los pares no relacionados (m, k) en el nuevo algoritmo en lugar de una solución aproximada como en el algoritmo estándar. METODOLOGÍA EXPERIMENTAL 5.1 Conjunto de Datos de Evaluación Para evaluar la técnica propuesta, utilizamos los siguientes tres conjuntos de datos principales (Tabla 1): Datos de MovieLens: Este conjunto de datos fue creado combinando las valoraciones de relevancia del conjunto de datos de MovieLens[9] con documentos de la Base de Datos de Películas en Internet (IMDB). MovieLens permite a los usuarios clasificar cuánto disfrutaron una película específica en una escala del 1 al 5. Esta calificación de simpatía se utilizó como una medida de cuán relevante es el documento que representa la película correspondiente para el usuario. Consideramos los documentos con puntuaciones de 4 o 5 como relevantes, y los documentos con una puntuación de 1 a 3 como irrelevantes para el usuario. MovieLens proporcionó juicios de relevancia sobre 3,057 documentos de 6,040 usuarios diferentes. En promedio, cada usuario calificó 151 películas, de las cuales 87 fueron consideradas relevantes. La puntuación promedio para un documento fue de 3.58. Los documentos que representan cada película fueron construidos a partir de la porción de la base de datos de IMDB que está disponible para descarga pública[13]. Basándonos en esta base de datos, creamos un documento por película que contenía la información relevante sobre ella (por ejemplo, directores, actores, etc.). Tabla 1: Estadísticas del conjunto de datos. En Reuters, el número de calificaciones para un usuario simulado es el número de documentos relevantes para el tema correspondiente. Datos Usuarios Documentos Calificaciones por Usuario MovieLens 6,040 3,057 151 Netflix-todos 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Datos de Netflix: Este conjunto de datos fue construido combinando documentos sobre películas obtenidos de la web con un conjunto de juicios de relevancia de clientes reales de alquiler de películas de Netflix[19]. Netflix proporciona públicamente las evaluaciones de relevancia de 480,189 clientes anónimos. Hay alrededor de 100 millones de calificaciones en una escala del 1 al 5 para 17,770 documentos. Similar a MovieLens, consideramos documentos con puntuaciones de 4 o 5 de agradabilidad como relevantes. Este número se redujo a 1000 clientes mediante muestreo aleatorio. El cliente promedio en el conjunto de datos reducido proporcionó 127 juicios, de los cuales 70 fueron considerados relevantes. La puntuación promedio de los documentos es de 3.55. Datos de Reuters: Este es el Corpus de Reuters, Volumen 1. Cubre 810,000 noticias en inglés de Reuters desde el 20 de agosto de 1996 hasta el 19 de agosto de 1997. Solo se utilizaron las primeras 100,000 noticias en nuestros experimentos. El corpus de Reuters viene con una jerarquía de temas. Cada documento se asigna a una de varias ubicaciones en el árbol jerárquico. El primer nivel del árbol contiene cuatro temas, denotados como C, E, M y G. Para los experimentos en este artículo, el árbol fue cortado en el nivel 1 para crear cuatro árboles más pequeños, cada uno de los cuales corresponde a un conjunto de datos más pequeño: Reuters-E, Reuters-C, Reuters-M y Reuters-G. Para cada conjunto de datos pequeño, creamos varios perfiles, un perfil para cada nodo en un subárbol, para simular múltiples usuarios, cada uno con una definición de relevancia relacionada pero separada. Todos los perfiles de usuario en una sub-rama se supone que comparten la misma distribución de modelo previo. Dado que este corpus indica explícitamente solo los documentos relevantes para un tema (usuario), todos los demás documentos se consideran irrelevantes. 5.2 Evaluación Diseñamos los experimentos para responder a las siguientes tres preguntas: 1. ¿Necesitamos hacer el esfuerzo de utilizar un enfoque bayesiano y aprender una distribución a priori de otros usuarios? 2. ¿El nuevo algoritmo funciona mejor que el algoritmo EM estándar para aprender el modelo lineal jerárquico bayesiano? 3. ¿Puede el nuevo algoritmo aprender rápidamente muchos modelos de usuario? Para responder a la primera pregunta, comparamos los modelos jerárquicos bayesianos con los modelos de regresión lineal regularizados Norm-2 comúnmente utilizados. De hecho, el enfoque comúnmente utilizado es equivalente al modelo aprendido al final de la primera iteración de EM. Para responder a la segunda pregunta, comparamos el nuevo algoritmo propuesto con el algoritmo EM estándar para ver si el nuevo algoritmo de aprendizaje es mejor. Para responder a la tercera pregunta, probamos la eficiencia del nuevo algoritmo en todo el conjunto de datos de Netflix, donde aproximadamente medio millón de modelos de usuario deben ser aprendidos juntos. Para los conjuntos de datos de MovieLens y Netflix, la efectividad del algoritmo se midió mediante el error cuadrático medio, mientras que en el conjunto de datos de Reuters se utilizó el error de clasificación porque era más informativo. Primero evaluamos el rendimiento en cada usuario individual, y luego estimamos el promedio macro sobre todos los usuarios. Se realizaron pruebas estadísticas (pruebas t) para determinar si los resultados son significativos. Para los experimentos en los conjuntos de datos de MovieLens y Netflix, utilizamos una muestra aleatoria del 90% de cada usuario para entrenamiento, y el resto para pruebas. En el conjunto de datos de Reuters, debido a que hay demasiados documentos relevantes para cada tema en el corpus, utilizamos una muestra aleatoria del 10% de cada tema para el entrenamiento, y el 10% de los documentos restantes para las pruebas. Para todas las ejecuciones, establecimos (a, b, c, Σ) = (0.1, 10, 0.1, 1) manualmente. 6. RESULTADOS EXPERIMENTALES Las Figuras 2, 3 y 4 muestran que en todos los conjuntos de datos, el enfoque de modelado jerárquico bayesiano tiene una mejora estadísticamente significativa sobre el modelo de regresión lineal regularizado, que es equivalente a los modelos jerárquicos bayesianos aprendidos en la primera iteración. Un análisis adicional muestra una correlación negativa entre la cantidad de datos de entrenamiento para un usuario y la mejora que obtiene el sistema. Esto sugiere que la información prestada de otros usuarios tiene mejoras más significativas para usuarios con menos datos de entrenamiento, lo cual es lo esperado. Sin embargo, la fuerza de la correlación varía entre los conjuntos de datos, y la cantidad de datos de entrenamiento no es la única característica que influirá en el rendimiento final. Las Figuras 2 y 3 muestran que el nuevo algoritmo propuesto funciona mejor que el algoritmo EM estándar en los conjuntos de datos de Netflix y MovieLens. Esto no es sorprendente ya que el número de pares de características-usuarios relacionados es mucho menor que el número de pares de características-usuarios no relacionados en estos dos conjuntos de datos, por lo que se espera que el nuevo algoritmo propuesto funcione mejor. La Figura 4 muestra que los dos algoritmos funcionan de manera similar en el conjunto de datos de Reuters-E. La precisión del nuevo algoritmo es similar a la del algoritmo EM estándar en cada iteración. Los patrones generales son muy similares en otros subconjuntos de Reuters. Un análisis adicional muestra que solo el 58% de los pares usuario-característica no están relacionados en este conjunto de datos. Dado que el número de pares usuario-característica no relacionados no es extremadamente grande, la dispersión no es un problema grave en el conjunto de datos de Reuters. Por lo tanto, los dos algoritmos de aprendizaje se desempeñan de manera similar. Los resultados sugieren que solo en un corpus donde el número de pares usuario-característica no relacionados es mucho mayor que el número de pares relacionados, como en el conjunto de datos de Netflix, la técnica propuesta obtendrá una mejora significativa sobre el EM estándar. Sin embargo, los experimentos también muestran que cuando la suposición no se cumple, el nuevo algoritmo no afecta el rendimiento. Aunque la técnica propuesta es más rápida que la estándar. Figura 2: Rendimiento en un subconjunto de Netflix con 1,000 usuarios. El nuevo algoritmo es estadísticamente significativamente mejor que el algoritmo EM en las iteraciones 2 a 10. Los modelos lineales regularizados con norma-2 son equivalentes a los modelos jerárquicos bayesianos aprendidos en la primera iteración, y son estadísticamente significativamente peores que los modelos jerárquicos bayesianos. Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional Figura 3: Rendimiento en un subconjunto de MovieLens con 1,000 usuarios. El nuevo algoritmo es significativamente mejor estadísticamente que el algoritmo EM en las iteraciones 2 a 17 (evaluado con error cuadrático medio). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iteraciones ErrorCuadráticoMedio Nuevo Algoritmo EM Tradicional 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iteraciones Error de Clasificación Nuevo Algoritmo EM Tradicional Figura 4: Rendimiento en un subconjunto de Reuters-E con 26 perfiles. Las actuaciones en Reuters-C, Reuters-M, Reuters-G son similares. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional EM, ¿realmente puede aprender rápidamente millones de modelos de usuario? Nuestros resultados muestran que el algoritmo EM modificado converge rápidamente, y 2-3 iteraciones del EM modificado darían como resultado una estimación confiable. Evaluamos el algoritmo en todo el conjunto de datos de Netflix (480,189 usuarios, 159,836 características y 100 millones de valoraciones) ejecutándolo en un solo PC con CPU (2GB de memoria, P4 3GHz). El sistema completó una iteración EM modificada en aproximadamente 4 horas. Esto demuestra que la técnica propuesta puede manejar eficientemente sistemas a gran escala como Netflix. CONCLUSIÓN El aprendizaje de perfiles de usuario basado en contenido es un problema importante y es clave para proporcionar recomendaciones personales a un usuario, especialmente para recomendar nuevos elementos con un pequeño número de calificaciones. El enfoque de modelado jerárquico bayesiano se está convirtiendo en un enfoque importante para el aprendizaje de perfiles de usuario debido a su capacidad teóricamente justificada para ayudar a un usuario a través de la transferencia de información de otros usuarios mediante hiperpriors. Este artículo examinó la debilidad del enfoque de aprendizaje basado en EM popular para modelos lineales jerárquicos bayesianos y propuso una técnica de aprendizaje mejorada llamada EM Modificado. Demostramos que la nueva técnica es teóricamente más eficiente computacionalmente que el algoritmo EM estándar. La evaluación en los conjuntos de datos de MovieLens y Netflix demostró la efectividad de la nueva técnica cuando los datos son dispersos, lo que significa que la proporción de pares de usuario-característica relacionados con respecto a los pares no relacionados es pequeña. La evaluación en el conjunto de datos de Reuters mostró que la nueva técnica tuvo un rendimiento similar al algoritmo EM estándar cuando la condición de dispersión no se cumple. En general, es mejor utilizar el nuevo algoritmo ya que es tan simple como el EM estándar, el rendimiento es igual o mejor que el del EM, y la complejidad computacional es menor en cada iteración. Vale la pena mencionar que aunque el espacio de problemas original no sea disperso, la dispersión puede crearse artificialmente cuando un sistema de recomendación utiliza técnicas de selección de características específicas del usuario para reducir el ruido y la complejidad del modelo del usuario. La técnica propuesta también puede adaptarse para mejorar el aprendizaje en dicho escenario. También demostramos que la técnica propuesta puede aprender medio millón de perfiles de usuario a partir de 100 millones de valoraciones en unas pocas horas con una sola CPU. La investigación es importante porque la escalabilidad es una preocupación importante para los investigadores al utilizar el enfoque de modelado lineal jerárquico bayesiano para construir un sistema a gran escala práctico, a pesar de que la literatura ha demostrado la efectividad de los modelos en muchas aplicaciones. Nuestro trabajo es un paso importante en el camino para hacer que los modelos lineales jerárquicos bayesianos sean más prácticos. La nueva técnica propuesta se puede adaptar fácilmente para ejecutarse en un clúster de máquinas, y así acelerar aún más el proceso de aprendizaje para manejar un sistema a mayor escala con cientos de millones de usuarios. La investigación tiene mucho potencial para beneficiar a las personas utilizando el algoritmo EM en muchos otros problemas de IR, así como en problemas de aprendizaje automático. El algoritmo EM es una técnica de aprendizaje automático comúnmente utilizada. Se utiliza para encontrar los parámetros del modelo en muchos problemas de IR donde los datos de entrenamiento son muy dispersos. Aunque nos estamos centrando en los modelos lineales jerárquicos bayesianos para recomendación y filtrado, la nueva idea de utilizar una solución analítica en lugar de una solución numérica para pares de usuario-característica no relacionados en el paso M podría adaptarse a muchos otros problemas. 8. AGRADECIMIENTOS Agradecemos a Wei Xu, David Lewis y a los revisores anónimos por sus valiosos comentarios sobre el trabajo descrito en este artículo. Parte del trabajo fue apoyado por Yahoo, Google, el Instituto de Almacenamiento de Datos a Escala Peta y el Instituto de Gestión de Datos Científicos Escalables. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las de los patrocinadores. REFERENCIAS [1] C. Basu, H. Hirsh y W. Cohen. Recomendación como clasificación: Utilizando información social y basada en contenido en la recomendación. En Actas de la Decimoquinta Conferencia Nacional de Inteligencia Artificial, 1998. [2] J. S. Breese, D. Heckerman y C. Kadie. Análisis empírico de algoritmos predictivos para filtrado colaborativo. Informe técnico, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan. Filtrado de documentos con redes de inferencia. En Actas de la Decimonovena Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor y A. Vinokourov. Método del núcleo para el filtrado de documentos. En la Undécima Conferencia de Recuperación de Información de Texto (TREC11). Instituto Nacional de Normas y Tecnología, publicación especial 500-249, 2003. [5] C. Chelba y A. Acero. Adaptación del capitalizador de entropía máxima: Poca información puede ayudar mucho. En D. Lin y D. Wu, editores, Actas de EMNLP 2004, páginas 285-292, Barcelona, España, julio de 2004. Asociación de Lingüística Computacional. [6] B. Croft y J. Lafferty, editores. Modelado de lenguaje para recuperación de información. Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov y A. Genkin. Construyendo distribuciones a priori informativas a partir del conocimiento del dominio en la clasificación de textos. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 493-500, Nueva York, NY, EE. UU., 2006. ACM Press. [8] J. Delgado y N. Ishii. Predicción basada en memoria ponderada para sistemas de recomendación. En el Taller ACM SIGIR99 sobre Sistemas de Recomendación, 1999. [9] GroupLens. Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman. Un tutorial sobre el aprendizaje con redes bayesianas. En M. Jordan, editor, Aprendizaje en Modelos Gráficos. Kluwer Academic, 1998. [11] J. L. Herlocker, J. \n\nKluwer Academic, 1998. [11] J. L. Herlocker, J. A. Konstan, A. Borchers y J. Riedl. Un marco algorítmico para realizar filtrado colaborativo. En SIGIR 99: Actas de la 22ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 230-237, Nueva York, NY, EE. UU., 1999. ACM Press. [12] T. Hofmann y J. Puzicha. Modelos de clases latentes para filtrado colaborativo. En IJCAI 99: Actas de la Decimosexta Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 688-693, San Francisco, CA, EE. UU., 1999. Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).\nMorgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB). Base de datos de películas en internet. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai y L. Si. Un esquema de ponderación automática para filtrado colaborativo. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 337-344, Nueva York, NY, EE. UU., 2004. ACM Press. [15] J. A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon y J. Riedl. GroupLens: Aplicando filtrado colaborativo a las noticias de Usenet. Comunicaciones de la ACM, 40(3):77-87, 1997. [16] D. Lewis. Aplicando máquinas de vectores de soporte a las tareas de filtrado y enrutamiento por lotes de TREC-2001. En Actas de la Undécima Conferencia de Recuperación de Texto (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee y P. Yu. Clasificación de texto mediante etiquetado de palabras. En Actas de la Decimonovena Conferencia Nacional de Inteligencia Artificial (AAAI-2004), 25-29 de julio de 2004. [18] P. Melville, R. J. Mooney y R. Nagarajan. Filtrado colaborativo potenciado por contenido para recomendaciones mejoradas. En Actas de la Decimoctava Conferencia Nacional de Inteligencia Artificial (AAAI-2002), Edmonton, Canadá, 2002. [19] Netflix. Premio Netflix. http://www.netflixprize.com (visitado el 30 de noviembre de 2006), 2006. [20] S. Robertson y K. Sparck-Jones. Ponderación de la relevancia de los términos de búsqueda. En Journal of the American Society for Information Science, volumen 27, páginas 129-146, 1976. [21] J. Wang, A. P. de Vries y M. J. T. Reinders. Unificando enfoques de filtrado colaborativo basados en usuarios y en elementos mediante la fusión de similitudes. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 501-508, Nueva York, NY, EE. UU., 2006. ACM Press. [22] X. Wu y R. K. Srihari. Incorporando conocimientos previos con máquinas de vectores de soporte de margen ponderado. En Proc. Conferencia de Minería de Datos y Descubrimiento de Conocimiento de ACM (ACM SIGKDD 2004), agosto de 2004. [23] Y. Yang, S. Yoo, J. Zhang y B. Kisiel. Robustez de los métodos de filtrado adaptativo en una evaluación de referencia cruzada. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 2005. [24] K. Yu, V. Tresp y A. Schwaighofer. Aprendiendo procesos gaussianos de múltiples tareas. En ICML 05: Actas de la 22ª conferencia internacional sobre aprendizaje automático, páginas 1012-1019, Nueva York, NY, EE. UU., 2005. ACM Press. [25] K. Yu, V. Tresp, y S. Yu. Un marco bayesiano jerárquico no paramétrico para el filtrado de información. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 353-360. ACM Press, 2004. [26] X. Zhu. \n\nACM Press, 2004. [26] X. Zhu. Revisión de la literatura sobre aprendizaje semisupervisado. Informe técnico, Universidad de Wisconsin - Madison, 9 de diciembre de 2006. [27] P. Zigoris y Y. Zhang. Perfilado de usuario bayesiano adaptativo con retroalimentación explícita e implícita. En la Conferencia sobre Gestión de la Información y el Conocimiento 2006, 2006. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "bayesian hierarchical model": {
            "translated_key": "modelo jerárquico bayesiano",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, USA {yiz, jonathan}@soe.ucsc.edu ABSTRACT A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual users interest.",
                "A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a <br>bayesian hierarchical model</br>.",
                "Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive.",
                "The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications.",
                "This paper proposes a new fast learning technique to learn a large number of individual user profiles.",
                "The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens.",
                "Categories and Subject Descriptors: B.3.3 [Information Search and Retrieval]: Information filtering General Terms: Algorithms 1.",
                "INTRODUCTION Personalization is the future of the Web, and it has achieved great success in industrial applications.",
                "For example, online stores, such as Amazon and Netflix, provide customized recommendations for additional products or services based on a users history.",
                "Recent offerings such as My MSN, My Yahoo!, My Google, and Google News have attracted much attention due to their potential ability to infer a users interests from his/her history.",
                "One major personalization topic studied in the information retrieval community is content-based personal recommendation systems1 .",
                "These systems learn user-specific profiles from user feedback so that they can recommend information tailored to each individual users interest without requiring the user to make an explicit query.",
                "Learning the user profiles is the core problem for these systems.",
                "A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user.",
                "One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small.",
                "This is known as the cold start problem.",
                "This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile.",
                "There has been much research on improving classification accuracy when the amount of labeled training data is small.",
                "The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal [26].",
                "Another approach is using domain knowledge.",
                "Researchers have modified different learning algorithms, such as Na¨ıveBayes [17], logistic regression [7], and SVMs [22], to integrate domain knowledge into a text classifier.",
                "The third approach is borrowing training data from other resources [5][7].",
                "The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data.",
                "One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach.",
                "Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial performance for each user[27][25].",
                "In order to learn a <br>bayesian hierarchical model</br>, the system usually tries to find the most likely model parameters for the given data.",
                "A mature recommendation system usually works for millions of users.",
                "It is well known that learning the optimal parameters of a <br>bayesian hierarchical model</br> is computationally expensive when there are thousands or millions of users.",
                "The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee.",
                "However, a content based recommendation system often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector.",
                "With careful analysis of the EM algorithm in this scenario (Section 4), we find that the EM tering, or item-based collaborative filtering.",
                "In this paper, the words filtering and recommendation are used interchangeably. algorithm converges very slowly due to the sparseness of the input variables.",
                "We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O(MK), where M is the number of users and K is the number of dimensions.",
                "This paper modifies the standard EM algorithm to create an improved learning algorithm, which we call the Modified EM algorithm.",
                "The basic idea is that instead of calculating the numerical solution for all the user profile parameters, we derive the analytical solution of the parameters for some feature dimensions, and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters.",
                "This greatly reduces the computation at a single EM iteration, and also has the benefit of increasing the convergence speed of the learning algorithm.",
                "The proposed technique is not only well supported by theory, but also by experimental results.",
                "The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression modeling framework used for content-based recommendations.",
                "Section 4 describes how to learn the model parameters using the standard EM algorithm, along with using the new technique proposed in this paper.",
                "The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6.",
                "Section 7 summarizes and offers concluding remarks. 2.",
                "RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the IR community since the 1970s.",
                "The approaches that have been used to solve this problem can be roughly classified into two major categories: content based filtering versus collaborative filtering.",
                "Content-based filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user.",
                "The user may read the delivered documents and provide explicit relevance feedback, which the filtering system then uses to update the users profile using relevance feedback retrieval models (e.g.",
                "Boolean models, vector space models, traditional probabilistic models [20] , inference networks [3] and language models [6]) or machine learning algorithms (e.g.",
                "Support Vector Machines (SVM), K nearest neighbors (K-NN) clustering, neural networks, logistic regression, or Winnow [16] [4] [23]).",
                "Collaborative filtering goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past.",
                "Memorybased heuristics and model based approaches have been used in collaborative filtering task [15] [8] [2] [14] [12] [11].",
                "This paper contributes to the content-based recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks[27][25].",
                "This paper does not intend to compare content-based filtering with collaborative filtering or claim which one is a better.",
                "We think each complements the other, and that content-based filtering is extremely useful for handling new documents/items with little or no user feedback.",
                "Similar to some other researchers[18][1][21], we found that a recommendation system will be more effective when both techniques are combined.",
                "However, this is beyond the scope of this paper and thus not discussed here. 3.",
                "BAYESIAN HIERARCHICAL LINEAR REGRESSION Assume there are M users in the system.",
                "The task of the system is to recommend documents that are relevant to each user.",
                "For each user, the system learns a user model from the users history.",
                "In the rest of this paper, we will use the following notations to represent the variables in the system. m = 1, 2, ..., M: The index for each individual user.",
                "M is the total number of users. wm: The user model parameter associated with user m. wm is a K dimensional vector. j = 1, 2, ..., Jm: The index for a set of data for user m. Jm is the number of training data for user m. Dm = {(xm,j, ym,j)}: A set of data associated with user m. xm,j is a K dimensional vector that represents the mth users jth training document.2 ym,j is a scalar that represents the label of document xm,j. k = 1, 2, ..., K: The dimensional index of input variable x.",
                "The Bayesian hierarchical modeling approach has been widely used in real-world information retrieval applications.",
                "Generalized Bayesian hierarchical linear models, one of the simplest Bayesian hierarchical models, are commonly used and have achieved good performance on collaborative filtering [25] and content-based adaptive filtering [27] tasks.",
                "Figure 1 shows the graphical representation of a <br>bayesian hierarchical model</br>.",
                "In this graph, each user model is represented by a random vector wm.",
                "We assume a user model is sampled randomly from a prior distribution P(w|Φ).",
                "The system can predict the user label y of a document x given an estimation of wm (or wms distribution) using a function y = f(x, w).",
                "The model is called generalized Bayesian hierarchical linear model when y = f(wT x) is any generalized linear model such as logistic regression, SVM, and linear regression.",
                "To reliably estimate the user model wm, the system can borrow information from other users through the prior Φ = (µ, Σ).",
                "Now we look at one commonly used model where y = wT x + , where ∼ N(0, σ2 ) is a random noise [25][27].",
                "Assume that each user model wm is an independent draw from a population distribution P(w|Φ), which is governed by some unknown hyperparameter Φ.",
                "Let the prior distribution of user model w be a Gaussian distribution with parameter Φ = (µ, Σ), which is the commonly used prior for linear models. µ = (µ1, µ2, ..., µK ) is a K dimensional vector that represents the mean of the Gaussian distribution, and Σ is the covariance matrix of the Gaussian.",
                "Usually, a Normal distribution N(0, aI) and an Inverse Wishart distribution P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) are used as hyperprior to model the prior distribution of µ and Σ respectively.",
                "I is the K dimensional identity matrix, and a, b, and c are real numbers.",
                "With these settings, we have the following model for the system: 1. µ and Σ are sampled from N(0, aI) and IWν (aI), respectively. 2 The first dimension of x is a dummy variable that always equals to 1.",
                "Figure 1: Illustration of dependencies of variables in the hierarchical model.",
                "The rating, y, for a document, x, is conditioned on the document and the user model, wm, associated with the user m. Users share information about their models through the prior, Φ = (µ, Σ). 2.",
                "For each user m, wm is sampled randomly from a Normal distribution: wm ∼ N(µ, Σ2 ) 3.",
                "For each item xm,j, ym,j is sampled randomly from a Normal distribution: ym,j ∼ N(wT mxm,j, σ2 ).",
                "Let θ = (Φ, w1, w2, ..., wM ) represent the parameters of this system that needs to be estimated.",
                "The joint likelihood for all the variables in the probabilistic model, which includes the data and the parameters, is: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) For simplicity, we assume a, b, c, and σ are provided to the system. 4.",
                "MODEL PARAMETER LEARNING If the prior Φ is known, finding the optimal wm is straightforward: it is a simple linear regression.",
                "Therefore, we will focus on estimating Φ.",
                "The maximum a priori solution of Φ is given by ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Finding the optimal solution for the above problem is challenging, since we need to integrate over all w = (w1, w2, ..., wM ), which are unobserved hidden variables. 4.1 EM Algorithm for Bayesian Hierarchical Linear Models In Equation 5, Φ is the parameter needs to be estimated, and the result depends on unobserved latent variables w. This kind of optimization problem is usually solved by the EM algorithm.",
                "Applying EM to the above problem, the set of user models w are the unobservable hidden variables and we have: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw Based on the derivation of the EM formulas presented in [24], we have the following Expectation-Maximization steps for finding the optimal hyperparameters.",
                "For space considerations, we omit the derivation in this paper since it is not the focus of our work.",
                "E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of the prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) where Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j M step: Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Many machine learning driven IR systems use a point estimate of the parameters at different stages in the system.",
                "However, we are estimating the posterior distribution of the variables at the E step.",
                "This avoids overfitting wm to a particular users data, which may be small and noisy.",
                "A detailed discussion about this subject appears in [10]. 4.2 New Algorithm: Modified EM Although the EM algorithm is widely studied and used in machine learning applications, using the above EM process to solve Bayesian hierarchical linear models in large-scale information retrieval systems is still too computationally expensive.",
                "In this section, we describe why the learning rate of the EM algorithm is slow in our application and introduce a new technique to make the learning of the Bayesian hierarchical linear model scalable.",
                "The derivation of the new learning algorithm will be based on the EM algorithm described in the previous section.",
                "First, the covariance matrices Σ2 , Σ2 m are usually too large to be computationally feasible.",
                "For simplicity, and as a common practice in IR, we do not model the correlation between features.",
                "Thus we approximate these matrices with K dimensional diagonal matrices.",
                "In the rest of the paper, we use these symbols to represent their diagonal approximations: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     Secondly, and most importantly, the input space is very sparse and there are many dimensions that are not related to a particular user in a real IR application.",
                "For example, let us consider a movie recommendation system, with the input variable x representing a particular movie.",
                "For the jth movie that the user m has seen, let xm,j,k = 1 if the director of the movie is Jean-Pierre Jeunet (indexed by k).",
                "Here we assume that whether or not that this director directed a specific movie is represented by the kth dimension.",
                "If the user m has never seen a movie directed by Jean-Pierre Jeunet, then the corresponding dimension is always zero (xm,j,k = 0 for all j) .",
                "One major drawback of the EM algorithm is that the importance of a feature, µk, may be greatly dominated by users who have never encountered this feature (i.e. j xm,j,k = 0) at the M step (Equation 8).",
                "Assume that 100 out of 1 million users have viewed the movie directed by Jean-Pierre Jeunet, and that the viewers have rated all of his movies as excellent.",
                "Intuitively, he is a good director and the weight for him (µk) should be high.",
                "Before the EM iteration, the initial value of µ is usually set to 0.",
                "Since the other 999,900 users have not seen this movie, their corresponding weights (w1,k, w2,k, ..., wm,k..., w999900,k) for that director would be very small initially.",
                "Thus the corresponding weight of the director in the prior µk at the first M step would be very low , and the variance σm,k will be large (Equations 8 and 7).",
                "It is undesirable that users who have never seen any movie produced by the director influence the importance of the director so much.",
                "This makes the convergence of the standard EM algorithm very slow.",
                "Now lets look at whether we can improve the learning speed of the algorithm.",
                "Without a loss of generality, let us assume that the kth dimension of the input variable x is not related to a particular user m. By which we mean, xm,j,k = 0 for all j = 1, ..., Jm.",
                "It is straightforward to prove that the kth row and kth column of Sxx,m are completely filled with zeros, and that the kth dimension of Sxy,m is zeroed as well.",
                "Thus the corresponding kth dimension of the user models mean, ¯wm, should be equal to that of the prior: ¯wm,k = µk, with the corresponding covariance of σm,k = σk.",
                "At the M step, the standard EM algorithm uses the numerical solution of the distribution P(wm|Dm, Φ) estimated at E step (Equation 8 and Equation 7).",
                "However, the numerical solutions are very unreliable for ¯wm,k and σm,k when the kth dimension is not related to the mth user.",
                "A better approach is using the analytical solutions ¯wm,k = µk, and σm,k = σk for the unrelated (m, k) pairs, along with the numerical solution estimated at E step for the other (m, k) pairs.",
                "Thus we get the following new EM-like algorithm: Modified E step: For each user m, estimate the user model distribution P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) based on the current estimation of σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) where sxx,m,k = j x2 m,j,k and sxy,m,k = j xm,j,kym,j Modified M Step Optimize the prior Φ = (µ, Σ2 ) based on the estimation from the last E step for related userfeature pairs.",
                "The M step implicitly uses the analytical solution for unrelated user-feature pairs. µk = 1 Mk m:related ¯wm,k (12) σ2 k = 1 Mk m:related σ2 m,k +( ¯wm,k − µk)( ¯wm,k − µk)T (13) where Mk is the number of users that are related to feature k We only estimate the diagonal of Σ2 m and Σ since we are using the diagonal approximation of the covariance matrices.",
                "To estimate ¯wm, we only need to calculate the numerical solutions for dimensions that are related to user m. To estimate σ2 k and µk, we only sum over users that are related to the kth feature.",
                "There are two major benefits of the new algorithm.",
                "First, because only the related (m, k) pairs are needed at the modified M step, the computational complexity in a single EM iteration is much smaller when the data is sparse, and many of (m, k) pairs are unrelated.",
                "Second, the parameters estimated at the modified M step (Equations 12 - 13) are more accurate than the standard M step described in Section 4.1 because the exact analytical solutions ¯wm,k = µk and σm,k = σk for the unrelated (m, k) pairs were used in the new algorithm instead of an approximate solution as in the standard algorithm. 5.",
                "EXPERIMENTAL METHODOLOGY 5.1 Evaluation Data Set To evaluate the proposed technique, we used the following three major data sets (Table 1): MovieLens Data: This data set was created by combining the relevance judgments from the MovieLens[9] data set with documents from the Internet Movie Database (IMDB).",
                "MovieLens allows users to rank how much he/she enjoyed a specific movie on a scale from 1 to 5.",
                "This likeability rating was used as a measurement of how relevant the document representing the corresponding movie is to the user.",
                "We considered documents with likeability scores of 4 or 5 as relevant, and documents with a score of 1 to 3 as irrelevant to the user.",
                "MovieLens provided relevance judgments on 3,057 documents from 6,040 separate users.",
                "On average, each user rated 151 movies, of these 87 were judged to be relevant.",
                "The average score for a document was 3.58.",
                "Documents representing each movie were constructed from the portion of the IMDB database that is available for public download[13].",
                "Based on this database, we created one document per movie that contained the relevant information about it (e.g. directors, actors, etc.).",
                "Table 1: Data Set Statistics.",
                "On Reuters, the number of rating for a simulated user is the number of documents relevant to the corresponding topic.",
                "Data Users Docs Ratings per User MovieLens 6,040 3,057 151 Netflix-all 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Netflix Data: This data set was constructed by combining documents about movies crawled from the web with a set of actual movie rental customer relevance judgments from Netflix[19].",
                "Netflix publicly provides the relevance judgments of 480,189 anonymous customers.",
                "There are around 100 million rating on a scale of 1 to 5 for 17,770 documents.",
                "Similar to MovieLens, we considered documents with likeability scores of 4 or 5 as relevant.",
                "This number was reduced to 1000 customers through random sampling.",
                "The average customer on the reduced data set provided 127 judgments, with 70 being deemed relevant.",
                "The average score for documents is 3.55.",
                "Reuters Data: This is the Reuters Corpus, Volume 1.",
                "It covers 810,000 Reuters English language news stories from August 20, 1996 to August 19, 1997.",
                "Only the first 100,000 news were used in our experiments.",
                "The Reuters corpus comes with a topic hierarchy.",
                "Each document is assigned to one of several locations on the hierarchical tree.",
                "The first level of the tree contains four topics, denoted as C, E, M, and G. For the experiments in this paper, the tree was cut at level 1 to create four smaller trees, each of which corresponds to one smaller data set: Reuters-E Reuters-C, ReutersM and Reuters-G. For each small data set, we created several profiles, one profile for each node in a sub-tree, to simulate multiple users, each with a related, yet separate definition of relevance.",
                "All the user profiles on a sub-tree are supposed to share the same prior model distribution.",
                "Since this corpus explicitly indicates only the relevant documents for a topic(user), all other documents are considered irrelevant. 5.2 Evaluation We designed the experiments to answer the following three questions: 1.",
                "Do we need to take the effort to use a Bayesian approach and learn a prior from other users? 2.",
                "Does the new algorithm work better than the standard EM algorithm for learning the Bayesian hierarchical linear model? 3.",
                "Can the new algorithm quickly learn many user models?",
                "To answer the first question, we compared the Bayesian hierarchical models with commonly used Norm-2 regularized linear regression models.",
                "In fact, the commonly used approach is equivalent to the model learned at the end of the first EM iteration.",
                "To answer the second question, we compared the proposed new algorithm with the standard EM algorithm to see whether the new learning algorithm is better.",
                "To answer the third question, we tested the efficiency of the new algorithm on the entire Netflix data set where about half a million user models need to be learned together.",
                "For the MovieLens and Netflix data sets, algorithm effectiveness was measured by mean square error, while on the Reuters data set classification error was used because it was more informative.",
                "We first evaluated the performance on each individual user, and then estimated the macro average over all users.",
                "Statistical tests (t-tests) were carried out to see whether the results are significant.",
                "For the experiments on the MovieLens and Netflix data sets, we used a random sample of 90% of each user for training, and the rest for testing.",
                "On Reuters data set, because there are too many relevant documents for each topic in the corpus, we used a random sample of 10% of each topic for training, and 10% of the remaining documents for testing.",
                "For all runs, we set (a, b, c, Σ ) = (0.1, 10, 0.1, 1) manually. 6.",
                "EXPERIMENTAL RESULTS Figure 2, Figure 3, and Figure 4 show that on all data sets, the Bayesian hierarchical modeling approach has a statistical significant improvement over the regularized linear regression model, which is equivalent to the Bayesian hierarchical models learned at the first iteration.",
                "Further analysis shows a negative correlation between the number of training data for a user and the improvement the system gets.",
                "This suggests that the borrowing information from other users has more significant improvements for users with less training data, which is as expected.",
                "However, the strength of the correlation differs over data sets, and the amount of training data is not the only characteristics that will influence the final performance.",
                "Figure 2 and Figure 3 show that the proposed new algorithm works better than the standard EM algorithm on the Netflix and MovieLens data sets.",
                "This is not surprising since the number of related feature-users pairs is much smaller than the number of unrelated feature-user pairs on these two data sets, and thus the proposed new algorithm is expected to work better.",
                "Figure 4 shows that the two algorithms work similarly on the Reuters-E data set.",
                "The accuracy of the new algorithm is similar to that of the standard EM algorithm at each iteration.",
                "The general patterns are very similar on other Reuters subsets.",
                "Further analysis shows that only 58% of the user-feature pairs are unrelated on this data set.",
                "Since the number of unrelated user-feature pairs is not extremely large, the sparseness is not a serious problem on the Reuters data set.",
                "Thus the two learning algorithms perform similarly.",
                "The results suggest that only on a corpus where the number of unrelated user-feature pairs is much larger than the number of related pairs, such as on the Netflix data set, the proposed technique will get a significant improvement over standard EM.",
                "However, the experiments also show that when the assumption does not hold, the new algorithm does not hurt performance.",
                "Although the proposed technique is faster than standard Figure 2: Performance on a Netflix subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iterations 2 - 10.",
                "Norm-2 regularized linear models are equivalent to the Bayesian hierarchical models learned at the first iteration, and are statistical significantly worse than the Bayesian hierarchical models. 0 2 4 6 8 10 1 1.05 1.1 1.15 1.2 1.25 1.3 1.35 1.4 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iterations ClassificationError New Algorithm Traditional EM Figure 3: Performance on a MovieLens subset with 1,000 users.",
                "The new algorithm is statistical significantly better than EM algorithm at iteration 2 to 17 (evaluated with mean square error). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iterations MeanSquareError New Algorithm Traditional EM 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iterations ClassificationError New Algorithm Traditional EM Figure 4: Performance on a Reuters-E subset with 26 profiles.",
                "Performances on Reuters-C, Reuters-M, Reuters-G are similar. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iterations MeanSquareError New Algorithm Traditional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iterations ClassificationError New Algorithm Traditional EM EM, can it really learn millions of user models quickly?",
                "Our results show that the modified EM algorithm converges quickly, and 2 - 3 modified EM iterations would result in a reliable estimation.",
                "We evaluated the algorithm on the whole Netflix data set (480,189 users, 159,836 features, and 100 million ratings) running on a single CPU PC (2GB memory, P4 3GHz).",
                "The system finished one modified EM iteration in about 4 hours.",
                "This demonstrates that the proposed technique can efficiently handle large-scale system like Netflix. 7.",
                "CONCLUSION Content-based user profile learning is an important problem and is the key to providing personal recommendations to a user, especially for recommending new items with a small number of ratings.",
                "The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors.",
                "This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM.",
                "We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm.",
                "Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse, by which we mean the ratio of related user-feature pairs to unrelated pairs is small.",
                "Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold.",
                "In general, it is better to use the new algorithm since it is as simple as standard EM, the performance is either better or similar to EM, and the computation complexity is lower at each iteration.",
                "It is worth mentioning that even if the original problem space is not sparse, sparseness can be created artificially when a recommendation system uses user-specific feature selection techniques to reduce the noise and user model complexity.",
                "The proposed technique can also be adapted to improve the learning in such a scenario.",
                "We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU.",
                "The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear modeling approach to build a practical large scale system, even though the literature have demonstrated the effectiveness of the models in many applications.",
                "Our work is one major step on the road to make Bayesian hierarchical linear models more practical.",
                "The proposed new technique can be easily adapted to run on a cluster of machines, and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users.",
                "The research has much potential to benefit people using EM algorithm on many other IR problems as well as machine learning problems.",
                "EM algorithm is a commonly used machine learning technique.",
                "It is used to find model parameters in many IR problems where the training data is very sparse.",
                "Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering, the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems. 8.",
                "ACKNOWLEDGMENTS We thank Wei Xu, David Lewis and anonymous reviewers for valuable feedback on the work described in this paper.",
                "Part of the work was supported by Yahoo, Google, the Petascale Data Storage Institute and the Institute for Scalable Scientific Data Management.",
                "Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors, and do not necessarily reflect those of the sponsors. 9.",
                "REFERENCES [1] C. Basu, H. Hirsh, and W. Cohen.",
                "Recommendation as classification: Using social and content-based information in recommendation.",
                "In Proceedings of the Fifteenth National Conference on Artificial Intelligence, 1998. [2] J. S. Breese, D. Heckerman, and C. Kadie.",
                "Empirical analysis of predictive algorithms for collaborative filtering.",
                "Technical report, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan.",
                "Document filtering with inference networks.",
                "In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor, and A. Vinokourov.",
                "Kernel method for document filtering.",
                "In The Eleventh Text REtrieval Conference (TREC11).",
                "National Institute of Standards and Technology, special publication 500-249, 2003. [5] C. Chelba and A. Acero.",
                "Adaptation of maximum entropy capitalizer: Little data can help a lot.",
                "In D. Lin and D. Wu, editors, Proceedings of EMNLP 2004, pages 285-292, Barcelona, Spain, July 2004.",
                "Association for Computational Linguistics. [6] B. Croft and J. Lafferty, editors.",
                "Language Modeling for Information Retrieval.",
                "Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov, and A. Genkin.",
                "Constructing informative prior distributions from domain knowledge in text classification.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 493-500, New York, NY, USA, 2006.",
                "ACM Press. [8] J. Delgado and N. Ishii.",
                "Memory-based weightedmajority prediction for recommender systems.",
                "In ACM SIGIR99 Workshop on Recommender Systems, 1999. [9] GroupLens.",
                "Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman.",
                "A tutorial on learning with bayesian networks.",
                "In M. Jordan, editor, Learning in Graphical Models.",
                "Kluwer Academic, 1998. [11] J. L. Herlocker, J.",
                "A. Konstan, A. Borchers, and J. Riedl.",
                "An algorithmic framework for performing collaborative filtering.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 230-237, New York, NY, USA, 1999.",
                "ACM Press. [12] T. Hofmann and J. Puzicha.",
                "Latent class models for collaborative filtering.",
                "In IJCAI 99: Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 688-693, San Francisco, CA, USA, 1999.",
                "Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).",
                "Internet movie database. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai, and L. Si.",
                "An automatic weighting scheme for collaborative filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 337-344, New York, NY, USA, 2004.",
                "ACM Press. [15] J.",
                "A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl.",
                "GroupLens: Applying collaborative filtering to Usenet news.",
                "Communications of the ACM, 40(3):77-87, 1997. [16] D. Lewis.",
                "Applying support vector machines to the TREC-2001 batch filtering and routing tasks.",
                "In Proceedings of the Eleventh Text REtrieval Conference (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee, , and P. Yu.",
                "Text classification by labeling words.",
                "In Proceedings of The Nineteenth National Conference on Artificial Intelligence (AAAI-2004), July 25-29, 2004. [18] P. Melville, R. J. Mooney, and R. Nagarajan.",
                "Content-boosted collaborative filtering for improved recommendations.",
                "In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002), Edmonton, Canada, 2002. [19] Netflix.",
                "Netflix prize. http://www.netflixprize.com (visited on Nov. 30, 2006), 2006. [20] S. Robertson and K. Sparck-Jones.",
                "Relevance weighting of search terms.",
                "In Journal of the American Society for Information Science, volume 27, pages 129-146, 1976. [21] J. Wang, A. P. de Vries, and M. J. T. Reinders.",
                "Unifying user-based and item-based collaborative filtering approaches by similarity fusion.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 501-508, New York, NY, USA, 2006.",
                "ACM Press. [22] X. Wu and R. K. Srihari.",
                "Incorporating prior knowledge with weighted margin support vector machines.",
                "In Proc.",
                "ACM Knowledge Discovery Data Mining Conf. (ACM SIGKDD 2004), Aug. 2004. [23] Y. Yang, S. Yoo, J. Zhang, and B. Kisiel.",
                "Robustness of adaptive filtering methods in a cross-benchmark evaluation.",
                "In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2005. [24] K. Yu, V. Tresp, and A. Schwaighofer.",
                "Learning gaussian processes from multiple tasks.",
                "In ICML 05: Proceedings of the 22nd international conference on Machine learning, pages 1012-1019, New York, NY, USA, 2005.",
                "ACM Press. [25] K. Yu, V. Tresp, and S. Yu.",
                "A nonparametric hierarchical bayesian framework for information filtering.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 353-360.",
                "ACM Press, 2004. [26] X. Zhu.",
                "Semi-supervised learning literature survey.",
                "Technical report, University of Wisconsin - Madison, December 9, 2006. [27] P. Zigoris and Y. Zhang.",
                "Bayesian adaptive user profiling with explicit & implicit feedback.",
                "In Conference on Information and Knowledge Mangement 2006, 2006."
            ],
            "original_annotated_samples": [
                "A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a <br>bayesian hierarchical model</br>.",
                "In order to learn a <br>bayesian hierarchical model</br>, the system usually tries to find the most likely model parameters for the given data.",
                "It is well known that learning the optimal parameters of a <br>bayesian hierarchical model</br> is computationally expensive when there are thousands or millions of users.",
                "Figure 1 shows the graphical representation of a <br>bayesian hierarchical model</br>."
            ],
            "translated_annotated_samples": [
                "Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un <br>modelo jerárquico bayesiano</br>.",
                "Para aprender un <br>modelo jerárquico bayesiano</br>, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados.",
                "Es bien sabido que aprender los parámetros óptimos de un <br>modelo jerárquico bayesiano</br> es computacionalmente costoso cuando hay miles o millones de usuarios.",
                "La Figura 1 muestra la representación gráfica de un <br>modelo jerárquico bayesiano</br>."
            ],
            "translated_text": "Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual. Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un <br>modelo jerárquico bayesiano</br>. Aprender los parámetros del modelo para optimizar la verosimilitud conjunta de los datos de millones de usuarios es muy costoso computacionalmente. El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de datos en aplicaciones de IR. Este documento propone una nueva técnica de aprendizaje rápido para aprender un gran número de perfiles de usuario individuales. La eficacia y eficiencia del algoritmo propuesto están justificadas por la teoría y demostradas en datos reales de usuarios de Netflix y MovieLens. Categorías y Descriptores de Asignaturas: B.3.3 [Búsqueda y Recuperación de Información]: Filtrado de información Términos Generales: Algoritmos 1. La personalización es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales. Por ejemplo, las tiendas en línea, como Amazon y Netflix, ofrecen recomendaciones personalizadas de productos o servicios adicionales basadas en el historial de un usuario. Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de un usuario a partir de su historial. Un tema importante de personalización estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados basados en el contenido. Estos sistemas aprenden perfiles específicos de usuario a partir de la retroalimentación del usuario para poder recomendar información adaptada a los intereses de cada usuario sin necesidad de que el usuario realice una consulta explícita. Aprender los perfiles de usuario es el problema central de estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica qué tan relevante es un documento para el usuario. Uno de los principales desafíos de construir un sistema de recomendación o personalización es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña. Esto se conoce como el problema de inicio en frío. Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente retroalimentación de ese usuario para aprender un perfil de usuario confiable. Se ha realizado mucha investigación sobre cómo mejorar la precisión de clasificación cuando la cantidad de datos de entrenamiento etiquetados es pequeña. El enfoque de aprendizaje semisupervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26]. Otro enfoque es utilizar el conocimiento del dominio. Los investigadores han modificado diferentes algoritmos de aprendizaje, como NaïveBayes [17], regresión logística [7] y SVMs [22], para integrar el conocimiento del dominio en un clasificador de texto. El tercer enfoque consiste en tomar datos de entrenamiento de otros recursos [5][7]. La efectividad de estos enfoques diferentes es mixta, debido a qué tan bien se ajusta la suposición del modelo subyacente a los datos. Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano. Varios investigadores han demostrado que este enfoque intercambia eficazmente entre la información compartida y la específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario[27][25]. Para aprender un <br>modelo jerárquico bayesiano</br>, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados. Un sistema de recomendación maduro generalmente funciona para millones de usuarios. Es bien sabido que aprender los parámetros óptimos de un <br>modelo jerárquico bayesiano</br> es computacionalmente costoso cuando hay miles o millones de usuarios. El algoritmo EM es una técnica comúnmente utilizada para el aprendizaje de parámetros debido a su simplicidad y garantía de convergencia. Sin embargo, un sistema de recomendación basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso. Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM tering, o filtrado colaborativo basado en elementos. En este documento, las palabras filtrado y recomendación se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de las variables de entrada. También encontramos que actualizar el parámetro del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones. Este documento modifica el algoritmo EM estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos algoritmo EM modificado. La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M utilizamos la solución analítica en lugar de la solución numérica estimada en el paso E para esos parámetros. Esto reduce considerablemente la computación en una sola iteración de EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales. La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de regresión lineal jerárquica bayesiana utilizado para recomendaciones basadas en contenido. La sección 4 describe cómo aprender los parámetros del modelo utilizando el algoritmo EM estándar, junto con el uso de la nueva técnica propuesta en este artículo. La configuración experimental y los resultados utilizados para validar la técnica de aprendizaje propuesta se informan en las Secciones 5 y 6. La sección 7 resume y ofrece observaciones finales. 2. TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de IR desde la década de 1970. Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus filtrado colaborativo. El filtrado basado en contenido estudia el escenario en el que un sistema de recomendación monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente. El usuario puede leer los documentos entregados y proporcionar retroalimentación explícita de relevancia, la cual el sistema de filtrado utiliza para actualizar el perfil del usuario mediante modelos de recuperación de retroalimentación de relevancia (por ejemplo,). Modelos booleanos, modelos de espacio vectorial, modelos probabilísticos tradicionales [20], redes de inferencia [3] y modelos de lenguaje [6]) o algoritmos de aprendizaje automático (por ejemplo, Máquinas de Vectores de Soporte (SVM), agrupamiento de K vecinos más cercanos (K-NN), redes neuronales, regresión logística o Winnow [16] [4] [23]. El filtrado colaborativo va más allá de simplemente usar el contenido de un documento para recomendar elementos a un usuario, aprovechando la información de otros usuarios con gustos y preferencias similares en el pasado. Se han utilizado heurísticas basadas en memoria y enfoques basados en modelos en la tarea de filtrado colaborativo [15] [8] [2] [14] [12] [11]. Este artículo contribuye a la investigación de recomendaciones basadas en contenido al mejorar la eficiencia y efectividad de los modelos lineales jerárquicos bayesianos, los cuales tienen una sólida base teórica y un buen rendimiento empírico en tareas de recomendación[27][25]. Este artículo no tiene la intención de comparar el filtrado basado en contenido con el filtrado colaborativo ni de afirmar cuál es mejor. Creemos que cada uno complementa al otro, y que el filtrado basado en contenido es extremadamente útil para manejar nuevos documentos/artículos con poco o ningún feedback del usuario. Similar a otros investigadores[18][1][21], encontramos que un sistema de recomendación será más efectivo cuando se combinan ambas técnicas. Sin embargo, esto está fuera del alcance de este documento y, por lo tanto, no se discute aquí. 3. REGRESIÓN LINEAL HIERÁRQUICA BAYESIANA Suponga que hay M usuarios en el sistema. La tarea del sistema es recomendar documentos que sean relevantes para cada usuario. Para cada usuario, el sistema aprende un modelo de usuario a partir del historial de los usuarios. En el resto de este documento, utilizaremos las siguientes notaciones para representar las variables en el sistema. m = 1, 2, ..., M: El índice para cada usuario individual. M es el número total de usuarios. wm: El parámetro del modelo de usuario asociado con el usuario m. wm es un vector de dimensión K. j = 1, 2, ..., Jm: El índice para un conjunto de datos para el usuario m. Jm es el número de datos de entrenamiento para el usuario m. Dm = {(xm,j, ym,j)}: Un conjunto de datos asociado con el usuario m. xm,j es un vector de dimensión K que representa el j-ésimo documento de entrenamiento del usuario m. ym,j es un escalar que representa la etiqueta del documento xm,j. k = 1, 2, ..., K: El índice dimensional de la variable de entrada x. El enfoque de modelado jerárquico bayesiano ha sido ampliamente utilizado en aplicaciones reales de recuperación de información. Los modelos lineales jerárquicos bayesianos generalizados, uno de los modelos jerárquicos bayesianos más simples, son comúnmente utilizados y han logrado un buen rendimiento en tareas de filtrado colaborativo [25] y filtrado adaptativo basado en contenido [27]. La Figura 1 muestra la representación gráfica de un <br>modelo jerárquico bayesiano</br>. En este gráfico, cada modelo de usuario está representado por un vector aleatorio wm. Suponemos que un modelo de usuario se muestrea aleatoriamente de una distribución previa P(w|Φ). El sistema puede predecir la etiqueta de usuario y de un documento x dado una estimación de wm (o distribución de wms) utilizando una función y = f(x, w). El modelo se llama modelo lineal jerárquico bayesiano generalizado cuando y = f(wT x) es cualquier modelo lineal generalizado como regresión logística, SVM y regresión lineal. Para estimar de manera confiable el modelo de usuario wm, el sistema puede obtener información de otros usuarios a través de la prior Φ = (µ, Σ). Ahora observamos un modelo comúnmente utilizado donde y = wT x + , donde ∼ N(0, σ2 ) es un ruido aleatorio [25][27]. Suponga que cada modelo de usuario wm es una muestra independiente de una distribución poblacional P(w|Φ), la cual está regida por un hiperparámetro desconocido Φ. Que la distribución previa del modelo de usuario w sea una distribución gaussiana con parámetro Φ = (µ, Σ), que es la distribución previa comúnmente utilizada para modelos lineales. µ = (µ1, µ2, ..., µK) es un vector de K dimensiones que representa la media de la distribución gaussiana, y Σ es la matriz de covarianza de la gaussiana. Normalmente, se utiliza una distribución Normal N(0, aI) y una distribución Inverse Wishart P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) como hiperprior para modelar la distribución previa de µ y Σ respectivamente. Yo es la matriz identidad de dimensión K, y a, b y c son números reales. Con esta configuración, tenemos el siguiente modelo para el sistema: 1. µ y Σ se muestrean de N(0, aI) e IWν (aI), respectivamente. 2. La primera dimensión de x es una variable ficticia que siempre es igual a 1. Figura 1: Ilustración de las dependencias de variables en el modelo jerárquico. La calificación, y, para un documento, x, está condicionada al documento y al modelo de usuario, wm, asociado con el usuario m. Los usuarios comparten información sobre sus modelos a través de la prior, Φ = (µ, Σ). Para cada usuario m, wm se muestrea aleatoriamente de una distribución Normal: wm ∼ N(µ, Σ2 ) 3. Para cada elemento xm,j, ym,j se muestrea aleatoriamente de una distribución Normal: ym,j ∼ N(wT mxm,j, σ2). Que θ = (Φ, w1, w2, ..., wM) represente los parámetros de este sistema que necesitan ser estimados. La verosimilitud conjunta de todas las variables en el modelo probabilístico, que incluye los datos y los parámetros, es: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) Para simplificar, asumimos que a, b, c y σ son proporcionados al sistema. 4. APRENDIZAJE DE PARÁMETROS DEL MODELO Si se conoce el prior Φ, encontrar el óptimo wm es sencillo: se trata de una regresión lineal simple. Por lo tanto, nos enfocaremos en estimar Φ. La solución a priori máxima de Φ se da por ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Encontrar la solución óptima para el problema anterior es desafiante, ya que necesitamos integrar sobre todos los w = (w1, w2, ..., wM), que son variables ocultas no observadas. 4.1 Algoritmo EM para Modelos Lineales Jerárquicos Bayesianos En la Ecuación 5, Φ es el parámetro que necesita ser estimado, y el resultado depende de las variables latentes no observadas w. Este tipo de problema de optimización suele resolverse mediante el algoritmo EM. Aplicando EM al problema anterior, el conjunto de modelos de usuario w son las variables ocultas no observables y tenemos: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw. Basándonos en la derivación de las fórmulas EM presentadas en [24], tenemos los siguientes pasos de Expectation-Maximization para encontrar los hiperparámetros óptimos. Por razones de espacio, omitimos la derivación en este artículo ya que no es el enfoque de nuestro trabajo. Paso E: Para cada usuario m, estime la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual del prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) donde Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j Paso M: Optimice el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Muchos sistemas de IR impulsados por aprendizaje automático utilizan una estimación puntual de los parámetros en diferentes etapas del sistema. Sin embargo, estamos estimando la distribución posterior de las variables en el paso E. Esto evita el sobreajuste de wm a los datos de un usuario en particular, que pueden ser pequeños y ruidosos. Una discusión detallada sobre este tema aparece en [10]. 4.2 Nuevo Algoritmo: EM Modificado. Aunque el algoritmo EM es ampliamente estudiado y utilizado en aplicaciones de aprendizaje automático, utilizar el proceso EM mencionado anteriormente para resolver modelos lineales jerárquicos bayesianos en sistemas de recuperación de información a gran escala sigue siendo demasiado costoso computacionalmente. En esta sección, describimos por qué la tasa de aprendizaje del algoritmo EM es lenta en nuestra aplicación e introducimos una nueva técnica para hacer que el aprendizaje del modelo lineal jerárquico bayesiano sea escalable. La derivación del nuevo algoritmo de aprendizaje estará basada en el algoritmo EM descrito en la sección anterior. Primero, las matrices de covarianza Σ2 , Σ2 m suelen ser demasiado grandes para ser computacionalmente factibles. Por simplicidad, y como práctica común en IR, no modelamos la correlación entre características. Así aproximamos estas matrices con matrices diagonales de dimensión K. En el resto del documento, utilizamos estos símbolos para representar sus aproximaciones diagonales: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     En segundo lugar, y lo más importante, el espacio de entrada es muy disperso y hay muchas dimensiones que no están relacionadas con un usuario particular en una aplicación de recuperación de información real. Por ejemplo, consideremos un sistema de recomendación de películas, con la variable de entrada x representando una película en particular. Para la j-ésima película que el usuario m ha visto, sea xm,j,k = 1 si el director de la película es Jean-Pierre Jeunet (indexado por k). Aquí asumimos que si este director dirigió una película específica está representado por la k-ésima dimensión. Si el usuario m nunca ha visto una película dirigida por Jean-Pierre Jeunet, entonces la dimensión correspondiente siempre es cero (xm,j,k = 0 para todos los j). Una desventaja importante del algoritmo EM es que la importancia de una característica, µk, puede estar fuertemente dominada por usuarios que nunca han encontrado esta característica (es decir, j xm,j,k = 0) en el paso M (Ecuación 8). Suponga que 100 de cada 1 millón de usuarios han visto la película dirigida por Jean-Pierre Jeunet, y que los espectadores han calificado todas sus películas como excelentes. Intuitivamente, él es un buen director y el peso para él (µk) debería ser alto. Antes de la iteración de EM, el valor inicial de µ suele establecerse en 0. Dado que los otros 999,900 usuarios no han visto esta película, sus pesos correspondientes (w1,k, w2,k, ..., wm,k..., w999900,k) para ese director serían muy pequeños inicialmente. Por lo tanto, el peso correspondiente del director en el µk anterior en el primer paso M sería muy bajo, y la varianza σm,k será grande (Ecuaciones 8 y 7). Es indeseable que los usuarios que nunca han visto ninguna película producida por el director influyan tanto en la importancia del director. Esto hace que la convergencia del algoritmo EM estándar sea muy lenta. Ahora veamos si podemos mejorar la velocidad de aprendizaje del algoritmo. Sin pérdida de generalidad, asumamos que la k-ésima dimensión de la variable de entrada x no está relacionada con un usuario particular m. Lo que queremos decir es que xm,j,k = 0 para todo j = 1, ..., Jm. Es sencillo demostrar que la k-ésima fila y la k-ésima columna de Sxx,m están completamente llenas de ceros, y que la k-ésima dimensión de Sxy,m también se anula. Por lo tanto, la dimensión k correspondiente de la media de los modelos de usuario, ¯wm, debería ser igual a la del anterior: ¯wm,k = µk, con la covarianza correspondiente de σm,k = σk. En el paso M, el algoritmo EM estándar utiliza la solución numérica de la distribución P(wm|Dm, Φ) estimada en el paso E (Ecuación 8 y Ecuación 7). Sin embargo, las soluciones numéricas son muy poco confiables para ¯wm,k y σm,k cuando la k-ésima dimensión no está relacionada con el m-ésimo usuario. Un enfoque mejor es utilizar las soluciones analíticas ¯wm,k = µk, y σm,k = σk para los pares no relacionados (m, k), junto con la solución numérica estimada en el paso E para los otros pares (m, k). Así obtenemos el siguiente nuevo algoritmo EM similar: Paso E modificado: Para cada usuario m, estimar la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual de σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) donde sxx,m,k = j x2 m,j,k y sxy,m,k = j xm,j,kym,j Paso M modificado Optimizar el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E para pares de usuario-característica relacionados. El paso M utiliza implícitamente la solución analítica para pares de usuario-característica no relacionados. µk = 1 Mk m:relacionado ¯wm,k (12) σ2 k = 1 Mk m:relacionado σ2 m,k + ( ¯wm,k − µk)( ¯wm,k − µk)T (13) donde Mk es el número de usuarios relacionados con la característica k. Solo estimamos la diagonal de Σ2 m y Σ, ya que estamos utilizando la aproximación diagonal de las matrices de covarianza. Para estimar ¯wm, solo necesitamos calcular las soluciones numéricas para las dimensiones que están relacionadas con el usuario m. Para estimar σ2 k y µk, solo sumamos sobre los usuarios que están relacionados con la k-ésima característica. Hay dos beneficios principales del nuevo algoritmo. Primero, dado que solo se necesitan los pares relacionados (m, k) en el paso M modificado, la complejidad computacional en una sola iteración de EM es mucho menor cuando los datos son dispersos y muchos de los pares (m, k) no están relacionados. En segundo lugar, los parámetros estimados en el paso M modificado (Ecuaciones 12 - 13) son más precisos que el paso M estándar descrito en la Sección 4.1 porque se utilizaron soluciones analíticas exactas ¯wm,k = µk y σm,k = σk para los pares no relacionados (m, k) en el nuevo algoritmo en lugar de una solución aproximada como en el algoritmo estándar. METODOLOGÍA EXPERIMENTAL 5.1 Conjunto de Datos de Evaluación Para evaluar la técnica propuesta, utilizamos los siguientes tres conjuntos de datos principales (Tabla 1): Datos de MovieLens: Este conjunto de datos fue creado combinando las valoraciones de relevancia del conjunto de datos de MovieLens[9] con documentos de la Base de Datos de Películas en Internet (IMDB). MovieLens permite a los usuarios clasificar cuánto disfrutaron una película específica en una escala del 1 al 5. Esta calificación de simpatía se utilizó como una medida de cuán relevante es el documento que representa la película correspondiente para el usuario. Consideramos los documentos con puntuaciones de 4 o 5 como relevantes, y los documentos con una puntuación de 1 a 3 como irrelevantes para el usuario. MovieLens proporcionó juicios de relevancia sobre 3,057 documentos de 6,040 usuarios diferentes. En promedio, cada usuario calificó 151 películas, de las cuales 87 fueron consideradas relevantes. La puntuación promedio para un documento fue de 3.58. Los documentos que representan cada película fueron construidos a partir de la porción de la base de datos de IMDB que está disponible para descarga pública[13]. Basándonos en esta base de datos, creamos un documento por película que contenía la información relevante sobre ella (por ejemplo, directores, actores, etc.). Tabla 1: Estadísticas del conjunto de datos. En Reuters, el número de calificaciones para un usuario simulado es el número de documentos relevantes para el tema correspondiente. Datos Usuarios Documentos Calificaciones por Usuario MovieLens 6,040 3,057 151 Netflix-todos 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Datos de Netflix: Este conjunto de datos fue construido combinando documentos sobre películas obtenidos de la web con un conjunto de juicios de relevancia de clientes reales de alquiler de películas de Netflix[19]. Netflix proporciona públicamente las evaluaciones de relevancia de 480,189 clientes anónimos. Hay alrededor de 100 millones de calificaciones en una escala del 1 al 5 para 17,770 documentos. Similar a MovieLens, consideramos documentos con puntuaciones de 4 o 5 de agradabilidad como relevantes. Este número se redujo a 1000 clientes mediante muestreo aleatorio. El cliente promedio en el conjunto de datos reducido proporcionó 127 juicios, de los cuales 70 fueron considerados relevantes. La puntuación promedio de los documentos es de 3.55. Datos de Reuters: Este es el Corpus de Reuters, Volumen 1. Cubre 810,000 noticias en inglés de Reuters desde el 20 de agosto de 1996 hasta el 19 de agosto de 1997. Solo se utilizaron las primeras 100,000 noticias en nuestros experimentos. El corpus de Reuters viene con una jerarquía de temas. Cada documento se asigna a una de varias ubicaciones en el árbol jerárquico. El primer nivel del árbol contiene cuatro temas, denotados como C, E, M y G. Para los experimentos en este artículo, el árbol fue cortado en el nivel 1 para crear cuatro árboles más pequeños, cada uno de los cuales corresponde a un conjunto de datos más pequeño: Reuters-E, Reuters-C, Reuters-M y Reuters-G. Para cada conjunto de datos pequeño, creamos varios perfiles, un perfil para cada nodo en un subárbol, para simular múltiples usuarios, cada uno con una definición de relevancia relacionada pero separada. Todos los perfiles de usuario en una sub-rama se supone que comparten la misma distribución de modelo previo. Dado que este corpus indica explícitamente solo los documentos relevantes para un tema (usuario), todos los demás documentos se consideran irrelevantes. 5.2 Evaluación Diseñamos los experimentos para responder a las siguientes tres preguntas: 1. ¿Necesitamos hacer el esfuerzo de utilizar un enfoque bayesiano y aprender una distribución a priori de otros usuarios? 2. ¿El nuevo algoritmo funciona mejor que el algoritmo EM estándar para aprender el modelo lineal jerárquico bayesiano? 3. ¿Puede el nuevo algoritmo aprender rápidamente muchos modelos de usuario? Para responder a la primera pregunta, comparamos los modelos jerárquicos bayesianos con los modelos de regresión lineal regularizados Norm-2 comúnmente utilizados. De hecho, el enfoque comúnmente utilizado es equivalente al modelo aprendido al final de la primera iteración de EM. Para responder a la segunda pregunta, comparamos el nuevo algoritmo propuesto con el algoritmo EM estándar para ver si el nuevo algoritmo de aprendizaje es mejor. Para responder a la tercera pregunta, probamos la eficiencia del nuevo algoritmo en todo el conjunto de datos de Netflix, donde aproximadamente medio millón de modelos de usuario deben ser aprendidos juntos. Para los conjuntos de datos de MovieLens y Netflix, la efectividad del algoritmo se midió mediante el error cuadrático medio, mientras que en el conjunto de datos de Reuters se utilizó el error de clasificación porque era más informativo. Primero evaluamos el rendimiento en cada usuario individual, y luego estimamos el promedio macro sobre todos los usuarios. Se realizaron pruebas estadísticas (pruebas t) para determinar si los resultados son significativos. Para los experimentos en los conjuntos de datos de MovieLens y Netflix, utilizamos una muestra aleatoria del 90% de cada usuario para entrenamiento, y el resto para pruebas. En el conjunto de datos de Reuters, debido a que hay demasiados documentos relevantes para cada tema en el corpus, utilizamos una muestra aleatoria del 10% de cada tema para el entrenamiento, y el 10% de los documentos restantes para las pruebas. Para todas las ejecuciones, establecimos (a, b, c, Σ) = (0.1, 10, 0.1, 1) manualmente. 6. RESULTADOS EXPERIMENTALES Las Figuras 2, 3 y 4 muestran que en todos los conjuntos de datos, el enfoque de modelado jerárquico bayesiano tiene una mejora estadísticamente significativa sobre el modelo de regresión lineal regularizado, que es equivalente a los modelos jerárquicos bayesianos aprendidos en la primera iteración. Un análisis adicional muestra una correlación negativa entre la cantidad de datos de entrenamiento para un usuario y la mejora que obtiene el sistema. Esto sugiere que la información prestada de otros usuarios tiene mejoras más significativas para usuarios con menos datos de entrenamiento, lo cual es lo esperado. Sin embargo, la fuerza de la correlación varía entre los conjuntos de datos, y la cantidad de datos de entrenamiento no es la única característica que influirá en el rendimiento final. Las Figuras 2 y 3 muestran que el nuevo algoritmo propuesto funciona mejor que el algoritmo EM estándar en los conjuntos de datos de Netflix y MovieLens. Esto no es sorprendente ya que el número de pares de características-usuarios relacionados es mucho menor que el número de pares de características-usuarios no relacionados en estos dos conjuntos de datos, por lo que se espera que el nuevo algoritmo propuesto funcione mejor. La Figura 4 muestra que los dos algoritmos funcionan de manera similar en el conjunto de datos de Reuters-E. La precisión del nuevo algoritmo es similar a la del algoritmo EM estándar en cada iteración. Los patrones generales son muy similares en otros subconjuntos de Reuters. Un análisis adicional muestra que solo el 58% de los pares usuario-característica no están relacionados en este conjunto de datos. Dado que el número de pares usuario-característica no relacionados no es extremadamente grande, la dispersión no es un problema grave en el conjunto de datos de Reuters. Por lo tanto, los dos algoritmos de aprendizaje se desempeñan de manera similar. Los resultados sugieren que solo en un corpus donde el número de pares usuario-característica no relacionados es mucho mayor que el número de pares relacionados, como en el conjunto de datos de Netflix, la técnica propuesta obtendrá una mejora significativa sobre el EM estándar. Sin embargo, los experimentos también muestran que cuando la suposición no se cumple, el nuevo algoritmo no afecta el rendimiento. Aunque la técnica propuesta es más rápida que la estándar. Figura 2: Rendimiento en un subconjunto de Netflix con 1,000 usuarios. El nuevo algoritmo es estadísticamente significativamente mejor que el algoritmo EM en las iteraciones 2 a 10. Los modelos lineales regularizados con norma-2 son equivalentes a los modelos jerárquicos bayesianos aprendidos en la primera iteración, y son estadísticamente significativamente peores que los modelos jerárquicos bayesianos. Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional Figura 3: Rendimiento en un subconjunto de MovieLens con 1,000 usuarios. El nuevo algoritmo es significativamente mejor estadísticamente que el algoritmo EM en las iteraciones 2 a 17 (evaluado con error cuadrático medio). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iteraciones ErrorCuadráticoMedio Nuevo Algoritmo EM Tradicional 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iteraciones Error de Clasificación Nuevo Algoritmo EM Tradicional Figura 4: Rendimiento en un subconjunto de Reuters-E con 26 perfiles. Las actuaciones en Reuters-C, Reuters-M, Reuters-G son similares. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional EM, ¿realmente puede aprender rápidamente millones de modelos de usuario? Nuestros resultados muestran que el algoritmo EM modificado converge rápidamente, y 2-3 iteraciones del EM modificado darían como resultado una estimación confiable. Evaluamos el algoritmo en todo el conjunto de datos de Netflix (480,189 usuarios, 159,836 características y 100 millones de valoraciones) ejecutándolo en un solo PC con CPU (2GB de memoria, P4 3GHz). El sistema completó una iteración EM modificada en aproximadamente 4 horas. Esto demuestra que la técnica propuesta puede manejar eficientemente sistemas a gran escala como Netflix. CONCLUSIÓN El aprendizaje de perfiles de usuario basado en contenido es un problema importante y es clave para proporcionar recomendaciones personales a un usuario, especialmente para recomendar nuevos elementos con un pequeño número de calificaciones. El enfoque de modelado jerárquico bayesiano se está convirtiendo en un enfoque importante para el aprendizaje de perfiles de usuario debido a su capacidad teóricamente justificada para ayudar a un usuario a través de la transferencia de información de otros usuarios mediante hiperpriors. Este artículo examinó la debilidad del enfoque de aprendizaje basado en EM popular para modelos lineales jerárquicos bayesianos y propuso una técnica de aprendizaje mejorada llamada EM Modificado. Demostramos que la nueva técnica es teóricamente más eficiente computacionalmente que el algoritmo EM estándar. La evaluación en los conjuntos de datos de MovieLens y Netflix demostró la efectividad de la nueva técnica cuando los datos son dispersos, lo que significa que la proporción de pares de usuario-característica relacionados con respecto a los pares no relacionados es pequeña. La evaluación en el conjunto de datos de Reuters mostró que la nueva técnica tuvo un rendimiento similar al algoritmo EM estándar cuando la condición de dispersión no se cumple. En general, es mejor utilizar el nuevo algoritmo ya que es tan simple como el EM estándar, el rendimiento es igual o mejor que el del EM, y la complejidad computacional es menor en cada iteración. Vale la pena mencionar que aunque el espacio de problemas original no sea disperso, la dispersión puede crearse artificialmente cuando un sistema de recomendación utiliza técnicas de selección de características específicas del usuario para reducir el ruido y la complejidad del modelo del usuario. La técnica propuesta también puede adaptarse para mejorar el aprendizaje en dicho escenario. También demostramos que la técnica propuesta puede aprender medio millón de perfiles de usuario a partir de 100 millones de valoraciones en unas pocas horas con una sola CPU. La investigación es importante porque la escalabilidad es una preocupación importante para los investigadores al utilizar el enfoque de modelado lineal jerárquico bayesiano para construir un sistema a gran escala práctico, a pesar de que la literatura ha demostrado la efectividad de los modelos en muchas aplicaciones. Nuestro trabajo es un paso importante en el camino para hacer que los modelos lineales jerárquicos bayesianos sean más prácticos. La nueva técnica propuesta se puede adaptar fácilmente para ejecutarse en un clúster de máquinas, y así acelerar aún más el proceso de aprendizaje para manejar un sistema a mayor escala con cientos de millones de usuarios. La investigación tiene mucho potencial para beneficiar a las personas utilizando el algoritmo EM en muchos otros problemas de IR, así como en problemas de aprendizaje automático. El algoritmo EM es una técnica de aprendizaje automático comúnmente utilizada. Se utiliza para encontrar los parámetros del modelo en muchos problemas de IR donde los datos de entrenamiento son muy dispersos. Aunque nos estamos centrando en los modelos lineales jerárquicos bayesianos para recomendación y filtrado, la nueva idea de utilizar una solución analítica en lugar de una solución numérica para pares de usuario-característica no relacionados en el paso M podría adaptarse a muchos otros problemas. 8. AGRADECIMIENTOS Agradecemos a Wei Xu, David Lewis y a los revisores anónimos por sus valiosos comentarios sobre el trabajo descrito en este artículo. Parte del trabajo fue apoyado por Yahoo, Google, el Instituto de Almacenamiento de Datos a Escala Peta y el Instituto de Gestión de Datos Científicos Escalables. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las de los patrocinadores. REFERENCIAS [1] C. Basu, H. Hirsh y W. Cohen. Recomendación como clasificación: Utilizando información social y basada en contenido en la recomendación. En Actas de la Decimoquinta Conferencia Nacional de Inteligencia Artificial, 1998. [2] J. S. Breese, D. Heckerman y C. Kadie. Análisis empírico de algoritmos predictivos para filtrado colaborativo. Informe técnico, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan. Filtrado de documentos con redes de inferencia. En Actas de la Decimonovena Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor y A. Vinokourov. Método del núcleo para el filtrado de documentos. En la Undécima Conferencia de Recuperación de Información de Texto (TREC11). Instituto Nacional de Normas y Tecnología, publicación especial 500-249, 2003. [5] C. Chelba y A. Acero. Adaptación del capitalizador de entropía máxima: Poca información puede ayudar mucho. En D. Lin y D. Wu, editores, Actas de EMNLP 2004, páginas 285-292, Barcelona, España, julio de 2004. Asociación de Lingüística Computacional. [6] B. Croft y J. Lafferty, editores. Modelado de lenguaje para recuperación de información. Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov y A. Genkin. Construyendo distribuciones a priori informativas a partir del conocimiento del dominio en la clasificación de textos. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 493-500, Nueva York, NY, EE. UU., 2006. ACM Press. [8] J. Delgado y N. Ishii. Predicción basada en memoria ponderada para sistemas de recomendación. En el Taller ACM SIGIR99 sobre Sistemas de Recomendación, 1999. [9] GroupLens. Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman. Un tutorial sobre el aprendizaje con redes bayesianas. En M. Jordan, editor, Aprendizaje en Modelos Gráficos. Kluwer Academic, 1998. [11] J. L. Herlocker, J. \n\nKluwer Academic, 1998. [11] J. L. Herlocker, J. A. Konstan, A. Borchers y J. Riedl. Un marco algorítmico para realizar filtrado colaborativo. En SIGIR 99: Actas de la 22ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 230-237, Nueva York, NY, EE. UU., 1999. ACM Press. [12] T. Hofmann y J. Puzicha. Modelos de clases latentes para filtrado colaborativo. En IJCAI 99: Actas de la Decimosexta Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 688-693, San Francisco, CA, EE. UU., 1999. Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).\nMorgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB). Base de datos de películas en internet. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai y L. Si. Un esquema de ponderación automática para filtrado colaborativo. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 337-344, Nueva York, NY, EE. UU., 2004. ACM Press. [15] J. A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon y J. Riedl. GroupLens: Aplicando filtrado colaborativo a las noticias de Usenet. Comunicaciones de la ACM, 40(3):77-87, 1997. [16] D. Lewis. Aplicando máquinas de vectores de soporte a las tareas de filtrado y enrutamiento por lotes de TREC-2001. En Actas de la Undécima Conferencia de Recuperación de Texto (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee y P. Yu. Clasificación de texto mediante etiquetado de palabras. En Actas de la Decimonovena Conferencia Nacional de Inteligencia Artificial (AAAI-2004), 25-29 de julio de 2004. [18] P. Melville, R. J. Mooney y R. Nagarajan. Filtrado colaborativo potenciado por contenido para recomendaciones mejoradas. En Actas de la Decimoctava Conferencia Nacional de Inteligencia Artificial (AAAI-2002), Edmonton, Canadá, 2002. [19] Netflix. Premio Netflix. http://www.netflixprize.com (visitado el 30 de noviembre de 2006), 2006. [20] S. Robertson y K. Sparck-Jones. Ponderación de la relevancia de los términos de búsqueda. En Journal of the American Society for Information Science, volumen 27, páginas 129-146, 1976. [21] J. Wang, A. P. de Vries y M. J. T. Reinders. Unificando enfoques de filtrado colaborativo basados en usuarios y en elementos mediante la fusión de similitudes. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 501-508, Nueva York, NY, EE. UU., 2006. ACM Press. [22] X. Wu y R. K. Srihari. Incorporando conocimientos previos con máquinas de vectores de soporte de margen ponderado. En Proc. Conferencia de Minería de Datos y Descubrimiento de Conocimiento de ACM (ACM SIGKDD 2004), agosto de 2004. [23] Y. Yang, S. Yoo, J. Zhang y B. Kisiel. Robustez de los métodos de filtrado adaptativo en una evaluación de referencia cruzada. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 2005. [24] K. Yu, V. Tresp y A. Schwaighofer. Aprendiendo procesos gaussianos de múltiples tareas. En ICML 05: Actas de la 22ª conferencia internacional sobre aprendizaje automático, páginas 1012-1019, Nueva York, NY, EE. UU., 2005. ACM Press. [25] K. Yu, V. Tresp, y S. Yu. Un marco bayesiano jerárquico no paramétrico para el filtrado de información. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 353-360. ACM Press, 2004. [26] X. Zhu. \n\nACM Press, 2004. [26] X. Zhu. Revisión de la literatura sobre aprendizaje semisupervisado. Informe técnico, Universidad de Wisconsin - Madison, 9 de diciembre de 2006. [27] P. Zigoris y Y. Zhang. Perfilado de usuario bayesiano adaptativo con retroalimentación explícita e implícita. En la Conferencia sobre Gestión de la Información y el Conocimiento 2006, 2006. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        }
    }
}