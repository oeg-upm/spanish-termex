{
    "id": "J-31",
    "original_text": "Computing the Optimal Strategy to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously. However, this model is not always realistic. In many settings, one player is able to commit to a strategy before the other player makes a decision. Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously. The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position). In this paper, we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games. We give both positive results (efficient algorithms) and negative results (NP-hardness results). Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity General Terms Algorithms, Economics, Theory 1. INTRODUCTION In multiagent systems with self-interested agents (including most economic settings), the optimal action for one agent to take depends on the actions that the other agents take. To analyze how an agent should behave in such settings, the tools of game theory need to be applied. Typically, when a strategic setting is modeled in the framework of game theory, it is assumed that players choose their strategies simultaneously. This is especially true when the setting is modeled as a normal-form game, which only specifies each agents utility as a function of the vector of strategies that the agents choose, and does not provide any information on the order in which agents make their decisions and what the agents observe about earlier decisions by other agents. Given that the game is modeled in normal form, it is typically analyzed using the concept of Nash equilibrium. A Nash equilibrium specifies a strategy for each player, such that no player has an incentive to individually deviate from this profile of strategies. (Typically, the strategies are allowed to be mixed, that is, probability distributions over the original (pure) strategies.) A (mixed-strategy) Nash equilibrium is guaranteed to exist in finite games [18], but one problem is that there may be multiple Nash equilibria. This leads to the equilibrium selection problem of how an agent can know which strategy to play if it does not know which equilibrium is to be played. When the setting is modeled as an extensive-form game, it is possible to specify that some players receive some information about actions taken by others earlier in the game before deciding on their action. Nevertheless, in general, the players do not know everything that happened earlier in the game. Because of this, these games are typically still analyzed using an equilibrium concept, where one specifies a mixed strategy for each player, and requires that each players strategy is a best response to the others strategies. (Typically an additional constraint on the strategies is now imposed to ensure that players do not play in a way that is irrational with respect to the information that they have received so far. This leads to refinements of Nash equilibrium such as subgame perfect and sequential equilibrium.) However, in many real-world settings, strategies are not selected in such a simultaneous manner. Oftentimes, one player (the leader) is able to commit to a strategy before another player (the follower). This can be due to a variety of reasons. For example, one of the players may arrive at the site at which the game is to be played before another agent (e.g., in economic settings, one player may enter a market earlier and commit to a way of doing busi82 ness). Such commitment power has a profound impact on how the game should be played. For example, the leader may be best off playing a strategy that is dominated in the normal-form representation of the game. Perhaps the earliest and best-known example of the effect of commitment is that by von Stackelberg [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution. In general, if commitment to mixed strategies is possible, then (under minor assumptions) it never hurts, and often helps, to commit to a strategy [26]. Being forced to commit to a pure strategy sometimes helps, and sometimes hurts (for example, committing to a pure strategy in rock-paper-scissors before the other players decision will naturally result in a loss). In this paper, we will assume commitment is always forced; if it is not, the player who has the choice of whether to commit can simply compare the commitment outcome to the non-commitment (simultaneous-move) outcome. Models of leadership are especially important in settings with multiple self-interested software agents. Once the code for an agent (or for a team of agents) is finalized and the agent is deployed, the agent is committed to playing the (possibly randomized) strategy that the code prescribes. Thus, as long as one can credibly show that one cannot change the code later, the code serves as a commitment device. This holds true for recreational tournaments among agents (e.g., poker tournaments, RoboSoccer), and for industrial applications such as sensor webs. Finally, there is also an implicit leadership situation in the field of mechanism design, in which one player (the designer) gets to choose the rules of the game that the remaining players then play. Mechanism design is an extremely important topic to the EC community: the papers published on mechanism design in recent EC conferences are too numerous to cite. Indeed, the mechanism designer may benefit from committing to a choice that, if the (remaining) agents actions were fixed, would be suboptimal. For example, in a (first-price) auction, the seller may wish to set a positive (artificial) reserve price for the item, below which the item will not be sold-even if the seller values the item at 0. In hindsight (after the bids have come in), this (na¨ıvely) appears suboptimal: if a bid exceeding the reserve price came in, the reserve price had no effect, and if no such bid came in, the seller would have been better off accepting a lower bid. Of course, the reason for setting the reserve price is that it incentivizes the bidders to bid higher, and because of this, setting artificial reserve prices can actually increase expected revenue to the seller. A significant amount of research has recently been devoted to the computation of solutions according to various solution concepts for settings in which the agents choose their strategies simultaneously, such as dominance [7, 11, 3] and (especially) Nash equilibrium [8, 21, 16, 15, 2, 22, 23, 4]. However, the computation of the optimal strategy to commit to in a leadership situation has gone ignored. Theoretically, leadership situations can simply be thought of as an extensive-form game in which one player chooses a strategy (for the original game) first. The number of strategies in this extensive-form game, however, can be exceedingly large. For example, if the leader is able to commit to a mixed strategy in the original game, then every one of the (continuum of) mixed strategies constitutes a pure strategy in the extensive-form representation of the leadership situation. (We note that a commitment to a distribution is not the same as a distribution over commitments.) Moreover, if the original game is itself an extensive-form game, the number of strategies in the extensive-form representation of the leadership situation (which is a different extensive-form game) becomes even larger. Because of this, it is usually not computationally feasible to simply transform the original game into the extensive-form representation of the leadership situation; instead, we have to analyze the game in its original representation. In this paper, we study how to compute the optimal strategy to commit to, both in normal-form games (Section 2) and in Bayesian games, which are a special case of extensiveform games (Section 3). 2. NORMAL-FORM GAMES In this section, we study how to compute the optimal strategy to commit to for games represented in normal form. 2.1 Definitions In a normal-form game, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a pure strategy for every player, also known as a profile of pure strategies) to a real number. To ease notation, in the case of two players, we will refer to player 1s pure strategy set as S, and player 2s pure strategy set as T. Such games can be represented in (bi-)matrix form, in which the rows correspond to player 1s pure strategies, the columns correspond to player 2s pure strategies, and the entries of the matrix give the row and column players utilities (in that order) for the corresponding outcome of the game. In the case of three players, we will use R, S, and T, for player 1, 2, and 3s pure strategies, respectively. A mixed strategy for a player is a probability distribution over that players pure strategies. In the case of two-player games, we will refer to player 1 as the leader and player 2 as the follower. Before defining optimal leadership strategies, consider the following game which illustrates the effect of the leaders ability to commit. 2, 1 4, 0 1, 0 3, 1 In this normal-form representation, the bottom strategy for the row player is strictly dominated by the top strategy. Nevertheless, if the row player has the ability to commit to a pure strategy before the column player chooses his strategy, the row player should commit to the bottom strategy: doing so will make the column player prefer to play the right strategy, leading to a utility of 3 for the row player. By contrast, if the row player were to commit to the top strategy, the column player would prefer to play the left strategy, leading to a utility of only 2 for the row player. If the row player is able to commit to a mixed strategy, then she can get an even greater (expected) utility: if the row player commits to placing probability p > 1/2 on the bottom strategy, then the column player will still prefer to play the right strategy, and the row players expected utility will be 3p + 4(1 − p) = 4 − p ≥ 3. If the row player plays each strategy with probability exactly 1/2, the column player is 83 indifferent between the strategies. In such cases, we will assume that the column player will choose the strategy that maximizes the row players utility (in this case, the right strategy). Hence, the optimal mixed strategy to commit to for the row player is p = 1/2. There are a few good reasons for this assumption. If we were to assume the opposite, then there would not exist an optimal strategy for the row player in the example game: the row player would play the bottom strategy with probability p = 1/2 + with > 0, and the smaller , the better the utility for the row player. By contrast, if we assume that the follower always breaks ties in the leaders favor, then an optimal mixed strategy for the leader always exists, and this corresponds to a subgame perfect equilibrium of the extensive-form representation of the leadership situation. In any case, this is a standard assumption for such models (e.g. [20]), although some work has investigated what can happen in the other subgame perfect equilibria [26]. (For generic two-player games, the leaders subgame-perfect equilibrium payoff is unique.) Also, the same assumption is typically used in mechanism design, in that it is assumed that if an agent is indifferent between revealing his preferences truthfully and revealing them falsely, he will report them truthfully. Given this assumption, we can safely refer to optimal leadership strategies rather than having to use some equilibrium notion. Hence, for the purposes of this paper, an optimal strategy to commit to in a 2-player game is a strategy s ∈ S that maximizes maxt∈BR(s) ul(s, t), where BR(s) = arg maxt∈T uf (s, t). (ul and uf are the leader and followers utility functions, respectively.) We can have S = S for the case of commitment to pure strategies, or S = ∆(S), the set of probability distributions over S, for the case of commitment to mixed strategies. (We note that replacing T by ∆(T) makes no difference in this definition.) For games with more than two players, in which the players commit to their strategies in sequence, we define optimal strategies to commit to recursively. After the leader commits to a strategy, the game to be played by the remaining agents is itself a (smaller) leadership game. Thus, we define an optimal strategy to commit to as a strategy that maximizes the leaders utility, assuming that the play of the remaining agents is itself optimal under this definition, and maximizes the leaders utility among all optimal ways to play the remaining game. Again, commitment to mixed strategies may or may not be a possibility for every player (although for the last player it does not matter if we allow for commitment to mixed strategies). 2.2 Commitment to pure strategies We first study how to compute the optimal pure strategy to commit to. This is relatively simple, because the number of strategies to commit to is not very large. (In the following, #outcomes is the number of complete strategy profiles.) Theorem 1. Under commitment to pure strategies, the set of all optimal strategy profiles in a normal-form game can be found in O(#players · #outcomes) time. Proof. Each pure strategy that the first player may commit to will induce a subgame for the remaining players. We can solve each such subgame recursively to find all of its optimal strategy profiles; each of these will give the original leader some utility. Those that give the leader maximal utility correspond exactly to the optimal strategy profiles of the original game. We now present the algorithm formally. Let Su(G, s1) be the subgame that results after the first (remaining) player in G plays s1 ∈ SG 1 . A game with 0 players is simply an outcome of the game. The function Append(s, O) appends the strategy s to each of the vectors of strategies in the set O. Let e be the empty vector with no elements. In a slight abuse of notation, we will write uG 1 (C) when all strategy profiles in the set C give player 1 the same utility in the game G. (Here, player 1 is the first remaining player in the subgame G, not necessarily player 1 in the original game.) We note that arg max is set-valued. Then, the following algorithm computes all optimal strategy profiles: Algorithm Solve(G) if G has 0 players return {e} C ← ∅ for all s1 ∈ SG 1 { O ← Solve(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) if C = ∅ or uG 1 (s1, O ) = uG 1 (C) C ← C∪Append(s1, O ) if uG 1 (s1, O ) > uG 1 (C) C ←Append(s1, O ) } return C Every outcome is (potentially) examined by every player, which leads to the given runtime bound. As an example of how the algorithm works, consider the following 3-player game, in which the first player chooses the left or right matrix, the second player chooses a row, and the third player chooses a column. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 3,0,0 First we eliminate the outcomes that do not correspond to best responses for the third player (removing them from the matrix): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Next, we remove the entries in which the third player does not break ties in favor of the second player, as well as entries that do not correspond to best responses for the second player. 0,1,1 2,1,1 1,1,1 0,5,1 Finally, we remove the entries in which the second and third players do not break ties in favor of the first player, as well as entries that do not correspond to best responses for the first player. 2,1,1 84 Hence, in optimal play, the first player chooses the left matrix, the second player chooses the middle row, and the third player chooses the left column. (We note that this outcome is Pareto-dominated by (Right, Middle, Left).) For general normal-form games, each players utility for each of the outcomes has to be explicitly represented in the input, so that the input size is itself Ω(#players · #outcomes). Therefore, the algorithm is in fact a linear-time algorithm. 2.3 Commitment to mixed strategies In the special case of two-player zero-sum games, computing an optimal mixed strategy for the leader to commit to is equivalent to computing a minimax strategy, which minimizes the maximum expected utility that the opponent can obtain. Minimax strategies constitute the only natural solution concept for two-player zero-sum games: von Neumanns Minimax Theorem [24] states that in two-player zero-sum games, it does not matter (in terms of the players utilities) which player gets to commit to a mixed strategy first, and a profile of mixed strategies is a Nash equilibrium if and only if both strategies are minimax strategies. It is well-known that a minimax strategy can be found in polynomial time, using linear programming [17]. Our first result in this section generalizes this result, showing that an optimal mixed strategy for the leader to commit to can be efficiently computed in general-sum two-player games, again using linear programming. Theorem 2. In 2-player normal-form games, an optimal mixed strategy to commit to can be found in polynomial time using linear programming. Proof. For every pure follower strategy t, we compute a mixed strategy for the leader such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders utility. Such a mixed strategy can be computed using the following simple linear program: maximize s∈S psul(s, t) subject to for all t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1 We note that this program may be infeasible for some follower strategies t, for example, if t is a strictly dominated strategy. Nevertheless, the program must be feasible for at least some follower strategies; among these follower strategies, choose a strategy t∗ that maximizes the linear programs solution value. Then, if the leader chooses as her mixed strategy the optimal settings of the variables ps for the linear program for t∗ , and the follower plays t∗ , this constitutes an optimal strategy profile. In the following result, we show that we cannot expect to solve the problem more efficiently than linear programming, because we can reduce any linear program with a probability constraint on its variables to a problem of computing the optimal mixed strategy to commit to in a 2-player normalform game. Theorem 3. Any linear program whose variables xi (with xi ∈ R≥0 ) must satsify i xi = 1 can be modeled as a problem of computing the optimal mixed strategy to commit to in a 2-player normal-form game. Proof. Let the leader have a pure strategy i for every variable xi. Let the column player have one pure strategy j for every constraint in the linear program (other than i xi = 1), and a single additional pure strategy 0. Let the utility functions be as follows. Writing the objective of the linear program as maximize i cixi, for any i, let ul(i, 0) = ci and uf (i, 0) = 0. Writing the jth constraint of the linear program (not including i xi = 1) as i aijxi ≤ bj, for any i, j > 0, let ul(i, j) = mini ci − 1 and uf (i, j) = aij − bj. For example, consider the following linear program. maximize 2x1 + x2 subject to x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 The optimal solution to this program is x1 = 1/3, x2 = 2/3. Our reduction transforms this program into the following leader-follower game (where the leader is the row player). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 Indeed, the optimal strategy for the leader is to play the top strategy with probability 1/3 and the bottom strategy with probability 2/3. We now show that the reduction works in general. Clearly, the leader wants to incentivize the follower to play 0, because the utility that the leader gets when the follower plays 0 is always greater than when the follower does not play 0. In order for the follower not to prefer playing j > 0 rather than 0, it must be the case that i pl(i)(aij − bj) ≤ 0, or equivalently i pl(i)aij ≤ bj. Hence the leader will get a utility of at least mini ci if and only if there is a feasible solution to the constraints. Given that the pl(i) incentivize the follower to play 0, the leader attempts to maximize i pl(i)ci. Thus the leader must solve the original linear program. As an alternative proof of Theorem 3, one may observe that it is known that finding a minimax strategy in a zerosum game is as hard as the linear programming problem [6], and as we pointed out at the beginning of this section, computing a minimax strategy in a zero-sum game is a special case of the problem of computing an optimal mixed strategy to commit to. This polynomial-time solvability of the problem of computing an optimal mixed strategy to commit to in two-player normal-form games contrasts with the unknown complexity of computing a Nash equilibrium in such games [21], as well as with the NP-hardness of finding a Nash equilibrium with maximum utility for a given player in such games [8, 2]. Unfortunately, this result does not generalize to more than two players-here, the problem becomes NP-hard. To show this, we reduce from the VERTEX-COVER problem. Definition 1. In VERTEX-COVER, we are given a graph G = (V, E) and an integer K. We are asked whether there 85 exists a subset of the vertices S ⊆ V , with |S| = K, such that every edge e ∈ E has at least one of its endpoints in S. BALANCED-VERTEX-COVER is the special case of VERTEX-COVER in which K = |V |/2. VERTEX-COVER is NP-complete [9]. The following lemma shows that the hardness remains if we require K = |V |/2. (Similar results have been shown for other NP-complete problems.) Lemma 1. BALANCED-VERTEX-COVER is NP-complete. Proof. Membership in NP follows from the fact that the problem is a special case of VERTEX-COVER, which is in NP. To show NP-hardness, we reduce an arbitrary VERTEX-COVER instance to a BALANCED-VERTEXCOVER instance, as follows. If, for the VERTEX-COVER instance, K > |V |/2, then we simply add isolated vertices that are disjoint from the rest of the graph, until K = |V |/2. If K < |V |/2, we add isolated triangles (that is, the complete graph on three vertices) to the graph, increasing K by 2 every time, until K = |V |/2. Theorem 4. In 3-player normal-form games, finding an optimal mixed strategy to commit to is NP-hard. Proof. We reduce an arbitrary BALANCED-VERTEXCOVER instance to the following 3-player normal-form game. For every vertex v, each of the three players has a pure strategy corresponding to that vertex (rv, sv, tv, respectively). In addition, for every edge e, the third player has a pure strategy te; and finally, the third player has one additional pure strategy t0. The utilities are as follows: • for all r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • for all r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • for all v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • for all v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • for all v ∈ V , for all r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V | |V |−2 ; • for all e ∈ E, s ∈ S, for both v ∈ e, u3(rv, s, te) = 0; • for all e ∈ E, s ∈ S, for all v /∈ e, u3(rv, s, te) = |V | |V |−2 . • for all r ∈ R, s ∈ S, u3(r, s, t0) = 1. We note that players 1 and 2 have the same utility function. We claim that there is an optimal strategy profile in which players 1 and 2 both obtain 1 (their maximum utility) if and only if there is a solution to the BALANCED-VERTEXCOVER problem. (Otherwise, these players will both obtain 0.) First, suppose there exists a solution to the BALANCEDVERTEX-COVER problem. Then, let player 1 play every rv such that v is in the cover with probability 2 |V | , and let player 2 play every sv such that v is not in the cover with probability 2 |V | . Then, for player 3, the expected utility of playing tv (for any v) is (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of 2 |V | that rv or sv is played. Additionally, the expected utility of playing te (for any e) is at most (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of at least 2 |V | that some rv with v ∈ e is played (because player 1 is randomizing over the pure strategies corresponding to the cover). It follows that playing t0 is a best response for player 3, giving players 1 and 2 a utility of 1. Now, suppose that players 1 and 2 obtain 1 in optimal play. Then, it must be the case that player 3 plays t0. Hence, for every v ∈ V , there must be a probability of at least 2 |V | that either rv or sv is played, for otherwise player 3 would be better off playing tv. Because players 1 and 2 have only a total probability of 2 to distribute, it must be the case that for each v, either rv or sv is played with probability 2 |V | , and the other is played with probability 0. (It is not possible for both to have nonzero probability, because then there would be some probability that both are played simultaneously (correlation is not possible), hence the total probability of at least one being played could not be high enough for all vertices.) Thus, for exactly half the v ∈ V , player 1 places probability 2 |V | on rv. Moreover, for every e ∈ E, there must be a probability of at least 2 |V | that some rv with v ∈ e is played, for otherwise player 3 would be better off playing te. Thus, the v ∈ V such that player 1 places probability 2 |V | on rv constitute a balanced vertex cover. 3. BAYESIAN GAMES So far, we have restricted our attention to normal-form games. In a normal-form game, it is assumed that every agent knows every other agents preferences over the outcomes of the game. In general, however, agents may have some private information about their preferences that is not known to the other agents. Moreover, at the time of commitment to a strategy, the agents may not even know their own (final) preferences over the outcomes of the game yet, because these preferences may be dependent on a context that has yet to materialize. For example, when the code for a trading agent is written, it may not yet be clear how that agent will value resources that it will negotiate over later, because this depends on information that is not yet available at the time at which the code is written (such as orders that will have been placed to the agent before the negotiation). In this section, we will study commitment in Bayesian games, which can model such uncertainty over preferences. 3.1 Definitions In a Bayesian game, every player i has a set of actions Si, a set of types Θi with an associated probability distribution πi : Θi → [0, 1], and, for each type θi, a utility function uθi i : S1 × S2 × . . . × Sn → R. A pure strategy in a Bayesian game is a mapping from the players types to actions, σi : Θi → Si. (Bayesian games can be rewritten in normal form by enumerating every pure strategy σi, but this will cause an exponential blowup in the size of the representation of the game and therefore cannot lead to efficient algorithms.) The strategy that the leader should commit to depends on whether, at the time of commitment, the leader knows her own type. If the leader does know her own type, the other types that the leader might have had become irrelevant and the leader should simply commit to the strategy that is optimal for the type. However, as argued above, the leader does not necessarily know her own type at the time of commitment (e.g., the time at which the code is submitted). In this case, the leader must commit to a strategy that is 86 dependent upon the leaders eventual type. We will study this latter model, although we will pay specific attention to the case where the leader has only a single type, which is effectively the same as the former model. 3.2 Commitment to pure strategies It turns out that computing an optimal pure strategy to commit to is hard in Bayesian games, even with two players. Theorem 5. Finding an optimal pure strategy to commit to in 2-player Bayesian games is NP-hard, even when the follower has only a single type. Proof. We reduce an arbitrary VERTEX-COVER instance to the following Bayesian game between the leader and the follower. The leader has K types θ1, θ2, . . . , θK , each occurring with probability 1/K, and for every vertex v ∈ V , the leader has an action sv. The follower has only a single type; for each edge e ∈ E, the follower has an action te, and the follower has a single additional action t0. The utility function for the leader is given by, for all θl ∈ Θl and all s ∈ S, u θl l (s, t0) = 1, and for all e ∈ E, u θl l (s, te) = 0. The followers utility is given by: • For all v ∈ V , for all e ∈ E with v /∈ e, uf (sv, te) = 1; • For all v ∈ V , for all e ∈ E with v ∈ e, uf (sv, te) = −K; • For all v ∈ V , uf (sv, t0) = 0. We claim that the leader can get a utility of 1 if and only if there is a solution to the VERTEX-COVER instance. First, suppose that there is a solution to the VERTEXCOVER instance. Then, the leader can commit to a pure strategy such that for each vertex v in the cover, the leader plays sv for some type. Then, the followers utility for playing te (for any e ∈ E) is at most K−1 K + 1 K (−K) = − 1 K , so that the follower will prefer to play t0, which gives the leader a utility of 1, as required. Now, suppose that there is a pure strategy for the leader that will give the leader a utility of 1. Then, the follower must play t0. In order for the follower not to prefer playing te (for any e ∈ E) instead, for at least one v ∈ e the leader must play sv for some type θl. Hence, the set of vertices v that the leader plays for some type must constitute a vertex cover; and this set can have size at most K, because the leader has only K types. So there is a solution to the VERTEXCOVER instance. However, if the leader has only a single type, then the problem becomes easy again (#types is the number of types for the follower): Theorem 6. In 2-player Bayesian games in which the leader has only a single type, an optimal pure strategy to commit to can be found in O(#outcomes · #types) time. Proof. For every leader action s, we can compute, for every follower type θf ∈ Θf , which actions t maximize the followers utility; call this set of actions BRθf (s). Then, the utility that the leader receives for committing to action s can be computed as θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), and the leader can choose the best action to commit to. 3.3 Commitment to mixed strategies In two-player zero-sum imperfect information games with perfect recall (no player ever forgets something that it once knew), a minimax strategy can be constructed in polynomial time [12, 13]. Unfortunately, this result does not extend to computing optimal mixed strategies to commit to in the general-sum case-not even in Bayesian games. We will exhibit NP-hardness by reducing from the INDEPENDENTSET problem. Definition 2. In INDEPENDENT-SET, we are given a graph G = (V, E) and an integer K. We are asked whether there exists a subset of the vertices S ⊆ V , with |S| = K, such that no edge e ∈ E has both of its endpoints in S. Again, this problem is NP-complete [9]. Theorem 7. Finding an optimal mixed strategy to commit to in 2-player Bayesian games is NP-hard, even when the leader has only a single type and the follower has only two actions. Proof. We reduce an arbitrary INDEPENDENT-SET instance to the following Bayesian game between the leader and the follower. The leader has only a single type, and for every vertex v ∈ V , the leader has an action sv. The follower has a type θv for every v ∈ V , occurring with probability 1 (|E|+1)|V | , and a type θe for every e ∈ E, occurring with probability 1 |E|+1 . The follower has two actions: t0 and t1. The leaders utility is given by, for all s ∈ S, ul(s, t0) = 1 and ul(s, t1) = 0. The followers utility is given by: • For all v ∈ V , uθv f (sv, t1) = 0; • For all v ∈ V and s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • For all v ∈ V and s ∈ S, uθv f (s, t0) = 1; • For all e ∈ E, s ∈ S, uθe f (s, t0) = 1; • For all e ∈ E, for both v ∈ e, uθe f (sv, t1) = 2K 3 ; • For all e ∈ E, for all v /∈ e, uθe f (sv, t1) = 0. We claim that an optimal strategy to commit to gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | if and only if there is a solution to the INDEPENDENT-SET instance. First, suppose that there is a solution to the INDEPENDENT-SET instance. Then, the leader could commit to the following strategy: for every vertex v in the independent set, play the corresponding sv with probability 1/K. If the follower has type θe for some e ∈ E, the expected utility for the follower of playing t1 is at most 1 K 2K 3 = 2/3, because there is at most one vertex v ∈ e such that sv is played with nonzero probability. Hence, the follower will play t0 and obtain a utility of 1. If the follower has type θv for some vertex v in the independent set, the expected utility for the follower of playing t1 is K−1 K K K−1 = 1, because the leader plays sv with probability 1/K. It follows that the follower (who breaks ties to maximize the leaders utility) will play t0, which also gives a utility of 1 and gives the leader a higher utility. Hence the leaders expected utility for this strategy is at least |E| |E|+1 + K (|E|+1)|V | , as required. 87 Now, suppose that there is a strategy that gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | . Then, this strategy must induce the follower to play t0 whenever it has a type of the form θe (because otherwise, the utility could be at most |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ). Thus, it cannot be the case that for some edge e = (v1, v2) ∈ E, the probability that the leader plays one of sv1 and sv2 is at least 2/K, because then the expected utility for the follower of playing t1 when it has type θe would be at least 2 K 2K 3 = 4/3 > 1. Moreover, the strategy must induce the follower to play t0 for at least K types of the form θv. Inducing the follower to play t0 when it has type θv can be done only by playing sv with probability at least 1/K, which will give the follower a utility of at most K−1 K K K−1 = 1 for playing t1. But then, the set of vertices v such that sv is played with probability at least 1/K must constitute an independent set of size K (because if there were an edge e between two such vertices, it would induce the follower to play t1 for type θe by the above). By contrast, if the follower has only a single type, then we can generalize the linear programming approach for normalform games: Theorem 8. In 2-player Bayesian games in which the follower has only a single type, an optimal mixed strategy to commit to can be found in polynomial time using linear programming. Proof. We generalize the approach in Theorem 2 as follows. For every pure follower strategy t, we compute a mixed strategy for the leader for every one of the leaders types such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders ex ante expected utility. To do so, we generalize the linear program as follows: maximize θl∈Θl π(θl) s∈S pθl s uθl l (s, t) subject to for all t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t ) for all θl ∈ Θl, s∈S p θl s = 1 As in Theorem 2, the solution for the linear program that maximizes the solution value is an optimal strategy to commit to. This shows an interesting contrast between commitment to pure strategies and commitment to mixed strategies in Bayesian games: for pure strategies, the problem becomes easy if the leader has only a single type (but not if the follower has only a single type), whereas for mixed strategies, the problem becomes easy if the follower has only a single type (but not if the leader has only a single type). 4. CONCLUSIONS AND FUTURE RESEARCH In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously. This requires some equilibrium notion (Nash equilibrium and its refinements), and often leads to the equilibrium selection problem: it is unclear to each individual player according to which equilibrium she should play. However, this model is not always realistic. In many settings, one player is able to commit to a strategy before the other player makes a decision. For example, one agent may arrive at the (real or virtual) site of the game before the other, or, in the specific case of software agents, the code for one agent may be completed and committed before that of another agent. Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously. Specifically, if commitment to mixed strategies is possible, then (optimal) commitment never hurts the leader, and often helps. The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position). In this paper, we studied how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games. For normal-form games, we showed that the optimal pure strategy to commit to can be found efficiently for any number of players. An optimal mixed strategy to commit to in a normal-form game can be found efficiently for two players using linear programming (and no more efficiently than that, in the sense that any linear program with a probability constraint can be encoded as such a problem). (This is a generalization of the polynomial-time computability of minimax strategies in normal-form games.) The problem becomes NP-hard for three (or more) players. In Bayesian games, the problem of finding an optimal pure strategy to commit to is NP-hard even in two-player games in which the follower has only a single type, although two-player games in which the leader has only a single type can be solved efficiently. The problem of finding an optimal mixed strategy to commit to in a Bayesian game is NP-hard even in two-player games in which the leader has only a single type, although two-player games in which the follower has only a single type can be solved efficiently using a generalization of the linear progamming approach for normal-form games. The following two tables summarize these results. 2 players ≥ 3 players normal-form O(#outcomes) O(#outcomes· #players) Bayesian, O(#outcomes· NP-hard 1-type leader #types) Bayesian, NP-hard NP-hard 1-type follower Bayesian (general) NP-hard NP-hard Results for commitment to pure strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.) 88 2 players ≥ 3 players normal-form one LP-solve per NP-hard follower action Bayesian, NP-hard NP-hard 1-type leader Bayesian, one LP-solve per NP-hard 1-type follower follower action Bayesian (general) NP-hard NP-hard Results for commitment to mixed strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.) Future research can take a number of directions. First, we can empirically evaluate the techniques presented here on test suites such as GAMUT [19]. We can also study the computation of optimal strategies to commit to in other1 concise representations of normal-form games-for example, in graphical games [10] or local-effect/action graph games [14, 1]. For the cases where computing an optimal strategy to commit to is NP-hard, we can also study the computation of approximately optimal strategies to commit to. While the correct definition of an approximately optimal strategy is in this setting may appear simple at first-it should be a strategy that, if the following players play optimally, performs almost as well as the optimal strategy in expectation-this definition becomes problematic when we consider that the other players may also be playing only approximately optimally. One may also study models in which multiple (but not all) players commit at the same time. Another interesting direction to pursue is to see if computing optimal mixed strategies to commit to can help us in, or otherwise shed light on, computing Nash equilibria. Often, optimal mixed strategies to commit to are also Nash equilibrium strategies (for example, in two-player zero-sum games this is always true), although this is not always the case (for example, as we already pointed out, sometimes the optimal strategy to commit to is a strictly dominated strategy, which can never be a Nash equilibrium strategy). 5. REFERENCES [1] N. A. R. Bhat and K. Leyton-Brown. Computing Nash equilibria of action-graph games. In Proceedings of the 20th Annual Conference on Uncertainty in Artificial Intelligence (UAI), Banff, Canada, 2004. [2] V. Conitzer and T. Sandholm. Complexity results about Nash equilibria. In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pages 765-771, Acapulco, Mexico, 2003. [3] V. Conitzer and T. Sandholm. Complexity of (iterated) dominance. In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 88-97, Vancouver, Canada, 2005. [4] V. Conitzer and T. Sandholm. A generalized strategy eliminability criterion and computational methods for applying it. In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 483-488, Pittsburgh, PA, USA, 2005. [5] A. A. Cournot. Recherches sur les principes math´ematiques de la th´eorie des richesses (Researches 1 Bayesian games are one potentially concise representation of normal-form games. into the Mathematical Principles of the Theory of Wealth). Hachette, Paris, 1838. [6] G. Dantzig. A proof of the equivalence of the programming problem and the game problem. In T. Koopmans, editor, Activity Analysis of Production and Allocation, pages 330-335. John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel. The complexity of eliminating dominated strategies. Mathematics of Operation Research, 18:553-565, 1993. [8] I. Gilboa and E. Zemel. Nash and correlated equilibria: Some complexity considerations. Games and Economic Behavior, 1:80-93, 1989. [9] R. Karp. Reducibility among combinatorial problems. In R. E. Miller and J. W. Thatcher, editors, Complexity of Computer Computations, pages 85-103. Plenum Press, NY, 1972. [10] M. Kearns, M. Littman, and S. Singh. Graphical models for game theory. In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou, and J. N. Tsitsiklis. A note on strategy elimination in bimatrix games. Operations Research Letters, 7(3):103-107, 1988. [12] D. Koller and N. Megiddo. The complexity of two-person zero-sum games in extensive form. Games and Economic Behavior, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo, and B. von Stengel. Efficient computation of equilibria for extensive two-person games. Games and Economic Behavior, 14(2):247-259, 1996. [14] K. Leyton-Brown and M. Tennenholtz. Local-effect games. In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), Acapulco, Mexico, 2003. [15] R. Lipton, E. Markakis, and A. Mehta. Playing large games using simple strategies. In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 36-41, San Diego, CA, 2003. [16] M. Littman and P. Stone. A polynomial-time Nash equilibrium algorithm for repeated games. In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 48-54, San Diego, CA, 2003. [17] R. D. Luce and H. Raiffa. Games and Decisions. John Wiley and Sons, New York, 1957. Dover republication 1989. [18] J. Nash. Equilibrium points in n-person games. Proc. of the National Academy of Sciences, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown, and Y. Shoham. Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms. In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), New York, NY, USA, 2004. [20] M. J. Osborne and A. Rubinstein. A Course in Game Theory. MIT Press, 1994. [21] C. Papadimitriou. Algorithms, games and the Internet. In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 749-753, 2001. 89 [22] R. Porter, E. Nudelman, and Y. Shoham. Simple search methods for finding a Nash equilibrium. In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 664-669, San Jose, CA, USA, 2004. [23] T. Sandholm, A. Gilpin, and V. Conitzer. Mixed-integer programming methods for finding Nash equilibria. In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 495-501, Pittsburgh, PA, USA, 2005. [24] J. von Neumann. Zur Theorie der Gesellschaftsspiele. Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg. Marktform und Gleichgewicht. Springer, Vienna, 1934. [26] B. von Stengel and S. Zamir. Leadership with commitment to mixed strategies. CDAM Research Report LSE-CDAM-2004-01, London School of Economics, Feb. 2004. 90",
    "original_translation": "En sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias simultáneamente. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. El reciente aumento en el interés por las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas a comprometerse tanto en el compromiso de estrategias puras como en el compromiso de estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Ofrecemos tanto resultados positivos (algoritmos eficientes) como resultados negativos (resultados de NP-hardness). Categorías y Descriptores de Asignaturas J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas Términos Generales Algoritmos, Economía, Teoría 1. En sistemas multiagentes con agentes auto-interesados (incluyendo la mayoría de los entornos económicos), la acción óptima que un agente debe tomar depende de las acciones que tomen los otros agentes. Para analizar cómo un agente debería comportarse en tales situaciones, es necesario aplicar las herramientas de la teoría de juegos. Normalmente, cuando se modela un escenario estratégico en el marco de la teoría de juegos, se asume que los jugadores eligen sus estrategias de forma simultánea. Esto es especialmente cierto cuando el escenario se modela como un juego en forma normal, que solo especifica la utilidad de cada agente como una función del vector de estrategias que los agentes eligen, y no proporciona información sobre el orden en que los agentes toman sus decisiones y lo que los agentes observan sobre las decisiones anteriores de otros agentes. Dado que el juego está modelado en forma normal, típicamente se analiza utilizando el concepto de equilibrio de Nash. Un equilibrio de Nash especifica una estrategia para cada jugador, de modo que ningún jugador tenga un incentivo para desviarse individualmente de este perfil de estrategias. (Por lo general, se permite que las estrategias sean mixtas, es decir, distribuciones de probabilidad sobre las estrategias originales (puras).) Un equilibrio de Nash (de estrategia mixta) está garantizado de existir en juegos finitos [18], pero un problema es que puede haber múltiples equilibrios de Nash. Esto conduce al problema de selección de equilibrio de cómo un agente puede saber qué estrategia jugar si no sabe qué equilibrio se va a jugar. Cuando el escenario se modela como un juego de forma extensiva, es posible especificar que algunos jugadores reciben información sobre las acciones tomadas por otros antes en el juego antes de decidir su acción. Sin embargo, en general, los jugadores no saben todo lo que sucedió anteriormente en el juego. Por lo tanto, estos juegos suelen ser analizados todavía utilizando un concepto de equilibrio, donde se especifica una estrategia mixta para cada jugador, y se requiere que la estrategia de cada jugador sea una mejor respuesta a las estrategias de los demás. (Normalmente se impone ahora una restricción adicional en las estrategias para garantizar que los jugadores no jueguen de una manera irracional con respecto a la información que han recibido hasta el momento). Esto conduce a refinamientos del equilibrio de Nash como el equilibrio perfecto en subjuegos y el equilibrio secuencial. Sin embargo, en muchos entornos del mundo real, las estrategias no se seleccionan de manera simultánea. A menudo, un jugador (el líder) puede comprometerse con una estrategia antes que otro jugador (el seguidor). Esto puede deberse a una variedad de razones. Por ejemplo, uno de los jugadores puede llegar al lugar donde se jugará el juego antes que otro agente (por ejemplo, en entornos económicos, un jugador puede ingresar al mercado antes y comprometerse con una forma de hacer negocios). Un compromiso tan poderoso tiene un impacto profundo en cómo debería jugarse el juego. Por ejemplo, el líder puede estar mejor jugando una estrategia que esté dominada en la representación de forma normal del juego. Quizás el ejemplo más temprano y conocido del efecto del compromiso es el de von Stackelberg [25], quien demostró que, en el modelo de duopolio de Cournot [5], si una empresa puede comprometerse con una cantidad de producción primero, esa empresa lo hará mucho mejor que en la solución de movimiento simultáneo (Nash). En general, si es posible comprometerse con estrategias mixtas, entonces (bajo suposiciones menores) nunca perjudica, y a menudo ayuda, comprometerse con una estrategia [26]. Verse obligado a comprometerse con una estrategia pura a veces ayuda y a veces perjudica (por ejemplo, comprometerse con una estrategia pura en piedra-papel-tijeras antes de la decisión de los otros jugadores naturalmente resultará en una derrota). En este documento, asumiremos que el compromiso siempre es forzado; si no lo es, el jugador que tiene la opción de comprometerse simplemente puede comparar el resultado del compromiso con el resultado de no comprometerse (movimiento simultáneo). Los modelos de liderazgo son especialmente importantes en entornos con múltiples agentes de software con intereses propios. Una vez que el código de un agente (o de un equipo de agentes) está finalizado y el agente es desplegado, el agente se compromete a jugar la estrategia (posiblemente aleatoria) que el código prescribe. Por lo tanto, siempre y cuando se pueda demostrar de manera creíble que no se puede cambiar el código más tarde, el código funciona como un dispositivo de compromiso. Esto es válido para torneos recreativos entre agentes (por ejemplo, torneos de póker, RoboSoccer) y para aplicaciones industriales como redes de sensores. Finalmente, también existe una situación de liderazgo implícito en el campo del diseño de mecanismos, en la cual un jugador (el diseñador) tiene la oportunidad de elegir las reglas del juego que los demás jugadores luego siguen. El diseño de mecanismos es un tema extremadamente importante para la comunidad de EC: los artículos publicados sobre diseño de mecanismos en las recientes conferencias de EC son demasiados para citar. De hecho, el diseñador del mecanismo puede beneficiarse al comprometerse con una elección que, si las acciones de los agentes (restantes) estuvieran fijas, sería subóptima. Por ejemplo, en una subasta (a precio fijo), el vendedor puede desear establecer un precio de reserva positivo (artificial) para el artículo, por debajo del cual el artículo no se venderá, incluso si el vendedor valora el artículo en 0. En retrospectiva (después de recibir las ofertas), esto (ingenuamente) parece subóptimo: si llegaba una oferta que superaba el precio de reserva, el precio de reserva no tenía efecto, y si no llegaba tal oferta, el vendedor hubiera estado mejor aceptando una oferta más baja. Por supuesto, la razón para establecer el precio de reserva es incentivar a los postores a ofertar más alto, y debido a esto, establecer precios de reserva artificiales puede aumentar realmente los ingresos esperados para el vendedor. Recientemente se ha dedicado una cantidad significativa de investigación al cálculo de soluciones de acuerdo con varios conceptos de solución para escenarios en los que los agentes eligen sus estrategias simultáneamente, como la dominancia [7, 11, 3] y (especialmente) el equilibrio de Nash [8, 21, 16, 15, 2, 22, 23, 4]. Sin embargo, se ha ignorado el cálculo de la estrategia óptima a comprometerse en una situación de liderazgo. Teóricamente, las situaciones de liderazgo simplemente pueden ser consideradas como un juego de forma extensiva en el que un jugador elige una estrategia (para el juego original) primero. El número de estrategias en este juego de forma extensiva, sin embargo, puede ser extremadamente grande. Por ejemplo, si el líder es capaz de comprometerse con una estrategia mixta en el juego original, entonces cada una de las estrategias mixtas (continuo de) constituye una estrategia pura en la representación de forma extensiva de la situación de liderazgo. (Se destaca que un compromiso con una distribución no es lo mismo que una distribución sobre compromisos). Además, si el juego original es en sí mismo un juego de forma extensiva, el número de estrategias en la representación de forma extensiva de la situación de liderazgo (que es un juego de forma extensiva diferente) se vuelve aún más grande. Por lo tanto, generalmente no es factible computacionalmente simplemente transformar el juego original en la representación de forma extensiva de la situación de liderazgo; en su lugar, debemos analizar el juego en su representación original. En este artículo, estudiamos cómo calcular la estrategia óptima a comprometerse, tanto en juegos de forma normal (Sección 2) como en juegos bayesianos, que son un caso especial de juegos de forma extensiva (Sección 3). JUEGOS EN FORMA NORMAL En esta sección, estudiamos cómo calcular la estrategia óptima a comprometerse para juegos representados en forma normal. 2.1 Definiciones En un juego en forma normal, cada jugador i ∈ {1, . . . , n} tiene un conjunto de estrategias puras (o acciones) Si, y una función de utilidad ui : S1×S2×. . .×Sn → R que mapea cada resultado (un vector que consiste en una estrategia pura para cada jugador, también conocido como un perfil de estrategias puras) a un número real. Para facilitar la notación, en el caso de dos jugadores, nos referiremos al conjunto de estrategias puras del jugador 1 como S, y al conjunto de estrategias puras del jugador 2 como T. Estos juegos pueden representarse en forma de matriz (bi-matriz), en la que las filas corresponden a las estrategias puras del jugador 1, las columnas corresponden a las estrategias puras del jugador 2, y las entradas de la matriz dan las utilidades de los jugadores de fila y columna (en ese orden) para el resultado correspondiente del juego. En el caso de tres jugadores, usaremos R, S y T, para las estrategias puras de los jugadores 1, 2 y 3, respectivamente. Una estrategia mixta para un jugador es una distribución de probabilidad sobre las estrategias puras de ese jugador. En el caso de juegos de dos jugadores, nos referiremos al jugador 1 como el líder y al jugador 2 como el seguidor. Antes de definir estrategias de liderazgo óptimas, considera el siguiente juego que ilustra el efecto de la capacidad del líder para comprometerse. 2, 1 4, 0 1, 0 3, 1 En esta representación en forma normal, la estrategia inferior para el jugador de la fila está estrictamente dominada por la estrategia superior. Sin embargo, si el jugador de la fila tiene la capacidad de comprometerse con una estrategia pura antes de que el jugador de la columna elija su estrategia, el jugador de la fila debería comprometerse con la estrategia inferior: al hacerlo, el jugador de la columna preferirá jugar la estrategia correcta, lo que llevará a una utilidad de 3 para el jugador de la fila. Por el contrario, si el jugador de la fila se comprometiera con la estrategia superior, el jugador de la columna preferiría jugar la estrategia izquierda, lo que llevaría a una utilidad de solo 2 para el jugador de la fila. Si el jugador de la fila puede comprometerse a una estrategia mixta, entonces puede obtener una utilidad aún mayor (esperada): si el jugador de la fila se compromete a colocar una probabilidad p > 1/2 en la estrategia inferior, entonces el jugador de la columna seguirá prefiriendo jugar la estrategia derecha, y la utilidad esperada de los jugadores de la fila será 3p + 4(1 − p) = 4 − p ≥ 3. Si el jugador de la fila juega cada estrategia con una probabilidad exacta de 1/2, el jugador de la columna está 83 indiferente entre las estrategias. En tales casos, asumiremos que el jugador de la columna elegirá la estrategia que maximiza la utilidad de los jugadores de la fila (en este caso, la estrategia correcta). Por lo tanto, la estrategia mixta óptima a la que debe comprometerse el jugador de la fila es p = 1/2. Hay algunas buenas razones para esta suposición. Si asumiéramos lo contrario, entonces no existiría una estrategia óptima para el jugador de la fila en el juego de ejemplo: el jugador de la fila jugaría la estrategia inferior con una probabilidad p = 1/2 + con > 0, y cuanto menor sea , mejor será la utilidad para el jugador de la fila. Por el contrario, si asumimos que el seguidor siempre rompe los empates a favor de los líderes, entonces siempre existe una estrategia mixta óptima para el líder, lo que corresponde a un equilibrio perfecto en subjuegos de la representación en forma extensiva de la situación de liderazgo. En cualquier caso, esta es una suposición estándar para tales modelos (por ejemplo, [20]), aunque algunos trabajos han investigado lo que puede suceder en los otros equilibrios perfectos de subjuego [26]. (Para juegos genéricos de dos jugadores, el pago del equilibrio perfecto de subjuego de los líderes es único). Además, la misma suposición se utiliza típicamente en el diseño de mecanismos, asumiendo que si un agente es indiferente entre revelar sus preferencias de manera veraz o falsa, las reportará de manera veraz. Dado este supuesto, podemos hacer referencia de manera segura a estrategias de liderazgo óptimas en lugar de tener que utilizar alguna noción de equilibrio. Por lo tanto, para los propósitos de este documento, una estrategia óptima a comprometerse en un juego de 2 jugadores es una estrategia s ∈ S que maximiza maxt∈BR(s) ul(s, t), donde BR(s) = arg maxt∈T uf (s, t). (ul y uf son las funciones de utilidad del líder y los seguidores, respectivamente). Podemos tener S = S para el caso de compromiso con estrategias puras, o S = ∆(S), el conjunto de distribuciones de probabilidad sobre S, para el caso de compromiso con estrategias mixtas. (Observamos que reemplazar T por ∆(T) no hace ninguna diferencia en esta definición). Para juegos con más de dos jugadores, en los que los jugadores se comprometen con sus estrategias en secuencia, definimos estrategias óptimas a las que comprometerse de forma recursiva. Después de que el líder se compromete con una estrategia, el juego que jugarán los agentes restantes es en sí mismo un juego de liderazgo (más pequeño). Por lo tanto, definimos una estrategia óptima a comprometerse como una estrategia que maximiza la utilidad del líder, asumiendo que el juego de los agentes restantes es óptimo bajo esta definición, y maximiza la utilidad del líder entre todas las formas óptimas de jugar el juego restante. Nuevamente, el compromiso con estrategias mixtas puede o no ser una posibilidad para cada jugador (aunque para el último jugador no importa si permitimos el compromiso con estrategias mixtas). 2.2 Compromiso con estrategias puras. Primero estudiamos cómo calcular la estrategia pura óptima a la que comprometerse. Esto es relativamente simple, porque el número de estrategias a comprometer no es muy grande. (En lo siguiente, #resultados es el número de perfiles de estrategia completos). Teorema 1. Bajo el compromiso de estrategias puras, el conjunto de todos los perfiles de estrategia óptimos en un juego en forma normal se puede encontrar en tiempo O(#jugadores · #resultados). Prueba. Cada estrategia pura a la que el primer jugador pueda comprometerse inducirá un subjuego para los jugadores restantes. Podemos resolver cada subjuego de esta manera de forma recursiva para encontrar todos sus perfiles de estrategia óptimos; cada uno de estos le dará al líder original cierta utilidad. Aquellos que proporcionan al líder la utilidad máxima corresponden exactamente a los perfiles de estrategia óptimos del juego original. Ahora presentamos el algoritmo de forma formal. Sea Su(G, s1) el subjuego que resulta después de que el primer jugador restante en G juega s1 ∈ SG 1. Un juego con 0 jugadores es simplemente un resultado del juego. La función Append(s, O) añade la estrategia s a cada uno de los vectores de estrategias en el conjunto O. Sea e el vector vacío sin elementos. En un ligero abuso de notación, escribiremos uG 1 (C) cuando todos los perfiles estratégicos en el conjunto C le den al jugador 1 la misma utilidad en el juego G. (Aquí, el jugador 1 es el primer jugador restante en el subjuego G, no necesariamente el jugador 1 en el juego original). Observamos que arg max es un conjunto de valores. Entonces, el siguiente algoritmo calcula todos los perfiles de estrategia óptimos: Algoritmo Resolver(G) si G tiene 0 jugadores, devuelve {e} C ← ∅ para todo s1 ∈ SG 1 { O ← Resolver(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) si C = ∅ o uG 1 (s1, O ) = uG 1 (C) C ← C∪Agregar(s1, O ) si uG 1 (s1, O ) > uG 1 (C) C ←Agregar(s1, O ) } devuelve C Cada resultado es examinado (potencialmente) por cada jugador, lo que lleva al límite de tiempo dado. Como ejemplo de cómo funciona el algoritmo, considera el siguiente juego de 3 jugadores, en el que el primer jugador elige la matriz izquierda o derecha, el segundo jugador elige una fila y el tercer jugador elige una columna. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 Primero eliminamos los resultados que no corresponden a las mejores respuestas para el tercer jugador (eliminándolos de la matriz): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Luego, eliminamos las entradas en las que el tercer jugador no resuelve los empates a favor del segundo jugador, así como las entradas que no corresponden a las mejores respuestas para el segundo jugador. 0,1,1 2,1,1 1,1,1 0,5,1 Finalmente, eliminamos las entradas en las que el segundo y tercer jugador no resuelven los empates a favor del primer jugador, así como las entradas que no corresponden a las mejores respuestas para el primer jugador. 2,1,1 Por lo tanto, en el juego óptimo, el primer jugador elige la matriz izquierda, el segundo jugador elige la fila del medio y el tercer jugador elige la columna izquierda. (Notamos que este resultado está dominado por Pareto por (Derecha, Medio, Izquierda).) Para juegos en forma normal general, la utilidad de cada jugador para cada uno de los resultados debe representarse explícitamente en la entrada, de modo que el tamaño de la entrada sea en sí mismo Ω(#jugadores · #resultados). Por lo tanto, el algoritmo es de hecho un algoritmo de tiempo lineal. 2.3 Compromiso con estrategias mixtas En el caso especial de juegos de dos jugadores de suma cero, calcular una estrategia mixta óptima para que el líder se comprometa es equivalente a calcular una estrategia minimax, que minimiza la utilidad esperada máxima que el oponente puede obtener. Las estrategias minimax constituyen el único concepto de solución natural para juegos de suma cero de dos jugadores: el Teorema Minimax de von Neumann [24] establece que en juegos de suma cero de dos jugadores, no importa (en términos de las utilidades de los jugadores) qué jugador se compromete primero a una estrategia mixta, y un perfil de estrategias mixtas es un equilibrio de Nash si y solo si ambas estrategias son estrategias minimax. Es bien sabido que una estrategia minimax se puede encontrar en tiempo polinómico, utilizando programación lineal [17]. Nuestro primer resultado en esta sección generaliza este resultado, mostrando que una estrategia mixta óptima para que el líder se comprometa puede ser calculada eficientemente en juegos de dos jugadores de suma general, nuevamente utilizando programación lineal. Teorema 2. En juegos de forma normal de 2 jugadores, una estrategia mixta óptima a la que comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal. Prueba. Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder de modo que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad del líder. Un programa lineal simple puede calcular una estrategia mixta como la siguiente: maximizar s∈S psul(s, t) sujeto a que para todo t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1. Se destaca que este programa puede ser inviable para algunas estrategias seguidoras t, por ejemplo, si t es una estrategia estrictamente dominada. Sin embargo, el programa debe ser factible para al menos algunas estrategias seguidoras; entre estas estrategias seguidoras, elige una estrategia t∗ que maximice el valor de la solución de los programas lineales. Entonces, si la líder elige como su estrategia mixta los ajustes óptimos de las variables ps para el programa lineal para t∗, y el seguidor juega t∗, esto constituye un perfil de estrategia óptimo. En el siguiente resultado, demostramos que no podemos esperar resolver el problema de manera más eficiente que la programación lineal, ya que podemos reducir cualquier programa lineal con una restricción de probabilidad en sus variables a un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores. Teorema 3. Cualquier programa lineal cuyas variables xi (con xi ∈ R≥0) deben satisfacer i xi = 1 puede ser modelado como un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores. Prueba. Que el líder tenga una estrategia pura i para cada variable xi. Que el jugador de la columna tenga una estrategia pura j para cada restricción en el programa lineal (distinta de i xi = 1), y una única estrategia pura adicional 0. Que las funciones de utilidad sean las siguientes. Escribiendo el objetivo del programa lineal como maximizar ci xi, para cualquier i, dejando ul(i, 0) = ci y uf(i, 0) = 0. Escribiendo la j-ésima restricción del programa lineal (sin incluir i xi = 1) como i aijxi ≤ bj, para cualquier i, j > 0, sea ul(i, j) = mini ci − 1 y uf(i, j) = aij − bj. Por ejemplo, considera el siguiente programa lineal. maximizar 2x1 + x2 sujeto a x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 La solución óptima de este programa es x1 = 1/3, x2 = 2/3. Nuestra reducción transforma este programa en el siguiente juego de líder-seguidor (donde el líder es el jugador de la fila). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 De hecho, la estrategia óptima para el líder es jugar la estrategia superior con una probabilidad de 1/3 y la estrategia inferior con una probabilidad de 2/3. Ahora demostramos que la reducción funciona en general. Claramente, el líder quiere incentivar al seguidor a jugar 0, porque la utilidad que el líder obtiene cuando el seguidor juega 0 siempre es mayor que cuando el seguidor no juega 0. Para que el seguidor no prefiera jugar j > 0 en lugar de 0, debe ser el caso que i pl(i)(aij − bj) ≤ 0, o equivalentemente i pl(i)aij ≤ bj. Por lo tanto, el líder obtendrá una utilidad de al menos mini ci si y solo si hay una solución factible a las restricciones. Dado que el pl(i) incentiva al seguidor a jugar 0, el líder intenta maximizar i pl(i)ci. Por lo tanto, el líder debe resolver el programa lineal original. Como prueba alternativa del Teorema 3, se puede observar que se sabe que encontrar una estrategia minimax en un juego de suma cero es tan difícil como el problema de programación lineal [6], y como señalamos al principio de esta sección, calcular una estrategia minimax en un juego de suma cero es un caso especial del problema de calcular una estrategia mixta óptima a la que comprometerse. La solubilidad en tiempo polinómico del problema de calcular una estrategia mixta óptima a la que comprometerse en juegos de forma normal de dos jugadores contrasta con la complejidad desconocida de calcular un equilibrio de Nash en tales juegos [21], así como con la NP-dificultad de encontrar un equilibrio de Nash con utilidad máxima para un jugador dado en tales juegos [8, 2]. Desafortunadamente, este resultado no se generaliza a más de dos jugadores; aquí, el problema se vuelve NP-duro. Para demostrar esto, reducimos desde el problema de CUBRIR-VÉRTICES. Definición 1. En VERTEX-COVER, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que cada arista e ∈ E tenga al menos uno de sus extremos en S. BALANCED-VERTEX-COVER es el caso especial de VERTEX-COVER en el que K = |V|/2. VERTEX-COVER es NP-completo [9]. El siguiente lema muestra que la dificultad persiste si requerimos K = |V|/2. (Resultados similares se han demostrado para otros problemas NP-completos). Lema 1. El problema de la COBERTURA DE VÉRTICES EQUILIBRADA es NP-completo. Prueba. La pertenencia a NP se deriva del hecho de que el problema es un caso especial de CUBRIMIENTO DE VÉRTICES, que está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES a una instancia de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO, de la siguiente manera. Si, para la instancia de CUBRIMIENTO DE VÉRTICES, K > |V|/2, simplemente agregamos vértices aislados que estén disjuntos del resto del grafo, hasta que K = |V|/2. Si K < |V|/2, agregamos triángulos aislados (es decir, el grafo completo de tres vértices) al grafo, aumentando K en 2 cada vez, hasta que K = |V|/2. Teorema 4. En juegos de forma normal de 3 jugadores, encontrar una estrategia mixta óptima a la que comprometerse es NP-difícil. Prueba. Reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO al siguiente juego de forma normal de 3 jugadores. Para cada vértice v, cada uno de los tres jugadores tiene una estrategia pura correspondiente a ese vértice (rv, sv, tv, respectivamente). Además, para cada arista e, el tercer jugador tiene una estrategia pura te; y finalmente, el tercer jugador tiene una estrategia pura adicional t0. Los servicios son los siguientes: • para todo r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • para todo r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • para todo v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • para todo v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • para todo v ∈ V, para todo r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V| |V|−2; • para todo e ∈ E, s ∈ S, para ambos v ∈ e, u3(rv, s, te) = 0; • para todo e ∈ E, s ∈ S, para todo v /∈ e, u3(rv, s, te) = |V| |V|−2. • para todo r ∈ R, s ∈ S, u3(r, s, t0) = 1. Observamos que los jugadores 1 y 2 tienen la misma función de utilidad. Sostenemos que existe un perfil de estrategia óptimo en el que los jugadores 1 y 2 obtienen ambos 1 (su utilidad máxima) si y solo si hay una solución al problema de la COBERTURA DE VÉRTICES EQUILIBRADA. (De lo contrario, estos jugadores obtendrán ambos 0). Primero, supongamos que existe una solución al problema de la cubierta de vértices balanceada. Entonces, deja que el jugador 1 juegue cada rv de manera que v esté en la cobertura con probabilidad 2 |V|, y deja que el jugador 2 juegue cada sv de manera que v no esté en la cobertura con probabilidad 2 |V|. Entonces, para el jugador 3, la utilidad esperada de jugar tv (para cualquier v) es (1 − 2 |V|) |V| |V|−2 = 1, porque hay una probabilidad de 2 |V| de que se juegue rv o sv. Además, la utilidad esperada de jugar te (para cualquier e) es a lo sumo (1 − 2 |V | ) |V | |V |−2 = 1, porque hay una probabilidad de al menos 2 |V | de que algún rv con v ∈ e se juegue (debido a que el jugador 1 está aleatorizando sobre las estrategias puras correspondientes a la cobertura). Se deduce que jugar t0 es la mejor respuesta para el jugador 3, otorgando a los jugadores 1 y 2 una utilidad de 1. Ahora, supongamos que los jugadores 1 y 2 obtienen 1 en el juego óptimo. Entonces, debe ser el caso de que el jugador 3 juegue t0. Por lo tanto, para cada v ∈ V, debe haber una probabilidad de al menos 2 |V| de que se juegue rv o sv, de lo contrario, al jugador 3 le convendría más jugar tv. Dado que los jugadores 1 y 2 solo tienen una probabilidad total de 2 para distribuir, debe ser el caso que para cada v, ya sea rv o sv se juegue con una probabilidad de 2 |V|, y el otro se juegue con una probabilidad de 0. (No es posible que ambos tengan una probabilidad distinta de cero, porque entonces habría alguna probabilidad de que ambos se jugaran simultáneamente (la correlación no es posible), por lo tanto, la probabilidad total de que al menos uno se juegue no podría ser lo suficientemente alta para todos los vértices). Por lo tanto, para exactamente la mitad de los v ∈ V, el jugador 1 coloca una probabilidad de 2 |V| en rv. Además, para cada e ∈ E, debe haber una probabilidad de al menos 2 |V | de que se juegue algún rv con v ∈ e, de lo contrario, al jugador 3 le convendría más jugar te. Por lo tanto, el v ∈ V tal que el jugador 1 coloca una probabilidad de 2 |V | en rv constituye una cubierta de vértices equilibrada. 3. Juegos bayesianos. Hasta ahora, hemos restringido nuestra atención a los juegos en forma normal. En un juego en forma normal, se asume que cada agente conoce las preferencias de todos los demás agentes sobre los resultados del juego. En general, sin embargo, los agentes pueden tener información privada sobre sus preferencias que no es conocida por los otros agentes. Además, en el momento de comprometerse con una estrategia, los agentes pueden ni siquiera conocer sus propias preferencias (finales) sobre los resultados del juego aún, ya que estas preferencias pueden depender de un contexto que aún no se ha materializado. Por ejemplo, cuando se escribe el código para un agente de negociación, puede que aún no esté claro cómo ese agente valorará los recursos sobre los que negociará más adelante, porque esto depende de información que aún no está disponible en el momento en que se escribe el código (como órdenes que habrán sido colocadas al agente antes de la negociación). En esta sección, estudiaremos el compromiso en juegos bayesianos, los cuales pueden modelar tal incertidumbre sobre preferencias. 3.1 Definiciones En un juego bayesiano, cada jugador i tiene un conjunto de acciones Si, un conjunto de tipos Θi con una distribución de probabilidad asociada πi : Θi → [0, 1], y, para cada tipo θi, una función de utilidad uθi i : S1 × S2 × . . . × Sn → R. Una estrategia pura en un juego bayesiano es una asignación de los tipos de los jugadores a acciones, σi : Θi → Si. (Los juegos bayesianos pueden ser reescritos en forma normal enumerando cada estrategia pura σi, pero esto causará un crecimiento exponencial en el tamaño de la representación del juego y por lo tanto no puede llevar a algoritmos eficientes). La estrategia a la que el líder debería comprometerse depende de si, en el momento del compromiso, el líder conoce su propio tipo. Si la líder conoce su propio tipo, los otros tipos que la líder podría haber tenido se vuelven irrelevantes y la líder simplemente debería comprometerse con la estrategia que sea óptima para ese tipo. Sin embargo, como se argumentó anteriormente, la líder no necesariamente conoce su propio tipo en el momento de comprometerse (por ejemplo, en el momento en que se envía el código). En este caso, el líder debe comprometerse con una estrategia que dependa en un 86% del tipo eventual del líder. Estudiaremos este último modelo, aunque prestaremos atención específica al caso en el que el líder tiene un solo tipo, lo cual es efectivamente lo mismo que el modelo anterior. 3.2 Compromiso con estrategias puras Resulta que calcular una estrategia pura óptima a la que comprometerse es difícil en juegos bayesianos, incluso con dos jugadores. Teorema 5. Encontrar una estrategia pura óptima a comprometerse en juegos bayesianos de 2 jugadores es NP-difícil, incluso cuando el seguidor tiene solo un tipo. Prueba. Reducimos una instancia arbitraria de CUBRIMIENTO DE VÉRTICES al siguiente juego bayesiano entre el líder y el seguidor. El líder tiene K tipos θ1, θ2, . . . , θK, cada uno ocurriendo con probabilidad 1/K, y para cada vértice v ∈ V, el líder tiene una acción sv. El seguidor tiene solo un tipo; para cada borde e ∈ E, el seguidor tiene una acción te, y el seguidor tiene una acción adicional única t0. La función de utilidad para el líder está dada por, para todo θl ∈ Θl y todo s ∈ S, u θl l (s, t0) = 1, y para todo e ∈ E, u θl l (s, te) = 0. La utilidad de los seguidores se da por: • Para todo v ∈ V, para todo e ∈ E con v /∈ e, uf (sv, te) = 1; • Para todo v ∈ V, para todo e ∈ E con v ∈ e, uf (sv, te) = −K; • Para todo v ∈ V, uf (sv, t0) = 0. Sostenemos que el líder puede obtener una utilidad de 1 si y solo si hay una solución para la instancia de CUBRIMIENTO-DE-VÉRTICES. Primero, supongamos que hay una solución para la instancia de CUBRIRVÉRTICES. Entonces, el líder puede comprometerse con una estrategia pura tal que para cada vértice v en la cobertura, el líder juega sv para algún tipo. Entonces, la utilidad de los seguidores para jugar te (para cualquier e ∈ E) es a lo sumo K−1 K + 1 K (−K) = − 1 K , por lo que el seguidor preferirá jugar t0, lo que le da al líder una utilidad de 1, como se requiere. Ahora, supongamos que hay una estrategia pura para el líder que le dará al líder una utilidad de 1. Entonces, el seguidor debe jugar t0. Para que el seguidor no prefiera jugar te (para cualquier e ∈ E) en su lugar, al menos para un v ∈ e, el líder debe jugar sv para algún tipo θl. Por lo tanto, el conjunto de vértices v que el líder juega para algún tipo debe constituir una cubierta de vértices; y este conjunto puede tener un tamaño de como máximo K, ya que el líder solo tiene K tipos. Entonces hay una solución para la instancia de CUBRIMIENTODEVÉRTICES. Sin embargo, si el líder tiene solo un tipo, entonces el problema se vuelve fácil nuevamente (#tipos es el número de tipos para el seguidor): Teorema 6. En juegos bayesianos de 2 jugadores en los que el líder tiene solo un tipo, una estrategia pura óptima a comprometerse puede encontrarse en tiempo O(#resultados · #tipos). Prueba. Para cada acción de líder s, podemos calcular, para cada tipo de seguidor θf ∈ Θf, qué acciones t maximizan la utilidad de los seguidores; llamamos a este conjunto de acciones BRθf (s). Entonces, la utilidad que recibe el líder por comprometerse a la acción s se puede calcular como θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), y el líder puede elegir la mejor acción a la que comprometerse. 3.3 Compromiso con estrategias mixtas En juegos de información imperfecta de suma cero de dos jugadores con memoria perfecta (ningún jugador olvida algo que una vez supo), una estrategia minimax se puede construir en tiempo polinómico [12, 13]. Desafortunadamente, este resultado no se extiende a calcular estrategias mixtas óptimas a comprometerse en el caso de suma general, ni siquiera en juegos bayesianos. Demostraremos la NP-dificultad reduciendo desde el problema de CONJUNTOINDEPENDIENTE. Definición 2. En INDEPENDENT-SET, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que ninguna arista e ∈ E tenga ambos extremos en S. Nuevamente, este problema es NP-completo [9]. Teorema 7. Encontrar una estrategia mixta óptima a comprometerse en juegos bayesianos de 2 jugadores es NP-duro, incluso cuando el líder tiene solo un tipo y el seguidor tiene solo dos acciones. Prueba. Reducimos una instancia arbitraria de CONJUNTO-INDEPENDIENTE al siguiente juego bayesiano entre el líder y el seguidor. El líder tiene solo un tipo, y para cada vértice v ∈ V, el líder tiene una acción sv. El seguidor tiene un tipo θv para cada v ∈ V, que ocurre con una probabilidad de 1 (|E|+1)|V|, y un tipo θe para cada e ∈ E, que ocurre con una probabilidad de 1 |E|+1. El seguidor tiene dos acciones: t0 y t1. La utilidad de los líderes se da por, para todo s ∈ S, ul(s, t0) = 1 y ul(s, t1) = 0. La utilidad de los seguidores se da por: • Para todo v ∈ V, uθv f (sv, t1) = 0; • Para todo v ∈ V y s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • Para todo v ∈ V y s ∈ S, uθv f (s, t0) = 1; • Para todo e ∈ E, s ∈ S, uθe f (s, t0) = 1; • Para todo e ∈ E, para ambos v ∈ e, uθe f (sv, t1) = 2K 3 ; • Para todo e ∈ E, para todo v /∈ e, uθe f (sv, t1) = 0. Sostenemos que una estrategia óptima a comprometerse le otorga al líder una utilidad esperada de al menos |E| |E|+1 + K (|E|+1)|V | si y solo si hay una solución para la instancia de CONJUNTO-INDEPENDIENTE. Primero, supongamos que hay una solución para la instancia de CONJUNTO-INDEPENDIENTE. Entonces, el líder podría comprometerse con la siguiente estrategia: por cada vértice v en el conjunto independiente, jugar el correspondiente sv con una probabilidad de 1/K. Si el seguidor tiene el tipo θe para algún e ∈ E, la utilidad esperada para el seguidor al jugar t1 es a lo sumo 1 K 2K 3 = 2/3, porque hay a lo sumo un vértice v ∈ e tal que sv se juega con probabilidad distinta de cero. Por lo tanto, el seguidor jugará t0 y obtendrá una utilidad de 1. Si el seguidor tiene el tipo θv para algún vértice v en el conjunto independiente, la utilidad esperada para el seguidor al jugar t1 es K−1 K K K−1 = 1, porque el líder juega sv con probabilidad 1/K. Se deduce que el seguidor (quien rompe los empates para maximizar la utilidad de los líderes) jugará t0, lo que también otorga una utilidad de 1 y brinda al líder una mayor utilidad. Por lo tanto, la utilidad esperada de los líderes para esta estrategia es al menos |E| |E|+1 + K (|E|+1)|V |, como se requiere. Ahora, supongamos que hay una estrategia que le da al líder una utilidad esperada de al menos |E| |E|+1 + K (|E|+1)|V |. Entonces, esta estrategia debe inducir al seguidor a jugar t0 siempre que tenga un tipo de la forma θe (porque de lo contrario, la utilidad podría ser a lo sumo |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ). Por lo tanto, no puede ser el caso de que para alguna arista e = (v1, v2) ∈ E, la probabilidad de que el líder juegue uno de sv1 y sv2 sea al menos 2/K, porque entonces la utilidad esperada para el seguidor de jugar t1 cuando tiene el tipo θe sería al menos 2 K 2K 3 = 4/3 > 1. Además, la estrategia debe inducir al seguidor a jugar t0 durante al menos K tipos de la forma θv. Inducir al seguidor a jugar t0 cuando tiene el tipo θv solo se puede lograr jugando sv con una probabilidad de al menos 1/K, lo que le dará al seguidor una utilidad de como máximo K−1 K K K−1 = 1 por jugar t1. Pero entonces, el conjunto de vértices v tales que sv se juega con una probabilidad de al menos 1/K debe constituir un conjunto independiente de tamaño K (porque si hubiera una arista e entre dos de estos vértices, induciría al seguidor a jugar t1 para el tipo θe según lo mencionado anteriormente). Por el contrario, si el seguidor tiene solo un tipo, entonces podemos generalizar el enfoque de programación lineal para juegos en forma normal: Teorema 8. En juegos bayesianos de 2 jugadores en los que el seguidor tiene solo un tipo, una estrategia mixta óptima a comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal. Prueba. Generalizamos el enfoque en el Teorema 2 de la siguiente manera. Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder para cada uno de los tipos de líderes de manera que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad esperada ex ante de los líderes. Para hacerlo, generalizamos el programa lineal de la siguiente manera: maximizar θl∈Θl π(θl) s∈S pθl s uθl l (s, t) sujeto a para todo t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t) para todo θl ∈ Θl, s∈S p θl s = 1 Como en el Teorema 2, la solución para el programa lineal que maximiza el valor de la solución es una estrategia óptima a comprometerse. Esto muestra un contraste interesante entre el compromiso con estrategias puras y el compromiso con estrategias mixtas en juegos bayesianos: para las estrategias puras, el problema se vuelve fácil si el líder tiene solo un tipo (pero no si el seguidor tiene solo un tipo), mientras que para las estrategias mixtas, el problema se vuelve fácil si el seguidor tiene solo un tipo (pero no si el líder tiene solo un tipo). 4. CONCLUSIONES E INVESTIGACIONES FUTURAS En los sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias de forma simultánea. Esto requiere cierta noción de equilibrio (equilibrio de Nash y sus refinamientos), y a menudo conduce al problema de selección de equilibrio: no está claro para cada jugador individual según qué equilibrio debería jugar. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Por ejemplo, un agente puede llegar al sitio del juego (real o virtual) antes que el otro, o, en el caso específico de agentes de software, el código de un agente puede estar completo y comprometido antes que el de otro agente. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. Específicamente, si es posible el compromiso con estrategias mixtas, entonces el compromiso (óptimo) nunca perjudica al líder y a menudo lo beneficia. El reciente aumento del interés en las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas para comprometerse tanto a estrategias puras como a estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Para juegos en forma normal, demostramos que la estrategia pura óptima a comprometerse se puede encontrar eficientemente para cualquier número de jugadores. Una estrategia mixta óptima para comprometerse en un juego en forma normal puede encontrarse eficientemente para dos jugadores utilizando programación lineal (y no más eficientemente que eso, en el sentido de que cualquier programa lineal con una restricción de probabilidad puede ser codificado como tal problema). (Esta es una generalización de la computabilidad en tiempo polinómico de las estrategias minimax en juegos en forma normal). El problema se vuelve NP-duro para tres (o más) jugadores. En los juegos bayesianos, el problema de encontrar una estrategia pura óptima a la que comprometerse es NP-duro incluso en juegos de dos jugadores en los que el seguidor tiene solo un tipo, aunque los juegos de dos jugadores en los que el líder tiene solo un tipo pueden resolverse eficientemente. El problema de encontrar una estrategia mixta óptima a comprometerse en un juego bayesiano es NP-duro incluso en juegos de dos jugadores en los que el líder tiene solo un tipo, aunque los juegos de dos jugadores en los que el seguidor tiene solo un tipo pueden resolverse eficientemente utilizando una generalización del enfoque de programación lineal para juegos en forma normal. Las siguientes dos tablas resumen estos resultados. 2 jugadores ≥ 3 jugadores forma normal O(#resultados) O(#resultados· #jugadores) Bayesiano, O(#resultados· NP-completo 1-tipo líder #tipos) Bayesiano, NP-completo NP-completo 1-tipo seguidor Bayesiano (general) NP-completo NP-completo Resultados para el compromiso con estrategias puras. (Con más de 2 jugadores, el seguidor es el último jugador en comprometerse, el líder es el primero.) 88 2 jugadores ≥ 3 jugadores forma normal una resolución de LP por acción NP-completa del seguidor Bayesiano, NP-completo NP-completo 1-tipo líder Bayesiano, una resolución de LP por acción NP-completa del 1-tipo seguidor Bayesiano (general) NP-completo NP-completo Resultados para el compromiso con estrategias mixtas. (Con más de 2 jugadores, el seguidor es el último jugador en comprometerse, el líder es el primero.) La investigación futura puede tomar varias direcciones. Primero, podemos evaluar empíricamente las técnicas presentadas aquí en conjuntos de pruebas como GAMUT [19]. También podemos estudiar la computación de estrategias óptimas a comprometerse en otras representaciones concisas de juegos en forma normal, por ejemplo, en juegos gráficos [10] o juegos de grafo de efecto local/acción [14, 1]. Para los casos en los que calcular una estrategia óptima para comprometerse es NP-duro, también podemos estudiar la computación de estrategias aproximadamente óptimas para comprometerse. Si bien la definición correcta de una estrategia aproximadamente óptima en este contexto puede parecer simple al principio, debería ser una estrategia que, si los jugadores siguientes juegan de manera óptima, funcione casi tan bien como la estrategia óptima en promedio, esta definición se vuelve problemática cuando consideramos que los otros jugadores también podrían estar jugando solo de manera aproximadamente óptima. Uno también puede estudiar modelos en los que múltiples (pero no todos) jugadores se comprometen al mismo tiempo. Otra dirección interesante a explorar es ver si calcular estrategias mixtas óptimas a las que comprometerse puede ayudarnos, o de alguna manera arrojar luz sobre, el cálculo de equilibrios de Nash. A menudo, las estrategias mixtas óptimas a las que comprometerse también son estrategias de equilibrio de Nash (por ejemplo, en juegos de suma cero de dos jugadores esto siempre es cierto), aunque no siempre es el caso (por ejemplo, como ya señalamos, a veces la estrategia óptima a la que comprometerse es una estrategia estrictamente dominada, que nunca puede ser una estrategia de equilibrio de Nash). 5. REFERENCIAS [1] N. A. R. Bhat y K. Leyton-Brown. Calculando los equilibrios de Nash de juegos de gráficos de acción. En Actas de la 20ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI), Banff, Canadá, 2004. [2] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Actas de la Decimoctava Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 765-771, Acapulco, México, 2003. [3] V. Conitzer y T. Sandholm. Complejidad del dominio (iterado). En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 88-97, Vancouver, Canadá, 2005. [4] V. Conitzer y T. Sandholm. Un criterio de eliminabilidad de estrategias generalizado y métodos computacionales para aplicarlo. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 483-488, Pittsburgh, PA, EE. UU., 2005. [5] A. A. Cournot. Las investigaciones sobre los juegos bayesianos son una representación potencialmente concisa de los juegos en forma normal en los principios matemáticos de la teoría de la riqueza. Hachette, París, 1838. [6] G. Dantzig. Una prueba de la equivalencia del problema de programación y el problema de juego. En T. Koopmans, editor, Análisis de la actividad de producción y asignación, páginas 330-335. John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel. \n\nJohn Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, y E. Zemel. La complejidad de eliminar estrategias dominadas. Matemáticas de la Investigación de Operaciones, 18:553-565, 1993. [8] I. Gilboa y E. Zemel. Nash y equilibrios correlacionados: Algunas consideraciones de complejidad. Juegos y Comportamiento Económico, 1:80-93, 1989. [9] R. Karp. Reductibilidad entre problemas combinatorios. En R. E. Miller y J. W. Thatcher, editores, Complejidad de las Computaciones de Computadoras, páginas 85-103. Plenum Press, Nueva York, 1972. [10] M. Kearns, M. Littman y S. Singh. Modelos gráficos para teoría de juegos. En Actas de la Conferencia sobre Incertidumbre en Inteligencia Artificial (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou y J. N. Tsitsiklis. Una nota sobre la eliminación de estrategias en juegos bimatrix. Cartas de Investigación Operativa, 7(3):103-107, 1988. [12] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [14] K. Leyton-Brown y M. Tennenholtz. Juegos de efecto local. En Actas de la Decimoctava Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), Acapulco, México, 2003. [15] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 36-41, San Diego, CA, 2003. [16] M. Littman y P. Stone. Un algoritmo de equilibrio de Nash de tiempo polinómico para juegos repetidos. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 48-54, San Diego, CA, 2003. [17] R. D. Luce y H. Raiffa. Juegos y decisiones. John Wiley and Sons, Nueva York, 1957. Reedición de Dover 1989. [18] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown y Y. Shoham. Ejecutar el GAMUT: Un enfoque integral para evaluar algoritmos de teoría de juegos. En la Conferencia Internacional sobre Agentes Autónomos y Sistemas Multiagente (AAMAS), Nueva York, NY, EE. UU., 2004. [20] M. J. Osborne y A. Rubinstein. Un curso de teoría de juegos. MIT Press, 1994. [21] C. Papadimitriou. \n\nMIT Press, 1994. [21] C. Papadimitriou. Algoritmos, juegos e Internet. En Actas del Simposio Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. 89 [22] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 664-669, San José, CA, EE. UU., 2004. [23] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [24] J. von Neumann. A la teoría de los juegos sociales. Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg. \n\nMathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg. Forma de mercado y equilibrio. Springer, Viena, 1934. [26] B. von Stengel y S. Zamir. Liderazgo con compromiso hacia estrategias mixtas. Informe de investigación CDAM LSE-CDAM-2004-01, London School of Economics, febrero de 2004. 90",
    "original_sentences": [
        "Computing the Optimal Strategy to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
        "However, this model is not always realistic.",
        "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
        "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
        "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
        "In this paper, we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
        "We give both positive results (efficient algorithms) and negative results (NP-hardness results).",
        "Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity General Terms Algorithms, Economics, Theory 1.",
        "INTRODUCTION In multiagent systems with self-interested agents (including most economic settings), the optimal action for one agent to take depends on the actions that the other agents take.",
        "To analyze how an agent should behave in such settings, the tools of game theory need to be applied.",
        "Typically, when a strategic setting is modeled in the framework of game theory, it is assumed that players choose their strategies simultaneously.",
        "This is especially true when the setting is modeled as a normal-form game, which only specifies each agents utility as a function of the vector of strategies that the agents choose, and does not provide any information on the order in which agents make their decisions and what the agents observe about earlier decisions by other agents.",
        "Given that the game is modeled in normal form, it is typically analyzed using the concept of Nash equilibrium.",
        "A Nash equilibrium specifies a strategy for each player, such that no player has an incentive to individually deviate from this profile of strategies. (Typically, the strategies are allowed to be mixed, that is, probability distributions over the original (pure) strategies.)",
        "A (mixed-strategy) Nash equilibrium is guaranteed to exist in finite games [18], but one problem is that there may be multiple Nash equilibria.",
        "This leads to the equilibrium selection problem of how an agent can know which strategy to play if it does not know which equilibrium is to be played.",
        "When the setting is modeled as an extensive-form game, it is possible to specify that some players receive some information about actions taken by others earlier in the game before deciding on their action.",
        "Nevertheless, in general, the players do not know everything that happened earlier in the game.",
        "Because of this, these games are typically still analyzed using an equilibrium concept, where one specifies a mixed strategy for each player, and requires that each players strategy is a best response to the others strategies. (Typically an additional constraint on the strategies is now imposed to ensure that players do not play in a way that is irrational with respect to the information that they have received so far.",
        "This leads to refinements of Nash equilibrium such as subgame perfect and sequential equilibrium.)",
        "However, in many real-world settings, strategies are not selected in such a simultaneous manner.",
        "Oftentimes, one player (the leader) is able to commit to a strategy before another player (the follower).",
        "This can be due to a variety of reasons.",
        "For example, one of the players may arrive at the site at which the game is to be played before another agent (e.g., in economic settings, one player may enter a market earlier and commit to a way of doing busi82 ness).",
        "Such commitment power has a profound impact on how the game should be played.",
        "For example, the leader may be best off playing a strategy that is dominated in the normal-form representation of the game.",
        "Perhaps the earliest and best-known example of the effect of commitment is that by von Stackelberg [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution.",
        "In general, if commitment to mixed strategies is possible, then (under minor assumptions) it never hurts, and often helps, to commit to a strategy [26].",
        "Being forced to commit to a pure strategy sometimes helps, and sometimes hurts (for example, committing to a pure strategy in rock-paper-scissors before the other players decision will naturally result in a loss).",
        "In this paper, we will assume commitment is always forced; if it is not, the player who has the choice of whether to commit can simply compare the commitment outcome to the non-commitment (simultaneous-move) outcome.",
        "Models of leadership are especially important in settings with multiple self-interested software agents.",
        "Once the code for an agent (or for a team of agents) is finalized and the agent is deployed, the agent is committed to playing the (possibly randomized) strategy that the code prescribes.",
        "Thus, as long as one can credibly show that one cannot change the code later, the code serves as a commitment device.",
        "This holds true for recreational tournaments among agents (e.g., poker tournaments, RoboSoccer), and for industrial applications such as sensor webs.",
        "Finally, there is also an implicit leadership situation in the field of mechanism design, in which one player (the designer) gets to choose the rules of the game that the remaining players then play.",
        "Mechanism design is an extremely important topic to the EC community: the papers published on mechanism design in recent EC conferences are too numerous to cite.",
        "Indeed, the mechanism designer may benefit from committing to a choice that, if the (remaining) agents actions were fixed, would be suboptimal.",
        "For example, in a (first-price) auction, the seller may wish to set a positive (artificial) reserve price for the item, below which the item will not be sold-even if the seller values the item at 0.",
        "In hindsight (after the bids have come in), this (na¨ıvely) appears suboptimal: if a bid exceeding the reserve price came in, the reserve price had no effect, and if no such bid came in, the seller would have been better off accepting a lower bid.",
        "Of course, the reason for setting the reserve price is that it incentivizes the bidders to bid higher, and because of this, setting artificial reserve prices can actually increase expected revenue to the seller.",
        "A significant amount of research has recently been devoted to the computation of solutions according to various solution concepts for settings in which the agents choose their strategies simultaneously, such as dominance [7, 11, 3] and (especially) Nash equilibrium [8, 21, 16, 15, 2, 22, 23, 4].",
        "However, the computation of the optimal strategy to commit to in a leadership situation has gone ignored.",
        "Theoretically, leadership situations can simply be thought of as an extensive-form game in which one player chooses a strategy (for the original game) first.",
        "The number of strategies in this extensive-form game, however, can be exceedingly large.",
        "For example, if the leader is able to commit to a mixed strategy in the original game, then every one of the (continuum of) mixed strategies constitutes a pure strategy in the extensive-form representation of the leadership situation. (We note that a commitment to a distribution is not the same as a distribution over commitments.)",
        "Moreover, if the original game is itself an extensive-form game, the number of strategies in the extensive-form representation of the leadership situation (which is a different extensive-form game) becomes even larger.",
        "Because of this, it is usually not computationally feasible to simply transform the original game into the extensive-form representation of the leadership situation; instead, we have to analyze the game in its original representation.",
        "In this paper, we study how to compute the optimal strategy to commit to, both in normal-form games (Section 2) and in Bayesian games, which are a special case of extensiveform games (Section 3). 2.",
        "NORMAL-FORM GAMES In this section, we study how to compute the optimal strategy to commit to for games represented in normal form. 2.1 Definitions In a normal-form game, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a pure strategy for every player, also known as a profile of pure strategies) to a real number.",
        "To ease notation, in the case of two players, we will refer to player 1s pure strategy set as S, and player 2s pure strategy set as T. Such games can be represented in (bi-)matrix form, in which the rows correspond to player 1s pure strategies, the columns correspond to player 2s pure strategies, and the entries of the matrix give the row and column players utilities (in that order) for the corresponding outcome of the game.",
        "In the case of three players, we will use R, S, and T, for player 1, 2, and 3s pure strategies, respectively.",
        "A mixed strategy for a player is a probability distribution over that players pure strategies.",
        "In the case of two-player games, we will refer to player 1 as the leader and player 2 as the follower.",
        "Before defining optimal leadership strategies, consider the following game which illustrates the effect of the leaders ability to commit. 2, 1 4, 0 1, 0 3, 1 In this normal-form representation, the bottom strategy for the row player is strictly dominated by the top strategy.",
        "Nevertheless, if the row player has the ability to commit to a pure strategy before the column player chooses his strategy, the row player should commit to the bottom strategy: doing so will make the column player prefer to play the right strategy, leading to a utility of 3 for the row player.",
        "By contrast, if the row player were to commit to the top strategy, the column player would prefer to play the left strategy, leading to a utility of only 2 for the row player.",
        "If the row player is able to commit to a mixed strategy, then she can get an even greater (expected) utility: if the row player commits to placing probability p > 1/2 on the bottom strategy, then the column player will still prefer to play the right strategy, and the row players expected utility will be 3p + 4(1 − p) = 4 − p ≥ 3.",
        "If the row player plays each strategy with probability exactly 1/2, the column player is 83 indifferent between the strategies.",
        "In such cases, we will assume that the column player will choose the strategy that maximizes the row players utility (in this case, the right strategy).",
        "Hence, the optimal mixed strategy to commit to for the row player is p = 1/2.",
        "There are a few good reasons for this assumption.",
        "If we were to assume the opposite, then there would not exist an optimal strategy for the row player in the example game: the row player would play the bottom strategy with probability p = 1/2 + with > 0, and the smaller , the better the utility for the row player.",
        "By contrast, if we assume that the follower always breaks ties in the leaders favor, then an optimal mixed strategy for the leader always exists, and this corresponds to a subgame perfect equilibrium of the extensive-form representation of the leadership situation.",
        "In any case, this is a standard assumption for such models (e.g. [20]), although some work has investigated what can happen in the other subgame perfect equilibria [26]. (For generic two-player games, the leaders subgame-perfect equilibrium payoff is unique.)",
        "Also, the same assumption is typically used in mechanism design, in that it is assumed that if an agent is indifferent between revealing his preferences truthfully and revealing them falsely, he will report them truthfully.",
        "Given this assumption, we can safely refer to optimal leadership strategies rather than having to use some equilibrium notion.",
        "Hence, for the purposes of this paper, an optimal strategy to commit to in a 2-player game is a strategy s ∈ S that maximizes maxt∈BR(s) ul(s, t), where BR(s) = arg maxt∈T uf (s, t). (ul and uf are the leader and followers utility functions, respectively.)",
        "We can have S = S for the case of commitment to pure strategies, or S = ∆(S), the set of probability distributions over S, for the case of commitment to mixed strategies. (We note that replacing T by ∆(T) makes no difference in this definition.)",
        "For games with more than two players, in which the players commit to their strategies in sequence, we define optimal strategies to commit to recursively.",
        "After the leader commits to a strategy, the game to be played by the remaining agents is itself a (smaller) leadership game.",
        "Thus, we define an optimal strategy to commit to as a strategy that maximizes the leaders utility, assuming that the play of the remaining agents is itself optimal under this definition, and maximizes the leaders utility among all optimal ways to play the remaining game.",
        "Again, commitment to mixed strategies may or may not be a possibility for every player (although for the last player it does not matter if we allow for commitment to mixed strategies). 2.2 Commitment to pure strategies We first study how to compute the optimal pure strategy to commit to.",
        "This is relatively simple, because the number of strategies to commit to is not very large. (In the following, #outcomes is the number of complete strategy profiles.)",
        "Theorem 1.",
        "Under commitment to pure strategies, the set of all optimal strategy profiles in a normal-form game can be found in O(#players · #outcomes) time.",
        "Proof.",
        "Each pure strategy that the first player may commit to will induce a subgame for the remaining players.",
        "We can solve each such subgame recursively to find all of its optimal strategy profiles; each of these will give the original leader some utility.",
        "Those that give the leader maximal utility correspond exactly to the optimal strategy profiles of the original game.",
        "We now present the algorithm formally.",
        "Let Su(G, s1) be the subgame that results after the first (remaining) player in G plays s1 ∈ SG 1 .",
        "A game with 0 players is simply an outcome of the game.",
        "The function Append(s, O) appends the strategy s to each of the vectors of strategies in the set O.",
        "Let e be the empty vector with no elements.",
        "In a slight abuse of notation, we will write uG 1 (C) when all strategy profiles in the set C give player 1 the same utility in the game G. (Here, player 1 is the first remaining player in the subgame G, not necessarily player 1 in the original game.)",
        "We note that arg max is set-valued.",
        "Then, the following algorithm computes all optimal strategy profiles: Algorithm Solve(G) if G has 0 players return {e} C ← ∅ for all s1 ∈ SG 1 { O ← Solve(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) if C = ∅ or uG 1 (s1, O ) = uG 1 (C) C ← C∪Append(s1, O ) if uG 1 (s1, O ) > uG 1 (C) C ←Append(s1, O ) } return C Every outcome is (potentially) examined by every player, which leads to the given runtime bound.",
        "As an example of how the algorithm works, consider the following 3-player game, in which the first player chooses the left or right matrix, the second player chooses a row, and the third player chooses a column. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 3,0,0 First we eliminate the outcomes that do not correspond to best responses for the third player (removing them from the matrix): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Next, we remove the entries in which the third player does not break ties in favor of the second player, as well as entries that do not correspond to best responses for the second player. 0,1,1 2,1,1 1,1,1 0,5,1 Finally, we remove the entries in which the second and third players do not break ties in favor of the first player, as well as entries that do not correspond to best responses for the first player. 2,1,1 84 Hence, in optimal play, the first player chooses the left matrix, the second player chooses the middle row, and the third player chooses the left column. (We note that this outcome is Pareto-dominated by (Right, Middle, Left).)",
        "For general normal-form games, each players utility for each of the outcomes has to be explicitly represented in the input, so that the input size is itself Ω(#players · #outcomes).",
        "Therefore, the algorithm is in fact a linear-time algorithm. 2.3 Commitment to mixed strategies In the special case of two-player zero-sum games, computing an optimal mixed strategy for the leader to commit to is equivalent to computing a minimax strategy, which minimizes the maximum expected utility that the opponent can obtain.",
        "Minimax strategies constitute the only natural solution concept for two-player zero-sum games: von Neumanns Minimax Theorem [24] states that in two-player zero-sum games, it does not matter (in terms of the players utilities) which player gets to commit to a mixed strategy first, and a profile of mixed strategies is a Nash equilibrium if and only if both strategies are minimax strategies.",
        "It is well-known that a minimax strategy can be found in polynomial time, using linear programming [17].",
        "Our first result in this section generalizes this result, showing that an optimal mixed strategy for the leader to commit to can be efficiently computed in general-sum two-player games, again using linear programming.",
        "Theorem 2.",
        "In 2-player normal-form games, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
        "Proof.",
        "For every pure follower strategy t, we compute a mixed strategy for the leader such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders utility.",
        "Such a mixed strategy can be computed using the following simple linear program: maximize s∈S psul(s, t) subject to for all t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1 We note that this program may be infeasible for some follower strategies t, for example, if t is a strictly dominated strategy.",
        "Nevertheless, the program must be feasible for at least some follower strategies; among these follower strategies, choose a strategy t∗ that maximizes the linear programs solution value.",
        "Then, if the leader chooses as her mixed strategy the optimal settings of the variables ps for the linear program for t∗ , and the follower plays t∗ , this constitutes an optimal strategy profile.",
        "In the following result, we show that we cannot expect to solve the problem more efficiently than linear programming, because we can reduce any linear program with a probability constraint on its variables to a problem of computing the optimal mixed strategy to commit to in a 2-player normalform game.",
        "Theorem 3.",
        "Any linear program whose variables xi (with xi ∈ R≥0 ) must satsify i xi = 1 can be modeled as a problem of computing the optimal mixed strategy to commit to in a 2-player normal-form game.",
        "Proof.",
        "Let the leader have a pure strategy i for every variable xi.",
        "Let the column player have one pure strategy j for every constraint in the linear program (other than i xi = 1), and a single additional pure strategy 0.",
        "Let the utility functions be as follows.",
        "Writing the objective of the linear program as maximize i cixi, for any i, let ul(i, 0) = ci and uf (i, 0) = 0.",
        "Writing the jth constraint of the linear program (not including i xi = 1) as i aijxi ≤ bj, for any i, j > 0, let ul(i, j) = mini ci − 1 and uf (i, j) = aij − bj.",
        "For example, consider the following linear program. maximize 2x1 + x2 subject to x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 The optimal solution to this program is x1 = 1/3, x2 = 2/3.",
        "Our reduction transforms this program into the following leader-follower game (where the leader is the row player). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 Indeed, the optimal strategy for the leader is to play the top strategy with probability 1/3 and the bottom strategy with probability 2/3.",
        "We now show that the reduction works in general.",
        "Clearly, the leader wants to incentivize the follower to play 0, because the utility that the leader gets when the follower plays 0 is always greater than when the follower does not play 0.",
        "In order for the follower not to prefer playing j > 0 rather than 0, it must be the case that i pl(i)(aij − bj) ≤ 0, or equivalently i pl(i)aij ≤ bj.",
        "Hence the leader will get a utility of at least mini ci if and only if there is a feasible solution to the constraints.",
        "Given that the pl(i) incentivize the follower to play 0, the leader attempts to maximize i pl(i)ci.",
        "Thus the leader must solve the original linear program.",
        "As an alternative proof of Theorem 3, one may observe that it is known that finding a minimax strategy in a zerosum game is as hard as the linear programming problem [6], and as we pointed out at the beginning of this section, computing a minimax strategy in a zero-sum game is a special case of the problem of computing an optimal mixed strategy to commit to.",
        "This polynomial-time solvability of the problem of computing an optimal mixed strategy to commit to in two-player normal-form games contrasts with the unknown complexity of computing a Nash equilibrium in such games [21], as well as with the NP-hardness of finding a Nash equilibrium with maximum utility for a given player in such games [8, 2].",
        "Unfortunately, this result does not generalize to more than two players-here, the problem becomes NP-hard.",
        "To show this, we reduce from the VERTEX-COVER problem.",
        "Definition 1.",
        "In VERTEX-COVER, we are given a graph G = (V, E) and an integer K. We are asked whether there 85 exists a subset of the vertices S ⊆ V , with |S| = K, such that every edge e ∈ E has at least one of its endpoints in S. BALANCED-VERTEX-COVER is the special case of VERTEX-COVER in which K = |V |/2.",
        "VERTEX-COVER is NP-complete [9].",
        "The following lemma shows that the hardness remains if we require K = |V |/2. (Similar results have been shown for other NP-complete problems.)",
        "Lemma 1.",
        "BALANCED-VERTEX-COVER is NP-complete.",
        "Proof.",
        "Membership in NP follows from the fact that the problem is a special case of VERTEX-COVER, which is in NP.",
        "To show NP-hardness, we reduce an arbitrary VERTEX-COVER instance to a BALANCED-VERTEXCOVER instance, as follows.",
        "If, for the VERTEX-COVER instance, K > |V |/2, then we simply add isolated vertices that are disjoint from the rest of the graph, until K = |V |/2.",
        "If K < |V |/2, we add isolated triangles (that is, the complete graph on three vertices) to the graph, increasing K by 2 every time, until K = |V |/2.",
        "Theorem 4.",
        "In 3-player normal-form games, finding an optimal mixed strategy to commit to is NP-hard.",
        "Proof.",
        "We reduce an arbitrary BALANCED-VERTEXCOVER instance to the following 3-player normal-form game.",
        "For every vertex v, each of the three players has a pure strategy corresponding to that vertex (rv, sv, tv, respectively).",
        "In addition, for every edge e, the third player has a pure strategy te; and finally, the third player has one additional pure strategy t0.",
        "The utilities are as follows: • for all r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • for all r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • for all v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • for all v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • for all v ∈ V , for all r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V | |V |−2 ; • for all e ∈ E, s ∈ S, for both v ∈ e, u3(rv, s, te) = 0; • for all e ∈ E, s ∈ S, for all v /∈ e, u3(rv, s, te) = |V | |V |−2 . • for all r ∈ R, s ∈ S, u3(r, s, t0) = 1.",
        "We note that players 1 and 2 have the same utility function.",
        "We claim that there is an optimal strategy profile in which players 1 and 2 both obtain 1 (their maximum utility) if and only if there is a solution to the BALANCED-VERTEXCOVER problem. (Otherwise, these players will both obtain 0.)",
        "First, suppose there exists a solution to the BALANCEDVERTEX-COVER problem.",
        "Then, let player 1 play every rv such that v is in the cover with probability 2 |V | , and let player 2 play every sv such that v is not in the cover with probability 2 |V | .",
        "Then, for player 3, the expected utility of playing tv (for any v) is (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of 2 |V | that rv or sv is played.",
        "Additionally, the expected utility of playing te (for any e) is at most (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of at least 2 |V | that some rv with v ∈ e is played (because player 1 is randomizing over the pure strategies corresponding to the cover).",
        "It follows that playing t0 is a best response for player 3, giving players 1 and 2 a utility of 1.",
        "Now, suppose that players 1 and 2 obtain 1 in optimal play.",
        "Then, it must be the case that player 3 plays t0.",
        "Hence, for every v ∈ V , there must be a probability of at least 2 |V | that either rv or sv is played, for otherwise player 3 would be better off playing tv.",
        "Because players 1 and 2 have only a total probability of 2 to distribute, it must be the case that for each v, either rv or sv is played with probability 2 |V | , and the other is played with probability 0. (It is not possible for both to have nonzero probability, because then there would be some probability that both are played simultaneously (correlation is not possible), hence the total probability of at least one being played could not be high enough for all vertices.)",
        "Thus, for exactly half the v ∈ V , player 1 places probability 2 |V | on rv.",
        "Moreover, for every e ∈ E, there must be a probability of at least 2 |V | that some rv with v ∈ e is played, for otherwise player 3 would be better off playing te.",
        "Thus, the v ∈ V such that player 1 places probability 2 |V | on rv constitute a balanced vertex cover. 3.",
        "BAYESIAN GAMES So far, we have restricted our attention to normal-form games.",
        "In a normal-form game, it is assumed that every agent knows every other agents preferences over the outcomes of the game.",
        "In general, however, agents may have some private information about their preferences that is not known to the other agents.",
        "Moreover, at the time of commitment to a strategy, the agents may not even know their own (final) preferences over the outcomes of the game yet, because these preferences may be dependent on a context that has yet to materialize.",
        "For example, when the code for a trading agent is written, it may not yet be clear how that agent will value resources that it will negotiate over later, because this depends on information that is not yet available at the time at which the code is written (such as orders that will have been placed to the agent before the negotiation).",
        "In this section, we will study commitment in Bayesian games, which can model such uncertainty over preferences. 3.1 Definitions In a Bayesian game, every player i has a set of actions Si, a set of types Θi with an associated probability distribution πi : Θi → [0, 1], and, for each type θi, a utility function uθi i : S1 × S2 × . . . × Sn → R. A pure strategy in a Bayesian game is a mapping from the players types to actions, σi : Θi → Si. (Bayesian games can be rewritten in normal form by enumerating every pure strategy σi, but this will cause an exponential blowup in the size of the representation of the game and therefore cannot lead to efficient algorithms.)",
        "The strategy that the leader should commit to depends on whether, at the time of commitment, the leader knows her own type.",
        "If the leader does know her own type, the other types that the leader might have had become irrelevant and the leader should simply commit to the strategy that is optimal for the type.",
        "However, as argued above, the leader does not necessarily know her own type at the time of commitment (e.g., the time at which the code is submitted).",
        "In this case, the leader must commit to a strategy that is 86 dependent upon the leaders eventual type.",
        "We will study this latter model, although we will pay specific attention to the case where the leader has only a single type, which is effectively the same as the former model. 3.2 Commitment to pure strategies It turns out that computing an optimal pure strategy to commit to is hard in Bayesian games, even with two players.",
        "Theorem 5.",
        "Finding an optimal pure strategy to commit to in 2-player Bayesian games is NP-hard, even when the follower has only a single type.",
        "Proof.",
        "We reduce an arbitrary VERTEX-COVER instance to the following Bayesian game between the leader and the follower.",
        "The leader has K types θ1, θ2, . . . , θK , each occurring with probability 1/K, and for every vertex v ∈ V , the leader has an action sv.",
        "The follower has only a single type; for each edge e ∈ E, the follower has an action te, and the follower has a single additional action t0.",
        "The utility function for the leader is given by, for all θl ∈ Θl and all s ∈ S, u θl l (s, t0) = 1, and for all e ∈ E, u θl l (s, te) = 0.",
        "The followers utility is given by: • For all v ∈ V , for all e ∈ E with v /∈ e, uf (sv, te) = 1; • For all v ∈ V , for all e ∈ E with v ∈ e, uf (sv, te) = −K; • For all v ∈ V , uf (sv, t0) = 0.",
        "We claim that the leader can get a utility of 1 if and only if there is a solution to the VERTEX-COVER instance.",
        "First, suppose that there is a solution to the VERTEXCOVER instance.",
        "Then, the leader can commit to a pure strategy such that for each vertex v in the cover, the leader plays sv for some type.",
        "Then, the followers utility for playing te (for any e ∈ E) is at most K−1 K + 1 K (−K) = − 1 K , so that the follower will prefer to play t0, which gives the leader a utility of 1, as required.",
        "Now, suppose that there is a pure strategy for the leader that will give the leader a utility of 1.",
        "Then, the follower must play t0.",
        "In order for the follower not to prefer playing te (for any e ∈ E) instead, for at least one v ∈ e the leader must play sv for some type θl.",
        "Hence, the set of vertices v that the leader plays for some type must constitute a vertex cover; and this set can have size at most K, because the leader has only K types.",
        "So there is a solution to the VERTEXCOVER instance.",
        "However, if the leader has only a single type, then the problem becomes easy again (#types is the number of types for the follower): Theorem 6.",
        "In 2-player Bayesian games in which the leader has only a single type, an optimal pure strategy to commit to can be found in O(#outcomes · #types) time.",
        "Proof.",
        "For every leader action s, we can compute, for every follower type θf ∈ Θf , which actions t maximize the followers utility; call this set of actions BRθf (s).",
        "Then, the utility that the leader receives for committing to action s can be computed as θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), and the leader can choose the best action to commit to. 3.3 Commitment to mixed strategies In two-player zero-sum imperfect information games with perfect recall (no player ever forgets something that it once knew), a minimax strategy can be constructed in polynomial time [12, 13].",
        "Unfortunately, this result does not extend to computing optimal mixed strategies to commit to in the general-sum case-not even in Bayesian games.",
        "We will exhibit NP-hardness by reducing from the INDEPENDENTSET problem.",
        "Definition 2.",
        "In INDEPENDENT-SET, we are given a graph G = (V, E) and an integer K. We are asked whether there exists a subset of the vertices S ⊆ V , with |S| = K, such that no edge e ∈ E has both of its endpoints in S. Again, this problem is NP-complete [9].",
        "Theorem 7.",
        "Finding an optimal mixed strategy to commit to in 2-player Bayesian games is NP-hard, even when the leader has only a single type and the follower has only two actions.",
        "Proof.",
        "We reduce an arbitrary INDEPENDENT-SET instance to the following Bayesian game between the leader and the follower.",
        "The leader has only a single type, and for every vertex v ∈ V , the leader has an action sv.",
        "The follower has a type θv for every v ∈ V , occurring with probability 1 (|E|+1)|V | , and a type θe for every e ∈ E, occurring with probability 1 |E|+1 .",
        "The follower has two actions: t0 and t1.",
        "The leaders utility is given by, for all s ∈ S, ul(s, t0) = 1 and ul(s, t1) = 0.",
        "The followers utility is given by: • For all v ∈ V , uθv f (sv, t1) = 0; • For all v ∈ V and s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • For all v ∈ V and s ∈ S, uθv f (s, t0) = 1; • For all e ∈ E, s ∈ S, uθe f (s, t0) = 1; • For all e ∈ E, for both v ∈ e, uθe f (sv, t1) = 2K 3 ; • For all e ∈ E, for all v /∈ e, uθe f (sv, t1) = 0.",
        "We claim that an optimal strategy to commit to gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | if and only if there is a solution to the INDEPENDENT-SET instance.",
        "First, suppose that there is a solution to the INDEPENDENT-SET instance.",
        "Then, the leader could commit to the following strategy: for every vertex v in the independent set, play the corresponding sv with probability 1/K.",
        "If the follower has type θe for some e ∈ E, the expected utility for the follower of playing t1 is at most 1 K 2K 3 = 2/3, because there is at most one vertex v ∈ e such that sv is played with nonzero probability.",
        "Hence, the follower will play t0 and obtain a utility of 1.",
        "If the follower has type θv for some vertex v in the independent set, the expected utility for the follower of playing t1 is K−1 K K K−1 = 1, because the leader plays sv with probability 1/K.",
        "It follows that the follower (who breaks ties to maximize the leaders utility) will play t0, which also gives a utility of 1 and gives the leader a higher utility.",
        "Hence the leaders expected utility for this strategy is at least |E| |E|+1 + K (|E|+1)|V | , as required. 87 Now, suppose that there is a strategy that gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | .",
        "Then, this strategy must induce the follower to play t0 whenever it has a type of the form θe (because otherwise, the utility could be at most |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ).",
        "Thus, it cannot be the case that for some edge e = (v1, v2) ∈ E, the probability that the leader plays one of sv1 and sv2 is at least 2/K, because then the expected utility for the follower of playing t1 when it has type θe would be at least 2 K 2K 3 = 4/3 > 1.",
        "Moreover, the strategy must induce the follower to play t0 for at least K types of the form θv.",
        "Inducing the follower to play t0 when it has type θv can be done only by playing sv with probability at least 1/K, which will give the follower a utility of at most K−1 K K K−1 = 1 for playing t1.",
        "But then, the set of vertices v such that sv is played with probability at least 1/K must constitute an independent set of size K (because if there were an edge e between two such vertices, it would induce the follower to play t1 for type θe by the above).",
        "By contrast, if the follower has only a single type, then we can generalize the linear programming approach for normalform games: Theorem 8.",
        "In 2-player Bayesian games in which the follower has only a single type, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
        "Proof.",
        "We generalize the approach in Theorem 2 as follows.",
        "For every pure follower strategy t, we compute a mixed strategy for the leader for every one of the leaders types such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders ex ante expected utility.",
        "To do so, we generalize the linear program as follows: maximize θl∈Θl π(θl) s∈S pθl s uθl l (s, t) subject to for all t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t ) for all θl ∈ Θl, s∈S p θl s = 1 As in Theorem 2, the solution for the linear program that maximizes the solution value is an optimal strategy to commit to.",
        "This shows an interesting contrast between commitment to pure strategies and commitment to mixed strategies in Bayesian games: for pure strategies, the problem becomes easy if the leader has only a single type (but not if the follower has only a single type), whereas for mixed strategies, the problem becomes easy if the follower has only a single type (but not if the leader has only a single type). 4.",
        "CONCLUSIONS AND FUTURE RESEARCH In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
        "This requires some equilibrium notion (Nash equilibrium and its refinements), and often leads to the equilibrium selection problem: it is unclear to each individual player according to which equilibrium she should play.",
        "However, this model is not always realistic.",
        "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
        "For example, one agent may arrive at the (real or virtual) site of the game before the other, or, in the specific case of software agents, the code for one agent may be completed and committed before that of another agent.",
        "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
        "Specifically, if commitment to mixed strategies is possible, then (optimal) commitment never hurts the leader, and often helps.",
        "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
        "In this paper, we studied how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
        "For normal-form games, we showed that the optimal pure strategy to commit to can be found efficiently for any number of players.",
        "An optimal mixed strategy to commit to in a normal-form game can be found efficiently for two players using linear programming (and no more efficiently than that, in the sense that any linear program with a probability constraint can be encoded as such a problem). (This is a generalization of the polynomial-time computability of minimax strategies in normal-form games.)",
        "The problem becomes NP-hard for three (or more) players.",
        "In Bayesian games, the problem of finding an optimal pure strategy to commit to is NP-hard even in two-player games in which the follower has only a single type, although two-player games in which the leader has only a single type can be solved efficiently.",
        "The problem of finding an optimal mixed strategy to commit to in a Bayesian game is NP-hard even in two-player games in which the leader has only a single type, although two-player games in which the follower has only a single type can be solved efficiently using a generalization of the linear progamming approach for normal-form games.",
        "The following two tables summarize these results. 2 players ≥ 3 players normal-form O(#outcomes) O(#outcomes· #players) Bayesian, O(#outcomes· NP-hard 1-type leader #types) Bayesian, NP-hard NP-hard 1-type follower Bayesian (general) NP-hard NP-hard Results for commitment to pure strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.) 88 2 players ≥ 3 players normal-form one LP-solve per NP-hard follower action Bayesian, NP-hard NP-hard 1-type leader Bayesian, one LP-solve per NP-hard 1-type follower follower action Bayesian (general) NP-hard NP-hard Results for commitment to mixed strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.)",
        "Future research can take a number of directions.",
        "First, we can empirically evaluate the techniques presented here on test suites such as GAMUT [19].",
        "We can also study the computation of optimal strategies to commit to in other1 concise representations of normal-form games-for example, in graphical games [10] or local-effect/action graph games [14, 1].",
        "For the cases where computing an optimal strategy to commit to is NP-hard, we can also study the computation of approximately optimal strategies to commit to.",
        "While the correct definition of an approximately optimal strategy is in this setting may appear simple at first-it should be a strategy that, if the following players play optimally, performs almost as well as the optimal strategy in expectation-this definition becomes problematic when we consider that the other players may also be playing only approximately optimally.",
        "One may also study models in which multiple (but not all) players commit at the same time.",
        "Another interesting direction to pursue is to see if computing optimal mixed strategies to commit to can help us in, or otherwise shed light on, computing Nash equilibria.",
        "Often, optimal mixed strategies to commit to are also Nash equilibrium strategies (for example, in two-player zero-sum games this is always true), although this is not always the case (for example, as we already pointed out, sometimes the optimal strategy to commit to is a strictly dominated strategy, which can never be a Nash equilibrium strategy). 5.",
        "REFERENCES [1] N. A. R. Bhat and K. Leyton-Brown.",
        "Computing Nash equilibria of action-graph games.",
        "In Proceedings of the 20th Annual Conference on Uncertainty in Artificial Intelligence (UAI), Banff, Canada, 2004. [2] V. Conitzer and T. Sandholm.",
        "Complexity results about Nash equilibria.",
        "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pages 765-771, Acapulco, Mexico, 2003. [3] V. Conitzer and T. Sandholm.",
        "Complexity of (iterated) dominance.",
        "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 88-97, Vancouver, Canada, 2005. [4] V. Conitzer and T. Sandholm.",
        "A generalized strategy eliminability criterion and computational methods for applying it.",
        "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 483-488, Pittsburgh, PA, USA, 2005. [5] A.",
        "A. Cournot.",
        "Recherches sur les principes math´ematiques de la th´eorie des richesses (Researches 1 Bayesian games are one potentially concise representation of normal-form games. into the Mathematical Principles of the Theory of Wealth).",
        "Hachette, Paris, 1838. [6] G. Dantzig.",
        "A proof of the equivalence of the programming problem and the game problem.",
        "In T. Koopmans, editor, Activity Analysis of Production and Allocation, pages 330-335.",
        "John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel.",
        "The complexity of eliminating dominated strategies.",
        "Mathematics of Operation Research, 18:553-565, 1993. [8] I. Gilboa and E. Zemel.",
        "Nash and correlated equilibria: Some complexity considerations.",
        "Games and Economic Behavior, 1:80-93, 1989. [9] R. Karp.",
        "Reducibility among combinatorial problems.",
        "In R. E. Miller and J. W. Thatcher, editors, Complexity of Computer Computations, pages 85-103.",
        "Plenum Press, NY, 1972. [10] M. Kearns, M. Littman, and S. Singh.",
        "Graphical models for game theory.",
        "In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou, and J. N. Tsitsiklis.",
        "A note on strategy elimination in bimatrix games.",
        "Operations Research Letters, 7(3):103-107, 1988. [12] D. Koller and N. Megiddo.",
        "The complexity of two-person zero-sum games in extensive form.",
        "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo, and B. von Stengel.",
        "Efficient computation of equilibria for extensive two-person games.",
        "Games and Economic Behavior, 14(2):247-259, 1996. [14] K. Leyton-Brown and M. Tennenholtz.",
        "Local-effect games.",
        "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), Acapulco, Mexico, 2003. [15] R. Lipton, E. Markakis, and A. Mehta.",
        "Playing large games using simple strategies.",
        "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 36-41, San Diego, CA, 2003. [16] M. Littman and P. Stone.",
        "A polynomial-time Nash equilibrium algorithm for repeated games.",
        "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 48-54, San Diego, CA, 2003. [17] R. D. Luce and H. Raiffa.",
        "Games and Decisions.",
        "John Wiley and Sons, New York, 1957.",
        "Dover republication 1989. [18] J. Nash.",
        "Equilibrium points in n-person games.",
        "Proc. of the National Academy of Sciences, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown, and Y. Shoham.",
        "Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms.",
        "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), New York, NY, USA, 2004. [20] M. J. Osborne and A. Rubinstein.",
        "A Course in Game Theory.",
        "MIT Press, 1994. [21] C. Papadimitriou.",
        "Algorithms, games and the Internet.",
        "In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 749-753, 2001. 89 [22] R. Porter, E. Nudelman, and Y. Shoham.",
        "Simple search methods for finding a Nash equilibrium.",
        "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 664-669, San Jose, CA, USA, 2004. [23] T. Sandholm, A. Gilpin, and V. Conitzer.",
        "Mixed-integer programming methods for finding Nash equilibria.",
        "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 495-501, Pittsburgh, PA, USA, 2005. [24] J. von Neumann.",
        "Zur Theorie der Gesellschaftsspiele.",
        "Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg.",
        "Marktform und Gleichgewicht.",
        "Springer, Vienna, 1934. [26] B. von Stengel and S. Zamir.",
        "Leadership with commitment to mixed strategies.",
        "CDAM Research Report LSE-CDAM-2004-01, London School of Economics, Feb. 2004. 90"
    ],
    "translated_text_sentences": [
        "En sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias simultáneamente.",
        "Sin embargo, este modelo no siempre es realista.",
        "En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión.",
        "Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente.",
        "El reciente aumento en el interés por las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo).",
        "En este artículo, estudiamos cómo calcular estrategias óptimas a comprometerse tanto en el compromiso de estrategias puras como en el compromiso de estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos.",
        "Ofrecemos tanto resultados positivos (algoritmos eficientes) como resultados negativos (resultados de NP-hardness).",
        "Categorías y Descriptores de Asignaturas J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas Términos Generales Algoritmos, Economía, Teoría 1.",
        "En sistemas multiagentes con agentes auto-interesados (incluyendo la mayoría de los entornos económicos), la acción óptima que un agente debe tomar depende de las acciones que tomen los otros agentes.",
        "Para analizar cómo un agente debería comportarse en tales situaciones, es necesario aplicar las herramientas de la teoría de juegos.",
        "Normalmente, cuando se modela un escenario estratégico en el marco de la teoría de juegos, se asume que los jugadores eligen sus estrategias de forma simultánea.",
        "Esto es especialmente cierto cuando el escenario se modela como un juego en forma normal, que solo especifica la utilidad de cada agente como una función del vector de estrategias que los agentes eligen, y no proporciona información sobre el orden en que los agentes toman sus decisiones y lo que los agentes observan sobre las decisiones anteriores de otros agentes.",
        "Dado que el juego está modelado en forma normal, típicamente se analiza utilizando el concepto de equilibrio de Nash.",
        "Un equilibrio de Nash especifica una estrategia para cada jugador, de modo que ningún jugador tenga un incentivo para desviarse individualmente de este perfil de estrategias. (Por lo general, se permite que las estrategias sean mixtas, es decir, distribuciones de probabilidad sobre las estrategias originales (puras).)",
        "Un equilibrio de Nash (de estrategia mixta) está garantizado de existir en juegos finitos [18], pero un problema es que puede haber múltiples equilibrios de Nash.",
        "Esto conduce al problema de selección de equilibrio de cómo un agente puede saber qué estrategia jugar si no sabe qué equilibrio se va a jugar.",
        "Cuando el escenario se modela como un juego de forma extensiva, es posible especificar que algunos jugadores reciben información sobre las acciones tomadas por otros antes en el juego antes de decidir su acción.",
        "Sin embargo, en general, los jugadores no saben todo lo que sucedió anteriormente en el juego.",
        "Por lo tanto, estos juegos suelen ser analizados todavía utilizando un concepto de equilibrio, donde se especifica una estrategia mixta para cada jugador, y se requiere que la estrategia de cada jugador sea una mejor respuesta a las estrategias de los demás. (Normalmente se impone ahora una restricción adicional en las estrategias para garantizar que los jugadores no jueguen de una manera irracional con respecto a la información que han recibido hasta el momento).",
        "Esto conduce a refinamientos del equilibrio de Nash como el equilibrio perfecto en subjuegos y el equilibrio secuencial.",
        "Sin embargo, en muchos entornos del mundo real, las estrategias no se seleccionan de manera simultánea.",
        "A menudo, un jugador (el líder) puede comprometerse con una estrategia antes que otro jugador (el seguidor).",
        "Esto puede deberse a una variedad de razones.",
        "Por ejemplo, uno de los jugadores puede llegar al lugar donde se jugará el juego antes que otro agente (por ejemplo, en entornos económicos, un jugador puede ingresar al mercado antes y comprometerse con una forma de hacer negocios).",
        "Un compromiso tan poderoso tiene un impacto profundo en cómo debería jugarse el juego.",
        "Por ejemplo, el líder puede estar mejor jugando una estrategia que esté dominada en la representación de forma normal del juego.",
        "Quizás el ejemplo más temprano y conocido del efecto del compromiso es el de von Stackelberg [25], quien demostró que, en el modelo de duopolio de Cournot [5], si una empresa puede comprometerse con una cantidad de producción primero, esa empresa lo hará mucho mejor que en la solución de movimiento simultáneo (Nash).",
        "En general, si es posible comprometerse con estrategias mixtas, entonces (bajo suposiciones menores) nunca perjudica, y a menudo ayuda, comprometerse con una estrategia [26].",
        "Verse obligado a comprometerse con una estrategia pura a veces ayuda y a veces perjudica (por ejemplo, comprometerse con una estrategia pura en piedra-papel-tijeras antes de la decisión de los otros jugadores naturalmente resultará en una derrota).",
        "En este documento, asumiremos que el compromiso siempre es forzado; si no lo es, el jugador que tiene la opción de comprometerse simplemente puede comparar el resultado del compromiso con el resultado de no comprometerse (movimiento simultáneo).",
        "Los modelos de liderazgo son especialmente importantes en entornos con múltiples agentes de software con intereses propios.",
        "Una vez que el código de un agente (o de un equipo de agentes) está finalizado y el agente es desplegado, el agente se compromete a jugar la estrategia (posiblemente aleatoria) que el código prescribe.",
        "Por lo tanto, siempre y cuando se pueda demostrar de manera creíble que no se puede cambiar el código más tarde, el código funciona como un dispositivo de compromiso.",
        "Esto es válido para torneos recreativos entre agentes (por ejemplo, torneos de póker, RoboSoccer) y para aplicaciones industriales como redes de sensores.",
        "Finalmente, también existe una situación de liderazgo implícito en el campo del diseño de mecanismos, en la cual un jugador (el diseñador) tiene la oportunidad de elegir las reglas del juego que los demás jugadores luego siguen.",
        "El diseño de mecanismos es un tema extremadamente importante para la comunidad de EC: los artículos publicados sobre diseño de mecanismos en las recientes conferencias de EC son demasiados para citar.",
        "De hecho, el diseñador del mecanismo puede beneficiarse al comprometerse con una elección que, si las acciones de los agentes (restantes) estuvieran fijas, sería subóptima.",
        "Por ejemplo, en una subasta (a precio fijo), el vendedor puede desear establecer un precio de reserva positivo (artificial) para el artículo, por debajo del cual el artículo no se venderá, incluso si el vendedor valora el artículo en 0.",
        "En retrospectiva (después de recibir las ofertas), esto (ingenuamente) parece subóptimo: si llegaba una oferta que superaba el precio de reserva, el precio de reserva no tenía efecto, y si no llegaba tal oferta, el vendedor hubiera estado mejor aceptando una oferta más baja.",
        "Por supuesto, la razón para establecer el precio de reserva es incentivar a los postores a ofertar más alto, y debido a esto, establecer precios de reserva artificiales puede aumentar realmente los ingresos esperados para el vendedor.",
        "Recientemente se ha dedicado una cantidad significativa de investigación al cálculo de soluciones de acuerdo con varios conceptos de solución para escenarios en los que los agentes eligen sus estrategias simultáneamente, como la dominancia [7, 11, 3] y (especialmente) el equilibrio de Nash [8, 21, 16, 15, 2, 22, 23, 4].",
        "Sin embargo, se ha ignorado el cálculo de la estrategia óptima a comprometerse en una situación de liderazgo.",
        "Teóricamente, las situaciones de liderazgo simplemente pueden ser consideradas como un juego de forma extensiva en el que un jugador elige una estrategia (para el juego original) primero.",
        "El número de estrategias en este juego de forma extensiva, sin embargo, puede ser extremadamente grande.",
        "Por ejemplo, si el líder es capaz de comprometerse con una estrategia mixta en el juego original, entonces cada una de las estrategias mixtas (continuo de) constituye una estrategia pura en la representación de forma extensiva de la situación de liderazgo. (Se destaca que un compromiso con una distribución no es lo mismo que una distribución sobre compromisos).",
        "Además, si el juego original es en sí mismo un juego de forma extensiva, el número de estrategias en la representación de forma extensiva de la situación de liderazgo (que es un juego de forma extensiva diferente) se vuelve aún más grande.",
        "Por lo tanto, generalmente no es factible computacionalmente simplemente transformar el juego original en la representación de forma extensiva de la situación de liderazgo; en su lugar, debemos analizar el juego en su representación original.",
        "En este artículo, estudiamos cómo calcular la estrategia óptima a comprometerse, tanto en juegos de forma normal (Sección 2) como en juegos bayesianos, que son un caso especial de juegos de forma extensiva (Sección 3).",
        "JUEGOS EN FORMA NORMAL En esta sección, estudiamos cómo calcular la estrategia óptima a comprometerse para juegos representados en forma normal. 2.1 Definiciones En un juego en forma normal, cada jugador i ∈ {1, . . . , n} tiene un conjunto de estrategias puras (o acciones) Si, y una función de utilidad ui : S1×S2×. . .×Sn → R que mapea cada resultado (un vector que consiste en una estrategia pura para cada jugador, también conocido como un perfil de estrategias puras) a un número real.",
        "Para facilitar la notación, en el caso de dos jugadores, nos referiremos al conjunto de estrategias puras del jugador 1 como S, y al conjunto de estrategias puras del jugador 2 como T. Estos juegos pueden representarse en forma de matriz (bi-matriz), en la que las filas corresponden a las estrategias puras del jugador 1, las columnas corresponden a las estrategias puras del jugador 2, y las entradas de la matriz dan las utilidades de los jugadores de fila y columna (en ese orden) para el resultado correspondiente del juego.",
        "En el caso de tres jugadores, usaremos R, S y T, para las estrategias puras de los jugadores 1, 2 y 3, respectivamente.",
        "Una estrategia mixta para un jugador es una distribución de probabilidad sobre las estrategias puras de ese jugador.",
        "En el caso de juegos de dos jugadores, nos referiremos al jugador 1 como el líder y al jugador 2 como el seguidor.",
        "Antes de definir estrategias de liderazgo óptimas, considera el siguiente juego que ilustra el efecto de la capacidad del líder para comprometerse. 2, 1 4, 0 1, 0 3, 1 En esta representación en forma normal, la estrategia inferior para el jugador de la fila está estrictamente dominada por la estrategia superior.",
        "Sin embargo, si el jugador de la fila tiene la capacidad de comprometerse con una estrategia pura antes de que el jugador de la columna elija su estrategia, el jugador de la fila debería comprometerse con la estrategia inferior: al hacerlo, el jugador de la columna preferirá jugar la estrategia correcta, lo que llevará a una utilidad de 3 para el jugador de la fila.",
        "Por el contrario, si el jugador de la fila se comprometiera con la estrategia superior, el jugador de la columna preferiría jugar la estrategia izquierda, lo que llevaría a una utilidad de solo 2 para el jugador de la fila.",
        "Si el jugador de la fila puede comprometerse a una estrategia mixta, entonces puede obtener una utilidad aún mayor (esperada): si el jugador de la fila se compromete a colocar una probabilidad p > 1/2 en la estrategia inferior, entonces el jugador de la columna seguirá prefiriendo jugar la estrategia derecha, y la utilidad esperada de los jugadores de la fila será 3p + 4(1 − p) = 4 − p ≥ 3.",
        "Si el jugador de la fila juega cada estrategia con una probabilidad exacta de 1/2, el jugador de la columna está 83 indiferente entre las estrategias.",
        "En tales casos, asumiremos que el jugador de la columna elegirá la estrategia que maximiza la utilidad de los jugadores de la fila (en este caso, la estrategia correcta).",
        "Por lo tanto, la estrategia mixta óptima a la que debe comprometerse el jugador de la fila es p = 1/2.",
        "Hay algunas buenas razones para esta suposición.",
        "Si asumiéramos lo contrario, entonces no existiría una estrategia óptima para el jugador de la fila en el juego de ejemplo: el jugador de la fila jugaría la estrategia inferior con una probabilidad p = 1/2 + con > 0, y cuanto menor sea , mejor será la utilidad para el jugador de la fila.",
        "Por el contrario, si asumimos que el seguidor siempre rompe los empates a favor de los líderes, entonces siempre existe una estrategia mixta óptima para el líder, lo que corresponde a un equilibrio perfecto en subjuegos de la representación en forma extensiva de la situación de liderazgo.",
        "En cualquier caso, esta es una suposición estándar para tales modelos (por ejemplo, [20]), aunque algunos trabajos han investigado lo que puede suceder en los otros equilibrios perfectos de subjuego [26]. (Para juegos genéricos de dos jugadores, el pago del equilibrio perfecto de subjuego de los líderes es único).",
        "Además, la misma suposición se utiliza típicamente en el diseño de mecanismos, asumiendo que si un agente es indiferente entre revelar sus preferencias de manera veraz o falsa, las reportará de manera veraz.",
        "Dado este supuesto, podemos hacer referencia de manera segura a estrategias de liderazgo óptimas en lugar de tener que utilizar alguna noción de equilibrio.",
        "Por lo tanto, para los propósitos de este documento, una estrategia óptima a comprometerse en un juego de 2 jugadores es una estrategia s ∈ S que maximiza maxt∈BR(s) ul(s, t), donde BR(s) = arg maxt∈T uf (s, t). (ul y uf son las funciones de utilidad del líder y los seguidores, respectivamente).",
        "Podemos tener S = S para el caso de compromiso con estrategias puras, o S = ∆(S), el conjunto de distribuciones de probabilidad sobre S, para el caso de compromiso con estrategias mixtas. (Observamos que reemplazar T por ∆(T) no hace ninguna diferencia en esta definición).",
        "Para juegos con más de dos jugadores, en los que los jugadores se comprometen con sus estrategias en secuencia, definimos estrategias óptimas a las que comprometerse de forma recursiva.",
        "Después de que el líder se compromete con una estrategia, el juego que jugarán los agentes restantes es en sí mismo un juego de liderazgo (más pequeño).",
        "Por lo tanto, definimos una estrategia óptima a comprometerse como una estrategia que maximiza la utilidad del líder, asumiendo que el juego de los agentes restantes es óptimo bajo esta definición, y maximiza la utilidad del líder entre todas las formas óptimas de jugar el juego restante.",
        "Nuevamente, el compromiso con estrategias mixtas puede o no ser una posibilidad para cada jugador (aunque para el último jugador no importa si permitimos el compromiso con estrategias mixtas). 2.2 Compromiso con estrategias puras. Primero estudiamos cómo calcular la estrategia pura óptima a la que comprometerse.",
        "Esto es relativamente simple, porque el número de estrategias a comprometer no es muy grande. (En lo siguiente, #resultados es el número de perfiles de estrategia completos).",
        "Teorema 1.",
        "Bajo el compromiso de estrategias puras, el conjunto de todos los perfiles de estrategia óptimos en un juego en forma normal se puede encontrar en tiempo O(#jugadores · #resultados).",
        "Prueba.",
        "Cada estrategia pura a la que el primer jugador pueda comprometerse inducirá un subjuego para los jugadores restantes.",
        "Podemos resolver cada subjuego de esta manera de forma recursiva para encontrar todos sus perfiles de estrategia óptimos; cada uno de estos le dará al líder original cierta utilidad.",
        "Aquellos que proporcionan al líder la utilidad máxima corresponden exactamente a los perfiles de estrategia óptimos del juego original.",
        "Ahora presentamos el algoritmo de forma formal.",
        "Sea Su(G, s1) el subjuego que resulta después de que el primer jugador restante en G juega s1 ∈ SG 1.",
        "Un juego con 0 jugadores es simplemente un resultado del juego.",
        "La función Append(s, O) añade la estrategia s a cada uno de los vectores de estrategias en el conjunto O.",
        "Sea e el vector vacío sin elementos.",
        "En un ligero abuso de notación, escribiremos uG 1 (C) cuando todos los perfiles estratégicos en el conjunto C le den al jugador 1 la misma utilidad en el juego G. (Aquí, el jugador 1 es el primer jugador restante en el subjuego G, no necesariamente el jugador 1 en el juego original).",
        "Observamos que arg max es un conjunto de valores.",
        "Entonces, el siguiente algoritmo calcula todos los perfiles de estrategia óptimos: Algoritmo Resolver(G) si G tiene 0 jugadores, devuelve {e} C ← ∅ para todo s1 ∈ SG 1 { O ← Resolver(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) si C = ∅ o uG 1 (s1, O ) = uG 1 (C) C ← C∪Agregar(s1, O ) si uG 1 (s1, O ) > uG 1 (C) C ←Agregar(s1, O ) } devuelve C Cada resultado es examinado (potencialmente) por cada jugador, lo que lleva al límite de tiempo dado.",
        "Como ejemplo de cómo funciona el algoritmo, considera el siguiente juego de 3 jugadores, en el que el primer jugador elige la matriz izquierda o derecha, el segundo jugador elige una fila y el tercer jugador elige una columna. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 Primero eliminamos los resultados que no corresponden a las mejores respuestas para el tercer jugador (eliminándolos de la matriz): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Luego, eliminamos las entradas en las que el tercer jugador no resuelve los empates a favor del segundo jugador, así como las entradas que no corresponden a las mejores respuestas para el segundo jugador. 0,1,1 2,1,1 1,1,1 0,5,1 Finalmente, eliminamos las entradas en las que el segundo y tercer jugador no resuelven los empates a favor del primer jugador, así como las entradas que no corresponden a las mejores respuestas para el primer jugador. 2,1,1 Por lo tanto, en el juego óptimo, el primer jugador elige la matriz izquierda, el segundo jugador elige la fila del medio y el tercer jugador elige la columna izquierda. (Notamos que este resultado está dominado por Pareto por (Derecha, Medio, Izquierda).)",
        "Para juegos en forma normal general, la utilidad de cada jugador para cada uno de los resultados debe representarse explícitamente en la entrada, de modo que el tamaño de la entrada sea en sí mismo Ω(#jugadores · #resultados).",
        "Por lo tanto, el algoritmo es de hecho un algoritmo de tiempo lineal. 2.3 Compromiso con estrategias mixtas En el caso especial de juegos de dos jugadores de suma cero, calcular una estrategia mixta óptima para que el líder se comprometa es equivalente a calcular una estrategia minimax, que minimiza la utilidad esperada máxima que el oponente puede obtener.",
        "Las estrategias minimax constituyen el único concepto de solución natural para juegos de suma cero de dos jugadores: el Teorema Minimax de von Neumann [24] establece que en juegos de suma cero de dos jugadores, no importa (en términos de las utilidades de los jugadores) qué jugador se compromete primero a una estrategia mixta, y un perfil de estrategias mixtas es un equilibrio de Nash si y solo si ambas estrategias son estrategias minimax.",
        "Es bien sabido que una estrategia minimax se puede encontrar en tiempo polinómico, utilizando programación lineal [17].",
        "Nuestro primer resultado en esta sección generaliza este resultado, mostrando que una estrategia mixta óptima para que el líder se comprometa puede ser calculada eficientemente en juegos de dos jugadores de suma general, nuevamente utilizando programación lineal.",
        "Teorema 2.",
        "En juegos de forma normal de 2 jugadores, una estrategia mixta óptima a la que comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal.",
        "Prueba.",
        "Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder de modo que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad del líder.",
        "Un programa lineal simple puede calcular una estrategia mixta como la siguiente: maximizar s∈S psul(s, t) sujeto a que para todo t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1. Se destaca que este programa puede ser inviable para algunas estrategias seguidoras t, por ejemplo, si t es una estrategia estrictamente dominada.",
        "Sin embargo, el programa debe ser factible para al menos algunas estrategias seguidoras; entre estas estrategias seguidoras, elige una estrategia t∗ que maximice el valor de la solución de los programas lineales.",
        "Entonces, si la líder elige como su estrategia mixta los ajustes óptimos de las variables ps para el programa lineal para t∗, y el seguidor juega t∗, esto constituye un perfil de estrategia óptimo.",
        "En el siguiente resultado, demostramos que no podemos esperar resolver el problema de manera más eficiente que la programación lineal, ya que podemos reducir cualquier programa lineal con una restricción de probabilidad en sus variables a un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores.",
        "Teorema 3.",
        "Cualquier programa lineal cuyas variables xi (con xi ∈ R≥0) deben satisfacer i xi = 1 puede ser modelado como un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores.",
        "Prueba.",
        "Que el líder tenga una estrategia pura i para cada variable xi.",
        "Que el jugador de la columna tenga una estrategia pura j para cada restricción en el programa lineal (distinta de i xi = 1), y una única estrategia pura adicional 0.",
        "Que las funciones de utilidad sean las siguientes.",
        "Escribiendo el objetivo del programa lineal como maximizar ci xi, para cualquier i, dejando ul(i, 0) = ci y uf(i, 0) = 0.",
        "Escribiendo la j-ésima restricción del programa lineal (sin incluir i xi = 1) como i aijxi ≤ bj, para cualquier i, j > 0, sea ul(i, j) = mini ci − 1 y uf(i, j) = aij − bj.",
        "Por ejemplo, considera el siguiente programa lineal. maximizar 2x1 + x2 sujeto a x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 La solución óptima de este programa es x1 = 1/3, x2 = 2/3.",
        "Nuestra reducción transforma este programa en el siguiente juego de líder-seguidor (donde el líder es el jugador de la fila). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 De hecho, la estrategia óptima para el líder es jugar la estrategia superior con una probabilidad de 1/3 y la estrategia inferior con una probabilidad de 2/3.",
        "Ahora demostramos que la reducción funciona en general.",
        "Claramente, el líder quiere incentivar al seguidor a jugar 0, porque la utilidad que el líder obtiene cuando el seguidor juega 0 siempre es mayor que cuando el seguidor no juega 0.",
        "Para que el seguidor no prefiera jugar j > 0 en lugar de 0, debe ser el caso que i pl(i)(aij − bj) ≤ 0, o equivalentemente i pl(i)aij ≤ bj.",
        "Por lo tanto, el líder obtendrá una utilidad de al menos mini ci si y solo si hay una solución factible a las restricciones.",
        "Dado que el pl(i) incentiva al seguidor a jugar 0, el líder intenta maximizar i pl(i)ci.",
        "Por lo tanto, el líder debe resolver el programa lineal original.",
        "Como prueba alternativa del Teorema 3, se puede observar que se sabe que encontrar una estrategia minimax en un juego de suma cero es tan difícil como el problema de programación lineal [6], y como señalamos al principio de esta sección, calcular una estrategia minimax en un juego de suma cero es un caso especial del problema de calcular una estrategia mixta óptima a la que comprometerse.",
        "La solubilidad en tiempo polinómico del problema de calcular una estrategia mixta óptima a la que comprometerse en juegos de forma normal de dos jugadores contrasta con la complejidad desconocida de calcular un equilibrio de Nash en tales juegos [21], así como con la NP-dificultad de encontrar un equilibrio de Nash con utilidad máxima para un jugador dado en tales juegos [8, 2].",
        "Desafortunadamente, este resultado no se generaliza a más de dos jugadores; aquí, el problema se vuelve NP-duro.",
        "Para demostrar esto, reducimos desde el problema de CUBRIR-VÉRTICES.",
        "Definición 1.",
        "En VERTEX-COVER, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que cada arista e ∈ E tenga al menos uno de sus extremos en S. BALANCED-VERTEX-COVER es el caso especial de VERTEX-COVER en el que K = |V|/2.",
        "VERTEX-COVER es NP-completo [9].",
        "El siguiente lema muestra que la dificultad persiste si requerimos K = |V|/2. (Resultados similares se han demostrado para otros problemas NP-completos).",
        "Lema 1.",
        "El problema de la COBERTURA DE VÉRTICES EQUILIBRADA es NP-completo.",
        "Prueba.",
        "La pertenencia a NP se deriva del hecho de que el problema es un caso especial de CUBRIMIENTO DE VÉRTICES, que está en NP.",
        "Para demostrar la NP-dificultad, reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES a una instancia de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO, de la siguiente manera.",
        "Si, para la instancia de CUBRIMIENTO DE VÉRTICES, K > |V|/2, simplemente agregamos vértices aislados que estén disjuntos del resto del grafo, hasta que K = |V|/2.",
        "Si K < |V|/2, agregamos triángulos aislados (es decir, el grafo completo de tres vértices) al grafo, aumentando K en 2 cada vez, hasta que K = |V|/2.",
        "Teorema 4.",
        "En juegos de forma normal de 3 jugadores, encontrar una estrategia mixta óptima a la que comprometerse es NP-difícil.",
        "Prueba.",
        "Reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO al siguiente juego de forma normal de 3 jugadores.",
        "Para cada vértice v, cada uno de los tres jugadores tiene una estrategia pura correspondiente a ese vértice (rv, sv, tv, respectivamente).",
        "Además, para cada arista e, el tercer jugador tiene una estrategia pura te; y finalmente, el tercer jugador tiene una estrategia pura adicional t0.",
        "Los servicios son los siguientes: • para todo r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • para todo r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • para todo v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • para todo v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • para todo v ∈ V, para todo r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V| |V|−2; • para todo e ∈ E, s ∈ S, para ambos v ∈ e, u3(rv, s, te) = 0; • para todo e ∈ E, s ∈ S, para todo v /∈ e, u3(rv, s, te) = |V| |V|−2. • para todo r ∈ R, s ∈ S, u3(r, s, t0) = 1.",
        "Observamos que los jugadores 1 y 2 tienen la misma función de utilidad.",
        "Sostenemos que existe un perfil de estrategia óptimo en el que los jugadores 1 y 2 obtienen ambos 1 (su utilidad máxima) si y solo si hay una solución al problema de la COBERTURA DE VÉRTICES EQUILIBRADA. (De lo contrario, estos jugadores obtendrán ambos 0).",
        "Primero, supongamos que existe una solución al problema de la cubierta de vértices balanceada.",
        "Entonces, deja que el jugador 1 juegue cada rv de manera que v esté en la cobertura con probabilidad 2 |V|, y deja que el jugador 2 juegue cada sv de manera que v no esté en la cobertura con probabilidad 2 |V|.",
        "Entonces, para el jugador 3, la utilidad esperada de jugar tv (para cualquier v) es (1 − 2 |V|) |V| |V|−2 = 1, porque hay una probabilidad de 2 |V| de que se juegue rv o sv.",
        "Además, la utilidad esperada de jugar te (para cualquier e) es a lo sumo (1 − 2 |V | ) |V | |V |−2 = 1, porque hay una probabilidad de al menos 2 |V | de que algún rv con v ∈ e se juegue (debido a que el jugador 1 está aleatorizando sobre las estrategias puras correspondientes a la cobertura).",
        "Se deduce que jugar t0 es la mejor respuesta para el jugador 3, otorgando a los jugadores 1 y 2 una utilidad de 1.",
        "Ahora, supongamos que los jugadores 1 y 2 obtienen 1 en el juego óptimo.",
        "Entonces, debe ser el caso de que el jugador 3 juegue t0.",
        "Por lo tanto, para cada v ∈ V, debe haber una probabilidad de al menos 2 |V| de que se juegue rv o sv, de lo contrario, al jugador 3 le convendría más jugar tv.",
        "Dado que los jugadores 1 y 2 solo tienen una probabilidad total de 2 para distribuir, debe ser el caso que para cada v, ya sea rv o sv se juegue con una probabilidad de 2 |V|, y el otro se juegue con una probabilidad de 0. (No es posible que ambos tengan una probabilidad distinta de cero, porque entonces habría alguna probabilidad de que ambos se jugaran simultáneamente (la correlación no es posible), por lo tanto, la probabilidad total de que al menos uno se juegue no podría ser lo suficientemente alta para todos los vértices).",
        "Por lo tanto, para exactamente la mitad de los v ∈ V, el jugador 1 coloca una probabilidad de 2 |V| en rv.",
        "Además, para cada e ∈ E, debe haber una probabilidad de al menos 2 |V | de que se juegue algún rv con v ∈ e, de lo contrario, al jugador 3 le convendría más jugar te.",
        "Por lo tanto, el v ∈ V tal que el jugador 1 coloca una probabilidad de 2 |V | en rv constituye una cubierta de vértices equilibrada. 3.",
        "Juegos bayesianos. Hasta ahora, hemos restringido nuestra atención a los juegos en forma normal.",
        "En un juego en forma normal, se asume que cada agente conoce las preferencias de todos los demás agentes sobre los resultados del juego.",
        "En general, sin embargo, los agentes pueden tener información privada sobre sus preferencias que no es conocida por los otros agentes.",
        "Además, en el momento de comprometerse con una estrategia, los agentes pueden ni siquiera conocer sus propias preferencias (finales) sobre los resultados del juego aún, ya que estas preferencias pueden depender de un contexto que aún no se ha materializado.",
        "Por ejemplo, cuando se escribe el código para un agente de negociación, puede que aún no esté claro cómo ese agente valorará los recursos sobre los que negociará más adelante, porque esto depende de información que aún no está disponible en el momento en que se escribe el código (como órdenes que habrán sido colocadas al agente antes de la negociación).",
        "En esta sección, estudiaremos el compromiso en juegos bayesianos, los cuales pueden modelar tal incertidumbre sobre preferencias. 3.1 Definiciones En un juego bayesiano, cada jugador i tiene un conjunto de acciones Si, un conjunto de tipos Θi con una distribución de probabilidad asociada πi : Θi → [0, 1], y, para cada tipo θi, una función de utilidad uθi i : S1 × S2 × . . . × Sn → R. Una estrategia pura en un juego bayesiano es una asignación de los tipos de los jugadores a acciones, σi : Θi → Si. (Los juegos bayesianos pueden ser reescritos en forma normal enumerando cada estrategia pura σi, pero esto causará un crecimiento exponencial en el tamaño de la representación del juego y por lo tanto no puede llevar a algoritmos eficientes).",
        "La estrategia a la que el líder debería comprometerse depende de si, en el momento del compromiso, el líder conoce su propio tipo.",
        "Si la líder conoce su propio tipo, los otros tipos que la líder podría haber tenido se vuelven irrelevantes y la líder simplemente debería comprometerse con la estrategia que sea óptima para ese tipo.",
        "Sin embargo, como se argumentó anteriormente, la líder no necesariamente conoce su propio tipo en el momento de comprometerse (por ejemplo, en el momento en que se envía el código).",
        "En este caso, el líder debe comprometerse con una estrategia que dependa en un 86% del tipo eventual del líder.",
        "Estudiaremos este último modelo, aunque prestaremos atención específica al caso en el que el líder tiene un solo tipo, lo cual es efectivamente lo mismo que el modelo anterior. 3.2 Compromiso con estrategias puras Resulta que calcular una estrategia pura óptima a la que comprometerse es difícil en juegos bayesianos, incluso con dos jugadores.",
        "Teorema 5.",
        "Encontrar una estrategia pura óptima a comprometerse en juegos bayesianos de 2 jugadores es NP-difícil, incluso cuando el seguidor tiene solo un tipo.",
        "Prueba.",
        "Reducimos una instancia arbitraria de CUBRIMIENTO DE VÉRTICES al siguiente juego bayesiano entre el líder y el seguidor.",
        "El líder tiene K tipos θ1, θ2, . . . , θK, cada uno ocurriendo con probabilidad 1/K, y para cada vértice v ∈ V, el líder tiene una acción sv.",
        "El seguidor tiene solo un tipo; para cada borde e ∈ E, el seguidor tiene una acción te, y el seguidor tiene una acción adicional única t0.",
        "La función de utilidad para el líder está dada por, para todo θl ∈ Θl y todo s ∈ S, u θl l (s, t0) = 1, y para todo e ∈ E, u θl l (s, te) = 0.",
        "La utilidad de los seguidores se da por: • Para todo v ∈ V, para todo e ∈ E con v /∈ e, uf (sv, te) = 1; • Para todo v ∈ V, para todo e ∈ E con v ∈ e, uf (sv, te) = −K; • Para todo v ∈ V, uf (sv, t0) = 0.",
        "Sostenemos que el líder puede obtener una utilidad de 1 si y solo si hay una solución para la instancia de CUBRIMIENTO-DE-VÉRTICES.",
        "Primero, supongamos que hay una solución para la instancia de CUBRIRVÉRTICES.",
        "Entonces, el líder puede comprometerse con una estrategia pura tal que para cada vértice v en la cobertura, el líder juega sv para algún tipo.",
        "Entonces, la utilidad de los seguidores para jugar te (para cualquier e ∈ E) es a lo sumo K−1 K + 1 K (−K) = − 1 K , por lo que el seguidor preferirá jugar t0, lo que le da al líder una utilidad de 1, como se requiere.",
        "Ahora, supongamos que hay una estrategia pura para el líder que le dará al líder una utilidad de 1.",
        "Entonces, el seguidor debe jugar t0.",
        "Para que el seguidor no prefiera jugar te (para cualquier e ∈ E) en su lugar, al menos para un v ∈ e, el líder debe jugar sv para algún tipo θl.",
        "Por lo tanto, el conjunto de vértices v que el líder juega para algún tipo debe constituir una cubierta de vértices; y este conjunto puede tener un tamaño de como máximo K, ya que el líder solo tiene K tipos.",
        "Entonces hay una solución para la instancia de CUBRIMIENTODEVÉRTICES.",
        "Sin embargo, si el líder tiene solo un tipo, entonces el problema se vuelve fácil nuevamente (#tipos es el número de tipos para el seguidor): Teorema 6.",
        "En juegos bayesianos de 2 jugadores en los que el líder tiene solo un tipo, una estrategia pura óptima a comprometerse puede encontrarse en tiempo O(#resultados · #tipos).",
        "Prueba.",
        "Para cada acción de líder s, podemos calcular, para cada tipo de seguidor θf ∈ Θf, qué acciones t maximizan la utilidad de los seguidores; llamamos a este conjunto de acciones BRθf (s).",
        "Entonces, la utilidad que recibe el líder por comprometerse a la acción s se puede calcular como θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), y el líder puede elegir la mejor acción a la que comprometerse. 3.3 Compromiso con estrategias mixtas En juegos de información imperfecta de suma cero de dos jugadores con memoria perfecta (ningún jugador olvida algo que una vez supo), una estrategia minimax se puede construir en tiempo polinómico [12, 13].",
        "Desafortunadamente, este resultado no se extiende a calcular estrategias mixtas óptimas a comprometerse en el caso de suma general, ni siquiera en juegos bayesianos.",
        "Demostraremos la NP-dificultad reduciendo desde el problema de CONJUNTOINDEPENDIENTE.",
        "Definición 2.",
        "En INDEPENDENT-SET, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que ninguna arista e ∈ E tenga ambos extremos en S. Nuevamente, este problema es NP-completo [9].",
        "Teorema 7.",
        "Encontrar una estrategia mixta óptima a comprometerse en juegos bayesianos de 2 jugadores es NP-duro, incluso cuando el líder tiene solo un tipo y el seguidor tiene solo dos acciones.",
        "Prueba.",
        "Reducimos una instancia arbitraria de CONJUNTO-INDEPENDIENTE al siguiente juego bayesiano entre el líder y el seguidor.",
        "El líder tiene solo un tipo, y para cada vértice v ∈ V, el líder tiene una acción sv.",
        "El seguidor tiene un tipo θv para cada v ∈ V, que ocurre con una probabilidad de 1 (|E|+1)|V|, y un tipo θe para cada e ∈ E, que ocurre con una probabilidad de 1 |E|+1.",
        "El seguidor tiene dos acciones: t0 y t1.",
        "La utilidad de los líderes se da por, para todo s ∈ S, ul(s, t0) = 1 y ul(s, t1) = 0.",
        "La utilidad de los seguidores se da por: • Para todo v ∈ V, uθv f (sv, t1) = 0; • Para todo v ∈ V y s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • Para todo v ∈ V y s ∈ S, uθv f (s, t0) = 1; • Para todo e ∈ E, s ∈ S, uθe f (s, t0) = 1; • Para todo e ∈ E, para ambos v ∈ e, uθe f (sv, t1) = 2K 3 ; • Para todo e ∈ E, para todo v /∈ e, uθe f (sv, t1) = 0.",
        "Sostenemos que una estrategia óptima a comprometerse le otorga al líder una utilidad esperada de al menos |E| |E|+1 + K (|E|+1)|V | si y solo si hay una solución para la instancia de CONJUNTO-INDEPENDIENTE.",
        "Primero, supongamos que hay una solución para la instancia de CONJUNTO-INDEPENDIENTE.",
        "Entonces, el líder podría comprometerse con la siguiente estrategia: por cada vértice v en el conjunto independiente, jugar el correspondiente sv con una probabilidad de 1/K.",
        "Si el seguidor tiene el tipo θe para algún e ∈ E, la utilidad esperada para el seguidor al jugar t1 es a lo sumo 1 K 2K 3 = 2/3, porque hay a lo sumo un vértice v ∈ e tal que sv se juega con probabilidad distinta de cero.",
        "Por lo tanto, el seguidor jugará t0 y obtendrá una utilidad de 1.",
        "Si el seguidor tiene el tipo θv para algún vértice v en el conjunto independiente, la utilidad esperada para el seguidor al jugar t1 es K−1 K K K−1 = 1, porque el líder juega sv con probabilidad 1/K.",
        "Se deduce que el seguidor (quien rompe los empates para maximizar la utilidad de los líderes) jugará t0, lo que también otorga una utilidad de 1 y brinda al líder una mayor utilidad.",
        "Por lo tanto, la utilidad esperada de los líderes para esta estrategia es al menos |E| |E|+1 + K (|E|+1)|V |, como se requiere. Ahora, supongamos que hay una estrategia que le da al líder una utilidad esperada de al menos |E| |E|+1 + K (|E|+1)|V |.",
        "Entonces, esta estrategia debe inducir al seguidor a jugar t0 siempre que tenga un tipo de la forma θe (porque de lo contrario, la utilidad podría ser a lo sumo |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ).",
        "Por lo tanto, no puede ser el caso de que para alguna arista e = (v1, v2) ∈ E, la probabilidad de que el líder juegue uno de sv1 y sv2 sea al menos 2/K, porque entonces la utilidad esperada para el seguidor de jugar t1 cuando tiene el tipo θe sería al menos 2 K 2K 3 = 4/3 > 1.",
        "Además, la estrategia debe inducir al seguidor a jugar t0 durante al menos K tipos de la forma θv.",
        "Inducir al seguidor a jugar t0 cuando tiene el tipo θv solo se puede lograr jugando sv con una probabilidad de al menos 1/K, lo que le dará al seguidor una utilidad de como máximo K−1 K K K−1 = 1 por jugar t1.",
        "Pero entonces, el conjunto de vértices v tales que sv se juega con una probabilidad de al menos 1/K debe constituir un conjunto independiente de tamaño K (porque si hubiera una arista e entre dos de estos vértices, induciría al seguidor a jugar t1 para el tipo θe según lo mencionado anteriormente).",
        "Por el contrario, si el seguidor tiene solo un tipo, entonces podemos generalizar el enfoque de programación lineal para juegos en forma normal: Teorema 8.",
        "En juegos bayesianos de 2 jugadores en los que el seguidor tiene solo un tipo, una estrategia mixta óptima a comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal.",
        "Prueba.",
        "Generalizamos el enfoque en el Teorema 2 de la siguiente manera.",
        "Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder para cada uno de los tipos de líderes de manera que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad esperada ex ante de los líderes.",
        "Para hacerlo, generalizamos el programa lineal de la siguiente manera: maximizar θl∈Θl π(θl) s∈S pθl s uθl l (s, t) sujeto a para todo t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t) para todo θl ∈ Θl, s∈S p θl s = 1 Como en el Teorema 2, la solución para el programa lineal que maximiza el valor de la solución es una estrategia óptima a comprometerse.",
        "Esto muestra un contraste interesante entre el compromiso con estrategias puras y el compromiso con estrategias mixtas en juegos bayesianos: para las estrategias puras, el problema se vuelve fácil si el líder tiene solo un tipo (pero no si el seguidor tiene solo un tipo), mientras que para las estrategias mixtas, el problema se vuelve fácil si el seguidor tiene solo un tipo (pero no si el líder tiene solo un tipo). 4.",
        "CONCLUSIONES E INVESTIGACIONES FUTURAS En los sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias de forma simultánea.",
        "Esto requiere cierta noción de equilibrio (equilibrio de Nash y sus refinamientos), y a menudo conduce al problema de selección de equilibrio: no está claro para cada jugador individual según qué equilibrio debería jugar.",
        "Sin embargo, este modelo no siempre es realista.",
        "En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión.",
        "Por ejemplo, un agente puede llegar al sitio del juego (real o virtual) antes que el otro, o, en el caso específico de agentes de software, el código de un agente puede estar completo y comprometido antes que el de otro agente.",
        "Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente.",
        "Específicamente, si es posible el compromiso con estrategias mixtas, entonces el compromiso (óptimo) nunca perjudica al líder y a menudo lo beneficia.",
        "El reciente aumento del interés en las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo).",
        "En este artículo, estudiamos cómo calcular estrategias óptimas para comprometerse tanto a estrategias puras como a estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos.",
        "Para juegos en forma normal, demostramos que la estrategia pura óptima a comprometerse se puede encontrar eficientemente para cualquier número de jugadores.",
        "Una estrategia mixta óptima para comprometerse en un juego en forma normal puede encontrarse eficientemente para dos jugadores utilizando programación lineal (y no más eficientemente que eso, en el sentido de que cualquier programa lineal con una restricción de probabilidad puede ser codificado como tal problema). (Esta es una generalización de la computabilidad en tiempo polinómico de las estrategias minimax en juegos en forma normal).",
        "El problema se vuelve NP-duro para tres (o más) jugadores.",
        "En los juegos bayesianos, el problema de encontrar una estrategia pura óptima a la que comprometerse es NP-duro incluso en juegos de dos jugadores en los que el seguidor tiene solo un tipo, aunque los juegos de dos jugadores en los que el líder tiene solo un tipo pueden resolverse eficientemente.",
        "El problema de encontrar una estrategia mixta óptima a comprometerse en un juego bayesiano es NP-duro incluso en juegos de dos jugadores en los que el líder tiene solo un tipo, aunque los juegos de dos jugadores en los que el seguidor tiene solo un tipo pueden resolverse eficientemente utilizando una generalización del enfoque de programación lineal para juegos en forma normal.",
        "Las siguientes dos tablas resumen estos resultados. 2 jugadores ≥ 3 jugadores forma normal O(#resultados) O(#resultados· #jugadores) Bayesiano, O(#resultados· NP-completo 1-tipo líder #tipos) Bayesiano, NP-completo NP-completo 1-tipo seguidor Bayesiano (general) NP-completo NP-completo Resultados para el compromiso con estrategias puras. (Con más de 2 jugadores, el seguidor es el último jugador en comprometerse, el líder es el primero.) 88 2 jugadores ≥ 3 jugadores forma normal una resolución de LP por acción NP-completa del seguidor Bayesiano, NP-completo NP-completo 1-tipo líder Bayesiano, una resolución de LP por acción NP-completa del 1-tipo seguidor Bayesiano (general) NP-completo NP-completo Resultados para el compromiso con estrategias mixtas. (Con más de 2 jugadores, el seguidor es el último jugador en comprometerse, el líder es el primero.)",
        "La investigación futura puede tomar varias direcciones.",
        "Primero, podemos evaluar empíricamente las técnicas presentadas aquí en conjuntos de pruebas como GAMUT [19].",
        "También podemos estudiar la computación de estrategias óptimas a comprometerse en otras representaciones concisas de juegos en forma normal, por ejemplo, en juegos gráficos [10] o juegos de grafo de efecto local/acción [14, 1].",
        "Para los casos en los que calcular una estrategia óptima para comprometerse es NP-duro, también podemos estudiar la computación de estrategias aproximadamente óptimas para comprometerse.",
        "Si bien la definición correcta de una estrategia aproximadamente óptima en este contexto puede parecer simple al principio, debería ser una estrategia que, si los jugadores siguientes juegan de manera óptima, funcione casi tan bien como la estrategia óptima en promedio, esta definición se vuelve problemática cuando consideramos que los otros jugadores también podrían estar jugando solo de manera aproximadamente óptima.",
        "Uno también puede estudiar modelos en los que múltiples (pero no todos) jugadores se comprometen al mismo tiempo.",
        "Otra dirección interesante a explorar es ver si calcular estrategias mixtas óptimas a las que comprometerse puede ayudarnos, o de alguna manera arrojar luz sobre, el cálculo de equilibrios de Nash.",
        "A menudo, las estrategias mixtas óptimas a las que comprometerse también son estrategias de equilibrio de Nash (por ejemplo, en juegos de suma cero de dos jugadores esto siempre es cierto), aunque no siempre es el caso (por ejemplo, como ya señalamos, a veces la estrategia óptima a la que comprometerse es una estrategia estrictamente dominada, que nunca puede ser una estrategia de equilibrio de Nash). 5.",
        "REFERENCIAS [1] N. A. R. Bhat y K. Leyton-Brown.",
        "Calculando los equilibrios de Nash de juegos de gráficos de acción.",
        "En Actas de la 20ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI), Banff, Canadá, 2004. [2] V. Conitzer y T. Sandholm.",
        "Resultados de complejidad sobre equilibrios de Nash.",
        "En Actas de la Decimoctava Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 765-771, Acapulco, México, 2003. [3] V. Conitzer y T. Sandholm.",
        "Complejidad del dominio (iterado).",
        "En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 88-97, Vancouver, Canadá, 2005. [4] V. Conitzer y T. Sandholm.",
        "Un criterio de eliminabilidad de estrategias generalizado y métodos computacionales para aplicarlo.",
        "En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 483-488, Pittsburgh, PA, EE. UU., 2005. [5] A.",
        "A. Cournot.",
        "Las investigaciones sobre los juegos bayesianos son una representación potencialmente concisa de los juegos en forma normal en los principios matemáticos de la teoría de la riqueza.",
        "Hachette, París, 1838. [6] G. Dantzig.",
        "Una prueba de la equivalencia del problema de programación y el problema de juego.",
        "En T. Koopmans, editor, Análisis de la actividad de producción y asignación, páginas 330-335.",
        "John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel. \n\nJohn Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, y E. Zemel.",
        "La complejidad de eliminar estrategias dominadas.",
        "Matemáticas de la Investigación de Operaciones, 18:553-565, 1993. [8] I. Gilboa y E. Zemel.",
        "Nash y equilibrios correlacionados: Algunas consideraciones de complejidad.",
        "Juegos y Comportamiento Económico, 1:80-93, 1989. [9] R. Karp.",
        "Reductibilidad entre problemas combinatorios.",
        "En R. E. Miller y J. W. Thatcher, editores, Complejidad de las Computaciones de Computadoras, páginas 85-103.",
        "Plenum Press, Nueva York, 1972. [10] M. Kearns, M. Littman y S. Singh.",
        "Modelos gráficos para teoría de juegos.",
        "En Actas de la Conferencia sobre Incertidumbre en Inteligencia Artificial (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou y J. N. Tsitsiklis.",
        "Una nota sobre la eliminación de estrategias en juegos bimatrix.",
        "Cartas de Investigación Operativa, 7(3):103-107, 1988. [12] D. Koller y N. Megiddo.",
        "La complejidad de los juegos de suma cero de dos personas en forma extensiva.",
        "Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo y B. von Stengel.",
        "Cálculo eficiente de equilibrios para juegos extensivos de dos personas.",
        "Juegos y Comportamiento Económico, 14(2):247-259, 1996. [14] K. Leyton-Brown y M. Tennenholtz.",
        "Juegos de efecto local.",
        "En Actas de la Decimoctava Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), Acapulco, México, 2003. [15] R. Lipton, E. Markakis y A. Mehta.",
        "Jugando juegos grandes utilizando estrategias simples.",
        "En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 36-41, San Diego, CA, 2003. [16] M. Littman y P. Stone.",
        "Un algoritmo de equilibrio de Nash de tiempo polinómico para juegos repetidos.",
        "En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 48-54, San Diego, CA, 2003. [17] R. D. Luce y H. Raiffa.",
        "Juegos y decisiones.",
        "John Wiley and Sons, Nueva York, 1957.",
        "Reedición de Dover 1989. [18] J. Nash.",
        "Puntos de equilibrio en juegos de n personas.",
        "Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown y Y. Shoham.",
        "Ejecutar el GAMUT: Un enfoque integral para evaluar algoritmos de teoría de juegos.",
        "En la Conferencia Internacional sobre Agentes Autónomos y Sistemas Multiagente (AAMAS), Nueva York, NY, EE. UU., 2004. [20] M. J. Osborne y A. Rubinstein.",
        "Un curso de teoría de juegos.",
        "MIT Press, 1994. [21] C. Papadimitriou. \n\nMIT Press, 1994. [21] C. Papadimitriou.",
        "Algoritmos, juegos e Internet.",
        "En Actas del Simposio Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. 89 [22] R. Porter, E. Nudelman y Y. Shoham.",
        "Métodos de búsqueda simples para encontrar un equilibrio de Nash.",
        "En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 664-669, San José, CA, EE. UU., 2004. [23] T. Sandholm, A. Gilpin y V. Conitzer.",
        "Métodos de programación entera mixta para encontrar equilibrios de Nash.",
        "En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [24] J. von Neumann.",
        "A la teoría de los juegos sociales.",
        "Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg. \n\nMathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg.",
        "Forma de mercado y equilibrio.",
        "Springer, Viena, 1934. [26] B. von Stengel y S. Zamir.",
        "Liderazgo con compromiso hacia estrategias mixtas.",
        "Informe de investigación CDAM LSE-CDAM-2004-01, London School of Economics, febrero de 2004. 90"
    ],
    "error_count": 1,
    "keys": {
        "optimal strategy": {
            "translated_key": "estrategia óptima",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Computing the <br>optimal strategy</br> to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "We give both positive results (efficient algorithms) and negative results (NP-hardness results).",
                "Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent systems with self-interested agents (including most economic settings), the optimal action for one agent to take depends on the actions that the other agents take.",
                "To analyze how an agent should behave in such settings, the tools of game theory need to be applied.",
                "Typically, when a strategic setting is modeled in the framework of game theory, it is assumed that players choose their strategies simultaneously.",
                "This is especially true when the setting is modeled as a normal-form game, which only specifies each agents utility as a function of the vector of strategies that the agents choose, and does not provide any information on the order in which agents make their decisions and what the agents observe about earlier decisions by other agents.",
                "Given that the game is modeled in normal form, it is typically analyzed using the concept of Nash equilibrium.",
                "A Nash equilibrium specifies a strategy for each player, such that no player has an incentive to individually deviate from this profile of strategies. (Typically, the strategies are allowed to be mixed, that is, probability distributions over the original (pure) strategies.)",
                "A (mixed-strategy) Nash equilibrium is guaranteed to exist in finite games [18], but one problem is that there may be multiple Nash equilibria.",
                "This leads to the equilibrium selection problem of how an agent can know which strategy to play if it does not know which equilibrium is to be played.",
                "When the setting is modeled as an extensive-form game, it is possible to specify that some players receive some information about actions taken by others earlier in the game before deciding on their action.",
                "Nevertheless, in general, the players do not know everything that happened earlier in the game.",
                "Because of this, these games are typically still analyzed using an equilibrium concept, where one specifies a mixed strategy for each player, and requires that each players strategy is a best response to the others strategies. (Typically an additional constraint on the strategies is now imposed to ensure that players do not play in a way that is irrational with respect to the information that they have received so far.",
                "This leads to refinements of Nash equilibrium such as subgame perfect and sequential equilibrium.)",
                "However, in many real-world settings, strategies are not selected in such a simultaneous manner.",
                "Oftentimes, one player (the leader) is able to commit to a strategy before another player (the follower).",
                "This can be due to a variety of reasons.",
                "For example, one of the players may arrive at the site at which the game is to be played before another agent (e.g., in economic settings, one player may enter a market earlier and commit to a way of doing busi82 ness).",
                "Such commitment power has a profound impact on how the game should be played.",
                "For example, the leader may be best off playing a strategy that is dominated in the normal-form representation of the game.",
                "Perhaps the earliest and best-known example of the effect of commitment is that by von Stackelberg [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution.",
                "In general, if commitment to mixed strategies is possible, then (under minor assumptions) it never hurts, and often helps, to commit to a strategy [26].",
                "Being forced to commit to a pure strategy sometimes helps, and sometimes hurts (for example, committing to a pure strategy in rock-paper-scissors before the other players decision will naturally result in a loss).",
                "In this paper, we will assume commitment is always forced; if it is not, the player who has the choice of whether to commit can simply compare the commitment outcome to the non-commitment (simultaneous-move) outcome.",
                "Models of leadership are especially important in settings with multiple self-interested software agents.",
                "Once the code for an agent (or for a team of agents) is finalized and the agent is deployed, the agent is committed to playing the (possibly randomized) strategy that the code prescribes.",
                "Thus, as long as one can credibly show that one cannot change the code later, the code serves as a commitment device.",
                "This holds true for recreational tournaments among agents (e.g., poker tournaments, RoboSoccer), and for industrial applications such as sensor webs.",
                "Finally, there is also an implicit leadership situation in the field of mechanism design, in which one player (the designer) gets to choose the rules of the game that the remaining players then play.",
                "Mechanism design is an extremely important topic to the EC community: the papers published on mechanism design in recent EC conferences are too numerous to cite.",
                "Indeed, the mechanism designer may benefit from committing to a choice that, if the (remaining) agents actions were fixed, would be suboptimal.",
                "For example, in a (first-price) auction, the seller may wish to set a positive (artificial) reserve price for the item, below which the item will not be sold-even if the seller values the item at 0.",
                "In hindsight (after the bids have come in), this (na¨ıvely) appears suboptimal: if a bid exceeding the reserve price came in, the reserve price had no effect, and if no such bid came in, the seller would have been better off accepting a lower bid.",
                "Of course, the reason for setting the reserve price is that it incentivizes the bidders to bid higher, and because of this, setting artificial reserve prices can actually increase expected revenue to the seller.",
                "A significant amount of research has recently been devoted to the computation of solutions according to various solution concepts for settings in which the agents choose their strategies simultaneously, such as dominance [7, 11, 3] and (especially) Nash equilibrium [8, 21, 16, 15, 2, 22, 23, 4].",
                "However, the computation of the <br>optimal strategy</br> to commit to in a leadership situation has gone ignored.",
                "Theoretically, leadership situations can simply be thought of as an extensive-form game in which one player chooses a strategy (for the original game) first.",
                "The number of strategies in this extensive-form game, however, can be exceedingly large.",
                "For example, if the leader is able to commit to a mixed strategy in the original game, then every one of the (continuum of) mixed strategies constitutes a pure strategy in the extensive-form representation of the leadership situation. (We note that a commitment to a distribution is not the same as a distribution over commitments.)",
                "Moreover, if the original game is itself an extensive-form game, the number of strategies in the extensive-form representation of the leadership situation (which is a different extensive-form game) becomes even larger.",
                "Because of this, it is usually not computationally feasible to simply transform the original game into the extensive-form representation of the leadership situation; instead, we have to analyze the game in its original representation.",
                "In this paper, we study how to compute the <br>optimal strategy</br> to commit to, both in normal-form games (Section 2) and in Bayesian games, which are a special case of extensiveform games (Section 3). 2.",
                "NORMAL-FORM GAMES In this section, we study how to compute the <br>optimal strategy</br> to commit to for games represented in normal form. 2.1 Definitions In a normal-form game, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a pure strategy for every player, also known as a profile of pure strategies) to a real number.",
                "To ease notation, in the case of two players, we will refer to player 1s pure strategy set as S, and player 2s pure strategy set as T. Such games can be represented in (bi-)matrix form, in which the rows correspond to player 1s pure strategies, the columns correspond to player 2s pure strategies, and the entries of the matrix give the row and column players utilities (in that order) for the corresponding outcome of the game.",
                "In the case of three players, we will use R, S, and T, for player 1, 2, and 3s pure strategies, respectively.",
                "A mixed strategy for a player is a probability distribution over that players pure strategies.",
                "In the case of two-player games, we will refer to player 1 as the leader and player 2 as the follower.",
                "Before defining optimal leadership strategies, consider the following game which illustrates the effect of the leaders ability to commit. 2, 1 4, 0 1, 0 3, 1 In this normal-form representation, the bottom strategy for the row player is strictly dominated by the top strategy.",
                "Nevertheless, if the row player has the ability to commit to a pure strategy before the column player chooses his strategy, the row player should commit to the bottom strategy: doing so will make the column player prefer to play the right strategy, leading to a utility of 3 for the row player.",
                "By contrast, if the row player were to commit to the top strategy, the column player would prefer to play the left strategy, leading to a utility of only 2 for the row player.",
                "If the row player is able to commit to a mixed strategy, then she can get an even greater (expected) utility: if the row player commits to placing probability p > 1/2 on the bottom strategy, then the column player will still prefer to play the right strategy, and the row players expected utility will be 3p + 4(1 − p) = 4 − p ≥ 3.",
                "If the row player plays each strategy with probability exactly 1/2, the column player is 83 indifferent between the strategies.",
                "In such cases, we will assume that the column player will choose the strategy that maximizes the row players utility (in this case, the right strategy).",
                "Hence, the optimal mixed strategy to commit to for the row player is p = 1/2.",
                "There are a few good reasons for this assumption.",
                "If we were to assume the opposite, then there would not exist an <br>optimal strategy</br> for the row player in the example game: the row player would play the bottom strategy with probability p = 1/2 + with > 0, and the smaller , the better the utility for the row player.",
                "By contrast, if we assume that the follower always breaks ties in the leaders favor, then an optimal mixed strategy for the leader always exists, and this corresponds to a subgame perfect equilibrium of the extensive-form representation of the leadership situation.",
                "In any case, this is a standard assumption for such models (e.g. [20]), although some work has investigated what can happen in the other subgame perfect equilibria [26]. (For generic two-player games, the leaders subgame-perfect equilibrium payoff is unique.)",
                "Also, the same assumption is typically used in mechanism design, in that it is assumed that if an agent is indifferent between revealing his preferences truthfully and revealing them falsely, he will report them truthfully.",
                "Given this assumption, we can safely refer to optimal leadership strategies rather than having to use some equilibrium notion.",
                "Hence, for the purposes of this paper, an <br>optimal strategy</br> to commit to in a 2-player game is a strategy s ∈ S that maximizes maxt∈BR(s) ul(s, t), where BR(s) = arg maxt∈T uf (s, t). (ul and uf are the leader and followers utility functions, respectively.)",
                "We can have S = S for the case of commitment to pure strategies, or S = ∆(S), the set of probability distributions over S, for the case of commitment to mixed strategies. (We note that replacing T by ∆(T) makes no difference in this definition.)",
                "For games with more than two players, in which the players commit to their strategies in sequence, we define optimal strategies to commit to recursively.",
                "After the leader commits to a strategy, the game to be played by the remaining agents is itself a (smaller) leadership game.",
                "Thus, we define an <br>optimal strategy</br> to commit to as a strategy that maximizes the leaders utility, assuming that the play of the remaining agents is itself optimal under this definition, and maximizes the leaders utility among all optimal ways to play the remaining game.",
                "Again, commitment to mixed strategies may or may not be a possibility for every player (although for the last player it does not matter if we allow for commitment to mixed strategies). 2.2 Commitment to pure strategies We first study how to compute the optimal pure strategy to commit to.",
                "This is relatively simple, because the number of strategies to commit to is not very large. (In the following, #outcomes is the number of complete strategy profiles.)",
                "Theorem 1.",
                "Under commitment to pure strategies, the set of all <br>optimal strategy</br> profiles in a normal-form game can be found in O(#players · #outcomes) time.",
                "Proof.",
                "Each pure strategy that the first player may commit to will induce a subgame for the remaining players.",
                "We can solve each such subgame recursively to find all of its <br>optimal strategy</br> profiles; each of these will give the original leader some utility.",
                "Those that give the leader maximal utility correspond exactly to the <br>optimal strategy</br> profiles of the original game.",
                "We now present the algorithm formally.",
                "Let Su(G, s1) be the subgame that results after the first (remaining) player in G plays s1 ∈ SG 1 .",
                "A game with 0 players is simply an outcome of the game.",
                "The function Append(s, O) appends the strategy s to each of the vectors of strategies in the set O.",
                "Let e be the empty vector with no elements.",
                "In a slight abuse of notation, we will write uG 1 (C) when all strategy profiles in the set C give player 1 the same utility in the game G. (Here, player 1 is the first remaining player in the subgame G, not necessarily player 1 in the original game.)",
                "We note that arg max is set-valued.",
                "Then, the following algorithm computes all <br>optimal strategy</br> profiles: Algorithm Solve(G) if G has 0 players return {e} C ← ∅ for all s1 ∈ SG 1 { O ← Solve(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) if C = ∅ or uG 1 (s1, O ) = uG 1 (C) C ← C∪Append(s1, O ) if uG 1 (s1, O ) > uG 1 (C) C ←Append(s1, O ) } return C Every outcome is (potentially) examined by every player, which leads to the given runtime bound.",
                "As an example of how the algorithm works, consider the following 3-player game, in which the first player chooses the left or right matrix, the second player chooses a row, and the third player chooses a column. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 3,0,0 First we eliminate the outcomes that do not correspond to best responses for the third player (removing them from the matrix): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Next, we remove the entries in which the third player does not break ties in favor of the second player, as well as entries that do not correspond to best responses for the second player. 0,1,1 2,1,1 1,1,1 0,5,1 Finally, we remove the entries in which the second and third players do not break ties in favor of the first player, as well as entries that do not correspond to best responses for the first player. 2,1,1 84 Hence, in optimal play, the first player chooses the left matrix, the second player chooses the middle row, and the third player chooses the left column. (We note that this outcome is Pareto-dominated by (Right, Middle, Left).)",
                "For general normal-form games, each players utility for each of the outcomes has to be explicitly represented in the input, so that the input size is itself Ω(#players · #outcomes).",
                "Therefore, the algorithm is in fact a linear-time algorithm. 2.3 Commitment to mixed strategies In the special case of two-player zero-sum games, computing an optimal mixed strategy for the leader to commit to is equivalent to computing a minimax strategy, which minimizes the maximum expected utility that the opponent can obtain.",
                "Minimax strategies constitute the only natural solution concept for two-player zero-sum games: von Neumanns Minimax Theorem [24] states that in two-player zero-sum games, it does not matter (in terms of the players utilities) which player gets to commit to a mixed strategy first, and a profile of mixed strategies is a Nash equilibrium if and only if both strategies are minimax strategies.",
                "It is well-known that a minimax strategy can be found in polynomial time, using linear programming [17].",
                "Our first result in this section generalizes this result, showing that an optimal mixed strategy for the leader to commit to can be efficiently computed in general-sum two-player games, again using linear programming.",
                "Theorem 2.",
                "In 2-player normal-form games, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders utility.",
                "Such a mixed strategy can be computed using the following simple linear program: maximize s∈S psul(s, t) subject to for all t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1 We note that this program may be infeasible for some follower strategies t, for example, if t is a strictly dominated strategy.",
                "Nevertheless, the program must be feasible for at least some follower strategies; among these follower strategies, choose a strategy t∗ that maximizes the linear programs solution value.",
                "Then, if the leader chooses as her mixed strategy the optimal settings of the variables ps for the linear program for t∗ , and the follower plays t∗ , this constitutes an <br>optimal strategy</br> profile.",
                "In the following result, we show that we cannot expect to solve the problem more efficiently than linear programming, because we can reduce any linear program with a probability constraint on its variables to a problem of computing the optimal mixed strategy to commit to in a 2-player normalform game.",
                "Theorem 3.",
                "Any linear program whose variables xi (with xi ∈ R≥0 ) must satsify i xi = 1 can be modeled as a problem of computing the optimal mixed strategy to commit to in a 2-player normal-form game.",
                "Proof.",
                "Let the leader have a pure strategy i for every variable xi.",
                "Let the column player have one pure strategy j for every constraint in the linear program (other than i xi = 1), and a single additional pure strategy 0.",
                "Let the utility functions be as follows.",
                "Writing the objective of the linear program as maximize i cixi, for any i, let ul(i, 0) = ci and uf (i, 0) = 0.",
                "Writing the jth constraint of the linear program (not including i xi = 1) as i aijxi ≤ bj, for any i, j > 0, let ul(i, j) = mini ci − 1 and uf (i, j) = aij − bj.",
                "For example, consider the following linear program. maximize 2x1 + x2 subject to x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 The optimal solution to this program is x1 = 1/3, x2 = 2/3.",
                "Our reduction transforms this program into the following leader-follower game (where the leader is the row player). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 Indeed, the <br>optimal strategy</br> for the leader is to play the top strategy with probability 1/3 and the bottom strategy with probability 2/3.",
                "We now show that the reduction works in general.",
                "Clearly, the leader wants to incentivize the follower to play 0, because the utility that the leader gets when the follower plays 0 is always greater than when the follower does not play 0.",
                "In order for the follower not to prefer playing j > 0 rather than 0, it must be the case that i pl(i)(aij − bj) ≤ 0, or equivalently i pl(i)aij ≤ bj.",
                "Hence the leader will get a utility of at least mini ci if and only if there is a feasible solution to the constraints.",
                "Given that the pl(i) incentivize the follower to play 0, the leader attempts to maximize i pl(i)ci.",
                "Thus the leader must solve the original linear program.",
                "As an alternative proof of Theorem 3, one may observe that it is known that finding a minimax strategy in a zerosum game is as hard as the linear programming problem [6], and as we pointed out at the beginning of this section, computing a minimax strategy in a zero-sum game is a special case of the problem of computing an optimal mixed strategy to commit to.",
                "This polynomial-time solvability of the problem of computing an optimal mixed strategy to commit to in two-player normal-form games contrasts with the unknown complexity of computing a Nash equilibrium in such games [21], as well as with the NP-hardness of finding a Nash equilibrium with maximum utility for a given player in such games [8, 2].",
                "Unfortunately, this result does not generalize to more than two players-here, the problem becomes NP-hard.",
                "To show this, we reduce from the VERTEX-COVER problem.",
                "Definition 1.",
                "In VERTEX-COVER, we are given a graph G = (V, E) and an integer K. We are asked whether there 85 exists a subset of the vertices S ⊆ V , with |S| = K, such that every edge e ∈ E has at least one of its endpoints in S. BALANCED-VERTEX-COVER is the special case of VERTEX-COVER in which K = |V |/2.",
                "VERTEX-COVER is NP-complete [9].",
                "The following lemma shows that the hardness remains if we require K = |V |/2. (Similar results have been shown for other NP-complete problems.)",
                "Lemma 1.",
                "BALANCED-VERTEX-COVER is NP-complete.",
                "Proof.",
                "Membership in NP follows from the fact that the problem is a special case of VERTEX-COVER, which is in NP.",
                "To show NP-hardness, we reduce an arbitrary VERTEX-COVER instance to a BALANCED-VERTEXCOVER instance, as follows.",
                "If, for the VERTEX-COVER instance, K > |V |/2, then we simply add isolated vertices that are disjoint from the rest of the graph, until K = |V |/2.",
                "If K < |V |/2, we add isolated triangles (that is, the complete graph on three vertices) to the graph, increasing K by 2 every time, until K = |V |/2.",
                "Theorem 4.",
                "In 3-player normal-form games, finding an optimal mixed strategy to commit to is NP-hard.",
                "Proof.",
                "We reduce an arbitrary BALANCED-VERTEXCOVER instance to the following 3-player normal-form game.",
                "For every vertex v, each of the three players has a pure strategy corresponding to that vertex (rv, sv, tv, respectively).",
                "In addition, for every edge e, the third player has a pure strategy te; and finally, the third player has one additional pure strategy t0.",
                "The utilities are as follows: • for all r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • for all r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • for all v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • for all v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • for all v ∈ V , for all r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V | |V |−2 ; • for all e ∈ E, s ∈ S, for both v ∈ e, u3(rv, s, te) = 0; • for all e ∈ E, s ∈ S, for all v /∈ e, u3(rv, s, te) = |V | |V |−2 . • for all r ∈ R, s ∈ S, u3(r, s, t0) = 1.",
                "We note that players 1 and 2 have the same utility function.",
                "We claim that there is an <br>optimal strategy</br> profile in which players 1 and 2 both obtain 1 (their maximum utility) if and only if there is a solution to the BALANCED-VERTEXCOVER problem. (Otherwise, these players will both obtain 0.)",
                "First, suppose there exists a solution to the BALANCEDVERTEX-COVER problem.",
                "Then, let player 1 play every rv such that v is in the cover with probability 2 |V | , and let player 2 play every sv such that v is not in the cover with probability 2 |V | .",
                "Then, for player 3, the expected utility of playing tv (for any v) is (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of 2 |V | that rv or sv is played.",
                "Additionally, the expected utility of playing te (for any e) is at most (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of at least 2 |V | that some rv with v ∈ e is played (because player 1 is randomizing over the pure strategies corresponding to the cover).",
                "It follows that playing t0 is a best response for player 3, giving players 1 and 2 a utility of 1.",
                "Now, suppose that players 1 and 2 obtain 1 in optimal play.",
                "Then, it must be the case that player 3 plays t0.",
                "Hence, for every v ∈ V , there must be a probability of at least 2 |V | that either rv or sv is played, for otherwise player 3 would be better off playing tv.",
                "Because players 1 and 2 have only a total probability of 2 to distribute, it must be the case that for each v, either rv or sv is played with probability 2 |V | , and the other is played with probability 0. (It is not possible for both to have nonzero probability, because then there would be some probability that both are played simultaneously (correlation is not possible), hence the total probability of at least one being played could not be high enough for all vertices.)",
                "Thus, for exactly half the v ∈ V , player 1 places probability 2 |V | on rv.",
                "Moreover, for every e ∈ E, there must be a probability of at least 2 |V | that some rv with v ∈ e is played, for otherwise player 3 would be better off playing te.",
                "Thus, the v ∈ V such that player 1 places probability 2 |V | on rv constitute a balanced vertex cover. 3.",
                "BAYESIAN GAMES So far, we have restricted our attention to normal-form games.",
                "In a normal-form game, it is assumed that every agent knows every other agents preferences over the outcomes of the game.",
                "In general, however, agents may have some private information about their preferences that is not known to the other agents.",
                "Moreover, at the time of commitment to a strategy, the agents may not even know their own (final) preferences over the outcomes of the game yet, because these preferences may be dependent on a context that has yet to materialize.",
                "For example, when the code for a trading agent is written, it may not yet be clear how that agent will value resources that it will negotiate over later, because this depends on information that is not yet available at the time at which the code is written (such as orders that will have been placed to the agent before the negotiation).",
                "In this section, we will study commitment in Bayesian games, which can model such uncertainty over preferences. 3.1 Definitions In a Bayesian game, every player i has a set of actions Si, a set of types Θi with an associated probability distribution πi : Θi → [0, 1], and, for each type θi, a utility function uθi i : S1 × S2 × . . . × Sn → R. A pure strategy in a Bayesian game is a mapping from the players types to actions, σi : Θi → Si. (Bayesian games can be rewritten in normal form by enumerating every pure strategy σi, but this will cause an exponential blowup in the size of the representation of the game and therefore cannot lead to efficient algorithms.)",
                "The strategy that the leader should commit to depends on whether, at the time of commitment, the leader knows her own type.",
                "If the leader does know her own type, the other types that the leader might have had become irrelevant and the leader should simply commit to the strategy that is optimal for the type.",
                "However, as argued above, the leader does not necessarily know her own type at the time of commitment (e.g., the time at which the code is submitted).",
                "In this case, the leader must commit to a strategy that is 86 dependent upon the leaders eventual type.",
                "We will study this latter model, although we will pay specific attention to the case where the leader has only a single type, which is effectively the same as the former model. 3.2 Commitment to pure strategies It turns out that computing an optimal pure strategy to commit to is hard in Bayesian games, even with two players.",
                "Theorem 5.",
                "Finding an optimal pure strategy to commit to in 2-player Bayesian games is NP-hard, even when the follower has only a single type.",
                "Proof.",
                "We reduce an arbitrary VERTEX-COVER instance to the following Bayesian game between the leader and the follower.",
                "The leader has K types θ1, θ2, . . . , θK , each occurring with probability 1/K, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has only a single type; for each edge e ∈ E, the follower has an action te, and the follower has a single additional action t0.",
                "The utility function for the leader is given by, for all θl ∈ Θl and all s ∈ S, u θl l (s, t0) = 1, and for all e ∈ E, u θl l (s, te) = 0.",
                "The followers utility is given by: • For all v ∈ V , for all e ∈ E with v /∈ e, uf (sv, te) = 1; • For all v ∈ V , for all e ∈ E with v ∈ e, uf (sv, te) = −K; • For all v ∈ V , uf (sv, t0) = 0.",
                "We claim that the leader can get a utility of 1 if and only if there is a solution to the VERTEX-COVER instance.",
                "First, suppose that there is a solution to the VERTEXCOVER instance.",
                "Then, the leader can commit to a pure strategy such that for each vertex v in the cover, the leader plays sv for some type.",
                "Then, the followers utility for playing te (for any e ∈ E) is at most K−1 K + 1 K (−K) = − 1 K , so that the follower will prefer to play t0, which gives the leader a utility of 1, as required.",
                "Now, suppose that there is a pure strategy for the leader that will give the leader a utility of 1.",
                "Then, the follower must play t0.",
                "In order for the follower not to prefer playing te (for any e ∈ E) instead, for at least one v ∈ e the leader must play sv for some type θl.",
                "Hence, the set of vertices v that the leader plays for some type must constitute a vertex cover; and this set can have size at most K, because the leader has only K types.",
                "So there is a solution to the VERTEXCOVER instance.",
                "However, if the leader has only a single type, then the problem becomes easy again (#types is the number of types for the follower): Theorem 6.",
                "In 2-player Bayesian games in which the leader has only a single type, an optimal pure strategy to commit to can be found in O(#outcomes · #types) time.",
                "Proof.",
                "For every leader action s, we can compute, for every follower type θf ∈ Θf , which actions t maximize the followers utility; call this set of actions BRθf (s).",
                "Then, the utility that the leader receives for committing to action s can be computed as θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), and the leader can choose the best action to commit to. 3.3 Commitment to mixed strategies In two-player zero-sum imperfect information games with perfect recall (no player ever forgets something that it once knew), a minimax strategy can be constructed in polynomial time [12, 13].",
                "Unfortunately, this result does not extend to computing optimal mixed strategies to commit to in the general-sum case-not even in Bayesian games.",
                "We will exhibit NP-hardness by reducing from the INDEPENDENTSET problem.",
                "Definition 2.",
                "In INDEPENDENT-SET, we are given a graph G = (V, E) and an integer K. We are asked whether there exists a subset of the vertices S ⊆ V , with |S| = K, such that no edge e ∈ E has both of its endpoints in S. Again, this problem is NP-complete [9].",
                "Theorem 7.",
                "Finding an optimal mixed strategy to commit to in 2-player Bayesian games is NP-hard, even when the leader has only a single type and the follower has only two actions.",
                "Proof.",
                "We reduce an arbitrary INDEPENDENT-SET instance to the following Bayesian game between the leader and the follower.",
                "The leader has only a single type, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has a type θv for every v ∈ V , occurring with probability 1 (|E|+1)|V | , and a type θe for every e ∈ E, occurring with probability 1 |E|+1 .",
                "The follower has two actions: t0 and t1.",
                "The leaders utility is given by, for all s ∈ S, ul(s, t0) = 1 and ul(s, t1) = 0.",
                "The followers utility is given by: • For all v ∈ V , uθv f (sv, t1) = 0; • For all v ∈ V and s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • For all v ∈ V and s ∈ S, uθv f (s, t0) = 1; • For all e ∈ E, s ∈ S, uθe f (s, t0) = 1; • For all e ∈ E, for both v ∈ e, uθe f (sv, t1) = 2K 3 ; • For all e ∈ E, for all v /∈ e, uθe f (sv, t1) = 0.",
                "We claim that an <br>optimal strategy</br> to commit to gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | if and only if there is a solution to the INDEPENDENT-SET instance.",
                "First, suppose that there is a solution to the INDEPENDENT-SET instance.",
                "Then, the leader could commit to the following strategy: for every vertex v in the independent set, play the corresponding sv with probability 1/K.",
                "If the follower has type θe for some e ∈ E, the expected utility for the follower of playing t1 is at most 1 K 2K 3 = 2/3, because there is at most one vertex v ∈ e such that sv is played with nonzero probability.",
                "Hence, the follower will play t0 and obtain a utility of 1.",
                "If the follower has type θv for some vertex v in the independent set, the expected utility for the follower of playing t1 is K−1 K K K−1 = 1, because the leader plays sv with probability 1/K.",
                "It follows that the follower (who breaks ties to maximize the leaders utility) will play t0, which also gives a utility of 1 and gives the leader a higher utility.",
                "Hence the leaders expected utility for this strategy is at least |E| |E|+1 + K (|E|+1)|V | , as required. 87 Now, suppose that there is a strategy that gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | .",
                "Then, this strategy must induce the follower to play t0 whenever it has a type of the form θe (because otherwise, the utility could be at most |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ).",
                "Thus, it cannot be the case that for some edge e = (v1, v2) ∈ E, the probability that the leader plays one of sv1 and sv2 is at least 2/K, because then the expected utility for the follower of playing t1 when it has type θe would be at least 2 K 2K 3 = 4/3 > 1.",
                "Moreover, the strategy must induce the follower to play t0 for at least K types of the form θv.",
                "Inducing the follower to play t0 when it has type θv can be done only by playing sv with probability at least 1/K, which will give the follower a utility of at most K−1 K K K−1 = 1 for playing t1.",
                "But then, the set of vertices v such that sv is played with probability at least 1/K must constitute an independent set of size K (because if there were an edge e between two such vertices, it would induce the follower to play t1 for type θe by the above).",
                "By contrast, if the follower has only a single type, then we can generalize the linear programming approach for normalform games: Theorem 8.",
                "In 2-player Bayesian games in which the follower has only a single type, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "We generalize the approach in Theorem 2 as follows.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader for every one of the leaders types such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders ex ante expected utility.",
                "To do so, we generalize the linear program as follows: maximize θl∈Θl π(θl) s∈S pθl s uθl l (s, t) subject to for all t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t ) for all θl ∈ Θl, s∈S p θl s = 1 As in Theorem 2, the solution for the linear program that maximizes the solution value is an <br>optimal strategy</br> to commit to.",
                "This shows an interesting contrast between commitment to pure strategies and commitment to mixed strategies in Bayesian games: for pure strategies, the problem becomes easy if the leader has only a single type (but not if the follower has only a single type), whereas for mixed strategies, the problem becomes easy if the follower has only a single type (but not if the leader has only a single type). 4.",
                "CONCLUSIONS AND FUTURE RESEARCH In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "This requires some equilibrium notion (Nash equilibrium and its refinements), and often leads to the equilibrium selection problem: it is unclear to each individual player according to which equilibrium she should play.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "For example, one agent may arrive at the (real or virtual) site of the game before the other, or, in the specific case of software agents, the code for one agent may be completed and committed before that of another agent.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "Specifically, if commitment to mixed strategies is possible, then (optimal) commitment never hurts the leader, and often helps.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we studied how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "For normal-form games, we showed that the optimal pure strategy to commit to can be found efficiently for any number of players.",
                "An optimal mixed strategy to commit to in a normal-form game can be found efficiently for two players using linear programming (and no more efficiently than that, in the sense that any linear program with a probability constraint can be encoded as such a problem). (This is a generalization of the polynomial-time computability of minimax strategies in normal-form games.)",
                "The problem becomes NP-hard for three (or more) players.",
                "In Bayesian games, the problem of finding an optimal pure strategy to commit to is NP-hard even in two-player games in which the follower has only a single type, although two-player games in which the leader has only a single type can be solved efficiently.",
                "The problem of finding an optimal mixed strategy to commit to in a Bayesian game is NP-hard even in two-player games in which the leader has only a single type, although two-player games in which the follower has only a single type can be solved efficiently using a generalization of the linear progamming approach for normal-form games.",
                "The following two tables summarize these results. 2 players ≥ 3 players normal-form O(#outcomes) O(#outcomes· #players) Bayesian, O(#outcomes· NP-hard 1-type leader #types) Bayesian, NP-hard NP-hard 1-type follower Bayesian (general) NP-hard NP-hard Results for commitment to pure strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.) 88 2 players ≥ 3 players normal-form one LP-solve per NP-hard follower action Bayesian, NP-hard NP-hard 1-type leader Bayesian, one LP-solve per NP-hard 1-type follower follower action Bayesian (general) NP-hard NP-hard Results for commitment to mixed strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.)",
                "Future research can take a number of directions.",
                "First, we can empirically evaluate the techniques presented here on test suites such as GAMUT [19].",
                "We can also study the computation of optimal strategies to commit to in other1 concise representations of normal-form games-for example, in graphical games [10] or local-effect/action graph games [14, 1].",
                "For the cases where computing an <br>optimal strategy</br> to commit to is NP-hard, we can also study the computation of approximately optimal strategies to commit to.",
                "While the correct definition of an approximately <br>optimal strategy</br> is in this setting may appear simple at first-it should be a strategy that, if the following players play optimally, performs almost as well as the <br>optimal strategy</br> in expectation-this definition becomes problematic when we consider that the other players may also be playing only approximately optimally.",
                "One may also study models in which multiple (but not all) players commit at the same time.",
                "Another interesting direction to pursue is to see if computing optimal mixed strategies to commit to can help us in, or otherwise shed light on, computing Nash equilibria.",
                "Often, optimal mixed strategies to commit to are also Nash equilibrium strategies (for example, in two-player zero-sum games this is always true), although this is not always the case (for example, as we already pointed out, sometimes the <br>optimal strategy</br> to commit to is a strictly dominated strategy, which can never be a Nash equilibrium strategy). 5.",
                "REFERENCES [1] N. A. R. Bhat and K. Leyton-Brown.",
                "Computing Nash equilibria of action-graph games.",
                "In Proceedings of the 20th Annual Conference on Uncertainty in Artificial Intelligence (UAI), Banff, Canada, 2004. [2] V. Conitzer and T. Sandholm.",
                "Complexity results about Nash equilibria.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pages 765-771, Acapulco, Mexico, 2003. [3] V. Conitzer and T. Sandholm.",
                "Complexity of (iterated) dominance.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 88-97, Vancouver, Canada, 2005. [4] V. Conitzer and T. Sandholm.",
                "A generalized strategy eliminability criterion and computational methods for applying it.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 483-488, Pittsburgh, PA, USA, 2005. [5] A.",
                "A. Cournot.",
                "Recherches sur les principes math´ematiques de la th´eorie des richesses (Researches 1 Bayesian games are one potentially concise representation of normal-form games. into the Mathematical Principles of the Theory of Wealth).",
                "Hachette, Paris, 1838. [6] G. Dantzig.",
                "A proof of the equivalence of the programming problem and the game problem.",
                "In T. Koopmans, editor, Activity Analysis of Production and Allocation, pages 330-335.",
                "John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel.",
                "The complexity of eliminating dominated strategies.",
                "Mathematics of Operation Research, 18:553-565, 1993. [8] I. Gilboa and E. Zemel.",
                "Nash and correlated equilibria: Some complexity considerations.",
                "Games and Economic Behavior, 1:80-93, 1989. [9] R. Karp.",
                "Reducibility among combinatorial problems.",
                "In R. E. Miller and J. W. Thatcher, editors, Complexity of Computer Computations, pages 85-103.",
                "Plenum Press, NY, 1972. [10] M. Kearns, M. Littman, and S. Singh.",
                "Graphical models for game theory.",
                "In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou, and J. N. Tsitsiklis.",
                "A note on strategy elimination in bimatrix games.",
                "Operations Research Letters, 7(3):103-107, 1988. [12] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [14] K. Leyton-Brown and M. Tennenholtz.",
                "Local-effect games.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), Acapulco, Mexico, 2003. [15] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 36-41, San Diego, CA, 2003. [16] M. Littman and P. Stone.",
                "A polynomial-time Nash equilibrium algorithm for repeated games.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 48-54, San Diego, CA, 2003. [17] R. D. Luce and H. Raiffa.",
                "Games and Decisions.",
                "John Wiley and Sons, New York, 1957.",
                "Dover republication 1989. [18] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown, and Y. Shoham.",
                "Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms.",
                "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), New York, NY, USA, 2004. [20] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "MIT Press, 1994. [21] C. Papadimitriou.",
                "Algorithms, games and the Internet.",
                "In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 749-753, 2001. 89 [22] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 664-669, San Jose, CA, USA, 2004. [23] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 495-501, Pittsburgh, PA, USA, 2005. [24] J. von Neumann.",
                "Zur Theorie der Gesellschaftsspiele.",
                "Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg.",
                "Marktform und Gleichgewicht.",
                "Springer, Vienna, 1934. [26] B. von Stengel and S. Zamir.",
                "Leadership with commitment to mixed strategies.",
                "CDAM Research Report LSE-CDAM-2004-01, London School of Economics, Feb. 2004. 90"
            ],
            "original_annotated_samples": [
                "Computing the <br>optimal strategy</br> to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "However, the computation of the <br>optimal strategy</br> to commit to in a leadership situation has gone ignored.",
                "In this paper, we study how to compute the <br>optimal strategy</br> to commit to, both in normal-form games (Section 2) and in Bayesian games, which are a special case of extensiveform games (Section 3). 2.",
                "NORMAL-FORM GAMES In this section, we study how to compute the <br>optimal strategy</br> to commit to for games represented in normal form. 2.1 Definitions In a normal-form game, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a pure strategy for every player, also known as a profile of pure strategies) to a real number.",
                "If we were to assume the opposite, then there would not exist an <br>optimal strategy</br> for the row player in the example game: the row player would play the bottom strategy with probability p = 1/2 + with > 0, and the smaller , the better the utility for the row player."
            ],
            "translated_annotated_samples": [
                "En sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias simultáneamente.",
                "Sin embargo, se ha ignorado el cálculo de la <br>estrategia óptima</br> a comprometerse en una situación de liderazgo.",
                "En este artículo, estudiamos cómo calcular la <br>estrategia óptima</br> a comprometerse, tanto en juegos de forma normal (Sección 2) como en juegos bayesianos, que son un caso especial de juegos de forma extensiva (Sección 3).",
                "JUEGOS EN FORMA NORMAL En esta sección, estudiamos cómo calcular la <br>estrategia óptima</br> a comprometerse para juegos representados en forma normal. 2.1 Definiciones En un juego en forma normal, cada jugador i ∈ {1, . . . , n} tiene un conjunto de estrategias puras (o acciones) Si, y una función de utilidad ui : S1×S2×. . .×Sn → R que mapea cada resultado (un vector que consiste en una estrategia pura para cada jugador, también conocido como un perfil de estrategias puras) a un número real.",
                "Si asumiéramos lo contrario, entonces no existiría una <br>estrategia óptima</br> para el jugador de la fila en el juego de ejemplo: el jugador de la fila jugaría la estrategia inferior con una probabilidad p = 1/2 + con > 0, y cuanto menor sea , mejor será la utilidad para el jugador de la fila."
            ],
            "translated_text": "En sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias simultáneamente. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. El reciente aumento en el interés por las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas a comprometerse tanto en el compromiso de estrategias puras como en el compromiso de estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Ofrecemos tanto resultados positivos (algoritmos eficientes) como resultados negativos (resultados de NP-hardness). Categorías y Descriptores de Asignaturas J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas Términos Generales Algoritmos, Economía, Teoría 1. En sistemas multiagentes con agentes auto-interesados (incluyendo la mayoría de los entornos económicos), la acción óptima que un agente debe tomar depende de las acciones que tomen los otros agentes. Para analizar cómo un agente debería comportarse en tales situaciones, es necesario aplicar las herramientas de la teoría de juegos. Normalmente, cuando se modela un escenario estratégico en el marco de la teoría de juegos, se asume que los jugadores eligen sus estrategias de forma simultánea. Esto es especialmente cierto cuando el escenario se modela como un juego en forma normal, que solo especifica la utilidad de cada agente como una función del vector de estrategias que los agentes eligen, y no proporciona información sobre el orden en que los agentes toman sus decisiones y lo que los agentes observan sobre las decisiones anteriores de otros agentes. Dado que el juego está modelado en forma normal, típicamente se analiza utilizando el concepto de equilibrio de Nash. Un equilibrio de Nash especifica una estrategia para cada jugador, de modo que ningún jugador tenga un incentivo para desviarse individualmente de este perfil de estrategias. (Por lo general, se permite que las estrategias sean mixtas, es decir, distribuciones de probabilidad sobre las estrategias originales (puras).) Un equilibrio de Nash (de estrategia mixta) está garantizado de existir en juegos finitos [18], pero un problema es que puede haber múltiples equilibrios de Nash. Esto conduce al problema de selección de equilibrio de cómo un agente puede saber qué estrategia jugar si no sabe qué equilibrio se va a jugar. Cuando el escenario se modela como un juego de forma extensiva, es posible especificar que algunos jugadores reciben información sobre las acciones tomadas por otros antes en el juego antes de decidir su acción. Sin embargo, en general, los jugadores no saben todo lo que sucedió anteriormente en el juego. Por lo tanto, estos juegos suelen ser analizados todavía utilizando un concepto de equilibrio, donde se especifica una estrategia mixta para cada jugador, y se requiere que la estrategia de cada jugador sea una mejor respuesta a las estrategias de los demás. (Normalmente se impone ahora una restricción adicional en las estrategias para garantizar que los jugadores no jueguen de una manera irracional con respecto a la información que han recibido hasta el momento). Esto conduce a refinamientos del equilibrio de Nash como el equilibrio perfecto en subjuegos y el equilibrio secuencial. Sin embargo, en muchos entornos del mundo real, las estrategias no se seleccionan de manera simultánea. A menudo, un jugador (el líder) puede comprometerse con una estrategia antes que otro jugador (el seguidor). Esto puede deberse a una variedad de razones. Por ejemplo, uno de los jugadores puede llegar al lugar donde se jugará el juego antes que otro agente (por ejemplo, en entornos económicos, un jugador puede ingresar al mercado antes y comprometerse con una forma de hacer negocios). Un compromiso tan poderoso tiene un impacto profundo en cómo debería jugarse el juego. Por ejemplo, el líder puede estar mejor jugando una estrategia que esté dominada en la representación de forma normal del juego. Quizás el ejemplo más temprano y conocido del efecto del compromiso es el de von Stackelberg [25], quien demostró que, en el modelo de duopolio de Cournot [5], si una empresa puede comprometerse con una cantidad de producción primero, esa empresa lo hará mucho mejor que en la solución de movimiento simultáneo (Nash). En general, si es posible comprometerse con estrategias mixtas, entonces (bajo suposiciones menores) nunca perjudica, y a menudo ayuda, comprometerse con una estrategia [26]. Verse obligado a comprometerse con una estrategia pura a veces ayuda y a veces perjudica (por ejemplo, comprometerse con una estrategia pura en piedra-papel-tijeras antes de la decisión de los otros jugadores naturalmente resultará en una derrota). En este documento, asumiremos que el compromiso siempre es forzado; si no lo es, el jugador que tiene la opción de comprometerse simplemente puede comparar el resultado del compromiso con el resultado de no comprometerse (movimiento simultáneo). Los modelos de liderazgo son especialmente importantes en entornos con múltiples agentes de software con intereses propios. Una vez que el código de un agente (o de un equipo de agentes) está finalizado y el agente es desplegado, el agente se compromete a jugar la estrategia (posiblemente aleatoria) que el código prescribe. Por lo tanto, siempre y cuando se pueda demostrar de manera creíble que no se puede cambiar el código más tarde, el código funciona como un dispositivo de compromiso. Esto es válido para torneos recreativos entre agentes (por ejemplo, torneos de póker, RoboSoccer) y para aplicaciones industriales como redes de sensores. Finalmente, también existe una situación de liderazgo implícito en el campo del diseño de mecanismos, en la cual un jugador (el diseñador) tiene la oportunidad de elegir las reglas del juego que los demás jugadores luego siguen. El diseño de mecanismos es un tema extremadamente importante para la comunidad de EC: los artículos publicados sobre diseño de mecanismos en las recientes conferencias de EC son demasiados para citar. De hecho, el diseñador del mecanismo puede beneficiarse al comprometerse con una elección que, si las acciones de los agentes (restantes) estuvieran fijas, sería subóptima. Por ejemplo, en una subasta (a precio fijo), el vendedor puede desear establecer un precio de reserva positivo (artificial) para el artículo, por debajo del cual el artículo no se venderá, incluso si el vendedor valora el artículo en 0. En retrospectiva (después de recibir las ofertas), esto (ingenuamente) parece subóptimo: si llegaba una oferta que superaba el precio de reserva, el precio de reserva no tenía efecto, y si no llegaba tal oferta, el vendedor hubiera estado mejor aceptando una oferta más baja. Por supuesto, la razón para establecer el precio de reserva es incentivar a los postores a ofertar más alto, y debido a esto, establecer precios de reserva artificiales puede aumentar realmente los ingresos esperados para el vendedor. Recientemente se ha dedicado una cantidad significativa de investigación al cálculo de soluciones de acuerdo con varios conceptos de solución para escenarios en los que los agentes eligen sus estrategias simultáneamente, como la dominancia [7, 11, 3] y (especialmente) el equilibrio de Nash [8, 21, 16, 15, 2, 22, 23, 4]. Sin embargo, se ha ignorado el cálculo de la <br>estrategia óptima</br> a comprometerse en una situación de liderazgo. Teóricamente, las situaciones de liderazgo simplemente pueden ser consideradas como un juego de forma extensiva en el que un jugador elige una estrategia (para el juego original) primero. El número de estrategias en este juego de forma extensiva, sin embargo, puede ser extremadamente grande. Por ejemplo, si el líder es capaz de comprometerse con una estrategia mixta en el juego original, entonces cada una de las estrategias mixtas (continuo de) constituye una estrategia pura en la representación de forma extensiva de la situación de liderazgo. (Se destaca que un compromiso con una distribución no es lo mismo que una distribución sobre compromisos). Además, si el juego original es en sí mismo un juego de forma extensiva, el número de estrategias en la representación de forma extensiva de la situación de liderazgo (que es un juego de forma extensiva diferente) se vuelve aún más grande. Por lo tanto, generalmente no es factible computacionalmente simplemente transformar el juego original en la representación de forma extensiva de la situación de liderazgo; en su lugar, debemos analizar el juego en su representación original. En este artículo, estudiamos cómo calcular la <br>estrategia óptima</br> a comprometerse, tanto en juegos de forma normal (Sección 2) como en juegos bayesianos, que son un caso especial de juegos de forma extensiva (Sección 3). JUEGOS EN FORMA NORMAL En esta sección, estudiamos cómo calcular la <br>estrategia óptima</br> a comprometerse para juegos representados en forma normal. 2.1 Definiciones En un juego en forma normal, cada jugador i ∈ {1, . . . , n} tiene un conjunto de estrategias puras (o acciones) Si, y una función de utilidad ui : S1×S2×. . .×Sn → R que mapea cada resultado (un vector que consiste en una estrategia pura para cada jugador, también conocido como un perfil de estrategias puras) a un número real. Para facilitar la notación, en el caso de dos jugadores, nos referiremos al conjunto de estrategias puras del jugador 1 como S, y al conjunto de estrategias puras del jugador 2 como T. Estos juegos pueden representarse en forma de matriz (bi-matriz), en la que las filas corresponden a las estrategias puras del jugador 1, las columnas corresponden a las estrategias puras del jugador 2, y las entradas de la matriz dan las utilidades de los jugadores de fila y columna (en ese orden) para el resultado correspondiente del juego. En el caso de tres jugadores, usaremos R, S y T, para las estrategias puras de los jugadores 1, 2 y 3, respectivamente. Una estrategia mixta para un jugador es una distribución de probabilidad sobre las estrategias puras de ese jugador. En el caso de juegos de dos jugadores, nos referiremos al jugador 1 como el líder y al jugador 2 como el seguidor. Antes de definir estrategias de liderazgo óptimas, considera el siguiente juego que ilustra el efecto de la capacidad del líder para comprometerse. 2, 1 4, 0 1, 0 3, 1 En esta representación en forma normal, la estrategia inferior para el jugador de la fila está estrictamente dominada por la estrategia superior. Sin embargo, si el jugador de la fila tiene la capacidad de comprometerse con una estrategia pura antes de que el jugador de la columna elija su estrategia, el jugador de la fila debería comprometerse con la estrategia inferior: al hacerlo, el jugador de la columna preferirá jugar la estrategia correcta, lo que llevará a una utilidad de 3 para el jugador de la fila. Por el contrario, si el jugador de la fila se comprometiera con la estrategia superior, el jugador de la columna preferiría jugar la estrategia izquierda, lo que llevaría a una utilidad de solo 2 para el jugador de la fila. Si el jugador de la fila puede comprometerse a una estrategia mixta, entonces puede obtener una utilidad aún mayor (esperada): si el jugador de la fila se compromete a colocar una probabilidad p > 1/2 en la estrategia inferior, entonces el jugador de la columna seguirá prefiriendo jugar la estrategia derecha, y la utilidad esperada de los jugadores de la fila será 3p + 4(1 − p) = 4 − p ≥ 3. Si el jugador de la fila juega cada estrategia con una probabilidad exacta de 1/2, el jugador de la columna está 83 indiferente entre las estrategias. En tales casos, asumiremos que el jugador de la columna elegirá la estrategia que maximiza la utilidad de los jugadores de la fila (en este caso, la estrategia correcta). Por lo tanto, la estrategia mixta óptima a la que debe comprometerse el jugador de la fila es p = 1/2. Hay algunas buenas razones para esta suposición. Si asumiéramos lo contrario, entonces no existiría una <br>estrategia óptima</br> para el jugador de la fila en el juego de ejemplo: el jugador de la fila jugaría la estrategia inferior con una probabilidad p = 1/2 + con > 0, y cuanto menor sea , mejor será la utilidad para el jugador de la fila. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "multiagent system": {
            "translated_key": "sistemas multiagentes",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Computing the Optimal Strategy to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In <br>multiagent system</br>s, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "We give both positive results (efficient algorithms) and negative results (NP-hardness results).",
                "Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In <br>multiagent system</br>s with self-interested agents (including most economic settings), the optimal action for one agent to take depends on the actions that the other agents take.",
                "To analyze how an agent should behave in such settings, the tools of game theory need to be applied.",
                "Typically, when a strategic setting is modeled in the framework of game theory, it is assumed that players choose their strategies simultaneously.",
                "This is especially true when the setting is modeled as a normal-form game, which only specifies each agents utility as a function of the vector of strategies that the agents choose, and does not provide any information on the order in which agents make their decisions and what the agents observe about earlier decisions by other agents.",
                "Given that the game is modeled in normal form, it is typically analyzed using the concept of Nash equilibrium.",
                "A Nash equilibrium specifies a strategy for each player, such that no player has an incentive to individually deviate from this profile of strategies. (Typically, the strategies are allowed to be mixed, that is, probability distributions over the original (pure) strategies.)",
                "A (mixed-strategy) Nash equilibrium is guaranteed to exist in finite games [18], but one problem is that there may be multiple Nash equilibria.",
                "This leads to the equilibrium selection problem of how an agent can know which strategy to play if it does not know which equilibrium is to be played.",
                "When the setting is modeled as an extensive-form game, it is possible to specify that some players receive some information about actions taken by others earlier in the game before deciding on their action.",
                "Nevertheless, in general, the players do not know everything that happened earlier in the game.",
                "Because of this, these games are typically still analyzed using an equilibrium concept, where one specifies a mixed strategy for each player, and requires that each players strategy is a best response to the others strategies. (Typically an additional constraint on the strategies is now imposed to ensure that players do not play in a way that is irrational with respect to the information that they have received so far.",
                "This leads to refinements of Nash equilibrium such as subgame perfect and sequential equilibrium.)",
                "However, in many real-world settings, strategies are not selected in such a simultaneous manner.",
                "Oftentimes, one player (the leader) is able to commit to a strategy before another player (the follower).",
                "This can be due to a variety of reasons.",
                "For example, one of the players may arrive at the site at which the game is to be played before another agent (e.g., in economic settings, one player may enter a market earlier and commit to a way of doing busi82 ness).",
                "Such commitment power has a profound impact on how the game should be played.",
                "For example, the leader may be best off playing a strategy that is dominated in the normal-form representation of the game.",
                "Perhaps the earliest and best-known example of the effect of commitment is that by von Stackelberg [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution.",
                "In general, if commitment to mixed strategies is possible, then (under minor assumptions) it never hurts, and often helps, to commit to a strategy [26].",
                "Being forced to commit to a pure strategy sometimes helps, and sometimes hurts (for example, committing to a pure strategy in rock-paper-scissors before the other players decision will naturally result in a loss).",
                "In this paper, we will assume commitment is always forced; if it is not, the player who has the choice of whether to commit can simply compare the commitment outcome to the non-commitment (simultaneous-move) outcome.",
                "Models of leadership are especially important in settings with multiple self-interested software agents.",
                "Once the code for an agent (or for a team of agents) is finalized and the agent is deployed, the agent is committed to playing the (possibly randomized) strategy that the code prescribes.",
                "Thus, as long as one can credibly show that one cannot change the code later, the code serves as a commitment device.",
                "This holds true for recreational tournaments among agents (e.g., poker tournaments, RoboSoccer), and for industrial applications such as sensor webs.",
                "Finally, there is also an implicit leadership situation in the field of mechanism design, in which one player (the designer) gets to choose the rules of the game that the remaining players then play.",
                "Mechanism design is an extremely important topic to the EC community: the papers published on mechanism design in recent EC conferences are too numerous to cite.",
                "Indeed, the mechanism designer may benefit from committing to a choice that, if the (remaining) agents actions were fixed, would be suboptimal.",
                "For example, in a (first-price) auction, the seller may wish to set a positive (artificial) reserve price for the item, below which the item will not be sold-even if the seller values the item at 0.",
                "In hindsight (after the bids have come in), this (na¨ıvely) appears suboptimal: if a bid exceeding the reserve price came in, the reserve price had no effect, and if no such bid came in, the seller would have been better off accepting a lower bid.",
                "Of course, the reason for setting the reserve price is that it incentivizes the bidders to bid higher, and because of this, setting artificial reserve prices can actually increase expected revenue to the seller.",
                "A significant amount of research has recently been devoted to the computation of solutions according to various solution concepts for settings in which the agents choose their strategies simultaneously, such as dominance [7, 11, 3] and (especially) Nash equilibrium [8, 21, 16, 15, 2, 22, 23, 4].",
                "However, the computation of the optimal strategy to commit to in a leadership situation has gone ignored.",
                "Theoretically, leadership situations can simply be thought of as an extensive-form game in which one player chooses a strategy (for the original game) first.",
                "The number of strategies in this extensive-form game, however, can be exceedingly large.",
                "For example, if the leader is able to commit to a mixed strategy in the original game, then every one of the (continuum of) mixed strategies constitutes a pure strategy in the extensive-form representation of the leadership situation. (We note that a commitment to a distribution is not the same as a distribution over commitments.)",
                "Moreover, if the original game is itself an extensive-form game, the number of strategies in the extensive-form representation of the leadership situation (which is a different extensive-form game) becomes even larger.",
                "Because of this, it is usually not computationally feasible to simply transform the original game into the extensive-form representation of the leadership situation; instead, we have to analyze the game in its original representation.",
                "In this paper, we study how to compute the optimal strategy to commit to, both in normal-form games (Section 2) and in Bayesian games, which are a special case of extensiveform games (Section 3). 2.",
                "NORMAL-FORM GAMES In this section, we study how to compute the optimal strategy to commit to for games represented in normal form. 2.1 Definitions In a normal-form game, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a pure strategy for every player, also known as a profile of pure strategies) to a real number.",
                "To ease notation, in the case of two players, we will refer to player 1s pure strategy set as S, and player 2s pure strategy set as T. Such games can be represented in (bi-)matrix form, in which the rows correspond to player 1s pure strategies, the columns correspond to player 2s pure strategies, and the entries of the matrix give the row and column players utilities (in that order) for the corresponding outcome of the game.",
                "In the case of three players, we will use R, S, and T, for player 1, 2, and 3s pure strategies, respectively.",
                "A mixed strategy for a player is a probability distribution over that players pure strategies.",
                "In the case of two-player games, we will refer to player 1 as the leader and player 2 as the follower.",
                "Before defining optimal leadership strategies, consider the following game which illustrates the effect of the leaders ability to commit. 2, 1 4, 0 1, 0 3, 1 In this normal-form representation, the bottom strategy for the row player is strictly dominated by the top strategy.",
                "Nevertheless, if the row player has the ability to commit to a pure strategy before the column player chooses his strategy, the row player should commit to the bottom strategy: doing so will make the column player prefer to play the right strategy, leading to a utility of 3 for the row player.",
                "By contrast, if the row player were to commit to the top strategy, the column player would prefer to play the left strategy, leading to a utility of only 2 for the row player.",
                "If the row player is able to commit to a mixed strategy, then she can get an even greater (expected) utility: if the row player commits to placing probability p > 1/2 on the bottom strategy, then the column player will still prefer to play the right strategy, and the row players expected utility will be 3p + 4(1 − p) = 4 − p ≥ 3.",
                "If the row player plays each strategy with probability exactly 1/2, the column player is 83 indifferent between the strategies.",
                "In such cases, we will assume that the column player will choose the strategy that maximizes the row players utility (in this case, the right strategy).",
                "Hence, the optimal mixed strategy to commit to for the row player is p = 1/2.",
                "There are a few good reasons for this assumption.",
                "If we were to assume the opposite, then there would not exist an optimal strategy for the row player in the example game: the row player would play the bottom strategy with probability p = 1/2 + with > 0, and the smaller , the better the utility for the row player.",
                "By contrast, if we assume that the follower always breaks ties in the leaders favor, then an optimal mixed strategy for the leader always exists, and this corresponds to a subgame perfect equilibrium of the extensive-form representation of the leadership situation.",
                "In any case, this is a standard assumption for such models (e.g. [20]), although some work has investigated what can happen in the other subgame perfect equilibria [26]. (For generic two-player games, the leaders subgame-perfect equilibrium payoff is unique.)",
                "Also, the same assumption is typically used in mechanism design, in that it is assumed that if an agent is indifferent between revealing his preferences truthfully and revealing them falsely, he will report them truthfully.",
                "Given this assumption, we can safely refer to optimal leadership strategies rather than having to use some equilibrium notion.",
                "Hence, for the purposes of this paper, an optimal strategy to commit to in a 2-player game is a strategy s ∈ S that maximizes maxt∈BR(s) ul(s, t), where BR(s) = arg maxt∈T uf (s, t). (ul and uf are the leader and followers utility functions, respectively.)",
                "We can have S = S for the case of commitment to pure strategies, or S = ∆(S), the set of probability distributions over S, for the case of commitment to mixed strategies. (We note that replacing T by ∆(T) makes no difference in this definition.)",
                "For games with more than two players, in which the players commit to their strategies in sequence, we define optimal strategies to commit to recursively.",
                "After the leader commits to a strategy, the game to be played by the remaining agents is itself a (smaller) leadership game.",
                "Thus, we define an optimal strategy to commit to as a strategy that maximizes the leaders utility, assuming that the play of the remaining agents is itself optimal under this definition, and maximizes the leaders utility among all optimal ways to play the remaining game.",
                "Again, commitment to mixed strategies may or may not be a possibility for every player (although for the last player it does not matter if we allow for commitment to mixed strategies). 2.2 Commitment to pure strategies We first study how to compute the optimal pure strategy to commit to.",
                "This is relatively simple, because the number of strategies to commit to is not very large. (In the following, #outcomes is the number of complete strategy profiles.)",
                "Theorem 1.",
                "Under commitment to pure strategies, the set of all optimal strategy profiles in a normal-form game can be found in O(#players · #outcomes) time.",
                "Proof.",
                "Each pure strategy that the first player may commit to will induce a subgame for the remaining players.",
                "We can solve each such subgame recursively to find all of its optimal strategy profiles; each of these will give the original leader some utility.",
                "Those that give the leader maximal utility correspond exactly to the optimal strategy profiles of the original game.",
                "We now present the algorithm formally.",
                "Let Su(G, s1) be the subgame that results after the first (remaining) player in G plays s1 ∈ SG 1 .",
                "A game with 0 players is simply an outcome of the game.",
                "The function Append(s, O) appends the strategy s to each of the vectors of strategies in the set O.",
                "Let e be the empty vector with no elements.",
                "In a slight abuse of notation, we will write uG 1 (C) when all strategy profiles in the set C give player 1 the same utility in the game G. (Here, player 1 is the first remaining player in the subgame G, not necessarily player 1 in the original game.)",
                "We note that arg max is set-valued.",
                "Then, the following algorithm computes all optimal strategy profiles: Algorithm Solve(G) if G has 0 players return {e} C ← ∅ for all s1 ∈ SG 1 { O ← Solve(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) if C = ∅ or uG 1 (s1, O ) = uG 1 (C) C ← C∪Append(s1, O ) if uG 1 (s1, O ) > uG 1 (C) C ←Append(s1, O ) } return C Every outcome is (potentially) examined by every player, which leads to the given runtime bound.",
                "As an example of how the algorithm works, consider the following 3-player game, in which the first player chooses the left or right matrix, the second player chooses a row, and the third player chooses a column. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 3,0,0 First we eliminate the outcomes that do not correspond to best responses for the third player (removing them from the matrix): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Next, we remove the entries in which the third player does not break ties in favor of the second player, as well as entries that do not correspond to best responses for the second player. 0,1,1 2,1,1 1,1,1 0,5,1 Finally, we remove the entries in which the second and third players do not break ties in favor of the first player, as well as entries that do not correspond to best responses for the first player. 2,1,1 84 Hence, in optimal play, the first player chooses the left matrix, the second player chooses the middle row, and the third player chooses the left column. (We note that this outcome is Pareto-dominated by (Right, Middle, Left).)",
                "For general normal-form games, each players utility for each of the outcomes has to be explicitly represented in the input, so that the input size is itself Ω(#players · #outcomes).",
                "Therefore, the algorithm is in fact a linear-time algorithm. 2.3 Commitment to mixed strategies In the special case of two-player zero-sum games, computing an optimal mixed strategy for the leader to commit to is equivalent to computing a minimax strategy, which minimizes the maximum expected utility that the opponent can obtain.",
                "Minimax strategies constitute the only natural solution concept for two-player zero-sum games: von Neumanns Minimax Theorem [24] states that in two-player zero-sum games, it does not matter (in terms of the players utilities) which player gets to commit to a mixed strategy first, and a profile of mixed strategies is a Nash equilibrium if and only if both strategies are minimax strategies.",
                "It is well-known that a minimax strategy can be found in polynomial time, using linear programming [17].",
                "Our first result in this section generalizes this result, showing that an optimal mixed strategy for the leader to commit to can be efficiently computed in general-sum two-player games, again using linear programming.",
                "Theorem 2.",
                "In 2-player normal-form games, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders utility.",
                "Such a mixed strategy can be computed using the following simple linear program: maximize s∈S psul(s, t) subject to for all t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1 We note that this program may be infeasible for some follower strategies t, for example, if t is a strictly dominated strategy.",
                "Nevertheless, the program must be feasible for at least some follower strategies; among these follower strategies, choose a strategy t∗ that maximizes the linear programs solution value.",
                "Then, if the leader chooses as her mixed strategy the optimal settings of the variables ps for the linear program for t∗ , and the follower plays t∗ , this constitutes an optimal strategy profile.",
                "In the following result, we show that we cannot expect to solve the problem more efficiently than linear programming, because we can reduce any linear program with a probability constraint on its variables to a problem of computing the optimal mixed strategy to commit to in a 2-player normalform game.",
                "Theorem 3.",
                "Any linear program whose variables xi (with xi ∈ R≥0 ) must satsify i xi = 1 can be modeled as a problem of computing the optimal mixed strategy to commit to in a 2-player normal-form game.",
                "Proof.",
                "Let the leader have a pure strategy i for every variable xi.",
                "Let the column player have one pure strategy j for every constraint in the linear program (other than i xi = 1), and a single additional pure strategy 0.",
                "Let the utility functions be as follows.",
                "Writing the objective of the linear program as maximize i cixi, for any i, let ul(i, 0) = ci and uf (i, 0) = 0.",
                "Writing the jth constraint of the linear program (not including i xi = 1) as i aijxi ≤ bj, for any i, j > 0, let ul(i, j) = mini ci − 1 and uf (i, j) = aij − bj.",
                "For example, consider the following linear program. maximize 2x1 + x2 subject to x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 The optimal solution to this program is x1 = 1/3, x2 = 2/3.",
                "Our reduction transforms this program into the following leader-follower game (where the leader is the row player). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 Indeed, the optimal strategy for the leader is to play the top strategy with probability 1/3 and the bottom strategy with probability 2/3.",
                "We now show that the reduction works in general.",
                "Clearly, the leader wants to incentivize the follower to play 0, because the utility that the leader gets when the follower plays 0 is always greater than when the follower does not play 0.",
                "In order for the follower not to prefer playing j > 0 rather than 0, it must be the case that i pl(i)(aij − bj) ≤ 0, or equivalently i pl(i)aij ≤ bj.",
                "Hence the leader will get a utility of at least mini ci if and only if there is a feasible solution to the constraints.",
                "Given that the pl(i) incentivize the follower to play 0, the leader attempts to maximize i pl(i)ci.",
                "Thus the leader must solve the original linear program.",
                "As an alternative proof of Theorem 3, one may observe that it is known that finding a minimax strategy in a zerosum game is as hard as the linear programming problem [6], and as we pointed out at the beginning of this section, computing a minimax strategy in a zero-sum game is a special case of the problem of computing an optimal mixed strategy to commit to.",
                "This polynomial-time solvability of the problem of computing an optimal mixed strategy to commit to in two-player normal-form games contrasts with the unknown complexity of computing a Nash equilibrium in such games [21], as well as with the NP-hardness of finding a Nash equilibrium with maximum utility for a given player in such games [8, 2].",
                "Unfortunately, this result does not generalize to more than two players-here, the problem becomes NP-hard.",
                "To show this, we reduce from the VERTEX-COVER problem.",
                "Definition 1.",
                "In VERTEX-COVER, we are given a graph G = (V, E) and an integer K. We are asked whether there 85 exists a subset of the vertices S ⊆ V , with |S| = K, such that every edge e ∈ E has at least one of its endpoints in S. BALANCED-VERTEX-COVER is the special case of VERTEX-COVER in which K = |V |/2.",
                "VERTEX-COVER is NP-complete [9].",
                "The following lemma shows that the hardness remains if we require K = |V |/2. (Similar results have been shown for other NP-complete problems.)",
                "Lemma 1.",
                "BALANCED-VERTEX-COVER is NP-complete.",
                "Proof.",
                "Membership in NP follows from the fact that the problem is a special case of VERTEX-COVER, which is in NP.",
                "To show NP-hardness, we reduce an arbitrary VERTEX-COVER instance to a BALANCED-VERTEXCOVER instance, as follows.",
                "If, for the VERTEX-COVER instance, K > |V |/2, then we simply add isolated vertices that are disjoint from the rest of the graph, until K = |V |/2.",
                "If K < |V |/2, we add isolated triangles (that is, the complete graph on three vertices) to the graph, increasing K by 2 every time, until K = |V |/2.",
                "Theorem 4.",
                "In 3-player normal-form games, finding an optimal mixed strategy to commit to is NP-hard.",
                "Proof.",
                "We reduce an arbitrary BALANCED-VERTEXCOVER instance to the following 3-player normal-form game.",
                "For every vertex v, each of the three players has a pure strategy corresponding to that vertex (rv, sv, tv, respectively).",
                "In addition, for every edge e, the third player has a pure strategy te; and finally, the third player has one additional pure strategy t0.",
                "The utilities are as follows: • for all r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • for all r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • for all v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • for all v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • for all v ∈ V , for all r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V | |V |−2 ; • for all e ∈ E, s ∈ S, for both v ∈ e, u3(rv, s, te) = 0; • for all e ∈ E, s ∈ S, for all v /∈ e, u3(rv, s, te) = |V | |V |−2 . • for all r ∈ R, s ∈ S, u3(r, s, t0) = 1.",
                "We note that players 1 and 2 have the same utility function.",
                "We claim that there is an optimal strategy profile in which players 1 and 2 both obtain 1 (their maximum utility) if and only if there is a solution to the BALANCED-VERTEXCOVER problem. (Otherwise, these players will both obtain 0.)",
                "First, suppose there exists a solution to the BALANCEDVERTEX-COVER problem.",
                "Then, let player 1 play every rv such that v is in the cover with probability 2 |V | , and let player 2 play every sv such that v is not in the cover with probability 2 |V | .",
                "Then, for player 3, the expected utility of playing tv (for any v) is (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of 2 |V | that rv or sv is played.",
                "Additionally, the expected utility of playing te (for any e) is at most (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of at least 2 |V | that some rv with v ∈ e is played (because player 1 is randomizing over the pure strategies corresponding to the cover).",
                "It follows that playing t0 is a best response for player 3, giving players 1 and 2 a utility of 1.",
                "Now, suppose that players 1 and 2 obtain 1 in optimal play.",
                "Then, it must be the case that player 3 plays t0.",
                "Hence, for every v ∈ V , there must be a probability of at least 2 |V | that either rv or sv is played, for otherwise player 3 would be better off playing tv.",
                "Because players 1 and 2 have only a total probability of 2 to distribute, it must be the case that for each v, either rv or sv is played with probability 2 |V | , and the other is played with probability 0. (It is not possible for both to have nonzero probability, because then there would be some probability that both are played simultaneously (correlation is not possible), hence the total probability of at least one being played could not be high enough for all vertices.)",
                "Thus, for exactly half the v ∈ V , player 1 places probability 2 |V | on rv.",
                "Moreover, for every e ∈ E, there must be a probability of at least 2 |V | that some rv with v ∈ e is played, for otherwise player 3 would be better off playing te.",
                "Thus, the v ∈ V such that player 1 places probability 2 |V | on rv constitute a balanced vertex cover. 3.",
                "BAYESIAN GAMES So far, we have restricted our attention to normal-form games.",
                "In a normal-form game, it is assumed that every agent knows every other agents preferences over the outcomes of the game.",
                "In general, however, agents may have some private information about their preferences that is not known to the other agents.",
                "Moreover, at the time of commitment to a strategy, the agents may not even know their own (final) preferences over the outcomes of the game yet, because these preferences may be dependent on a context that has yet to materialize.",
                "For example, when the code for a trading agent is written, it may not yet be clear how that agent will value resources that it will negotiate over later, because this depends on information that is not yet available at the time at which the code is written (such as orders that will have been placed to the agent before the negotiation).",
                "In this section, we will study commitment in Bayesian games, which can model such uncertainty over preferences. 3.1 Definitions In a Bayesian game, every player i has a set of actions Si, a set of types Θi with an associated probability distribution πi : Θi → [0, 1], and, for each type θi, a utility function uθi i : S1 × S2 × . . . × Sn → R. A pure strategy in a Bayesian game is a mapping from the players types to actions, σi : Θi → Si. (Bayesian games can be rewritten in normal form by enumerating every pure strategy σi, but this will cause an exponential blowup in the size of the representation of the game and therefore cannot lead to efficient algorithms.)",
                "The strategy that the leader should commit to depends on whether, at the time of commitment, the leader knows her own type.",
                "If the leader does know her own type, the other types that the leader might have had become irrelevant and the leader should simply commit to the strategy that is optimal for the type.",
                "However, as argued above, the leader does not necessarily know her own type at the time of commitment (e.g., the time at which the code is submitted).",
                "In this case, the leader must commit to a strategy that is 86 dependent upon the leaders eventual type.",
                "We will study this latter model, although we will pay specific attention to the case where the leader has only a single type, which is effectively the same as the former model. 3.2 Commitment to pure strategies It turns out that computing an optimal pure strategy to commit to is hard in Bayesian games, even with two players.",
                "Theorem 5.",
                "Finding an optimal pure strategy to commit to in 2-player Bayesian games is NP-hard, even when the follower has only a single type.",
                "Proof.",
                "We reduce an arbitrary VERTEX-COVER instance to the following Bayesian game between the leader and the follower.",
                "The leader has K types θ1, θ2, . . . , θK , each occurring with probability 1/K, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has only a single type; for each edge e ∈ E, the follower has an action te, and the follower has a single additional action t0.",
                "The utility function for the leader is given by, for all θl ∈ Θl and all s ∈ S, u θl l (s, t0) = 1, and for all e ∈ E, u θl l (s, te) = 0.",
                "The followers utility is given by: • For all v ∈ V , for all e ∈ E with v /∈ e, uf (sv, te) = 1; • For all v ∈ V , for all e ∈ E with v ∈ e, uf (sv, te) = −K; • For all v ∈ V , uf (sv, t0) = 0.",
                "We claim that the leader can get a utility of 1 if and only if there is a solution to the VERTEX-COVER instance.",
                "First, suppose that there is a solution to the VERTEXCOVER instance.",
                "Then, the leader can commit to a pure strategy such that for each vertex v in the cover, the leader plays sv for some type.",
                "Then, the followers utility for playing te (for any e ∈ E) is at most K−1 K + 1 K (−K) = − 1 K , so that the follower will prefer to play t0, which gives the leader a utility of 1, as required.",
                "Now, suppose that there is a pure strategy for the leader that will give the leader a utility of 1.",
                "Then, the follower must play t0.",
                "In order for the follower not to prefer playing te (for any e ∈ E) instead, for at least one v ∈ e the leader must play sv for some type θl.",
                "Hence, the set of vertices v that the leader plays for some type must constitute a vertex cover; and this set can have size at most K, because the leader has only K types.",
                "So there is a solution to the VERTEXCOVER instance.",
                "However, if the leader has only a single type, then the problem becomes easy again (#types is the number of types for the follower): Theorem 6.",
                "In 2-player Bayesian games in which the leader has only a single type, an optimal pure strategy to commit to can be found in O(#outcomes · #types) time.",
                "Proof.",
                "For every leader action s, we can compute, for every follower type θf ∈ Θf , which actions t maximize the followers utility; call this set of actions BRθf (s).",
                "Then, the utility that the leader receives for committing to action s can be computed as θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), and the leader can choose the best action to commit to. 3.3 Commitment to mixed strategies In two-player zero-sum imperfect information games with perfect recall (no player ever forgets something that it once knew), a minimax strategy can be constructed in polynomial time [12, 13].",
                "Unfortunately, this result does not extend to computing optimal mixed strategies to commit to in the general-sum case-not even in Bayesian games.",
                "We will exhibit NP-hardness by reducing from the INDEPENDENTSET problem.",
                "Definition 2.",
                "In INDEPENDENT-SET, we are given a graph G = (V, E) and an integer K. We are asked whether there exists a subset of the vertices S ⊆ V , with |S| = K, such that no edge e ∈ E has both of its endpoints in S. Again, this problem is NP-complete [9].",
                "Theorem 7.",
                "Finding an optimal mixed strategy to commit to in 2-player Bayesian games is NP-hard, even when the leader has only a single type and the follower has only two actions.",
                "Proof.",
                "We reduce an arbitrary INDEPENDENT-SET instance to the following Bayesian game between the leader and the follower.",
                "The leader has only a single type, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has a type θv for every v ∈ V , occurring with probability 1 (|E|+1)|V | , and a type θe for every e ∈ E, occurring with probability 1 |E|+1 .",
                "The follower has two actions: t0 and t1.",
                "The leaders utility is given by, for all s ∈ S, ul(s, t0) = 1 and ul(s, t1) = 0.",
                "The followers utility is given by: • For all v ∈ V , uθv f (sv, t1) = 0; • For all v ∈ V and s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • For all v ∈ V and s ∈ S, uθv f (s, t0) = 1; • For all e ∈ E, s ∈ S, uθe f (s, t0) = 1; • For all e ∈ E, for both v ∈ e, uθe f (sv, t1) = 2K 3 ; • For all e ∈ E, for all v /∈ e, uθe f (sv, t1) = 0.",
                "We claim that an optimal strategy to commit to gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | if and only if there is a solution to the INDEPENDENT-SET instance.",
                "First, suppose that there is a solution to the INDEPENDENT-SET instance.",
                "Then, the leader could commit to the following strategy: for every vertex v in the independent set, play the corresponding sv with probability 1/K.",
                "If the follower has type θe for some e ∈ E, the expected utility for the follower of playing t1 is at most 1 K 2K 3 = 2/3, because there is at most one vertex v ∈ e such that sv is played with nonzero probability.",
                "Hence, the follower will play t0 and obtain a utility of 1.",
                "If the follower has type θv for some vertex v in the independent set, the expected utility for the follower of playing t1 is K−1 K K K−1 = 1, because the leader plays sv with probability 1/K.",
                "It follows that the follower (who breaks ties to maximize the leaders utility) will play t0, which also gives a utility of 1 and gives the leader a higher utility.",
                "Hence the leaders expected utility for this strategy is at least |E| |E|+1 + K (|E|+1)|V | , as required. 87 Now, suppose that there is a strategy that gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | .",
                "Then, this strategy must induce the follower to play t0 whenever it has a type of the form θe (because otherwise, the utility could be at most |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ).",
                "Thus, it cannot be the case that for some edge e = (v1, v2) ∈ E, the probability that the leader plays one of sv1 and sv2 is at least 2/K, because then the expected utility for the follower of playing t1 when it has type θe would be at least 2 K 2K 3 = 4/3 > 1.",
                "Moreover, the strategy must induce the follower to play t0 for at least K types of the form θv.",
                "Inducing the follower to play t0 when it has type θv can be done only by playing sv with probability at least 1/K, which will give the follower a utility of at most K−1 K K K−1 = 1 for playing t1.",
                "But then, the set of vertices v such that sv is played with probability at least 1/K must constitute an independent set of size K (because if there were an edge e between two such vertices, it would induce the follower to play t1 for type θe by the above).",
                "By contrast, if the follower has only a single type, then we can generalize the linear programming approach for normalform games: Theorem 8.",
                "In 2-player Bayesian games in which the follower has only a single type, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "We generalize the approach in Theorem 2 as follows.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader for every one of the leaders types such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders ex ante expected utility.",
                "To do so, we generalize the linear program as follows: maximize θl∈Θl π(θl) s∈S pθl s uθl l (s, t) subject to for all t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t ) for all θl ∈ Θl, s∈S p θl s = 1 As in Theorem 2, the solution for the linear program that maximizes the solution value is an optimal strategy to commit to.",
                "This shows an interesting contrast between commitment to pure strategies and commitment to mixed strategies in Bayesian games: for pure strategies, the problem becomes easy if the leader has only a single type (but not if the follower has only a single type), whereas for mixed strategies, the problem becomes easy if the follower has only a single type (but not if the leader has only a single type). 4.",
                "CONCLUSIONS AND FUTURE RESEARCH In <br>multiagent system</br>s, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "This requires some equilibrium notion (Nash equilibrium and its refinements), and often leads to the equilibrium selection problem: it is unclear to each individual player according to which equilibrium she should play.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "For example, one agent may arrive at the (real or virtual) site of the game before the other, or, in the specific case of software agents, the code for one agent may be completed and committed before that of another agent.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "Specifically, if commitment to mixed strategies is possible, then (optimal) commitment never hurts the leader, and often helps.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we studied how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "For normal-form games, we showed that the optimal pure strategy to commit to can be found efficiently for any number of players.",
                "An optimal mixed strategy to commit to in a normal-form game can be found efficiently for two players using linear programming (and no more efficiently than that, in the sense that any linear program with a probability constraint can be encoded as such a problem). (This is a generalization of the polynomial-time computability of minimax strategies in normal-form games.)",
                "The problem becomes NP-hard for three (or more) players.",
                "In Bayesian games, the problem of finding an optimal pure strategy to commit to is NP-hard even in two-player games in which the follower has only a single type, although two-player games in which the leader has only a single type can be solved efficiently.",
                "The problem of finding an optimal mixed strategy to commit to in a Bayesian game is NP-hard even in two-player games in which the leader has only a single type, although two-player games in which the follower has only a single type can be solved efficiently using a generalization of the linear progamming approach for normal-form games.",
                "The following two tables summarize these results. 2 players ≥ 3 players normal-form O(#outcomes) O(#outcomes· #players) Bayesian, O(#outcomes· NP-hard 1-type leader #types) Bayesian, NP-hard NP-hard 1-type follower Bayesian (general) NP-hard NP-hard Results for commitment to pure strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.) 88 2 players ≥ 3 players normal-form one LP-solve per NP-hard follower action Bayesian, NP-hard NP-hard 1-type leader Bayesian, one LP-solve per NP-hard 1-type follower follower action Bayesian (general) NP-hard NP-hard Results for commitment to mixed strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.)",
                "Future research can take a number of directions.",
                "First, we can empirically evaluate the techniques presented here on test suites such as GAMUT [19].",
                "We can also study the computation of optimal strategies to commit to in other1 concise representations of normal-form games-for example, in graphical games [10] or local-effect/action graph games [14, 1].",
                "For the cases where computing an optimal strategy to commit to is NP-hard, we can also study the computation of approximately optimal strategies to commit to.",
                "While the correct definition of an approximately optimal strategy is in this setting may appear simple at first-it should be a strategy that, if the following players play optimally, performs almost as well as the optimal strategy in expectation-this definition becomes problematic when we consider that the other players may also be playing only approximately optimally.",
                "One may also study models in which multiple (but not all) players commit at the same time.",
                "Another interesting direction to pursue is to see if computing optimal mixed strategies to commit to can help us in, or otherwise shed light on, computing Nash equilibria.",
                "Often, optimal mixed strategies to commit to are also Nash equilibrium strategies (for example, in two-player zero-sum games this is always true), although this is not always the case (for example, as we already pointed out, sometimes the optimal strategy to commit to is a strictly dominated strategy, which can never be a Nash equilibrium strategy). 5.",
                "REFERENCES [1] N. A. R. Bhat and K. Leyton-Brown.",
                "Computing Nash equilibria of action-graph games.",
                "In Proceedings of the 20th Annual Conference on Uncertainty in Artificial Intelligence (UAI), Banff, Canada, 2004. [2] V. Conitzer and T. Sandholm.",
                "Complexity results about Nash equilibria.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pages 765-771, Acapulco, Mexico, 2003. [3] V. Conitzer and T. Sandholm.",
                "Complexity of (iterated) dominance.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 88-97, Vancouver, Canada, 2005. [4] V. Conitzer and T. Sandholm.",
                "A generalized strategy eliminability criterion and computational methods for applying it.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 483-488, Pittsburgh, PA, USA, 2005. [5] A.",
                "A. Cournot.",
                "Recherches sur les principes math´ematiques de la th´eorie des richesses (Researches 1 Bayesian games are one potentially concise representation of normal-form games. into the Mathematical Principles of the Theory of Wealth).",
                "Hachette, Paris, 1838. [6] G. Dantzig.",
                "A proof of the equivalence of the programming problem and the game problem.",
                "In T. Koopmans, editor, Activity Analysis of Production and Allocation, pages 330-335.",
                "John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel.",
                "The complexity of eliminating dominated strategies.",
                "Mathematics of Operation Research, 18:553-565, 1993. [8] I. Gilboa and E. Zemel.",
                "Nash and correlated equilibria: Some complexity considerations.",
                "Games and Economic Behavior, 1:80-93, 1989. [9] R. Karp.",
                "Reducibility among combinatorial problems.",
                "In R. E. Miller and J. W. Thatcher, editors, Complexity of Computer Computations, pages 85-103.",
                "Plenum Press, NY, 1972. [10] M. Kearns, M. Littman, and S. Singh.",
                "Graphical models for game theory.",
                "In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou, and J. N. Tsitsiklis.",
                "A note on strategy elimination in bimatrix games.",
                "Operations Research Letters, 7(3):103-107, 1988. [12] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [14] K. Leyton-Brown and M. Tennenholtz.",
                "Local-effect games.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), Acapulco, Mexico, 2003. [15] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 36-41, San Diego, CA, 2003. [16] M. Littman and P. Stone.",
                "A polynomial-time Nash equilibrium algorithm for repeated games.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 48-54, San Diego, CA, 2003. [17] R. D. Luce and H. Raiffa.",
                "Games and Decisions.",
                "John Wiley and Sons, New York, 1957.",
                "Dover republication 1989. [18] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown, and Y. Shoham.",
                "Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms.",
                "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), New York, NY, USA, 2004. [20] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "MIT Press, 1994. [21] C. Papadimitriou.",
                "Algorithms, games and the Internet.",
                "In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 749-753, 2001. 89 [22] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 664-669, San Jose, CA, USA, 2004. [23] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 495-501, Pittsburgh, PA, USA, 2005. [24] J. von Neumann.",
                "Zur Theorie der Gesellschaftsspiele.",
                "Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg.",
                "Marktform und Gleichgewicht.",
                "Springer, Vienna, 1934. [26] B. von Stengel and S. Zamir.",
                "Leadership with commitment to mixed strategies.",
                "CDAM Research Report LSE-CDAM-2004-01, London School of Economics, Feb. 2004. 90"
            ],
            "original_annotated_samples": [
                "Computing the Optimal Strategy to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In <br>multiagent system</br>s, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "INTRODUCTION In <br>multiagent system</br>s with self-interested agents (including most economic settings), the optimal action for one agent to take depends on the actions that the other agents take.",
                "CONCLUSIONS AND FUTURE RESEARCH In <br>multiagent system</br>s, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously."
            ],
            "translated_annotated_samples": [
                "En <br>sistemas multiagentes</br>, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias simultáneamente.",
                "En <br>sistemas multiagentes</br> con agentes auto-interesados (incluyendo la mayoría de los entornos económicos), la acción óptima que un agente debe tomar depende de las acciones que tomen los otros agentes.",
                "CONCLUSIONES E INVESTIGACIONES FUTURAS En los <br>sistemas multiagentes</br>, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias de forma simultánea."
            ],
            "translated_text": "En <br>sistemas multiagentes</br>, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias simultáneamente. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. El reciente aumento en el interés por las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas a comprometerse tanto en el compromiso de estrategias puras como en el compromiso de estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Ofrecemos tanto resultados positivos (algoritmos eficientes) como resultados negativos (resultados de NP-hardness). Categorías y Descriptores de Asignaturas J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas Términos Generales Algoritmos, Economía, Teoría 1. En <br>sistemas multiagentes</br> con agentes auto-interesados (incluyendo la mayoría de los entornos económicos), la acción óptima que un agente debe tomar depende de las acciones que tomen los otros agentes. Para analizar cómo un agente debería comportarse en tales situaciones, es necesario aplicar las herramientas de la teoría de juegos. Normalmente, cuando se modela un escenario estratégico en el marco de la teoría de juegos, se asume que los jugadores eligen sus estrategias de forma simultánea. Esto es especialmente cierto cuando el escenario se modela como un juego en forma normal, que solo especifica la utilidad de cada agente como una función del vector de estrategias que los agentes eligen, y no proporciona información sobre el orden en que los agentes toman sus decisiones y lo que los agentes observan sobre las decisiones anteriores de otros agentes. Dado que el juego está modelado en forma normal, típicamente se analiza utilizando el concepto de equilibrio de Nash. Un equilibrio de Nash especifica una estrategia para cada jugador, de modo que ningún jugador tenga un incentivo para desviarse individualmente de este perfil de estrategias. (Por lo general, se permite que las estrategias sean mixtas, es decir, distribuciones de probabilidad sobre las estrategias originales (puras).) Un equilibrio de Nash (de estrategia mixta) está garantizado de existir en juegos finitos [18], pero un problema es que puede haber múltiples equilibrios de Nash. Esto conduce al problema de selección de equilibrio de cómo un agente puede saber qué estrategia jugar si no sabe qué equilibrio se va a jugar. Cuando el escenario se modela como un juego de forma extensiva, es posible especificar que algunos jugadores reciben información sobre las acciones tomadas por otros antes en el juego antes de decidir su acción. Sin embargo, en general, los jugadores no saben todo lo que sucedió anteriormente en el juego. Por lo tanto, estos juegos suelen ser analizados todavía utilizando un concepto de equilibrio, donde se especifica una estrategia mixta para cada jugador, y se requiere que la estrategia de cada jugador sea una mejor respuesta a las estrategias de los demás. (Normalmente se impone ahora una restricción adicional en las estrategias para garantizar que los jugadores no jueguen de una manera irracional con respecto a la información que han recibido hasta el momento). Esto conduce a refinamientos del equilibrio de Nash como el equilibrio perfecto en subjuegos y el equilibrio secuencial. Sin embargo, en muchos entornos del mundo real, las estrategias no se seleccionan de manera simultánea. A menudo, un jugador (el líder) puede comprometerse con una estrategia antes que otro jugador (el seguidor). Esto puede deberse a una variedad de razones. Por ejemplo, uno de los jugadores puede llegar al lugar donde se jugará el juego antes que otro agente (por ejemplo, en entornos económicos, un jugador puede ingresar al mercado antes y comprometerse con una forma de hacer negocios). Un compromiso tan poderoso tiene un impacto profundo en cómo debería jugarse el juego. Por ejemplo, el líder puede estar mejor jugando una estrategia que esté dominada en la representación de forma normal del juego. Quizás el ejemplo más temprano y conocido del efecto del compromiso es el de von Stackelberg [25], quien demostró que, en el modelo de duopolio de Cournot [5], si una empresa puede comprometerse con una cantidad de producción primero, esa empresa lo hará mucho mejor que en la solución de movimiento simultáneo (Nash). En general, si es posible comprometerse con estrategias mixtas, entonces (bajo suposiciones menores) nunca perjudica, y a menudo ayuda, comprometerse con una estrategia [26]. Verse obligado a comprometerse con una estrategia pura a veces ayuda y a veces perjudica (por ejemplo, comprometerse con una estrategia pura en piedra-papel-tijeras antes de la decisión de los otros jugadores naturalmente resultará en una derrota). En este documento, asumiremos que el compromiso siempre es forzado; si no lo es, el jugador que tiene la opción de comprometerse simplemente puede comparar el resultado del compromiso con el resultado de no comprometerse (movimiento simultáneo). Los modelos de liderazgo son especialmente importantes en entornos con múltiples agentes de software con intereses propios. Una vez que el código de un agente (o de un equipo de agentes) está finalizado y el agente es desplegado, el agente se compromete a jugar la estrategia (posiblemente aleatoria) que el código prescribe. Por lo tanto, siempre y cuando se pueda demostrar de manera creíble que no se puede cambiar el código más tarde, el código funciona como un dispositivo de compromiso. Esto es válido para torneos recreativos entre agentes (por ejemplo, torneos de póker, RoboSoccer) y para aplicaciones industriales como redes de sensores. Finalmente, también existe una situación de liderazgo implícito en el campo del diseño de mecanismos, en la cual un jugador (el diseñador) tiene la oportunidad de elegir las reglas del juego que los demás jugadores luego siguen. El diseño de mecanismos es un tema extremadamente importante para la comunidad de EC: los artículos publicados sobre diseño de mecanismos en las recientes conferencias de EC son demasiados para citar. De hecho, el diseñador del mecanismo puede beneficiarse al comprometerse con una elección que, si las acciones de los agentes (restantes) estuvieran fijas, sería subóptima. Por ejemplo, en una subasta (a precio fijo), el vendedor puede desear establecer un precio de reserva positivo (artificial) para el artículo, por debajo del cual el artículo no se venderá, incluso si el vendedor valora el artículo en 0. En retrospectiva (después de recibir las ofertas), esto (ingenuamente) parece subóptimo: si llegaba una oferta que superaba el precio de reserva, el precio de reserva no tenía efecto, y si no llegaba tal oferta, el vendedor hubiera estado mejor aceptando una oferta más baja. Por supuesto, la razón para establecer el precio de reserva es incentivar a los postores a ofertar más alto, y debido a esto, establecer precios de reserva artificiales puede aumentar realmente los ingresos esperados para el vendedor. Recientemente se ha dedicado una cantidad significativa de investigación al cálculo de soluciones de acuerdo con varios conceptos de solución para escenarios en los que los agentes eligen sus estrategias simultáneamente, como la dominancia [7, 11, 3] y (especialmente) el equilibrio de Nash [8, 21, 16, 15, 2, 22, 23, 4]. Sin embargo, se ha ignorado el cálculo de la estrategia óptima a comprometerse en una situación de liderazgo. Teóricamente, las situaciones de liderazgo simplemente pueden ser consideradas como un juego de forma extensiva en el que un jugador elige una estrategia (para el juego original) primero. El número de estrategias en este juego de forma extensiva, sin embargo, puede ser extremadamente grande. Por ejemplo, si el líder es capaz de comprometerse con una estrategia mixta en el juego original, entonces cada una de las estrategias mixtas (continuo de) constituye una estrategia pura en la representación de forma extensiva de la situación de liderazgo. (Se destaca que un compromiso con una distribución no es lo mismo que una distribución sobre compromisos). Además, si el juego original es en sí mismo un juego de forma extensiva, el número de estrategias en la representación de forma extensiva de la situación de liderazgo (que es un juego de forma extensiva diferente) se vuelve aún más grande. Por lo tanto, generalmente no es factible computacionalmente simplemente transformar el juego original en la representación de forma extensiva de la situación de liderazgo; en su lugar, debemos analizar el juego en su representación original. En este artículo, estudiamos cómo calcular la estrategia óptima a comprometerse, tanto en juegos de forma normal (Sección 2) como en juegos bayesianos, que son un caso especial de juegos de forma extensiva (Sección 3). JUEGOS EN FORMA NORMAL En esta sección, estudiamos cómo calcular la estrategia óptima a comprometerse para juegos representados en forma normal. 2.1 Definiciones En un juego en forma normal, cada jugador i ∈ {1, . . . , n} tiene un conjunto de estrategias puras (o acciones) Si, y una función de utilidad ui : S1×S2×. . .×Sn → R que mapea cada resultado (un vector que consiste en una estrategia pura para cada jugador, también conocido como un perfil de estrategias puras) a un número real. Para facilitar la notación, en el caso de dos jugadores, nos referiremos al conjunto de estrategias puras del jugador 1 como S, y al conjunto de estrategias puras del jugador 2 como T. Estos juegos pueden representarse en forma de matriz (bi-matriz), en la que las filas corresponden a las estrategias puras del jugador 1, las columnas corresponden a las estrategias puras del jugador 2, y las entradas de la matriz dan las utilidades de los jugadores de fila y columna (en ese orden) para el resultado correspondiente del juego. En el caso de tres jugadores, usaremos R, S y T, para las estrategias puras de los jugadores 1, 2 y 3, respectivamente. Una estrategia mixta para un jugador es una distribución de probabilidad sobre las estrategias puras de ese jugador. En el caso de juegos de dos jugadores, nos referiremos al jugador 1 como el líder y al jugador 2 como el seguidor. Antes de definir estrategias de liderazgo óptimas, considera el siguiente juego que ilustra el efecto de la capacidad del líder para comprometerse. 2, 1 4, 0 1, 0 3, 1 En esta representación en forma normal, la estrategia inferior para el jugador de la fila está estrictamente dominada por la estrategia superior. Sin embargo, si el jugador de la fila tiene la capacidad de comprometerse con una estrategia pura antes de que el jugador de la columna elija su estrategia, el jugador de la fila debería comprometerse con la estrategia inferior: al hacerlo, el jugador de la columna preferirá jugar la estrategia correcta, lo que llevará a una utilidad de 3 para el jugador de la fila. Por el contrario, si el jugador de la fila se comprometiera con la estrategia superior, el jugador de la columna preferiría jugar la estrategia izquierda, lo que llevaría a una utilidad de solo 2 para el jugador de la fila. Si el jugador de la fila puede comprometerse a una estrategia mixta, entonces puede obtener una utilidad aún mayor (esperada): si el jugador de la fila se compromete a colocar una probabilidad p > 1/2 en la estrategia inferior, entonces el jugador de la columna seguirá prefiriendo jugar la estrategia derecha, y la utilidad esperada de los jugadores de la fila será 3p + 4(1 − p) = 4 − p ≥ 3. Si el jugador de la fila juega cada estrategia con una probabilidad exacta de 1/2, el jugador de la columna está 83 indiferente entre las estrategias. En tales casos, asumiremos que el jugador de la columna elegirá la estrategia que maximiza la utilidad de los jugadores de la fila (en este caso, la estrategia correcta). Por lo tanto, la estrategia mixta óptima a la que debe comprometerse el jugador de la fila es p = 1/2. Hay algunas buenas razones para esta suposición. Si asumiéramos lo contrario, entonces no existiría una estrategia óptima para el jugador de la fila en el juego de ejemplo: el jugador de la fila jugaría la estrategia inferior con una probabilidad p = 1/2 + con > 0, y cuanto menor sea , mejor será la utilidad para el jugador de la fila. Por el contrario, si asumimos que el seguidor siempre rompe los empates a favor de los líderes, entonces siempre existe una estrategia mixta óptima para el líder, lo que corresponde a un equilibrio perfecto en subjuegos de la representación en forma extensiva de la situación de liderazgo. En cualquier caso, esta es una suposición estándar para tales modelos (por ejemplo, [20]), aunque algunos trabajos han investigado lo que puede suceder en los otros equilibrios perfectos de subjuego [26]. (Para juegos genéricos de dos jugadores, el pago del equilibrio perfecto de subjuego de los líderes es único). Además, la misma suposición se utiliza típicamente en el diseño de mecanismos, asumiendo que si un agente es indiferente entre revelar sus preferencias de manera veraz o falsa, las reportará de manera veraz. Dado este supuesto, podemos hacer referencia de manera segura a estrategias de liderazgo óptimas en lugar de tener que utilizar alguna noción de equilibrio. Por lo tanto, para los propósitos de este documento, una estrategia óptima a comprometerse en un juego de 2 jugadores es una estrategia s ∈ S que maximiza maxt∈BR(s) ul(s, t), donde BR(s) = arg maxt∈T uf (s, t). (ul y uf son las funciones de utilidad del líder y los seguidores, respectivamente). Podemos tener S = S para el caso de compromiso con estrategias puras, o S = ∆(S), el conjunto de distribuciones de probabilidad sobre S, para el caso de compromiso con estrategias mixtas. (Observamos que reemplazar T por ∆(T) no hace ninguna diferencia en esta definición). Para juegos con más de dos jugadores, en los que los jugadores se comprometen con sus estrategias en secuencia, definimos estrategias óptimas a las que comprometerse de forma recursiva. Después de que el líder se compromete con una estrategia, el juego que jugarán los agentes restantes es en sí mismo un juego de liderazgo (más pequeño). Por lo tanto, definimos una estrategia óptima a comprometerse como una estrategia que maximiza la utilidad del líder, asumiendo que el juego de los agentes restantes es óptimo bajo esta definición, y maximiza la utilidad del líder entre todas las formas óptimas de jugar el juego restante. Nuevamente, el compromiso con estrategias mixtas puede o no ser una posibilidad para cada jugador (aunque para el último jugador no importa si permitimos el compromiso con estrategias mixtas). 2.2 Compromiso con estrategias puras. Primero estudiamos cómo calcular la estrategia pura óptima a la que comprometerse. Esto es relativamente simple, porque el número de estrategias a comprometer no es muy grande. (En lo siguiente, #resultados es el número de perfiles de estrategia completos). Teorema 1. Bajo el compromiso de estrategias puras, el conjunto de todos los perfiles de estrategia óptimos en un juego en forma normal se puede encontrar en tiempo O(#jugadores · #resultados). Prueba. Cada estrategia pura a la que el primer jugador pueda comprometerse inducirá un subjuego para los jugadores restantes. Podemos resolver cada subjuego de esta manera de forma recursiva para encontrar todos sus perfiles de estrategia óptimos; cada uno de estos le dará al líder original cierta utilidad. Aquellos que proporcionan al líder la utilidad máxima corresponden exactamente a los perfiles de estrategia óptimos del juego original. Ahora presentamos el algoritmo de forma formal. Sea Su(G, s1) el subjuego que resulta después de que el primer jugador restante en G juega s1 ∈ SG 1. Un juego con 0 jugadores es simplemente un resultado del juego. La función Append(s, O) añade la estrategia s a cada uno de los vectores de estrategias en el conjunto O. Sea e el vector vacío sin elementos. En un ligero abuso de notación, escribiremos uG 1 (C) cuando todos los perfiles estratégicos en el conjunto C le den al jugador 1 la misma utilidad en el juego G. (Aquí, el jugador 1 es el primer jugador restante en el subjuego G, no necesariamente el jugador 1 en el juego original). Observamos que arg max es un conjunto de valores. Entonces, el siguiente algoritmo calcula todos los perfiles de estrategia óptimos: Algoritmo Resolver(G) si G tiene 0 jugadores, devuelve {e} C ← ∅ para todo s1 ∈ SG 1 { O ← Resolver(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) si C = ∅ o uG 1 (s1, O ) = uG 1 (C) C ← C∪Agregar(s1, O ) si uG 1 (s1, O ) > uG 1 (C) C ←Agregar(s1, O ) } devuelve C Cada resultado es examinado (potencialmente) por cada jugador, lo que lleva al límite de tiempo dado. Como ejemplo de cómo funciona el algoritmo, considera el siguiente juego de 3 jugadores, en el que el primer jugador elige la matriz izquierda o derecha, el segundo jugador elige una fila y el tercer jugador elige una columna. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 Primero eliminamos los resultados que no corresponden a las mejores respuestas para el tercer jugador (eliminándolos de la matriz): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Luego, eliminamos las entradas en las que el tercer jugador no resuelve los empates a favor del segundo jugador, así como las entradas que no corresponden a las mejores respuestas para el segundo jugador. 0,1,1 2,1,1 1,1,1 0,5,1 Finalmente, eliminamos las entradas en las que el segundo y tercer jugador no resuelven los empates a favor del primer jugador, así como las entradas que no corresponden a las mejores respuestas para el primer jugador. 2,1,1 Por lo tanto, en el juego óptimo, el primer jugador elige la matriz izquierda, el segundo jugador elige la fila del medio y el tercer jugador elige la columna izquierda. (Notamos que este resultado está dominado por Pareto por (Derecha, Medio, Izquierda).) Para juegos en forma normal general, la utilidad de cada jugador para cada uno de los resultados debe representarse explícitamente en la entrada, de modo que el tamaño de la entrada sea en sí mismo Ω(#jugadores · #resultados). Por lo tanto, el algoritmo es de hecho un algoritmo de tiempo lineal. 2.3 Compromiso con estrategias mixtas En el caso especial de juegos de dos jugadores de suma cero, calcular una estrategia mixta óptima para que el líder se comprometa es equivalente a calcular una estrategia minimax, que minimiza la utilidad esperada máxima que el oponente puede obtener. Las estrategias minimax constituyen el único concepto de solución natural para juegos de suma cero de dos jugadores: el Teorema Minimax de von Neumann [24] establece que en juegos de suma cero de dos jugadores, no importa (en términos de las utilidades de los jugadores) qué jugador se compromete primero a una estrategia mixta, y un perfil de estrategias mixtas es un equilibrio de Nash si y solo si ambas estrategias son estrategias minimax. Es bien sabido que una estrategia minimax se puede encontrar en tiempo polinómico, utilizando programación lineal [17]. Nuestro primer resultado en esta sección generaliza este resultado, mostrando que una estrategia mixta óptima para que el líder se comprometa puede ser calculada eficientemente en juegos de dos jugadores de suma general, nuevamente utilizando programación lineal. Teorema 2. En juegos de forma normal de 2 jugadores, una estrategia mixta óptima a la que comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal. Prueba. Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder de modo que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad del líder. Un programa lineal simple puede calcular una estrategia mixta como la siguiente: maximizar s∈S psul(s, t) sujeto a que para todo t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1. Se destaca que este programa puede ser inviable para algunas estrategias seguidoras t, por ejemplo, si t es una estrategia estrictamente dominada. Sin embargo, el programa debe ser factible para al menos algunas estrategias seguidoras; entre estas estrategias seguidoras, elige una estrategia t∗ que maximice el valor de la solución de los programas lineales. Entonces, si la líder elige como su estrategia mixta los ajustes óptimos de las variables ps para el programa lineal para t∗, y el seguidor juega t∗, esto constituye un perfil de estrategia óptimo. En el siguiente resultado, demostramos que no podemos esperar resolver el problema de manera más eficiente que la programación lineal, ya que podemos reducir cualquier programa lineal con una restricción de probabilidad en sus variables a un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores. Teorema 3. Cualquier programa lineal cuyas variables xi (con xi ∈ R≥0) deben satisfacer i xi = 1 puede ser modelado como un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores. Prueba. Que el líder tenga una estrategia pura i para cada variable xi. Que el jugador de la columna tenga una estrategia pura j para cada restricción en el programa lineal (distinta de i xi = 1), y una única estrategia pura adicional 0. Que las funciones de utilidad sean las siguientes. Escribiendo el objetivo del programa lineal como maximizar ci xi, para cualquier i, dejando ul(i, 0) = ci y uf(i, 0) = 0. Escribiendo la j-ésima restricción del programa lineal (sin incluir i xi = 1) como i aijxi ≤ bj, para cualquier i, j > 0, sea ul(i, j) = mini ci − 1 y uf(i, j) = aij − bj. Por ejemplo, considera el siguiente programa lineal. maximizar 2x1 + x2 sujeto a x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 La solución óptima de este programa es x1 = 1/3, x2 = 2/3. Nuestra reducción transforma este programa en el siguiente juego de líder-seguidor (donde el líder es el jugador de la fila). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 De hecho, la estrategia óptima para el líder es jugar la estrategia superior con una probabilidad de 1/3 y la estrategia inferior con una probabilidad de 2/3. Ahora demostramos que la reducción funciona en general. Claramente, el líder quiere incentivar al seguidor a jugar 0, porque la utilidad que el líder obtiene cuando el seguidor juega 0 siempre es mayor que cuando el seguidor no juega 0. Para que el seguidor no prefiera jugar j > 0 en lugar de 0, debe ser el caso que i pl(i)(aij − bj) ≤ 0, o equivalentemente i pl(i)aij ≤ bj. Por lo tanto, el líder obtendrá una utilidad de al menos mini ci si y solo si hay una solución factible a las restricciones. Dado que el pl(i) incentiva al seguidor a jugar 0, el líder intenta maximizar i pl(i)ci. Por lo tanto, el líder debe resolver el programa lineal original. Como prueba alternativa del Teorema 3, se puede observar que se sabe que encontrar una estrategia minimax en un juego de suma cero es tan difícil como el problema de programación lineal [6], y como señalamos al principio de esta sección, calcular una estrategia minimax en un juego de suma cero es un caso especial del problema de calcular una estrategia mixta óptima a la que comprometerse. La solubilidad en tiempo polinómico del problema de calcular una estrategia mixta óptima a la que comprometerse en juegos de forma normal de dos jugadores contrasta con la complejidad desconocida de calcular un equilibrio de Nash en tales juegos [21], así como con la NP-dificultad de encontrar un equilibrio de Nash con utilidad máxima para un jugador dado en tales juegos [8, 2]. Desafortunadamente, este resultado no se generaliza a más de dos jugadores; aquí, el problema se vuelve NP-duro. Para demostrar esto, reducimos desde el problema de CUBRIR-VÉRTICES. Definición 1. En VERTEX-COVER, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que cada arista e ∈ E tenga al menos uno de sus extremos en S. BALANCED-VERTEX-COVER es el caso especial de VERTEX-COVER en el que K = |V|/2. VERTEX-COVER es NP-completo [9]. El siguiente lema muestra que la dificultad persiste si requerimos K = |V|/2. (Resultados similares se han demostrado para otros problemas NP-completos). Lema 1. El problema de la COBERTURA DE VÉRTICES EQUILIBRADA es NP-completo. Prueba. La pertenencia a NP se deriva del hecho de que el problema es un caso especial de CUBRIMIENTO DE VÉRTICES, que está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES a una instancia de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO, de la siguiente manera. Si, para la instancia de CUBRIMIENTO DE VÉRTICES, K > |V|/2, simplemente agregamos vértices aislados que estén disjuntos del resto del grafo, hasta que K = |V|/2. Si K < |V|/2, agregamos triángulos aislados (es decir, el grafo completo de tres vértices) al grafo, aumentando K en 2 cada vez, hasta que K = |V|/2. Teorema 4. En juegos de forma normal de 3 jugadores, encontrar una estrategia mixta óptima a la que comprometerse es NP-difícil. Prueba. Reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO al siguiente juego de forma normal de 3 jugadores. Para cada vértice v, cada uno de los tres jugadores tiene una estrategia pura correspondiente a ese vértice (rv, sv, tv, respectivamente). Además, para cada arista e, el tercer jugador tiene una estrategia pura te; y finalmente, el tercer jugador tiene una estrategia pura adicional t0. Los servicios son los siguientes: • para todo r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • para todo r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • para todo v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • para todo v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • para todo v ∈ V, para todo r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V| |V|−2; • para todo e ∈ E, s ∈ S, para ambos v ∈ e, u3(rv, s, te) = 0; • para todo e ∈ E, s ∈ S, para todo v /∈ e, u3(rv, s, te) = |V| |V|−2. • para todo r ∈ R, s ∈ S, u3(r, s, t0) = 1. Observamos que los jugadores 1 y 2 tienen la misma función de utilidad. Sostenemos que existe un perfil de estrategia óptimo en el que los jugadores 1 y 2 obtienen ambos 1 (su utilidad máxima) si y solo si hay una solución al problema de la COBERTURA DE VÉRTICES EQUILIBRADA. (De lo contrario, estos jugadores obtendrán ambos 0). Primero, supongamos que existe una solución al problema de la cubierta de vértices balanceada. Entonces, deja que el jugador 1 juegue cada rv de manera que v esté en la cobertura con probabilidad 2 |V|, y deja que el jugador 2 juegue cada sv de manera que v no esté en la cobertura con probabilidad 2 |V|. Entonces, para el jugador 3, la utilidad esperada de jugar tv (para cualquier v) es (1 − 2 |V|) |V| |V|−2 = 1, porque hay una probabilidad de 2 |V| de que se juegue rv o sv. Además, la utilidad esperada de jugar te (para cualquier e) es a lo sumo (1 − 2 |V | ) |V | |V |−2 = 1, porque hay una probabilidad de al menos 2 |V | de que algún rv con v ∈ e se juegue (debido a que el jugador 1 está aleatorizando sobre las estrategias puras correspondientes a la cobertura). Se deduce que jugar t0 es la mejor respuesta para el jugador 3, otorgando a los jugadores 1 y 2 una utilidad de 1. Ahora, supongamos que los jugadores 1 y 2 obtienen 1 en el juego óptimo. Entonces, debe ser el caso de que el jugador 3 juegue t0. Por lo tanto, para cada v ∈ V, debe haber una probabilidad de al menos 2 |V| de que se juegue rv o sv, de lo contrario, al jugador 3 le convendría más jugar tv. Dado que los jugadores 1 y 2 solo tienen una probabilidad total de 2 para distribuir, debe ser el caso que para cada v, ya sea rv o sv se juegue con una probabilidad de 2 |V|, y el otro se juegue con una probabilidad de 0. (No es posible que ambos tengan una probabilidad distinta de cero, porque entonces habría alguna probabilidad de que ambos se jugaran simultáneamente (la correlación no es posible), por lo tanto, la probabilidad total de que al menos uno se juegue no podría ser lo suficientemente alta para todos los vértices). Por lo tanto, para exactamente la mitad de los v ∈ V, el jugador 1 coloca una probabilidad de 2 |V| en rv. Además, para cada e ∈ E, debe haber una probabilidad de al menos 2 |V | de que se juegue algún rv con v ∈ e, de lo contrario, al jugador 3 le convendría más jugar te. Por lo tanto, el v ∈ V tal que el jugador 1 coloca una probabilidad de 2 |V | en rv constituye una cubierta de vértices equilibrada. 3. Juegos bayesianos. Hasta ahora, hemos restringido nuestra atención a los juegos en forma normal. En un juego en forma normal, se asume que cada agente conoce las preferencias de todos los demás agentes sobre los resultados del juego. En general, sin embargo, los agentes pueden tener información privada sobre sus preferencias que no es conocida por los otros agentes. Además, en el momento de comprometerse con una estrategia, los agentes pueden ni siquiera conocer sus propias preferencias (finales) sobre los resultados del juego aún, ya que estas preferencias pueden depender de un contexto que aún no se ha materializado. Por ejemplo, cuando se escribe el código para un agente de negociación, puede que aún no esté claro cómo ese agente valorará los recursos sobre los que negociará más adelante, porque esto depende de información que aún no está disponible en el momento en que se escribe el código (como órdenes que habrán sido colocadas al agente antes de la negociación). En esta sección, estudiaremos el compromiso en juegos bayesianos, los cuales pueden modelar tal incertidumbre sobre preferencias. 3.1 Definiciones En un juego bayesiano, cada jugador i tiene un conjunto de acciones Si, un conjunto de tipos Θi con una distribución de probabilidad asociada πi : Θi → [0, 1], y, para cada tipo θi, una función de utilidad uθi i : S1 × S2 × . . . × Sn → R. Una estrategia pura en un juego bayesiano es una asignación de los tipos de los jugadores a acciones, σi : Θi → Si. (Los juegos bayesianos pueden ser reescritos en forma normal enumerando cada estrategia pura σi, pero esto causará un crecimiento exponencial en el tamaño de la representación del juego y por lo tanto no puede llevar a algoritmos eficientes). La estrategia a la que el líder debería comprometerse depende de si, en el momento del compromiso, el líder conoce su propio tipo. Si la líder conoce su propio tipo, los otros tipos que la líder podría haber tenido se vuelven irrelevantes y la líder simplemente debería comprometerse con la estrategia que sea óptima para ese tipo. Sin embargo, como se argumentó anteriormente, la líder no necesariamente conoce su propio tipo en el momento de comprometerse (por ejemplo, en el momento en que se envía el código). En este caso, el líder debe comprometerse con una estrategia que dependa en un 86% del tipo eventual del líder. Estudiaremos este último modelo, aunque prestaremos atención específica al caso en el que el líder tiene un solo tipo, lo cual es efectivamente lo mismo que el modelo anterior. 3.2 Compromiso con estrategias puras Resulta que calcular una estrategia pura óptima a la que comprometerse es difícil en juegos bayesianos, incluso con dos jugadores. Teorema 5. Encontrar una estrategia pura óptima a comprometerse en juegos bayesianos de 2 jugadores es NP-difícil, incluso cuando el seguidor tiene solo un tipo. Prueba. Reducimos una instancia arbitraria de CUBRIMIENTO DE VÉRTICES al siguiente juego bayesiano entre el líder y el seguidor. El líder tiene K tipos θ1, θ2, . . . , θK, cada uno ocurriendo con probabilidad 1/K, y para cada vértice v ∈ V, el líder tiene una acción sv. El seguidor tiene solo un tipo; para cada borde e ∈ E, el seguidor tiene una acción te, y el seguidor tiene una acción adicional única t0. La función de utilidad para el líder está dada por, para todo θl ∈ Θl y todo s ∈ S, u θl l (s, t0) = 1, y para todo e ∈ E, u θl l (s, te) = 0. La utilidad de los seguidores se da por: • Para todo v ∈ V, para todo e ∈ E con v /∈ e, uf (sv, te) = 1; • Para todo v ∈ V, para todo e ∈ E con v ∈ e, uf (sv, te) = −K; • Para todo v ∈ V, uf (sv, t0) = 0. Sostenemos que el líder puede obtener una utilidad de 1 si y solo si hay una solución para la instancia de CUBRIMIENTO-DE-VÉRTICES. Primero, supongamos que hay una solución para la instancia de CUBRIRVÉRTICES. Entonces, el líder puede comprometerse con una estrategia pura tal que para cada vértice v en la cobertura, el líder juega sv para algún tipo. Entonces, la utilidad de los seguidores para jugar te (para cualquier e ∈ E) es a lo sumo K−1 K + 1 K (−K) = − 1 K , por lo que el seguidor preferirá jugar t0, lo que le da al líder una utilidad de 1, como se requiere. Ahora, supongamos que hay una estrategia pura para el líder que le dará al líder una utilidad de 1. Entonces, el seguidor debe jugar t0. Para que el seguidor no prefiera jugar te (para cualquier e ∈ E) en su lugar, al menos para un v ∈ e, el líder debe jugar sv para algún tipo θl. Por lo tanto, el conjunto de vértices v que el líder juega para algún tipo debe constituir una cubierta de vértices; y este conjunto puede tener un tamaño de como máximo K, ya que el líder solo tiene K tipos. Entonces hay una solución para la instancia de CUBRIMIENTODEVÉRTICES. Sin embargo, si el líder tiene solo un tipo, entonces el problema se vuelve fácil nuevamente (#tipos es el número de tipos para el seguidor): Teorema 6. En juegos bayesianos de 2 jugadores en los que el líder tiene solo un tipo, una estrategia pura óptima a comprometerse puede encontrarse en tiempo O(#resultados · #tipos). Prueba. Para cada acción de líder s, podemos calcular, para cada tipo de seguidor θf ∈ Θf, qué acciones t maximizan la utilidad de los seguidores; llamamos a este conjunto de acciones BRθf (s). Entonces, la utilidad que recibe el líder por comprometerse a la acción s se puede calcular como θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), y el líder puede elegir la mejor acción a la que comprometerse. 3.3 Compromiso con estrategias mixtas En juegos de información imperfecta de suma cero de dos jugadores con memoria perfecta (ningún jugador olvida algo que una vez supo), una estrategia minimax se puede construir en tiempo polinómico [12, 13]. Desafortunadamente, este resultado no se extiende a calcular estrategias mixtas óptimas a comprometerse en el caso de suma general, ni siquiera en juegos bayesianos. Demostraremos la NP-dificultad reduciendo desde el problema de CONJUNTOINDEPENDIENTE. Definición 2. En INDEPENDENT-SET, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que ninguna arista e ∈ E tenga ambos extremos en S. Nuevamente, este problema es NP-completo [9]. Teorema 7. Encontrar una estrategia mixta óptima a comprometerse en juegos bayesianos de 2 jugadores es NP-duro, incluso cuando el líder tiene solo un tipo y el seguidor tiene solo dos acciones. Prueba. Reducimos una instancia arbitraria de CONJUNTO-INDEPENDIENTE al siguiente juego bayesiano entre el líder y el seguidor. El líder tiene solo un tipo, y para cada vértice v ∈ V, el líder tiene una acción sv. El seguidor tiene un tipo θv para cada v ∈ V, que ocurre con una probabilidad de 1 (|E|+1)|V|, y un tipo θe para cada e ∈ E, que ocurre con una probabilidad de 1 |E|+1. El seguidor tiene dos acciones: t0 y t1. La utilidad de los líderes se da por, para todo s ∈ S, ul(s, t0) = 1 y ul(s, t1) = 0. La utilidad de los seguidores se da por: • Para todo v ∈ V, uθv f (sv, t1) = 0; • Para todo v ∈ V y s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • Para todo v ∈ V y s ∈ S, uθv f (s, t0) = 1; • Para todo e ∈ E, s ∈ S, uθe f (s, t0) = 1; • Para todo e ∈ E, para ambos v ∈ e, uθe f (sv, t1) = 2K 3 ; • Para todo e ∈ E, para todo v /∈ e, uθe f (sv, t1) = 0. Sostenemos que una estrategia óptima a comprometerse le otorga al líder una utilidad esperada de al menos |E| |E|+1 + K (|E|+1)|V | si y solo si hay una solución para la instancia de CONJUNTO-INDEPENDIENTE. Primero, supongamos que hay una solución para la instancia de CONJUNTO-INDEPENDIENTE. Entonces, el líder podría comprometerse con la siguiente estrategia: por cada vértice v en el conjunto independiente, jugar el correspondiente sv con una probabilidad de 1/K. Si el seguidor tiene el tipo θe para algún e ∈ E, la utilidad esperada para el seguidor al jugar t1 es a lo sumo 1 K 2K 3 = 2/3, porque hay a lo sumo un vértice v ∈ e tal que sv se juega con probabilidad distinta de cero. Por lo tanto, el seguidor jugará t0 y obtendrá una utilidad de 1. Si el seguidor tiene el tipo θv para algún vértice v en el conjunto independiente, la utilidad esperada para el seguidor al jugar t1 es K−1 K K K−1 = 1, porque el líder juega sv con probabilidad 1/K. Se deduce que el seguidor (quien rompe los empates para maximizar la utilidad de los líderes) jugará t0, lo que también otorga una utilidad de 1 y brinda al líder una mayor utilidad. Por lo tanto, la utilidad esperada de los líderes para esta estrategia es al menos |E| |E|+1 + K (|E|+1)|V |, como se requiere. Ahora, supongamos que hay una estrategia que le da al líder una utilidad esperada de al menos |E| |E|+1 + K (|E|+1)|V |. Entonces, esta estrategia debe inducir al seguidor a jugar t0 siempre que tenga un tipo de la forma θe (porque de lo contrario, la utilidad podría ser a lo sumo |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ). Por lo tanto, no puede ser el caso de que para alguna arista e = (v1, v2) ∈ E, la probabilidad de que el líder juegue uno de sv1 y sv2 sea al menos 2/K, porque entonces la utilidad esperada para el seguidor de jugar t1 cuando tiene el tipo θe sería al menos 2 K 2K 3 = 4/3 > 1. Además, la estrategia debe inducir al seguidor a jugar t0 durante al menos K tipos de la forma θv. Inducir al seguidor a jugar t0 cuando tiene el tipo θv solo se puede lograr jugando sv con una probabilidad de al menos 1/K, lo que le dará al seguidor una utilidad de como máximo K−1 K K K−1 = 1 por jugar t1. Pero entonces, el conjunto de vértices v tales que sv se juega con una probabilidad de al menos 1/K debe constituir un conjunto independiente de tamaño K (porque si hubiera una arista e entre dos de estos vértices, induciría al seguidor a jugar t1 para el tipo θe según lo mencionado anteriormente). Por el contrario, si el seguidor tiene solo un tipo, entonces podemos generalizar el enfoque de programación lineal para juegos en forma normal: Teorema 8. En juegos bayesianos de 2 jugadores en los que el seguidor tiene solo un tipo, una estrategia mixta óptima a comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal. Prueba. Generalizamos el enfoque en el Teorema 2 de la siguiente manera. Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder para cada uno de los tipos de líderes de manera que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad esperada ex ante de los líderes. Para hacerlo, generalizamos el programa lineal de la siguiente manera: maximizar θl∈Θl π(θl) s∈S pθl s uθl l (s, t) sujeto a para todo t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t) para todo θl ∈ Θl, s∈S p θl s = 1 Como en el Teorema 2, la solución para el programa lineal que maximiza el valor de la solución es una estrategia óptima a comprometerse. Esto muestra un contraste interesante entre el compromiso con estrategias puras y el compromiso con estrategias mixtas en juegos bayesianos: para las estrategias puras, el problema se vuelve fácil si el líder tiene solo un tipo (pero no si el seguidor tiene solo un tipo), mientras que para las estrategias mixtas, el problema se vuelve fácil si el seguidor tiene solo un tipo (pero no si el líder tiene solo un tipo). 4. CONCLUSIONES E INVESTIGACIONES FUTURAS En los <br>sistemas multiagentes</br>, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias de forma simultánea. Esto requiere cierta noción de equilibrio (equilibrio de Nash y sus refinamientos), y a menudo conduce al problema de selección de equilibrio: no está claro para cada jugador individual según qué equilibrio debería jugar. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Por ejemplo, un agente puede llegar al sitio del juego (real o virtual) antes que el otro, o, en el caso específico de agentes de software, el código de un agente puede estar completo y comprometido antes que el de otro agente. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. Específicamente, si es posible el compromiso con estrategias mixtas, entonces el compromiso (óptimo) nunca perjudica al líder y a menudo lo beneficia. El reciente aumento del interés en las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas para comprometerse tanto a estrategias puras como a estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Para juegos en forma normal, demostramos que la estrategia pura óptima a comprometerse se puede encontrar eficientemente para cualquier número de jugadores. Una estrategia mixta óptima para comprometerse en un juego en forma normal puede encontrarse eficientemente para dos jugadores utilizando programación lineal (y no más eficientemente que eso, en el sentido de que cualquier programa lineal con una restricción de probabilidad puede ser codificado como tal problema). (Esta es una generalización de la computabilidad en tiempo polinómico de las estrategias minimax en juegos en forma normal). El problema se vuelve NP-duro para tres (o más) jugadores. En los juegos bayesianos, el problema de encontrar una estrategia pura óptima a la que comprometerse es NP-duro incluso en juegos de dos jugadores en los que el seguidor tiene solo un tipo, aunque los juegos de dos jugadores en los que el líder tiene solo un tipo pueden resolverse eficientemente. El problema de encontrar una estrategia mixta óptima a comprometerse en un juego bayesiano es NP-duro incluso en juegos de dos jugadores en los que el líder tiene solo un tipo, aunque los juegos de dos jugadores en los que el seguidor tiene solo un tipo pueden resolverse eficientemente utilizando una generalización del enfoque de programación lineal para juegos en forma normal. Las siguientes dos tablas resumen estos resultados. 2 jugadores ≥ 3 jugadores forma normal O(#resultados) O(#resultados· #jugadores) Bayesiano, O(#resultados· NP-completo 1-tipo líder #tipos) Bayesiano, NP-completo NP-completo 1-tipo seguidor Bayesiano (general) NP-completo NP-completo Resultados para el compromiso con estrategias puras. (Con más de 2 jugadores, el seguidor es el último jugador en comprometerse, el líder es el primero.) 88 2 jugadores ≥ 3 jugadores forma normal una resolución de LP por acción NP-completa del seguidor Bayesiano, NP-completo NP-completo 1-tipo líder Bayesiano, una resolución de LP por acción NP-completa del 1-tipo seguidor Bayesiano (general) NP-completo NP-completo Resultados para el compromiso con estrategias mixtas. (Con más de 2 jugadores, el seguidor es el último jugador en comprometerse, el líder es el primero.) La investigación futura puede tomar varias direcciones. Primero, podemos evaluar empíricamente las técnicas presentadas aquí en conjuntos de pruebas como GAMUT [19]. También podemos estudiar la computación de estrategias óptimas a comprometerse en otras representaciones concisas de juegos en forma normal, por ejemplo, en juegos gráficos [10] o juegos de grafo de efecto local/acción [14, 1]. Para los casos en los que calcular una estrategia óptima para comprometerse es NP-duro, también podemos estudiar la computación de estrategias aproximadamente óptimas para comprometerse. Si bien la definición correcta de una estrategia aproximadamente óptima en este contexto puede parecer simple al principio, debería ser una estrategia que, si los jugadores siguientes juegan de manera óptima, funcione casi tan bien como la estrategia óptima en promedio, esta definición se vuelve problemática cuando consideramos que los otros jugadores también podrían estar jugando solo de manera aproximadamente óptima. Uno también puede estudiar modelos en los que múltiples (pero no todos) jugadores se comprometen al mismo tiempo. Otra dirección interesante a explorar es ver si calcular estrategias mixtas óptimas a las que comprometerse puede ayudarnos, o de alguna manera arrojar luz sobre, el cálculo de equilibrios de Nash. A menudo, las estrategias mixtas óptimas a las que comprometerse también son estrategias de equilibrio de Nash (por ejemplo, en juegos de suma cero de dos jugadores esto siempre es cierto), aunque no siempre es el caso (por ejemplo, como ya señalamos, a veces la estrategia óptima a la que comprometerse es una estrategia estrictamente dominada, que nunca puede ser una estrategia de equilibrio de Nash). 5. REFERENCIAS [1] N. A. R. Bhat y K. Leyton-Brown. Calculando los equilibrios de Nash de juegos de gráficos de acción. En Actas de la 20ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI), Banff, Canadá, 2004. [2] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Actas de la Decimoctava Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 765-771, Acapulco, México, 2003. [3] V. Conitzer y T. Sandholm. Complejidad del dominio (iterado). En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 88-97, Vancouver, Canadá, 2005. [4] V. Conitzer y T. Sandholm. Un criterio de eliminabilidad de estrategias generalizado y métodos computacionales para aplicarlo. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 483-488, Pittsburgh, PA, EE. UU., 2005. [5] A. A. Cournot. Las investigaciones sobre los juegos bayesianos son una representación potencialmente concisa de los juegos en forma normal en los principios matemáticos de la teoría de la riqueza. Hachette, París, 1838. [6] G. Dantzig. Una prueba de la equivalencia del problema de programación y el problema de juego. En T. Koopmans, editor, Análisis de la actividad de producción y asignación, páginas 330-335. John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel. \n\nJohn Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, y E. Zemel. La complejidad de eliminar estrategias dominadas. Matemáticas de la Investigación de Operaciones, 18:553-565, 1993. [8] I. Gilboa y E. Zemel. Nash y equilibrios correlacionados: Algunas consideraciones de complejidad. Juegos y Comportamiento Económico, 1:80-93, 1989. [9] R. Karp. Reductibilidad entre problemas combinatorios. En R. E. Miller y J. W. Thatcher, editores, Complejidad de las Computaciones de Computadoras, páginas 85-103. Plenum Press, Nueva York, 1972. [10] M. Kearns, M. Littman y S. Singh. Modelos gráficos para teoría de juegos. En Actas de la Conferencia sobre Incertidumbre en Inteligencia Artificial (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou y J. N. Tsitsiklis. Una nota sobre la eliminación de estrategias en juegos bimatrix. Cartas de Investigación Operativa, 7(3):103-107, 1988. [12] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [14] K. Leyton-Brown y M. Tennenholtz. Juegos de efecto local. En Actas de la Decimoctava Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), Acapulco, México, 2003. [15] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 36-41, San Diego, CA, 2003. [16] M. Littman y P. Stone. Un algoritmo de equilibrio de Nash de tiempo polinómico para juegos repetidos. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 48-54, San Diego, CA, 2003. [17] R. D. Luce y H. Raiffa. Juegos y decisiones. John Wiley and Sons, Nueva York, 1957. Reedición de Dover 1989. [18] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown y Y. Shoham. Ejecutar el GAMUT: Un enfoque integral para evaluar algoritmos de teoría de juegos. En la Conferencia Internacional sobre Agentes Autónomos y Sistemas Multiagente (AAMAS), Nueva York, NY, EE. UU., 2004. [20] M. J. Osborne y A. Rubinstein. Un curso de teoría de juegos. MIT Press, 1994. [21] C. Papadimitriou. \n\nMIT Press, 1994. [21] C. Papadimitriou. Algoritmos, juegos e Internet. En Actas del Simposio Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. 89 [22] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 664-669, San José, CA, EE. UU., 2004. [23] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [24] J. von Neumann. A la teoría de los juegos sociales. Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg. \n\nMathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg. Forma de mercado y equilibrio. Springer, Viena, 1934. [26] B. von Stengel y S. Zamir. Liderazgo con compromiso hacia estrategias mixtas. Informe de investigación CDAM LSE-CDAM-2004-01, London School of Economics, febrero de 2004. 90 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "simultaneous manner": {
            "translated_key": "manera simultánea",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Computing the Optimal Strategy to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "We give both positive results (efficient algorithms) and negative results (NP-hardness results).",
                "Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent systems with self-interested agents (including most economic settings), the optimal action for one agent to take depends on the actions that the other agents take.",
                "To analyze how an agent should behave in such settings, the tools of game theory need to be applied.",
                "Typically, when a strategic setting is modeled in the framework of game theory, it is assumed that players choose their strategies simultaneously.",
                "This is especially true when the setting is modeled as a normal-form game, which only specifies each agents utility as a function of the vector of strategies that the agents choose, and does not provide any information on the order in which agents make their decisions and what the agents observe about earlier decisions by other agents.",
                "Given that the game is modeled in normal form, it is typically analyzed using the concept of Nash equilibrium.",
                "A Nash equilibrium specifies a strategy for each player, such that no player has an incentive to individually deviate from this profile of strategies. (Typically, the strategies are allowed to be mixed, that is, probability distributions over the original (pure) strategies.)",
                "A (mixed-strategy) Nash equilibrium is guaranteed to exist in finite games [18], but one problem is that there may be multiple Nash equilibria.",
                "This leads to the equilibrium selection problem of how an agent can know which strategy to play if it does not know which equilibrium is to be played.",
                "When the setting is modeled as an extensive-form game, it is possible to specify that some players receive some information about actions taken by others earlier in the game before deciding on their action.",
                "Nevertheless, in general, the players do not know everything that happened earlier in the game.",
                "Because of this, these games are typically still analyzed using an equilibrium concept, where one specifies a mixed strategy for each player, and requires that each players strategy is a best response to the others strategies. (Typically an additional constraint on the strategies is now imposed to ensure that players do not play in a way that is irrational with respect to the information that they have received so far.",
                "This leads to refinements of Nash equilibrium such as subgame perfect and sequential equilibrium.)",
                "However, in many real-world settings, strategies are not selected in such a <br>simultaneous manner</br>.",
                "Oftentimes, one player (the leader) is able to commit to a strategy before another player (the follower).",
                "This can be due to a variety of reasons.",
                "For example, one of the players may arrive at the site at which the game is to be played before another agent (e.g., in economic settings, one player may enter a market earlier and commit to a way of doing busi82 ness).",
                "Such commitment power has a profound impact on how the game should be played.",
                "For example, the leader may be best off playing a strategy that is dominated in the normal-form representation of the game.",
                "Perhaps the earliest and best-known example of the effect of commitment is that by von Stackelberg [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution.",
                "In general, if commitment to mixed strategies is possible, then (under minor assumptions) it never hurts, and often helps, to commit to a strategy [26].",
                "Being forced to commit to a pure strategy sometimes helps, and sometimes hurts (for example, committing to a pure strategy in rock-paper-scissors before the other players decision will naturally result in a loss).",
                "In this paper, we will assume commitment is always forced; if it is not, the player who has the choice of whether to commit can simply compare the commitment outcome to the non-commitment (simultaneous-move) outcome.",
                "Models of leadership are especially important in settings with multiple self-interested software agents.",
                "Once the code for an agent (or for a team of agents) is finalized and the agent is deployed, the agent is committed to playing the (possibly randomized) strategy that the code prescribes.",
                "Thus, as long as one can credibly show that one cannot change the code later, the code serves as a commitment device.",
                "This holds true for recreational tournaments among agents (e.g., poker tournaments, RoboSoccer), and for industrial applications such as sensor webs.",
                "Finally, there is also an implicit leadership situation in the field of mechanism design, in which one player (the designer) gets to choose the rules of the game that the remaining players then play.",
                "Mechanism design is an extremely important topic to the EC community: the papers published on mechanism design in recent EC conferences are too numerous to cite.",
                "Indeed, the mechanism designer may benefit from committing to a choice that, if the (remaining) agents actions were fixed, would be suboptimal.",
                "For example, in a (first-price) auction, the seller may wish to set a positive (artificial) reserve price for the item, below which the item will not be sold-even if the seller values the item at 0.",
                "In hindsight (after the bids have come in), this (na¨ıvely) appears suboptimal: if a bid exceeding the reserve price came in, the reserve price had no effect, and if no such bid came in, the seller would have been better off accepting a lower bid.",
                "Of course, the reason for setting the reserve price is that it incentivizes the bidders to bid higher, and because of this, setting artificial reserve prices can actually increase expected revenue to the seller.",
                "A significant amount of research has recently been devoted to the computation of solutions according to various solution concepts for settings in which the agents choose their strategies simultaneously, such as dominance [7, 11, 3] and (especially) Nash equilibrium [8, 21, 16, 15, 2, 22, 23, 4].",
                "However, the computation of the optimal strategy to commit to in a leadership situation has gone ignored.",
                "Theoretically, leadership situations can simply be thought of as an extensive-form game in which one player chooses a strategy (for the original game) first.",
                "The number of strategies in this extensive-form game, however, can be exceedingly large.",
                "For example, if the leader is able to commit to a mixed strategy in the original game, then every one of the (continuum of) mixed strategies constitutes a pure strategy in the extensive-form representation of the leadership situation. (We note that a commitment to a distribution is not the same as a distribution over commitments.)",
                "Moreover, if the original game is itself an extensive-form game, the number of strategies in the extensive-form representation of the leadership situation (which is a different extensive-form game) becomes even larger.",
                "Because of this, it is usually not computationally feasible to simply transform the original game into the extensive-form representation of the leadership situation; instead, we have to analyze the game in its original representation.",
                "In this paper, we study how to compute the optimal strategy to commit to, both in normal-form games (Section 2) and in Bayesian games, which are a special case of extensiveform games (Section 3). 2.",
                "NORMAL-FORM GAMES In this section, we study how to compute the optimal strategy to commit to for games represented in normal form. 2.1 Definitions In a normal-form game, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a pure strategy for every player, also known as a profile of pure strategies) to a real number.",
                "To ease notation, in the case of two players, we will refer to player 1s pure strategy set as S, and player 2s pure strategy set as T. Such games can be represented in (bi-)matrix form, in which the rows correspond to player 1s pure strategies, the columns correspond to player 2s pure strategies, and the entries of the matrix give the row and column players utilities (in that order) for the corresponding outcome of the game.",
                "In the case of three players, we will use R, S, and T, for player 1, 2, and 3s pure strategies, respectively.",
                "A mixed strategy for a player is a probability distribution over that players pure strategies.",
                "In the case of two-player games, we will refer to player 1 as the leader and player 2 as the follower.",
                "Before defining optimal leadership strategies, consider the following game which illustrates the effect of the leaders ability to commit. 2, 1 4, 0 1, 0 3, 1 In this normal-form representation, the bottom strategy for the row player is strictly dominated by the top strategy.",
                "Nevertheless, if the row player has the ability to commit to a pure strategy before the column player chooses his strategy, the row player should commit to the bottom strategy: doing so will make the column player prefer to play the right strategy, leading to a utility of 3 for the row player.",
                "By contrast, if the row player were to commit to the top strategy, the column player would prefer to play the left strategy, leading to a utility of only 2 for the row player.",
                "If the row player is able to commit to a mixed strategy, then she can get an even greater (expected) utility: if the row player commits to placing probability p > 1/2 on the bottom strategy, then the column player will still prefer to play the right strategy, and the row players expected utility will be 3p + 4(1 − p) = 4 − p ≥ 3.",
                "If the row player plays each strategy with probability exactly 1/2, the column player is 83 indifferent between the strategies.",
                "In such cases, we will assume that the column player will choose the strategy that maximizes the row players utility (in this case, the right strategy).",
                "Hence, the optimal mixed strategy to commit to for the row player is p = 1/2.",
                "There are a few good reasons for this assumption.",
                "If we were to assume the opposite, then there would not exist an optimal strategy for the row player in the example game: the row player would play the bottom strategy with probability p = 1/2 + with > 0, and the smaller , the better the utility for the row player.",
                "By contrast, if we assume that the follower always breaks ties in the leaders favor, then an optimal mixed strategy for the leader always exists, and this corresponds to a subgame perfect equilibrium of the extensive-form representation of the leadership situation.",
                "In any case, this is a standard assumption for such models (e.g. [20]), although some work has investigated what can happen in the other subgame perfect equilibria [26]. (For generic two-player games, the leaders subgame-perfect equilibrium payoff is unique.)",
                "Also, the same assumption is typically used in mechanism design, in that it is assumed that if an agent is indifferent between revealing his preferences truthfully and revealing them falsely, he will report them truthfully.",
                "Given this assumption, we can safely refer to optimal leadership strategies rather than having to use some equilibrium notion.",
                "Hence, for the purposes of this paper, an optimal strategy to commit to in a 2-player game is a strategy s ∈ S that maximizes maxt∈BR(s) ul(s, t), where BR(s) = arg maxt∈T uf (s, t). (ul and uf are the leader and followers utility functions, respectively.)",
                "We can have S = S for the case of commitment to pure strategies, or S = ∆(S), the set of probability distributions over S, for the case of commitment to mixed strategies. (We note that replacing T by ∆(T) makes no difference in this definition.)",
                "For games with more than two players, in which the players commit to their strategies in sequence, we define optimal strategies to commit to recursively.",
                "After the leader commits to a strategy, the game to be played by the remaining agents is itself a (smaller) leadership game.",
                "Thus, we define an optimal strategy to commit to as a strategy that maximizes the leaders utility, assuming that the play of the remaining agents is itself optimal under this definition, and maximizes the leaders utility among all optimal ways to play the remaining game.",
                "Again, commitment to mixed strategies may or may not be a possibility for every player (although for the last player it does not matter if we allow for commitment to mixed strategies). 2.2 Commitment to pure strategies We first study how to compute the optimal pure strategy to commit to.",
                "This is relatively simple, because the number of strategies to commit to is not very large. (In the following, #outcomes is the number of complete strategy profiles.)",
                "Theorem 1.",
                "Under commitment to pure strategies, the set of all optimal strategy profiles in a normal-form game can be found in O(#players · #outcomes) time.",
                "Proof.",
                "Each pure strategy that the first player may commit to will induce a subgame for the remaining players.",
                "We can solve each such subgame recursively to find all of its optimal strategy profiles; each of these will give the original leader some utility.",
                "Those that give the leader maximal utility correspond exactly to the optimal strategy profiles of the original game.",
                "We now present the algorithm formally.",
                "Let Su(G, s1) be the subgame that results after the first (remaining) player in G plays s1 ∈ SG 1 .",
                "A game with 0 players is simply an outcome of the game.",
                "The function Append(s, O) appends the strategy s to each of the vectors of strategies in the set O.",
                "Let e be the empty vector with no elements.",
                "In a slight abuse of notation, we will write uG 1 (C) when all strategy profiles in the set C give player 1 the same utility in the game G. (Here, player 1 is the first remaining player in the subgame G, not necessarily player 1 in the original game.)",
                "We note that arg max is set-valued.",
                "Then, the following algorithm computes all optimal strategy profiles: Algorithm Solve(G) if G has 0 players return {e} C ← ∅ for all s1 ∈ SG 1 { O ← Solve(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) if C = ∅ or uG 1 (s1, O ) = uG 1 (C) C ← C∪Append(s1, O ) if uG 1 (s1, O ) > uG 1 (C) C ←Append(s1, O ) } return C Every outcome is (potentially) examined by every player, which leads to the given runtime bound.",
                "As an example of how the algorithm works, consider the following 3-player game, in which the first player chooses the left or right matrix, the second player chooses a row, and the third player chooses a column. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 3,0,0 First we eliminate the outcomes that do not correspond to best responses for the third player (removing them from the matrix): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Next, we remove the entries in which the third player does not break ties in favor of the second player, as well as entries that do not correspond to best responses for the second player. 0,1,1 2,1,1 1,1,1 0,5,1 Finally, we remove the entries in which the second and third players do not break ties in favor of the first player, as well as entries that do not correspond to best responses for the first player. 2,1,1 84 Hence, in optimal play, the first player chooses the left matrix, the second player chooses the middle row, and the third player chooses the left column. (We note that this outcome is Pareto-dominated by (Right, Middle, Left).)",
                "For general normal-form games, each players utility for each of the outcomes has to be explicitly represented in the input, so that the input size is itself Ω(#players · #outcomes).",
                "Therefore, the algorithm is in fact a linear-time algorithm. 2.3 Commitment to mixed strategies In the special case of two-player zero-sum games, computing an optimal mixed strategy for the leader to commit to is equivalent to computing a minimax strategy, which minimizes the maximum expected utility that the opponent can obtain.",
                "Minimax strategies constitute the only natural solution concept for two-player zero-sum games: von Neumanns Minimax Theorem [24] states that in two-player zero-sum games, it does not matter (in terms of the players utilities) which player gets to commit to a mixed strategy first, and a profile of mixed strategies is a Nash equilibrium if and only if both strategies are minimax strategies.",
                "It is well-known that a minimax strategy can be found in polynomial time, using linear programming [17].",
                "Our first result in this section generalizes this result, showing that an optimal mixed strategy for the leader to commit to can be efficiently computed in general-sum two-player games, again using linear programming.",
                "Theorem 2.",
                "In 2-player normal-form games, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders utility.",
                "Such a mixed strategy can be computed using the following simple linear program: maximize s∈S psul(s, t) subject to for all t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1 We note that this program may be infeasible for some follower strategies t, for example, if t is a strictly dominated strategy.",
                "Nevertheless, the program must be feasible for at least some follower strategies; among these follower strategies, choose a strategy t∗ that maximizes the linear programs solution value.",
                "Then, if the leader chooses as her mixed strategy the optimal settings of the variables ps for the linear program for t∗ , and the follower plays t∗ , this constitutes an optimal strategy profile.",
                "In the following result, we show that we cannot expect to solve the problem more efficiently than linear programming, because we can reduce any linear program with a probability constraint on its variables to a problem of computing the optimal mixed strategy to commit to in a 2-player normalform game.",
                "Theorem 3.",
                "Any linear program whose variables xi (with xi ∈ R≥0 ) must satsify i xi = 1 can be modeled as a problem of computing the optimal mixed strategy to commit to in a 2-player normal-form game.",
                "Proof.",
                "Let the leader have a pure strategy i for every variable xi.",
                "Let the column player have one pure strategy j for every constraint in the linear program (other than i xi = 1), and a single additional pure strategy 0.",
                "Let the utility functions be as follows.",
                "Writing the objective of the linear program as maximize i cixi, for any i, let ul(i, 0) = ci and uf (i, 0) = 0.",
                "Writing the jth constraint of the linear program (not including i xi = 1) as i aijxi ≤ bj, for any i, j > 0, let ul(i, j) = mini ci − 1 and uf (i, j) = aij − bj.",
                "For example, consider the following linear program. maximize 2x1 + x2 subject to x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 The optimal solution to this program is x1 = 1/3, x2 = 2/3.",
                "Our reduction transforms this program into the following leader-follower game (where the leader is the row player). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 Indeed, the optimal strategy for the leader is to play the top strategy with probability 1/3 and the bottom strategy with probability 2/3.",
                "We now show that the reduction works in general.",
                "Clearly, the leader wants to incentivize the follower to play 0, because the utility that the leader gets when the follower plays 0 is always greater than when the follower does not play 0.",
                "In order for the follower not to prefer playing j > 0 rather than 0, it must be the case that i pl(i)(aij − bj) ≤ 0, or equivalently i pl(i)aij ≤ bj.",
                "Hence the leader will get a utility of at least mini ci if and only if there is a feasible solution to the constraints.",
                "Given that the pl(i) incentivize the follower to play 0, the leader attempts to maximize i pl(i)ci.",
                "Thus the leader must solve the original linear program.",
                "As an alternative proof of Theorem 3, one may observe that it is known that finding a minimax strategy in a zerosum game is as hard as the linear programming problem [6], and as we pointed out at the beginning of this section, computing a minimax strategy in a zero-sum game is a special case of the problem of computing an optimal mixed strategy to commit to.",
                "This polynomial-time solvability of the problem of computing an optimal mixed strategy to commit to in two-player normal-form games contrasts with the unknown complexity of computing a Nash equilibrium in such games [21], as well as with the NP-hardness of finding a Nash equilibrium with maximum utility for a given player in such games [8, 2].",
                "Unfortunately, this result does not generalize to more than two players-here, the problem becomes NP-hard.",
                "To show this, we reduce from the VERTEX-COVER problem.",
                "Definition 1.",
                "In VERTEX-COVER, we are given a graph G = (V, E) and an integer K. We are asked whether there 85 exists a subset of the vertices S ⊆ V , with |S| = K, such that every edge e ∈ E has at least one of its endpoints in S. BALANCED-VERTEX-COVER is the special case of VERTEX-COVER in which K = |V |/2.",
                "VERTEX-COVER is NP-complete [9].",
                "The following lemma shows that the hardness remains if we require K = |V |/2. (Similar results have been shown for other NP-complete problems.)",
                "Lemma 1.",
                "BALANCED-VERTEX-COVER is NP-complete.",
                "Proof.",
                "Membership in NP follows from the fact that the problem is a special case of VERTEX-COVER, which is in NP.",
                "To show NP-hardness, we reduce an arbitrary VERTEX-COVER instance to a BALANCED-VERTEXCOVER instance, as follows.",
                "If, for the VERTEX-COVER instance, K > |V |/2, then we simply add isolated vertices that are disjoint from the rest of the graph, until K = |V |/2.",
                "If K < |V |/2, we add isolated triangles (that is, the complete graph on three vertices) to the graph, increasing K by 2 every time, until K = |V |/2.",
                "Theorem 4.",
                "In 3-player normal-form games, finding an optimal mixed strategy to commit to is NP-hard.",
                "Proof.",
                "We reduce an arbitrary BALANCED-VERTEXCOVER instance to the following 3-player normal-form game.",
                "For every vertex v, each of the three players has a pure strategy corresponding to that vertex (rv, sv, tv, respectively).",
                "In addition, for every edge e, the third player has a pure strategy te; and finally, the third player has one additional pure strategy t0.",
                "The utilities are as follows: • for all r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • for all r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • for all v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • for all v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • for all v ∈ V , for all r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V | |V |−2 ; • for all e ∈ E, s ∈ S, for both v ∈ e, u3(rv, s, te) = 0; • for all e ∈ E, s ∈ S, for all v /∈ e, u3(rv, s, te) = |V | |V |−2 . • for all r ∈ R, s ∈ S, u3(r, s, t0) = 1.",
                "We note that players 1 and 2 have the same utility function.",
                "We claim that there is an optimal strategy profile in which players 1 and 2 both obtain 1 (their maximum utility) if and only if there is a solution to the BALANCED-VERTEXCOVER problem. (Otherwise, these players will both obtain 0.)",
                "First, suppose there exists a solution to the BALANCEDVERTEX-COVER problem.",
                "Then, let player 1 play every rv such that v is in the cover with probability 2 |V | , and let player 2 play every sv such that v is not in the cover with probability 2 |V | .",
                "Then, for player 3, the expected utility of playing tv (for any v) is (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of 2 |V | that rv or sv is played.",
                "Additionally, the expected utility of playing te (for any e) is at most (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of at least 2 |V | that some rv with v ∈ e is played (because player 1 is randomizing over the pure strategies corresponding to the cover).",
                "It follows that playing t0 is a best response for player 3, giving players 1 and 2 a utility of 1.",
                "Now, suppose that players 1 and 2 obtain 1 in optimal play.",
                "Then, it must be the case that player 3 plays t0.",
                "Hence, for every v ∈ V , there must be a probability of at least 2 |V | that either rv or sv is played, for otherwise player 3 would be better off playing tv.",
                "Because players 1 and 2 have only a total probability of 2 to distribute, it must be the case that for each v, either rv or sv is played with probability 2 |V | , and the other is played with probability 0. (It is not possible for both to have nonzero probability, because then there would be some probability that both are played simultaneously (correlation is not possible), hence the total probability of at least one being played could not be high enough for all vertices.)",
                "Thus, for exactly half the v ∈ V , player 1 places probability 2 |V | on rv.",
                "Moreover, for every e ∈ E, there must be a probability of at least 2 |V | that some rv with v ∈ e is played, for otherwise player 3 would be better off playing te.",
                "Thus, the v ∈ V such that player 1 places probability 2 |V | on rv constitute a balanced vertex cover. 3.",
                "BAYESIAN GAMES So far, we have restricted our attention to normal-form games.",
                "In a normal-form game, it is assumed that every agent knows every other agents preferences over the outcomes of the game.",
                "In general, however, agents may have some private information about their preferences that is not known to the other agents.",
                "Moreover, at the time of commitment to a strategy, the agents may not even know their own (final) preferences over the outcomes of the game yet, because these preferences may be dependent on a context that has yet to materialize.",
                "For example, when the code for a trading agent is written, it may not yet be clear how that agent will value resources that it will negotiate over later, because this depends on information that is not yet available at the time at which the code is written (such as orders that will have been placed to the agent before the negotiation).",
                "In this section, we will study commitment in Bayesian games, which can model such uncertainty over preferences. 3.1 Definitions In a Bayesian game, every player i has a set of actions Si, a set of types Θi with an associated probability distribution πi : Θi → [0, 1], and, for each type θi, a utility function uθi i : S1 × S2 × . . . × Sn → R. A pure strategy in a Bayesian game is a mapping from the players types to actions, σi : Θi → Si. (Bayesian games can be rewritten in normal form by enumerating every pure strategy σi, but this will cause an exponential blowup in the size of the representation of the game and therefore cannot lead to efficient algorithms.)",
                "The strategy that the leader should commit to depends on whether, at the time of commitment, the leader knows her own type.",
                "If the leader does know her own type, the other types that the leader might have had become irrelevant and the leader should simply commit to the strategy that is optimal for the type.",
                "However, as argued above, the leader does not necessarily know her own type at the time of commitment (e.g., the time at which the code is submitted).",
                "In this case, the leader must commit to a strategy that is 86 dependent upon the leaders eventual type.",
                "We will study this latter model, although we will pay specific attention to the case where the leader has only a single type, which is effectively the same as the former model. 3.2 Commitment to pure strategies It turns out that computing an optimal pure strategy to commit to is hard in Bayesian games, even with two players.",
                "Theorem 5.",
                "Finding an optimal pure strategy to commit to in 2-player Bayesian games is NP-hard, even when the follower has only a single type.",
                "Proof.",
                "We reduce an arbitrary VERTEX-COVER instance to the following Bayesian game between the leader and the follower.",
                "The leader has K types θ1, θ2, . . . , θK , each occurring with probability 1/K, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has only a single type; for each edge e ∈ E, the follower has an action te, and the follower has a single additional action t0.",
                "The utility function for the leader is given by, for all θl ∈ Θl and all s ∈ S, u θl l (s, t0) = 1, and for all e ∈ E, u θl l (s, te) = 0.",
                "The followers utility is given by: • For all v ∈ V , for all e ∈ E with v /∈ e, uf (sv, te) = 1; • For all v ∈ V , for all e ∈ E with v ∈ e, uf (sv, te) = −K; • For all v ∈ V , uf (sv, t0) = 0.",
                "We claim that the leader can get a utility of 1 if and only if there is a solution to the VERTEX-COVER instance.",
                "First, suppose that there is a solution to the VERTEXCOVER instance.",
                "Then, the leader can commit to a pure strategy such that for each vertex v in the cover, the leader plays sv for some type.",
                "Then, the followers utility for playing te (for any e ∈ E) is at most K−1 K + 1 K (−K) = − 1 K , so that the follower will prefer to play t0, which gives the leader a utility of 1, as required.",
                "Now, suppose that there is a pure strategy for the leader that will give the leader a utility of 1.",
                "Then, the follower must play t0.",
                "In order for the follower not to prefer playing te (for any e ∈ E) instead, for at least one v ∈ e the leader must play sv for some type θl.",
                "Hence, the set of vertices v that the leader plays for some type must constitute a vertex cover; and this set can have size at most K, because the leader has only K types.",
                "So there is a solution to the VERTEXCOVER instance.",
                "However, if the leader has only a single type, then the problem becomes easy again (#types is the number of types for the follower): Theorem 6.",
                "In 2-player Bayesian games in which the leader has only a single type, an optimal pure strategy to commit to can be found in O(#outcomes · #types) time.",
                "Proof.",
                "For every leader action s, we can compute, for every follower type θf ∈ Θf , which actions t maximize the followers utility; call this set of actions BRθf (s).",
                "Then, the utility that the leader receives for committing to action s can be computed as θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), and the leader can choose the best action to commit to. 3.3 Commitment to mixed strategies In two-player zero-sum imperfect information games with perfect recall (no player ever forgets something that it once knew), a minimax strategy can be constructed in polynomial time [12, 13].",
                "Unfortunately, this result does not extend to computing optimal mixed strategies to commit to in the general-sum case-not even in Bayesian games.",
                "We will exhibit NP-hardness by reducing from the INDEPENDENTSET problem.",
                "Definition 2.",
                "In INDEPENDENT-SET, we are given a graph G = (V, E) and an integer K. We are asked whether there exists a subset of the vertices S ⊆ V , with |S| = K, such that no edge e ∈ E has both of its endpoints in S. Again, this problem is NP-complete [9].",
                "Theorem 7.",
                "Finding an optimal mixed strategy to commit to in 2-player Bayesian games is NP-hard, even when the leader has only a single type and the follower has only two actions.",
                "Proof.",
                "We reduce an arbitrary INDEPENDENT-SET instance to the following Bayesian game between the leader and the follower.",
                "The leader has only a single type, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has a type θv for every v ∈ V , occurring with probability 1 (|E|+1)|V | , and a type θe for every e ∈ E, occurring with probability 1 |E|+1 .",
                "The follower has two actions: t0 and t1.",
                "The leaders utility is given by, for all s ∈ S, ul(s, t0) = 1 and ul(s, t1) = 0.",
                "The followers utility is given by: • For all v ∈ V , uθv f (sv, t1) = 0; • For all v ∈ V and s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • For all v ∈ V and s ∈ S, uθv f (s, t0) = 1; • For all e ∈ E, s ∈ S, uθe f (s, t0) = 1; • For all e ∈ E, for both v ∈ e, uθe f (sv, t1) = 2K 3 ; • For all e ∈ E, for all v /∈ e, uθe f (sv, t1) = 0.",
                "We claim that an optimal strategy to commit to gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | if and only if there is a solution to the INDEPENDENT-SET instance.",
                "First, suppose that there is a solution to the INDEPENDENT-SET instance.",
                "Then, the leader could commit to the following strategy: for every vertex v in the independent set, play the corresponding sv with probability 1/K.",
                "If the follower has type θe for some e ∈ E, the expected utility for the follower of playing t1 is at most 1 K 2K 3 = 2/3, because there is at most one vertex v ∈ e such that sv is played with nonzero probability.",
                "Hence, the follower will play t0 and obtain a utility of 1.",
                "If the follower has type θv for some vertex v in the independent set, the expected utility for the follower of playing t1 is K−1 K K K−1 = 1, because the leader plays sv with probability 1/K.",
                "It follows that the follower (who breaks ties to maximize the leaders utility) will play t0, which also gives a utility of 1 and gives the leader a higher utility.",
                "Hence the leaders expected utility for this strategy is at least |E| |E|+1 + K (|E|+1)|V | , as required. 87 Now, suppose that there is a strategy that gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | .",
                "Then, this strategy must induce the follower to play t0 whenever it has a type of the form θe (because otherwise, the utility could be at most |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ).",
                "Thus, it cannot be the case that for some edge e = (v1, v2) ∈ E, the probability that the leader plays one of sv1 and sv2 is at least 2/K, because then the expected utility for the follower of playing t1 when it has type θe would be at least 2 K 2K 3 = 4/3 > 1.",
                "Moreover, the strategy must induce the follower to play t0 for at least K types of the form θv.",
                "Inducing the follower to play t0 when it has type θv can be done only by playing sv with probability at least 1/K, which will give the follower a utility of at most K−1 K K K−1 = 1 for playing t1.",
                "But then, the set of vertices v such that sv is played with probability at least 1/K must constitute an independent set of size K (because if there were an edge e between two such vertices, it would induce the follower to play t1 for type θe by the above).",
                "By contrast, if the follower has only a single type, then we can generalize the linear programming approach for normalform games: Theorem 8.",
                "In 2-player Bayesian games in which the follower has only a single type, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "We generalize the approach in Theorem 2 as follows.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader for every one of the leaders types such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders ex ante expected utility.",
                "To do so, we generalize the linear program as follows: maximize θl∈Θl π(θl) s∈S pθl s uθl l (s, t) subject to for all t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t ) for all θl ∈ Θl, s∈S p θl s = 1 As in Theorem 2, the solution for the linear program that maximizes the solution value is an optimal strategy to commit to.",
                "This shows an interesting contrast between commitment to pure strategies and commitment to mixed strategies in Bayesian games: for pure strategies, the problem becomes easy if the leader has only a single type (but not if the follower has only a single type), whereas for mixed strategies, the problem becomes easy if the follower has only a single type (but not if the leader has only a single type). 4.",
                "CONCLUSIONS AND FUTURE RESEARCH In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "This requires some equilibrium notion (Nash equilibrium and its refinements), and often leads to the equilibrium selection problem: it is unclear to each individual player according to which equilibrium she should play.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "For example, one agent may arrive at the (real or virtual) site of the game before the other, or, in the specific case of software agents, the code for one agent may be completed and committed before that of another agent.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "Specifically, if commitment to mixed strategies is possible, then (optimal) commitment never hurts the leader, and often helps.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we studied how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "For normal-form games, we showed that the optimal pure strategy to commit to can be found efficiently for any number of players.",
                "An optimal mixed strategy to commit to in a normal-form game can be found efficiently for two players using linear programming (and no more efficiently than that, in the sense that any linear program with a probability constraint can be encoded as such a problem). (This is a generalization of the polynomial-time computability of minimax strategies in normal-form games.)",
                "The problem becomes NP-hard for three (or more) players.",
                "In Bayesian games, the problem of finding an optimal pure strategy to commit to is NP-hard even in two-player games in which the follower has only a single type, although two-player games in which the leader has only a single type can be solved efficiently.",
                "The problem of finding an optimal mixed strategy to commit to in a Bayesian game is NP-hard even in two-player games in which the leader has only a single type, although two-player games in which the follower has only a single type can be solved efficiently using a generalization of the linear progamming approach for normal-form games.",
                "The following two tables summarize these results. 2 players ≥ 3 players normal-form O(#outcomes) O(#outcomes· #players) Bayesian, O(#outcomes· NP-hard 1-type leader #types) Bayesian, NP-hard NP-hard 1-type follower Bayesian (general) NP-hard NP-hard Results for commitment to pure strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.) 88 2 players ≥ 3 players normal-form one LP-solve per NP-hard follower action Bayesian, NP-hard NP-hard 1-type leader Bayesian, one LP-solve per NP-hard 1-type follower follower action Bayesian (general) NP-hard NP-hard Results for commitment to mixed strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.)",
                "Future research can take a number of directions.",
                "First, we can empirically evaluate the techniques presented here on test suites such as GAMUT [19].",
                "We can also study the computation of optimal strategies to commit to in other1 concise representations of normal-form games-for example, in graphical games [10] or local-effect/action graph games [14, 1].",
                "For the cases where computing an optimal strategy to commit to is NP-hard, we can also study the computation of approximately optimal strategies to commit to.",
                "While the correct definition of an approximately optimal strategy is in this setting may appear simple at first-it should be a strategy that, if the following players play optimally, performs almost as well as the optimal strategy in expectation-this definition becomes problematic when we consider that the other players may also be playing only approximately optimally.",
                "One may also study models in which multiple (but not all) players commit at the same time.",
                "Another interesting direction to pursue is to see if computing optimal mixed strategies to commit to can help us in, or otherwise shed light on, computing Nash equilibria.",
                "Often, optimal mixed strategies to commit to are also Nash equilibrium strategies (for example, in two-player zero-sum games this is always true), although this is not always the case (for example, as we already pointed out, sometimes the optimal strategy to commit to is a strictly dominated strategy, which can never be a Nash equilibrium strategy). 5.",
                "REFERENCES [1] N. A. R. Bhat and K. Leyton-Brown.",
                "Computing Nash equilibria of action-graph games.",
                "In Proceedings of the 20th Annual Conference on Uncertainty in Artificial Intelligence (UAI), Banff, Canada, 2004. [2] V. Conitzer and T. Sandholm.",
                "Complexity results about Nash equilibria.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pages 765-771, Acapulco, Mexico, 2003. [3] V. Conitzer and T. Sandholm.",
                "Complexity of (iterated) dominance.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 88-97, Vancouver, Canada, 2005. [4] V. Conitzer and T. Sandholm.",
                "A generalized strategy eliminability criterion and computational methods for applying it.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 483-488, Pittsburgh, PA, USA, 2005. [5] A.",
                "A. Cournot.",
                "Recherches sur les principes math´ematiques de la th´eorie des richesses (Researches 1 Bayesian games are one potentially concise representation of normal-form games. into the Mathematical Principles of the Theory of Wealth).",
                "Hachette, Paris, 1838. [6] G. Dantzig.",
                "A proof of the equivalence of the programming problem and the game problem.",
                "In T. Koopmans, editor, Activity Analysis of Production and Allocation, pages 330-335.",
                "John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel.",
                "The complexity of eliminating dominated strategies.",
                "Mathematics of Operation Research, 18:553-565, 1993. [8] I. Gilboa and E. Zemel.",
                "Nash and correlated equilibria: Some complexity considerations.",
                "Games and Economic Behavior, 1:80-93, 1989. [9] R. Karp.",
                "Reducibility among combinatorial problems.",
                "In R. E. Miller and J. W. Thatcher, editors, Complexity of Computer Computations, pages 85-103.",
                "Plenum Press, NY, 1972. [10] M. Kearns, M. Littman, and S. Singh.",
                "Graphical models for game theory.",
                "In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou, and J. N. Tsitsiklis.",
                "A note on strategy elimination in bimatrix games.",
                "Operations Research Letters, 7(3):103-107, 1988. [12] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [14] K. Leyton-Brown and M. Tennenholtz.",
                "Local-effect games.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), Acapulco, Mexico, 2003. [15] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 36-41, San Diego, CA, 2003. [16] M. Littman and P. Stone.",
                "A polynomial-time Nash equilibrium algorithm for repeated games.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 48-54, San Diego, CA, 2003. [17] R. D. Luce and H. Raiffa.",
                "Games and Decisions.",
                "John Wiley and Sons, New York, 1957.",
                "Dover republication 1989. [18] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown, and Y. Shoham.",
                "Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms.",
                "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), New York, NY, USA, 2004. [20] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "MIT Press, 1994. [21] C. Papadimitriou.",
                "Algorithms, games and the Internet.",
                "In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 749-753, 2001. 89 [22] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 664-669, San Jose, CA, USA, 2004. [23] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 495-501, Pittsburgh, PA, USA, 2005. [24] J. von Neumann.",
                "Zur Theorie der Gesellschaftsspiele.",
                "Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg.",
                "Marktform und Gleichgewicht.",
                "Springer, Vienna, 1934. [26] B. von Stengel and S. Zamir.",
                "Leadership with commitment to mixed strategies.",
                "CDAM Research Report LSE-CDAM-2004-01, London School of Economics, Feb. 2004. 90"
            ],
            "original_annotated_samples": [
                "However, in many real-world settings, strategies are not selected in such a <br>simultaneous manner</br>."
            ],
            "translated_annotated_samples": [
                "Sin embargo, en muchos entornos del mundo real, las estrategias no se seleccionan de <br>manera simultánea</br>."
            ],
            "translated_text": "En sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias simultáneamente. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. El reciente aumento en el interés por las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas a comprometerse tanto en el compromiso de estrategias puras como en el compromiso de estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Ofrecemos tanto resultados positivos (algoritmos eficientes) como resultados negativos (resultados de NP-hardness). Categorías y Descriptores de Asignaturas J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas Términos Generales Algoritmos, Economía, Teoría 1. En sistemas multiagentes con agentes auto-interesados (incluyendo la mayoría de los entornos económicos), la acción óptima que un agente debe tomar depende de las acciones que tomen los otros agentes. Para analizar cómo un agente debería comportarse en tales situaciones, es necesario aplicar las herramientas de la teoría de juegos. Normalmente, cuando se modela un escenario estratégico en el marco de la teoría de juegos, se asume que los jugadores eligen sus estrategias de forma simultánea. Esto es especialmente cierto cuando el escenario se modela como un juego en forma normal, que solo especifica la utilidad de cada agente como una función del vector de estrategias que los agentes eligen, y no proporciona información sobre el orden en que los agentes toman sus decisiones y lo que los agentes observan sobre las decisiones anteriores de otros agentes. Dado que el juego está modelado en forma normal, típicamente se analiza utilizando el concepto de equilibrio de Nash. Un equilibrio de Nash especifica una estrategia para cada jugador, de modo que ningún jugador tenga un incentivo para desviarse individualmente de este perfil de estrategias. (Por lo general, se permite que las estrategias sean mixtas, es decir, distribuciones de probabilidad sobre las estrategias originales (puras).) Un equilibrio de Nash (de estrategia mixta) está garantizado de existir en juegos finitos [18], pero un problema es que puede haber múltiples equilibrios de Nash. Esto conduce al problema de selección de equilibrio de cómo un agente puede saber qué estrategia jugar si no sabe qué equilibrio se va a jugar. Cuando el escenario se modela como un juego de forma extensiva, es posible especificar que algunos jugadores reciben información sobre las acciones tomadas por otros antes en el juego antes de decidir su acción. Sin embargo, en general, los jugadores no saben todo lo que sucedió anteriormente en el juego. Por lo tanto, estos juegos suelen ser analizados todavía utilizando un concepto de equilibrio, donde se especifica una estrategia mixta para cada jugador, y se requiere que la estrategia de cada jugador sea una mejor respuesta a las estrategias de los demás. (Normalmente se impone ahora una restricción adicional en las estrategias para garantizar que los jugadores no jueguen de una manera irracional con respecto a la información que han recibido hasta el momento). Esto conduce a refinamientos del equilibrio de Nash como el equilibrio perfecto en subjuegos y el equilibrio secuencial. Sin embargo, en muchos entornos del mundo real, las estrategias no se seleccionan de <br>manera simultánea</br>. A menudo, un jugador (el líder) puede comprometerse con una estrategia antes que otro jugador (el seguidor). Esto puede deberse a una variedad de razones. Por ejemplo, uno de los jugadores puede llegar al lugar donde se jugará el juego antes que otro agente (por ejemplo, en entornos económicos, un jugador puede ingresar al mercado antes y comprometerse con una forma de hacer negocios). Un compromiso tan poderoso tiene un impacto profundo en cómo debería jugarse el juego. Por ejemplo, el líder puede estar mejor jugando una estrategia que esté dominada en la representación de forma normal del juego. Quizás el ejemplo más temprano y conocido del efecto del compromiso es el de von Stackelberg [25], quien demostró que, en el modelo de duopolio de Cournot [5], si una empresa puede comprometerse con una cantidad de producción primero, esa empresa lo hará mucho mejor que en la solución de movimiento simultáneo (Nash). En general, si es posible comprometerse con estrategias mixtas, entonces (bajo suposiciones menores) nunca perjudica, y a menudo ayuda, comprometerse con una estrategia [26]. Verse obligado a comprometerse con una estrategia pura a veces ayuda y a veces perjudica (por ejemplo, comprometerse con una estrategia pura en piedra-papel-tijeras antes de la decisión de los otros jugadores naturalmente resultará en una derrota). En este documento, asumiremos que el compromiso siempre es forzado; si no lo es, el jugador que tiene la opción de comprometerse simplemente puede comparar el resultado del compromiso con el resultado de no comprometerse (movimiento simultáneo). Los modelos de liderazgo son especialmente importantes en entornos con múltiples agentes de software con intereses propios. Una vez que el código de un agente (o de un equipo de agentes) está finalizado y el agente es desplegado, el agente se compromete a jugar la estrategia (posiblemente aleatoria) que el código prescribe. Por lo tanto, siempre y cuando se pueda demostrar de manera creíble que no se puede cambiar el código más tarde, el código funciona como un dispositivo de compromiso. Esto es válido para torneos recreativos entre agentes (por ejemplo, torneos de póker, RoboSoccer) y para aplicaciones industriales como redes de sensores. Finalmente, también existe una situación de liderazgo implícito en el campo del diseño de mecanismos, en la cual un jugador (el diseñador) tiene la oportunidad de elegir las reglas del juego que los demás jugadores luego siguen. El diseño de mecanismos es un tema extremadamente importante para la comunidad de EC: los artículos publicados sobre diseño de mecanismos en las recientes conferencias de EC son demasiados para citar. De hecho, el diseñador del mecanismo puede beneficiarse al comprometerse con una elección que, si las acciones de los agentes (restantes) estuvieran fijas, sería subóptima. Por ejemplo, en una subasta (a precio fijo), el vendedor puede desear establecer un precio de reserva positivo (artificial) para el artículo, por debajo del cual el artículo no se venderá, incluso si el vendedor valora el artículo en 0. En retrospectiva (después de recibir las ofertas), esto (ingenuamente) parece subóptimo: si llegaba una oferta que superaba el precio de reserva, el precio de reserva no tenía efecto, y si no llegaba tal oferta, el vendedor hubiera estado mejor aceptando una oferta más baja. Por supuesto, la razón para establecer el precio de reserva es incentivar a los postores a ofertar más alto, y debido a esto, establecer precios de reserva artificiales puede aumentar realmente los ingresos esperados para el vendedor. Recientemente se ha dedicado una cantidad significativa de investigación al cálculo de soluciones de acuerdo con varios conceptos de solución para escenarios en los que los agentes eligen sus estrategias simultáneamente, como la dominancia [7, 11, 3] y (especialmente) el equilibrio de Nash [8, 21, 16, 15, 2, 22, 23, 4]. Sin embargo, se ha ignorado el cálculo de la estrategia óptima a comprometerse en una situación de liderazgo. Teóricamente, las situaciones de liderazgo simplemente pueden ser consideradas como un juego de forma extensiva en el que un jugador elige una estrategia (para el juego original) primero. El número de estrategias en este juego de forma extensiva, sin embargo, puede ser extremadamente grande. Por ejemplo, si el líder es capaz de comprometerse con una estrategia mixta en el juego original, entonces cada una de las estrategias mixtas (continuo de) constituye una estrategia pura en la representación de forma extensiva de la situación de liderazgo. (Se destaca que un compromiso con una distribución no es lo mismo que una distribución sobre compromisos). Además, si el juego original es en sí mismo un juego de forma extensiva, el número de estrategias en la representación de forma extensiva de la situación de liderazgo (que es un juego de forma extensiva diferente) se vuelve aún más grande. Por lo tanto, generalmente no es factible computacionalmente simplemente transformar el juego original en la representación de forma extensiva de la situación de liderazgo; en su lugar, debemos analizar el juego en su representación original. En este artículo, estudiamos cómo calcular la estrategia óptima a comprometerse, tanto en juegos de forma normal (Sección 2) como en juegos bayesianos, que son un caso especial de juegos de forma extensiva (Sección 3). JUEGOS EN FORMA NORMAL En esta sección, estudiamos cómo calcular la estrategia óptima a comprometerse para juegos representados en forma normal. 2.1 Definiciones En un juego en forma normal, cada jugador i ∈ {1, . . . , n} tiene un conjunto de estrategias puras (o acciones) Si, y una función de utilidad ui : S1×S2×. . .×Sn → R que mapea cada resultado (un vector que consiste en una estrategia pura para cada jugador, también conocido como un perfil de estrategias puras) a un número real. Para facilitar la notación, en el caso de dos jugadores, nos referiremos al conjunto de estrategias puras del jugador 1 como S, y al conjunto de estrategias puras del jugador 2 como T. Estos juegos pueden representarse en forma de matriz (bi-matriz), en la que las filas corresponden a las estrategias puras del jugador 1, las columnas corresponden a las estrategias puras del jugador 2, y las entradas de la matriz dan las utilidades de los jugadores de fila y columna (en ese orden) para el resultado correspondiente del juego. En el caso de tres jugadores, usaremos R, S y T, para las estrategias puras de los jugadores 1, 2 y 3, respectivamente. Una estrategia mixta para un jugador es una distribución de probabilidad sobre las estrategias puras de ese jugador. En el caso de juegos de dos jugadores, nos referiremos al jugador 1 como el líder y al jugador 2 como el seguidor. Antes de definir estrategias de liderazgo óptimas, considera el siguiente juego que ilustra el efecto de la capacidad del líder para comprometerse. 2, 1 4, 0 1, 0 3, 1 En esta representación en forma normal, la estrategia inferior para el jugador de la fila está estrictamente dominada por la estrategia superior. Sin embargo, si el jugador de la fila tiene la capacidad de comprometerse con una estrategia pura antes de que el jugador de la columna elija su estrategia, el jugador de la fila debería comprometerse con la estrategia inferior: al hacerlo, el jugador de la columna preferirá jugar la estrategia correcta, lo que llevará a una utilidad de 3 para el jugador de la fila. Por el contrario, si el jugador de la fila se comprometiera con la estrategia superior, el jugador de la columna preferiría jugar la estrategia izquierda, lo que llevaría a una utilidad de solo 2 para el jugador de la fila. Si el jugador de la fila puede comprometerse a una estrategia mixta, entonces puede obtener una utilidad aún mayor (esperada): si el jugador de la fila se compromete a colocar una probabilidad p > 1/2 en la estrategia inferior, entonces el jugador de la columna seguirá prefiriendo jugar la estrategia derecha, y la utilidad esperada de los jugadores de la fila será 3p + 4(1 − p) = 4 − p ≥ 3. Si el jugador de la fila juega cada estrategia con una probabilidad exacta de 1/2, el jugador de la columna está 83 indiferente entre las estrategias. En tales casos, asumiremos que el jugador de la columna elegirá la estrategia que maximiza la utilidad de los jugadores de la fila (en este caso, la estrategia correcta). Por lo tanto, la estrategia mixta óptima a la que debe comprometerse el jugador de la fila es p = 1/2. Hay algunas buenas razones para esta suposición. Si asumiéramos lo contrario, entonces no existiría una estrategia óptima para el jugador de la fila en el juego de ejemplo: el jugador de la fila jugaría la estrategia inferior con una probabilidad p = 1/2 + con > 0, y cuanto menor sea , mejor será la utilidad para el jugador de la fila. Por el contrario, si asumimos que el seguidor siempre rompe los empates a favor de los líderes, entonces siempre existe una estrategia mixta óptima para el líder, lo que corresponde a un equilibrio perfecto en subjuegos de la representación en forma extensiva de la situación de liderazgo. En cualquier caso, esta es una suposición estándar para tales modelos (por ejemplo, [20]), aunque algunos trabajos han investigado lo que puede suceder en los otros equilibrios perfectos de subjuego [26]. (Para juegos genéricos de dos jugadores, el pago del equilibrio perfecto de subjuego de los líderes es único). Además, la misma suposición se utiliza típicamente en el diseño de mecanismos, asumiendo que si un agente es indiferente entre revelar sus preferencias de manera veraz o falsa, las reportará de manera veraz. Dado este supuesto, podemos hacer referencia de manera segura a estrategias de liderazgo óptimas en lugar de tener que utilizar alguna noción de equilibrio. Por lo tanto, para los propósitos de este documento, una estrategia óptima a comprometerse en un juego de 2 jugadores es una estrategia s ∈ S que maximiza maxt∈BR(s) ul(s, t), donde BR(s) = arg maxt∈T uf (s, t). (ul y uf son las funciones de utilidad del líder y los seguidores, respectivamente). Podemos tener S = S para el caso de compromiso con estrategias puras, o S = ∆(S), el conjunto de distribuciones de probabilidad sobre S, para el caso de compromiso con estrategias mixtas. (Observamos que reemplazar T por ∆(T) no hace ninguna diferencia en esta definición). Para juegos con más de dos jugadores, en los que los jugadores se comprometen con sus estrategias en secuencia, definimos estrategias óptimas a las que comprometerse de forma recursiva. Después de que el líder se compromete con una estrategia, el juego que jugarán los agentes restantes es en sí mismo un juego de liderazgo (más pequeño). Por lo tanto, definimos una estrategia óptima a comprometerse como una estrategia que maximiza la utilidad del líder, asumiendo que el juego de los agentes restantes es óptimo bajo esta definición, y maximiza la utilidad del líder entre todas las formas óptimas de jugar el juego restante. Nuevamente, el compromiso con estrategias mixtas puede o no ser una posibilidad para cada jugador (aunque para el último jugador no importa si permitimos el compromiso con estrategias mixtas). 2.2 Compromiso con estrategias puras. Primero estudiamos cómo calcular la estrategia pura óptima a la que comprometerse. Esto es relativamente simple, porque el número de estrategias a comprometer no es muy grande. (En lo siguiente, #resultados es el número de perfiles de estrategia completos). Teorema 1. Bajo el compromiso de estrategias puras, el conjunto de todos los perfiles de estrategia óptimos en un juego en forma normal se puede encontrar en tiempo O(#jugadores · #resultados). Prueba. Cada estrategia pura a la que el primer jugador pueda comprometerse inducirá un subjuego para los jugadores restantes. Podemos resolver cada subjuego de esta manera de forma recursiva para encontrar todos sus perfiles de estrategia óptimos; cada uno de estos le dará al líder original cierta utilidad. Aquellos que proporcionan al líder la utilidad máxima corresponden exactamente a los perfiles de estrategia óptimos del juego original. Ahora presentamos el algoritmo de forma formal. Sea Su(G, s1) el subjuego que resulta después de que el primer jugador restante en G juega s1 ∈ SG 1. Un juego con 0 jugadores es simplemente un resultado del juego. La función Append(s, O) añade la estrategia s a cada uno de los vectores de estrategias en el conjunto O. Sea e el vector vacío sin elementos. En un ligero abuso de notación, escribiremos uG 1 (C) cuando todos los perfiles estratégicos en el conjunto C le den al jugador 1 la misma utilidad en el juego G. (Aquí, el jugador 1 es el primer jugador restante en el subjuego G, no necesariamente el jugador 1 en el juego original). Observamos que arg max es un conjunto de valores. Entonces, el siguiente algoritmo calcula todos los perfiles de estrategia óptimos: Algoritmo Resolver(G) si G tiene 0 jugadores, devuelve {e} C ← ∅ para todo s1 ∈ SG 1 { O ← Resolver(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) si C = ∅ o uG 1 (s1, O ) = uG 1 (C) C ← C∪Agregar(s1, O ) si uG 1 (s1, O ) > uG 1 (C) C ←Agregar(s1, O ) } devuelve C Cada resultado es examinado (potencialmente) por cada jugador, lo que lleva al límite de tiempo dado. Como ejemplo de cómo funciona el algoritmo, considera el siguiente juego de 3 jugadores, en el que el primer jugador elige la matriz izquierda o derecha, el segundo jugador elige una fila y el tercer jugador elige una columna. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 Primero eliminamos los resultados que no corresponden a las mejores respuestas para el tercer jugador (eliminándolos de la matriz): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Luego, eliminamos las entradas en las que el tercer jugador no resuelve los empates a favor del segundo jugador, así como las entradas que no corresponden a las mejores respuestas para el segundo jugador. 0,1,1 2,1,1 1,1,1 0,5,1 Finalmente, eliminamos las entradas en las que el segundo y tercer jugador no resuelven los empates a favor del primer jugador, así como las entradas que no corresponden a las mejores respuestas para el primer jugador. 2,1,1 Por lo tanto, en el juego óptimo, el primer jugador elige la matriz izquierda, el segundo jugador elige la fila del medio y el tercer jugador elige la columna izquierda. (Notamos que este resultado está dominado por Pareto por (Derecha, Medio, Izquierda).) Para juegos en forma normal general, la utilidad de cada jugador para cada uno de los resultados debe representarse explícitamente en la entrada, de modo que el tamaño de la entrada sea en sí mismo Ω(#jugadores · #resultados). Por lo tanto, el algoritmo es de hecho un algoritmo de tiempo lineal. 2.3 Compromiso con estrategias mixtas En el caso especial de juegos de dos jugadores de suma cero, calcular una estrategia mixta óptima para que el líder se comprometa es equivalente a calcular una estrategia minimax, que minimiza la utilidad esperada máxima que el oponente puede obtener. Las estrategias minimax constituyen el único concepto de solución natural para juegos de suma cero de dos jugadores: el Teorema Minimax de von Neumann [24] establece que en juegos de suma cero de dos jugadores, no importa (en términos de las utilidades de los jugadores) qué jugador se compromete primero a una estrategia mixta, y un perfil de estrategias mixtas es un equilibrio de Nash si y solo si ambas estrategias son estrategias minimax. Es bien sabido que una estrategia minimax se puede encontrar en tiempo polinómico, utilizando programación lineal [17]. Nuestro primer resultado en esta sección generaliza este resultado, mostrando que una estrategia mixta óptima para que el líder se comprometa puede ser calculada eficientemente en juegos de dos jugadores de suma general, nuevamente utilizando programación lineal. Teorema 2. En juegos de forma normal de 2 jugadores, una estrategia mixta óptima a la que comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal. Prueba. Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder de modo que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad del líder. Un programa lineal simple puede calcular una estrategia mixta como la siguiente: maximizar s∈S psul(s, t) sujeto a que para todo t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1. Se destaca que este programa puede ser inviable para algunas estrategias seguidoras t, por ejemplo, si t es una estrategia estrictamente dominada. Sin embargo, el programa debe ser factible para al menos algunas estrategias seguidoras; entre estas estrategias seguidoras, elige una estrategia t∗ que maximice el valor de la solución de los programas lineales. Entonces, si la líder elige como su estrategia mixta los ajustes óptimos de las variables ps para el programa lineal para t∗, y el seguidor juega t∗, esto constituye un perfil de estrategia óptimo. En el siguiente resultado, demostramos que no podemos esperar resolver el problema de manera más eficiente que la programación lineal, ya que podemos reducir cualquier programa lineal con una restricción de probabilidad en sus variables a un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores. Teorema 3. Cualquier programa lineal cuyas variables xi (con xi ∈ R≥0) deben satisfacer i xi = 1 puede ser modelado como un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores. Prueba. Que el líder tenga una estrategia pura i para cada variable xi. Que el jugador de la columna tenga una estrategia pura j para cada restricción en el programa lineal (distinta de i xi = 1), y una única estrategia pura adicional 0. Que las funciones de utilidad sean las siguientes. Escribiendo el objetivo del programa lineal como maximizar ci xi, para cualquier i, dejando ul(i, 0) = ci y uf(i, 0) = 0. Escribiendo la j-ésima restricción del programa lineal (sin incluir i xi = 1) como i aijxi ≤ bj, para cualquier i, j > 0, sea ul(i, j) = mini ci − 1 y uf(i, j) = aij − bj. Por ejemplo, considera el siguiente programa lineal. maximizar 2x1 + x2 sujeto a x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 La solución óptima de este programa es x1 = 1/3, x2 = 2/3. Nuestra reducción transforma este programa en el siguiente juego de líder-seguidor (donde el líder es el jugador de la fila). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 De hecho, la estrategia óptima para el líder es jugar la estrategia superior con una probabilidad de 1/3 y la estrategia inferior con una probabilidad de 2/3. Ahora demostramos que la reducción funciona en general. Claramente, el líder quiere incentivar al seguidor a jugar 0, porque la utilidad que el líder obtiene cuando el seguidor juega 0 siempre es mayor que cuando el seguidor no juega 0. Para que el seguidor no prefiera jugar j > 0 en lugar de 0, debe ser el caso que i pl(i)(aij − bj) ≤ 0, o equivalentemente i pl(i)aij ≤ bj. Por lo tanto, el líder obtendrá una utilidad de al menos mini ci si y solo si hay una solución factible a las restricciones. Dado que el pl(i) incentiva al seguidor a jugar 0, el líder intenta maximizar i pl(i)ci. Por lo tanto, el líder debe resolver el programa lineal original. Como prueba alternativa del Teorema 3, se puede observar que se sabe que encontrar una estrategia minimax en un juego de suma cero es tan difícil como el problema de programación lineal [6], y como señalamos al principio de esta sección, calcular una estrategia minimax en un juego de suma cero es un caso especial del problema de calcular una estrategia mixta óptima a la que comprometerse. La solubilidad en tiempo polinómico del problema de calcular una estrategia mixta óptima a la que comprometerse en juegos de forma normal de dos jugadores contrasta con la complejidad desconocida de calcular un equilibrio de Nash en tales juegos [21], así como con la NP-dificultad de encontrar un equilibrio de Nash con utilidad máxima para un jugador dado en tales juegos [8, 2]. Desafortunadamente, este resultado no se generaliza a más de dos jugadores; aquí, el problema se vuelve NP-duro. Para demostrar esto, reducimos desde el problema de CUBRIR-VÉRTICES. Definición 1. En VERTEX-COVER, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que cada arista e ∈ E tenga al menos uno de sus extremos en S. BALANCED-VERTEX-COVER es el caso especial de VERTEX-COVER en el que K = |V|/2. VERTEX-COVER es NP-completo [9]. El siguiente lema muestra que la dificultad persiste si requerimos K = |V|/2. (Resultados similares se han demostrado para otros problemas NP-completos). Lema 1. El problema de la COBERTURA DE VÉRTICES EQUILIBRADA es NP-completo. Prueba. La pertenencia a NP se deriva del hecho de que el problema es un caso especial de CUBRIMIENTO DE VÉRTICES, que está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES a una instancia de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO, de la siguiente manera. Si, para la instancia de CUBRIMIENTO DE VÉRTICES, K > |V|/2, simplemente agregamos vértices aislados que estén disjuntos del resto del grafo, hasta que K = |V|/2. Si K < |V|/2, agregamos triángulos aislados (es decir, el grafo completo de tres vértices) al grafo, aumentando K en 2 cada vez, hasta que K = |V|/2. Teorema 4. En juegos de forma normal de 3 jugadores, encontrar una estrategia mixta óptima a la que comprometerse es NP-difícil. Prueba. Reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO al siguiente juego de forma normal de 3 jugadores. Para cada vértice v, cada uno de los tres jugadores tiene una estrategia pura correspondiente a ese vértice (rv, sv, tv, respectivamente). Además, para cada arista e, el tercer jugador tiene una estrategia pura te; y finalmente, el tercer jugador tiene una estrategia pura adicional t0. Los servicios son los siguientes: • para todo r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • para todo r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • para todo v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • para todo v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • para todo v ∈ V, para todo r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V| |V|−2; • para todo e ∈ E, s ∈ S, para ambos v ∈ e, u3(rv, s, te) = 0; • para todo e ∈ E, s ∈ S, para todo v /∈ e, u3(rv, s, te) = |V| |V|−2. • para todo r ∈ R, s ∈ S, u3(r, s, t0) = 1. Observamos que los jugadores 1 y 2 tienen la misma función de utilidad. Sostenemos que existe un perfil de estrategia óptimo en el que los jugadores 1 y 2 obtienen ambos 1 (su utilidad máxima) si y solo si hay una solución al problema de la COBERTURA DE VÉRTICES EQUILIBRADA. (De lo contrario, estos jugadores obtendrán ambos 0). Primero, supongamos que existe una solución al problema de la cubierta de vértices balanceada. Entonces, deja que el jugador 1 juegue cada rv de manera que v esté en la cobertura con probabilidad 2 |V|, y deja que el jugador 2 juegue cada sv de manera que v no esté en la cobertura con probabilidad 2 |V|. Entonces, para el jugador 3, la utilidad esperada de jugar tv (para cualquier v) es (1 − 2 |V|) |V| |V|−2 = 1, porque hay una probabilidad de 2 |V| de que se juegue rv o sv. Además, la utilidad esperada de jugar te (para cualquier e) es a lo sumo (1 − 2 |V | ) |V | |V |−2 = 1, porque hay una probabilidad de al menos 2 |V | de que algún rv con v ∈ e se juegue (debido a que el jugador 1 está aleatorizando sobre las estrategias puras correspondientes a la cobertura). Se deduce que jugar t0 es la mejor respuesta para el jugador 3, otorgando a los jugadores 1 y 2 una utilidad de 1. Ahora, supongamos que los jugadores 1 y 2 obtienen 1 en el juego óptimo. Entonces, debe ser el caso de que el jugador 3 juegue t0. Por lo tanto, para cada v ∈ V, debe haber una probabilidad de al menos 2 |V| de que se juegue rv o sv, de lo contrario, al jugador 3 le convendría más jugar tv. Dado que los jugadores 1 y 2 solo tienen una probabilidad total de 2 para distribuir, debe ser el caso que para cada v, ya sea rv o sv se juegue con una probabilidad de 2 |V|, y el otro se juegue con una probabilidad de 0. (No es posible que ambos tengan una probabilidad distinta de cero, porque entonces habría alguna probabilidad de que ambos se jugaran simultáneamente (la correlación no es posible), por lo tanto, la probabilidad total de que al menos uno se juegue no podría ser lo suficientemente alta para todos los vértices). Por lo tanto, para exactamente la mitad de los v ∈ V, el jugador 1 coloca una probabilidad de 2 |V| en rv. Además, para cada e ∈ E, debe haber una probabilidad de al menos 2 |V | de que se juegue algún rv con v ∈ e, de lo contrario, al jugador 3 le convendría más jugar te. Por lo tanto, el v ∈ V tal que el jugador 1 coloca una probabilidad de 2 |V | en rv constituye una cubierta de vértices equilibrada. 3. Juegos bayesianos. Hasta ahora, hemos restringido nuestra atención a los juegos en forma normal. En un juego en forma normal, se asume que cada agente conoce las preferencias de todos los demás agentes sobre los resultados del juego. En general, sin embargo, los agentes pueden tener información privada sobre sus preferencias que no es conocida por los otros agentes. Además, en el momento de comprometerse con una estrategia, los agentes pueden ni siquiera conocer sus propias preferencias (finales) sobre los resultados del juego aún, ya que estas preferencias pueden depender de un contexto que aún no se ha materializado. Por ejemplo, cuando se escribe el código para un agente de negociación, puede que aún no esté claro cómo ese agente valorará los recursos sobre los que negociará más adelante, porque esto depende de información que aún no está disponible en el momento en que se escribe el código (como órdenes que habrán sido colocadas al agente antes de la negociación). En esta sección, estudiaremos el compromiso en juegos bayesianos, los cuales pueden modelar tal incertidumbre sobre preferencias. 3.1 Definiciones En un juego bayesiano, cada jugador i tiene un conjunto de acciones Si, un conjunto de tipos Θi con una distribución de probabilidad asociada πi : Θi → [0, 1], y, para cada tipo θi, una función de utilidad uθi i : S1 × S2 × . . . × Sn → R. Una estrategia pura en un juego bayesiano es una asignación de los tipos de los jugadores a acciones, σi : Θi → Si. (Los juegos bayesianos pueden ser reescritos en forma normal enumerando cada estrategia pura σi, pero esto causará un crecimiento exponencial en el tamaño de la representación del juego y por lo tanto no puede llevar a algoritmos eficientes). La estrategia a la que el líder debería comprometerse depende de si, en el momento del compromiso, el líder conoce su propio tipo. Si la líder conoce su propio tipo, los otros tipos que la líder podría haber tenido se vuelven irrelevantes y la líder simplemente debería comprometerse con la estrategia que sea óptima para ese tipo. Sin embargo, como se argumentó anteriormente, la líder no necesariamente conoce su propio tipo en el momento de comprometerse (por ejemplo, en el momento en que se envía el código). En este caso, el líder debe comprometerse con una estrategia que dependa en un 86% del tipo eventual del líder. Estudiaremos este último modelo, aunque prestaremos atención específica al caso en el que el líder tiene un solo tipo, lo cual es efectivamente lo mismo que el modelo anterior. 3.2 Compromiso con estrategias puras Resulta que calcular una estrategia pura óptima a la que comprometerse es difícil en juegos bayesianos, incluso con dos jugadores. Teorema 5. Encontrar una estrategia pura óptima a comprometerse en juegos bayesianos de 2 jugadores es NP-difícil, incluso cuando el seguidor tiene solo un tipo. Prueba. Reducimos una instancia arbitraria de CUBRIMIENTO DE VÉRTICES al siguiente juego bayesiano entre el líder y el seguidor. El líder tiene K tipos θ1, θ2, . . . , θK, cada uno ocurriendo con probabilidad 1/K, y para cada vértice v ∈ V, el líder tiene una acción sv. El seguidor tiene solo un tipo; para cada borde e ∈ E, el seguidor tiene una acción te, y el seguidor tiene una acción adicional única t0. La función de utilidad para el líder está dada por, para todo θl ∈ Θl y todo s ∈ S, u θl l (s, t0) = 1, y para todo e ∈ E, u θl l (s, te) = 0. La utilidad de los seguidores se da por: • Para todo v ∈ V, para todo e ∈ E con v /∈ e, uf (sv, te) = 1; • Para todo v ∈ V, para todo e ∈ E con v ∈ e, uf (sv, te) = −K; • Para todo v ∈ V, uf (sv, t0) = 0. Sostenemos que el líder puede obtener una utilidad de 1 si y solo si hay una solución para la instancia de CUBRIMIENTO-DE-VÉRTICES. Primero, supongamos que hay una solución para la instancia de CUBRIRVÉRTICES. Entonces, el líder puede comprometerse con una estrategia pura tal que para cada vértice v en la cobertura, el líder juega sv para algún tipo. Entonces, la utilidad de los seguidores para jugar te (para cualquier e ∈ E) es a lo sumo K−1 K + 1 K (−K) = − 1 K , por lo que el seguidor preferirá jugar t0, lo que le da al líder una utilidad de 1, como se requiere. Ahora, supongamos que hay una estrategia pura para el líder que le dará al líder una utilidad de 1. Entonces, el seguidor debe jugar t0. Para que el seguidor no prefiera jugar te (para cualquier e ∈ E) en su lugar, al menos para un v ∈ e, el líder debe jugar sv para algún tipo θl. Por lo tanto, el conjunto de vértices v que el líder juega para algún tipo debe constituir una cubierta de vértices; y este conjunto puede tener un tamaño de como máximo K, ya que el líder solo tiene K tipos. Entonces hay una solución para la instancia de CUBRIMIENTODEVÉRTICES. Sin embargo, si el líder tiene solo un tipo, entonces el problema se vuelve fácil nuevamente (#tipos es el número de tipos para el seguidor): Teorema 6. En juegos bayesianos de 2 jugadores en los que el líder tiene solo un tipo, una estrategia pura óptima a comprometerse puede encontrarse en tiempo O(#resultados · #tipos). Prueba. Para cada acción de líder s, podemos calcular, para cada tipo de seguidor θf ∈ Θf, qué acciones t maximizan la utilidad de los seguidores; llamamos a este conjunto de acciones BRθf (s). Entonces, la utilidad que recibe el líder por comprometerse a la acción s se puede calcular como θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), y el líder puede elegir la mejor acción a la que comprometerse. 3.3 Compromiso con estrategias mixtas En juegos de información imperfecta de suma cero de dos jugadores con memoria perfecta (ningún jugador olvida algo que una vez supo), una estrategia minimax se puede construir en tiempo polinómico [12, 13]. Desafortunadamente, este resultado no se extiende a calcular estrategias mixtas óptimas a comprometerse en el caso de suma general, ni siquiera en juegos bayesianos. Demostraremos la NP-dificultad reduciendo desde el problema de CONJUNTOINDEPENDIENTE. Definición 2. En INDEPENDENT-SET, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que ninguna arista e ∈ E tenga ambos extremos en S. Nuevamente, este problema es NP-completo [9]. Teorema 7. Encontrar una estrategia mixta óptima a comprometerse en juegos bayesianos de 2 jugadores es NP-duro, incluso cuando el líder tiene solo un tipo y el seguidor tiene solo dos acciones. Prueba. Reducimos una instancia arbitraria de CONJUNTO-INDEPENDIENTE al siguiente juego bayesiano entre el líder y el seguidor. El líder tiene solo un tipo, y para cada vértice v ∈ V, el líder tiene una acción sv. El seguidor tiene un tipo θv para cada v ∈ V, que ocurre con una probabilidad de 1 (|E|+1)|V|, y un tipo θe para cada e ∈ E, que ocurre con una probabilidad de 1 |E|+1. El seguidor tiene dos acciones: t0 y t1. La utilidad de los líderes se da por, para todo s ∈ S, ul(s, t0) = 1 y ul(s, t1) = 0. La utilidad de los seguidores se da por: • Para todo v ∈ V, uθv f (sv, t1) = 0; • Para todo v ∈ V y s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • Para todo v ∈ V y s ∈ S, uθv f (s, t0) = 1; • Para todo e ∈ E, s ∈ S, uθe f (s, t0) = 1; • Para todo e ∈ E, para ambos v ∈ e, uθe f (sv, t1) = 2K 3 ; • Para todo e ∈ E, para todo v /∈ e, uθe f (sv, t1) = 0. Sostenemos que una estrategia óptima a comprometerse le otorga al líder una utilidad esperada de al menos |E| |E|+1 + K (|E|+1)|V | si y solo si hay una solución para la instancia de CONJUNTO-INDEPENDIENTE. Primero, supongamos que hay una solución para la instancia de CONJUNTO-INDEPENDIENTE. Entonces, el líder podría comprometerse con la siguiente estrategia: por cada vértice v en el conjunto independiente, jugar el correspondiente sv con una probabilidad de 1/K. Si el seguidor tiene el tipo θe para algún e ∈ E, la utilidad esperada para el seguidor al jugar t1 es a lo sumo 1 K 2K 3 = 2/3, porque hay a lo sumo un vértice v ∈ e tal que sv se juega con probabilidad distinta de cero. Por lo tanto, el seguidor jugará t0 y obtendrá una utilidad de 1. Si el seguidor tiene el tipo θv para algún vértice v en el conjunto independiente, la utilidad esperada para el seguidor al jugar t1 es K−1 K K K−1 = 1, porque el líder juega sv con probabilidad 1/K. Se deduce que el seguidor (quien rompe los empates para maximizar la utilidad de los líderes) jugará t0, lo que también otorga una utilidad de 1 y brinda al líder una mayor utilidad. Por lo tanto, la utilidad esperada de los líderes para esta estrategia es al menos |E| |E|+1 + K (|E|+1)|V |, como se requiere. Ahora, supongamos que hay una estrategia que le da al líder una utilidad esperada de al menos |E| |E|+1 + K (|E|+1)|V |. Entonces, esta estrategia debe inducir al seguidor a jugar t0 siempre que tenga un tipo de la forma θe (porque de lo contrario, la utilidad podría ser a lo sumo |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ). Por lo tanto, no puede ser el caso de que para alguna arista e = (v1, v2) ∈ E, la probabilidad de que el líder juegue uno de sv1 y sv2 sea al menos 2/K, porque entonces la utilidad esperada para el seguidor de jugar t1 cuando tiene el tipo θe sería al menos 2 K 2K 3 = 4/3 > 1. Además, la estrategia debe inducir al seguidor a jugar t0 durante al menos K tipos de la forma θv. Inducir al seguidor a jugar t0 cuando tiene el tipo θv solo se puede lograr jugando sv con una probabilidad de al menos 1/K, lo que le dará al seguidor una utilidad de como máximo K−1 K K K−1 = 1 por jugar t1. Pero entonces, el conjunto de vértices v tales que sv se juega con una probabilidad de al menos 1/K debe constituir un conjunto independiente de tamaño K (porque si hubiera una arista e entre dos de estos vértices, induciría al seguidor a jugar t1 para el tipo θe según lo mencionado anteriormente). Por el contrario, si el seguidor tiene solo un tipo, entonces podemos generalizar el enfoque de programación lineal para juegos en forma normal: Teorema 8. En juegos bayesianos de 2 jugadores en los que el seguidor tiene solo un tipo, una estrategia mixta óptima a comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal. Prueba. Generalizamos el enfoque en el Teorema 2 de la siguiente manera. Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder para cada uno de los tipos de líderes de manera que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad esperada ex ante de los líderes. Para hacerlo, generalizamos el programa lineal de la siguiente manera: maximizar θl∈Θl π(θl) s∈S pθl s uθl l (s, t) sujeto a para todo t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t) para todo θl ∈ Θl, s∈S p θl s = 1 Como en el Teorema 2, la solución para el programa lineal que maximiza el valor de la solución es una estrategia óptima a comprometerse. Esto muestra un contraste interesante entre el compromiso con estrategias puras y el compromiso con estrategias mixtas en juegos bayesianos: para las estrategias puras, el problema se vuelve fácil si el líder tiene solo un tipo (pero no si el seguidor tiene solo un tipo), mientras que para las estrategias mixtas, el problema se vuelve fácil si el seguidor tiene solo un tipo (pero no si el líder tiene solo un tipo). 4. CONCLUSIONES E INVESTIGACIONES FUTURAS En los sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias de forma simultánea. Esto requiere cierta noción de equilibrio (equilibrio de Nash y sus refinamientos), y a menudo conduce al problema de selección de equilibrio: no está claro para cada jugador individual según qué equilibrio debería jugar. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Por ejemplo, un agente puede llegar al sitio del juego (real o virtual) antes que el otro, o, en el caso específico de agentes de software, el código de un agente puede estar completo y comprometido antes que el de otro agente. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. Específicamente, si es posible el compromiso con estrategias mixtas, entonces el compromiso (óptimo) nunca perjudica al líder y a menudo lo beneficia. El reciente aumento del interés en las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas para comprometerse tanto a estrategias puras como a estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Para juegos en forma normal, demostramos que la estrategia pura óptima a comprometerse se puede encontrar eficientemente para cualquier número de jugadores. Una estrategia mixta óptima para comprometerse en un juego en forma normal puede encontrarse eficientemente para dos jugadores utilizando programación lineal (y no más eficientemente que eso, en el sentido de que cualquier programa lineal con una restricción de probabilidad puede ser codificado como tal problema). (Esta es una generalización de la computabilidad en tiempo polinómico de las estrategias minimax en juegos en forma normal). El problema se vuelve NP-duro para tres (o más) jugadores. En los juegos bayesianos, el problema de encontrar una estrategia pura óptima a la que comprometerse es NP-duro incluso en juegos de dos jugadores en los que el seguidor tiene solo un tipo, aunque los juegos de dos jugadores en los que el líder tiene solo un tipo pueden resolverse eficientemente. El problema de encontrar una estrategia mixta óptima a comprometerse en un juego bayesiano es NP-duro incluso en juegos de dos jugadores en los que el líder tiene solo un tipo, aunque los juegos de dos jugadores en los que el seguidor tiene solo un tipo pueden resolverse eficientemente utilizando una generalización del enfoque de programación lineal para juegos en forma normal. Las siguientes dos tablas resumen estos resultados. 2 jugadores ≥ 3 jugadores forma normal O(#resultados) O(#resultados· #jugadores) Bayesiano, O(#resultados· NP-completo 1-tipo líder #tipos) Bayesiano, NP-completo NP-completo 1-tipo seguidor Bayesiano (general) NP-completo NP-completo Resultados para el compromiso con estrategias puras. (Con más de 2 jugadores, el seguidor es el último jugador en comprometerse, el líder es el primero.) 88 2 jugadores ≥ 3 jugadores forma normal una resolución de LP por acción NP-completa del seguidor Bayesiano, NP-completo NP-completo 1-tipo líder Bayesiano, una resolución de LP por acción NP-completa del 1-tipo seguidor Bayesiano (general) NP-completo NP-completo Resultados para el compromiso con estrategias mixtas. (Con más de 2 jugadores, el seguidor es el último jugador en comprometerse, el líder es el primero.) La investigación futura puede tomar varias direcciones. Primero, podemos evaluar empíricamente las técnicas presentadas aquí en conjuntos de pruebas como GAMUT [19]. También podemos estudiar la computación de estrategias óptimas a comprometerse en otras representaciones concisas de juegos en forma normal, por ejemplo, en juegos gráficos [10] o juegos de grafo de efecto local/acción [14, 1]. Para los casos en los que calcular una estrategia óptima para comprometerse es NP-duro, también podemos estudiar la computación de estrategias aproximadamente óptimas para comprometerse. Si bien la definición correcta de una estrategia aproximadamente óptima en este contexto puede parecer simple al principio, debería ser una estrategia que, si los jugadores siguientes juegan de manera óptima, funcione casi tan bien como la estrategia óptima en promedio, esta definición se vuelve problemática cuando consideramos que los otros jugadores también podrían estar jugando solo de manera aproximadamente óptima. Uno también puede estudiar modelos en los que múltiples (pero no todos) jugadores se comprometen al mismo tiempo. Otra dirección interesante a explorar es ver si calcular estrategias mixtas óptimas a las que comprometerse puede ayudarnos, o de alguna manera arrojar luz sobre, el cálculo de equilibrios de Nash. A menudo, las estrategias mixtas óptimas a las que comprometerse también son estrategias de equilibrio de Nash (por ejemplo, en juegos de suma cero de dos jugadores esto siempre es cierto), aunque no siempre es el caso (por ejemplo, como ya señalamos, a veces la estrategia óptima a la que comprometerse es una estrategia estrictamente dominada, que nunca puede ser una estrategia de equilibrio de Nash). 5. REFERENCIAS [1] N. A. R. Bhat y K. Leyton-Brown. Calculando los equilibrios de Nash de juegos de gráficos de acción. En Actas de la 20ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI), Banff, Canadá, 2004. [2] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Actas de la Decimoctava Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 765-771, Acapulco, México, 2003. [3] V. Conitzer y T. Sandholm. Complejidad del dominio (iterado). En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 88-97, Vancouver, Canadá, 2005. [4] V. Conitzer y T. Sandholm. Un criterio de eliminabilidad de estrategias generalizado y métodos computacionales para aplicarlo. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 483-488, Pittsburgh, PA, EE. UU., 2005. [5] A. A. Cournot. Las investigaciones sobre los juegos bayesianos son una representación potencialmente concisa de los juegos en forma normal en los principios matemáticos de la teoría de la riqueza. Hachette, París, 1838. [6] G. Dantzig. Una prueba de la equivalencia del problema de programación y el problema de juego. En T. Koopmans, editor, Análisis de la actividad de producción y asignación, páginas 330-335. John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel. \n\nJohn Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, y E. Zemel. La complejidad de eliminar estrategias dominadas. Matemáticas de la Investigación de Operaciones, 18:553-565, 1993. [8] I. Gilboa y E. Zemel. Nash y equilibrios correlacionados: Algunas consideraciones de complejidad. Juegos y Comportamiento Económico, 1:80-93, 1989. [9] R. Karp. Reductibilidad entre problemas combinatorios. En R. E. Miller y J. W. Thatcher, editores, Complejidad de las Computaciones de Computadoras, páginas 85-103. Plenum Press, Nueva York, 1972. [10] M. Kearns, M. Littman y S. Singh. Modelos gráficos para teoría de juegos. En Actas de la Conferencia sobre Incertidumbre en Inteligencia Artificial (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou y J. N. Tsitsiklis. Una nota sobre la eliminación de estrategias en juegos bimatrix. Cartas de Investigación Operativa, 7(3):103-107, 1988. [12] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [14] K. Leyton-Brown y M. Tennenholtz. Juegos de efecto local. En Actas de la Decimoctava Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), Acapulco, México, 2003. [15] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 36-41, San Diego, CA, 2003. [16] M. Littman y P. Stone. Un algoritmo de equilibrio de Nash de tiempo polinómico para juegos repetidos. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 48-54, San Diego, CA, 2003. [17] R. D. Luce y H. Raiffa. Juegos y decisiones. John Wiley and Sons, Nueva York, 1957. Reedición de Dover 1989. [18] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown y Y. Shoham. Ejecutar el GAMUT: Un enfoque integral para evaluar algoritmos de teoría de juegos. En la Conferencia Internacional sobre Agentes Autónomos y Sistemas Multiagente (AAMAS), Nueva York, NY, EE. UU., 2004. [20] M. J. Osborne y A. Rubinstein. Un curso de teoría de juegos. MIT Press, 1994. [21] C. Papadimitriou. \n\nMIT Press, 1994. [21] C. Papadimitriou. Algoritmos, juegos e Internet. En Actas del Simposio Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. 89 [22] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 664-669, San José, CA, EE. UU., 2004. [23] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [24] J. von Neumann. A la teoría de los juegos sociales. Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg. \n\nMathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg. Forma de mercado y equilibrio. Springer, Viena, 1934. [26] B. von Stengel y S. Zamir. Liderazgo con compromiso hacia estrategias mixtas. Informe de investigación CDAM LSE-CDAM-2004-01, London School of Economics, febrero de 2004. 90 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "stackelberg model": {
            "translated_key": "modelo de Stackelberg",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Computing the Optimal Strategy to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "We give both positive results (efficient algorithms) and negative results (NP-hardness results).",
                "Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent systems with self-interested agents (including most economic settings), the optimal action for one agent to take depends on the actions that the other agents take.",
                "To analyze how an agent should behave in such settings, the tools of game theory need to be applied.",
                "Typically, when a strategic setting is modeled in the framework of game theory, it is assumed that players choose their strategies simultaneously.",
                "This is especially true when the setting is modeled as a normal-form game, which only specifies each agents utility as a function of the vector of strategies that the agents choose, and does not provide any information on the order in which agents make their decisions and what the agents observe about earlier decisions by other agents.",
                "Given that the game is modeled in normal form, it is typically analyzed using the concept of Nash equilibrium.",
                "A Nash equilibrium specifies a strategy for each player, such that no player has an incentive to individually deviate from this profile of strategies. (Typically, the strategies are allowed to be mixed, that is, probability distributions over the original (pure) strategies.)",
                "A (mixed-strategy) Nash equilibrium is guaranteed to exist in finite games [18], but one problem is that there may be multiple Nash equilibria.",
                "This leads to the equilibrium selection problem of how an agent can know which strategy to play if it does not know which equilibrium is to be played.",
                "When the setting is modeled as an extensive-form game, it is possible to specify that some players receive some information about actions taken by others earlier in the game before deciding on their action.",
                "Nevertheless, in general, the players do not know everything that happened earlier in the game.",
                "Because of this, these games are typically still analyzed using an equilibrium concept, where one specifies a mixed strategy for each player, and requires that each players strategy is a best response to the others strategies. (Typically an additional constraint on the strategies is now imposed to ensure that players do not play in a way that is irrational with respect to the information that they have received so far.",
                "This leads to refinements of Nash equilibrium such as subgame perfect and sequential equilibrium.)",
                "However, in many real-world settings, strategies are not selected in such a simultaneous manner.",
                "Oftentimes, one player (the leader) is able to commit to a strategy before another player (the follower).",
                "This can be due to a variety of reasons.",
                "For example, one of the players may arrive at the site at which the game is to be played before another agent (e.g., in economic settings, one player may enter a market earlier and commit to a way of doing busi82 ness).",
                "Such commitment power has a profound impact on how the game should be played.",
                "For example, the leader may be best off playing a strategy that is dominated in the normal-form representation of the game.",
                "Perhaps the earliest and best-known example of the effect of commitment is that by von Stackelberg [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution.",
                "In general, if commitment to mixed strategies is possible, then (under minor assumptions) it never hurts, and often helps, to commit to a strategy [26].",
                "Being forced to commit to a pure strategy sometimes helps, and sometimes hurts (for example, committing to a pure strategy in rock-paper-scissors before the other players decision will naturally result in a loss).",
                "In this paper, we will assume commitment is always forced; if it is not, the player who has the choice of whether to commit can simply compare the commitment outcome to the non-commitment (simultaneous-move) outcome.",
                "Models of leadership are especially important in settings with multiple self-interested software agents.",
                "Once the code for an agent (or for a team of agents) is finalized and the agent is deployed, the agent is committed to playing the (possibly randomized) strategy that the code prescribes.",
                "Thus, as long as one can credibly show that one cannot change the code later, the code serves as a commitment device.",
                "This holds true for recreational tournaments among agents (e.g., poker tournaments, RoboSoccer), and for industrial applications such as sensor webs.",
                "Finally, there is also an implicit leadership situation in the field of mechanism design, in which one player (the designer) gets to choose the rules of the game that the remaining players then play.",
                "Mechanism design is an extremely important topic to the EC community: the papers published on mechanism design in recent EC conferences are too numerous to cite.",
                "Indeed, the mechanism designer may benefit from committing to a choice that, if the (remaining) agents actions were fixed, would be suboptimal.",
                "For example, in a (first-price) auction, the seller may wish to set a positive (artificial) reserve price for the item, below which the item will not be sold-even if the seller values the item at 0.",
                "In hindsight (after the bids have come in), this (na¨ıvely) appears suboptimal: if a bid exceeding the reserve price came in, the reserve price had no effect, and if no such bid came in, the seller would have been better off accepting a lower bid.",
                "Of course, the reason for setting the reserve price is that it incentivizes the bidders to bid higher, and because of this, setting artificial reserve prices can actually increase expected revenue to the seller.",
                "A significant amount of research has recently been devoted to the computation of solutions according to various solution concepts for settings in which the agents choose their strategies simultaneously, such as dominance [7, 11, 3] and (especially) Nash equilibrium [8, 21, 16, 15, 2, 22, 23, 4].",
                "However, the computation of the optimal strategy to commit to in a leadership situation has gone ignored.",
                "Theoretically, leadership situations can simply be thought of as an extensive-form game in which one player chooses a strategy (for the original game) first.",
                "The number of strategies in this extensive-form game, however, can be exceedingly large.",
                "For example, if the leader is able to commit to a mixed strategy in the original game, then every one of the (continuum of) mixed strategies constitutes a pure strategy in the extensive-form representation of the leadership situation. (We note that a commitment to a distribution is not the same as a distribution over commitments.)",
                "Moreover, if the original game is itself an extensive-form game, the number of strategies in the extensive-form representation of the leadership situation (which is a different extensive-form game) becomes even larger.",
                "Because of this, it is usually not computationally feasible to simply transform the original game into the extensive-form representation of the leadership situation; instead, we have to analyze the game in its original representation.",
                "In this paper, we study how to compute the optimal strategy to commit to, both in normal-form games (Section 2) and in Bayesian games, which are a special case of extensiveform games (Section 3). 2.",
                "NORMAL-FORM GAMES In this section, we study how to compute the optimal strategy to commit to for games represented in normal form. 2.1 Definitions In a normal-form game, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a pure strategy for every player, also known as a profile of pure strategies) to a real number.",
                "To ease notation, in the case of two players, we will refer to player 1s pure strategy set as S, and player 2s pure strategy set as T. Such games can be represented in (bi-)matrix form, in which the rows correspond to player 1s pure strategies, the columns correspond to player 2s pure strategies, and the entries of the matrix give the row and column players utilities (in that order) for the corresponding outcome of the game.",
                "In the case of three players, we will use R, S, and T, for player 1, 2, and 3s pure strategies, respectively.",
                "A mixed strategy for a player is a probability distribution over that players pure strategies.",
                "In the case of two-player games, we will refer to player 1 as the leader and player 2 as the follower.",
                "Before defining optimal leadership strategies, consider the following game which illustrates the effect of the leaders ability to commit. 2, 1 4, 0 1, 0 3, 1 In this normal-form representation, the bottom strategy for the row player is strictly dominated by the top strategy.",
                "Nevertheless, if the row player has the ability to commit to a pure strategy before the column player chooses his strategy, the row player should commit to the bottom strategy: doing so will make the column player prefer to play the right strategy, leading to a utility of 3 for the row player.",
                "By contrast, if the row player were to commit to the top strategy, the column player would prefer to play the left strategy, leading to a utility of only 2 for the row player.",
                "If the row player is able to commit to a mixed strategy, then she can get an even greater (expected) utility: if the row player commits to placing probability p > 1/2 on the bottom strategy, then the column player will still prefer to play the right strategy, and the row players expected utility will be 3p + 4(1 − p) = 4 − p ≥ 3.",
                "If the row player plays each strategy with probability exactly 1/2, the column player is 83 indifferent between the strategies.",
                "In such cases, we will assume that the column player will choose the strategy that maximizes the row players utility (in this case, the right strategy).",
                "Hence, the optimal mixed strategy to commit to for the row player is p = 1/2.",
                "There are a few good reasons for this assumption.",
                "If we were to assume the opposite, then there would not exist an optimal strategy for the row player in the example game: the row player would play the bottom strategy with probability p = 1/2 + with > 0, and the smaller , the better the utility for the row player.",
                "By contrast, if we assume that the follower always breaks ties in the leaders favor, then an optimal mixed strategy for the leader always exists, and this corresponds to a subgame perfect equilibrium of the extensive-form representation of the leadership situation.",
                "In any case, this is a standard assumption for such models (e.g. [20]), although some work has investigated what can happen in the other subgame perfect equilibria [26]. (For generic two-player games, the leaders subgame-perfect equilibrium payoff is unique.)",
                "Also, the same assumption is typically used in mechanism design, in that it is assumed that if an agent is indifferent between revealing his preferences truthfully and revealing them falsely, he will report them truthfully.",
                "Given this assumption, we can safely refer to optimal leadership strategies rather than having to use some equilibrium notion.",
                "Hence, for the purposes of this paper, an optimal strategy to commit to in a 2-player game is a strategy s ∈ S that maximizes maxt∈BR(s) ul(s, t), where BR(s) = arg maxt∈T uf (s, t). (ul and uf are the leader and followers utility functions, respectively.)",
                "We can have S = S for the case of commitment to pure strategies, or S = ∆(S), the set of probability distributions over S, for the case of commitment to mixed strategies. (We note that replacing T by ∆(T) makes no difference in this definition.)",
                "For games with more than two players, in which the players commit to their strategies in sequence, we define optimal strategies to commit to recursively.",
                "After the leader commits to a strategy, the game to be played by the remaining agents is itself a (smaller) leadership game.",
                "Thus, we define an optimal strategy to commit to as a strategy that maximizes the leaders utility, assuming that the play of the remaining agents is itself optimal under this definition, and maximizes the leaders utility among all optimal ways to play the remaining game.",
                "Again, commitment to mixed strategies may or may not be a possibility for every player (although for the last player it does not matter if we allow for commitment to mixed strategies). 2.2 Commitment to pure strategies We first study how to compute the optimal pure strategy to commit to.",
                "This is relatively simple, because the number of strategies to commit to is not very large. (In the following, #outcomes is the number of complete strategy profiles.)",
                "Theorem 1.",
                "Under commitment to pure strategies, the set of all optimal strategy profiles in a normal-form game can be found in O(#players · #outcomes) time.",
                "Proof.",
                "Each pure strategy that the first player may commit to will induce a subgame for the remaining players.",
                "We can solve each such subgame recursively to find all of its optimal strategy profiles; each of these will give the original leader some utility.",
                "Those that give the leader maximal utility correspond exactly to the optimal strategy profiles of the original game.",
                "We now present the algorithm formally.",
                "Let Su(G, s1) be the subgame that results after the first (remaining) player in G plays s1 ∈ SG 1 .",
                "A game with 0 players is simply an outcome of the game.",
                "The function Append(s, O) appends the strategy s to each of the vectors of strategies in the set O.",
                "Let e be the empty vector with no elements.",
                "In a slight abuse of notation, we will write uG 1 (C) when all strategy profiles in the set C give player 1 the same utility in the game G. (Here, player 1 is the first remaining player in the subgame G, not necessarily player 1 in the original game.)",
                "We note that arg max is set-valued.",
                "Then, the following algorithm computes all optimal strategy profiles: Algorithm Solve(G) if G has 0 players return {e} C ← ∅ for all s1 ∈ SG 1 { O ← Solve(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) if C = ∅ or uG 1 (s1, O ) = uG 1 (C) C ← C∪Append(s1, O ) if uG 1 (s1, O ) > uG 1 (C) C ←Append(s1, O ) } return C Every outcome is (potentially) examined by every player, which leads to the given runtime bound.",
                "As an example of how the algorithm works, consider the following 3-player game, in which the first player chooses the left or right matrix, the second player chooses a row, and the third player chooses a column. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 3,0,0 First we eliminate the outcomes that do not correspond to best responses for the third player (removing them from the matrix): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Next, we remove the entries in which the third player does not break ties in favor of the second player, as well as entries that do not correspond to best responses for the second player. 0,1,1 2,1,1 1,1,1 0,5,1 Finally, we remove the entries in which the second and third players do not break ties in favor of the first player, as well as entries that do not correspond to best responses for the first player. 2,1,1 84 Hence, in optimal play, the first player chooses the left matrix, the second player chooses the middle row, and the third player chooses the left column. (We note that this outcome is Pareto-dominated by (Right, Middle, Left).)",
                "For general normal-form games, each players utility for each of the outcomes has to be explicitly represented in the input, so that the input size is itself Ω(#players · #outcomes).",
                "Therefore, the algorithm is in fact a linear-time algorithm. 2.3 Commitment to mixed strategies In the special case of two-player zero-sum games, computing an optimal mixed strategy for the leader to commit to is equivalent to computing a minimax strategy, which minimizes the maximum expected utility that the opponent can obtain.",
                "Minimax strategies constitute the only natural solution concept for two-player zero-sum games: von Neumanns Minimax Theorem [24] states that in two-player zero-sum games, it does not matter (in terms of the players utilities) which player gets to commit to a mixed strategy first, and a profile of mixed strategies is a Nash equilibrium if and only if both strategies are minimax strategies.",
                "It is well-known that a minimax strategy can be found in polynomial time, using linear programming [17].",
                "Our first result in this section generalizes this result, showing that an optimal mixed strategy for the leader to commit to can be efficiently computed in general-sum two-player games, again using linear programming.",
                "Theorem 2.",
                "In 2-player normal-form games, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders utility.",
                "Such a mixed strategy can be computed using the following simple linear program: maximize s∈S psul(s, t) subject to for all t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1 We note that this program may be infeasible for some follower strategies t, for example, if t is a strictly dominated strategy.",
                "Nevertheless, the program must be feasible for at least some follower strategies; among these follower strategies, choose a strategy t∗ that maximizes the linear programs solution value.",
                "Then, if the leader chooses as her mixed strategy the optimal settings of the variables ps for the linear program for t∗ , and the follower plays t∗ , this constitutes an optimal strategy profile.",
                "In the following result, we show that we cannot expect to solve the problem more efficiently than linear programming, because we can reduce any linear program with a probability constraint on its variables to a problem of computing the optimal mixed strategy to commit to in a 2-player normalform game.",
                "Theorem 3.",
                "Any linear program whose variables xi (with xi ∈ R≥0 ) must satsify i xi = 1 can be modeled as a problem of computing the optimal mixed strategy to commit to in a 2-player normal-form game.",
                "Proof.",
                "Let the leader have a pure strategy i for every variable xi.",
                "Let the column player have one pure strategy j for every constraint in the linear program (other than i xi = 1), and a single additional pure strategy 0.",
                "Let the utility functions be as follows.",
                "Writing the objective of the linear program as maximize i cixi, for any i, let ul(i, 0) = ci and uf (i, 0) = 0.",
                "Writing the jth constraint of the linear program (not including i xi = 1) as i aijxi ≤ bj, for any i, j > 0, let ul(i, j) = mini ci − 1 and uf (i, j) = aij − bj.",
                "For example, consider the following linear program. maximize 2x1 + x2 subject to x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 The optimal solution to this program is x1 = 1/3, x2 = 2/3.",
                "Our reduction transforms this program into the following leader-follower game (where the leader is the row player). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 Indeed, the optimal strategy for the leader is to play the top strategy with probability 1/3 and the bottom strategy with probability 2/3.",
                "We now show that the reduction works in general.",
                "Clearly, the leader wants to incentivize the follower to play 0, because the utility that the leader gets when the follower plays 0 is always greater than when the follower does not play 0.",
                "In order for the follower not to prefer playing j > 0 rather than 0, it must be the case that i pl(i)(aij − bj) ≤ 0, or equivalently i pl(i)aij ≤ bj.",
                "Hence the leader will get a utility of at least mini ci if and only if there is a feasible solution to the constraints.",
                "Given that the pl(i) incentivize the follower to play 0, the leader attempts to maximize i pl(i)ci.",
                "Thus the leader must solve the original linear program.",
                "As an alternative proof of Theorem 3, one may observe that it is known that finding a minimax strategy in a zerosum game is as hard as the linear programming problem [6], and as we pointed out at the beginning of this section, computing a minimax strategy in a zero-sum game is a special case of the problem of computing an optimal mixed strategy to commit to.",
                "This polynomial-time solvability of the problem of computing an optimal mixed strategy to commit to in two-player normal-form games contrasts with the unknown complexity of computing a Nash equilibrium in such games [21], as well as with the NP-hardness of finding a Nash equilibrium with maximum utility for a given player in such games [8, 2].",
                "Unfortunately, this result does not generalize to more than two players-here, the problem becomes NP-hard.",
                "To show this, we reduce from the VERTEX-COVER problem.",
                "Definition 1.",
                "In VERTEX-COVER, we are given a graph G = (V, E) and an integer K. We are asked whether there 85 exists a subset of the vertices S ⊆ V , with |S| = K, such that every edge e ∈ E has at least one of its endpoints in S. BALANCED-VERTEX-COVER is the special case of VERTEX-COVER in which K = |V |/2.",
                "VERTEX-COVER is NP-complete [9].",
                "The following lemma shows that the hardness remains if we require K = |V |/2. (Similar results have been shown for other NP-complete problems.)",
                "Lemma 1.",
                "BALANCED-VERTEX-COVER is NP-complete.",
                "Proof.",
                "Membership in NP follows from the fact that the problem is a special case of VERTEX-COVER, which is in NP.",
                "To show NP-hardness, we reduce an arbitrary VERTEX-COVER instance to a BALANCED-VERTEXCOVER instance, as follows.",
                "If, for the VERTEX-COVER instance, K > |V |/2, then we simply add isolated vertices that are disjoint from the rest of the graph, until K = |V |/2.",
                "If K < |V |/2, we add isolated triangles (that is, the complete graph on three vertices) to the graph, increasing K by 2 every time, until K = |V |/2.",
                "Theorem 4.",
                "In 3-player normal-form games, finding an optimal mixed strategy to commit to is NP-hard.",
                "Proof.",
                "We reduce an arbitrary BALANCED-VERTEXCOVER instance to the following 3-player normal-form game.",
                "For every vertex v, each of the three players has a pure strategy corresponding to that vertex (rv, sv, tv, respectively).",
                "In addition, for every edge e, the third player has a pure strategy te; and finally, the third player has one additional pure strategy t0.",
                "The utilities are as follows: • for all r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • for all r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • for all v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • for all v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • for all v ∈ V , for all r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V | |V |−2 ; • for all e ∈ E, s ∈ S, for both v ∈ e, u3(rv, s, te) = 0; • for all e ∈ E, s ∈ S, for all v /∈ e, u3(rv, s, te) = |V | |V |−2 . • for all r ∈ R, s ∈ S, u3(r, s, t0) = 1.",
                "We note that players 1 and 2 have the same utility function.",
                "We claim that there is an optimal strategy profile in which players 1 and 2 both obtain 1 (their maximum utility) if and only if there is a solution to the BALANCED-VERTEXCOVER problem. (Otherwise, these players will both obtain 0.)",
                "First, suppose there exists a solution to the BALANCEDVERTEX-COVER problem.",
                "Then, let player 1 play every rv such that v is in the cover with probability 2 |V | , and let player 2 play every sv such that v is not in the cover with probability 2 |V | .",
                "Then, for player 3, the expected utility of playing tv (for any v) is (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of 2 |V | that rv or sv is played.",
                "Additionally, the expected utility of playing te (for any e) is at most (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of at least 2 |V | that some rv with v ∈ e is played (because player 1 is randomizing over the pure strategies corresponding to the cover).",
                "It follows that playing t0 is a best response for player 3, giving players 1 and 2 a utility of 1.",
                "Now, suppose that players 1 and 2 obtain 1 in optimal play.",
                "Then, it must be the case that player 3 plays t0.",
                "Hence, for every v ∈ V , there must be a probability of at least 2 |V | that either rv or sv is played, for otherwise player 3 would be better off playing tv.",
                "Because players 1 and 2 have only a total probability of 2 to distribute, it must be the case that for each v, either rv or sv is played with probability 2 |V | , and the other is played with probability 0. (It is not possible for both to have nonzero probability, because then there would be some probability that both are played simultaneously (correlation is not possible), hence the total probability of at least one being played could not be high enough for all vertices.)",
                "Thus, for exactly half the v ∈ V , player 1 places probability 2 |V | on rv.",
                "Moreover, for every e ∈ E, there must be a probability of at least 2 |V | that some rv with v ∈ e is played, for otherwise player 3 would be better off playing te.",
                "Thus, the v ∈ V such that player 1 places probability 2 |V | on rv constitute a balanced vertex cover. 3.",
                "BAYESIAN GAMES So far, we have restricted our attention to normal-form games.",
                "In a normal-form game, it is assumed that every agent knows every other agents preferences over the outcomes of the game.",
                "In general, however, agents may have some private information about their preferences that is not known to the other agents.",
                "Moreover, at the time of commitment to a strategy, the agents may not even know their own (final) preferences over the outcomes of the game yet, because these preferences may be dependent on a context that has yet to materialize.",
                "For example, when the code for a trading agent is written, it may not yet be clear how that agent will value resources that it will negotiate over later, because this depends on information that is not yet available at the time at which the code is written (such as orders that will have been placed to the agent before the negotiation).",
                "In this section, we will study commitment in Bayesian games, which can model such uncertainty over preferences. 3.1 Definitions In a Bayesian game, every player i has a set of actions Si, a set of types Θi with an associated probability distribution πi : Θi → [0, 1], and, for each type θi, a utility function uθi i : S1 × S2 × . . . × Sn → R. A pure strategy in a Bayesian game is a mapping from the players types to actions, σi : Θi → Si. (Bayesian games can be rewritten in normal form by enumerating every pure strategy σi, but this will cause an exponential blowup in the size of the representation of the game and therefore cannot lead to efficient algorithms.)",
                "The strategy that the leader should commit to depends on whether, at the time of commitment, the leader knows her own type.",
                "If the leader does know her own type, the other types that the leader might have had become irrelevant and the leader should simply commit to the strategy that is optimal for the type.",
                "However, as argued above, the leader does not necessarily know her own type at the time of commitment (e.g., the time at which the code is submitted).",
                "In this case, the leader must commit to a strategy that is 86 dependent upon the leaders eventual type.",
                "We will study this latter model, although we will pay specific attention to the case where the leader has only a single type, which is effectively the same as the former model. 3.2 Commitment to pure strategies It turns out that computing an optimal pure strategy to commit to is hard in Bayesian games, even with two players.",
                "Theorem 5.",
                "Finding an optimal pure strategy to commit to in 2-player Bayesian games is NP-hard, even when the follower has only a single type.",
                "Proof.",
                "We reduce an arbitrary VERTEX-COVER instance to the following Bayesian game between the leader and the follower.",
                "The leader has K types θ1, θ2, . . . , θK , each occurring with probability 1/K, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has only a single type; for each edge e ∈ E, the follower has an action te, and the follower has a single additional action t0.",
                "The utility function for the leader is given by, for all θl ∈ Θl and all s ∈ S, u θl l (s, t0) = 1, and for all e ∈ E, u θl l (s, te) = 0.",
                "The followers utility is given by: • For all v ∈ V , for all e ∈ E with v /∈ e, uf (sv, te) = 1; • For all v ∈ V , for all e ∈ E with v ∈ e, uf (sv, te) = −K; • For all v ∈ V , uf (sv, t0) = 0.",
                "We claim that the leader can get a utility of 1 if and only if there is a solution to the VERTEX-COVER instance.",
                "First, suppose that there is a solution to the VERTEXCOVER instance.",
                "Then, the leader can commit to a pure strategy such that for each vertex v in the cover, the leader plays sv for some type.",
                "Then, the followers utility for playing te (for any e ∈ E) is at most K−1 K + 1 K (−K) = − 1 K , so that the follower will prefer to play t0, which gives the leader a utility of 1, as required.",
                "Now, suppose that there is a pure strategy for the leader that will give the leader a utility of 1.",
                "Then, the follower must play t0.",
                "In order for the follower not to prefer playing te (for any e ∈ E) instead, for at least one v ∈ e the leader must play sv for some type θl.",
                "Hence, the set of vertices v that the leader plays for some type must constitute a vertex cover; and this set can have size at most K, because the leader has only K types.",
                "So there is a solution to the VERTEXCOVER instance.",
                "However, if the leader has only a single type, then the problem becomes easy again (#types is the number of types for the follower): Theorem 6.",
                "In 2-player Bayesian games in which the leader has only a single type, an optimal pure strategy to commit to can be found in O(#outcomes · #types) time.",
                "Proof.",
                "For every leader action s, we can compute, for every follower type θf ∈ Θf , which actions t maximize the followers utility; call this set of actions BRθf (s).",
                "Then, the utility that the leader receives for committing to action s can be computed as θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), and the leader can choose the best action to commit to. 3.3 Commitment to mixed strategies In two-player zero-sum imperfect information games with perfect recall (no player ever forgets something that it once knew), a minimax strategy can be constructed in polynomial time [12, 13].",
                "Unfortunately, this result does not extend to computing optimal mixed strategies to commit to in the general-sum case-not even in Bayesian games.",
                "We will exhibit NP-hardness by reducing from the INDEPENDENTSET problem.",
                "Definition 2.",
                "In INDEPENDENT-SET, we are given a graph G = (V, E) and an integer K. We are asked whether there exists a subset of the vertices S ⊆ V , with |S| = K, such that no edge e ∈ E has both of its endpoints in S. Again, this problem is NP-complete [9].",
                "Theorem 7.",
                "Finding an optimal mixed strategy to commit to in 2-player Bayesian games is NP-hard, even when the leader has only a single type and the follower has only two actions.",
                "Proof.",
                "We reduce an arbitrary INDEPENDENT-SET instance to the following Bayesian game between the leader and the follower.",
                "The leader has only a single type, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has a type θv for every v ∈ V , occurring with probability 1 (|E|+1)|V | , and a type θe for every e ∈ E, occurring with probability 1 |E|+1 .",
                "The follower has two actions: t0 and t1.",
                "The leaders utility is given by, for all s ∈ S, ul(s, t0) = 1 and ul(s, t1) = 0.",
                "The followers utility is given by: • For all v ∈ V , uθv f (sv, t1) = 0; • For all v ∈ V and s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • For all v ∈ V and s ∈ S, uθv f (s, t0) = 1; • For all e ∈ E, s ∈ S, uθe f (s, t0) = 1; • For all e ∈ E, for both v ∈ e, uθe f (sv, t1) = 2K 3 ; • For all e ∈ E, for all v /∈ e, uθe f (sv, t1) = 0.",
                "We claim that an optimal strategy to commit to gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | if and only if there is a solution to the INDEPENDENT-SET instance.",
                "First, suppose that there is a solution to the INDEPENDENT-SET instance.",
                "Then, the leader could commit to the following strategy: for every vertex v in the independent set, play the corresponding sv with probability 1/K.",
                "If the follower has type θe for some e ∈ E, the expected utility for the follower of playing t1 is at most 1 K 2K 3 = 2/3, because there is at most one vertex v ∈ e such that sv is played with nonzero probability.",
                "Hence, the follower will play t0 and obtain a utility of 1.",
                "If the follower has type θv for some vertex v in the independent set, the expected utility for the follower of playing t1 is K−1 K K K−1 = 1, because the leader plays sv with probability 1/K.",
                "It follows that the follower (who breaks ties to maximize the leaders utility) will play t0, which also gives a utility of 1 and gives the leader a higher utility.",
                "Hence the leaders expected utility for this strategy is at least |E| |E|+1 + K (|E|+1)|V | , as required. 87 Now, suppose that there is a strategy that gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | .",
                "Then, this strategy must induce the follower to play t0 whenever it has a type of the form θe (because otherwise, the utility could be at most |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ).",
                "Thus, it cannot be the case that for some edge e = (v1, v2) ∈ E, the probability that the leader plays one of sv1 and sv2 is at least 2/K, because then the expected utility for the follower of playing t1 when it has type θe would be at least 2 K 2K 3 = 4/3 > 1.",
                "Moreover, the strategy must induce the follower to play t0 for at least K types of the form θv.",
                "Inducing the follower to play t0 when it has type θv can be done only by playing sv with probability at least 1/K, which will give the follower a utility of at most K−1 K K K−1 = 1 for playing t1.",
                "But then, the set of vertices v such that sv is played with probability at least 1/K must constitute an independent set of size K (because if there were an edge e between two such vertices, it would induce the follower to play t1 for type θe by the above).",
                "By contrast, if the follower has only a single type, then we can generalize the linear programming approach for normalform games: Theorem 8.",
                "In 2-player Bayesian games in which the follower has only a single type, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "We generalize the approach in Theorem 2 as follows.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader for every one of the leaders types such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders ex ante expected utility.",
                "To do so, we generalize the linear program as follows: maximize θl∈Θl π(θl) s∈S pθl s uθl l (s, t) subject to for all t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t ) for all θl ∈ Θl, s∈S p θl s = 1 As in Theorem 2, the solution for the linear program that maximizes the solution value is an optimal strategy to commit to.",
                "This shows an interesting contrast between commitment to pure strategies and commitment to mixed strategies in Bayesian games: for pure strategies, the problem becomes easy if the leader has only a single type (but not if the follower has only a single type), whereas for mixed strategies, the problem becomes easy if the follower has only a single type (but not if the leader has only a single type). 4.",
                "CONCLUSIONS AND FUTURE RESEARCH In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "This requires some equilibrium notion (Nash equilibrium and its refinements), and often leads to the equilibrium selection problem: it is unclear to each individual player according to which equilibrium she should play.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "For example, one agent may arrive at the (real or virtual) site of the game before the other, or, in the specific case of software agents, the code for one agent may be completed and committed before that of another agent.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "Specifically, if commitment to mixed strategies is possible, then (optimal) commitment never hurts the leader, and often helps.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we studied how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "For normal-form games, we showed that the optimal pure strategy to commit to can be found efficiently for any number of players.",
                "An optimal mixed strategy to commit to in a normal-form game can be found efficiently for two players using linear programming (and no more efficiently than that, in the sense that any linear program with a probability constraint can be encoded as such a problem). (This is a generalization of the polynomial-time computability of minimax strategies in normal-form games.)",
                "The problem becomes NP-hard for three (or more) players.",
                "In Bayesian games, the problem of finding an optimal pure strategy to commit to is NP-hard even in two-player games in which the follower has only a single type, although two-player games in which the leader has only a single type can be solved efficiently.",
                "The problem of finding an optimal mixed strategy to commit to in a Bayesian game is NP-hard even in two-player games in which the leader has only a single type, although two-player games in which the follower has only a single type can be solved efficiently using a generalization of the linear progamming approach for normal-form games.",
                "The following two tables summarize these results. 2 players ≥ 3 players normal-form O(#outcomes) O(#outcomes· #players) Bayesian, O(#outcomes· NP-hard 1-type leader #types) Bayesian, NP-hard NP-hard 1-type follower Bayesian (general) NP-hard NP-hard Results for commitment to pure strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.) 88 2 players ≥ 3 players normal-form one LP-solve per NP-hard follower action Bayesian, NP-hard NP-hard 1-type leader Bayesian, one LP-solve per NP-hard 1-type follower follower action Bayesian (general) NP-hard NP-hard Results for commitment to mixed strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.)",
                "Future research can take a number of directions.",
                "First, we can empirically evaluate the techniques presented here on test suites such as GAMUT [19].",
                "We can also study the computation of optimal strategies to commit to in other1 concise representations of normal-form games-for example, in graphical games [10] or local-effect/action graph games [14, 1].",
                "For the cases where computing an optimal strategy to commit to is NP-hard, we can also study the computation of approximately optimal strategies to commit to.",
                "While the correct definition of an approximately optimal strategy is in this setting may appear simple at first-it should be a strategy that, if the following players play optimally, performs almost as well as the optimal strategy in expectation-this definition becomes problematic when we consider that the other players may also be playing only approximately optimally.",
                "One may also study models in which multiple (but not all) players commit at the same time.",
                "Another interesting direction to pursue is to see if computing optimal mixed strategies to commit to can help us in, or otherwise shed light on, computing Nash equilibria.",
                "Often, optimal mixed strategies to commit to are also Nash equilibrium strategies (for example, in two-player zero-sum games this is always true), although this is not always the case (for example, as we already pointed out, sometimes the optimal strategy to commit to is a strictly dominated strategy, which can never be a Nash equilibrium strategy). 5.",
                "REFERENCES [1] N. A. R. Bhat and K. Leyton-Brown.",
                "Computing Nash equilibria of action-graph games.",
                "In Proceedings of the 20th Annual Conference on Uncertainty in Artificial Intelligence (UAI), Banff, Canada, 2004. [2] V. Conitzer and T. Sandholm.",
                "Complexity results about Nash equilibria.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pages 765-771, Acapulco, Mexico, 2003. [3] V. Conitzer and T. Sandholm.",
                "Complexity of (iterated) dominance.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 88-97, Vancouver, Canada, 2005. [4] V. Conitzer and T. Sandholm.",
                "A generalized strategy eliminability criterion and computational methods for applying it.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 483-488, Pittsburgh, PA, USA, 2005. [5] A.",
                "A. Cournot.",
                "Recherches sur les principes math´ematiques de la th´eorie des richesses (Researches 1 Bayesian games are one potentially concise representation of normal-form games. into the Mathematical Principles of the Theory of Wealth).",
                "Hachette, Paris, 1838. [6] G. Dantzig.",
                "A proof of the equivalence of the programming problem and the game problem.",
                "In T. Koopmans, editor, Activity Analysis of Production and Allocation, pages 330-335.",
                "John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel.",
                "The complexity of eliminating dominated strategies.",
                "Mathematics of Operation Research, 18:553-565, 1993. [8] I. Gilboa and E. Zemel.",
                "Nash and correlated equilibria: Some complexity considerations.",
                "Games and Economic Behavior, 1:80-93, 1989. [9] R. Karp.",
                "Reducibility among combinatorial problems.",
                "In R. E. Miller and J. W. Thatcher, editors, Complexity of Computer Computations, pages 85-103.",
                "Plenum Press, NY, 1972. [10] M. Kearns, M. Littman, and S. Singh.",
                "Graphical models for game theory.",
                "In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou, and J. N. Tsitsiklis.",
                "A note on strategy elimination in bimatrix games.",
                "Operations Research Letters, 7(3):103-107, 1988. [12] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [14] K. Leyton-Brown and M. Tennenholtz.",
                "Local-effect games.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), Acapulco, Mexico, 2003. [15] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 36-41, San Diego, CA, 2003. [16] M. Littman and P. Stone.",
                "A polynomial-time Nash equilibrium algorithm for repeated games.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 48-54, San Diego, CA, 2003. [17] R. D. Luce and H. Raiffa.",
                "Games and Decisions.",
                "John Wiley and Sons, New York, 1957.",
                "Dover republication 1989. [18] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown, and Y. Shoham.",
                "Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms.",
                "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), New York, NY, USA, 2004. [20] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "MIT Press, 1994. [21] C. Papadimitriou.",
                "Algorithms, games and the Internet.",
                "In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 749-753, 2001. 89 [22] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 664-669, San Jose, CA, USA, 2004. [23] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 495-501, Pittsburgh, PA, USA, 2005. [24] J. von Neumann.",
                "Zur Theorie der Gesellschaftsspiele.",
                "Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg.",
                "Marktform und Gleichgewicht.",
                "Springer, Vienna, 1934. [26] B. von Stengel and S. Zamir.",
                "Leadership with commitment to mixed strategies.",
                "CDAM Research Report LSE-CDAM-2004-01, London School of Economics, Feb. 2004. 90"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "leadership model": {
            "translated_key": "modelos de liderazgo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Computing the Optimal Strategy to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored <br>leadership model</br>s (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "We give both positive results (efficient algorithms) and negative results (NP-hardness results).",
                "Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent systems with self-interested agents (including most economic settings), the optimal action for one agent to take depends on the actions that the other agents take.",
                "To analyze how an agent should behave in such settings, the tools of game theory need to be applied.",
                "Typically, when a strategic setting is modeled in the framework of game theory, it is assumed that players choose their strategies simultaneously.",
                "This is especially true when the setting is modeled as a normal-form game, which only specifies each agents utility as a function of the vector of strategies that the agents choose, and does not provide any information on the order in which agents make their decisions and what the agents observe about earlier decisions by other agents.",
                "Given that the game is modeled in normal form, it is typically analyzed using the concept of Nash equilibrium.",
                "A Nash equilibrium specifies a strategy for each player, such that no player has an incentive to individually deviate from this profile of strategies. (Typically, the strategies are allowed to be mixed, that is, probability distributions over the original (pure) strategies.)",
                "A (mixed-strategy) Nash equilibrium is guaranteed to exist in finite games [18], but one problem is that there may be multiple Nash equilibria.",
                "This leads to the equilibrium selection problem of how an agent can know which strategy to play if it does not know which equilibrium is to be played.",
                "When the setting is modeled as an extensive-form game, it is possible to specify that some players receive some information about actions taken by others earlier in the game before deciding on their action.",
                "Nevertheless, in general, the players do not know everything that happened earlier in the game.",
                "Because of this, these games are typically still analyzed using an equilibrium concept, where one specifies a mixed strategy for each player, and requires that each players strategy is a best response to the others strategies. (Typically an additional constraint on the strategies is now imposed to ensure that players do not play in a way that is irrational with respect to the information that they have received so far.",
                "This leads to refinements of Nash equilibrium such as subgame perfect and sequential equilibrium.)",
                "However, in many real-world settings, strategies are not selected in such a simultaneous manner.",
                "Oftentimes, one player (the leader) is able to commit to a strategy before another player (the follower).",
                "This can be due to a variety of reasons.",
                "For example, one of the players may arrive at the site at which the game is to be played before another agent (e.g., in economic settings, one player may enter a market earlier and commit to a way of doing busi82 ness).",
                "Such commitment power has a profound impact on how the game should be played.",
                "For example, the leader may be best off playing a strategy that is dominated in the normal-form representation of the game.",
                "Perhaps the earliest and best-known example of the effect of commitment is that by von Stackelberg [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution.",
                "In general, if commitment to mixed strategies is possible, then (under minor assumptions) it never hurts, and often helps, to commit to a strategy [26].",
                "Being forced to commit to a pure strategy sometimes helps, and sometimes hurts (for example, committing to a pure strategy in rock-paper-scissors before the other players decision will naturally result in a loss).",
                "In this paper, we will assume commitment is always forced; if it is not, the player who has the choice of whether to commit can simply compare the commitment outcome to the non-commitment (simultaneous-move) outcome.",
                "Models of leadership are especially important in settings with multiple self-interested software agents.",
                "Once the code for an agent (or for a team of agents) is finalized and the agent is deployed, the agent is committed to playing the (possibly randomized) strategy that the code prescribes.",
                "Thus, as long as one can credibly show that one cannot change the code later, the code serves as a commitment device.",
                "This holds true for recreational tournaments among agents (e.g., poker tournaments, RoboSoccer), and for industrial applications such as sensor webs.",
                "Finally, there is also an implicit leadership situation in the field of mechanism design, in which one player (the designer) gets to choose the rules of the game that the remaining players then play.",
                "Mechanism design is an extremely important topic to the EC community: the papers published on mechanism design in recent EC conferences are too numerous to cite.",
                "Indeed, the mechanism designer may benefit from committing to a choice that, if the (remaining) agents actions were fixed, would be suboptimal.",
                "For example, in a (first-price) auction, the seller may wish to set a positive (artificial) reserve price for the item, below which the item will not be sold-even if the seller values the item at 0.",
                "In hindsight (after the bids have come in), this (na¨ıvely) appears suboptimal: if a bid exceeding the reserve price came in, the reserve price had no effect, and if no such bid came in, the seller would have been better off accepting a lower bid.",
                "Of course, the reason for setting the reserve price is that it incentivizes the bidders to bid higher, and because of this, setting artificial reserve prices can actually increase expected revenue to the seller.",
                "A significant amount of research has recently been devoted to the computation of solutions according to various solution concepts for settings in which the agents choose their strategies simultaneously, such as dominance [7, 11, 3] and (especially) Nash equilibrium [8, 21, 16, 15, 2, 22, 23, 4].",
                "However, the computation of the optimal strategy to commit to in a leadership situation has gone ignored.",
                "Theoretically, leadership situations can simply be thought of as an extensive-form game in which one player chooses a strategy (for the original game) first.",
                "The number of strategies in this extensive-form game, however, can be exceedingly large.",
                "For example, if the leader is able to commit to a mixed strategy in the original game, then every one of the (continuum of) mixed strategies constitutes a pure strategy in the extensive-form representation of the leadership situation. (We note that a commitment to a distribution is not the same as a distribution over commitments.)",
                "Moreover, if the original game is itself an extensive-form game, the number of strategies in the extensive-form representation of the leadership situation (which is a different extensive-form game) becomes even larger.",
                "Because of this, it is usually not computationally feasible to simply transform the original game into the extensive-form representation of the leadership situation; instead, we have to analyze the game in its original representation.",
                "In this paper, we study how to compute the optimal strategy to commit to, both in normal-form games (Section 2) and in Bayesian games, which are a special case of extensiveform games (Section 3). 2.",
                "NORMAL-FORM GAMES In this section, we study how to compute the optimal strategy to commit to for games represented in normal form. 2.1 Definitions In a normal-form game, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a pure strategy for every player, also known as a profile of pure strategies) to a real number.",
                "To ease notation, in the case of two players, we will refer to player 1s pure strategy set as S, and player 2s pure strategy set as T. Such games can be represented in (bi-)matrix form, in which the rows correspond to player 1s pure strategies, the columns correspond to player 2s pure strategies, and the entries of the matrix give the row and column players utilities (in that order) for the corresponding outcome of the game.",
                "In the case of three players, we will use R, S, and T, for player 1, 2, and 3s pure strategies, respectively.",
                "A mixed strategy for a player is a probability distribution over that players pure strategies.",
                "In the case of two-player games, we will refer to player 1 as the leader and player 2 as the follower.",
                "Before defining optimal leadership strategies, consider the following game which illustrates the effect of the leaders ability to commit. 2, 1 4, 0 1, 0 3, 1 In this normal-form representation, the bottom strategy for the row player is strictly dominated by the top strategy.",
                "Nevertheless, if the row player has the ability to commit to a pure strategy before the column player chooses his strategy, the row player should commit to the bottom strategy: doing so will make the column player prefer to play the right strategy, leading to a utility of 3 for the row player.",
                "By contrast, if the row player were to commit to the top strategy, the column player would prefer to play the left strategy, leading to a utility of only 2 for the row player.",
                "If the row player is able to commit to a mixed strategy, then she can get an even greater (expected) utility: if the row player commits to placing probability p > 1/2 on the bottom strategy, then the column player will still prefer to play the right strategy, and the row players expected utility will be 3p + 4(1 − p) = 4 − p ≥ 3.",
                "If the row player plays each strategy with probability exactly 1/2, the column player is 83 indifferent between the strategies.",
                "In such cases, we will assume that the column player will choose the strategy that maximizes the row players utility (in this case, the right strategy).",
                "Hence, the optimal mixed strategy to commit to for the row player is p = 1/2.",
                "There are a few good reasons for this assumption.",
                "If we were to assume the opposite, then there would not exist an optimal strategy for the row player in the example game: the row player would play the bottom strategy with probability p = 1/2 + with > 0, and the smaller , the better the utility for the row player.",
                "By contrast, if we assume that the follower always breaks ties in the leaders favor, then an optimal mixed strategy for the leader always exists, and this corresponds to a subgame perfect equilibrium of the extensive-form representation of the leadership situation.",
                "In any case, this is a standard assumption for such models (e.g. [20]), although some work has investigated what can happen in the other subgame perfect equilibria [26]. (For generic two-player games, the leaders subgame-perfect equilibrium payoff is unique.)",
                "Also, the same assumption is typically used in mechanism design, in that it is assumed that if an agent is indifferent between revealing his preferences truthfully and revealing them falsely, he will report them truthfully.",
                "Given this assumption, we can safely refer to optimal leadership strategies rather than having to use some equilibrium notion.",
                "Hence, for the purposes of this paper, an optimal strategy to commit to in a 2-player game is a strategy s ∈ S that maximizes maxt∈BR(s) ul(s, t), where BR(s) = arg maxt∈T uf (s, t). (ul and uf are the leader and followers utility functions, respectively.)",
                "We can have S = S for the case of commitment to pure strategies, or S = ∆(S), the set of probability distributions over S, for the case of commitment to mixed strategies. (We note that replacing T by ∆(T) makes no difference in this definition.)",
                "For games with more than two players, in which the players commit to their strategies in sequence, we define optimal strategies to commit to recursively.",
                "After the leader commits to a strategy, the game to be played by the remaining agents is itself a (smaller) leadership game.",
                "Thus, we define an optimal strategy to commit to as a strategy that maximizes the leaders utility, assuming that the play of the remaining agents is itself optimal under this definition, and maximizes the leaders utility among all optimal ways to play the remaining game.",
                "Again, commitment to mixed strategies may or may not be a possibility for every player (although for the last player it does not matter if we allow for commitment to mixed strategies). 2.2 Commitment to pure strategies We first study how to compute the optimal pure strategy to commit to.",
                "This is relatively simple, because the number of strategies to commit to is not very large. (In the following, #outcomes is the number of complete strategy profiles.)",
                "Theorem 1.",
                "Under commitment to pure strategies, the set of all optimal strategy profiles in a normal-form game can be found in O(#players · #outcomes) time.",
                "Proof.",
                "Each pure strategy that the first player may commit to will induce a subgame for the remaining players.",
                "We can solve each such subgame recursively to find all of its optimal strategy profiles; each of these will give the original leader some utility.",
                "Those that give the leader maximal utility correspond exactly to the optimal strategy profiles of the original game.",
                "We now present the algorithm formally.",
                "Let Su(G, s1) be the subgame that results after the first (remaining) player in G plays s1 ∈ SG 1 .",
                "A game with 0 players is simply an outcome of the game.",
                "The function Append(s, O) appends the strategy s to each of the vectors of strategies in the set O.",
                "Let e be the empty vector with no elements.",
                "In a slight abuse of notation, we will write uG 1 (C) when all strategy profiles in the set C give player 1 the same utility in the game G. (Here, player 1 is the first remaining player in the subgame G, not necessarily player 1 in the original game.)",
                "We note that arg max is set-valued.",
                "Then, the following algorithm computes all optimal strategy profiles: Algorithm Solve(G) if G has 0 players return {e} C ← ∅ for all s1 ∈ SG 1 { O ← Solve(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) if C = ∅ or uG 1 (s1, O ) = uG 1 (C) C ← C∪Append(s1, O ) if uG 1 (s1, O ) > uG 1 (C) C ←Append(s1, O ) } return C Every outcome is (potentially) examined by every player, which leads to the given runtime bound.",
                "As an example of how the algorithm works, consider the following 3-player game, in which the first player chooses the left or right matrix, the second player chooses a row, and the third player chooses a column. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 3,0,0 First we eliminate the outcomes that do not correspond to best responses for the third player (removing them from the matrix): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Next, we remove the entries in which the third player does not break ties in favor of the second player, as well as entries that do not correspond to best responses for the second player. 0,1,1 2,1,1 1,1,1 0,5,1 Finally, we remove the entries in which the second and third players do not break ties in favor of the first player, as well as entries that do not correspond to best responses for the first player. 2,1,1 84 Hence, in optimal play, the first player chooses the left matrix, the second player chooses the middle row, and the third player chooses the left column. (We note that this outcome is Pareto-dominated by (Right, Middle, Left).)",
                "For general normal-form games, each players utility for each of the outcomes has to be explicitly represented in the input, so that the input size is itself Ω(#players · #outcomes).",
                "Therefore, the algorithm is in fact a linear-time algorithm. 2.3 Commitment to mixed strategies In the special case of two-player zero-sum games, computing an optimal mixed strategy for the leader to commit to is equivalent to computing a minimax strategy, which minimizes the maximum expected utility that the opponent can obtain.",
                "Minimax strategies constitute the only natural solution concept for two-player zero-sum games: von Neumanns Minimax Theorem [24] states that in two-player zero-sum games, it does not matter (in terms of the players utilities) which player gets to commit to a mixed strategy first, and a profile of mixed strategies is a Nash equilibrium if and only if both strategies are minimax strategies.",
                "It is well-known that a minimax strategy can be found in polynomial time, using linear programming [17].",
                "Our first result in this section generalizes this result, showing that an optimal mixed strategy for the leader to commit to can be efficiently computed in general-sum two-player games, again using linear programming.",
                "Theorem 2.",
                "In 2-player normal-form games, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders utility.",
                "Such a mixed strategy can be computed using the following simple linear program: maximize s∈S psul(s, t) subject to for all t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1 We note that this program may be infeasible for some follower strategies t, for example, if t is a strictly dominated strategy.",
                "Nevertheless, the program must be feasible for at least some follower strategies; among these follower strategies, choose a strategy t∗ that maximizes the linear programs solution value.",
                "Then, if the leader chooses as her mixed strategy the optimal settings of the variables ps for the linear program for t∗ , and the follower plays t∗ , this constitutes an optimal strategy profile.",
                "In the following result, we show that we cannot expect to solve the problem more efficiently than linear programming, because we can reduce any linear program with a probability constraint on its variables to a problem of computing the optimal mixed strategy to commit to in a 2-player normalform game.",
                "Theorem 3.",
                "Any linear program whose variables xi (with xi ∈ R≥0 ) must satsify i xi = 1 can be modeled as a problem of computing the optimal mixed strategy to commit to in a 2-player normal-form game.",
                "Proof.",
                "Let the leader have a pure strategy i for every variable xi.",
                "Let the column player have one pure strategy j for every constraint in the linear program (other than i xi = 1), and a single additional pure strategy 0.",
                "Let the utility functions be as follows.",
                "Writing the objective of the linear program as maximize i cixi, for any i, let ul(i, 0) = ci and uf (i, 0) = 0.",
                "Writing the jth constraint of the linear program (not including i xi = 1) as i aijxi ≤ bj, for any i, j > 0, let ul(i, j) = mini ci − 1 and uf (i, j) = aij − bj.",
                "For example, consider the following linear program. maximize 2x1 + x2 subject to x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 The optimal solution to this program is x1 = 1/3, x2 = 2/3.",
                "Our reduction transforms this program into the following leader-follower game (where the leader is the row player). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 Indeed, the optimal strategy for the leader is to play the top strategy with probability 1/3 and the bottom strategy with probability 2/3.",
                "We now show that the reduction works in general.",
                "Clearly, the leader wants to incentivize the follower to play 0, because the utility that the leader gets when the follower plays 0 is always greater than when the follower does not play 0.",
                "In order for the follower not to prefer playing j > 0 rather than 0, it must be the case that i pl(i)(aij − bj) ≤ 0, or equivalently i pl(i)aij ≤ bj.",
                "Hence the leader will get a utility of at least mini ci if and only if there is a feasible solution to the constraints.",
                "Given that the pl(i) incentivize the follower to play 0, the leader attempts to maximize i pl(i)ci.",
                "Thus the leader must solve the original linear program.",
                "As an alternative proof of Theorem 3, one may observe that it is known that finding a minimax strategy in a zerosum game is as hard as the linear programming problem [6], and as we pointed out at the beginning of this section, computing a minimax strategy in a zero-sum game is a special case of the problem of computing an optimal mixed strategy to commit to.",
                "This polynomial-time solvability of the problem of computing an optimal mixed strategy to commit to in two-player normal-form games contrasts with the unknown complexity of computing a Nash equilibrium in such games [21], as well as with the NP-hardness of finding a Nash equilibrium with maximum utility for a given player in such games [8, 2].",
                "Unfortunately, this result does not generalize to more than two players-here, the problem becomes NP-hard.",
                "To show this, we reduce from the VERTEX-COVER problem.",
                "Definition 1.",
                "In VERTEX-COVER, we are given a graph G = (V, E) and an integer K. We are asked whether there 85 exists a subset of the vertices S ⊆ V , with |S| = K, such that every edge e ∈ E has at least one of its endpoints in S. BALANCED-VERTEX-COVER is the special case of VERTEX-COVER in which K = |V |/2.",
                "VERTEX-COVER is NP-complete [9].",
                "The following lemma shows that the hardness remains if we require K = |V |/2. (Similar results have been shown for other NP-complete problems.)",
                "Lemma 1.",
                "BALANCED-VERTEX-COVER is NP-complete.",
                "Proof.",
                "Membership in NP follows from the fact that the problem is a special case of VERTEX-COVER, which is in NP.",
                "To show NP-hardness, we reduce an arbitrary VERTEX-COVER instance to a BALANCED-VERTEXCOVER instance, as follows.",
                "If, for the VERTEX-COVER instance, K > |V |/2, then we simply add isolated vertices that are disjoint from the rest of the graph, until K = |V |/2.",
                "If K < |V |/2, we add isolated triangles (that is, the complete graph on three vertices) to the graph, increasing K by 2 every time, until K = |V |/2.",
                "Theorem 4.",
                "In 3-player normal-form games, finding an optimal mixed strategy to commit to is NP-hard.",
                "Proof.",
                "We reduce an arbitrary BALANCED-VERTEXCOVER instance to the following 3-player normal-form game.",
                "For every vertex v, each of the three players has a pure strategy corresponding to that vertex (rv, sv, tv, respectively).",
                "In addition, for every edge e, the third player has a pure strategy te; and finally, the third player has one additional pure strategy t0.",
                "The utilities are as follows: • for all r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • for all r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • for all v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • for all v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • for all v ∈ V , for all r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V | |V |−2 ; • for all e ∈ E, s ∈ S, for both v ∈ e, u3(rv, s, te) = 0; • for all e ∈ E, s ∈ S, for all v /∈ e, u3(rv, s, te) = |V | |V |−2 . • for all r ∈ R, s ∈ S, u3(r, s, t0) = 1.",
                "We note that players 1 and 2 have the same utility function.",
                "We claim that there is an optimal strategy profile in which players 1 and 2 both obtain 1 (their maximum utility) if and only if there is a solution to the BALANCED-VERTEXCOVER problem. (Otherwise, these players will both obtain 0.)",
                "First, suppose there exists a solution to the BALANCEDVERTEX-COVER problem.",
                "Then, let player 1 play every rv such that v is in the cover with probability 2 |V | , and let player 2 play every sv such that v is not in the cover with probability 2 |V | .",
                "Then, for player 3, the expected utility of playing tv (for any v) is (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of 2 |V | that rv or sv is played.",
                "Additionally, the expected utility of playing te (for any e) is at most (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of at least 2 |V | that some rv with v ∈ e is played (because player 1 is randomizing over the pure strategies corresponding to the cover).",
                "It follows that playing t0 is a best response for player 3, giving players 1 and 2 a utility of 1.",
                "Now, suppose that players 1 and 2 obtain 1 in optimal play.",
                "Then, it must be the case that player 3 plays t0.",
                "Hence, for every v ∈ V , there must be a probability of at least 2 |V | that either rv or sv is played, for otherwise player 3 would be better off playing tv.",
                "Because players 1 and 2 have only a total probability of 2 to distribute, it must be the case that for each v, either rv or sv is played with probability 2 |V | , and the other is played with probability 0. (It is not possible for both to have nonzero probability, because then there would be some probability that both are played simultaneously (correlation is not possible), hence the total probability of at least one being played could not be high enough for all vertices.)",
                "Thus, for exactly half the v ∈ V , player 1 places probability 2 |V | on rv.",
                "Moreover, for every e ∈ E, there must be a probability of at least 2 |V | that some rv with v ∈ e is played, for otherwise player 3 would be better off playing te.",
                "Thus, the v ∈ V such that player 1 places probability 2 |V | on rv constitute a balanced vertex cover. 3.",
                "BAYESIAN GAMES So far, we have restricted our attention to normal-form games.",
                "In a normal-form game, it is assumed that every agent knows every other agents preferences over the outcomes of the game.",
                "In general, however, agents may have some private information about their preferences that is not known to the other agents.",
                "Moreover, at the time of commitment to a strategy, the agents may not even know their own (final) preferences over the outcomes of the game yet, because these preferences may be dependent on a context that has yet to materialize.",
                "For example, when the code for a trading agent is written, it may not yet be clear how that agent will value resources that it will negotiate over later, because this depends on information that is not yet available at the time at which the code is written (such as orders that will have been placed to the agent before the negotiation).",
                "In this section, we will study commitment in Bayesian games, which can model such uncertainty over preferences. 3.1 Definitions In a Bayesian game, every player i has a set of actions Si, a set of types Θi with an associated probability distribution πi : Θi → [0, 1], and, for each type θi, a utility function uθi i : S1 × S2 × . . . × Sn → R. A pure strategy in a Bayesian game is a mapping from the players types to actions, σi : Θi → Si. (Bayesian games can be rewritten in normal form by enumerating every pure strategy σi, but this will cause an exponential blowup in the size of the representation of the game and therefore cannot lead to efficient algorithms.)",
                "The strategy that the leader should commit to depends on whether, at the time of commitment, the leader knows her own type.",
                "If the leader does know her own type, the other types that the leader might have had become irrelevant and the leader should simply commit to the strategy that is optimal for the type.",
                "However, as argued above, the leader does not necessarily know her own type at the time of commitment (e.g., the time at which the code is submitted).",
                "In this case, the leader must commit to a strategy that is 86 dependent upon the leaders eventual type.",
                "We will study this latter model, although we will pay specific attention to the case where the leader has only a single type, which is effectively the same as the former model. 3.2 Commitment to pure strategies It turns out that computing an optimal pure strategy to commit to is hard in Bayesian games, even with two players.",
                "Theorem 5.",
                "Finding an optimal pure strategy to commit to in 2-player Bayesian games is NP-hard, even when the follower has only a single type.",
                "Proof.",
                "We reduce an arbitrary VERTEX-COVER instance to the following Bayesian game between the leader and the follower.",
                "The leader has K types θ1, θ2, . . . , θK , each occurring with probability 1/K, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has only a single type; for each edge e ∈ E, the follower has an action te, and the follower has a single additional action t0.",
                "The utility function for the leader is given by, for all θl ∈ Θl and all s ∈ S, u θl l (s, t0) = 1, and for all e ∈ E, u θl l (s, te) = 0.",
                "The followers utility is given by: • For all v ∈ V , for all e ∈ E with v /∈ e, uf (sv, te) = 1; • For all v ∈ V , for all e ∈ E with v ∈ e, uf (sv, te) = −K; • For all v ∈ V , uf (sv, t0) = 0.",
                "We claim that the leader can get a utility of 1 if and only if there is a solution to the VERTEX-COVER instance.",
                "First, suppose that there is a solution to the VERTEXCOVER instance.",
                "Then, the leader can commit to a pure strategy such that for each vertex v in the cover, the leader plays sv for some type.",
                "Then, the followers utility for playing te (for any e ∈ E) is at most K−1 K + 1 K (−K) = − 1 K , so that the follower will prefer to play t0, which gives the leader a utility of 1, as required.",
                "Now, suppose that there is a pure strategy for the leader that will give the leader a utility of 1.",
                "Then, the follower must play t0.",
                "In order for the follower not to prefer playing te (for any e ∈ E) instead, for at least one v ∈ e the leader must play sv for some type θl.",
                "Hence, the set of vertices v that the leader plays for some type must constitute a vertex cover; and this set can have size at most K, because the leader has only K types.",
                "So there is a solution to the VERTEXCOVER instance.",
                "However, if the leader has only a single type, then the problem becomes easy again (#types is the number of types for the follower): Theorem 6.",
                "In 2-player Bayesian games in which the leader has only a single type, an optimal pure strategy to commit to can be found in O(#outcomes · #types) time.",
                "Proof.",
                "For every leader action s, we can compute, for every follower type θf ∈ Θf , which actions t maximize the followers utility; call this set of actions BRθf (s).",
                "Then, the utility that the leader receives for committing to action s can be computed as θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), and the leader can choose the best action to commit to. 3.3 Commitment to mixed strategies In two-player zero-sum imperfect information games with perfect recall (no player ever forgets something that it once knew), a minimax strategy can be constructed in polynomial time [12, 13].",
                "Unfortunately, this result does not extend to computing optimal mixed strategies to commit to in the general-sum case-not even in Bayesian games.",
                "We will exhibit NP-hardness by reducing from the INDEPENDENTSET problem.",
                "Definition 2.",
                "In INDEPENDENT-SET, we are given a graph G = (V, E) and an integer K. We are asked whether there exists a subset of the vertices S ⊆ V , with |S| = K, such that no edge e ∈ E has both of its endpoints in S. Again, this problem is NP-complete [9].",
                "Theorem 7.",
                "Finding an optimal mixed strategy to commit to in 2-player Bayesian games is NP-hard, even when the leader has only a single type and the follower has only two actions.",
                "Proof.",
                "We reduce an arbitrary INDEPENDENT-SET instance to the following Bayesian game between the leader and the follower.",
                "The leader has only a single type, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has a type θv for every v ∈ V , occurring with probability 1 (|E|+1)|V | , and a type θe for every e ∈ E, occurring with probability 1 |E|+1 .",
                "The follower has two actions: t0 and t1.",
                "The leaders utility is given by, for all s ∈ S, ul(s, t0) = 1 and ul(s, t1) = 0.",
                "The followers utility is given by: • For all v ∈ V , uθv f (sv, t1) = 0; • For all v ∈ V and s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • For all v ∈ V and s ∈ S, uθv f (s, t0) = 1; • For all e ∈ E, s ∈ S, uθe f (s, t0) = 1; • For all e ∈ E, for both v ∈ e, uθe f (sv, t1) = 2K 3 ; • For all e ∈ E, for all v /∈ e, uθe f (sv, t1) = 0.",
                "We claim that an optimal strategy to commit to gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | if and only if there is a solution to the INDEPENDENT-SET instance.",
                "First, suppose that there is a solution to the INDEPENDENT-SET instance.",
                "Then, the leader could commit to the following strategy: for every vertex v in the independent set, play the corresponding sv with probability 1/K.",
                "If the follower has type θe for some e ∈ E, the expected utility for the follower of playing t1 is at most 1 K 2K 3 = 2/3, because there is at most one vertex v ∈ e such that sv is played with nonzero probability.",
                "Hence, the follower will play t0 and obtain a utility of 1.",
                "If the follower has type θv for some vertex v in the independent set, the expected utility for the follower of playing t1 is K−1 K K K−1 = 1, because the leader plays sv with probability 1/K.",
                "It follows that the follower (who breaks ties to maximize the leaders utility) will play t0, which also gives a utility of 1 and gives the leader a higher utility.",
                "Hence the leaders expected utility for this strategy is at least |E| |E|+1 + K (|E|+1)|V | , as required. 87 Now, suppose that there is a strategy that gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | .",
                "Then, this strategy must induce the follower to play t0 whenever it has a type of the form θe (because otherwise, the utility could be at most |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ).",
                "Thus, it cannot be the case that for some edge e = (v1, v2) ∈ E, the probability that the leader plays one of sv1 and sv2 is at least 2/K, because then the expected utility for the follower of playing t1 when it has type θe would be at least 2 K 2K 3 = 4/3 > 1.",
                "Moreover, the strategy must induce the follower to play t0 for at least K types of the form θv.",
                "Inducing the follower to play t0 when it has type θv can be done only by playing sv with probability at least 1/K, which will give the follower a utility of at most K−1 K K K−1 = 1 for playing t1.",
                "But then, the set of vertices v such that sv is played with probability at least 1/K must constitute an independent set of size K (because if there were an edge e between two such vertices, it would induce the follower to play t1 for type θe by the above).",
                "By contrast, if the follower has only a single type, then we can generalize the linear programming approach for normalform games: Theorem 8.",
                "In 2-player Bayesian games in which the follower has only a single type, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "We generalize the approach in Theorem 2 as follows.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader for every one of the leaders types such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders ex ante expected utility.",
                "To do so, we generalize the linear program as follows: maximize θl∈Θl π(θl) s∈S pθl s uθl l (s, t) subject to for all t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t ) for all θl ∈ Θl, s∈S p θl s = 1 As in Theorem 2, the solution for the linear program that maximizes the solution value is an optimal strategy to commit to.",
                "This shows an interesting contrast between commitment to pure strategies and commitment to mixed strategies in Bayesian games: for pure strategies, the problem becomes easy if the leader has only a single type (but not if the follower has only a single type), whereas for mixed strategies, the problem becomes easy if the follower has only a single type (but not if the leader has only a single type). 4.",
                "CONCLUSIONS AND FUTURE RESEARCH In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "This requires some equilibrium notion (Nash equilibrium and its refinements), and often leads to the equilibrium selection problem: it is unclear to each individual player according to which equilibrium she should play.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "For example, one agent may arrive at the (real or virtual) site of the game before the other, or, in the specific case of software agents, the code for one agent may be completed and committed before that of another agent.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "Specifically, if commitment to mixed strategies is possible, then (optimal) commitment never hurts the leader, and often helps.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored <br>leadership model</br>s (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we studied how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "For normal-form games, we showed that the optimal pure strategy to commit to can be found efficiently for any number of players.",
                "An optimal mixed strategy to commit to in a normal-form game can be found efficiently for two players using linear programming (and no more efficiently than that, in the sense that any linear program with a probability constraint can be encoded as such a problem). (This is a generalization of the polynomial-time computability of minimax strategies in normal-form games.)",
                "The problem becomes NP-hard for three (or more) players.",
                "In Bayesian games, the problem of finding an optimal pure strategy to commit to is NP-hard even in two-player games in which the follower has only a single type, although two-player games in which the leader has only a single type can be solved efficiently.",
                "The problem of finding an optimal mixed strategy to commit to in a Bayesian game is NP-hard even in two-player games in which the leader has only a single type, although two-player games in which the follower has only a single type can be solved efficiently using a generalization of the linear progamming approach for normal-form games.",
                "The following two tables summarize these results. 2 players ≥ 3 players normal-form O(#outcomes) O(#outcomes· #players) Bayesian, O(#outcomes· NP-hard 1-type leader #types) Bayesian, NP-hard NP-hard 1-type follower Bayesian (general) NP-hard NP-hard Results for commitment to pure strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.) 88 2 players ≥ 3 players normal-form one LP-solve per NP-hard follower action Bayesian, NP-hard NP-hard 1-type leader Bayesian, one LP-solve per NP-hard 1-type follower follower action Bayesian (general) NP-hard NP-hard Results for commitment to mixed strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.)",
                "Future research can take a number of directions.",
                "First, we can empirically evaluate the techniques presented here on test suites such as GAMUT [19].",
                "We can also study the computation of optimal strategies to commit to in other1 concise representations of normal-form games-for example, in graphical games [10] or local-effect/action graph games [14, 1].",
                "For the cases where computing an optimal strategy to commit to is NP-hard, we can also study the computation of approximately optimal strategies to commit to.",
                "While the correct definition of an approximately optimal strategy is in this setting may appear simple at first-it should be a strategy that, if the following players play optimally, performs almost as well as the optimal strategy in expectation-this definition becomes problematic when we consider that the other players may also be playing only approximately optimally.",
                "One may also study models in which multiple (but not all) players commit at the same time.",
                "Another interesting direction to pursue is to see if computing optimal mixed strategies to commit to can help us in, or otherwise shed light on, computing Nash equilibria.",
                "Often, optimal mixed strategies to commit to are also Nash equilibrium strategies (for example, in two-player zero-sum games this is always true), although this is not always the case (for example, as we already pointed out, sometimes the optimal strategy to commit to is a strictly dominated strategy, which can never be a Nash equilibrium strategy). 5.",
                "REFERENCES [1] N. A. R. Bhat and K. Leyton-Brown.",
                "Computing Nash equilibria of action-graph games.",
                "In Proceedings of the 20th Annual Conference on Uncertainty in Artificial Intelligence (UAI), Banff, Canada, 2004. [2] V. Conitzer and T. Sandholm.",
                "Complexity results about Nash equilibria.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pages 765-771, Acapulco, Mexico, 2003. [3] V. Conitzer and T. Sandholm.",
                "Complexity of (iterated) dominance.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 88-97, Vancouver, Canada, 2005. [4] V. Conitzer and T. Sandholm.",
                "A generalized strategy eliminability criterion and computational methods for applying it.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 483-488, Pittsburgh, PA, USA, 2005. [5] A.",
                "A. Cournot.",
                "Recherches sur les principes math´ematiques de la th´eorie des richesses (Researches 1 Bayesian games are one potentially concise representation of normal-form games. into the Mathematical Principles of the Theory of Wealth).",
                "Hachette, Paris, 1838. [6] G. Dantzig.",
                "A proof of the equivalence of the programming problem and the game problem.",
                "In T. Koopmans, editor, Activity Analysis of Production and Allocation, pages 330-335.",
                "John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel.",
                "The complexity of eliminating dominated strategies.",
                "Mathematics of Operation Research, 18:553-565, 1993. [8] I. Gilboa and E. Zemel.",
                "Nash and correlated equilibria: Some complexity considerations.",
                "Games and Economic Behavior, 1:80-93, 1989. [9] R. Karp.",
                "Reducibility among combinatorial problems.",
                "In R. E. Miller and J. W. Thatcher, editors, Complexity of Computer Computations, pages 85-103.",
                "Plenum Press, NY, 1972. [10] M. Kearns, M. Littman, and S. Singh.",
                "Graphical models for game theory.",
                "In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou, and J. N. Tsitsiklis.",
                "A note on strategy elimination in bimatrix games.",
                "Operations Research Letters, 7(3):103-107, 1988. [12] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [14] K. Leyton-Brown and M. Tennenholtz.",
                "Local-effect games.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), Acapulco, Mexico, 2003. [15] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 36-41, San Diego, CA, 2003. [16] M. Littman and P. Stone.",
                "A polynomial-time Nash equilibrium algorithm for repeated games.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 48-54, San Diego, CA, 2003. [17] R. D. Luce and H. Raiffa.",
                "Games and Decisions.",
                "John Wiley and Sons, New York, 1957.",
                "Dover republication 1989. [18] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown, and Y. Shoham.",
                "Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms.",
                "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), New York, NY, USA, 2004. [20] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "MIT Press, 1994. [21] C. Papadimitriou.",
                "Algorithms, games and the Internet.",
                "In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 749-753, 2001. 89 [22] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 664-669, San Jose, CA, USA, 2004. [23] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 495-501, Pittsburgh, PA, USA, 2005. [24] J. von Neumann.",
                "Zur Theorie der Gesellschaftsspiele.",
                "Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg.",
                "Marktform und Gleichgewicht.",
                "Springer, Vienna, 1934. [26] B. von Stengel and S. Zamir.",
                "Leadership with commitment to mixed strategies.",
                "CDAM Research Report LSE-CDAM-2004-01, London School of Economics, Feb. 2004. 90"
            ],
            "original_annotated_samples": [
                "The recent surge in interest in computing game-theoretic solutions has so far ignored <br>leadership model</br>s (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored <br>leadership model</br>s (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position)."
            ],
            "translated_annotated_samples": [
                "El reciente aumento en el interés por las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los <br>modelos de liderazgo</br> (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo).",
                "El reciente aumento del interés en las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los <br>modelos de liderazgo</br> (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo)."
            ],
            "translated_text": "En sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias simultáneamente. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. El reciente aumento en el interés por las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los <br>modelos de liderazgo</br> (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas a comprometerse tanto en el compromiso de estrategias puras como en el compromiso de estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Ofrecemos tanto resultados positivos (algoritmos eficientes) como resultados negativos (resultados de NP-hardness). Categorías y Descriptores de Asignaturas J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas Términos Generales Algoritmos, Economía, Teoría 1. En sistemas multiagentes con agentes auto-interesados (incluyendo la mayoría de los entornos económicos), la acción óptima que un agente debe tomar depende de las acciones que tomen los otros agentes. Para analizar cómo un agente debería comportarse en tales situaciones, es necesario aplicar las herramientas de la teoría de juegos. Normalmente, cuando se modela un escenario estratégico en el marco de la teoría de juegos, se asume que los jugadores eligen sus estrategias de forma simultánea. Esto es especialmente cierto cuando el escenario se modela como un juego en forma normal, que solo especifica la utilidad de cada agente como una función del vector de estrategias que los agentes eligen, y no proporciona información sobre el orden en que los agentes toman sus decisiones y lo que los agentes observan sobre las decisiones anteriores de otros agentes. Dado que el juego está modelado en forma normal, típicamente se analiza utilizando el concepto de equilibrio de Nash. Un equilibrio de Nash especifica una estrategia para cada jugador, de modo que ningún jugador tenga un incentivo para desviarse individualmente de este perfil de estrategias. (Por lo general, se permite que las estrategias sean mixtas, es decir, distribuciones de probabilidad sobre las estrategias originales (puras).) Un equilibrio de Nash (de estrategia mixta) está garantizado de existir en juegos finitos [18], pero un problema es que puede haber múltiples equilibrios de Nash. Esto conduce al problema de selección de equilibrio de cómo un agente puede saber qué estrategia jugar si no sabe qué equilibrio se va a jugar. Cuando el escenario se modela como un juego de forma extensiva, es posible especificar que algunos jugadores reciben información sobre las acciones tomadas por otros antes en el juego antes de decidir su acción. Sin embargo, en general, los jugadores no saben todo lo que sucedió anteriormente en el juego. Por lo tanto, estos juegos suelen ser analizados todavía utilizando un concepto de equilibrio, donde se especifica una estrategia mixta para cada jugador, y se requiere que la estrategia de cada jugador sea una mejor respuesta a las estrategias de los demás. (Normalmente se impone ahora una restricción adicional en las estrategias para garantizar que los jugadores no jueguen de una manera irracional con respecto a la información que han recibido hasta el momento). Esto conduce a refinamientos del equilibrio de Nash como el equilibrio perfecto en subjuegos y el equilibrio secuencial. Sin embargo, en muchos entornos del mundo real, las estrategias no se seleccionan de manera simultánea. A menudo, un jugador (el líder) puede comprometerse con una estrategia antes que otro jugador (el seguidor). Esto puede deberse a una variedad de razones. Por ejemplo, uno de los jugadores puede llegar al lugar donde se jugará el juego antes que otro agente (por ejemplo, en entornos económicos, un jugador puede ingresar al mercado antes y comprometerse con una forma de hacer negocios). Un compromiso tan poderoso tiene un impacto profundo en cómo debería jugarse el juego. Por ejemplo, el líder puede estar mejor jugando una estrategia que esté dominada en la representación de forma normal del juego. Quizás el ejemplo más temprano y conocido del efecto del compromiso es el de von Stackelberg [25], quien demostró que, en el modelo de duopolio de Cournot [5], si una empresa puede comprometerse con una cantidad de producción primero, esa empresa lo hará mucho mejor que en la solución de movimiento simultáneo (Nash). En general, si es posible comprometerse con estrategias mixtas, entonces (bajo suposiciones menores) nunca perjudica, y a menudo ayuda, comprometerse con una estrategia [26]. Verse obligado a comprometerse con una estrategia pura a veces ayuda y a veces perjudica (por ejemplo, comprometerse con una estrategia pura en piedra-papel-tijeras antes de la decisión de los otros jugadores naturalmente resultará en una derrota). En este documento, asumiremos que el compromiso siempre es forzado; si no lo es, el jugador que tiene la opción de comprometerse simplemente puede comparar el resultado del compromiso con el resultado de no comprometerse (movimiento simultáneo). Los modelos de liderazgo son especialmente importantes en entornos con múltiples agentes de software con intereses propios. Una vez que el código de un agente (o de un equipo de agentes) está finalizado y el agente es desplegado, el agente se compromete a jugar la estrategia (posiblemente aleatoria) que el código prescribe. Por lo tanto, siempre y cuando se pueda demostrar de manera creíble que no se puede cambiar el código más tarde, el código funciona como un dispositivo de compromiso. Esto es válido para torneos recreativos entre agentes (por ejemplo, torneos de póker, RoboSoccer) y para aplicaciones industriales como redes de sensores. Finalmente, también existe una situación de liderazgo implícito en el campo del diseño de mecanismos, en la cual un jugador (el diseñador) tiene la oportunidad de elegir las reglas del juego que los demás jugadores luego siguen. El diseño de mecanismos es un tema extremadamente importante para la comunidad de EC: los artículos publicados sobre diseño de mecanismos en las recientes conferencias de EC son demasiados para citar. De hecho, el diseñador del mecanismo puede beneficiarse al comprometerse con una elección que, si las acciones de los agentes (restantes) estuvieran fijas, sería subóptima. Por ejemplo, en una subasta (a precio fijo), el vendedor puede desear establecer un precio de reserva positivo (artificial) para el artículo, por debajo del cual el artículo no se venderá, incluso si el vendedor valora el artículo en 0. En retrospectiva (después de recibir las ofertas), esto (ingenuamente) parece subóptimo: si llegaba una oferta que superaba el precio de reserva, el precio de reserva no tenía efecto, y si no llegaba tal oferta, el vendedor hubiera estado mejor aceptando una oferta más baja. Por supuesto, la razón para establecer el precio de reserva es incentivar a los postores a ofertar más alto, y debido a esto, establecer precios de reserva artificiales puede aumentar realmente los ingresos esperados para el vendedor. Recientemente se ha dedicado una cantidad significativa de investigación al cálculo de soluciones de acuerdo con varios conceptos de solución para escenarios en los que los agentes eligen sus estrategias simultáneamente, como la dominancia [7, 11, 3] y (especialmente) el equilibrio de Nash [8, 21, 16, 15, 2, 22, 23, 4]. Sin embargo, se ha ignorado el cálculo de la estrategia óptima a comprometerse en una situación de liderazgo. Teóricamente, las situaciones de liderazgo simplemente pueden ser consideradas como un juego de forma extensiva en el que un jugador elige una estrategia (para el juego original) primero. El número de estrategias en este juego de forma extensiva, sin embargo, puede ser extremadamente grande. Por ejemplo, si el líder es capaz de comprometerse con una estrategia mixta en el juego original, entonces cada una de las estrategias mixtas (continuo de) constituye una estrategia pura en la representación de forma extensiva de la situación de liderazgo. (Se destaca que un compromiso con una distribución no es lo mismo que una distribución sobre compromisos). Además, si el juego original es en sí mismo un juego de forma extensiva, el número de estrategias en la representación de forma extensiva de la situación de liderazgo (que es un juego de forma extensiva diferente) se vuelve aún más grande. Por lo tanto, generalmente no es factible computacionalmente simplemente transformar el juego original en la representación de forma extensiva de la situación de liderazgo; en su lugar, debemos analizar el juego en su representación original. En este artículo, estudiamos cómo calcular la estrategia óptima a comprometerse, tanto en juegos de forma normal (Sección 2) como en juegos bayesianos, que son un caso especial de juegos de forma extensiva (Sección 3). JUEGOS EN FORMA NORMAL En esta sección, estudiamos cómo calcular la estrategia óptima a comprometerse para juegos representados en forma normal. 2.1 Definiciones En un juego en forma normal, cada jugador i ∈ {1, . . . , n} tiene un conjunto de estrategias puras (o acciones) Si, y una función de utilidad ui : S1×S2×. . .×Sn → R que mapea cada resultado (un vector que consiste en una estrategia pura para cada jugador, también conocido como un perfil de estrategias puras) a un número real. Para facilitar la notación, en el caso de dos jugadores, nos referiremos al conjunto de estrategias puras del jugador 1 como S, y al conjunto de estrategias puras del jugador 2 como T. Estos juegos pueden representarse en forma de matriz (bi-matriz), en la que las filas corresponden a las estrategias puras del jugador 1, las columnas corresponden a las estrategias puras del jugador 2, y las entradas de la matriz dan las utilidades de los jugadores de fila y columna (en ese orden) para el resultado correspondiente del juego. En el caso de tres jugadores, usaremos R, S y T, para las estrategias puras de los jugadores 1, 2 y 3, respectivamente. Una estrategia mixta para un jugador es una distribución de probabilidad sobre las estrategias puras de ese jugador. En el caso de juegos de dos jugadores, nos referiremos al jugador 1 como el líder y al jugador 2 como el seguidor. Antes de definir estrategias de liderazgo óptimas, considera el siguiente juego que ilustra el efecto de la capacidad del líder para comprometerse. 2, 1 4, 0 1, 0 3, 1 En esta representación en forma normal, la estrategia inferior para el jugador de la fila está estrictamente dominada por la estrategia superior. Sin embargo, si el jugador de la fila tiene la capacidad de comprometerse con una estrategia pura antes de que el jugador de la columna elija su estrategia, el jugador de la fila debería comprometerse con la estrategia inferior: al hacerlo, el jugador de la columna preferirá jugar la estrategia correcta, lo que llevará a una utilidad de 3 para el jugador de la fila. Por el contrario, si el jugador de la fila se comprometiera con la estrategia superior, el jugador de la columna preferiría jugar la estrategia izquierda, lo que llevaría a una utilidad de solo 2 para el jugador de la fila. Si el jugador de la fila puede comprometerse a una estrategia mixta, entonces puede obtener una utilidad aún mayor (esperada): si el jugador de la fila se compromete a colocar una probabilidad p > 1/2 en la estrategia inferior, entonces el jugador de la columna seguirá prefiriendo jugar la estrategia derecha, y la utilidad esperada de los jugadores de la fila será 3p + 4(1 − p) = 4 − p ≥ 3. Si el jugador de la fila juega cada estrategia con una probabilidad exacta de 1/2, el jugador de la columna está 83 indiferente entre las estrategias. En tales casos, asumiremos que el jugador de la columna elegirá la estrategia que maximiza la utilidad de los jugadores de la fila (en este caso, la estrategia correcta). Por lo tanto, la estrategia mixta óptima a la que debe comprometerse el jugador de la fila es p = 1/2. Hay algunas buenas razones para esta suposición. Si asumiéramos lo contrario, entonces no existiría una estrategia óptima para el jugador de la fila en el juego de ejemplo: el jugador de la fila jugaría la estrategia inferior con una probabilidad p = 1/2 + con > 0, y cuanto menor sea , mejor será la utilidad para el jugador de la fila. Por el contrario, si asumimos que el seguidor siempre rompe los empates a favor de los líderes, entonces siempre existe una estrategia mixta óptima para el líder, lo que corresponde a un equilibrio perfecto en subjuegos de la representación en forma extensiva de la situación de liderazgo. En cualquier caso, esta es una suposición estándar para tales modelos (por ejemplo, [20]), aunque algunos trabajos han investigado lo que puede suceder en los otros equilibrios perfectos de subjuego [26]. (Para juegos genéricos de dos jugadores, el pago del equilibrio perfecto de subjuego de los líderes es único). Además, la misma suposición se utiliza típicamente en el diseño de mecanismos, asumiendo que si un agente es indiferente entre revelar sus preferencias de manera veraz o falsa, las reportará de manera veraz. Dado este supuesto, podemos hacer referencia de manera segura a estrategias de liderazgo óptimas en lugar de tener que utilizar alguna noción de equilibrio. Por lo tanto, para los propósitos de este documento, una estrategia óptima a comprometerse en un juego de 2 jugadores es una estrategia s ∈ S que maximiza maxt∈BR(s) ul(s, t), donde BR(s) = arg maxt∈T uf (s, t). (ul y uf son las funciones de utilidad del líder y los seguidores, respectivamente). Podemos tener S = S para el caso de compromiso con estrategias puras, o S = ∆(S), el conjunto de distribuciones de probabilidad sobre S, para el caso de compromiso con estrategias mixtas. (Observamos que reemplazar T por ∆(T) no hace ninguna diferencia en esta definición). Para juegos con más de dos jugadores, en los que los jugadores se comprometen con sus estrategias en secuencia, definimos estrategias óptimas a las que comprometerse de forma recursiva. Después de que el líder se compromete con una estrategia, el juego que jugarán los agentes restantes es en sí mismo un juego de liderazgo (más pequeño). Por lo tanto, definimos una estrategia óptima a comprometerse como una estrategia que maximiza la utilidad del líder, asumiendo que el juego de los agentes restantes es óptimo bajo esta definición, y maximiza la utilidad del líder entre todas las formas óptimas de jugar el juego restante. Nuevamente, el compromiso con estrategias mixtas puede o no ser una posibilidad para cada jugador (aunque para el último jugador no importa si permitimos el compromiso con estrategias mixtas). 2.2 Compromiso con estrategias puras. Primero estudiamos cómo calcular la estrategia pura óptima a la que comprometerse. Esto es relativamente simple, porque el número de estrategias a comprometer no es muy grande. (En lo siguiente, #resultados es el número de perfiles de estrategia completos). Teorema 1. Bajo el compromiso de estrategias puras, el conjunto de todos los perfiles de estrategia óptimos en un juego en forma normal se puede encontrar en tiempo O(#jugadores · #resultados). Prueba. Cada estrategia pura a la que el primer jugador pueda comprometerse inducirá un subjuego para los jugadores restantes. Podemos resolver cada subjuego de esta manera de forma recursiva para encontrar todos sus perfiles de estrategia óptimos; cada uno de estos le dará al líder original cierta utilidad. Aquellos que proporcionan al líder la utilidad máxima corresponden exactamente a los perfiles de estrategia óptimos del juego original. Ahora presentamos el algoritmo de forma formal. Sea Su(G, s1) el subjuego que resulta después de que el primer jugador restante en G juega s1 ∈ SG 1. Un juego con 0 jugadores es simplemente un resultado del juego. La función Append(s, O) añade la estrategia s a cada uno de los vectores de estrategias en el conjunto O. Sea e el vector vacío sin elementos. En un ligero abuso de notación, escribiremos uG 1 (C) cuando todos los perfiles estratégicos en el conjunto C le den al jugador 1 la misma utilidad en el juego G. (Aquí, el jugador 1 es el primer jugador restante en el subjuego G, no necesariamente el jugador 1 en el juego original). Observamos que arg max es un conjunto de valores. Entonces, el siguiente algoritmo calcula todos los perfiles de estrategia óptimos: Algoritmo Resolver(G) si G tiene 0 jugadores, devuelve {e} C ← ∅ para todo s1 ∈ SG 1 { O ← Resolver(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) si C = ∅ o uG 1 (s1, O ) = uG 1 (C) C ← C∪Agregar(s1, O ) si uG 1 (s1, O ) > uG 1 (C) C ←Agregar(s1, O ) } devuelve C Cada resultado es examinado (potencialmente) por cada jugador, lo que lleva al límite de tiempo dado. Como ejemplo de cómo funciona el algoritmo, considera el siguiente juego de 3 jugadores, en el que el primer jugador elige la matriz izquierda o derecha, el segundo jugador elige una fila y el tercer jugador elige una columna. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 Primero eliminamos los resultados que no corresponden a las mejores respuestas para el tercer jugador (eliminándolos de la matriz): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Luego, eliminamos las entradas en las que el tercer jugador no resuelve los empates a favor del segundo jugador, así como las entradas que no corresponden a las mejores respuestas para el segundo jugador. 0,1,1 2,1,1 1,1,1 0,5,1 Finalmente, eliminamos las entradas en las que el segundo y tercer jugador no resuelven los empates a favor del primer jugador, así como las entradas que no corresponden a las mejores respuestas para el primer jugador. 2,1,1 Por lo tanto, en el juego óptimo, el primer jugador elige la matriz izquierda, el segundo jugador elige la fila del medio y el tercer jugador elige la columna izquierda. (Notamos que este resultado está dominado por Pareto por (Derecha, Medio, Izquierda).) Para juegos en forma normal general, la utilidad de cada jugador para cada uno de los resultados debe representarse explícitamente en la entrada, de modo que el tamaño de la entrada sea en sí mismo Ω(#jugadores · #resultados). Por lo tanto, el algoritmo es de hecho un algoritmo de tiempo lineal. 2.3 Compromiso con estrategias mixtas En el caso especial de juegos de dos jugadores de suma cero, calcular una estrategia mixta óptima para que el líder se comprometa es equivalente a calcular una estrategia minimax, que minimiza la utilidad esperada máxima que el oponente puede obtener. Las estrategias minimax constituyen el único concepto de solución natural para juegos de suma cero de dos jugadores: el Teorema Minimax de von Neumann [24] establece que en juegos de suma cero de dos jugadores, no importa (en términos de las utilidades de los jugadores) qué jugador se compromete primero a una estrategia mixta, y un perfil de estrategias mixtas es un equilibrio de Nash si y solo si ambas estrategias son estrategias minimax. Es bien sabido que una estrategia minimax se puede encontrar en tiempo polinómico, utilizando programación lineal [17]. Nuestro primer resultado en esta sección generaliza este resultado, mostrando que una estrategia mixta óptima para que el líder se comprometa puede ser calculada eficientemente en juegos de dos jugadores de suma general, nuevamente utilizando programación lineal. Teorema 2. En juegos de forma normal de 2 jugadores, una estrategia mixta óptima a la que comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal. Prueba. Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder de modo que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad del líder. Un programa lineal simple puede calcular una estrategia mixta como la siguiente: maximizar s∈S psul(s, t) sujeto a que para todo t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1. Se destaca que este programa puede ser inviable para algunas estrategias seguidoras t, por ejemplo, si t es una estrategia estrictamente dominada. Sin embargo, el programa debe ser factible para al menos algunas estrategias seguidoras; entre estas estrategias seguidoras, elige una estrategia t∗ que maximice el valor de la solución de los programas lineales. Entonces, si la líder elige como su estrategia mixta los ajustes óptimos de las variables ps para el programa lineal para t∗, y el seguidor juega t∗, esto constituye un perfil de estrategia óptimo. En el siguiente resultado, demostramos que no podemos esperar resolver el problema de manera más eficiente que la programación lineal, ya que podemos reducir cualquier programa lineal con una restricción de probabilidad en sus variables a un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores. Teorema 3. Cualquier programa lineal cuyas variables xi (con xi ∈ R≥0) deben satisfacer i xi = 1 puede ser modelado como un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores. Prueba. Que el líder tenga una estrategia pura i para cada variable xi. Que el jugador de la columna tenga una estrategia pura j para cada restricción en el programa lineal (distinta de i xi = 1), y una única estrategia pura adicional 0. Que las funciones de utilidad sean las siguientes. Escribiendo el objetivo del programa lineal como maximizar ci xi, para cualquier i, dejando ul(i, 0) = ci y uf(i, 0) = 0. Escribiendo la j-ésima restricción del programa lineal (sin incluir i xi = 1) como i aijxi ≤ bj, para cualquier i, j > 0, sea ul(i, j) = mini ci − 1 y uf(i, j) = aij − bj. Por ejemplo, considera el siguiente programa lineal. maximizar 2x1 + x2 sujeto a x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 La solución óptima de este programa es x1 = 1/3, x2 = 2/3. Nuestra reducción transforma este programa en el siguiente juego de líder-seguidor (donde el líder es el jugador de la fila). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 De hecho, la estrategia óptima para el líder es jugar la estrategia superior con una probabilidad de 1/3 y la estrategia inferior con una probabilidad de 2/3. Ahora demostramos que la reducción funciona en general. Claramente, el líder quiere incentivar al seguidor a jugar 0, porque la utilidad que el líder obtiene cuando el seguidor juega 0 siempre es mayor que cuando el seguidor no juega 0. Para que el seguidor no prefiera jugar j > 0 en lugar de 0, debe ser el caso que i pl(i)(aij − bj) ≤ 0, o equivalentemente i pl(i)aij ≤ bj. Por lo tanto, el líder obtendrá una utilidad de al menos mini ci si y solo si hay una solución factible a las restricciones. Dado que el pl(i) incentiva al seguidor a jugar 0, el líder intenta maximizar i pl(i)ci. Por lo tanto, el líder debe resolver el programa lineal original. Como prueba alternativa del Teorema 3, se puede observar que se sabe que encontrar una estrategia minimax en un juego de suma cero es tan difícil como el problema de programación lineal [6], y como señalamos al principio de esta sección, calcular una estrategia minimax en un juego de suma cero es un caso especial del problema de calcular una estrategia mixta óptima a la que comprometerse. La solubilidad en tiempo polinómico del problema de calcular una estrategia mixta óptima a la que comprometerse en juegos de forma normal de dos jugadores contrasta con la complejidad desconocida de calcular un equilibrio de Nash en tales juegos [21], así como con la NP-dificultad de encontrar un equilibrio de Nash con utilidad máxima para un jugador dado en tales juegos [8, 2]. Desafortunadamente, este resultado no se generaliza a más de dos jugadores; aquí, el problema se vuelve NP-duro. Para demostrar esto, reducimos desde el problema de CUBRIR-VÉRTICES. Definición 1. En VERTEX-COVER, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que cada arista e ∈ E tenga al menos uno de sus extremos en S. BALANCED-VERTEX-COVER es el caso especial de VERTEX-COVER en el que K = |V|/2. VERTEX-COVER es NP-completo [9]. El siguiente lema muestra que la dificultad persiste si requerimos K = |V|/2. (Resultados similares se han demostrado para otros problemas NP-completos). Lema 1. El problema de la COBERTURA DE VÉRTICES EQUILIBRADA es NP-completo. Prueba. La pertenencia a NP se deriva del hecho de que el problema es un caso especial de CUBRIMIENTO DE VÉRTICES, que está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES a una instancia de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO, de la siguiente manera. Si, para la instancia de CUBRIMIENTO DE VÉRTICES, K > |V|/2, simplemente agregamos vértices aislados que estén disjuntos del resto del grafo, hasta que K = |V|/2. Si K < |V|/2, agregamos triángulos aislados (es decir, el grafo completo de tres vértices) al grafo, aumentando K en 2 cada vez, hasta que K = |V|/2. Teorema 4. En juegos de forma normal de 3 jugadores, encontrar una estrategia mixta óptima a la que comprometerse es NP-difícil. Prueba. Reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO al siguiente juego de forma normal de 3 jugadores. Para cada vértice v, cada uno de los tres jugadores tiene una estrategia pura correspondiente a ese vértice (rv, sv, tv, respectivamente). Además, para cada arista e, el tercer jugador tiene una estrategia pura te; y finalmente, el tercer jugador tiene una estrategia pura adicional t0. Los servicios son los siguientes: • para todo r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • para todo r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • para todo v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • para todo v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • para todo v ∈ V, para todo r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V| |V|−2; • para todo e ∈ E, s ∈ S, para ambos v ∈ e, u3(rv, s, te) = 0; • para todo e ∈ E, s ∈ S, para todo v /∈ e, u3(rv, s, te) = |V| |V|−2. • para todo r ∈ R, s ∈ S, u3(r, s, t0) = 1. Observamos que los jugadores 1 y 2 tienen la misma función de utilidad. Sostenemos que existe un perfil de estrategia óptimo en el que los jugadores 1 y 2 obtienen ambos 1 (su utilidad máxima) si y solo si hay una solución al problema de la COBERTURA DE VÉRTICES EQUILIBRADA. (De lo contrario, estos jugadores obtendrán ambos 0). Primero, supongamos que existe una solución al problema de la cubierta de vértices balanceada. Entonces, deja que el jugador 1 juegue cada rv de manera que v esté en la cobertura con probabilidad 2 |V|, y deja que el jugador 2 juegue cada sv de manera que v no esté en la cobertura con probabilidad 2 |V|. Entonces, para el jugador 3, la utilidad esperada de jugar tv (para cualquier v) es (1 − 2 |V|) |V| |V|−2 = 1, porque hay una probabilidad de 2 |V| de que se juegue rv o sv. Además, la utilidad esperada de jugar te (para cualquier e) es a lo sumo (1 − 2 |V | ) |V | |V |−2 = 1, porque hay una probabilidad de al menos 2 |V | de que algún rv con v ∈ e se juegue (debido a que el jugador 1 está aleatorizando sobre las estrategias puras correspondientes a la cobertura). Se deduce que jugar t0 es la mejor respuesta para el jugador 3, otorgando a los jugadores 1 y 2 una utilidad de 1. Ahora, supongamos que los jugadores 1 y 2 obtienen 1 en el juego óptimo. Entonces, debe ser el caso de que el jugador 3 juegue t0. Por lo tanto, para cada v ∈ V, debe haber una probabilidad de al menos 2 |V| de que se juegue rv o sv, de lo contrario, al jugador 3 le convendría más jugar tv. Dado que los jugadores 1 y 2 solo tienen una probabilidad total de 2 para distribuir, debe ser el caso que para cada v, ya sea rv o sv se juegue con una probabilidad de 2 |V|, y el otro se juegue con una probabilidad de 0. (No es posible que ambos tengan una probabilidad distinta de cero, porque entonces habría alguna probabilidad de que ambos se jugaran simultáneamente (la correlación no es posible), por lo tanto, la probabilidad total de que al menos uno se juegue no podría ser lo suficientemente alta para todos los vértices). Por lo tanto, para exactamente la mitad de los v ∈ V, el jugador 1 coloca una probabilidad de 2 |V| en rv. Además, para cada e ∈ E, debe haber una probabilidad de al menos 2 |V | de que se juegue algún rv con v ∈ e, de lo contrario, al jugador 3 le convendría más jugar te. Por lo tanto, el v ∈ V tal que el jugador 1 coloca una probabilidad de 2 |V | en rv constituye una cubierta de vértices equilibrada. 3. Juegos bayesianos. Hasta ahora, hemos restringido nuestra atención a los juegos en forma normal. En un juego en forma normal, se asume que cada agente conoce las preferencias de todos los demás agentes sobre los resultados del juego. En general, sin embargo, los agentes pueden tener información privada sobre sus preferencias que no es conocida por los otros agentes. Además, en el momento de comprometerse con una estrategia, los agentes pueden ni siquiera conocer sus propias preferencias (finales) sobre los resultados del juego aún, ya que estas preferencias pueden depender de un contexto que aún no se ha materializado. Por ejemplo, cuando se escribe el código para un agente de negociación, puede que aún no esté claro cómo ese agente valorará los recursos sobre los que negociará más adelante, porque esto depende de información que aún no está disponible en el momento en que se escribe el código (como órdenes que habrán sido colocadas al agente antes de la negociación). En esta sección, estudiaremos el compromiso en juegos bayesianos, los cuales pueden modelar tal incertidumbre sobre preferencias. 3.1 Definiciones En un juego bayesiano, cada jugador i tiene un conjunto de acciones Si, un conjunto de tipos Θi con una distribución de probabilidad asociada πi : Θi → [0, 1], y, para cada tipo θi, una función de utilidad uθi i : S1 × S2 × . . . × Sn → R. Una estrategia pura en un juego bayesiano es una asignación de los tipos de los jugadores a acciones, σi : Θi → Si. (Los juegos bayesianos pueden ser reescritos en forma normal enumerando cada estrategia pura σi, pero esto causará un crecimiento exponencial en el tamaño de la representación del juego y por lo tanto no puede llevar a algoritmos eficientes). La estrategia a la que el líder debería comprometerse depende de si, en el momento del compromiso, el líder conoce su propio tipo. Si la líder conoce su propio tipo, los otros tipos que la líder podría haber tenido se vuelven irrelevantes y la líder simplemente debería comprometerse con la estrategia que sea óptima para ese tipo. Sin embargo, como se argumentó anteriormente, la líder no necesariamente conoce su propio tipo en el momento de comprometerse (por ejemplo, en el momento en que se envía el código). En este caso, el líder debe comprometerse con una estrategia que dependa en un 86% del tipo eventual del líder. Estudiaremos este último modelo, aunque prestaremos atención específica al caso en el que el líder tiene un solo tipo, lo cual es efectivamente lo mismo que el modelo anterior. 3.2 Compromiso con estrategias puras Resulta que calcular una estrategia pura óptima a la que comprometerse es difícil en juegos bayesianos, incluso con dos jugadores. Teorema 5. Encontrar una estrategia pura óptima a comprometerse en juegos bayesianos de 2 jugadores es NP-difícil, incluso cuando el seguidor tiene solo un tipo. Prueba. Reducimos una instancia arbitraria de CUBRIMIENTO DE VÉRTICES al siguiente juego bayesiano entre el líder y el seguidor. El líder tiene K tipos θ1, θ2, . . . , θK, cada uno ocurriendo con probabilidad 1/K, y para cada vértice v ∈ V, el líder tiene una acción sv. El seguidor tiene solo un tipo; para cada borde e ∈ E, el seguidor tiene una acción te, y el seguidor tiene una acción adicional única t0. La función de utilidad para el líder está dada por, para todo θl ∈ Θl y todo s ∈ S, u θl l (s, t0) = 1, y para todo e ∈ E, u θl l (s, te) = 0. La utilidad de los seguidores se da por: • Para todo v ∈ V, para todo e ∈ E con v /∈ e, uf (sv, te) = 1; • Para todo v ∈ V, para todo e ∈ E con v ∈ e, uf (sv, te) = −K; • Para todo v ∈ V, uf (sv, t0) = 0. Sostenemos que el líder puede obtener una utilidad de 1 si y solo si hay una solución para la instancia de CUBRIMIENTO-DE-VÉRTICES. Primero, supongamos que hay una solución para la instancia de CUBRIRVÉRTICES. Entonces, el líder puede comprometerse con una estrategia pura tal que para cada vértice v en la cobertura, el líder juega sv para algún tipo. Entonces, la utilidad de los seguidores para jugar te (para cualquier e ∈ E) es a lo sumo K−1 K + 1 K (−K) = − 1 K , por lo que el seguidor preferirá jugar t0, lo que le da al líder una utilidad de 1, como se requiere. Ahora, supongamos que hay una estrategia pura para el líder que le dará al líder una utilidad de 1. Entonces, el seguidor debe jugar t0. Para que el seguidor no prefiera jugar te (para cualquier e ∈ E) en su lugar, al menos para un v ∈ e, el líder debe jugar sv para algún tipo θl. Por lo tanto, el conjunto de vértices v que el líder juega para algún tipo debe constituir una cubierta de vértices; y este conjunto puede tener un tamaño de como máximo K, ya que el líder solo tiene K tipos. Entonces hay una solución para la instancia de CUBRIMIENTODEVÉRTICES. Sin embargo, si el líder tiene solo un tipo, entonces el problema se vuelve fácil nuevamente (#tipos es el número de tipos para el seguidor): Teorema 6. En juegos bayesianos de 2 jugadores en los que el líder tiene solo un tipo, una estrategia pura óptima a comprometerse puede encontrarse en tiempo O(#resultados · #tipos). Prueba. Para cada acción de líder s, podemos calcular, para cada tipo de seguidor θf ∈ Θf, qué acciones t maximizan la utilidad de los seguidores; llamamos a este conjunto de acciones BRθf (s). Entonces, la utilidad que recibe el líder por comprometerse a la acción s se puede calcular como θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), y el líder puede elegir la mejor acción a la que comprometerse. 3.3 Compromiso con estrategias mixtas En juegos de información imperfecta de suma cero de dos jugadores con memoria perfecta (ningún jugador olvida algo que una vez supo), una estrategia minimax se puede construir en tiempo polinómico [12, 13]. Desafortunadamente, este resultado no se extiende a calcular estrategias mixtas óptimas a comprometerse en el caso de suma general, ni siquiera en juegos bayesianos. Demostraremos la NP-dificultad reduciendo desde el problema de CONJUNTOINDEPENDIENTE. Definición 2. En INDEPENDENT-SET, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que ninguna arista e ∈ E tenga ambos extremos en S. Nuevamente, este problema es NP-completo [9]. Teorema 7. Encontrar una estrategia mixta óptima a comprometerse en juegos bayesianos de 2 jugadores es NP-duro, incluso cuando el líder tiene solo un tipo y el seguidor tiene solo dos acciones. Prueba. Reducimos una instancia arbitraria de CONJUNTO-INDEPENDIENTE al siguiente juego bayesiano entre el líder y el seguidor. El líder tiene solo un tipo, y para cada vértice v ∈ V, el líder tiene una acción sv. El seguidor tiene un tipo θv para cada v ∈ V, que ocurre con una probabilidad de 1 (|E|+1)|V|, y un tipo θe para cada e ∈ E, que ocurre con una probabilidad de 1 |E|+1. El seguidor tiene dos acciones: t0 y t1. La utilidad de los líderes se da por, para todo s ∈ S, ul(s, t0) = 1 y ul(s, t1) = 0. La utilidad de los seguidores se da por: • Para todo v ∈ V, uθv f (sv, t1) = 0; • Para todo v ∈ V y s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • Para todo v ∈ V y s ∈ S, uθv f (s, t0) = 1; • Para todo e ∈ E, s ∈ S, uθe f (s, t0) = 1; • Para todo e ∈ E, para ambos v ∈ e, uθe f (sv, t1) = 2K 3 ; • Para todo e ∈ E, para todo v /∈ e, uθe f (sv, t1) = 0. Sostenemos que una estrategia óptima a comprometerse le otorga al líder una utilidad esperada de al menos |E| |E|+1 + K (|E|+1)|V | si y solo si hay una solución para la instancia de CONJUNTO-INDEPENDIENTE. Primero, supongamos que hay una solución para la instancia de CONJUNTO-INDEPENDIENTE. Entonces, el líder podría comprometerse con la siguiente estrategia: por cada vértice v en el conjunto independiente, jugar el correspondiente sv con una probabilidad de 1/K. Si el seguidor tiene el tipo θe para algún e ∈ E, la utilidad esperada para el seguidor al jugar t1 es a lo sumo 1 K 2K 3 = 2/3, porque hay a lo sumo un vértice v ∈ e tal que sv se juega con probabilidad distinta de cero. Por lo tanto, el seguidor jugará t0 y obtendrá una utilidad de 1. Si el seguidor tiene el tipo θv para algún vértice v en el conjunto independiente, la utilidad esperada para el seguidor al jugar t1 es K−1 K K K−1 = 1, porque el líder juega sv con probabilidad 1/K. Se deduce que el seguidor (quien rompe los empates para maximizar la utilidad de los líderes) jugará t0, lo que también otorga una utilidad de 1 y brinda al líder una mayor utilidad. Por lo tanto, la utilidad esperada de los líderes para esta estrategia es al menos |E| |E|+1 + K (|E|+1)|V |, como se requiere. Ahora, supongamos que hay una estrategia que le da al líder una utilidad esperada de al menos |E| |E|+1 + K (|E|+1)|V |. Entonces, esta estrategia debe inducir al seguidor a jugar t0 siempre que tenga un tipo de la forma θe (porque de lo contrario, la utilidad podría ser a lo sumo |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ). Por lo tanto, no puede ser el caso de que para alguna arista e = (v1, v2) ∈ E, la probabilidad de que el líder juegue uno de sv1 y sv2 sea al menos 2/K, porque entonces la utilidad esperada para el seguidor de jugar t1 cuando tiene el tipo θe sería al menos 2 K 2K 3 = 4/3 > 1. Además, la estrategia debe inducir al seguidor a jugar t0 durante al menos K tipos de la forma θv. Inducir al seguidor a jugar t0 cuando tiene el tipo θv solo se puede lograr jugando sv con una probabilidad de al menos 1/K, lo que le dará al seguidor una utilidad de como máximo K−1 K K K−1 = 1 por jugar t1. Pero entonces, el conjunto de vértices v tales que sv se juega con una probabilidad de al menos 1/K debe constituir un conjunto independiente de tamaño K (porque si hubiera una arista e entre dos de estos vértices, induciría al seguidor a jugar t1 para el tipo θe según lo mencionado anteriormente). Por el contrario, si el seguidor tiene solo un tipo, entonces podemos generalizar el enfoque de programación lineal para juegos en forma normal: Teorema 8. En juegos bayesianos de 2 jugadores en los que el seguidor tiene solo un tipo, una estrategia mixta óptima a comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal. Prueba. Generalizamos el enfoque en el Teorema 2 de la siguiente manera. Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder para cada uno de los tipos de líderes de manera que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad esperada ex ante de los líderes. Para hacerlo, generalizamos el programa lineal de la siguiente manera: maximizar θl∈Θl π(θl) s∈S pθl s uθl l (s, t) sujeto a para todo t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t) para todo θl ∈ Θl, s∈S p θl s = 1 Como en el Teorema 2, la solución para el programa lineal que maximiza el valor de la solución es una estrategia óptima a comprometerse. Esto muestra un contraste interesante entre el compromiso con estrategias puras y el compromiso con estrategias mixtas en juegos bayesianos: para las estrategias puras, el problema se vuelve fácil si el líder tiene solo un tipo (pero no si el seguidor tiene solo un tipo), mientras que para las estrategias mixtas, el problema se vuelve fácil si el seguidor tiene solo un tipo (pero no si el líder tiene solo un tipo). 4. CONCLUSIONES E INVESTIGACIONES FUTURAS En los sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias de forma simultánea. Esto requiere cierta noción de equilibrio (equilibrio de Nash y sus refinamientos), y a menudo conduce al problema de selección de equilibrio: no está claro para cada jugador individual según qué equilibrio debería jugar. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Por ejemplo, un agente puede llegar al sitio del juego (real o virtual) antes que el otro, o, en el caso específico de agentes de software, el código de un agente puede estar completo y comprometido antes que el de otro agente. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. Específicamente, si es posible el compromiso con estrategias mixtas, entonces el compromiso (óptimo) nunca perjudica al líder y a menudo lo beneficia. El reciente aumento del interés en las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los <br>modelos de liderazgo</br> (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas para comprometerse tanto a estrategias puras como a estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Para juegos en forma normal, demostramos que la estrategia pura óptima a comprometerse se puede encontrar eficientemente para cualquier número de jugadores. Una estrategia mixta óptima para comprometerse en un juego en forma normal puede encontrarse eficientemente para dos jugadores utilizando programación lineal (y no más eficientemente que eso, en el sentido de que cualquier programa lineal con una restricción de probabilidad puede ser codificado como tal problema). (Esta es una generalización de la computabilidad en tiempo polinómico de las estrategias minimax en juegos en forma normal). El problema se vuelve NP-duro para tres (o más) jugadores. En los juegos bayesianos, el problema de encontrar una estrategia pura óptima a la que comprometerse es NP-duro incluso en juegos de dos jugadores en los que el seguidor tiene solo un tipo, aunque los juegos de dos jugadores en los que el líder tiene solo un tipo pueden resolverse eficientemente. El problema de encontrar una estrategia mixta óptima a comprometerse en un juego bayesiano es NP-duro incluso en juegos de dos jugadores en los que el líder tiene solo un tipo, aunque los juegos de dos jugadores en los que el seguidor tiene solo un tipo pueden resolverse eficientemente utilizando una generalización del enfoque de programación lineal para juegos en forma normal. Las siguientes dos tablas resumen estos resultados. 2 jugadores ≥ 3 jugadores forma normal O(#resultados) O(#resultados· #jugadores) Bayesiano, O(#resultados· NP-completo 1-tipo líder #tipos) Bayesiano, NP-completo NP-completo 1-tipo seguidor Bayesiano (general) NP-completo NP-completo Resultados para el compromiso con estrategias puras. (Con más de 2 jugadores, el seguidor es el último jugador en comprometerse, el líder es el primero.) 88 2 jugadores ≥ 3 jugadores forma normal una resolución de LP por acción NP-completa del seguidor Bayesiano, NP-completo NP-completo 1-tipo líder Bayesiano, una resolución de LP por acción NP-completa del 1-tipo seguidor Bayesiano (general) NP-completo NP-completo Resultados para el compromiso con estrategias mixtas. (Con más de 2 jugadores, el seguidor es el último jugador en comprometerse, el líder es el primero.) La investigación futura puede tomar varias direcciones. Primero, podemos evaluar empíricamente las técnicas presentadas aquí en conjuntos de pruebas como GAMUT [19]. También podemos estudiar la computación de estrategias óptimas a comprometerse en otras representaciones concisas de juegos en forma normal, por ejemplo, en juegos gráficos [10] o juegos de grafo de efecto local/acción [14, 1]. Para los casos en los que calcular una estrategia óptima para comprometerse es NP-duro, también podemos estudiar la computación de estrategias aproximadamente óptimas para comprometerse. Si bien la definición correcta de una estrategia aproximadamente óptima en este contexto puede parecer simple al principio, debería ser una estrategia que, si los jugadores siguientes juegan de manera óptima, funcione casi tan bien como la estrategia óptima en promedio, esta definición se vuelve problemática cuando consideramos que los otros jugadores también podrían estar jugando solo de manera aproximadamente óptima. Uno también puede estudiar modelos en los que múltiples (pero no todos) jugadores se comprometen al mismo tiempo. Otra dirección interesante a explorar es ver si calcular estrategias mixtas óptimas a las que comprometerse puede ayudarnos, o de alguna manera arrojar luz sobre, el cálculo de equilibrios de Nash. A menudo, las estrategias mixtas óptimas a las que comprometerse también son estrategias de equilibrio de Nash (por ejemplo, en juegos de suma cero de dos jugadores esto siempre es cierto), aunque no siempre es el caso (por ejemplo, como ya señalamos, a veces la estrategia óptima a la que comprometerse es una estrategia estrictamente dominada, que nunca puede ser una estrategia de equilibrio de Nash). 5. REFERENCIAS [1] N. A. R. Bhat y K. Leyton-Brown. Calculando los equilibrios de Nash de juegos de gráficos de acción. En Actas de la 20ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI), Banff, Canadá, 2004. [2] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Actas de la Decimoctava Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 765-771, Acapulco, México, 2003. [3] V. Conitzer y T. Sandholm. Complejidad del dominio (iterado). En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 88-97, Vancouver, Canadá, 2005. [4] V. Conitzer y T. Sandholm. Un criterio de eliminabilidad de estrategias generalizado y métodos computacionales para aplicarlo. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 483-488, Pittsburgh, PA, EE. UU., 2005. [5] A. A. Cournot. Las investigaciones sobre los juegos bayesianos son una representación potencialmente concisa de los juegos en forma normal en los principios matemáticos de la teoría de la riqueza. Hachette, París, 1838. [6] G. Dantzig. Una prueba de la equivalencia del problema de programación y el problema de juego. En T. Koopmans, editor, Análisis de la actividad de producción y asignación, páginas 330-335. John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel. \n\nJohn Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, y E. Zemel. La complejidad de eliminar estrategias dominadas. Matemáticas de la Investigación de Operaciones, 18:553-565, 1993. [8] I. Gilboa y E. Zemel. Nash y equilibrios correlacionados: Algunas consideraciones de complejidad. Juegos y Comportamiento Económico, 1:80-93, 1989. [9] R. Karp. Reductibilidad entre problemas combinatorios. En R. E. Miller y J. W. Thatcher, editores, Complejidad de las Computaciones de Computadoras, páginas 85-103. Plenum Press, Nueva York, 1972. [10] M. Kearns, M. Littman y S. Singh. Modelos gráficos para teoría de juegos. En Actas de la Conferencia sobre Incertidumbre en Inteligencia Artificial (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou y J. N. Tsitsiklis. Una nota sobre la eliminación de estrategias en juegos bimatrix. Cartas de Investigación Operativa, 7(3):103-107, 1988. [12] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [14] K. Leyton-Brown y M. Tennenholtz. Juegos de efecto local. En Actas de la Decimoctava Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), Acapulco, México, 2003. [15] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 36-41, San Diego, CA, 2003. [16] M. Littman y P. Stone. Un algoritmo de equilibrio de Nash de tiempo polinómico para juegos repetidos. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 48-54, San Diego, CA, 2003. [17] R. D. Luce y H. Raiffa. Juegos y decisiones. John Wiley and Sons, Nueva York, 1957. Reedición de Dover 1989. [18] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown y Y. Shoham. Ejecutar el GAMUT: Un enfoque integral para evaluar algoritmos de teoría de juegos. En la Conferencia Internacional sobre Agentes Autónomos y Sistemas Multiagente (AAMAS), Nueva York, NY, EE. UU., 2004. [20] M. J. Osborne y A. Rubinstein. Un curso de teoría de juegos. MIT Press, 1994. [21] C. Papadimitriou. \n\nMIT Press, 1994. [21] C. Papadimitriou. Algoritmos, juegos e Internet. En Actas del Simposio Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. 89 [22] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 664-669, San José, CA, EE. UU., 2004. [23] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [24] J. von Neumann. A la teoría de los juegos sociales. Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg. \n\nMathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg. Forma de mercado y equilibrio. Springer, Viena, 1934. [26] B. von Stengel y S. Zamir. Liderazgo con compromiso hacia estrategias mixtas. Informe de investigación CDAM LSE-CDAM-2004-01, London School of Economics, febrero de 2004. 90 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "pure strategy": {
            "translated_key": "estrategia pura",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Computing the Optimal Strategy to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "We give both positive results (efficient algorithms) and negative results (NP-hardness results).",
                "Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent systems with self-interested agents (including most economic settings), the optimal action for one agent to take depends on the actions that the other agents take.",
                "To analyze how an agent should behave in such settings, the tools of game theory need to be applied.",
                "Typically, when a strategic setting is modeled in the framework of game theory, it is assumed that players choose their strategies simultaneously.",
                "This is especially true when the setting is modeled as a normal-form game, which only specifies each agents utility as a function of the vector of strategies that the agents choose, and does not provide any information on the order in which agents make their decisions and what the agents observe about earlier decisions by other agents.",
                "Given that the game is modeled in normal form, it is typically analyzed using the concept of Nash equilibrium.",
                "A Nash equilibrium specifies a strategy for each player, such that no player has an incentive to individually deviate from this profile of strategies. (Typically, the strategies are allowed to be mixed, that is, probability distributions over the original (pure) strategies.)",
                "A (mixed-strategy) Nash equilibrium is guaranteed to exist in finite games [18], but one problem is that there may be multiple Nash equilibria.",
                "This leads to the equilibrium selection problem of how an agent can know which strategy to play if it does not know which equilibrium is to be played.",
                "When the setting is modeled as an extensive-form game, it is possible to specify that some players receive some information about actions taken by others earlier in the game before deciding on their action.",
                "Nevertheless, in general, the players do not know everything that happened earlier in the game.",
                "Because of this, these games are typically still analyzed using an equilibrium concept, where one specifies a mixed strategy for each player, and requires that each players strategy is a best response to the others strategies. (Typically an additional constraint on the strategies is now imposed to ensure that players do not play in a way that is irrational with respect to the information that they have received so far.",
                "This leads to refinements of Nash equilibrium such as subgame perfect and sequential equilibrium.)",
                "However, in many real-world settings, strategies are not selected in such a simultaneous manner.",
                "Oftentimes, one player (the leader) is able to commit to a strategy before another player (the follower).",
                "This can be due to a variety of reasons.",
                "For example, one of the players may arrive at the site at which the game is to be played before another agent (e.g., in economic settings, one player may enter a market earlier and commit to a way of doing busi82 ness).",
                "Such commitment power has a profound impact on how the game should be played.",
                "For example, the leader may be best off playing a strategy that is dominated in the normal-form representation of the game.",
                "Perhaps the earliest and best-known example of the effect of commitment is that by von Stackelberg [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution.",
                "In general, if commitment to mixed strategies is possible, then (under minor assumptions) it never hurts, and often helps, to commit to a strategy [26].",
                "Being forced to commit to a <br>pure strategy</br> sometimes helps, and sometimes hurts (for example, committing to a <br>pure strategy</br> in rock-paper-scissors before the other players decision will naturally result in a loss).",
                "In this paper, we will assume commitment is always forced; if it is not, the player who has the choice of whether to commit can simply compare the commitment outcome to the non-commitment (simultaneous-move) outcome.",
                "Models of leadership are especially important in settings with multiple self-interested software agents.",
                "Once the code for an agent (or for a team of agents) is finalized and the agent is deployed, the agent is committed to playing the (possibly randomized) strategy that the code prescribes.",
                "Thus, as long as one can credibly show that one cannot change the code later, the code serves as a commitment device.",
                "This holds true for recreational tournaments among agents (e.g., poker tournaments, RoboSoccer), and for industrial applications such as sensor webs.",
                "Finally, there is also an implicit leadership situation in the field of mechanism design, in which one player (the designer) gets to choose the rules of the game that the remaining players then play.",
                "Mechanism design is an extremely important topic to the EC community: the papers published on mechanism design in recent EC conferences are too numerous to cite.",
                "Indeed, the mechanism designer may benefit from committing to a choice that, if the (remaining) agents actions were fixed, would be suboptimal.",
                "For example, in a (first-price) auction, the seller may wish to set a positive (artificial) reserve price for the item, below which the item will not be sold-even if the seller values the item at 0.",
                "In hindsight (after the bids have come in), this (na¨ıvely) appears suboptimal: if a bid exceeding the reserve price came in, the reserve price had no effect, and if no such bid came in, the seller would have been better off accepting a lower bid.",
                "Of course, the reason for setting the reserve price is that it incentivizes the bidders to bid higher, and because of this, setting artificial reserve prices can actually increase expected revenue to the seller.",
                "A significant amount of research has recently been devoted to the computation of solutions according to various solution concepts for settings in which the agents choose their strategies simultaneously, such as dominance [7, 11, 3] and (especially) Nash equilibrium [8, 21, 16, 15, 2, 22, 23, 4].",
                "However, the computation of the optimal strategy to commit to in a leadership situation has gone ignored.",
                "Theoretically, leadership situations can simply be thought of as an extensive-form game in which one player chooses a strategy (for the original game) first.",
                "The number of strategies in this extensive-form game, however, can be exceedingly large.",
                "For example, if the leader is able to commit to a mixed strategy in the original game, then every one of the (continuum of) mixed strategies constitutes a <br>pure strategy</br> in the extensive-form representation of the leadership situation. (We note that a commitment to a distribution is not the same as a distribution over commitments.)",
                "Moreover, if the original game is itself an extensive-form game, the number of strategies in the extensive-form representation of the leadership situation (which is a different extensive-form game) becomes even larger.",
                "Because of this, it is usually not computationally feasible to simply transform the original game into the extensive-form representation of the leadership situation; instead, we have to analyze the game in its original representation.",
                "In this paper, we study how to compute the optimal strategy to commit to, both in normal-form games (Section 2) and in Bayesian games, which are a special case of extensiveform games (Section 3). 2.",
                "NORMAL-FORM GAMES In this section, we study how to compute the optimal strategy to commit to for games represented in normal form. 2.1 Definitions In a normal-form game, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a <br>pure strategy</br> for every player, also known as a profile of pure strategies) to a real number.",
                "To ease notation, in the case of two players, we will refer to player 1s <br>pure strategy</br> set as S, and player 2s <br>pure strategy</br> set as T. Such games can be represented in (bi-)matrix form, in which the rows correspond to player 1s pure strategies, the columns correspond to player 2s pure strategies, and the entries of the matrix give the row and column players utilities (in that order) for the corresponding outcome of the game.",
                "In the case of three players, we will use R, S, and T, for player 1, 2, and 3s pure strategies, respectively.",
                "A mixed strategy for a player is a probability distribution over that players pure strategies.",
                "In the case of two-player games, we will refer to player 1 as the leader and player 2 as the follower.",
                "Before defining optimal leadership strategies, consider the following game which illustrates the effect of the leaders ability to commit. 2, 1 4, 0 1, 0 3, 1 In this normal-form representation, the bottom strategy for the row player is strictly dominated by the top strategy.",
                "Nevertheless, if the row player has the ability to commit to a <br>pure strategy</br> before the column player chooses his strategy, the row player should commit to the bottom strategy: doing so will make the column player prefer to play the right strategy, leading to a utility of 3 for the row player.",
                "By contrast, if the row player were to commit to the top strategy, the column player would prefer to play the left strategy, leading to a utility of only 2 for the row player.",
                "If the row player is able to commit to a mixed strategy, then she can get an even greater (expected) utility: if the row player commits to placing probability p > 1/2 on the bottom strategy, then the column player will still prefer to play the right strategy, and the row players expected utility will be 3p + 4(1 − p) = 4 − p ≥ 3.",
                "If the row player plays each strategy with probability exactly 1/2, the column player is 83 indifferent between the strategies.",
                "In such cases, we will assume that the column player will choose the strategy that maximizes the row players utility (in this case, the right strategy).",
                "Hence, the optimal mixed strategy to commit to for the row player is p = 1/2.",
                "There are a few good reasons for this assumption.",
                "If we were to assume the opposite, then there would not exist an optimal strategy for the row player in the example game: the row player would play the bottom strategy with probability p = 1/2 + with > 0, and the smaller , the better the utility for the row player.",
                "By contrast, if we assume that the follower always breaks ties in the leaders favor, then an optimal mixed strategy for the leader always exists, and this corresponds to a subgame perfect equilibrium of the extensive-form representation of the leadership situation.",
                "In any case, this is a standard assumption for such models (e.g. [20]), although some work has investigated what can happen in the other subgame perfect equilibria [26]. (For generic two-player games, the leaders subgame-perfect equilibrium payoff is unique.)",
                "Also, the same assumption is typically used in mechanism design, in that it is assumed that if an agent is indifferent between revealing his preferences truthfully and revealing them falsely, he will report them truthfully.",
                "Given this assumption, we can safely refer to optimal leadership strategies rather than having to use some equilibrium notion.",
                "Hence, for the purposes of this paper, an optimal strategy to commit to in a 2-player game is a strategy s ∈ S that maximizes maxt∈BR(s) ul(s, t), where BR(s) = arg maxt∈T uf (s, t). (ul and uf are the leader and followers utility functions, respectively.)",
                "We can have S = S for the case of commitment to pure strategies, or S = ∆(S), the set of probability distributions over S, for the case of commitment to mixed strategies. (We note that replacing T by ∆(T) makes no difference in this definition.)",
                "For games with more than two players, in which the players commit to their strategies in sequence, we define optimal strategies to commit to recursively.",
                "After the leader commits to a strategy, the game to be played by the remaining agents is itself a (smaller) leadership game.",
                "Thus, we define an optimal strategy to commit to as a strategy that maximizes the leaders utility, assuming that the play of the remaining agents is itself optimal under this definition, and maximizes the leaders utility among all optimal ways to play the remaining game.",
                "Again, commitment to mixed strategies may or may not be a possibility for every player (although for the last player it does not matter if we allow for commitment to mixed strategies). 2.2 Commitment to pure strategies We first study how to compute the optimal <br>pure strategy</br> to commit to.",
                "This is relatively simple, because the number of strategies to commit to is not very large. (In the following, #outcomes is the number of complete strategy profiles.)",
                "Theorem 1.",
                "Under commitment to pure strategies, the set of all optimal strategy profiles in a normal-form game can be found in O(#players · #outcomes) time.",
                "Proof.",
                "Each <br>pure strategy</br> that the first player may commit to will induce a subgame for the remaining players.",
                "We can solve each such subgame recursively to find all of its optimal strategy profiles; each of these will give the original leader some utility.",
                "Those that give the leader maximal utility correspond exactly to the optimal strategy profiles of the original game.",
                "We now present the algorithm formally.",
                "Let Su(G, s1) be the subgame that results after the first (remaining) player in G plays s1 ∈ SG 1 .",
                "A game with 0 players is simply an outcome of the game.",
                "The function Append(s, O) appends the strategy s to each of the vectors of strategies in the set O.",
                "Let e be the empty vector with no elements.",
                "In a slight abuse of notation, we will write uG 1 (C) when all strategy profiles in the set C give player 1 the same utility in the game G. (Here, player 1 is the first remaining player in the subgame G, not necessarily player 1 in the original game.)",
                "We note that arg max is set-valued.",
                "Then, the following algorithm computes all optimal strategy profiles: Algorithm Solve(G) if G has 0 players return {e} C ← ∅ for all s1 ∈ SG 1 { O ← Solve(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) if C = ∅ or uG 1 (s1, O ) = uG 1 (C) C ← C∪Append(s1, O ) if uG 1 (s1, O ) > uG 1 (C) C ←Append(s1, O ) } return C Every outcome is (potentially) examined by every player, which leads to the given runtime bound.",
                "As an example of how the algorithm works, consider the following 3-player game, in which the first player chooses the left or right matrix, the second player chooses a row, and the third player chooses a column. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 3,0,0 First we eliminate the outcomes that do not correspond to best responses for the third player (removing them from the matrix): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Next, we remove the entries in which the third player does not break ties in favor of the second player, as well as entries that do not correspond to best responses for the second player. 0,1,1 2,1,1 1,1,1 0,5,1 Finally, we remove the entries in which the second and third players do not break ties in favor of the first player, as well as entries that do not correspond to best responses for the first player. 2,1,1 84 Hence, in optimal play, the first player chooses the left matrix, the second player chooses the middle row, and the third player chooses the left column. (We note that this outcome is Pareto-dominated by (Right, Middle, Left).)",
                "For general normal-form games, each players utility for each of the outcomes has to be explicitly represented in the input, so that the input size is itself Ω(#players · #outcomes).",
                "Therefore, the algorithm is in fact a linear-time algorithm. 2.3 Commitment to mixed strategies In the special case of two-player zero-sum games, computing an optimal mixed strategy for the leader to commit to is equivalent to computing a minimax strategy, which minimizes the maximum expected utility that the opponent can obtain.",
                "Minimax strategies constitute the only natural solution concept for two-player zero-sum games: von Neumanns Minimax Theorem [24] states that in two-player zero-sum games, it does not matter (in terms of the players utilities) which player gets to commit to a mixed strategy first, and a profile of mixed strategies is a Nash equilibrium if and only if both strategies are minimax strategies.",
                "It is well-known that a minimax strategy can be found in polynomial time, using linear programming [17].",
                "Our first result in this section generalizes this result, showing that an optimal mixed strategy for the leader to commit to can be efficiently computed in general-sum two-player games, again using linear programming.",
                "Theorem 2.",
                "In 2-player normal-form games, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders utility.",
                "Such a mixed strategy can be computed using the following simple linear program: maximize s∈S psul(s, t) subject to for all t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1 We note that this program may be infeasible for some follower strategies t, for example, if t is a strictly dominated strategy.",
                "Nevertheless, the program must be feasible for at least some follower strategies; among these follower strategies, choose a strategy t∗ that maximizes the linear programs solution value.",
                "Then, if the leader chooses as her mixed strategy the optimal settings of the variables ps for the linear program for t∗ , and the follower plays t∗ , this constitutes an optimal strategy profile.",
                "In the following result, we show that we cannot expect to solve the problem more efficiently than linear programming, because we can reduce any linear program with a probability constraint on its variables to a problem of computing the optimal mixed strategy to commit to in a 2-player normalform game.",
                "Theorem 3.",
                "Any linear program whose variables xi (with xi ∈ R≥0 ) must satsify i xi = 1 can be modeled as a problem of computing the optimal mixed strategy to commit to in a 2-player normal-form game.",
                "Proof.",
                "Let the leader have a <br>pure strategy</br> i for every variable xi.",
                "Let the column player have one <br>pure strategy</br> j for every constraint in the linear program (other than i xi = 1), and a single additional <br>pure strategy</br> 0.",
                "Let the utility functions be as follows.",
                "Writing the objective of the linear program as maximize i cixi, for any i, let ul(i, 0) = ci and uf (i, 0) = 0.",
                "Writing the jth constraint of the linear program (not including i xi = 1) as i aijxi ≤ bj, for any i, j > 0, let ul(i, j) = mini ci − 1 and uf (i, j) = aij − bj.",
                "For example, consider the following linear program. maximize 2x1 + x2 subject to x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 The optimal solution to this program is x1 = 1/3, x2 = 2/3.",
                "Our reduction transforms this program into the following leader-follower game (where the leader is the row player). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 Indeed, the optimal strategy for the leader is to play the top strategy with probability 1/3 and the bottom strategy with probability 2/3.",
                "We now show that the reduction works in general.",
                "Clearly, the leader wants to incentivize the follower to play 0, because the utility that the leader gets when the follower plays 0 is always greater than when the follower does not play 0.",
                "In order for the follower not to prefer playing j > 0 rather than 0, it must be the case that i pl(i)(aij − bj) ≤ 0, or equivalently i pl(i)aij ≤ bj.",
                "Hence the leader will get a utility of at least mini ci if and only if there is a feasible solution to the constraints.",
                "Given that the pl(i) incentivize the follower to play 0, the leader attempts to maximize i pl(i)ci.",
                "Thus the leader must solve the original linear program.",
                "As an alternative proof of Theorem 3, one may observe that it is known that finding a minimax strategy in a zerosum game is as hard as the linear programming problem [6], and as we pointed out at the beginning of this section, computing a minimax strategy in a zero-sum game is a special case of the problem of computing an optimal mixed strategy to commit to.",
                "This polynomial-time solvability of the problem of computing an optimal mixed strategy to commit to in two-player normal-form games contrasts with the unknown complexity of computing a Nash equilibrium in such games [21], as well as with the NP-hardness of finding a Nash equilibrium with maximum utility for a given player in such games [8, 2].",
                "Unfortunately, this result does not generalize to more than two players-here, the problem becomes NP-hard.",
                "To show this, we reduce from the VERTEX-COVER problem.",
                "Definition 1.",
                "In VERTEX-COVER, we are given a graph G = (V, E) and an integer K. We are asked whether there 85 exists a subset of the vertices S ⊆ V , with |S| = K, such that every edge e ∈ E has at least one of its endpoints in S. BALANCED-VERTEX-COVER is the special case of VERTEX-COVER in which K = |V |/2.",
                "VERTEX-COVER is NP-complete [9].",
                "The following lemma shows that the hardness remains if we require K = |V |/2. (Similar results have been shown for other NP-complete problems.)",
                "Lemma 1.",
                "BALANCED-VERTEX-COVER is NP-complete.",
                "Proof.",
                "Membership in NP follows from the fact that the problem is a special case of VERTEX-COVER, which is in NP.",
                "To show NP-hardness, we reduce an arbitrary VERTEX-COVER instance to a BALANCED-VERTEXCOVER instance, as follows.",
                "If, for the VERTEX-COVER instance, K > |V |/2, then we simply add isolated vertices that are disjoint from the rest of the graph, until K = |V |/2.",
                "If K < |V |/2, we add isolated triangles (that is, the complete graph on three vertices) to the graph, increasing K by 2 every time, until K = |V |/2.",
                "Theorem 4.",
                "In 3-player normal-form games, finding an optimal mixed strategy to commit to is NP-hard.",
                "Proof.",
                "We reduce an arbitrary BALANCED-VERTEXCOVER instance to the following 3-player normal-form game.",
                "For every vertex v, each of the three players has a <br>pure strategy</br> corresponding to that vertex (rv, sv, tv, respectively).",
                "In addition, for every edge e, the third player has a <br>pure strategy</br> te; and finally, the third player has one additional <br>pure strategy</br> t0.",
                "The utilities are as follows: • for all r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • for all r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • for all v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • for all v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • for all v ∈ V , for all r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V | |V |−2 ; • for all e ∈ E, s ∈ S, for both v ∈ e, u3(rv, s, te) = 0; • for all e ∈ E, s ∈ S, for all v /∈ e, u3(rv, s, te) = |V | |V |−2 . • for all r ∈ R, s ∈ S, u3(r, s, t0) = 1.",
                "We note that players 1 and 2 have the same utility function.",
                "We claim that there is an optimal strategy profile in which players 1 and 2 both obtain 1 (their maximum utility) if and only if there is a solution to the BALANCED-VERTEXCOVER problem. (Otherwise, these players will both obtain 0.)",
                "First, suppose there exists a solution to the BALANCEDVERTEX-COVER problem.",
                "Then, let player 1 play every rv such that v is in the cover with probability 2 |V | , and let player 2 play every sv such that v is not in the cover with probability 2 |V | .",
                "Then, for player 3, the expected utility of playing tv (for any v) is (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of 2 |V | that rv or sv is played.",
                "Additionally, the expected utility of playing te (for any e) is at most (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of at least 2 |V | that some rv with v ∈ e is played (because player 1 is randomizing over the pure strategies corresponding to the cover).",
                "It follows that playing t0 is a best response for player 3, giving players 1 and 2 a utility of 1.",
                "Now, suppose that players 1 and 2 obtain 1 in optimal play.",
                "Then, it must be the case that player 3 plays t0.",
                "Hence, for every v ∈ V , there must be a probability of at least 2 |V | that either rv or sv is played, for otherwise player 3 would be better off playing tv.",
                "Because players 1 and 2 have only a total probability of 2 to distribute, it must be the case that for each v, either rv or sv is played with probability 2 |V | , and the other is played with probability 0. (It is not possible for both to have nonzero probability, because then there would be some probability that both are played simultaneously (correlation is not possible), hence the total probability of at least one being played could not be high enough for all vertices.)",
                "Thus, for exactly half the v ∈ V , player 1 places probability 2 |V | on rv.",
                "Moreover, for every e ∈ E, there must be a probability of at least 2 |V | that some rv with v ∈ e is played, for otherwise player 3 would be better off playing te.",
                "Thus, the v ∈ V such that player 1 places probability 2 |V | on rv constitute a balanced vertex cover. 3.",
                "BAYESIAN GAMES So far, we have restricted our attention to normal-form games.",
                "In a normal-form game, it is assumed that every agent knows every other agents preferences over the outcomes of the game.",
                "In general, however, agents may have some private information about their preferences that is not known to the other agents.",
                "Moreover, at the time of commitment to a strategy, the agents may not even know their own (final) preferences over the outcomes of the game yet, because these preferences may be dependent on a context that has yet to materialize.",
                "For example, when the code for a trading agent is written, it may not yet be clear how that agent will value resources that it will negotiate over later, because this depends on information that is not yet available at the time at which the code is written (such as orders that will have been placed to the agent before the negotiation).",
                "In this section, we will study commitment in Bayesian games, which can model such uncertainty over preferences. 3.1 Definitions In a Bayesian game, every player i has a set of actions Si, a set of types Θi with an associated probability distribution πi : Θi → [0, 1], and, for each type θi, a utility function uθi i : S1 × S2 × . . . × Sn → R. A <br>pure strategy</br> in a Bayesian game is a mapping from the players types to actions, σi : Θi → Si. (Bayesian games can be rewritten in normal form by enumerating every <br>pure strategy</br> σi, but this will cause an exponential blowup in the size of the representation of the game and therefore cannot lead to efficient algorithms.)",
                "The strategy that the leader should commit to depends on whether, at the time of commitment, the leader knows her own type.",
                "If the leader does know her own type, the other types that the leader might have had become irrelevant and the leader should simply commit to the strategy that is optimal for the type.",
                "However, as argued above, the leader does not necessarily know her own type at the time of commitment (e.g., the time at which the code is submitted).",
                "In this case, the leader must commit to a strategy that is 86 dependent upon the leaders eventual type.",
                "We will study this latter model, although we will pay specific attention to the case where the leader has only a single type, which is effectively the same as the former model. 3.2 Commitment to pure strategies It turns out that computing an optimal <br>pure strategy</br> to commit to is hard in Bayesian games, even with two players.",
                "Theorem 5.",
                "Finding an optimal <br>pure strategy</br> to commit to in 2-player Bayesian games is NP-hard, even when the follower has only a single type.",
                "Proof.",
                "We reduce an arbitrary VERTEX-COVER instance to the following Bayesian game between the leader and the follower.",
                "The leader has K types θ1, θ2, . . . , θK , each occurring with probability 1/K, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has only a single type; for each edge e ∈ E, the follower has an action te, and the follower has a single additional action t0.",
                "The utility function for the leader is given by, for all θl ∈ Θl and all s ∈ S, u θl l (s, t0) = 1, and for all e ∈ E, u θl l (s, te) = 0.",
                "The followers utility is given by: • For all v ∈ V , for all e ∈ E with v /∈ e, uf (sv, te) = 1; • For all v ∈ V , for all e ∈ E with v ∈ e, uf (sv, te) = −K; • For all v ∈ V , uf (sv, t0) = 0.",
                "We claim that the leader can get a utility of 1 if and only if there is a solution to the VERTEX-COVER instance.",
                "First, suppose that there is a solution to the VERTEXCOVER instance.",
                "Then, the leader can commit to a <br>pure strategy</br> such that for each vertex v in the cover, the leader plays sv for some type.",
                "Then, the followers utility for playing te (for any e ∈ E) is at most K−1 K + 1 K (−K) = − 1 K , so that the follower will prefer to play t0, which gives the leader a utility of 1, as required.",
                "Now, suppose that there is a <br>pure strategy</br> for the leader that will give the leader a utility of 1.",
                "Then, the follower must play t0.",
                "In order for the follower not to prefer playing te (for any e ∈ E) instead, for at least one v ∈ e the leader must play sv for some type θl.",
                "Hence, the set of vertices v that the leader plays for some type must constitute a vertex cover; and this set can have size at most K, because the leader has only K types.",
                "So there is a solution to the VERTEXCOVER instance.",
                "However, if the leader has only a single type, then the problem becomes easy again (#types is the number of types for the follower): Theorem 6.",
                "In 2-player Bayesian games in which the leader has only a single type, an optimal <br>pure strategy</br> to commit to can be found in O(#outcomes · #types) time.",
                "Proof.",
                "For every leader action s, we can compute, for every follower type θf ∈ Θf , which actions t maximize the followers utility; call this set of actions BRθf (s).",
                "Then, the utility that the leader receives for committing to action s can be computed as θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), and the leader can choose the best action to commit to. 3.3 Commitment to mixed strategies In two-player zero-sum imperfect information games with perfect recall (no player ever forgets something that it once knew), a minimax strategy can be constructed in polynomial time [12, 13].",
                "Unfortunately, this result does not extend to computing optimal mixed strategies to commit to in the general-sum case-not even in Bayesian games.",
                "We will exhibit NP-hardness by reducing from the INDEPENDENTSET problem.",
                "Definition 2.",
                "In INDEPENDENT-SET, we are given a graph G = (V, E) and an integer K. We are asked whether there exists a subset of the vertices S ⊆ V , with |S| = K, such that no edge e ∈ E has both of its endpoints in S. Again, this problem is NP-complete [9].",
                "Theorem 7.",
                "Finding an optimal mixed strategy to commit to in 2-player Bayesian games is NP-hard, even when the leader has only a single type and the follower has only two actions.",
                "Proof.",
                "We reduce an arbitrary INDEPENDENT-SET instance to the following Bayesian game between the leader and the follower.",
                "The leader has only a single type, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has a type θv for every v ∈ V , occurring with probability 1 (|E|+1)|V | , and a type θe for every e ∈ E, occurring with probability 1 |E|+1 .",
                "The follower has two actions: t0 and t1.",
                "The leaders utility is given by, for all s ∈ S, ul(s, t0) = 1 and ul(s, t1) = 0.",
                "The followers utility is given by: • For all v ∈ V , uθv f (sv, t1) = 0; • For all v ∈ V and s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • For all v ∈ V and s ∈ S, uθv f (s, t0) = 1; • For all e ∈ E, s ∈ S, uθe f (s, t0) = 1; • For all e ∈ E, for both v ∈ e, uθe f (sv, t1) = 2K 3 ; • For all e ∈ E, for all v /∈ e, uθe f (sv, t1) = 0.",
                "We claim that an optimal strategy to commit to gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | if and only if there is a solution to the INDEPENDENT-SET instance.",
                "First, suppose that there is a solution to the INDEPENDENT-SET instance.",
                "Then, the leader could commit to the following strategy: for every vertex v in the independent set, play the corresponding sv with probability 1/K.",
                "If the follower has type θe for some e ∈ E, the expected utility for the follower of playing t1 is at most 1 K 2K 3 = 2/3, because there is at most one vertex v ∈ e such that sv is played with nonzero probability.",
                "Hence, the follower will play t0 and obtain a utility of 1.",
                "If the follower has type θv for some vertex v in the independent set, the expected utility for the follower of playing t1 is K−1 K K K−1 = 1, because the leader plays sv with probability 1/K.",
                "It follows that the follower (who breaks ties to maximize the leaders utility) will play t0, which also gives a utility of 1 and gives the leader a higher utility.",
                "Hence the leaders expected utility for this strategy is at least |E| |E|+1 + K (|E|+1)|V | , as required. 87 Now, suppose that there is a strategy that gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | .",
                "Then, this strategy must induce the follower to play t0 whenever it has a type of the form θe (because otherwise, the utility could be at most |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ).",
                "Thus, it cannot be the case that for some edge e = (v1, v2) ∈ E, the probability that the leader plays one of sv1 and sv2 is at least 2/K, because then the expected utility for the follower of playing t1 when it has type θe would be at least 2 K 2K 3 = 4/3 > 1.",
                "Moreover, the strategy must induce the follower to play t0 for at least K types of the form θv.",
                "Inducing the follower to play t0 when it has type θv can be done only by playing sv with probability at least 1/K, which will give the follower a utility of at most K−1 K K K−1 = 1 for playing t1.",
                "But then, the set of vertices v such that sv is played with probability at least 1/K must constitute an independent set of size K (because if there were an edge e between two such vertices, it would induce the follower to play t1 for type θe by the above).",
                "By contrast, if the follower has only a single type, then we can generalize the linear programming approach for normalform games: Theorem 8.",
                "In 2-player Bayesian games in which the follower has only a single type, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "We generalize the approach in Theorem 2 as follows.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader for every one of the leaders types such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders ex ante expected utility.",
                "To do so, we generalize the linear program as follows: maximize θl∈Θl π(θl) s∈S pθl s uθl l (s, t) subject to for all t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t ) for all θl ∈ Θl, s∈S p θl s = 1 As in Theorem 2, the solution for the linear program that maximizes the solution value is an optimal strategy to commit to.",
                "This shows an interesting contrast between commitment to pure strategies and commitment to mixed strategies in Bayesian games: for pure strategies, the problem becomes easy if the leader has only a single type (but not if the follower has only a single type), whereas for mixed strategies, the problem becomes easy if the follower has only a single type (but not if the leader has only a single type). 4.",
                "CONCLUSIONS AND FUTURE RESEARCH In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "This requires some equilibrium notion (Nash equilibrium and its refinements), and often leads to the equilibrium selection problem: it is unclear to each individual player according to which equilibrium she should play.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "For example, one agent may arrive at the (real or virtual) site of the game before the other, or, in the specific case of software agents, the code for one agent may be completed and committed before that of another agent.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "Specifically, if commitment to mixed strategies is possible, then (optimal) commitment never hurts the leader, and often helps.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we studied how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "For normal-form games, we showed that the optimal <br>pure strategy</br> to commit to can be found efficiently for any number of players.",
                "An optimal mixed strategy to commit to in a normal-form game can be found efficiently for two players using linear programming (and no more efficiently than that, in the sense that any linear program with a probability constraint can be encoded as such a problem). (This is a generalization of the polynomial-time computability of minimax strategies in normal-form games.)",
                "The problem becomes NP-hard for three (or more) players.",
                "In Bayesian games, the problem of finding an optimal <br>pure strategy</br> to commit to is NP-hard even in two-player games in which the follower has only a single type, although two-player games in which the leader has only a single type can be solved efficiently.",
                "The problem of finding an optimal mixed strategy to commit to in a Bayesian game is NP-hard even in two-player games in which the leader has only a single type, although two-player games in which the follower has only a single type can be solved efficiently using a generalization of the linear progamming approach for normal-form games.",
                "The following two tables summarize these results. 2 players ≥ 3 players normal-form O(#outcomes) O(#outcomes· #players) Bayesian, O(#outcomes· NP-hard 1-type leader #types) Bayesian, NP-hard NP-hard 1-type follower Bayesian (general) NP-hard NP-hard Results for commitment to pure strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.) 88 2 players ≥ 3 players normal-form one LP-solve per NP-hard follower action Bayesian, NP-hard NP-hard 1-type leader Bayesian, one LP-solve per NP-hard 1-type follower follower action Bayesian (general) NP-hard NP-hard Results for commitment to mixed strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.)",
                "Future research can take a number of directions.",
                "First, we can empirically evaluate the techniques presented here on test suites such as GAMUT [19].",
                "We can also study the computation of optimal strategies to commit to in other1 concise representations of normal-form games-for example, in graphical games [10] or local-effect/action graph games [14, 1].",
                "For the cases where computing an optimal strategy to commit to is NP-hard, we can also study the computation of approximately optimal strategies to commit to.",
                "While the correct definition of an approximately optimal strategy is in this setting may appear simple at first-it should be a strategy that, if the following players play optimally, performs almost as well as the optimal strategy in expectation-this definition becomes problematic when we consider that the other players may also be playing only approximately optimally.",
                "One may also study models in which multiple (but not all) players commit at the same time.",
                "Another interesting direction to pursue is to see if computing optimal mixed strategies to commit to can help us in, or otherwise shed light on, computing Nash equilibria.",
                "Often, optimal mixed strategies to commit to are also Nash equilibrium strategies (for example, in two-player zero-sum games this is always true), although this is not always the case (for example, as we already pointed out, sometimes the optimal strategy to commit to is a strictly dominated strategy, which can never be a Nash equilibrium strategy). 5.",
                "REFERENCES [1] N. A. R. Bhat and K. Leyton-Brown.",
                "Computing Nash equilibria of action-graph games.",
                "In Proceedings of the 20th Annual Conference on Uncertainty in Artificial Intelligence (UAI), Banff, Canada, 2004. [2] V. Conitzer and T. Sandholm.",
                "Complexity results about Nash equilibria.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pages 765-771, Acapulco, Mexico, 2003. [3] V. Conitzer and T. Sandholm.",
                "Complexity of (iterated) dominance.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 88-97, Vancouver, Canada, 2005. [4] V. Conitzer and T. Sandholm.",
                "A generalized strategy eliminability criterion and computational methods for applying it.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 483-488, Pittsburgh, PA, USA, 2005. [5] A.",
                "A. Cournot.",
                "Recherches sur les principes math´ematiques de la th´eorie des richesses (Researches 1 Bayesian games are one potentially concise representation of normal-form games. into the Mathematical Principles of the Theory of Wealth).",
                "Hachette, Paris, 1838. [6] G. Dantzig.",
                "A proof of the equivalence of the programming problem and the game problem.",
                "In T. Koopmans, editor, Activity Analysis of Production and Allocation, pages 330-335.",
                "John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel.",
                "The complexity of eliminating dominated strategies.",
                "Mathematics of Operation Research, 18:553-565, 1993. [8] I. Gilboa and E. Zemel.",
                "Nash and correlated equilibria: Some complexity considerations.",
                "Games and Economic Behavior, 1:80-93, 1989. [9] R. Karp.",
                "Reducibility among combinatorial problems.",
                "In R. E. Miller and J. W. Thatcher, editors, Complexity of Computer Computations, pages 85-103.",
                "Plenum Press, NY, 1972. [10] M. Kearns, M. Littman, and S. Singh.",
                "Graphical models for game theory.",
                "In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou, and J. N. Tsitsiklis.",
                "A note on strategy elimination in bimatrix games.",
                "Operations Research Letters, 7(3):103-107, 1988. [12] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [14] K. Leyton-Brown and M. Tennenholtz.",
                "Local-effect games.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), Acapulco, Mexico, 2003. [15] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 36-41, San Diego, CA, 2003. [16] M. Littman and P. Stone.",
                "A polynomial-time Nash equilibrium algorithm for repeated games.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 48-54, San Diego, CA, 2003. [17] R. D. Luce and H. Raiffa.",
                "Games and Decisions.",
                "John Wiley and Sons, New York, 1957.",
                "Dover republication 1989. [18] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown, and Y. Shoham.",
                "Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms.",
                "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), New York, NY, USA, 2004. [20] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "MIT Press, 1994. [21] C. Papadimitriou.",
                "Algorithms, games and the Internet.",
                "In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 749-753, 2001. 89 [22] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 664-669, San Jose, CA, USA, 2004. [23] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 495-501, Pittsburgh, PA, USA, 2005. [24] J. von Neumann.",
                "Zur Theorie der Gesellschaftsspiele.",
                "Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg.",
                "Marktform und Gleichgewicht.",
                "Springer, Vienna, 1934. [26] B. von Stengel and S. Zamir.",
                "Leadership with commitment to mixed strategies.",
                "CDAM Research Report LSE-CDAM-2004-01, London School of Economics, Feb. 2004. 90"
            ],
            "original_annotated_samples": [
                "Being forced to commit to a <br>pure strategy</br> sometimes helps, and sometimes hurts (for example, committing to a <br>pure strategy</br> in rock-paper-scissors before the other players decision will naturally result in a loss).",
                "For example, if the leader is able to commit to a mixed strategy in the original game, then every one of the (continuum of) mixed strategies constitutes a <br>pure strategy</br> in the extensive-form representation of the leadership situation. (We note that a commitment to a distribution is not the same as a distribution over commitments.)",
                "NORMAL-FORM GAMES In this section, we study how to compute the optimal strategy to commit to for games represented in normal form. 2.1 Definitions In a normal-form game, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a <br>pure strategy</br> for every player, also known as a profile of pure strategies) to a real number.",
                "To ease notation, in the case of two players, we will refer to player 1s <br>pure strategy</br> set as S, and player 2s <br>pure strategy</br> set as T. Such games can be represented in (bi-)matrix form, in which the rows correspond to player 1s pure strategies, the columns correspond to player 2s pure strategies, and the entries of the matrix give the row and column players utilities (in that order) for the corresponding outcome of the game.",
                "Nevertheless, if the row player has the ability to commit to a <br>pure strategy</br> before the column player chooses his strategy, the row player should commit to the bottom strategy: doing so will make the column player prefer to play the right strategy, leading to a utility of 3 for the row player."
            ],
            "translated_annotated_samples": [
                "Verse obligado a comprometerse con una <br>estrategia pura</br> a veces ayuda y a veces perjudica (por ejemplo, comprometerse con una <br>estrategia pura</br> en piedra-papel-tijeras antes de la decisión de los otros jugadores naturalmente resultará en una derrota).",
                "Por ejemplo, si el líder es capaz de comprometerse con una estrategia mixta en el juego original, entonces cada una de las estrategias mixtas (continuo de) constituye una <br>estrategia pura</br> en la representación de forma extensiva de la situación de liderazgo. (Se destaca que un compromiso con una distribución no es lo mismo que una distribución sobre compromisos).",
                "JUEGOS EN FORMA NORMAL En esta sección, estudiamos cómo calcular la estrategia óptima a comprometerse para juegos representados en forma normal. 2.1 Definiciones En un juego en forma normal, cada jugador i ∈ {1, . . . , n} tiene un conjunto de estrategias puras (o acciones) Si, y una función de utilidad ui : S1×S2×. . .×Sn → R que mapea cada resultado (un vector que consiste en una <br>estrategia pura</br> para cada jugador, también conocido como un perfil de estrategias puras) a un número real.",
                "Para facilitar la notación, en el caso de dos jugadores, nos referiremos al conjunto de <br>estrategias puras</br> del jugador 1 como S, y al conjunto de <br>estrategias puras</br> del jugador 2 como T. Estos juegos pueden representarse en forma de matriz (bi-matriz), en la que las filas corresponden a las estrategias puras del jugador 1, las columnas corresponden a las estrategias puras del jugador 2, y las entradas de la matriz dan las utilidades de los jugadores de fila y columna (en ese orden) para el resultado correspondiente del juego.",
                "Sin embargo, si el jugador de la fila tiene la capacidad de comprometerse con una <br>estrategia pura</br> antes de que el jugador de la columna elija su estrategia, el jugador de la fila debería comprometerse con la estrategia inferior: al hacerlo, el jugador de la columna preferirá jugar la estrategia correcta, lo que llevará a una utilidad de 3 para el jugador de la fila."
            ],
            "translated_text": "En sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias simultáneamente. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. El reciente aumento en el interés por las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas a comprometerse tanto en el compromiso de estrategias puras como en el compromiso de estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Ofrecemos tanto resultados positivos (algoritmos eficientes) como resultados negativos (resultados de NP-hardness). Categorías y Descriptores de Asignaturas J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas Términos Generales Algoritmos, Economía, Teoría 1. En sistemas multiagentes con agentes auto-interesados (incluyendo la mayoría de los entornos económicos), la acción óptima que un agente debe tomar depende de las acciones que tomen los otros agentes. Para analizar cómo un agente debería comportarse en tales situaciones, es necesario aplicar las herramientas de la teoría de juegos. Normalmente, cuando se modela un escenario estratégico en el marco de la teoría de juegos, se asume que los jugadores eligen sus estrategias de forma simultánea. Esto es especialmente cierto cuando el escenario se modela como un juego en forma normal, que solo especifica la utilidad de cada agente como una función del vector de estrategias que los agentes eligen, y no proporciona información sobre el orden en que los agentes toman sus decisiones y lo que los agentes observan sobre las decisiones anteriores de otros agentes. Dado que el juego está modelado en forma normal, típicamente se analiza utilizando el concepto de equilibrio de Nash. Un equilibrio de Nash especifica una estrategia para cada jugador, de modo que ningún jugador tenga un incentivo para desviarse individualmente de este perfil de estrategias. (Por lo general, se permite que las estrategias sean mixtas, es decir, distribuciones de probabilidad sobre las estrategias originales (puras).) Un equilibrio de Nash (de estrategia mixta) está garantizado de existir en juegos finitos [18], pero un problema es que puede haber múltiples equilibrios de Nash. Esto conduce al problema de selección de equilibrio de cómo un agente puede saber qué estrategia jugar si no sabe qué equilibrio se va a jugar. Cuando el escenario se modela como un juego de forma extensiva, es posible especificar que algunos jugadores reciben información sobre las acciones tomadas por otros antes en el juego antes de decidir su acción. Sin embargo, en general, los jugadores no saben todo lo que sucedió anteriormente en el juego. Por lo tanto, estos juegos suelen ser analizados todavía utilizando un concepto de equilibrio, donde se especifica una estrategia mixta para cada jugador, y se requiere que la estrategia de cada jugador sea una mejor respuesta a las estrategias de los demás. (Normalmente se impone ahora una restricción adicional en las estrategias para garantizar que los jugadores no jueguen de una manera irracional con respecto a la información que han recibido hasta el momento). Esto conduce a refinamientos del equilibrio de Nash como el equilibrio perfecto en subjuegos y el equilibrio secuencial. Sin embargo, en muchos entornos del mundo real, las estrategias no se seleccionan de manera simultánea. A menudo, un jugador (el líder) puede comprometerse con una estrategia antes que otro jugador (el seguidor). Esto puede deberse a una variedad de razones. Por ejemplo, uno de los jugadores puede llegar al lugar donde se jugará el juego antes que otro agente (por ejemplo, en entornos económicos, un jugador puede ingresar al mercado antes y comprometerse con una forma de hacer negocios). Un compromiso tan poderoso tiene un impacto profundo en cómo debería jugarse el juego. Por ejemplo, el líder puede estar mejor jugando una estrategia que esté dominada en la representación de forma normal del juego. Quizás el ejemplo más temprano y conocido del efecto del compromiso es el de von Stackelberg [25], quien demostró que, en el modelo de duopolio de Cournot [5], si una empresa puede comprometerse con una cantidad de producción primero, esa empresa lo hará mucho mejor que en la solución de movimiento simultáneo (Nash). En general, si es posible comprometerse con estrategias mixtas, entonces (bajo suposiciones menores) nunca perjudica, y a menudo ayuda, comprometerse con una estrategia [26]. Verse obligado a comprometerse con una <br>estrategia pura</br> a veces ayuda y a veces perjudica (por ejemplo, comprometerse con una <br>estrategia pura</br> en piedra-papel-tijeras antes de la decisión de los otros jugadores naturalmente resultará en una derrota). En este documento, asumiremos que el compromiso siempre es forzado; si no lo es, el jugador que tiene la opción de comprometerse simplemente puede comparar el resultado del compromiso con el resultado de no comprometerse (movimiento simultáneo). Los modelos de liderazgo son especialmente importantes en entornos con múltiples agentes de software con intereses propios. Una vez que el código de un agente (o de un equipo de agentes) está finalizado y el agente es desplegado, el agente se compromete a jugar la estrategia (posiblemente aleatoria) que el código prescribe. Por lo tanto, siempre y cuando se pueda demostrar de manera creíble que no se puede cambiar el código más tarde, el código funciona como un dispositivo de compromiso. Esto es válido para torneos recreativos entre agentes (por ejemplo, torneos de póker, RoboSoccer) y para aplicaciones industriales como redes de sensores. Finalmente, también existe una situación de liderazgo implícito en el campo del diseño de mecanismos, en la cual un jugador (el diseñador) tiene la oportunidad de elegir las reglas del juego que los demás jugadores luego siguen. El diseño de mecanismos es un tema extremadamente importante para la comunidad de EC: los artículos publicados sobre diseño de mecanismos en las recientes conferencias de EC son demasiados para citar. De hecho, el diseñador del mecanismo puede beneficiarse al comprometerse con una elección que, si las acciones de los agentes (restantes) estuvieran fijas, sería subóptima. Por ejemplo, en una subasta (a precio fijo), el vendedor puede desear establecer un precio de reserva positivo (artificial) para el artículo, por debajo del cual el artículo no se venderá, incluso si el vendedor valora el artículo en 0. En retrospectiva (después de recibir las ofertas), esto (ingenuamente) parece subóptimo: si llegaba una oferta que superaba el precio de reserva, el precio de reserva no tenía efecto, y si no llegaba tal oferta, el vendedor hubiera estado mejor aceptando una oferta más baja. Por supuesto, la razón para establecer el precio de reserva es incentivar a los postores a ofertar más alto, y debido a esto, establecer precios de reserva artificiales puede aumentar realmente los ingresos esperados para el vendedor. Recientemente se ha dedicado una cantidad significativa de investigación al cálculo de soluciones de acuerdo con varios conceptos de solución para escenarios en los que los agentes eligen sus estrategias simultáneamente, como la dominancia [7, 11, 3] y (especialmente) el equilibrio de Nash [8, 21, 16, 15, 2, 22, 23, 4]. Sin embargo, se ha ignorado el cálculo de la estrategia óptima a comprometerse en una situación de liderazgo. Teóricamente, las situaciones de liderazgo simplemente pueden ser consideradas como un juego de forma extensiva en el que un jugador elige una estrategia (para el juego original) primero. El número de estrategias en este juego de forma extensiva, sin embargo, puede ser extremadamente grande. Por ejemplo, si el líder es capaz de comprometerse con una estrategia mixta en el juego original, entonces cada una de las estrategias mixtas (continuo de) constituye una <br>estrategia pura</br> en la representación de forma extensiva de la situación de liderazgo. (Se destaca que un compromiso con una distribución no es lo mismo que una distribución sobre compromisos). Además, si el juego original es en sí mismo un juego de forma extensiva, el número de estrategias en la representación de forma extensiva de la situación de liderazgo (que es un juego de forma extensiva diferente) se vuelve aún más grande. Por lo tanto, generalmente no es factible computacionalmente simplemente transformar el juego original en la representación de forma extensiva de la situación de liderazgo; en su lugar, debemos analizar el juego en su representación original. En este artículo, estudiamos cómo calcular la estrategia óptima a comprometerse, tanto en juegos de forma normal (Sección 2) como en juegos bayesianos, que son un caso especial de juegos de forma extensiva (Sección 3). JUEGOS EN FORMA NORMAL En esta sección, estudiamos cómo calcular la estrategia óptima a comprometerse para juegos representados en forma normal. 2.1 Definiciones En un juego en forma normal, cada jugador i ∈ {1, . . . , n} tiene un conjunto de estrategias puras (o acciones) Si, y una función de utilidad ui : S1×S2×. . .×Sn → R que mapea cada resultado (un vector que consiste en una <br>estrategia pura</br> para cada jugador, también conocido como un perfil de estrategias puras) a un número real. Para facilitar la notación, en el caso de dos jugadores, nos referiremos al conjunto de <br>estrategias puras</br> del jugador 1 como S, y al conjunto de <br>estrategias puras</br> del jugador 2 como T. Estos juegos pueden representarse en forma de matriz (bi-matriz), en la que las filas corresponden a las estrategias puras del jugador 1, las columnas corresponden a las estrategias puras del jugador 2, y las entradas de la matriz dan las utilidades de los jugadores de fila y columna (en ese orden) para el resultado correspondiente del juego. En el caso de tres jugadores, usaremos R, S y T, para las estrategias puras de los jugadores 1, 2 y 3, respectivamente. Una estrategia mixta para un jugador es una distribución de probabilidad sobre las estrategias puras de ese jugador. En el caso de juegos de dos jugadores, nos referiremos al jugador 1 como el líder y al jugador 2 como el seguidor. Antes de definir estrategias de liderazgo óptimas, considera el siguiente juego que ilustra el efecto de la capacidad del líder para comprometerse. 2, 1 4, 0 1, 0 3, 1 En esta representación en forma normal, la estrategia inferior para el jugador de la fila está estrictamente dominada por la estrategia superior. Sin embargo, si el jugador de la fila tiene la capacidad de comprometerse con una <br>estrategia pura</br> antes de que el jugador de la columna elija su estrategia, el jugador de la fila debería comprometerse con la estrategia inferior: al hacerlo, el jugador de la columna preferirá jugar la estrategia correcta, lo que llevará a una utilidad de 3 para el jugador de la fila. ",
            "candidates": [],
            "error": [
                [
                    "estrategia pura",
                    "estrategia pura",
                    "estrategia pura",
                    "estrategia pura",
                    "estrategias puras",
                    "estrategias puras",
                    "estrategia pura"
                ]
            ]
        },
        "mixed strategy": {
            "translated_key": "estrategia mixta",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Computing the Optimal Strategy to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "We give both positive results (efficient algorithms) and negative results (NP-hardness results).",
                "Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent systems with self-interested agents (including most economic settings), the optimal action for one agent to take depends on the actions that the other agents take.",
                "To analyze how an agent should behave in such settings, the tools of game theory need to be applied.",
                "Typically, when a strategic setting is modeled in the framework of game theory, it is assumed that players choose their strategies simultaneously.",
                "This is especially true when the setting is modeled as a normal-form game, which only specifies each agents utility as a function of the vector of strategies that the agents choose, and does not provide any information on the order in which agents make their decisions and what the agents observe about earlier decisions by other agents.",
                "Given that the game is modeled in normal form, it is typically analyzed using the concept of Nash equilibrium.",
                "A Nash equilibrium specifies a strategy for each player, such that no player has an incentive to individually deviate from this profile of strategies. (Typically, the strategies are allowed to be mixed, that is, probability distributions over the original (pure) strategies.)",
                "A (mixed-strategy) Nash equilibrium is guaranteed to exist in finite games [18], but one problem is that there may be multiple Nash equilibria.",
                "This leads to the equilibrium selection problem of how an agent can know which strategy to play if it does not know which equilibrium is to be played.",
                "When the setting is modeled as an extensive-form game, it is possible to specify that some players receive some information about actions taken by others earlier in the game before deciding on their action.",
                "Nevertheless, in general, the players do not know everything that happened earlier in the game.",
                "Because of this, these games are typically still analyzed using an equilibrium concept, where one specifies a <br>mixed strategy</br> for each player, and requires that each players strategy is a best response to the others strategies. (Typically an additional constraint on the strategies is now imposed to ensure that players do not play in a way that is irrational with respect to the information that they have received so far.",
                "This leads to refinements of Nash equilibrium such as subgame perfect and sequential equilibrium.)",
                "However, in many real-world settings, strategies are not selected in such a simultaneous manner.",
                "Oftentimes, one player (the leader) is able to commit to a strategy before another player (the follower).",
                "This can be due to a variety of reasons.",
                "For example, one of the players may arrive at the site at which the game is to be played before another agent (e.g., in economic settings, one player may enter a market earlier and commit to a way of doing busi82 ness).",
                "Such commitment power has a profound impact on how the game should be played.",
                "For example, the leader may be best off playing a strategy that is dominated in the normal-form representation of the game.",
                "Perhaps the earliest and best-known example of the effect of commitment is that by von Stackelberg [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution.",
                "In general, if commitment to mixed strategies is possible, then (under minor assumptions) it never hurts, and often helps, to commit to a strategy [26].",
                "Being forced to commit to a pure strategy sometimes helps, and sometimes hurts (for example, committing to a pure strategy in rock-paper-scissors before the other players decision will naturally result in a loss).",
                "In this paper, we will assume commitment is always forced; if it is not, the player who has the choice of whether to commit can simply compare the commitment outcome to the non-commitment (simultaneous-move) outcome.",
                "Models of leadership are especially important in settings with multiple self-interested software agents.",
                "Once the code for an agent (or for a team of agents) is finalized and the agent is deployed, the agent is committed to playing the (possibly randomized) strategy that the code prescribes.",
                "Thus, as long as one can credibly show that one cannot change the code later, the code serves as a commitment device.",
                "This holds true for recreational tournaments among agents (e.g., poker tournaments, RoboSoccer), and for industrial applications such as sensor webs.",
                "Finally, there is also an implicit leadership situation in the field of mechanism design, in which one player (the designer) gets to choose the rules of the game that the remaining players then play.",
                "Mechanism design is an extremely important topic to the EC community: the papers published on mechanism design in recent EC conferences are too numerous to cite.",
                "Indeed, the mechanism designer may benefit from committing to a choice that, if the (remaining) agents actions were fixed, would be suboptimal.",
                "For example, in a (first-price) auction, the seller may wish to set a positive (artificial) reserve price for the item, below which the item will not be sold-even if the seller values the item at 0.",
                "In hindsight (after the bids have come in), this (na¨ıvely) appears suboptimal: if a bid exceeding the reserve price came in, the reserve price had no effect, and if no such bid came in, the seller would have been better off accepting a lower bid.",
                "Of course, the reason for setting the reserve price is that it incentivizes the bidders to bid higher, and because of this, setting artificial reserve prices can actually increase expected revenue to the seller.",
                "A significant amount of research has recently been devoted to the computation of solutions according to various solution concepts for settings in which the agents choose their strategies simultaneously, such as dominance [7, 11, 3] and (especially) Nash equilibrium [8, 21, 16, 15, 2, 22, 23, 4].",
                "However, the computation of the optimal strategy to commit to in a leadership situation has gone ignored.",
                "Theoretically, leadership situations can simply be thought of as an extensive-form game in which one player chooses a strategy (for the original game) first.",
                "The number of strategies in this extensive-form game, however, can be exceedingly large.",
                "For example, if the leader is able to commit to a <br>mixed strategy</br> in the original game, then every one of the (continuum of) mixed strategies constitutes a pure strategy in the extensive-form representation of the leadership situation. (We note that a commitment to a distribution is not the same as a distribution over commitments.)",
                "Moreover, if the original game is itself an extensive-form game, the number of strategies in the extensive-form representation of the leadership situation (which is a different extensive-form game) becomes even larger.",
                "Because of this, it is usually not computationally feasible to simply transform the original game into the extensive-form representation of the leadership situation; instead, we have to analyze the game in its original representation.",
                "In this paper, we study how to compute the optimal strategy to commit to, both in normal-form games (Section 2) and in Bayesian games, which are a special case of extensiveform games (Section 3). 2.",
                "NORMAL-FORM GAMES In this section, we study how to compute the optimal strategy to commit to for games represented in normal form. 2.1 Definitions In a normal-form game, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a pure strategy for every player, also known as a profile of pure strategies) to a real number.",
                "To ease notation, in the case of two players, we will refer to player 1s pure strategy set as S, and player 2s pure strategy set as T. Such games can be represented in (bi-)matrix form, in which the rows correspond to player 1s pure strategies, the columns correspond to player 2s pure strategies, and the entries of the matrix give the row and column players utilities (in that order) for the corresponding outcome of the game.",
                "In the case of three players, we will use R, S, and T, for player 1, 2, and 3s pure strategies, respectively.",
                "A <br>mixed strategy</br> for a player is a probability distribution over that players pure strategies.",
                "In the case of two-player games, we will refer to player 1 as the leader and player 2 as the follower.",
                "Before defining optimal leadership strategies, consider the following game which illustrates the effect of the leaders ability to commit. 2, 1 4, 0 1, 0 3, 1 In this normal-form representation, the bottom strategy for the row player is strictly dominated by the top strategy.",
                "Nevertheless, if the row player has the ability to commit to a pure strategy before the column player chooses his strategy, the row player should commit to the bottom strategy: doing so will make the column player prefer to play the right strategy, leading to a utility of 3 for the row player.",
                "By contrast, if the row player were to commit to the top strategy, the column player would prefer to play the left strategy, leading to a utility of only 2 for the row player.",
                "If the row player is able to commit to a <br>mixed strategy</br>, then she can get an even greater (expected) utility: if the row player commits to placing probability p > 1/2 on the bottom strategy, then the column player will still prefer to play the right strategy, and the row players expected utility will be 3p + 4(1 − p) = 4 − p ≥ 3.",
                "If the row player plays each strategy with probability exactly 1/2, the column player is 83 indifferent between the strategies.",
                "In such cases, we will assume that the column player will choose the strategy that maximizes the row players utility (in this case, the right strategy).",
                "Hence, the optimal <br>mixed strategy</br> to commit to for the row player is p = 1/2.",
                "There are a few good reasons for this assumption.",
                "If we were to assume the opposite, then there would not exist an optimal strategy for the row player in the example game: the row player would play the bottom strategy with probability p = 1/2 + with > 0, and the smaller , the better the utility for the row player.",
                "By contrast, if we assume that the follower always breaks ties in the leaders favor, then an optimal <br>mixed strategy</br> for the leader always exists, and this corresponds to a subgame perfect equilibrium of the extensive-form representation of the leadership situation.",
                "In any case, this is a standard assumption for such models (e.g. [20]), although some work has investigated what can happen in the other subgame perfect equilibria [26]. (For generic two-player games, the leaders subgame-perfect equilibrium payoff is unique.)",
                "Also, the same assumption is typically used in mechanism design, in that it is assumed that if an agent is indifferent between revealing his preferences truthfully and revealing them falsely, he will report them truthfully.",
                "Given this assumption, we can safely refer to optimal leadership strategies rather than having to use some equilibrium notion.",
                "Hence, for the purposes of this paper, an optimal strategy to commit to in a 2-player game is a strategy s ∈ S that maximizes maxt∈BR(s) ul(s, t), where BR(s) = arg maxt∈T uf (s, t). (ul and uf are the leader and followers utility functions, respectively.)",
                "We can have S = S for the case of commitment to pure strategies, or S = ∆(S), the set of probability distributions over S, for the case of commitment to mixed strategies. (We note that replacing T by ∆(T) makes no difference in this definition.)",
                "For games with more than two players, in which the players commit to their strategies in sequence, we define optimal strategies to commit to recursively.",
                "After the leader commits to a strategy, the game to be played by the remaining agents is itself a (smaller) leadership game.",
                "Thus, we define an optimal strategy to commit to as a strategy that maximizes the leaders utility, assuming that the play of the remaining agents is itself optimal under this definition, and maximizes the leaders utility among all optimal ways to play the remaining game.",
                "Again, commitment to mixed strategies may or may not be a possibility for every player (although for the last player it does not matter if we allow for commitment to mixed strategies). 2.2 Commitment to pure strategies We first study how to compute the optimal pure strategy to commit to.",
                "This is relatively simple, because the number of strategies to commit to is not very large. (In the following, #outcomes is the number of complete strategy profiles.)",
                "Theorem 1.",
                "Under commitment to pure strategies, the set of all optimal strategy profiles in a normal-form game can be found in O(#players · #outcomes) time.",
                "Proof.",
                "Each pure strategy that the first player may commit to will induce a subgame for the remaining players.",
                "We can solve each such subgame recursively to find all of its optimal strategy profiles; each of these will give the original leader some utility.",
                "Those that give the leader maximal utility correspond exactly to the optimal strategy profiles of the original game.",
                "We now present the algorithm formally.",
                "Let Su(G, s1) be the subgame that results after the first (remaining) player in G plays s1 ∈ SG 1 .",
                "A game with 0 players is simply an outcome of the game.",
                "The function Append(s, O) appends the strategy s to each of the vectors of strategies in the set O.",
                "Let e be the empty vector with no elements.",
                "In a slight abuse of notation, we will write uG 1 (C) when all strategy profiles in the set C give player 1 the same utility in the game G. (Here, player 1 is the first remaining player in the subgame G, not necessarily player 1 in the original game.)",
                "We note that arg max is set-valued.",
                "Then, the following algorithm computes all optimal strategy profiles: Algorithm Solve(G) if G has 0 players return {e} C ← ∅ for all s1 ∈ SG 1 { O ← Solve(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) if C = ∅ or uG 1 (s1, O ) = uG 1 (C) C ← C∪Append(s1, O ) if uG 1 (s1, O ) > uG 1 (C) C ←Append(s1, O ) } return C Every outcome is (potentially) examined by every player, which leads to the given runtime bound.",
                "As an example of how the algorithm works, consider the following 3-player game, in which the first player chooses the left or right matrix, the second player chooses a row, and the third player chooses a column. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 3,0,0 First we eliminate the outcomes that do not correspond to best responses for the third player (removing them from the matrix): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Next, we remove the entries in which the third player does not break ties in favor of the second player, as well as entries that do not correspond to best responses for the second player. 0,1,1 2,1,1 1,1,1 0,5,1 Finally, we remove the entries in which the second and third players do not break ties in favor of the first player, as well as entries that do not correspond to best responses for the first player. 2,1,1 84 Hence, in optimal play, the first player chooses the left matrix, the second player chooses the middle row, and the third player chooses the left column. (We note that this outcome is Pareto-dominated by (Right, Middle, Left).)",
                "For general normal-form games, each players utility for each of the outcomes has to be explicitly represented in the input, so that the input size is itself Ω(#players · #outcomes).",
                "Therefore, the algorithm is in fact a linear-time algorithm. 2.3 Commitment to mixed strategies In the special case of two-player zero-sum games, computing an optimal <br>mixed strategy</br> for the leader to commit to is equivalent to computing a minimax strategy, which minimizes the maximum expected utility that the opponent can obtain.",
                "Minimax strategies constitute the only natural solution concept for two-player zero-sum games: von Neumanns Minimax Theorem [24] states that in two-player zero-sum games, it does not matter (in terms of the players utilities) which player gets to commit to a <br>mixed strategy</br> first, and a profile of mixed strategies is a Nash equilibrium if and only if both strategies are minimax strategies.",
                "It is well-known that a minimax strategy can be found in polynomial time, using linear programming [17].",
                "Our first result in this section generalizes this result, showing that an optimal <br>mixed strategy</br> for the leader to commit to can be efficiently computed in general-sum two-player games, again using linear programming.",
                "Theorem 2.",
                "In 2-player normal-form games, an optimal <br>mixed strategy</br> to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "For every pure follower strategy t, we compute a <br>mixed strategy</br> for the leader such that 1) playing t is a best response for the follower, and 2) under this constraint, the <br>mixed strategy</br> maximizes the leaders utility.",
                "Such a <br>mixed strategy</br> can be computed using the following simple linear program: maximize s∈S psul(s, t) subject to for all t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1 We note that this program may be infeasible for some follower strategies t, for example, if t is a strictly dominated strategy.",
                "Nevertheless, the program must be feasible for at least some follower strategies; among these follower strategies, choose a strategy t∗ that maximizes the linear programs solution value.",
                "Then, if the leader chooses as her <br>mixed strategy</br> the optimal settings of the variables ps for the linear program for t∗ , and the follower plays t∗ , this constitutes an optimal strategy profile.",
                "In the following result, we show that we cannot expect to solve the problem more efficiently than linear programming, because we can reduce any linear program with a probability constraint on its variables to a problem of computing the optimal <br>mixed strategy</br> to commit to in a 2-player normalform game.",
                "Theorem 3.",
                "Any linear program whose variables xi (with xi ∈ R≥0 ) must satsify i xi = 1 can be modeled as a problem of computing the optimal <br>mixed strategy</br> to commit to in a 2-player normal-form game.",
                "Proof.",
                "Let the leader have a pure strategy i for every variable xi.",
                "Let the column player have one pure strategy j for every constraint in the linear program (other than i xi = 1), and a single additional pure strategy 0.",
                "Let the utility functions be as follows.",
                "Writing the objective of the linear program as maximize i cixi, for any i, let ul(i, 0) = ci and uf (i, 0) = 0.",
                "Writing the jth constraint of the linear program (not including i xi = 1) as i aijxi ≤ bj, for any i, j > 0, let ul(i, j) = mini ci − 1 and uf (i, j) = aij − bj.",
                "For example, consider the following linear program. maximize 2x1 + x2 subject to x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 The optimal solution to this program is x1 = 1/3, x2 = 2/3.",
                "Our reduction transforms this program into the following leader-follower game (where the leader is the row player). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 Indeed, the optimal strategy for the leader is to play the top strategy with probability 1/3 and the bottom strategy with probability 2/3.",
                "We now show that the reduction works in general.",
                "Clearly, the leader wants to incentivize the follower to play 0, because the utility that the leader gets when the follower plays 0 is always greater than when the follower does not play 0.",
                "In order for the follower not to prefer playing j > 0 rather than 0, it must be the case that i pl(i)(aij − bj) ≤ 0, or equivalently i pl(i)aij ≤ bj.",
                "Hence the leader will get a utility of at least mini ci if and only if there is a feasible solution to the constraints.",
                "Given that the pl(i) incentivize the follower to play 0, the leader attempts to maximize i pl(i)ci.",
                "Thus the leader must solve the original linear program.",
                "As an alternative proof of Theorem 3, one may observe that it is known that finding a minimax strategy in a zerosum game is as hard as the linear programming problem [6], and as we pointed out at the beginning of this section, computing a minimax strategy in a zero-sum game is a special case of the problem of computing an optimal <br>mixed strategy</br> to commit to.",
                "This polynomial-time solvability of the problem of computing an optimal <br>mixed strategy</br> to commit to in two-player normal-form games contrasts with the unknown complexity of computing a Nash equilibrium in such games [21], as well as with the NP-hardness of finding a Nash equilibrium with maximum utility for a given player in such games [8, 2].",
                "Unfortunately, this result does not generalize to more than two players-here, the problem becomes NP-hard.",
                "To show this, we reduce from the VERTEX-COVER problem.",
                "Definition 1.",
                "In VERTEX-COVER, we are given a graph G = (V, E) and an integer K. We are asked whether there 85 exists a subset of the vertices S ⊆ V , with |S| = K, such that every edge e ∈ E has at least one of its endpoints in S. BALANCED-VERTEX-COVER is the special case of VERTEX-COVER in which K = |V |/2.",
                "VERTEX-COVER is NP-complete [9].",
                "The following lemma shows that the hardness remains if we require K = |V |/2. (Similar results have been shown for other NP-complete problems.)",
                "Lemma 1.",
                "BALANCED-VERTEX-COVER is NP-complete.",
                "Proof.",
                "Membership in NP follows from the fact that the problem is a special case of VERTEX-COVER, which is in NP.",
                "To show NP-hardness, we reduce an arbitrary VERTEX-COVER instance to a BALANCED-VERTEXCOVER instance, as follows.",
                "If, for the VERTEX-COVER instance, K > |V |/2, then we simply add isolated vertices that are disjoint from the rest of the graph, until K = |V |/2.",
                "If K < |V |/2, we add isolated triangles (that is, the complete graph on three vertices) to the graph, increasing K by 2 every time, until K = |V |/2.",
                "Theorem 4.",
                "In 3-player normal-form games, finding an optimal <br>mixed strategy</br> to commit to is NP-hard.",
                "Proof.",
                "We reduce an arbitrary BALANCED-VERTEXCOVER instance to the following 3-player normal-form game.",
                "For every vertex v, each of the three players has a pure strategy corresponding to that vertex (rv, sv, tv, respectively).",
                "In addition, for every edge e, the third player has a pure strategy te; and finally, the third player has one additional pure strategy t0.",
                "The utilities are as follows: • for all r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • for all r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • for all v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • for all v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • for all v ∈ V , for all r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V | |V |−2 ; • for all e ∈ E, s ∈ S, for both v ∈ e, u3(rv, s, te) = 0; • for all e ∈ E, s ∈ S, for all v /∈ e, u3(rv, s, te) = |V | |V |−2 . • for all r ∈ R, s ∈ S, u3(r, s, t0) = 1.",
                "We note that players 1 and 2 have the same utility function.",
                "We claim that there is an optimal strategy profile in which players 1 and 2 both obtain 1 (their maximum utility) if and only if there is a solution to the BALANCED-VERTEXCOVER problem. (Otherwise, these players will both obtain 0.)",
                "First, suppose there exists a solution to the BALANCEDVERTEX-COVER problem.",
                "Then, let player 1 play every rv such that v is in the cover with probability 2 |V | , and let player 2 play every sv such that v is not in the cover with probability 2 |V | .",
                "Then, for player 3, the expected utility of playing tv (for any v) is (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of 2 |V | that rv or sv is played.",
                "Additionally, the expected utility of playing te (for any e) is at most (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of at least 2 |V | that some rv with v ∈ e is played (because player 1 is randomizing over the pure strategies corresponding to the cover).",
                "It follows that playing t0 is a best response for player 3, giving players 1 and 2 a utility of 1.",
                "Now, suppose that players 1 and 2 obtain 1 in optimal play.",
                "Then, it must be the case that player 3 plays t0.",
                "Hence, for every v ∈ V , there must be a probability of at least 2 |V | that either rv or sv is played, for otherwise player 3 would be better off playing tv.",
                "Because players 1 and 2 have only a total probability of 2 to distribute, it must be the case that for each v, either rv or sv is played with probability 2 |V | , and the other is played with probability 0. (It is not possible for both to have nonzero probability, because then there would be some probability that both are played simultaneously (correlation is not possible), hence the total probability of at least one being played could not be high enough for all vertices.)",
                "Thus, for exactly half the v ∈ V , player 1 places probability 2 |V | on rv.",
                "Moreover, for every e ∈ E, there must be a probability of at least 2 |V | that some rv with v ∈ e is played, for otherwise player 3 would be better off playing te.",
                "Thus, the v ∈ V such that player 1 places probability 2 |V | on rv constitute a balanced vertex cover. 3.",
                "BAYESIAN GAMES So far, we have restricted our attention to normal-form games.",
                "In a normal-form game, it is assumed that every agent knows every other agents preferences over the outcomes of the game.",
                "In general, however, agents may have some private information about their preferences that is not known to the other agents.",
                "Moreover, at the time of commitment to a strategy, the agents may not even know their own (final) preferences over the outcomes of the game yet, because these preferences may be dependent on a context that has yet to materialize.",
                "For example, when the code for a trading agent is written, it may not yet be clear how that agent will value resources that it will negotiate over later, because this depends on information that is not yet available at the time at which the code is written (such as orders that will have been placed to the agent before the negotiation).",
                "In this section, we will study commitment in Bayesian games, which can model such uncertainty over preferences. 3.1 Definitions In a Bayesian game, every player i has a set of actions Si, a set of types Θi with an associated probability distribution πi : Θi → [0, 1], and, for each type θi, a utility function uθi i : S1 × S2 × . . . × Sn → R. A pure strategy in a Bayesian game is a mapping from the players types to actions, σi : Θi → Si. (Bayesian games can be rewritten in normal form by enumerating every pure strategy σi, but this will cause an exponential blowup in the size of the representation of the game and therefore cannot lead to efficient algorithms.)",
                "The strategy that the leader should commit to depends on whether, at the time of commitment, the leader knows her own type.",
                "If the leader does know her own type, the other types that the leader might have had become irrelevant and the leader should simply commit to the strategy that is optimal for the type.",
                "However, as argued above, the leader does not necessarily know her own type at the time of commitment (e.g., the time at which the code is submitted).",
                "In this case, the leader must commit to a strategy that is 86 dependent upon the leaders eventual type.",
                "We will study this latter model, although we will pay specific attention to the case where the leader has only a single type, which is effectively the same as the former model. 3.2 Commitment to pure strategies It turns out that computing an optimal pure strategy to commit to is hard in Bayesian games, even with two players.",
                "Theorem 5.",
                "Finding an optimal pure strategy to commit to in 2-player Bayesian games is NP-hard, even when the follower has only a single type.",
                "Proof.",
                "We reduce an arbitrary VERTEX-COVER instance to the following Bayesian game between the leader and the follower.",
                "The leader has K types θ1, θ2, . . . , θK , each occurring with probability 1/K, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has only a single type; for each edge e ∈ E, the follower has an action te, and the follower has a single additional action t0.",
                "The utility function for the leader is given by, for all θl ∈ Θl and all s ∈ S, u θl l (s, t0) = 1, and for all e ∈ E, u θl l (s, te) = 0.",
                "The followers utility is given by: • For all v ∈ V , for all e ∈ E with v /∈ e, uf (sv, te) = 1; • For all v ∈ V , for all e ∈ E with v ∈ e, uf (sv, te) = −K; • For all v ∈ V , uf (sv, t0) = 0.",
                "We claim that the leader can get a utility of 1 if and only if there is a solution to the VERTEX-COVER instance.",
                "First, suppose that there is a solution to the VERTEXCOVER instance.",
                "Then, the leader can commit to a pure strategy such that for each vertex v in the cover, the leader plays sv for some type.",
                "Then, the followers utility for playing te (for any e ∈ E) is at most K−1 K + 1 K (−K) = − 1 K , so that the follower will prefer to play t0, which gives the leader a utility of 1, as required.",
                "Now, suppose that there is a pure strategy for the leader that will give the leader a utility of 1.",
                "Then, the follower must play t0.",
                "In order for the follower not to prefer playing te (for any e ∈ E) instead, for at least one v ∈ e the leader must play sv for some type θl.",
                "Hence, the set of vertices v that the leader plays for some type must constitute a vertex cover; and this set can have size at most K, because the leader has only K types.",
                "So there is a solution to the VERTEXCOVER instance.",
                "However, if the leader has only a single type, then the problem becomes easy again (#types is the number of types for the follower): Theorem 6.",
                "In 2-player Bayesian games in which the leader has only a single type, an optimal pure strategy to commit to can be found in O(#outcomes · #types) time.",
                "Proof.",
                "For every leader action s, we can compute, for every follower type θf ∈ Θf , which actions t maximize the followers utility; call this set of actions BRθf (s).",
                "Then, the utility that the leader receives for committing to action s can be computed as θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), and the leader can choose the best action to commit to. 3.3 Commitment to mixed strategies In two-player zero-sum imperfect information games with perfect recall (no player ever forgets something that it once knew), a minimax strategy can be constructed in polynomial time [12, 13].",
                "Unfortunately, this result does not extend to computing optimal mixed strategies to commit to in the general-sum case-not even in Bayesian games.",
                "We will exhibit NP-hardness by reducing from the INDEPENDENTSET problem.",
                "Definition 2.",
                "In INDEPENDENT-SET, we are given a graph G = (V, E) and an integer K. We are asked whether there exists a subset of the vertices S ⊆ V , with |S| = K, such that no edge e ∈ E has both of its endpoints in S. Again, this problem is NP-complete [9].",
                "Theorem 7.",
                "Finding an optimal <br>mixed strategy</br> to commit to in 2-player Bayesian games is NP-hard, even when the leader has only a single type and the follower has only two actions.",
                "Proof.",
                "We reduce an arbitrary INDEPENDENT-SET instance to the following Bayesian game between the leader and the follower.",
                "The leader has only a single type, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has a type θv for every v ∈ V , occurring with probability 1 (|E|+1)|V | , and a type θe for every e ∈ E, occurring with probability 1 |E|+1 .",
                "The follower has two actions: t0 and t1.",
                "The leaders utility is given by, for all s ∈ S, ul(s, t0) = 1 and ul(s, t1) = 0.",
                "The followers utility is given by: • For all v ∈ V , uθv f (sv, t1) = 0; • For all v ∈ V and s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • For all v ∈ V and s ∈ S, uθv f (s, t0) = 1; • For all e ∈ E, s ∈ S, uθe f (s, t0) = 1; • For all e ∈ E, for both v ∈ e, uθe f (sv, t1) = 2K 3 ; • For all e ∈ E, for all v /∈ e, uθe f (sv, t1) = 0.",
                "We claim that an optimal strategy to commit to gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | if and only if there is a solution to the INDEPENDENT-SET instance.",
                "First, suppose that there is a solution to the INDEPENDENT-SET instance.",
                "Then, the leader could commit to the following strategy: for every vertex v in the independent set, play the corresponding sv with probability 1/K.",
                "If the follower has type θe for some e ∈ E, the expected utility for the follower of playing t1 is at most 1 K 2K 3 = 2/3, because there is at most one vertex v ∈ e such that sv is played with nonzero probability.",
                "Hence, the follower will play t0 and obtain a utility of 1.",
                "If the follower has type θv for some vertex v in the independent set, the expected utility for the follower of playing t1 is K−1 K K K−1 = 1, because the leader plays sv with probability 1/K.",
                "It follows that the follower (who breaks ties to maximize the leaders utility) will play t0, which also gives a utility of 1 and gives the leader a higher utility.",
                "Hence the leaders expected utility for this strategy is at least |E| |E|+1 + K (|E|+1)|V | , as required. 87 Now, suppose that there is a strategy that gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | .",
                "Then, this strategy must induce the follower to play t0 whenever it has a type of the form θe (because otherwise, the utility could be at most |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ).",
                "Thus, it cannot be the case that for some edge e = (v1, v2) ∈ E, the probability that the leader plays one of sv1 and sv2 is at least 2/K, because then the expected utility for the follower of playing t1 when it has type θe would be at least 2 K 2K 3 = 4/3 > 1.",
                "Moreover, the strategy must induce the follower to play t0 for at least K types of the form θv.",
                "Inducing the follower to play t0 when it has type θv can be done only by playing sv with probability at least 1/K, which will give the follower a utility of at most K−1 K K K−1 = 1 for playing t1.",
                "But then, the set of vertices v such that sv is played with probability at least 1/K must constitute an independent set of size K (because if there were an edge e between two such vertices, it would induce the follower to play t1 for type θe by the above).",
                "By contrast, if the follower has only a single type, then we can generalize the linear programming approach for normalform games: Theorem 8.",
                "In 2-player Bayesian games in which the follower has only a single type, an optimal <br>mixed strategy</br> to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "We generalize the approach in Theorem 2 as follows.",
                "For every pure follower strategy t, we compute a <br>mixed strategy</br> for the leader for every one of the leaders types such that 1) playing t is a best response for the follower, and 2) under this constraint, the <br>mixed strategy</br> maximizes the leaders ex ante expected utility.",
                "To do so, we generalize the linear program as follows: maximize θl∈Θl π(θl) s∈S pθl s uθl l (s, t) subject to for all t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t ) for all θl ∈ Θl, s∈S p θl s = 1 As in Theorem 2, the solution for the linear program that maximizes the solution value is an optimal strategy to commit to.",
                "This shows an interesting contrast between commitment to pure strategies and commitment to mixed strategies in Bayesian games: for pure strategies, the problem becomes easy if the leader has only a single type (but not if the follower has only a single type), whereas for mixed strategies, the problem becomes easy if the follower has only a single type (but not if the leader has only a single type). 4.",
                "CONCLUSIONS AND FUTURE RESEARCH In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "This requires some equilibrium notion (Nash equilibrium and its refinements), and often leads to the equilibrium selection problem: it is unclear to each individual player according to which equilibrium she should play.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "For example, one agent may arrive at the (real or virtual) site of the game before the other, or, in the specific case of software agents, the code for one agent may be completed and committed before that of another agent.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "Specifically, if commitment to mixed strategies is possible, then (optimal) commitment never hurts the leader, and often helps.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we studied how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "For normal-form games, we showed that the optimal pure strategy to commit to can be found efficiently for any number of players.",
                "An optimal <br>mixed strategy</br> to commit to in a normal-form game can be found efficiently for two players using linear programming (and no more efficiently than that, in the sense that any linear program with a probability constraint can be encoded as such a problem). (This is a generalization of the polynomial-time computability of minimax strategies in normal-form games.)",
                "The problem becomes NP-hard for three (or more) players.",
                "In Bayesian games, the problem of finding an optimal pure strategy to commit to is NP-hard even in two-player games in which the follower has only a single type, although two-player games in which the leader has only a single type can be solved efficiently.",
                "The problem of finding an optimal <br>mixed strategy</br> to commit to in a Bayesian game is NP-hard even in two-player games in which the leader has only a single type, although two-player games in which the follower has only a single type can be solved efficiently using a generalization of the linear progamming approach for normal-form games.",
                "The following two tables summarize these results. 2 players ≥ 3 players normal-form O(#outcomes) O(#outcomes· #players) Bayesian, O(#outcomes· NP-hard 1-type leader #types) Bayesian, NP-hard NP-hard 1-type follower Bayesian (general) NP-hard NP-hard Results for commitment to pure strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.) 88 2 players ≥ 3 players normal-form one LP-solve per NP-hard follower action Bayesian, NP-hard NP-hard 1-type leader Bayesian, one LP-solve per NP-hard 1-type follower follower action Bayesian (general) NP-hard NP-hard Results for commitment to mixed strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.)",
                "Future research can take a number of directions.",
                "First, we can empirically evaluate the techniques presented here on test suites such as GAMUT [19].",
                "We can also study the computation of optimal strategies to commit to in other1 concise representations of normal-form games-for example, in graphical games [10] or local-effect/action graph games [14, 1].",
                "For the cases where computing an optimal strategy to commit to is NP-hard, we can also study the computation of approximately optimal strategies to commit to.",
                "While the correct definition of an approximately optimal strategy is in this setting may appear simple at first-it should be a strategy that, if the following players play optimally, performs almost as well as the optimal strategy in expectation-this definition becomes problematic when we consider that the other players may also be playing only approximately optimally.",
                "One may also study models in which multiple (but not all) players commit at the same time.",
                "Another interesting direction to pursue is to see if computing optimal mixed strategies to commit to can help us in, or otherwise shed light on, computing Nash equilibria.",
                "Often, optimal mixed strategies to commit to are also Nash equilibrium strategies (for example, in two-player zero-sum games this is always true), although this is not always the case (for example, as we already pointed out, sometimes the optimal strategy to commit to is a strictly dominated strategy, which can never be a Nash equilibrium strategy). 5.",
                "REFERENCES [1] N. A. R. Bhat and K. Leyton-Brown.",
                "Computing Nash equilibria of action-graph games.",
                "In Proceedings of the 20th Annual Conference on Uncertainty in Artificial Intelligence (UAI), Banff, Canada, 2004. [2] V. Conitzer and T. Sandholm.",
                "Complexity results about Nash equilibria.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pages 765-771, Acapulco, Mexico, 2003. [3] V. Conitzer and T. Sandholm.",
                "Complexity of (iterated) dominance.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 88-97, Vancouver, Canada, 2005. [4] V. Conitzer and T. Sandholm.",
                "A generalized strategy eliminability criterion and computational methods for applying it.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 483-488, Pittsburgh, PA, USA, 2005. [5] A.",
                "A. Cournot.",
                "Recherches sur les principes math´ematiques de la th´eorie des richesses (Researches 1 Bayesian games are one potentially concise representation of normal-form games. into the Mathematical Principles of the Theory of Wealth).",
                "Hachette, Paris, 1838. [6] G. Dantzig.",
                "A proof of the equivalence of the programming problem and the game problem.",
                "In T. Koopmans, editor, Activity Analysis of Production and Allocation, pages 330-335.",
                "John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel.",
                "The complexity of eliminating dominated strategies.",
                "Mathematics of Operation Research, 18:553-565, 1993. [8] I. Gilboa and E. Zemel.",
                "Nash and correlated equilibria: Some complexity considerations.",
                "Games and Economic Behavior, 1:80-93, 1989. [9] R. Karp.",
                "Reducibility among combinatorial problems.",
                "In R. E. Miller and J. W. Thatcher, editors, Complexity of Computer Computations, pages 85-103.",
                "Plenum Press, NY, 1972. [10] M. Kearns, M. Littman, and S. Singh.",
                "Graphical models for game theory.",
                "In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou, and J. N. Tsitsiklis.",
                "A note on strategy elimination in bimatrix games.",
                "Operations Research Letters, 7(3):103-107, 1988. [12] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [14] K. Leyton-Brown and M. Tennenholtz.",
                "Local-effect games.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), Acapulco, Mexico, 2003. [15] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 36-41, San Diego, CA, 2003. [16] M. Littman and P. Stone.",
                "A polynomial-time Nash equilibrium algorithm for repeated games.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 48-54, San Diego, CA, 2003. [17] R. D. Luce and H. Raiffa.",
                "Games and Decisions.",
                "John Wiley and Sons, New York, 1957.",
                "Dover republication 1989. [18] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown, and Y. Shoham.",
                "Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms.",
                "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), New York, NY, USA, 2004. [20] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "MIT Press, 1994. [21] C. Papadimitriou.",
                "Algorithms, games and the Internet.",
                "In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 749-753, 2001. 89 [22] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 664-669, San Jose, CA, USA, 2004. [23] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 495-501, Pittsburgh, PA, USA, 2005. [24] J. von Neumann.",
                "Zur Theorie der Gesellschaftsspiele.",
                "Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg.",
                "Marktform und Gleichgewicht.",
                "Springer, Vienna, 1934. [26] B. von Stengel and S. Zamir.",
                "Leadership with commitment to mixed strategies.",
                "CDAM Research Report LSE-CDAM-2004-01, London School of Economics, Feb. 2004. 90"
            ],
            "original_annotated_samples": [
                "Because of this, these games are typically still analyzed using an equilibrium concept, where one specifies a <br>mixed strategy</br> for each player, and requires that each players strategy is a best response to the others strategies. (Typically an additional constraint on the strategies is now imposed to ensure that players do not play in a way that is irrational with respect to the information that they have received so far.",
                "For example, if the leader is able to commit to a <br>mixed strategy</br> in the original game, then every one of the (continuum of) mixed strategies constitutes a pure strategy in the extensive-form representation of the leadership situation. (We note that a commitment to a distribution is not the same as a distribution over commitments.)",
                "A <br>mixed strategy</br> for a player is a probability distribution over that players pure strategies.",
                "If the row player is able to commit to a <br>mixed strategy</br>, then she can get an even greater (expected) utility: if the row player commits to placing probability p > 1/2 on the bottom strategy, then the column player will still prefer to play the right strategy, and the row players expected utility will be 3p + 4(1 − p) = 4 − p ≥ 3.",
                "Hence, the optimal <br>mixed strategy</br> to commit to for the row player is p = 1/2."
            ],
            "translated_annotated_samples": [
                "Por lo tanto, estos juegos suelen ser analizados todavía utilizando un concepto de equilibrio, donde se especifica una <br>estrategia mixta</br> para cada jugador, y se requiere que la estrategia de cada jugador sea una mejor respuesta a las estrategias de los demás. (Normalmente se impone ahora una restricción adicional en las estrategias para garantizar que los jugadores no jueguen de una manera irracional con respecto a la información que han recibido hasta el momento).",
                "Por ejemplo, si el líder es capaz de comprometerse con una <br>estrategia mixta</br> en el juego original, entonces cada una de las estrategias mixtas (continuo de) constituye una estrategia pura en la representación de forma extensiva de la situación de liderazgo. (Se destaca que un compromiso con una distribución no es lo mismo que una distribución sobre compromisos).",
                "Una <br>estrategia mixta</br> para un jugador es una distribución de probabilidad sobre las estrategias puras de ese jugador.",
                "Si el jugador de la fila puede comprometerse a una <br>estrategia mixta</br>, entonces puede obtener una utilidad aún mayor (esperada): si el jugador de la fila se compromete a colocar una probabilidad p > 1/2 en la estrategia inferior, entonces el jugador de la columna seguirá prefiriendo jugar la estrategia derecha, y la utilidad esperada de los jugadores de la fila será 3p + 4(1 − p) = 4 − p ≥ 3.",
                "Por lo tanto, la <br>estrategia mixta</br> óptima a la que debe comprometerse el jugador de la fila es p = 1/2."
            ],
            "translated_text": "En sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias simultáneamente. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. El reciente aumento en el interés por las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas a comprometerse tanto en el compromiso de estrategias puras como en el compromiso de estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Ofrecemos tanto resultados positivos (algoritmos eficientes) como resultados negativos (resultados de NP-hardness). Categorías y Descriptores de Asignaturas J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas Términos Generales Algoritmos, Economía, Teoría 1. En sistemas multiagentes con agentes auto-interesados (incluyendo la mayoría de los entornos económicos), la acción óptima que un agente debe tomar depende de las acciones que tomen los otros agentes. Para analizar cómo un agente debería comportarse en tales situaciones, es necesario aplicar las herramientas de la teoría de juegos. Normalmente, cuando se modela un escenario estratégico en el marco de la teoría de juegos, se asume que los jugadores eligen sus estrategias de forma simultánea. Esto es especialmente cierto cuando el escenario se modela como un juego en forma normal, que solo especifica la utilidad de cada agente como una función del vector de estrategias que los agentes eligen, y no proporciona información sobre el orden en que los agentes toman sus decisiones y lo que los agentes observan sobre las decisiones anteriores de otros agentes. Dado que el juego está modelado en forma normal, típicamente se analiza utilizando el concepto de equilibrio de Nash. Un equilibrio de Nash especifica una estrategia para cada jugador, de modo que ningún jugador tenga un incentivo para desviarse individualmente de este perfil de estrategias. (Por lo general, se permite que las estrategias sean mixtas, es decir, distribuciones de probabilidad sobre las estrategias originales (puras).) Un equilibrio de Nash (de estrategia mixta) está garantizado de existir en juegos finitos [18], pero un problema es que puede haber múltiples equilibrios de Nash. Esto conduce al problema de selección de equilibrio de cómo un agente puede saber qué estrategia jugar si no sabe qué equilibrio se va a jugar. Cuando el escenario se modela como un juego de forma extensiva, es posible especificar que algunos jugadores reciben información sobre las acciones tomadas por otros antes en el juego antes de decidir su acción. Sin embargo, en general, los jugadores no saben todo lo que sucedió anteriormente en el juego. Por lo tanto, estos juegos suelen ser analizados todavía utilizando un concepto de equilibrio, donde se especifica una <br>estrategia mixta</br> para cada jugador, y se requiere que la estrategia de cada jugador sea una mejor respuesta a las estrategias de los demás. (Normalmente se impone ahora una restricción adicional en las estrategias para garantizar que los jugadores no jueguen de una manera irracional con respecto a la información que han recibido hasta el momento). Esto conduce a refinamientos del equilibrio de Nash como el equilibrio perfecto en subjuegos y el equilibrio secuencial. Sin embargo, en muchos entornos del mundo real, las estrategias no se seleccionan de manera simultánea. A menudo, un jugador (el líder) puede comprometerse con una estrategia antes que otro jugador (el seguidor). Esto puede deberse a una variedad de razones. Por ejemplo, uno de los jugadores puede llegar al lugar donde se jugará el juego antes que otro agente (por ejemplo, en entornos económicos, un jugador puede ingresar al mercado antes y comprometerse con una forma de hacer negocios). Un compromiso tan poderoso tiene un impacto profundo en cómo debería jugarse el juego. Por ejemplo, el líder puede estar mejor jugando una estrategia que esté dominada en la representación de forma normal del juego. Quizás el ejemplo más temprano y conocido del efecto del compromiso es el de von Stackelberg [25], quien demostró que, en el modelo de duopolio de Cournot [5], si una empresa puede comprometerse con una cantidad de producción primero, esa empresa lo hará mucho mejor que en la solución de movimiento simultáneo (Nash). En general, si es posible comprometerse con estrategias mixtas, entonces (bajo suposiciones menores) nunca perjudica, y a menudo ayuda, comprometerse con una estrategia [26]. Verse obligado a comprometerse con una estrategia pura a veces ayuda y a veces perjudica (por ejemplo, comprometerse con una estrategia pura en piedra-papel-tijeras antes de la decisión de los otros jugadores naturalmente resultará en una derrota). En este documento, asumiremos que el compromiso siempre es forzado; si no lo es, el jugador que tiene la opción de comprometerse simplemente puede comparar el resultado del compromiso con el resultado de no comprometerse (movimiento simultáneo). Los modelos de liderazgo son especialmente importantes en entornos con múltiples agentes de software con intereses propios. Una vez que el código de un agente (o de un equipo de agentes) está finalizado y el agente es desplegado, el agente se compromete a jugar la estrategia (posiblemente aleatoria) que el código prescribe. Por lo tanto, siempre y cuando se pueda demostrar de manera creíble que no se puede cambiar el código más tarde, el código funciona como un dispositivo de compromiso. Esto es válido para torneos recreativos entre agentes (por ejemplo, torneos de póker, RoboSoccer) y para aplicaciones industriales como redes de sensores. Finalmente, también existe una situación de liderazgo implícito en el campo del diseño de mecanismos, en la cual un jugador (el diseñador) tiene la oportunidad de elegir las reglas del juego que los demás jugadores luego siguen. El diseño de mecanismos es un tema extremadamente importante para la comunidad de EC: los artículos publicados sobre diseño de mecanismos en las recientes conferencias de EC son demasiados para citar. De hecho, el diseñador del mecanismo puede beneficiarse al comprometerse con una elección que, si las acciones de los agentes (restantes) estuvieran fijas, sería subóptima. Por ejemplo, en una subasta (a precio fijo), el vendedor puede desear establecer un precio de reserva positivo (artificial) para el artículo, por debajo del cual el artículo no se venderá, incluso si el vendedor valora el artículo en 0. En retrospectiva (después de recibir las ofertas), esto (ingenuamente) parece subóptimo: si llegaba una oferta que superaba el precio de reserva, el precio de reserva no tenía efecto, y si no llegaba tal oferta, el vendedor hubiera estado mejor aceptando una oferta más baja. Por supuesto, la razón para establecer el precio de reserva es incentivar a los postores a ofertar más alto, y debido a esto, establecer precios de reserva artificiales puede aumentar realmente los ingresos esperados para el vendedor. Recientemente se ha dedicado una cantidad significativa de investigación al cálculo de soluciones de acuerdo con varios conceptos de solución para escenarios en los que los agentes eligen sus estrategias simultáneamente, como la dominancia [7, 11, 3] y (especialmente) el equilibrio de Nash [8, 21, 16, 15, 2, 22, 23, 4]. Sin embargo, se ha ignorado el cálculo de la estrategia óptima a comprometerse en una situación de liderazgo. Teóricamente, las situaciones de liderazgo simplemente pueden ser consideradas como un juego de forma extensiva en el que un jugador elige una estrategia (para el juego original) primero. El número de estrategias en este juego de forma extensiva, sin embargo, puede ser extremadamente grande. Por ejemplo, si el líder es capaz de comprometerse con una <br>estrategia mixta</br> en el juego original, entonces cada una de las estrategias mixtas (continuo de) constituye una estrategia pura en la representación de forma extensiva de la situación de liderazgo. (Se destaca que un compromiso con una distribución no es lo mismo que una distribución sobre compromisos). Además, si el juego original es en sí mismo un juego de forma extensiva, el número de estrategias en la representación de forma extensiva de la situación de liderazgo (que es un juego de forma extensiva diferente) se vuelve aún más grande. Por lo tanto, generalmente no es factible computacionalmente simplemente transformar el juego original en la representación de forma extensiva de la situación de liderazgo; en su lugar, debemos analizar el juego en su representación original. En este artículo, estudiamos cómo calcular la estrategia óptima a comprometerse, tanto en juegos de forma normal (Sección 2) como en juegos bayesianos, que son un caso especial de juegos de forma extensiva (Sección 3). JUEGOS EN FORMA NORMAL En esta sección, estudiamos cómo calcular la estrategia óptima a comprometerse para juegos representados en forma normal. 2.1 Definiciones En un juego en forma normal, cada jugador i ∈ {1, . . . , n} tiene un conjunto de estrategias puras (o acciones) Si, y una función de utilidad ui : S1×S2×. . .×Sn → R que mapea cada resultado (un vector que consiste en una estrategia pura para cada jugador, también conocido como un perfil de estrategias puras) a un número real. Para facilitar la notación, en el caso de dos jugadores, nos referiremos al conjunto de estrategias puras del jugador 1 como S, y al conjunto de estrategias puras del jugador 2 como T. Estos juegos pueden representarse en forma de matriz (bi-matriz), en la que las filas corresponden a las estrategias puras del jugador 1, las columnas corresponden a las estrategias puras del jugador 2, y las entradas de la matriz dan las utilidades de los jugadores de fila y columna (en ese orden) para el resultado correspondiente del juego. En el caso de tres jugadores, usaremos R, S y T, para las estrategias puras de los jugadores 1, 2 y 3, respectivamente. Una <br>estrategia mixta</br> para un jugador es una distribución de probabilidad sobre las estrategias puras de ese jugador. En el caso de juegos de dos jugadores, nos referiremos al jugador 1 como el líder y al jugador 2 como el seguidor. Antes de definir estrategias de liderazgo óptimas, considera el siguiente juego que ilustra el efecto de la capacidad del líder para comprometerse. 2, 1 4, 0 1, 0 3, 1 En esta representación en forma normal, la estrategia inferior para el jugador de la fila está estrictamente dominada por la estrategia superior. Sin embargo, si el jugador de la fila tiene la capacidad de comprometerse con una estrategia pura antes de que el jugador de la columna elija su estrategia, el jugador de la fila debería comprometerse con la estrategia inferior: al hacerlo, el jugador de la columna preferirá jugar la estrategia correcta, lo que llevará a una utilidad de 3 para el jugador de la fila. Por el contrario, si el jugador de la fila se comprometiera con la estrategia superior, el jugador de la columna preferiría jugar la estrategia izquierda, lo que llevaría a una utilidad de solo 2 para el jugador de la fila. Si el jugador de la fila puede comprometerse a una <br>estrategia mixta</br>, entonces puede obtener una utilidad aún mayor (esperada): si el jugador de la fila se compromete a colocar una probabilidad p > 1/2 en la estrategia inferior, entonces el jugador de la columna seguirá prefiriendo jugar la estrategia derecha, y la utilidad esperada de los jugadores de la fila será 3p + 4(1 − p) = 4 − p ≥ 3. Si el jugador de la fila juega cada estrategia con una probabilidad exacta de 1/2, el jugador de la columna está 83 indiferente entre las estrategias. En tales casos, asumiremos que el jugador de la columna elegirá la estrategia que maximiza la utilidad de los jugadores de la fila (en este caso, la estrategia correcta). Por lo tanto, la <br>estrategia mixta</br> óptima a la que debe comprometerse el jugador de la fila es p = 1/2. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "normal-form game": {
            "translated_key": "juego en forma normal",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Computing the Optimal Strategy to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "We give both positive results (efficient algorithms) and negative results (NP-hardness results).",
                "Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent systems with self-interested agents (including most economic settings), the optimal action for one agent to take depends on the actions that the other agents take.",
                "To analyze how an agent should behave in such settings, the tools of game theory need to be applied.",
                "Typically, when a strategic setting is modeled in the framework of game theory, it is assumed that players choose their strategies simultaneously.",
                "This is especially true when the setting is modeled as a <br>normal-form game</br>, which only specifies each agents utility as a function of the vector of strategies that the agents choose, and does not provide any information on the order in which agents make their decisions and what the agents observe about earlier decisions by other agents.",
                "Given that the game is modeled in normal form, it is typically analyzed using the concept of Nash equilibrium.",
                "A Nash equilibrium specifies a strategy for each player, such that no player has an incentive to individually deviate from this profile of strategies. (Typically, the strategies are allowed to be mixed, that is, probability distributions over the original (pure) strategies.)",
                "A (mixed-strategy) Nash equilibrium is guaranteed to exist in finite games [18], but one problem is that there may be multiple Nash equilibria.",
                "This leads to the equilibrium selection problem of how an agent can know which strategy to play if it does not know which equilibrium is to be played.",
                "When the setting is modeled as an extensive-form game, it is possible to specify that some players receive some information about actions taken by others earlier in the game before deciding on their action.",
                "Nevertheless, in general, the players do not know everything that happened earlier in the game.",
                "Because of this, these games are typically still analyzed using an equilibrium concept, where one specifies a mixed strategy for each player, and requires that each players strategy is a best response to the others strategies. (Typically an additional constraint on the strategies is now imposed to ensure that players do not play in a way that is irrational with respect to the information that they have received so far.",
                "This leads to refinements of Nash equilibrium such as subgame perfect and sequential equilibrium.)",
                "However, in many real-world settings, strategies are not selected in such a simultaneous manner.",
                "Oftentimes, one player (the leader) is able to commit to a strategy before another player (the follower).",
                "This can be due to a variety of reasons.",
                "For example, one of the players may arrive at the site at which the game is to be played before another agent (e.g., in economic settings, one player may enter a market earlier and commit to a way of doing busi82 ness).",
                "Such commitment power has a profound impact on how the game should be played.",
                "For example, the leader may be best off playing a strategy that is dominated in the normal-form representation of the game.",
                "Perhaps the earliest and best-known example of the effect of commitment is that by von Stackelberg [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution.",
                "In general, if commitment to mixed strategies is possible, then (under minor assumptions) it never hurts, and often helps, to commit to a strategy [26].",
                "Being forced to commit to a pure strategy sometimes helps, and sometimes hurts (for example, committing to a pure strategy in rock-paper-scissors before the other players decision will naturally result in a loss).",
                "In this paper, we will assume commitment is always forced; if it is not, the player who has the choice of whether to commit can simply compare the commitment outcome to the non-commitment (simultaneous-move) outcome.",
                "Models of leadership are especially important in settings with multiple self-interested software agents.",
                "Once the code for an agent (or for a team of agents) is finalized and the agent is deployed, the agent is committed to playing the (possibly randomized) strategy that the code prescribes.",
                "Thus, as long as one can credibly show that one cannot change the code later, the code serves as a commitment device.",
                "This holds true for recreational tournaments among agents (e.g., poker tournaments, RoboSoccer), and for industrial applications such as sensor webs.",
                "Finally, there is also an implicit leadership situation in the field of mechanism design, in which one player (the designer) gets to choose the rules of the game that the remaining players then play.",
                "Mechanism design is an extremely important topic to the EC community: the papers published on mechanism design in recent EC conferences are too numerous to cite.",
                "Indeed, the mechanism designer may benefit from committing to a choice that, if the (remaining) agents actions were fixed, would be suboptimal.",
                "For example, in a (first-price) auction, the seller may wish to set a positive (artificial) reserve price for the item, below which the item will not be sold-even if the seller values the item at 0.",
                "In hindsight (after the bids have come in), this (na¨ıvely) appears suboptimal: if a bid exceeding the reserve price came in, the reserve price had no effect, and if no such bid came in, the seller would have been better off accepting a lower bid.",
                "Of course, the reason for setting the reserve price is that it incentivizes the bidders to bid higher, and because of this, setting artificial reserve prices can actually increase expected revenue to the seller.",
                "A significant amount of research has recently been devoted to the computation of solutions according to various solution concepts for settings in which the agents choose their strategies simultaneously, such as dominance [7, 11, 3] and (especially) Nash equilibrium [8, 21, 16, 15, 2, 22, 23, 4].",
                "However, the computation of the optimal strategy to commit to in a leadership situation has gone ignored.",
                "Theoretically, leadership situations can simply be thought of as an extensive-form game in which one player chooses a strategy (for the original game) first.",
                "The number of strategies in this extensive-form game, however, can be exceedingly large.",
                "For example, if the leader is able to commit to a mixed strategy in the original game, then every one of the (continuum of) mixed strategies constitutes a pure strategy in the extensive-form representation of the leadership situation. (We note that a commitment to a distribution is not the same as a distribution over commitments.)",
                "Moreover, if the original game is itself an extensive-form game, the number of strategies in the extensive-form representation of the leadership situation (which is a different extensive-form game) becomes even larger.",
                "Because of this, it is usually not computationally feasible to simply transform the original game into the extensive-form representation of the leadership situation; instead, we have to analyze the game in its original representation.",
                "In this paper, we study how to compute the optimal strategy to commit to, both in normal-form games (Section 2) and in Bayesian games, which are a special case of extensiveform games (Section 3). 2.",
                "NORMAL-FORM GAMES In this section, we study how to compute the optimal strategy to commit to for games represented in normal form. 2.1 Definitions In a <br>normal-form game</br>, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a pure strategy for every player, also known as a profile of pure strategies) to a real number.",
                "To ease notation, in the case of two players, we will refer to player 1s pure strategy set as S, and player 2s pure strategy set as T. Such games can be represented in (bi-)matrix form, in which the rows correspond to player 1s pure strategies, the columns correspond to player 2s pure strategies, and the entries of the matrix give the row and column players utilities (in that order) for the corresponding outcome of the game.",
                "In the case of three players, we will use R, S, and T, for player 1, 2, and 3s pure strategies, respectively.",
                "A mixed strategy for a player is a probability distribution over that players pure strategies.",
                "In the case of two-player games, we will refer to player 1 as the leader and player 2 as the follower.",
                "Before defining optimal leadership strategies, consider the following game which illustrates the effect of the leaders ability to commit. 2, 1 4, 0 1, 0 3, 1 In this normal-form representation, the bottom strategy for the row player is strictly dominated by the top strategy.",
                "Nevertheless, if the row player has the ability to commit to a pure strategy before the column player chooses his strategy, the row player should commit to the bottom strategy: doing so will make the column player prefer to play the right strategy, leading to a utility of 3 for the row player.",
                "By contrast, if the row player were to commit to the top strategy, the column player would prefer to play the left strategy, leading to a utility of only 2 for the row player.",
                "If the row player is able to commit to a mixed strategy, then she can get an even greater (expected) utility: if the row player commits to placing probability p > 1/2 on the bottom strategy, then the column player will still prefer to play the right strategy, and the row players expected utility will be 3p + 4(1 − p) = 4 − p ≥ 3.",
                "If the row player plays each strategy with probability exactly 1/2, the column player is 83 indifferent between the strategies.",
                "In such cases, we will assume that the column player will choose the strategy that maximizes the row players utility (in this case, the right strategy).",
                "Hence, the optimal mixed strategy to commit to for the row player is p = 1/2.",
                "There are a few good reasons for this assumption.",
                "If we were to assume the opposite, then there would not exist an optimal strategy for the row player in the example game: the row player would play the bottom strategy with probability p = 1/2 + with > 0, and the smaller , the better the utility for the row player.",
                "By contrast, if we assume that the follower always breaks ties in the leaders favor, then an optimal mixed strategy for the leader always exists, and this corresponds to a subgame perfect equilibrium of the extensive-form representation of the leadership situation.",
                "In any case, this is a standard assumption for such models (e.g. [20]), although some work has investigated what can happen in the other subgame perfect equilibria [26]. (For generic two-player games, the leaders subgame-perfect equilibrium payoff is unique.)",
                "Also, the same assumption is typically used in mechanism design, in that it is assumed that if an agent is indifferent between revealing his preferences truthfully and revealing them falsely, he will report them truthfully.",
                "Given this assumption, we can safely refer to optimal leadership strategies rather than having to use some equilibrium notion.",
                "Hence, for the purposes of this paper, an optimal strategy to commit to in a 2-player game is a strategy s ∈ S that maximizes maxt∈BR(s) ul(s, t), where BR(s) = arg maxt∈T uf (s, t). (ul and uf are the leader and followers utility functions, respectively.)",
                "We can have S = S for the case of commitment to pure strategies, or S = ∆(S), the set of probability distributions over S, for the case of commitment to mixed strategies. (We note that replacing T by ∆(T) makes no difference in this definition.)",
                "For games with more than two players, in which the players commit to their strategies in sequence, we define optimal strategies to commit to recursively.",
                "After the leader commits to a strategy, the game to be played by the remaining agents is itself a (smaller) leadership game.",
                "Thus, we define an optimal strategy to commit to as a strategy that maximizes the leaders utility, assuming that the play of the remaining agents is itself optimal under this definition, and maximizes the leaders utility among all optimal ways to play the remaining game.",
                "Again, commitment to mixed strategies may or may not be a possibility for every player (although for the last player it does not matter if we allow for commitment to mixed strategies). 2.2 Commitment to pure strategies We first study how to compute the optimal pure strategy to commit to.",
                "This is relatively simple, because the number of strategies to commit to is not very large. (In the following, #outcomes is the number of complete strategy profiles.)",
                "Theorem 1.",
                "Under commitment to pure strategies, the set of all optimal strategy profiles in a <br>normal-form game</br> can be found in O(#players · #outcomes) time.",
                "Proof.",
                "Each pure strategy that the first player may commit to will induce a subgame for the remaining players.",
                "We can solve each such subgame recursively to find all of its optimal strategy profiles; each of these will give the original leader some utility.",
                "Those that give the leader maximal utility correspond exactly to the optimal strategy profiles of the original game.",
                "We now present the algorithm formally.",
                "Let Su(G, s1) be the subgame that results after the first (remaining) player in G plays s1 ∈ SG 1 .",
                "A game with 0 players is simply an outcome of the game.",
                "The function Append(s, O) appends the strategy s to each of the vectors of strategies in the set O.",
                "Let e be the empty vector with no elements.",
                "In a slight abuse of notation, we will write uG 1 (C) when all strategy profiles in the set C give player 1 the same utility in the game G. (Here, player 1 is the first remaining player in the subgame G, not necessarily player 1 in the original game.)",
                "We note that arg max is set-valued.",
                "Then, the following algorithm computes all optimal strategy profiles: Algorithm Solve(G) if G has 0 players return {e} C ← ∅ for all s1 ∈ SG 1 { O ← Solve(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) if C = ∅ or uG 1 (s1, O ) = uG 1 (C) C ← C∪Append(s1, O ) if uG 1 (s1, O ) > uG 1 (C) C ←Append(s1, O ) } return C Every outcome is (potentially) examined by every player, which leads to the given runtime bound.",
                "As an example of how the algorithm works, consider the following 3-player game, in which the first player chooses the left or right matrix, the second player chooses a row, and the third player chooses a column. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 3,0,0 First we eliminate the outcomes that do not correspond to best responses for the third player (removing them from the matrix): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Next, we remove the entries in which the third player does not break ties in favor of the second player, as well as entries that do not correspond to best responses for the second player. 0,1,1 2,1,1 1,1,1 0,5,1 Finally, we remove the entries in which the second and third players do not break ties in favor of the first player, as well as entries that do not correspond to best responses for the first player. 2,1,1 84 Hence, in optimal play, the first player chooses the left matrix, the second player chooses the middle row, and the third player chooses the left column. (We note that this outcome is Pareto-dominated by (Right, Middle, Left).)",
                "For general normal-form games, each players utility for each of the outcomes has to be explicitly represented in the input, so that the input size is itself Ω(#players · #outcomes).",
                "Therefore, the algorithm is in fact a linear-time algorithm. 2.3 Commitment to mixed strategies In the special case of two-player zero-sum games, computing an optimal mixed strategy for the leader to commit to is equivalent to computing a minimax strategy, which minimizes the maximum expected utility that the opponent can obtain.",
                "Minimax strategies constitute the only natural solution concept for two-player zero-sum games: von Neumanns Minimax Theorem [24] states that in two-player zero-sum games, it does not matter (in terms of the players utilities) which player gets to commit to a mixed strategy first, and a profile of mixed strategies is a Nash equilibrium if and only if both strategies are minimax strategies.",
                "It is well-known that a minimax strategy can be found in polynomial time, using linear programming [17].",
                "Our first result in this section generalizes this result, showing that an optimal mixed strategy for the leader to commit to can be efficiently computed in general-sum two-player games, again using linear programming.",
                "Theorem 2.",
                "In 2-player normal-form games, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders utility.",
                "Such a mixed strategy can be computed using the following simple linear program: maximize s∈S psul(s, t) subject to for all t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1 We note that this program may be infeasible for some follower strategies t, for example, if t is a strictly dominated strategy.",
                "Nevertheless, the program must be feasible for at least some follower strategies; among these follower strategies, choose a strategy t∗ that maximizes the linear programs solution value.",
                "Then, if the leader chooses as her mixed strategy the optimal settings of the variables ps for the linear program for t∗ , and the follower plays t∗ , this constitutes an optimal strategy profile.",
                "In the following result, we show that we cannot expect to solve the problem more efficiently than linear programming, because we can reduce any linear program with a probability constraint on its variables to a problem of computing the optimal mixed strategy to commit to in a 2-player normalform game.",
                "Theorem 3.",
                "Any linear program whose variables xi (with xi ∈ R≥0 ) must satsify i xi = 1 can be modeled as a problem of computing the optimal mixed strategy to commit to in a 2-player <br>normal-form game</br>.",
                "Proof.",
                "Let the leader have a pure strategy i for every variable xi.",
                "Let the column player have one pure strategy j for every constraint in the linear program (other than i xi = 1), and a single additional pure strategy 0.",
                "Let the utility functions be as follows.",
                "Writing the objective of the linear program as maximize i cixi, for any i, let ul(i, 0) = ci and uf (i, 0) = 0.",
                "Writing the jth constraint of the linear program (not including i xi = 1) as i aijxi ≤ bj, for any i, j > 0, let ul(i, j) = mini ci − 1 and uf (i, j) = aij − bj.",
                "For example, consider the following linear program. maximize 2x1 + x2 subject to x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 The optimal solution to this program is x1 = 1/3, x2 = 2/3.",
                "Our reduction transforms this program into the following leader-follower game (where the leader is the row player). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 Indeed, the optimal strategy for the leader is to play the top strategy with probability 1/3 and the bottom strategy with probability 2/3.",
                "We now show that the reduction works in general.",
                "Clearly, the leader wants to incentivize the follower to play 0, because the utility that the leader gets when the follower plays 0 is always greater than when the follower does not play 0.",
                "In order for the follower not to prefer playing j > 0 rather than 0, it must be the case that i pl(i)(aij − bj) ≤ 0, or equivalently i pl(i)aij ≤ bj.",
                "Hence the leader will get a utility of at least mini ci if and only if there is a feasible solution to the constraints.",
                "Given that the pl(i) incentivize the follower to play 0, the leader attempts to maximize i pl(i)ci.",
                "Thus the leader must solve the original linear program.",
                "As an alternative proof of Theorem 3, one may observe that it is known that finding a minimax strategy in a zerosum game is as hard as the linear programming problem [6], and as we pointed out at the beginning of this section, computing a minimax strategy in a zero-sum game is a special case of the problem of computing an optimal mixed strategy to commit to.",
                "This polynomial-time solvability of the problem of computing an optimal mixed strategy to commit to in two-player normal-form games contrasts with the unknown complexity of computing a Nash equilibrium in such games [21], as well as with the NP-hardness of finding a Nash equilibrium with maximum utility for a given player in such games [8, 2].",
                "Unfortunately, this result does not generalize to more than two players-here, the problem becomes NP-hard.",
                "To show this, we reduce from the VERTEX-COVER problem.",
                "Definition 1.",
                "In VERTEX-COVER, we are given a graph G = (V, E) and an integer K. We are asked whether there 85 exists a subset of the vertices S ⊆ V , with |S| = K, such that every edge e ∈ E has at least one of its endpoints in S. BALANCED-VERTEX-COVER is the special case of VERTEX-COVER in which K = |V |/2.",
                "VERTEX-COVER is NP-complete [9].",
                "The following lemma shows that the hardness remains if we require K = |V |/2. (Similar results have been shown for other NP-complete problems.)",
                "Lemma 1.",
                "BALANCED-VERTEX-COVER is NP-complete.",
                "Proof.",
                "Membership in NP follows from the fact that the problem is a special case of VERTEX-COVER, which is in NP.",
                "To show NP-hardness, we reduce an arbitrary VERTEX-COVER instance to a BALANCED-VERTEXCOVER instance, as follows.",
                "If, for the VERTEX-COVER instance, K > |V |/2, then we simply add isolated vertices that are disjoint from the rest of the graph, until K = |V |/2.",
                "If K < |V |/2, we add isolated triangles (that is, the complete graph on three vertices) to the graph, increasing K by 2 every time, until K = |V |/2.",
                "Theorem 4.",
                "In 3-player normal-form games, finding an optimal mixed strategy to commit to is NP-hard.",
                "Proof.",
                "We reduce an arbitrary BALANCED-VERTEXCOVER instance to the following 3-player <br>normal-form game</br>.",
                "For every vertex v, each of the three players has a pure strategy corresponding to that vertex (rv, sv, tv, respectively).",
                "In addition, for every edge e, the third player has a pure strategy te; and finally, the third player has one additional pure strategy t0.",
                "The utilities are as follows: • for all r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • for all r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • for all v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • for all v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • for all v ∈ V , for all r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V | |V |−2 ; • for all e ∈ E, s ∈ S, for both v ∈ e, u3(rv, s, te) = 0; • for all e ∈ E, s ∈ S, for all v /∈ e, u3(rv, s, te) = |V | |V |−2 . • for all r ∈ R, s ∈ S, u3(r, s, t0) = 1.",
                "We note that players 1 and 2 have the same utility function.",
                "We claim that there is an optimal strategy profile in which players 1 and 2 both obtain 1 (their maximum utility) if and only if there is a solution to the BALANCED-VERTEXCOVER problem. (Otherwise, these players will both obtain 0.)",
                "First, suppose there exists a solution to the BALANCEDVERTEX-COVER problem.",
                "Then, let player 1 play every rv such that v is in the cover with probability 2 |V | , and let player 2 play every sv such that v is not in the cover with probability 2 |V | .",
                "Then, for player 3, the expected utility of playing tv (for any v) is (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of 2 |V | that rv or sv is played.",
                "Additionally, the expected utility of playing te (for any e) is at most (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of at least 2 |V | that some rv with v ∈ e is played (because player 1 is randomizing over the pure strategies corresponding to the cover).",
                "It follows that playing t0 is a best response for player 3, giving players 1 and 2 a utility of 1.",
                "Now, suppose that players 1 and 2 obtain 1 in optimal play.",
                "Then, it must be the case that player 3 plays t0.",
                "Hence, for every v ∈ V , there must be a probability of at least 2 |V | that either rv or sv is played, for otherwise player 3 would be better off playing tv.",
                "Because players 1 and 2 have only a total probability of 2 to distribute, it must be the case that for each v, either rv or sv is played with probability 2 |V | , and the other is played with probability 0. (It is not possible for both to have nonzero probability, because then there would be some probability that both are played simultaneously (correlation is not possible), hence the total probability of at least one being played could not be high enough for all vertices.)",
                "Thus, for exactly half the v ∈ V , player 1 places probability 2 |V | on rv.",
                "Moreover, for every e ∈ E, there must be a probability of at least 2 |V | that some rv with v ∈ e is played, for otherwise player 3 would be better off playing te.",
                "Thus, the v ∈ V such that player 1 places probability 2 |V | on rv constitute a balanced vertex cover. 3.",
                "BAYESIAN GAMES So far, we have restricted our attention to normal-form games.",
                "In a <br>normal-form game</br>, it is assumed that every agent knows every other agents preferences over the outcomes of the game.",
                "In general, however, agents may have some private information about their preferences that is not known to the other agents.",
                "Moreover, at the time of commitment to a strategy, the agents may not even know their own (final) preferences over the outcomes of the game yet, because these preferences may be dependent on a context that has yet to materialize.",
                "For example, when the code for a trading agent is written, it may not yet be clear how that agent will value resources that it will negotiate over later, because this depends on information that is not yet available at the time at which the code is written (such as orders that will have been placed to the agent before the negotiation).",
                "In this section, we will study commitment in Bayesian games, which can model such uncertainty over preferences. 3.1 Definitions In a Bayesian game, every player i has a set of actions Si, a set of types Θi with an associated probability distribution πi : Θi → [0, 1], and, for each type θi, a utility function uθi i : S1 × S2 × . . . × Sn → R. A pure strategy in a Bayesian game is a mapping from the players types to actions, σi : Θi → Si. (Bayesian games can be rewritten in normal form by enumerating every pure strategy σi, but this will cause an exponential blowup in the size of the representation of the game and therefore cannot lead to efficient algorithms.)",
                "The strategy that the leader should commit to depends on whether, at the time of commitment, the leader knows her own type.",
                "If the leader does know her own type, the other types that the leader might have had become irrelevant and the leader should simply commit to the strategy that is optimal for the type.",
                "However, as argued above, the leader does not necessarily know her own type at the time of commitment (e.g., the time at which the code is submitted).",
                "In this case, the leader must commit to a strategy that is 86 dependent upon the leaders eventual type.",
                "We will study this latter model, although we will pay specific attention to the case where the leader has only a single type, which is effectively the same as the former model. 3.2 Commitment to pure strategies It turns out that computing an optimal pure strategy to commit to is hard in Bayesian games, even with two players.",
                "Theorem 5.",
                "Finding an optimal pure strategy to commit to in 2-player Bayesian games is NP-hard, even when the follower has only a single type.",
                "Proof.",
                "We reduce an arbitrary VERTEX-COVER instance to the following Bayesian game between the leader and the follower.",
                "The leader has K types θ1, θ2, . . . , θK , each occurring with probability 1/K, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has only a single type; for each edge e ∈ E, the follower has an action te, and the follower has a single additional action t0.",
                "The utility function for the leader is given by, for all θl ∈ Θl and all s ∈ S, u θl l (s, t0) = 1, and for all e ∈ E, u θl l (s, te) = 0.",
                "The followers utility is given by: • For all v ∈ V , for all e ∈ E with v /∈ e, uf (sv, te) = 1; • For all v ∈ V , for all e ∈ E with v ∈ e, uf (sv, te) = −K; • For all v ∈ V , uf (sv, t0) = 0.",
                "We claim that the leader can get a utility of 1 if and only if there is a solution to the VERTEX-COVER instance.",
                "First, suppose that there is a solution to the VERTEXCOVER instance.",
                "Then, the leader can commit to a pure strategy such that for each vertex v in the cover, the leader plays sv for some type.",
                "Then, the followers utility for playing te (for any e ∈ E) is at most K−1 K + 1 K (−K) = − 1 K , so that the follower will prefer to play t0, which gives the leader a utility of 1, as required.",
                "Now, suppose that there is a pure strategy for the leader that will give the leader a utility of 1.",
                "Then, the follower must play t0.",
                "In order for the follower not to prefer playing te (for any e ∈ E) instead, for at least one v ∈ e the leader must play sv for some type θl.",
                "Hence, the set of vertices v that the leader plays for some type must constitute a vertex cover; and this set can have size at most K, because the leader has only K types.",
                "So there is a solution to the VERTEXCOVER instance.",
                "However, if the leader has only a single type, then the problem becomes easy again (#types is the number of types for the follower): Theorem 6.",
                "In 2-player Bayesian games in which the leader has only a single type, an optimal pure strategy to commit to can be found in O(#outcomes · #types) time.",
                "Proof.",
                "For every leader action s, we can compute, for every follower type θf ∈ Θf , which actions t maximize the followers utility; call this set of actions BRθf (s).",
                "Then, the utility that the leader receives for committing to action s can be computed as θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), and the leader can choose the best action to commit to. 3.3 Commitment to mixed strategies In two-player zero-sum imperfect information games with perfect recall (no player ever forgets something that it once knew), a minimax strategy can be constructed in polynomial time [12, 13].",
                "Unfortunately, this result does not extend to computing optimal mixed strategies to commit to in the general-sum case-not even in Bayesian games.",
                "We will exhibit NP-hardness by reducing from the INDEPENDENTSET problem.",
                "Definition 2.",
                "In INDEPENDENT-SET, we are given a graph G = (V, E) and an integer K. We are asked whether there exists a subset of the vertices S ⊆ V , with |S| = K, such that no edge e ∈ E has both of its endpoints in S. Again, this problem is NP-complete [9].",
                "Theorem 7.",
                "Finding an optimal mixed strategy to commit to in 2-player Bayesian games is NP-hard, even when the leader has only a single type and the follower has only two actions.",
                "Proof.",
                "We reduce an arbitrary INDEPENDENT-SET instance to the following Bayesian game between the leader and the follower.",
                "The leader has only a single type, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has a type θv for every v ∈ V , occurring with probability 1 (|E|+1)|V | , and a type θe for every e ∈ E, occurring with probability 1 |E|+1 .",
                "The follower has two actions: t0 and t1.",
                "The leaders utility is given by, for all s ∈ S, ul(s, t0) = 1 and ul(s, t1) = 0.",
                "The followers utility is given by: • For all v ∈ V , uθv f (sv, t1) = 0; • For all v ∈ V and s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • For all v ∈ V and s ∈ S, uθv f (s, t0) = 1; • For all e ∈ E, s ∈ S, uθe f (s, t0) = 1; • For all e ∈ E, for both v ∈ e, uθe f (sv, t1) = 2K 3 ; • For all e ∈ E, for all v /∈ e, uθe f (sv, t1) = 0.",
                "We claim that an optimal strategy to commit to gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | if and only if there is a solution to the INDEPENDENT-SET instance.",
                "First, suppose that there is a solution to the INDEPENDENT-SET instance.",
                "Then, the leader could commit to the following strategy: for every vertex v in the independent set, play the corresponding sv with probability 1/K.",
                "If the follower has type θe for some e ∈ E, the expected utility for the follower of playing t1 is at most 1 K 2K 3 = 2/3, because there is at most one vertex v ∈ e such that sv is played with nonzero probability.",
                "Hence, the follower will play t0 and obtain a utility of 1.",
                "If the follower has type θv for some vertex v in the independent set, the expected utility for the follower of playing t1 is K−1 K K K−1 = 1, because the leader plays sv with probability 1/K.",
                "It follows that the follower (who breaks ties to maximize the leaders utility) will play t0, which also gives a utility of 1 and gives the leader a higher utility.",
                "Hence the leaders expected utility for this strategy is at least |E| |E|+1 + K (|E|+1)|V | , as required. 87 Now, suppose that there is a strategy that gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | .",
                "Then, this strategy must induce the follower to play t0 whenever it has a type of the form θe (because otherwise, the utility could be at most |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ).",
                "Thus, it cannot be the case that for some edge e = (v1, v2) ∈ E, the probability that the leader plays one of sv1 and sv2 is at least 2/K, because then the expected utility for the follower of playing t1 when it has type θe would be at least 2 K 2K 3 = 4/3 > 1.",
                "Moreover, the strategy must induce the follower to play t0 for at least K types of the form θv.",
                "Inducing the follower to play t0 when it has type θv can be done only by playing sv with probability at least 1/K, which will give the follower a utility of at most K−1 K K K−1 = 1 for playing t1.",
                "But then, the set of vertices v such that sv is played with probability at least 1/K must constitute an independent set of size K (because if there were an edge e between two such vertices, it would induce the follower to play t1 for type θe by the above).",
                "By contrast, if the follower has only a single type, then we can generalize the linear programming approach for normalform games: Theorem 8.",
                "In 2-player Bayesian games in which the follower has only a single type, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "We generalize the approach in Theorem 2 as follows.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader for every one of the leaders types such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders ex ante expected utility.",
                "To do so, we generalize the linear program as follows: maximize θl∈Θl π(θl) s∈S pθl s uθl l (s, t) subject to for all t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t ) for all θl ∈ Θl, s∈S p θl s = 1 As in Theorem 2, the solution for the linear program that maximizes the solution value is an optimal strategy to commit to.",
                "This shows an interesting contrast between commitment to pure strategies and commitment to mixed strategies in Bayesian games: for pure strategies, the problem becomes easy if the leader has only a single type (but not if the follower has only a single type), whereas for mixed strategies, the problem becomes easy if the follower has only a single type (but not if the leader has only a single type). 4.",
                "CONCLUSIONS AND FUTURE RESEARCH In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "This requires some equilibrium notion (Nash equilibrium and its refinements), and often leads to the equilibrium selection problem: it is unclear to each individual player according to which equilibrium she should play.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "For example, one agent may arrive at the (real or virtual) site of the game before the other, or, in the specific case of software agents, the code for one agent may be completed and committed before that of another agent.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "Specifically, if commitment to mixed strategies is possible, then (optimal) commitment never hurts the leader, and often helps.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we studied how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "For normal-form games, we showed that the optimal pure strategy to commit to can be found efficiently for any number of players.",
                "An optimal mixed strategy to commit to in a <br>normal-form game</br> can be found efficiently for two players using linear programming (and no more efficiently than that, in the sense that any linear program with a probability constraint can be encoded as such a problem). (This is a generalization of the polynomial-time computability of minimax strategies in normal-form games.)",
                "The problem becomes NP-hard for three (or more) players.",
                "In Bayesian games, the problem of finding an optimal pure strategy to commit to is NP-hard even in two-player games in which the follower has only a single type, although two-player games in which the leader has only a single type can be solved efficiently.",
                "The problem of finding an optimal mixed strategy to commit to in a Bayesian game is NP-hard even in two-player games in which the leader has only a single type, although two-player games in which the follower has only a single type can be solved efficiently using a generalization of the linear progamming approach for normal-form games.",
                "The following two tables summarize these results. 2 players ≥ 3 players normal-form O(#outcomes) O(#outcomes· #players) Bayesian, O(#outcomes· NP-hard 1-type leader #types) Bayesian, NP-hard NP-hard 1-type follower Bayesian (general) NP-hard NP-hard Results for commitment to pure strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.) 88 2 players ≥ 3 players normal-form one LP-solve per NP-hard follower action Bayesian, NP-hard NP-hard 1-type leader Bayesian, one LP-solve per NP-hard 1-type follower follower action Bayesian (general) NP-hard NP-hard Results for commitment to mixed strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.)",
                "Future research can take a number of directions.",
                "First, we can empirically evaluate the techniques presented here on test suites such as GAMUT [19].",
                "We can also study the computation of optimal strategies to commit to in other1 concise representations of normal-form games-for example, in graphical games [10] or local-effect/action graph games [14, 1].",
                "For the cases where computing an optimal strategy to commit to is NP-hard, we can also study the computation of approximately optimal strategies to commit to.",
                "While the correct definition of an approximately optimal strategy is in this setting may appear simple at first-it should be a strategy that, if the following players play optimally, performs almost as well as the optimal strategy in expectation-this definition becomes problematic when we consider that the other players may also be playing only approximately optimally.",
                "One may also study models in which multiple (but not all) players commit at the same time.",
                "Another interesting direction to pursue is to see if computing optimal mixed strategies to commit to can help us in, or otherwise shed light on, computing Nash equilibria.",
                "Often, optimal mixed strategies to commit to are also Nash equilibrium strategies (for example, in two-player zero-sum games this is always true), although this is not always the case (for example, as we already pointed out, sometimes the optimal strategy to commit to is a strictly dominated strategy, which can never be a Nash equilibrium strategy). 5.",
                "REFERENCES [1] N. A. R. Bhat and K. Leyton-Brown.",
                "Computing Nash equilibria of action-graph games.",
                "In Proceedings of the 20th Annual Conference on Uncertainty in Artificial Intelligence (UAI), Banff, Canada, 2004. [2] V. Conitzer and T. Sandholm.",
                "Complexity results about Nash equilibria.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pages 765-771, Acapulco, Mexico, 2003. [3] V. Conitzer and T. Sandholm.",
                "Complexity of (iterated) dominance.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 88-97, Vancouver, Canada, 2005. [4] V. Conitzer and T. Sandholm.",
                "A generalized strategy eliminability criterion and computational methods for applying it.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 483-488, Pittsburgh, PA, USA, 2005. [5] A.",
                "A. Cournot.",
                "Recherches sur les principes math´ematiques de la th´eorie des richesses (Researches 1 Bayesian games are one potentially concise representation of normal-form games. into the Mathematical Principles of the Theory of Wealth).",
                "Hachette, Paris, 1838. [6] G. Dantzig.",
                "A proof of the equivalence of the programming problem and the game problem.",
                "In T. Koopmans, editor, Activity Analysis of Production and Allocation, pages 330-335.",
                "John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel.",
                "The complexity of eliminating dominated strategies.",
                "Mathematics of Operation Research, 18:553-565, 1993. [8] I. Gilboa and E. Zemel.",
                "Nash and correlated equilibria: Some complexity considerations.",
                "Games and Economic Behavior, 1:80-93, 1989. [9] R. Karp.",
                "Reducibility among combinatorial problems.",
                "In R. E. Miller and J. W. Thatcher, editors, Complexity of Computer Computations, pages 85-103.",
                "Plenum Press, NY, 1972. [10] M. Kearns, M. Littman, and S. Singh.",
                "Graphical models for game theory.",
                "In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou, and J. N. Tsitsiklis.",
                "A note on strategy elimination in bimatrix games.",
                "Operations Research Letters, 7(3):103-107, 1988. [12] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [14] K. Leyton-Brown and M. Tennenholtz.",
                "Local-effect games.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), Acapulco, Mexico, 2003. [15] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 36-41, San Diego, CA, 2003. [16] M. Littman and P. Stone.",
                "A polynomial-time Nash equilibrium algorithm for repeated games.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 48-54, San Diego, CA, 2003. [17] R. D. Luce and H. Raiffa.",
                "Games and Decisions.",
                "John Wiley and Sons, New York, 1957.",
                "Dover republication 1989. [18] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown, and Y. Shoham.",
                "Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms.",
                "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), New York, NY, USA, 2004. [20] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "MIT Press, 1994. [21] C. Papadimitriou.",
                "Algorithms, games and the Internet.",
                "In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 749-753, 2001. 89 [22] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 664-669, San Jose, CA, USA, 2004. [23] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 495-501, Pittsburgh, PA, USA, 2005. [24] J. von Neumann.",
                "Zur Theorie der Gesellschaftsspiele.",
                "Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg.",
                "Marktform und Gleichgewicht.",
                "Springer, Vienna, 1934. [26] B. von Stengel and S. Zamir.",
                "Leadership with commitment to mixed strategies.",
                "CDAM Research Report LSE-CDAM-2004-01, London School of Economics, Feb. 2004. 90"
            ],
            "original_annotated_samples": [
                "This is especially true when the setting is modeled as a <br>normal-form game</br>, which only specifies each agents utility as a function of the vector of strategies that the agents choose, and does not provide any information on the order in which agents make their decisions and what the agents observe about earlier decisions by other agents.",
                "NORMAL-FORM GAMES In this section, we study how to compute the optimal strategy to commit to for games represented in normal form. 2.1 Definitions In a <br>normal-form game</br>, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a pure strategy for every player, also known as a profile of pure strategies) to a real number.",
                "Under commitment to pure strategies, the set of all optimal strategy profiles in a <br>normal-form game</br> can be found in O(#players · #outcomes) time.",
                "Any linear program whose variables xi (with xi ∈ R≥0 ) must satsify i xi = 1 can be modeled as a problem of computing the optimal mixed strategy to commit to in a 2-player <br>normal-form game</br>.",
                "We reduce an arbitrary BALANCED-VERTEXCOVER instance to the following 3-player <br>normal-form game</br>."
            ],
            "translated_annotated_samples": [
                "Esto es especialmente cierto cuando el escenario se modela como un <br>juego en forma normal</br>, que solo especifica la utilidad de cada agente como una función del vector de estrategias que los agentes eligen, y no proporciona información sobre el orden en que los agentes toman sus decisiones y lo que los agentes observan sobre las decisiones anteriores de otros agentes.",
                "JUEGOS EN FORMA NORMAL En esta sección, estudiamos cómo calcular la estrategia óptima a comprometerse para juegos representados en <br>forma normal</br>. 2.1 Definiciones En un juego en <br>forma normal</br>, cada jugador i ∈ {1, . . . , n} tiene un conjunto de estrategias puras (o acciones) Si, y una función de utilidad ui : S1×S2×. . .×Sn → R que mapea cada resultado (un vector que consiste en una estrategia pura para cada jugador, también conocido como un perfil de estrategias puras) a un número real.",
                "Bajo el compromiso de estrategias puras, el conjunto de todos los perfiles de estrategia óptimos en un <br>juego en forma normal</br> se puede encontrar en tiempo O(#jugadores · #resultados).",
                "Cualquier programa lineal cuyas variables xi (con xi ∈ R≥0) deben satisfacer i xi = 1 puede ser modelado como un problema de calcular la estrategia mixta óptima a comprometerse en un juego de <br>forma normal</br> de 2 jugadores.",
                "Reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO al siguiente juego de <br>forma normal</br> de 3 jugadores."
            ],
            "translated_text": "En sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias simultáneamente. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. El reciente aumento en el interés por las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas a comprometerse tanto en el compromiso de estrategias puras como en el compromiso de estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Ofrecemos tanto resultados positivos (algoritmos eficientes) como resultados negativos (resultados de NP-hardness). Categorías y Descriptores de Asignaturas J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas Términos Generales Algoritmos, Economía, Teoría 1. En sistemas multiagentes con agentes auto-interesados (incluyendo la mayoría de los entornos económicos), la acción óptima que un agente debe tomar depende de las acciones que tomen los otros agentes. Para analizar cómo un agente debería comportarse en tales situaciones, es necesario aplicar las herramientas de la teoría de juegos. Normalmente, cuando se modela un escenario estratégico en el marco de la teoría de juegos, se asume que los jugadores eligen sus estrategias de forma simultánea. Esto es especialmente cierto cuando el escenario se modela como un <br>juego en forma normal</br>, que solo especifica la utilidad de cada agente como una función del vector de estrategias que los agentes eligen, y no proporciona información sobre el orden en que los agentes toman sus decisiones y lo que los agentes observan sobre las decisiones anteriores de otros agentes. Dado que el juego está modelado en forma normal, típicamente se analiza utilizando el concepto de equilibrio de Nash. Un equilibrio de Nash especifica una estrategia para cada jugador, de modo que ningún jugador tenga un incentivo para desviarse individualmente de este perfil de estrategias. (Por lo general, se permite que las estrategias sean mixtas, es decir, distribuciones de probabilidad sobre las estrategias originales (puras).) Un equilibrio de Nash (de estrategia mixta) está garantizado de existir en juegos finitos [18], pero un problema es que puede haber múltiples equilibrios de Nash. Esto conduce al problema de selección de equilibrio de cómo un agente puede saber qué estrategia jugar si no sabe qué equilibrio se va a jugar. Cuando el escenario se modela como un juego de forma extensiva, es posible especificar que algunos jugadores reciben información sobre las acciones tomadas por otros antes en el juego antes de decidir su acción. Sin embargo, en general, los jugadores no saben todo lo que sucedió anteriormente en el juego. Por lo tanto, estos juegos suelen ser analizados todavía utilizando un concepto de equilibrio, donde se especifica una estrategia mixta para cada jugador, y se requiere que la estrategia de cada jugador sea una mejor respuesta a las estrategias de los demás. (Normalmente se impone ahora una restricción adicional en las estrategias para garantizar que los jugadores no jueguen de una manera irracional con respecto a la información que han recibido hasta el momento). Esto conduce a refinamientos del equilibrio de Nash como el equilibrio perfecto en subjuegos y el equilibrio secuencial. Sin embargo, en muchos entornos del mundo real, las estrategias no se seleccionan de manera simultánea. A menudo, un jugador (el líder) puede comprometerse con una estrategia antes que otro jugador (el seguidor). Esto puede deberse a una variedad de razones. Por ejemplo, uno de los jugadores puede llegar al lugar donde se jugará el juego antes que otro agente (por ejemplo, en entornos económicos, un jugador puede ingresar al mercado antes y comprometerse con una forma de hacer negocios). Un compromiso tan poderoso tiene un impacto profundo en cómo debería jugarse el juego. Por ejemplo, el líder puede estar mejor jugando una estrategia que esté dominada en la representación de forma normal del juego. Quizás el ejemplo más temprano y conocido del efecto del compromiso es el de von Stackelberg [25], quien demostró que, en el modelo de duopolio de Cournot [5], si una empresa puede comprometerse con una cantidad de producción primero, esa empresa lo hará mucho mejor que en la solución de movimiento simultáneo (Nash). En general, si es posible comprometerse con estrategias mixtas, entonces (bajo suposiciones menores) nunca perjudica, y a menudo ayuda, comprometerse con una estrategia [26]. Verse obligado a comprometerse con una estrategia pura a veces ayuda y a veces perjudica (por ejemplo, comprometerse con una estrategia pura en piedra-papel-tijeras antes de la decisión de los otros jugadores naturalmente resultará en una derrota). En este documento, asumiremos que el compromiso siempre es forzado; si no lo es, el jugador que tiene la opción de comprometerse simplemente puede comparar el resultado del compromiso con el resultado de no comprometerse (movimiento simultáneo). Los modelos de liderazgo son especialmente importantes en entornos con múltiples agentes de software con intereses propios. Una vez que el código de un agente (o de un equipo de agentes) está finalizado y el agente es desplegado, el agente se compromete a jugar la estrategia (posiblemente aleatoria) que el código prescribe. Por lo tanto, siempre y cuando se pueda demostrar de manera creíble que no se puede cambiar el código más tarde, el código funciona como un dispositivo de compromiso. Esto es válido para torneos recreativos entre agentes (por ejemplo, torneos de póker, RoboSoccer) y para aplicaciones industriales como redes de sensores. Finalmente, también existe una situación de liderazgo implícito en el campo del diseño de mecanismos, en la cual un jugador (el diseñador) tiene la oportunidad de elegir las reglas del juego que los demás jugadores luego siguen. El diseño de mecanismos es un tema extremadamente importante para la comunidad de EC: los artículos publicados sobre diseño de mecanismos en las recientes conferencias de EC son demasiados para citar. De hecho, el diseñador del mecanismo puede beneficiarse al comprometerse con una elección que, si las acciones de los agentes (restantes) estuvieran fijas, sería subóptima. Por ejemplo, en una subasta (a precio fijo), el vendedor puede desear establecer un precio de reserva positivo (artificial) para el artículo, por debajo del cual el artículo no se venderá, incluso si el vendedor valora el artículo en 0. En retrospectiva (después de recibir las ofertas), esto (ingenuamente) parece subóptimo: si llegaba una oferta que superaba el precio de reserva, el precio de reserva no tenía efecto, y si no llegaba tal oferta, el vendedor hubiera estado mejor aceptando una oferta más baja. Por supuesto, la razón para establecer el precio de reserva es incentivar a los postores a ofertar más alto, y debido a esto, establecer precios de reserva artificiales puede aumentar realmente los ingresos esperados para el vendedor. Recientemente se ha dedicado una cantidad significativa de investigación al cálculo de soluciones de acuerdo con varios conceptos de solución para escenarios en los que los agentes eligen sus estrategias simultáneamente, como la dominancia [7, 11, 3] y (especialmente) el equilibrio de Nash [8, 21, 16, 15, 2, 22, 23, 4]. Sin embargo, se ha ignorado el cálculo de la estrategia óptima a comprometerse en una situación de liderazgo. Teóricamente, las situaciones de liderazgo simplemente pueden ser consideradas como un juego de forma extensiva en el que un jugador elige una estrategia (para el juego original) primero. El número de estrategias en este juego de forma extensiva, sin embargo, puede ser extremadamente grande. Por ejemplo, si el líder es capaz de comprometerse con una estrategia mixta en el juego original, entonces cada una de las estrategias mixtas (continuo de) constituye una estrategia pura en la representación de forma extensiva de la situación de liderazgo. (Se destaca que un compromiso con una distribución no es lo mismo que una distribución sobre compromisos). Además, si el juego original es en sí mismo un juego de forma extensiva, el número de estrategias en la representación de forma extensiva de la situación de liderazgo (que es un juego de forma extensiva diferente) se vuelve aún más grande. Por lo tanto, generalmente no es factible computacionalmente simplemente transformar el juego original en la representación de forma extensiva de la situación de liderazgo; en su lugar, debemos analizar el juego en su representación original. En este artículo, estudiamos cómo calcular la estrategia óptima a comprometerse, tanto en juegos de forma normal (Sección 2) como en juegos bayesianos, que son un caso especial de juegos de forma extensiva (Sección 3). JUEGOS EN FORMA NORMAL En esta sección, estudiamos cómo calcular la estrategia óptima a comprometerse para juegos representados en <br>forma normal</br>. 2.1 Definiciones En un juego en <br>forma normal</br>, cada jugador i ∈ {1, . . . , n} tiene un conjunto de estrategias puras (o acciones) Si, y una función de utilidad ui : S1×S2×. . .×Sn → R que mapea cada resultado (un vector que consiste en una estrategia pura para cada jugador, también conocido como un perfil de estrategias puras) a un número real. Para facilitar la notación, en el caso de dos jugadores, nos referiremos al conjunto de estrategias puras del jugador 1 como S, y al conjunto de estrategias puras del jugador 2 como T. Estos juegos pueden representarse en forma de matriz (bi-matriz), en la que las filas corresponden a las estrategias puras del jugador 1, las columnas corresponden a las estrategias puras del jugador 2, y las entradas de la matriz dan las utilidades de los jugadores de fila y columna (en ese orden) para el resultado correspondiente del juego. En el caso de tres jugadores, usaremos R, S y T, para las estrategias puras de los jugadores 1, 2 y 3, respectivamente. Una estrategia mixta para un jugador es una distribución de probabilidad sobre las estrategias puras de ese jugador. En el caso de juegos de dos jugadores, nos referiremos al jugador 1 como el líder y al jugador 2 como el seguidor. Antes de definir estrategias de liderazgo óptimas, considera el siguiente juego que ilustra el efecto de la capacidad del líder para comprometerse. 2, 1 4, 0 1, 0 3, 1 En esta representación en forma normal, la estrategia inferior para el jugador de la fila está estrictamente dominada por la estrategia superior. Sin embargo, si el jugador de la fila tiene la capacidad de comprometerse con una estrategia pura antes de que el jugador de la columna elija su estrategia, el jugador de la fila debería comprometerse con la estrategia inferior: al hacerlo, el jugador de la columna preferirá jugar la estrategia correcta, lo que llevará a una utilidad de 3 para el jugador de la fila. Por el contrario, si el jugador de la fila se comprometiera con la estrategia superior, el jugador de la columna preferiría jugar la estrategia izquierda, lo que llevaría a una utilidad de solo 2 para el jugador de la fila. Si el jugador de la fila puede comprometerse a una estrategia mixta, entonces puede obtener una utilidad aún mayor (esperada): si el jugador de la fila se compromete a colocar una probabilidad p > 1/2 en la estrategia inferior, entonces el jugador de la columna seguirá prefiriendo jugar la estrategia derecha, y la utilidad esperada de los jugadores de la fila será 3p + 4(1 − p) = 4 − p ≥ 3. Si el jugador de la fila juega cada estrategia con una probabilidad exacta de 1/2, el jugador de la columna está 83 indiferente entre las estrategias. En tales casos, asumiremos que el jugador de la columna elegirá la estrategia que maximiza la utilidad de los jugadores de la fila (en este caso, la estrategia correcta). Por lo tanto, la estrategia mixta óptima a la que debe comprometerse el jugador de la fila es p = 1/2. Hay algunas buenas razones para esta suposición. Si asumiéramos lo contrario, entonces no existiría una estrategia óptima para el jugador de la fila en el juego de ejemplo: el jugador de la fila jugaría la estrategia inferior con una probabilidad p = 1/2 + con > 0, y cuanto menor sea , mejor será la utilidad para el jugador de la fila. Por el contrario, si asumimos que el seguidor siempre rompe los empates a favor de los líderes, entonces siempre existe una estrategia mixta óptima para el líder, lo que corresponde a un equilibrio perfecto en subjuegos de la representación en forma extensiva de la situación de liderazgo. En cualquier caso, esta es una suposición estándar para tales modelos (por ejemplo, [20]), aunque algunos trabajos han investigado lo que puede suceder en los otros equilibrios perfectos de subjuego [26]. (Para juegos genéricos de dos jugadores, el pago del equilibrio perfecto de subjuego de los líderes es único). Además, la misma suposición se utiliza típicamente en el diseño de mecanismos, asumiendo que si un agente es indiferente entre revelar sus preferencias de manera veraz o falsa, las reportará de manera veraz. Dado este supuesto, podemos hacer referencia de manera segura a estrategias de liderazgo óptimas en lugar de tener que utilizar alguna noción de equilibrio. Por lo tanto, para los propósitos de este documento, una estrategia óptima a comprometerse en un juego de 2 jugadores es una estrategia s ∈ S que maximiza maxt∈BR(s) ul(s, t), donde BR(s) = arg maxt∈T uf (s, t). (ul y uf son las funciones de utilidad del líder y los seguidores, respectivamente). Podemos tener S = S para el caso de compromiso con estrategias puras, o S = ∆(S), el conjunto de distribuciones de probabilidad sobre S, para el caso de compromiso con estrategias mixtas. (Observamos que reemplazar T por ∆(T) no hace ninguna diferencia en esta definición). Para juegos con más de dos jugadores, en los que los jugadores se comprometen con sus estrategias en secuencia, definimos estrategias óptimas a las que comprometerse de forma recursiva. Después de que el líder se compromete con una estrategia, el juego que jugarán los agentes restantes es en sí mismo un juego de liderazgo (más pequeño). Por lo tanto, definimos una estrategia óptima a comprometerse como una estrategia que maximiza la utilidad del líder, asumiendo que el juego de los agentes restantes es óptimo bajo esta definición, y maximiza la utilidad del líder entre todas las formas óptimas de jugar el juego restante. Nuevamente, el compromiso con estrategias mixtas puede o no ser una posibilidad para cada jugador (aunque para el último jugador no importa si permitimos el compromiso con estrategias mixtas). 2.2 Compromiso con estrategias puras. Primero estudiamos cómo calcular la estrategia pura óptima a la que comprometerse. Esto es relativamente simple, porque el número de estrategias a comprometer no es muy grande. (En lo siguiente, #resultados es el número de perfiles de estrategia completos). Teorema 1. Bajo el compromiso de estrategias puras, el conjunto de todos los perfiles de estrategia óptimos en un <br>juego en forma normal</br> se puede encontrar en tiempo O(#jugadores · #resultados). Prueba. Cada estrategia pura a la que el primer jugador pueda comprometerse inducirá un subjuego para los jugadores restantes. Podemos resolver cada subjuego de esta manera de forma recursiva para encontrar todos sus perfiles de estrategia óptimos; cada uno de estos le dará al líder original cierta utilidad. Aquellos que proporcionan al líder la utilidad máxima corresponden exactamente a los perfiles de estrategia óptimos del juego original. Ahora presentamos el algoritmo de forma formal. Sea Su(G, s1) el subjuego que resulta después de que el primer jugador restante en G juega s1 ∈ SG 1. Un juego con 0 jugadores es simplemente un resultado del juego. La función Append(s, O) añade la estrategia s a cada uno de los vectores de estrategias en el conjunto O. Sea e el vector vacío sin elementos. En un ligero abuso de notación, escribiremos uG 1 (C) cuando todos los perfiles estratégicos en el conjunto C le den al jugador 1 la misma utilidad en el juego G. (Aquí, el jugador 1 es el primer jugador restante en el subjuego G, no necesariamente el jugador 1 en el juego original). Observamos que arg max es un conjunto de valores. Entonces, el siguiente algoritmo calcula todos los perfiles de estrategia óptimos: Algoritmo Resolver(G) si G tiene 0 jugadores, devuelve {e} C ← ∅ para todo s1 ∈ SG 1 { O ← Resolver(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) si C = ∅ o uG 1 (s1, O ) = uG 1 (C) C ← C∪Agregar(s1, O ) si uG 1 (s1, O ) > uG 1 (C) C ←Agregar(s1, O ) } devuelve C Cada resultado es examinado (potencialmente) por cada jugador, lo que lleva al límite de tiempo dado. Como ejemplo de cómo funciona el algoritmo, considera el siguiente juego de 3 jugadores, en el que el primer jugador elige la matriz izquierda o derecha, el segundo jugador elige una fila y el tercer jugador elige una columna. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 Primero eliminamos los resultados que no corresponden a las mejores respuestas para el tercer jugador (eliminándolos de la matriz): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Luego, eliminamos las entradas en las que el tercer jugador no resuelve los empates a favor del segundo jugador, así como las entradas que no corresponden a las mejores respuestas para el segundo jugador. 0,1,1 2,1,1 1,1,1 0,5,1 Finalmente, eliminamos las entradas en las que el segundo y tercer jugador no resuelven los empates a favor del primer jugador, así como las entradas que no corresponden a las mejores respuestas para el primer jugador. 2,1,1 Por lo tanto, en el juego óptimo, el primer jugador elige la matriz izquierda, el segundo jugador elige la fila del medio y el tercer jugador elige la columna izquierda. (Notamos que este resultado está dominado por Pareto por (Derecha, Medio, Izquierda).) Para juegos en forma normal general, la utilidad de cada jugador para cada uno de los resultados debe representarse explícitamente en la entrada, de modo que el tamaño de la entrada sea en sí mismo Ω(#jugadores · #resultados). Por lo tanto, el algoritmo es de hecho un algoritmo de tiempo lineal. 2.3 Compromiso con estrategias mixtas En el caso especial de juegos de dos jugadores de suma cero, calcular una estrategia mixta óptima para que el líder se comprometa es equivalente a calcular una estrategia minimax, que minimiza la utilidad esperada máxima que el oponente puede obtener. Las estrategias minimax constituyen el único concepto de solución natural para juegos de suma cero de dos jugadores: el Teorema Minimax de von Neumann [24] establece que en juegos de suma cero de dos jugadores, no importa (en términos de las utilidades de los jugadores) qué jugador se compromete primero a una estrategia mixta, y un perfil de estrategias mixtas es un equilibrio de Nash si y solo si ambas estrategias son estrategias minimax. Es bien sabido que una estrategia minimax se puede encontrar en tiempo polinómico, utilizando programación lineal [17]. Nuestro primer resultado en esta sección generaliza este resultado, mostrando que una estrategia mixta óptima para que el líder se comprometa puede ser calculada eficientemente en juegos de dos jugadores de suma general, nuevamente utilizando programación lineal. Teorema 2. En juegos de forma normal de 2 jugadores, una estrategia mixta óptima a la que comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal. Prueba. Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder de modo que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad del líder. Un programa lineal simple puede calcular una estrategia mixta como la siguiente: maximizar s∈S psul(s, t) sujeto a que para todo t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1. Se destaca que este programa puede ser inviable para algunas estrategias seguidoras t, por ejemplo, si t es una estrategia estrictamente dominada. Sin embargo, el programa debe ser factible para al menos algunas estrategias seguidoras; entre estas estrategias seguidoras, elige una estrategia t∗ que maximice el valor de la solución de los programas lineales. Entonces, si la líder elige como su estrategia mixta los ajustes óptimos de las variables ps para el programa lineal para t∗, y el seguidor juega t∗, esto constituye un perfil de estrategia óptimo. En el siguiente resultado, demostramos que no podemos esperar resolver el problema de manera más eficiente que la programación lineal, ya que podemos reducir cualquier programa lineal con una restricción de probabilidad en sus variables a un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores. Teorema 3. Cualquier programa lineal cuyas variables xi (con xi ∈ R≥0) deben satisfacer i xi = 1 puede ser modelado como un problema de calcular la estrategia mixta óptima a comprometerse en un juego de <br>forma normal</br> de 2 jugadores. Prueba. Que el líder tenga una estrategia pura i para cada variable xi. Que el jugador de la columna tenga una estrategia pura j para cada restricción en el programa lineal (distinta de i xi = 1), y una única estrategia pura adicional 0. Que las funciones de utilidad sean las siguientes. Escribiendo el objetivo del programa lineal como maximizar ci xi, para cualquier i, dejando ul(i, 0) = ci y uf(i, 0) = 0. Escribiendo la j-ésima restricción del programa lineal (sin incluir i xi = 1) como i aijxi ≤ bj, para cualquier i, j > 0, sea ul(i, j) = mini ci − 1 y uf(i, j) = aij − bj. Por ejemplo, considera el siguiente programa lineal. maximizar 2x1 + x2 sujeto a x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 La solución óptima de este programa es x1 = 1/3, x2 = 2/3. Nuestra reducción transforma este programa en el siguiente juego de líder-seguidor (donde el líder es el jugador de la fila). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 De hecho, la estrategia óptima para el líder es jugar la estrategia superior con una probabilidad de 1/3 y la estrategia inferior con una probabilidad de 2/3. Ahora demostramos que la reducción funciona en general. Claramente, el líder quiere incentivar al seguidor a jugar 0, porque la utilidad que el líder obtiene cuando el seguidor juega 0 siempre es mayor que cuando el seguidor no juega 0. Para que el seguidor no prefiera jugar j > 0 en lugar de 0, debe ser el caso que i pl(i)(aij − bj) ≤ 0, o equivalentemente i pl(i)aij ≤ bj. Por lo tanto, el líder obtendrá una utilidad de al menos mini ci si y solo si hay una solución factible a las restricciones. Dado que el pl(i) incentiva al seguidor a jugar 0, el líder intenta maximizar i pl(i)ci. Por lo tanto, el líder debe resolver el programa lineal original. Como prueba alternativa del Teorema 3, se puede observar que se sabe que encontrar una estrategia minimax en un juego de suma cero es tan difícil como el problema de programación lineal [6], y como señalamos al principio de esta sección, calcular una estrategia minimax en un juego de suma cero es un caso especial del problema de calcular una estrategia mixta óptima a la que comprometerse. La solubilidad en tiempo polinómico del problema de calcular una estrategia mixta óptima a la que comprometerse en juegos de forma normal de dos jugadores contrasta con la complejidad desconocida de calcular un equilibrio de Nash en tales juegos [21], así como con la NP-dificultad de encontrar un equilibrio de Nash con utilidad máxima para un jugador dado en tales juegos [8, 2]. Desafortunadamente, este resultado no se generaliza a más de dos jugadores; aquí, el problema se vuelve NP-duro. Para demostrar esto, reducimos desde el problema de CUBRIR-VÉRTICES. Definición 1. En VERTEX-COVER, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que cada arista e ∈ E tenga al menos uno de sus extremos en S. BALANCED-VERTEX-COVER es el caso especial de VERTEX-COVER en el que K = |V|/2. VERTEX-COVER es NP-completo [9]. El siguiente lema muestra que la dificultad persiste si requerimos K = |V|/2. (Resultados similares se han demostrado para otros problemas NP-completos). Lema 1. El problema de la COBERTURA DE VÉRTICES EQUILIBRADA es NP-completo. Prueba. La pertenencia a NP se deriva del hecho de que el problema es un caso especial de CUBRIMIENTO DE VÉRTICES, que está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES a una instancia de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO, de la siguiente manera. Si, para la instancia de CUBRIMIENTO DE VÉRTICES, K > |V|/2, simplemente agregamos vértices aislados que estén disjuntos del resto del grafo, hasta que K = |V|/2. Si K < |V|/2, agregamos triángulos aislados (es decir, el grafo completo de tres vértices) al grafo, aumentando K en 2 cada vez, hasta que K = |V|/2. Teorema 4. En juegos de forma normal de 3 jugadores, encontrar una estrategia mixta óptima a la que comprometerse es NP-difícil. Prueba. Reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO al siguiente juego de <br>forma normal</br> de 3 jugadores. ",
            "candidates": [],
            "error": [
                [
                    "juego en forma normal",
                    "forma normal",
                    "forma normal",
                    "juego en forma normal",
                    "forma normal",
                    "forma normal"
                ]
            ]
        },
        "bayesian game": {
            "translated_key": "juego bayesiano",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Computing the Optimal Strategy to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "We give both positive results (efficient algorithms) and negative results (NP-hardness results).",
                "Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent systems with self-interested agents (including most economic settings), the optimal action for one agent to take depends on the actions that the other agents take.",
                "To analyze how an agent should behave in such settings, the tools of game theory need to be applied.",
                "Typically, when a strategic setting is modeled in the framework of game theory, it is assumed that players choose their strategies simultaneously.",
                "This is especially true when the setting is modeled as a normal-form game, which only specifies each agents utility as a function of the vector of strategies that the agents choose, and does not provide any information on the order in which agents make their decisions and what the agents observe about earlier decisions by other agents.",
                "Given that the game is modeled in normal form, it is typically analyzed using the concept of Nash equilibrium.",
                "A Nash equilibrium specifies a strategy for each player, such that no player has an incentive to individually deviate from this profile of strategies. (Typically, the strategies are allowed to be mixed, that is, probability distributions over the original (pure) strategies.)",
                "A (mixed-strategy) Nash equilibrium is guaranteed to exist in finite games [18], but one problem is that there may be multiple Nash equilibria.",
                "This leads to the equilibrium selection problem of how an agent can know which strategy to play if it does not know which equilibrium is to be played.",
                "When the setting is modeled as an extensive-form game, it is possible to specify that some players receive some information about actions taken by others earlier in the game before deciding on their action.",
                "Nevertheless, in general, the players do not know everything that happened earlier in the game.",
                "Because of this, these games are typically still analyzed using an equilibrium concept, where one specifies a mixed strategy for each player, and requires that each players strategy is a best response to the others strategies. (Typically an additional constraint on the strategies is now imposed to ensure that players do not play in a way that is irrational with respect to the information that they have received so far.",
                "This leads to refinements of Nash equilibrium such as subgame perfect and sequential equilibrium.)",
                "However, in many real-world settings, strategies are not selected in such a simultaneous manner.",
                "Oftentimes, one player (the leader) is able to commit to a strategy before another player (the follower).",
                "This can be due to a variety of reasons.",
                "For example, one of the players may arrive at the site at which the game is to be played before another agent (e.g., in economic settings, one player may enter a market earlier and commit to a way of doing busi82 ness).",
                "Such commitment power has a profound impact on how the game should be played.",
                "For example, the leader may be best off playing a strategy that is dominated in the normal-form representation of the game.",
                "Perhaps the earliest and best-known example of the effect of commitment is that by von Stackelberg [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution.",
                "In general, if commitment to mixed strategies is possible, then (under minor assumptions) it never hurts, and often helps, to commit to a strategy [26].",
                "Being forced to commit to a pure strategy sometimes helps, and sometimes hurts (for example, committing to a pure strategy in rock-paper-scissors before the other players decision will naturally result in a loss).",
                "In this paper, we will assume commitment is always forced; if it is not, the player who has the choice of whether to commit can simply compare the commitment outcome to the non-commitment (simultaneous-move) outcome.",
                "Models of leadership are especially important in settings with multiple self-interested software agents.",
                "Once the code for an agent (or for a team of agents) is finalized and the agent is deployed, the agent is committed to playing the (possibly randomized) strategy that the code prescribes.",
                "Thus, as long as one can credibly show that one cannot change the code later, the code serves as a commitment device.",
                "This holds true for recreational tournaments among agents (e.g., poker tournaments, RoboSoccer), and for industrial applications such as sensor webs.",
                "Finally, there is also an implicit leadership situation in the field of mechanism design, in which one player (the designer) gets to choose the rules of the game that the remaining players then play.",
                "Mechanism design is an extremely important topic to the EC community: the papers published on mechanism design in recent EC conferences are too numerous to cite.",
                "Indeed, the mechanism designer may benefit from committing to a choice that, if the (remaining) agents actions were fixed, would be suboptimal.",
                "For example, in a (first-price) auction, the seller may wish to set a positive (artificial) reserve price for the item, below which the item will not be sold-even if the seller values the item at 0.",
                "In hindsight (after the bids have come in), this (na¨ıvely) appears suboptimal: if a bid exceeding the reserve price came in, the reserve price had no effect, and if no such bid came in, the seller would have been better off accepting a lower bid.",
                "Of course, the reason for setting the reserve price is that it incentivizes the bidders to bid higher, and because of this, setting artificial reserve prices can actually increase expected revenue to the seller.",
                "A significant amount of research has recently been devoted to the computation of solutions according to various solution concepts for settings in which the agents choose their strategies simultaneously, such as dominance [7, 11, 3] and (especially) Nash equilibrium [8, 21, 16, 15, 2, 22, 23, 4].",
                "However, the computation of the optimal strategy to commit to in a leadership situation has gone ignored.",
                "Theoretically, leadership situations can simply be thought of as an extensive-form game in which one player chooses a strategy (for the original game) first.",
                "The number of strategies in this extensive-form game, however, can be exceedingly large.",
                "For example, if the leader is able to commit to a mixed strategy in the original game, then every one of the (continuum of) mixed strategies constitutes a pure strategy in the extensive-form representation of the leadership situation. (We note that a commitment to a distribution is not the same as a distribution over commitments.)",
                "Moreover, if the original game is itself an extensive-form game, the number of strategies in the extensive-form representation of the leadership situation (which is a different extensive-form game) becomes even larger.",
                "Because of this, it is usually not computationally feasible to simply transform the original game into the extensive-form representation of the leadership situation; instead, we have to analyze the game in its original representation.",
                "In this paper, we study how to compute the optimal strategy to commit to, both in normal-form games (Section 2) and in Bayesian games, which are a special case of extensiveform games (Section 3). 2.",
                "NORMAL-FORM GAMES In this section, we study how to compute the optimal strategy to commit to for games represented in normal form. 2.1 Definitions In a normal-form game, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a pure strategy for every player, also known as a profile of pure strategies) to a real number.",
                "To ease notation, in the case of two players, we will refer to player 1s pure strategy set as S, and player 2s pure strategy set as T. Such games can be represented in (bi-)matrix form, in which the rows correspond to player 1s pure strategies, the columns correspond to player 2s pure strategies, and the entries of the matrix give the row and column players utilities (in that order) for the corresponding outcome of the game.",
                "In the case of three players, we will use R, S, and T, for player 1, 2, and 3s pure strategies, respectively.",
                "A mixed strategy for a player is a probability distribution over that players pure strategies.",
                "In the case of two-player games, we will refer to player 1 as the leader and player 2 as the follower.",
                "Before defining optimal leadership strategies, consider the following game which illustrates the effect of the leaders ability to commit. 2, 1 4, 0 1, 0 3, 1 In this normal-form representation, the bottom strategy for the row player is strictly dominated by the top strategy.",
                "Nevertheless, if the row player has the ability to commit to a pure strategy before the column player chooses his strategy, the row player should commit to the bottom strategy: doing so will make the column player prefer to play the right strategy, leading to a utility of 3 for the row player.",
                "By contrast, if the row player were to commit to the top strategy, the column player would prefer to play the left strategy, leading to a utility of only 2 for the row player.",
                "If the row player is able to commit to a mixed strategy, then she can get an even greater (expected) utility: if the row player commits to placing probability p > 1/2 on the bottom strategy, then the column player will still prefer to play the right strategy, and the row players expected utility will be 3p + 4(1 − p) = 4 − p ≥ 3.",
                "If the row player plays each strategy with probability exactly 1/2, the column player is 83 indifferent between the strategies.",
                "In such cases, we will assume that the column player will choose the strategy that maximizes the row players utility (in this case, the right strategy).",
                "Hence, the optimal mixed strategy to commit to for the row player is p = 1/2.",
                "There are a few good reasons for this assumption.",
                "If we were to assume the opposite, then there would not exist an optimal strategy for the row player in the example game: the row player would play the bottom strategy with probability p = 1/2 + with > 0, and the smaller , the better the utility for the row player.",
                "By contrast, if we assume that the follower always breaks ties in the leaders favor, then an optimal mixed strategy for the leader always exists, and this corresponds to a subgame perfect equilibrium of the extensive-form representation of the leadership situation.",
                "In any case, this is a standard assumption for such models (e.g. [20]), although some work has investigated what can happen in the other subgame perfect equilibria [26]. (For generic two-player games, the leaders subgame-perfect equilibrium payoff is unique.)",
                "Also, the same assumption is typically used in mechanism design, in that it is assumed that if an agent is indifferent between revealing his preferences truthfully and revealing them falsely, he will report them truthfully.",
                "Given this assumption, we can safely refer to optimal leadership strategies rather than having to use some equilibrium notion.",
                "Hence, for the purposes of this paper, an optimal strategy to commit to in a 2-player game is a strategy s ∈ S that maximizes maxt∈BR(s) ul(s, t), where BR(s) = arg maxt∈T uf (s, t). (ul and uf are the leader and followers utility functions, respectively.)",
                "We can have S = S for the case of commitment to pure strategies, or S = ∆(S), the set of probability distributions over S, for the case of commitment to mixed strategies. (We note that replacing T by ∆(T) makes no difference in this definition.)",
                "For games with more than two players, in which the players commit to their strategies in sequence, we define optimal strategies to commit to recursively.",
                "After the leader commits to a strategy, the game to be played by the remaining agents is itself a (smaller) leadership game.",
                "Thus, we define an optimal strategy to commit to as a strategy that maximizes the leaders utility, assuming that the play of the remaining agents is itself optimal under this definition, and maximizes the leaders utility among all optimal ways to play the remaining game.",
                "Again, commitment to mixed strategies may or may not be a possibility for every player (although for the last player it does not matter if we allow for commitment to mixed strategies). 2.2 Commitment to pure strategies We first study how to compute the optimal pure strategy to commit to.",
                "This is relatively simple, because the number of strategies to commit to is not very large. (In the following, #outcomes is the number of complete strategy profiles.)",
                "Theorem 1.",
                "Under commitment to pure strategies, the set of all optimal strategy profiles in a normal-form game can be found in O(#players · #outcomes) time.",
                "Proof.",
                "Each pure strategy that the first player may commit to will induce a subgame for the remaining players.",
                "We can solve each such subgame recursively to find all of its optimal strategy profiles; each of these will give the original leader some utility.",
                "Those that give the leader maximal utility correspond exactly to the optimal strategy profiles of the original game.",
                "We now present the algorithm formally.",
                "Let Su(G, s1) be the subgame that results after the first (remaining) player in G plays s1 ∈ SG 1 .",
                "A game with 0 players is simply an outcome of the game.",
                "The function Append(s, O) appends the strategy s to each of the vectors of strategies in the set O.",
                "Let e be the empty vector with no elements.",
                "In a slight abuse of notation, we will write uG 1 (C) when all strategy profiles in the set C give player 1 the same utility in the game G. (Here, player 1 is the first remaining player in the subgame G, not necessarily player 1 in the original game.)",
                "We note that arg max is set-valued.",
                "Then, the following algorithm computes all optimal strategy profiles: Algorithm Solve(G) if G has 0 players return {e} C ← ∅ for all s1 ∈ SG 1 { O ← Solve(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) if C = ∅ or uG 1 (s1, O ) = uG 1 (C) C ← C∪Append(s1, O ) if uG 1 (s1, O ) > uG 1 (C) C ←Append(s1, O ) } return C Every outcome is (potentially) examined by every player, which leads to the given runtime bound.",
                "As an example of how the algorithm works, consider the following 3-player game, in which the first player chooses the left or right matrix, the second player chooses a row, and the third player chooses a column. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 3,0,0 First we eliminate the outcomes that do not correspond to best responses for the third player (removing them from the matrix): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Next, we remove the entries in which the third player does not break ties in favor of the second player, as well as entries that do not correspond to best responses for the second player. 0,1,1 2,1,1 1,1,1 0,5,1 Finally, we remove the entries in which the second and third players do not break ties in favor of the first player, as well as entries that do not correspond to best responses for the first player. 2,1,1 84 Hence, in optimal play, the first player chooses the left matrix, the second player chooses the middle row, and the third player chooses the left column. (We note that this outcome is Pareto-dominated by (Right, Middle, Left).)",
                "For general normal-form games, each players utility for each of the outcomes has to be explicitly represented in the input, so that the input size is itself Ω(#players · #outcomes).",
                "Therefore, the algorithm is in fact a linear-time algorithm. 2.3 Commitment to mixed strategies In the special case of two-player zero-sum games, computing an optimal mixed strategy for the leader to commit to is equivalent to computing a minimax strategy, which minimizes the maximum expected utility that the opponent can obtain.",
                "Minimax strategies constitute the only natural solution concept for two-player zero-sum games: von Neumanns Minimax Theorem [24] states that in two-player zero-sum games, it does not matter (in terms of the players utilities) which player gets to commit to a mixed strategy first, and a profile of mixed strategies is a Nash equilibrium if and only if both strategies are minimax strategies.",
                "It is well-known that a minimax strategy can be found in polynomial time, using linear programming [17].",
                "Our first result in this section generalizes this result, showing that an optimal mixed strategy for the leader to commit to can be efficiently computed in general-sum two-player games, again using linear programming.",
                "Theorem 2.",
                "In 2-player normal-form games, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders utility.",
                "Such a mixed strategy can be computed using the following simple linear program: maximize s∈S psul(s, t) subject to for all t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1 We note that this program may be infeasible for some follower strategies t, for example, if t is a strictly dominated strategy.",
                "Nevertheless, the program must be feasible for at least some follower strategies; among these follower strategies, choose a strategy t∗ that maximizes the linear programs solution value.",
                "Then, if the leader chooses as her mixed strategy the optimal settings of the variables ps for the linear program for t∗ , and the follower plays t∗ , this constitutes an optimal strategy profile.",
                "In the following result, we show that we cannot expect to solve the problem more efficiently than linear programming, because we can reduce any linear program with a probability constraint on its variables to a problem of computing the optimal mixed strategy to commit to in a 2-player normalform game.",
                "Theorem 3.",
                "Any linear program whose variables xi (with xi ∈ R≥0 ) must satsify i xi = 1 can be modeled as a problem of computing the optimal mixed strategy to commit to in a 2-player normal-form game.",
                "Proof.",
                "Let the leader have a pure strategy i for every variable xi.",
                "Let the column player have one pure strategy j for every constraint in the linear program (other than i xi = 1), and a single additional pure strategy 0.",
                "Let the utility functions be as follows.",
                "Writing the objective of the linear program as maximize i cixi, for any i, let ul(i, 0) = ci and uf (i, 0) = 0.",
                "Writing the jth constraint of the linear program (not including i xi = 1) as i aijxi ≤ bj, for any i, j > 0, let ul(i, j) = mini ci − 1 and uf (i, j) = aij − bj.",
                "For example, consider the following linear program. maximize 2x1 + x2 subject to x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 The optimal solution to this program is x1 = 1/3, x2 = 2/3.",
                "Our reduction transforms this program into the following leader-follower game (where the leader is the row player). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 Indeed, the optimal strategy for the leader is to play the top strategy with probability 1/3 and the bottom strategy with probability 2/3.",
                "We now show that the reduction works in general.",
                "Clearly, the leader wants to incentivize the follower to play 0, because the utility that the leader gets when the follower plays 0 is always greater than when the follower does not play 0.",
                "In order for the follower not to prefer playing j > 0 rather than 0, it must be the case that i pl(i)(aij − bj) ≤ 0, or equivalently i pl(i)aij ≤ bj.",
                "Hence the leader will get a utility of at least mini ci if and only if there is a feasible solution to the constraints.",
                "Given that the pl(i) incentivize the follower to play 0, the leader attempts to maximize i pl(i)ci.",
                "Thus the leader must solve the original linear program.",
                "As an alternative proof of Theorem 3, one may observe that it is known that finding a minimax strategy in a zerosum game is as hard as the linear programming problem [6], and as we pointed out at the beginning of this section, computing a minimax strategy in a zero-sum game is a special case of the problem of computing an optimal mixed strategy to commit to.",
                "This polynomial-time solvability of the problem of computing an optimal mixed strategy to commit to in two-player normal-form games contrasts with the unknown complexity of computing a Nash equilibrium in such games [21], as well as with the NP-hardness of finding a Nash equilibrium with maximum utility for a given player in such games [8, 2].",
                "Unfortunately, this result does not generalize to more than two players-here, the problem becomes NP-hard.",
                "To show this, we reduce from the VERTEX-COVER problem.",
                "Definition 1.",
                "In VERTEX-COVER, we are given a graph G = (V, E) and an integer K. We are asked whether there 85 exists a subset of the vertices S ⊆ V , with |S| = K, such that every edge e ∈ E has at least one of its endpoints in S. BALANCED-VERTEX-COVER is the special case of VERTEX-COVER in which K = |V |/2.",
                "VERTEX-COVER is NP-complete [9].",
                "The following lemma shows that the hardness remains if we require K = |V |/2. (Similar results have been shown for other NP-complete problems.)",
                "Lemma 1.",
                "BALANCED-VERTEX-COVER is NP-complete.",
                "Proof.",
                "Membership in NP follows from the fact that the problem is a special case of VERTEX-COVER, which is in NP.",
                "To show NP-hardness, we reduce an arbitrary VERTEX-COVER instance to a BALANCED-VERTEXCOVER instance, as follows.",
                "If, for the VERTEX-COVER instance, K > |V |/2, then we simply add isolated vertices that are disjoint from the rest of the graph, until K = |V |/2.",
                "If K < |V |/2, we add isolated triangles (that is, the complete graph on three vertices) to the graph, increasing K by 2 every time, until K = |V |/2.",
                "Theorem 4.",
                "In 3-player normal-form games, finding an optimal mixed strategy to commit to is NP-hard.",
                "Proof.",
                "We reduce an arbitrary BALANCED-VERTEXCOVER instance to the following 3-player normal-form game.",
                "For every vertex v, each of the three players has a pure strategy corresponding to that vertex (rv, sv, tv, respectively).",
                "In addition, for every edge e, the third player has a pure strategy te; and finally, the third player has one additional pure strategy t0.",
                "The utilities are as follows: • for all r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • for all r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • for all v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • for all v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • for all v ∈ V , for all r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V | |V |−2 ; • for all e ∈ E, s ∈ S, for both v ∈ e, u3(rv, s, te) = 0; • for all e ∈ E, s ∈ S, for all v /∈ e, u3(rv, s, te) = |V | |V |−2 . • for all r ∈ R, s ∈ S, u3(r, s, t0) = 1.",
                "We note that players 1 and 2 have the same utility function.",
                "We claim that there is an optimal strategy profile in which players 1 and 2 both obtain 1 (their maximum utility) if and only if there is a solution to the BALANCED-VERTEXCOVER problem. (Otherwise, these players will both obtain 0.)",
                "First, suppose there exists a solution to the BALANCEDVERTEX-COVER problem.",
                "Then, let player 1 play every rv such that v is in the cover with probability 2 |V | , and let player 2 play every sv such that v is not in the cover with probability 2 |V | .",
                "Then, for player 3, the expected utility of playing tv (for any v) is (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of 2 |V | that rv or sv is played.",
                "Additionally, the expected utility of playing te (for any e) is at most (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of at least 2 |V | that some rv with v ∈ e is played (because player 1 is randomizing over the pure strategies corresponding to the cover).",
                "It follows that playing t0 is a best response for player 3, giving players 1 and 2 a utility of 1.",
                "Now, suppose that players 1 and 2 obtain 1 in optimal play.",
                "Then, it must be the case that player 3 plays t0.",
                "Hence, for every v ∈ V , there must be a probability of at least 2 |V | that either rv or sv is played, for otherwise player 3 would be better off playing tv.",
                "Because players 1 and 2 have only a total probability of 2 to distribute, it must be the case that for each v, either rv or sv is played with probability 2 |V | , and the other is played with probability 0. (It is not possible for both to have nonzero probability, because then there would be some probability that both are played simultaneously (correlation is not possible), hence the total probability of at least one being played could not be high enough for all vertices.)",
                "Thus, for exactly half the v ∈ V , player 1 places probability 2 |V | on rv.",
                "Moreover, for every e ∈ E, there must be a probability of at least 2 |V | that some rv with v ∈ e is played, for otherwise player 3 would be better off playing te.",
                "Thus, the v ∈ V such that player 1 places probability 2 |V | on rv constitute a balanced vertex cover. 3.",
                "BAYESIAN GAMES So far, we have restricted our attention to normal-form games.",
                "In a normal-form game, it is assumed that every agent knows every other agents preferences over the outcomes of the game.",
                "In general, however, agents may have some private information about their preferences that is not known to the other agents.",
                "Moreover, at the time of commitment to a strategy, the agents may not even know their own (final) preferences over the outcomes of the game yet, because these preferences may be dependent on a context that has yet to materialize.",
                "For example, when the code for a trading agent is written, it may not yet be clear how that agent will value resources that it will negotiate over later, because this depends on information that is not yet available at the time at which the code is written (such as orders that will have been placed to the agent before the negotiation).",
                "In this section, we will study commitment in Bayesian games, which can model such uncertainty over preferences. 3.1 Definitions In a <br>bayesian game</br>, every player i has a set of actions Si, a set of types Θi with an associated probability distribution πi : Θi → [0, 1], and, for each type θi, a utility function uθi i : S1 × S2 × . . . × Sn → R. A pure strategy in a <br>bayesian game</br> is a mapping from the players types to actions, σi : Θi → Si. (Bayesian games can be rewritten in normal form by enumerating every pure strategy σi, but this will cause an exponential blowup in the size of the representation of the game and therefore cannot lead to efficient algorithms.)",
                "The strategy that the leader should commit to depends on whether, at the time of commitment, the leader knows her own type.",
                "If the leader does know her own type, the other types that the leader might have had become irrelevant and the leader should simply commit to the strategy that is optimal for the type.",
                "However, as argued above, the leader does not necessarily know her own type at the time of commitment (e.g., the time at which the code is submitted).",
                "In this case, the leader must commit to a strategy that is 86 dependent upon the leaders eventual type.",
                "We will study this latter model, although we will pay specific attention to the case where the leader has only a single type, which is effectively the same as the former model. 3.2 Commitment to pure strategies It turns out that computing an optimal pure strategy to commit to is hard in Bayesian games, even with two players.",
                "Theorem 5.",
                "Finding an optimal pure strategy to commit to in 2-player Bayesian games is NP-hard, even when the follower has only a single type.",
                "Proof.",
                "We reduce an arbitrary VERTEX-COVER instance to the following <br>bayesian game</br> between the leader and the follower.",
                "The leader has K types θ1, θ2, . . . , θK , each occurring with probability 1/K, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has only a single type; for each edge e ∈ E, the follower has an action te, and the follower has a single additional action t0.",
                "The utility function for the leader is given by, for all θl ∈ Θl and all s ∈ S, u θl l (s, t0) = 1, and for all e ∈ E, u θl l (s, te) = 0.",
                "The followers utility is given by: • For all v ∈ V , for all e ∈ E with v /∈ e, uf (sv, te) = 1; • For all v ∈ V , for all e ∈ E with v ∈ e, uf (sv, te) = −K; • For all v ∈ V , uf (sv, t0) = 0.",
                "We claim that the leader can get a utility of 1 if and only if there is a solution to the VERTEX-COVER instance.",
                "First, suppose that there is a solution to the VERTEXCOVER instance.",
                "Then, the leader can commit to a pure strategy such that for each vertex v in the cover, the leader plays sv for some type.",
                "Then, the followers utility for playing te (for any e ∈ E) is at most K−1 K + 1 K (−K) = − 1 K , so that the follower will prefer to play t0, which gives the leader a utility of 1, as required.",
                "Now, suppose that there is a pure strategy for the leader that will give the leader a utility of 1.",
                "Then, the follower must play t0.",
                "In order for the follower not to prefer playing te (for any e ∈ E) instead, for at least one v ∈ e the leader must play sv for some type θl.",
                "Hence, the set of vertices v that the leader plays for some type must constitute a vertex cover; and this set can have size at most K, because the leader has only K types.",
                "So there is a solution to the VERTEXCOVER instance.",
                "However, if the leader has only a single type, then the problem becomes easy again (#types is the number of types for the follower): Theorem 6.",
                "In 2-player Bayesian games in which the leader has only a single type, an optimal pure strategy to commit to can be found in O(#outcomes · #types) time.",
                "Proof.",
                "For every leader action s, we can compute, for every follower type θf ∈ Θf , which actions t maximize the followers utility; call this set of actions BRθf (s).",
                "Then, the utility that the leader receives for committing to action s can be computed as θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), and the leader can choose the best action to commit to. 3.3 Commitment to mixed strategies In two-player zero-sum imperfect information games with perfect recall (no player ever forgets something that it once knew), a minimax strategy can be constructed in polynomial time [12, 13].",
                "Unfortunately, this result does not extend to computing optimal mixed strategies to commit to in the general-sum case-not even in Bayesian games.",
                "We will exhibit NP-hardness by reducing from the INDEPENDENTSET problem.",
                "Definition 2.",
                "In INDEPENDENT-SET, we are given a graph G = (V, E) and an integer K. We are asked whether there exists a subset of the vertices S ⊆ V , with |S| = K, such that no edge e ∈ E has both of its endpoints in S. Again, this problem is NP-complete [9].",
                "Theorem 7.",
                "Finding an optimal mixed strategy to commit to in 2-player Bayesian games is NP-hard, even when the leader has only a single type and the follower has only two actions.",
                "Proof.",
                "We reduce an arbitrary INDEPENDENT-SET instance to the following <br>bayesian game</br> between the leader and the follower.",
                "The leader has only a single type, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has a type θv for every v ∈ V , occurring with probability 1 (|E|+1)|V | , and a type θe for every e ∈ E, occurring with probability 1 |E|+1 .",
                "The follower has two actions: t0 and t1.",
                "The leaders utility is given by, for all s ∈ S, ul(s, t0) = 1 and ul(s, t1) = 0.",
                "The followers utility is given by: • For all v ∈ V , uθv f (sv, t1) = 0; • For all v ∈ V and s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • For all v ∈ V and s ∈ S, uθv f (s, t0) = 1; • For all e ∈ E, s ∈ S, uθe f (s, t0) = 1; • For all e ∈ E, for both v ∈ e, uθe f (sv, t1) = 2K 3 ; • For all e ∈ E, for all v /∈ e, uθe f (sv, t1) = 0.",
                "We claim that an optimal strategy to commit to gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | if and only if there is a solution to the INDEPENDENT-SET instance.",
                "First, suppose that there is a solution to the INDEPENDENT-SET instance.",
                "Then, the leader could commit to the following strategy: for every vertex v in the independent set, play the corresponding sv with probability 1/K.",
                "If the follower has type θe for some e ∈ E, the expected utility for the follower of playing t1 is at most 1 K 2K 3 = 2/3, because there is at most one vertex v ∈ e such that sv is played with nonzero probability.",
                "Hence, the follower will play t0 and obtain a utility of 1.",
                "If the follower has type θv for some vertex v in the independent set, the expected utility for the follower of playing t1 is K−1 K K K−1 = 1, because the leader plays sv with probability 1/K.",
                "It follows that the follower (who breaks ties to maximize the leaders utility) will play t0, which also gives a utility of 1 and gives the leader a higher utility.",
                "Hence the leaders expected utility for this strategy is at least |E| |E|+1 + K (|E|+1)|V | , as required. 87 Now, suppose that there is a strategy that gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | .",
                "Then, this strategy must induce the follower to play t0 whenever it has a type of the form θe (because otherwise, the utility could be at most |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ).",
                "Thus, it cannot be the case that for some edge e = (v1, v2) ∈ E, the probability that the leader plays one of sv1 and sv2 is at least 2/K, because then the expected utility for the follower of playing t1 when it has type θe would be at least 2 K 2K 3 = 4/3 > 1.",
                "Moreover, the strategy must induce the follower to play t0 for at least K types of the form θv.",
                "Inducing the follower to play t0 when it has type θv can be done only by playing sv with probability at least 1/K, which will give the follower a utility of at most K−1 K K K−1 = 1 for playing t1.",
                "But then, the set of vertices v such that sv is played with probability at least 1/K must constitute an independent set of size K (because if there were an edge e between two such vertices, it would induce the follower to play t1 for type θe by the above).",
                "By contrast, if the follower has only a single type, then we can generalize the linear programming approach for normalform games: Theorem 8.",
                "In 2-player Bayesian games in which the follower has only a single type, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "We generalize the approach in Theorem 2 as follows.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader for every one of the leaders types such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders ex ante expected utility.",
                "To do so, we generalize the linear program as follows: maximize θl∈Θl π(θl) s∈S pθl s uθl l (s, t) subject to for all t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t ) for all θl ∈ Θl, s∈S p θl s = 1 As in Theorem 2, the solution for the linear program that maximizes the solution value is an optimal strategy to commit to.",
                "This shows an interesting contrast between commitment to pure strategies and commitment to mixed strategies in Bayesian games: for pure strategies, the problem becomes easy if the leader has only a single type (but not if the follower has only a single type), whereas for mixed strategies, the problem becomes easy if the follower has only a single type (but not if the leader has only a single type). 4.",
                "CONCLUSIONS AND FUTURE RESEARCH In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "This requires some equilibrium notion (Nash equilibrium and its refinements), and often leads to the equilibrium selection problem: it is unclear to each individual player according to which equilibrium she should play.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "For example, one agent may arrive at the (real or virtual) site of the game before the other, or, in the specific case of software agents, the code for one agent may be completed and committed before that of another agent.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "Specifically, if commitment to mixed strategies is possible, then (optimal) commitment never hurts the leader, and often helps.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we studied how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "For normal-form games, we showed that the optimal pure strategy to commit to can be found efficiently for any number of players.",
                "An optimal mixed strategy to commit to in a normal-form game can be found efficiently for two players using linear programming (and no more efficiently than that, in the sense that any linear program with a probability constraint can be encoded as such a problem). (This is a generalization of the polynomial-time computability of minimax strategies in normal-form games.)",
                "The problem becomes NP-hard for three (or more) players.",
                "In Bayesian games, the problem of finding an optimal pure strategy to commit to is NP-hard even in two-player games in which the follower has only a single type, although two-player games in which the leader has only a single type can be solved efficiently.",
                "The problem of finding an optimal mixed strategy to commit to in a <br>bayesian game</br> is NP-hard even in two-player games in which the leader has only a single type, although two-player games in which the follower has only a single type can be solved efficiently using a generalization of the linear progamming approach for normal-form games.",
                "The following two tables summarize these results. 2 players ≥ 3 players normal-form O(#outcomes) O(#outcomes· #players) Bayesian, O(#outcomes· NP-hard 1-type leader #types) Bayesian, NP-hard NP-hard 1-type follower Bayesian (general) NP-hard NP-hard Results for commitment to pure strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.) 88 2 players ≥ 3 players normal-form one LP-solve per NP-hard follower action Bayesian, NP-hard NP-hard 1-type leader Bayesian, one LP-solve per NP-hard 1-type follower follower action Bayesian (general) NP-hard NP-hard Results for commitment to mixed strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.)",
                "Future research can take a number of directions.",
                "First, we can empirically evaluate the techniques presented here on test suites such as GAMUT [19].",
                "We can also study the computation of optimal strategies to commit to in other1 concise representations of normal-form games-for example, in graphical games [10] or local-effect/action graph games [14, 1].",
                "For the cases where computing an optimal strategy to commit to is NP-hard, we can also study the computation of approximately optimal strategies to commit to.",
                "While the correct definition of an approximately optimal strategy is in this setting may appear simple at first-it should be a strategy that, if the following players play optimally, performs almost as well as the optimal strategy in expectation-this definition becomes problematic when we consider that the other players may also be playing only approximately optimally.",
                "One may also study models in which multiple (but not all) players commit at the same time.",
                "Another interesting direction to pursue is to see if computing optimal mixed strategies to commit to can help us in, or otherwise shed light on, computing Nash equilibria.",
                "Often, optimal mixed strategies to commit to are also Nash equilibrium strategies (for example, in two-player zero-sum games this is always true), although this is not always the case (for example, as we already pointed out, sometimes the optimal strategy to commit to is a strictly dominated strategy, which can never be a Nash equilibrium strategy). 5.",
                "REFERENCES [1] N. A. R. Bhat and K. Leyton-Brown.",
                "Computing Nash equilibria of action-graph games.",
                "In Proceedings of the 20th Annual Conference on Uncertainty in Artificial Intelligence (UAI), Banff, Canada, 2004. [2] V. Conitzer and T. Sandholm.",
                "Complexity results about Nash equilibria.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pages 765-771, Acapulco, Mexico, 2003. [3] V. Conitzer and T. Sandholm.",
                "Complexity of (iterated) dominance.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 88-97, Vancouver, Canada, 2005. [4] V. Conitzer and T. Sandholm.",
                "A generalized strategy eliminability criterion and computational methods for applying it.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 483-488, Pittsburgh, PA, USA, 2005. [5] A.",
                "A. Cournot.",
                "Recherches sur les principes math´ematiques de la th´eorie des richesses (Researches 1 Bayesian games are one potentially concise representation of normal-form games. into the Mathematical Principles of the Theory of Wealth).",
                "Hachette, Paris, 1838. [6] G. Dantzig.",
                "A proof of the equivalence of the programming problem and the game problem.",
                "In T. Koopmans, editor, Activity Analysis of Production and Allocation, pages 330-335.",
                "John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel.",
                "The complexity of eliminating dominated strategies.",
                "Mathematics of Operation Research, 18:553-565, 1993. [8] I. Gilboa and E. Zemel.",
                "Nash and correlated equilibria: Some complexity considerations.",
                "Games and Economic Behavior, 1:80-93, 1989. [9] R. Karp.",
                "Reducibility among combinatorial problems.",
                "In R. E. Miller and J. W. Thatcher, editors, Complexity of Computer Computations, pages 85-103.",
                "Plenum Press, NY, 1972. [10] M. Kearns, M. Littman, and S. Singh.",
                "Graphical models for game theory.",
                "In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou, and J. N. Tsitsiklis.",
                "A note on strategy elimination in bimatrix games.",
                "Operations Research Letters, 7(3):103-107, 1988. [12] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [14] K. Leyton-Brown and M. Tennenholtz.",
                "Local-effect games.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), Acapulco, Mexico, 2003. [15] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 36-41, San Diego, CA, 2003. [16] M. Littman and P. Stone.",
                "A polynomial-time Nash equilibrium algorithm for repeated games.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 48-54, San Diego, CA, 2003. [17] R. D. Luce and H. Raiffa.",
                "Games and Decisions.",
                "John Wiley and Sons, New York, 1957.",
                "Dover republication 1989. [18] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown, and Y. Shoham.",
                "Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms.",
                "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), New York, NY, USA, 2004. [20] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "MIT Press, 1994. [21] C. Papadimitriou.",
                "Algorithms, games and the Internet.",
                "In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 749-753, 2001. 89 [22] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 664-669, San Jose, CA, USA, 2004. [23] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 495-501, Pittsburgh, PA, USA, 2005. [24] J. von Neumann.",
                "Zur Theorie der Gesellschaftsspiele.",
                "Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg.",
                "Marktform und Gleichgewicht.",
                "Springer, Vienna, 1934. [26] B. von Stengel and S. Zamir.",
                "Leadership with commitment to mixed strategies.",
                "CDAM Research Report LSE-CDAM-2004-01, London School of Economics, Feb. 2004. 90"
            ],
            "original_annotated_samples": [
                "In this section, we will study commitment in Bayesian games, which can model such uncertainty over preferences. 3.1 Definitions In a <br>bayesian game</br>, every player i has a set of actions Si, a set of types Θi with an associated probability distribution πi : Θi → [0, 1], and, for each type θi, a utility function uθi i : S1 × S2 × . . . × Sn → R. A pure strategy in a <br>bayesian game</br> is a mapping from the players types to actions, σi : Θi → Si. (Bayesian games can be rewritten in normal form by enumerating every pure strategy σi, but this will cause an exponential blowup in the size of the representation of the game and therefore cannot lead to efficient algorithms.)",
                "We reduce an arbitrary VERTEX-COVER instance to the following <br>bayesian game</br> between the leader and the follower.",
                "We reduce an arbitrary INDEPENDENT-SET instance to the following <br>bayesian game</br> between the leader and the follower.",
                "The problem of finding an optimal mixed strategy to commit to in a <br>bayesian game</br> is NP-hard even in two-player games in which the leader has only a single type, although two-player games in which the follower has only a single type can be solved efficiently using a generalization of the linear progamming approach for normal-form games."
            ],
            "translated_annotated_samples": [
                "En esta sección, estudiaremos el compromiso en juegos bayesianos, los cuales pueden modelar tal incertidumbre sobre preferencias. 3.1 Definiciones En un <br>juego bayesiano</br>, cada jugador i tiene un conjunto de acciones Si, un conjunto de tipos Θi con una distribución de probabilidad asociada πi : Θi → [0, 1], y, para cada tipo θi, una función de utilidad uθi i : S1 × S2 × . . . × Sn → R. Una estrategia pura en un <br>juego bayesiano</br> es una asignación de los tipos de los jugadores a acciones, σi : Θi → Si. (Los juegos bayesianos pueden ser reescritos en forma normal enumerando cada estrategia pura σi, pero esto causará un crecimiento exponencial en el tamaño de la representación del juego y por lo tanto no puede llevar a algoritmos eficientes).",
                "Reducimos una instancia arbitraria de CUBRIMIENTO DE VÉRTICES al siguiente <br>juego bayesiano</br> entre el líder y el seguidor.",
                "Reducimos una instancia arbitraria de CONJUNTO-INDEPENDIENTE al siguiente <br>juego bayesiano</br> entre el líder y el seguidor.",
                "El problema de encontrar una estrategia mixta óptima a comprometerse en un <br>juego bayesiano</br> es NP-duro incluso en juegos de dos jugadores en los que el líder tiene solo un tipo, aunque los juegos de dos jugadores en los que el seguidor tiene solo un tipo pueden resolverse eficientemente utilizando una generalización del enfoque de programación lineal para juegos en forma normal."
            ],
            "translated_text": "En sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias simultáneamente. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. El reciente aumento en el interés por las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas a comprometerse tanto en el compromiso de estrategias puras como en el compromiso de estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Ofrecemos tanto resultados positivos (algoritmos eficientes) como resultados negativos (resultados de NP-hardness). Categorías y Descriptores de Asignaturas J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas Términos Generales Algoritmos, Economía, Teoría 1. En sistemas multiagentes con agentes auto-interesados (incluyendo la mayoría de los entornos económicos), la acción óptima que un agente debe tomar depende de las acciones que tomen los otros agentes. Para analizar cómo un agente debería comportarse en tales situaciones, es necesario aplicar las herramientas de la teoría de juegos. Normalmente, cuando se modela un escenario estratégico en el marco de la teoría de juegos, se asume que los jugadores eligen sus estrategias de forma simultánea. Esto es especialmente cierto cuando el escenario se modela como un juego en forma normal, que solo especifica la utilidad de cada agente como una función del vector de estrategias que los agentes eligen, y no proporciona información sobre el orden en que los agentes toman sus decisiones y lo que los agentes observan sobre las decisiones anteriores de otros agentes. Dado que el juego está modelado en forma normal, típicamente se analiza utilizando el concepto de equilibrio de Nash. Un equilibrio de Nash especifica una estrategia para cada jugador, de modo que ningún jugador tenga un incentivo para desviarse individualmente de este perfil de estrategias. (Por lo general, se permite que las estrategias sean mixtas, es decir, distribuciones de probabilidad sobre las estrategias originales (puras).) Un equilibrio de Nash (de estrategia mixta) está garantizado de existir en juegos finitos [18], pero un problema es que puede haber múltiples equilibrios de Nash. Esto conduce al problema de selección de equilibrio de cómo un agente puede saber qué estrategia jugar si no sabe qué equilibrio se va a jugar. Cuando el escenario se modela como un juego de forma extensiva, es posible especificar que algunos jugadores reciben información sobre las acciones tomadas por otros antes en el juego antes de decidir su acción. Sin embargo, en general, los jugadores no saben todo lo que sucedió anteriormente en el juego. Por lo tanto, estos juegos suelen ser analizados todavía utilizando un concepto de equilibrio, donde se especifica una estrategia mixta para cada jugador, y se requiere que la estrategia de cada jugador sea una mejor respuesta a las estrategias de los demás. (Normalmente se impone ahora una restricción adicional en las estrategias para garantizar que los jugadores no jueguen de una manera irracional con respecto a la información que han recibido hasta el momento). Esto conduce a refinamientos del equilibrio de Nash como el equilibrio perfecto en subjuegos y el equilibrio secuencial. Sin embargo, en muchos entornos del mundo real, las estrategias no se seleccionan de manera simultánea. A menudo, un jugador (el líder) puede comprometerse con una estrategia antes que otro jugador (el seguidor). Esto puede deberse a una variedad de razones. Por ejemplo, uno de los jugadores puede llegar al lugar donde se jugará el juego antes que otro agente (por ejemplo, en entornos económicos, un jugador puede ingresar al mercado antes y comprometerse con una forma de hacer negocios). Un compromiso tan poderoso tiene un impacto profundo en cómo debería jugarse el juego. Por ejemplo, el líder puede estar mejor jugando una estrategia que esté dominada en la representación de forma normal del juego. Quizás el ejemplo más temprano y conocido del efecto del compromiso es el de von Stackelberg [25], quien demostró que, en el modelo de duopolio de Cournot [5], si una empresa puede comprometerse con una cantidad de producción primero, esa empresa lo hará mucho mejor que en la solución de movimiento simultáneo (Nash). En general, si es posible comprometerse con estrategias mixtas, entonces (bajo suposiciones menores) nunca perjudica, y a menudo ayuda, comprometerse con una estrategia [26]. Verse obligado a comprometerse con una estrategia pura a veces ayuda y a veces perjudica (por ejemplo, comprometerse con una estrategia pura en piedra-papel-tijeras antes de la decisión de los otros jugadores naturalmente resultará en una derrota). En este documento, asumiremos que el compromiso siempre es forzado; si no lo es, el jugador que tiene la opción de comprometerse simplemente puede comparar el resultado del compromiso con el resultado de no comprometerse (movimiento simultáneo). Los modelos de liderazgo son especialmente importantes en entornos con múltiples agentes de software con intereses propios. Una vez que el código de un agente (o de un equipo de agentes) está finalizado y el agente es desplegado, el agente se compromete a jugar la estrategia (posiblemente aleatoria) que el código prescribe. Por lo tanto, siempre y cuando se pueda demostrar de manera creíble que no se puede cambiar el código más tarde, el código funciona como un dispositivo de compromiso. Esto es válido para torneos recreativos entre agentes (por ejemplo, torneos de póker, RoboSoccer) y para aplicaciones industriales como redes de sensores. Finalmente, también existe una situación de liderazgo implícito en el campo del diseño de mecanismos, en la cual un jugador (el diseñador) tiene la oportunidad de elegir las reglas del juego que los demás jugadores luego siguen. El diseño de mecanismos es un tema extremadamente importante para la comunidad de EC: los artículos publicados sobre diseño de mecanismos en las recientes conferencias de EC son demasiados para citar. De hecho, el diseñador del mecanismo puede beneficiarse al comprometerse con una elección que, si las acciones de los agentes (restantes) estuvieran fijas, sería subóptima. Por ejemplo, en una subasta (a precio fijo), el vendedor puede desear establecer un precio de reserva positivo (artificial) para el artículo, por debajo del cual el artículo no se venderá, incluso si el vendedor valora el artículo en 0. En retrospectiva (después de recibir las ofertas), esto (ingenuamente) parece subóptimo: si llegaba una oferta que superaba el precio de reserva, el precio de reserva no tenía efecto, y si no llegaba tal oferta, el vendedor hubiera estado mejor aceptando una oferta más baja. Por supuesto, la razón para establecer el precio de reserva es incentivar a los postores a ofertar más alto, y debido a esto, establecer precios de reserva artificiales puede aumentar realmente los ingresos esperados para el vendedor. Recientemente se ha dedicado una cantidad significativa de investigación al cálculo de soluciones de acuerdo con varios conceptos de solución para escenarios en los que los agentes eligen sus estrategias simultáneamente, como la dominancia [7, 11, 3] y (especialmente) el equilibrio de Nash [8, 21, 16, 15, 2, 22, 23, 4]. Sin embargo, se ha ignorado el cálculo de la estrategia óptima a comprometerse en una situación de liderazgo. Teóricamente, las situaciones de liderazgo simplemente pueden ser consideradas como un juego de forma extensiva en el que un jugador elige una estrategia (para el juego original) primero. El número de estrategias en este juego de forma extensiva, sin embargo, puede ser extremadamente grande. Por ejemplo, si el líder es capaz de comprometerse con una estrategia mixta en el juego original, entonces cada una de las estrategias mixtas (continuo de) constituye una estrategia pura en la representación de forma extensiva de la situación de liderazgo. (Se destaca que un compromiso con una distribución no es lo mismo que una distribución sobre compromisos). Además, si el juego original es en sí mismo un juego de forma extensiva, el número de estrategias en la representación de forma extensiva de la situación de liderazgo (que es un juego de forma extensiva diferente) se vuelve aún más grande. Por lo tanto, generalmente no es factible computacionalmente simplemente transformar el juego original en la representación de forma extensiva de la situación de liderazgo; en su lugar, debemos analizar el juego en su representación original. En este artículo, estudiamos cómo calcular la estrategia óptima a comprometerse, tanto en juegos de forma normal (Sección 2) como en juegos bayesianos, que son un caso especial de juegos de forma extensiva (Sección 3). JUEGOS EN FORMA NORMAL En esta sección, estudiamos cómo calcular la estrategia óptima a comprometerse para juegos representados en forma normal. 2.1 Definiciones En un juego en forma normal, cada jugador i ∈ {1, . . . , n} tiene un conjunto de estrategias puras (o acciones) Si, y una función de utilidad ui : S1×S2×. . .×Sn → R que mapea cada resultado (un vector que consiste en una estrategia pura para cada jugador, también conocido como un perfil de estrategias puras) a un número real. Para facilitar la notación, en el caso de dos jugadores, nos referiremos al conjunto de estrategias puras del jugador 1 como S, y al conjunto de estrategias puras del jugador 2 como T. Estos juegos pueden representarse en forma de matriz (bi-matriz), en la que las filas corresponden a las estrategias puras del jugador 1, las columnas corresponden a las estrategias puras del jugador 2, y las entradas de la matriz dan las utilidades de los jugadores de fila y columna (en ese orden) para el resultado correspondiente del juego. En el caso de tres jugadores, usaremos R, S y T, para las estrategias puras de los jugadores 1, 2 y 3, respectivamente. Una estrategia mixta para un jugador es una distribución de probabilidad sobre las estrategias puras de ese jugador. En el caso de juegos de dos jugadores, nos referiremos al jugador 1 como el líder y al jugador 2 como el seguidor. Antes de definir estrategias de liderazgo óptimas, considera el siguiente juego que ilustra el efecto de la capacidad del líder para comprometerse. 2, 1 4, 0 1, 0 3, 1 En esta representación en forma normal, la estrategia inferior para el jugador de la fila está estrictamente dominada por la estrategia superior. Sin embargo, si el jugador de la fila tiene la capacidad de comprometerse con una estrategia pura antes de que el jugador de la columna elija su estrategia, el jugador de la fila debería comprometerse con la estrategia inferior: al hacerlo, el jugador de la columna preferirá jugar la estrategia correcta, lo que llevará a una utilidad de 3 para el jugador de la fila. Por el contrario, si el jugador de la fila se comprometiera con la estrategia superior, el jugador de la columna preferiría jugar la estrategia izquierda, lo que llevaría a una utilidad de solo 2 para el jugador de la fila. Si el jugador de la fila puede comprometerse a una estrategia mixta, entonces puede obtener una utilidad aún mayor (esperada): si el jugador de la fila se compromete a colocar una probabilidad p > 1/2 en la estrategia inferior, entonces el jugador de la columna seguirá prefiriendo jugar la estrategia derecha, y la utilidad esperada de los jugadores de la fila será 3p + 4(1 − p) = 4 − p ≥ 3. Si el jugador de la fila juega cada estrategia con una probabilidad exacta de 1/2, el jugador de la columna está 83 indiferente entre las estrategias. En tales casos, asumiremos que el jugador de la columna elegirá la estrategia que maximiza la utilidad de los jugadores de la fila (en este caso, la estrategia correcta). Por lo tanto, la estrategia mixta óptima a la que debe comprometerse el jugador de la fila es p = 1/2. Hay algunas buenas razones para esta suposición. Si asumiéramos lo contrario, entonces no existiría una estrategia óptima para el jugador de la fila en el juego de ejemplo: el jugador de la fila jugaría la estrategia inferior con una probabilidad p = 1/2 + con > 0, y cuanto menor sea , mejor será la utilidad para el jugador de la fila. Por el contrario, si asumimos que el seguidor siempre rompe los empates a favor de los líderes, entonces siempre existe una estrategia mixta óptima para el líder, lo que corresponde a un equilibrio perfecto en subjuegos de la representación en forma extensiva de la situación de liderazgo. En cualquier caso, esta es una suposición estándar para tales modelos (por ejemplo, [20]), aunque algunos trabajos han investigado lo que puede suceder en los otros equilibrios perfectos de subjuego [26]. (Para juegos genéricos de dos jugadores, el pago del equilibrio perfecto de subjuego de los líderes es único). Además, la misma suposición se utiliza típicamente en el diseño de mecanismos, asumiendo que si un agente es indiferente entre revelar sus preferencias de manera veraz o falsa, las reportará de manera veraz. Dado este supuesto, podemos hacer referencia de manera segura a estrategias de liderazgo óptimas en lugar de tener que utilizar alguna noción de equilibrio. Por lo tanto, para los propósitos de este documento, una estrategia óptima a comprometerse en un juego de 2 jugadores es una estrategia s ∈ S que maximiza maxt∈BR(s) ul(s, t), donde BR(s) = arg maxt∈T uf (s, t). (ul y uf son las funciones de utilidad del líder y los seguidores, respectivamente). Podemos tener S = S para el caso de compromiso con estrategias puras, o S = ∆(S), el conjunto de distribuciones de probabilidad sobre S, para el caso de compromiso con estrategias mixtas. (Observamos que reemplazar T por ∆(T) no hace ninguna diferencia en esta definición). Para juegos con más de dos jugadores, en los que los jugadores se comprometen con sus estrategias en secuencia, definimos estrategias óptimas a las que comprometerse de forma recursiva. Después de que el líder se compromete con una estrategia, el juego que jugarán los agentes restantes es en sí mismo un juego de liderazgo (más pequeño). Por lo tanto, definimos una estrategia óptima a comprometerse como una estrategia que maximiza la utilidad del líder, asumiendo que el juego de los agentes restantes es óptimo bajo esta definición, y maximiza la utilidad del líder entre todas las formas óptimas de jugar el juego restante. Nuevamente, el compromiso con estrategias mixtas puede o no ser una posibilidad para cada jugador (aunque para el último jugador no importa si permitimos el compromiso con estrategias mixtas). 2.2 Compromiso con estrategias puras. Primero estudiamos cómo calcular la estrategia pura óptima a la que comprometerse. Esto es relativamente simple, porque el número de estrategias a comprometer no es muy grande. (En lo siguiente, #resultados es el número de perfiles de estrategia completos). Teorema 1. Bajo el compromiso de estrategias puras, el conjunto de todos los perfiles de estrategia óptimos en un juego en forma normal se puede encontrar en tiempo O(#jugadores · #resultados). Prueba. Cada estrategia pura a la que el primer jugador pueda comprometerse inducirá un subjuego para los jugadores restantes. Podemos resolver cada subjuego de esta manera de forma recursiva para encontrar todos sus perfiles de estrategia óptimos; cada uno de estos le dará al líder original cierta utilidad. Aquellos que proporcionan al líder la utilidad máxima corresponden exactamente a los perfiles de estrategia óptimos del juego original. Ahora presentamos el algoritmo de forma formal. Sea Su(G, s1) el subjuego que resulta después de que el primer jugador restante en G juega s1 ∈ SG 1. Un juego con 0 jugadores es simplemente un resultado del juego. La función Append(s, O) añade la estrategia s a cada uno de los vectores de estrategias en el conjunto O. Sea e el vector vacío sin elementos. En un ligero abuso de notación, escribiremos uG 1 (C) cuando todos los perfiles estratégicos en el conjunto C le den al jugador 1 la misma utilidad en el juego G. (Aquí, el jugador 1 es el primer jugador restante en el subjuego G, no necesariamente el jugador 1 en el juego original). Observamos que arg max es un conjunto de valores. Entonces, el siguiente algoritmo calcula todos los perfiles de estrategia óptimos: Algoritmo Resolver(G) si G tiene 0 jugadores, devuelve {e} C ← ∅ para todo s1 ∈ SG 1 { O ← Resolver(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) si C = ∅ o uG 1 (s1, O ) = uG 1 (C) C ← C∪Agregar(s1, O ) si uG 1 (s1, O ) > uG 1 (C) C ←Agregar(s1, O ) } devuelve C Cada resultado es examinado (potencialmente) por cada jugador, lo que lleva al límite de tiempo dado. Como ejemplo de cómo funciona el algoritmo, considera el siguiente juego de 3 jugadores, en el que el primer jugador elige la matriz izquierda o derecha, el segundo jugador elige una fila y el tercer jugador elige una columna. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 Primero eliminamos los resultados que no corresponden a las mejores respuestas para el tercer jugador (eliminándolos de la matriz): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Luego, eliminamos las entradas en las que el tercer jugador no resuelve los empates a favor del segundo jugador, así como las entradas que no corresponden a las mejores respuestas para el segundo jugador. 0,1,1 2,1,1 1,1,1 0,5,1 Finalmente, eliminamos las entradas en las que el segundo y tercer jugador no resuelven los empates a favor del primer jugador, así como las entradas que no corresponden a las mejores respuestas para el primer jugador. 2,1,1 Por lo tanto, en el juego óptimo, el primer jugador elige la matriz izquierda, el segundo jugador elige la fila del medio y el tercer jugador elige la columna izquierda. (Notamos que este resultado está dominado por Pareto por (Derecha, Medio, Izquierda).) Para juegos en forma normal general, la utilidad de cada jugador para cada uno de los resultados debe representarse explícitamente en la entrada, de modo que el tamaño de la entrada sea en sí mismo Ω(#jugadores · #resultados). Por lo tanto, el algoritmo es de hecho un algoritmo de tiempo lineal. 2.3 Compromiso con estrategias mixtas En el caso especial de juegos de dos jugadores de suma cero, calcular una estrategia mixta óptima para que el líder se comprometa es equivalente a calcular una estrategia minimax, que minimiza la utilidad esperada máxima que el oponente puede obtener. Las estrategias minimax constituyen el único concepto de solución natural para juegos de suma cero de dos jugadores: el Teorema Minimax de von Neumann [24] establece que en juegos de suma cero de dos jugadores, no importa (en términos de las utilidades de los jugadores) qué jugador se compromete primero a una estrategia mixta, y un perfil de estrategias mixtas es un equilibrio de Nash si y solo si ambas estrategias son estrategias minimax. Es bien sabido que una estrategia minimax se puede encontrar en tiempo polinómico, utilizando programación lineal [17]. Nuestro primer resultado en esta sección generaliza este resultado, mostrando que una estrategia mixta óptima para que el líder se comprometa puede ser calculada eficientemente en juegos de dos jugadores de suma general, nuevamente utilizando programación lineal. Teorema 2. En juegos de forma normal de 2 jugadores, una estrategia mixta óptima a la que comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal. Prueba. Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder de modo que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad del líder. Un programa lineal simple puede calcular una estrategia mixta como la siguiente: maximizar s∈S psul(s, t) sujeto a que para todo t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1. Se destaca que este programa puede ser inviable para algunas estrategias seguidoras t, por ejemplo, si t es una estrategia estrictamente dominada. Sin embargo, el programa debe ser factible para al menos algunas estrategias seguidoras; entre estas estrategias seguidoras, elige una estrategia t∗ que maximice el valor de la solución de los programas lineales. Entonces, si la líder elige como su estrategia mixta los ajustes óptimos de las variables ps para el programa lineal para t∗, y el seguidor juega t∗, esto constituye un perfil de estrategia óptimo. En el siguiente resultado, demostramos que no podemos esperar resolver el problema de manera más eficiente que la programación lineal, ya que podemos reducir cualquier programa lineal con una restricción de probabilidad en sus variables a un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores. Teorema 3. Cualquier programa lineal cuyas variables xi (con xi ∈ R≥0) deben satisfacer i xi = 1 puede ser modelado como un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores. Prueba. Que el líder tenga una estrategia pura i para cada variable xi. Que el jugador de la columna tenga una estrategia pura j para cada restricción en el programa lineal (distinta de i xi = 1), y una única estrategia pura adicional 0. Que las funciones de utilidad sean las siguientes. Escribiendo el objetivo del programa lineal como maximizar ci xi, para cualquier i, dejando ul(i, 0) = ci y uf(i, 0) = 0. Escribiendo la j-ésima restricción del programa lineal (sin incluir i xi = 1) como i aijxi ≤ bj, para cualquier i, j > 0, sea ul(i, j) = mini ci − 1 y uf(i, j) = aij − bj. Por ejemplo, considera el siguiente programa lineal. maximizar 2x1 + x2 sujeto a x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 La solución óptima de este programa es x1 = 1/3, x2 = 2/3. Nuestra reducción transforma este programa en el siguiente juego de líder-seguidor (donde el líder es el jugador de la fila). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 De hecho, la estrategia óptima para el líder es jugar la estrategia superior con una probabilidad de 1/3 y la estrategia inferior con una probabilidad de 2/3. Ahora demostramos que la reducción funciona en general. Claramente, el líder quiere incentivar al seguidor a jugar 0, porque la utilidad que el líder obtiene cuando el seguidor juega 0 siempre es mayor que cuando el seguidor no juega 0. Para que el seguidor no prefiera jugar j > 0 en lugar de 0, debe ser el caso que i pl(i)(aij − bj) ≤ 0, o equivalentemente i pl(i)aij ≤ bj. Por lo tanto, el líder obtendrá una utilidad de al menos mini ci si y solo si hay una solución factible a las restricciones. Dado que el pl(i) incentiva al seguidor a jugar 0, el líder intenta maximizar i pl(i)ci. Por lo tanto, el líder debe resolver el programa lineal original. Como prueba alternativa del Teorema 3, se puede observar que se sabe que encontrar una estrategia minimax en un juego de suma cero es tan difícil como el problema de programación lineal [6], y como señalamos al principio de esta sección, calcular una estrategia minimax en un juego de suma cero es un caso especial del problema de calcular una estrategia mixta óptima a la que comprometerse. La solubilidad en tiempo polinómico del problema de calcular una estrategia mixta óptima a la que comprometerse en juegos de forma normal de dos jugadores contrasta con la complejidad desconocida de calcular un equilibrio de Nash en tales juegos [21], así como con la NP-dificultad de encontrar un equilibrio de Nash con utilidad máxima para un jugador dado en tales juegos [8, 2]. Desafortunadamente, este resultado no se generaliza a más de dos jugadores; aquí, el problema se vuelve NP-duro. Para demostrar esto, reducimos desde el problema de CUBRIR-VÉRTICES. Definición 1. En VERTEX-COVER, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que cada arista e ∈ E tenga al menos uno de sus extremos en S. BALANCED-VERTEX-COVER es el caso especial de VERTEX-COVER en el que K = |V|/2. VERTEX-COVER es NP-completo [9]. El siguiente lema muestra que la dificultad persiste si requerimos K = |V|/2. (Resultados similares se han demostrado para otros problemas NP-completos). Lema 1. El problema de la COBERTURA DE VÉRTICES EQUILIBRADA es NP-completo. Prueba. La pertenencia a NP se deriva del hecho de que el problema es un caso especial de CUBRIMIENTO DE VÉRTICES, que está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES a una instancia de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO, de la siguiente manera. Si, para la instancia de CUBRIMIENTO DE VÉRTICES, K > |V|/2, simplemente agregamos vértices aislados que estén disjuntos del resto del grafo, hasta que K = |V|/2. Si K < |V|/2, agregamos triángulos aislados (es decir, el grafo completo de tres vértices) al grafo, aumentando K en 2 cada vez, hasta que K = |V|/2. Teorema 4. En juegos de forma normal de 3 jugadores, encontrar una estrategia mixta óptima a la que comprometerse es NP-difícil. Prueba. Reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO al siguiente juego de forma normal de 3 jugadores. Para cada vértice v, cada uno de los tres jugadores tiene una estrategia pura correspondiente a ese vértice (rv, sv, tv, respectivamente). Además, para cada arista e, el tercer jugador tiene una estrategia pura te; y finalmente, el tercer jugador tiene una estrategia pura adicional t0. Los servicios son los siguientes: • para todo r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • para todo r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • para todo v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • para todo v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • para todo v ∈ V, para todo r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V| |V|−2; • para todo e ∈ E, s ∈ S, para ambos v ∈ e, u3(rv, s, te) = 0; • para todo e ∈ E, s ∈ S, para todo v /∈ e, u3(rv, s, te) = |V| |V|−2. • para todo r ∈ R, s ∈ S, u3(r, s, t0) = 1. Observamos que los jugadores 1 y 2 tienen la misma función de utilidad. Sostenemos que existe un perfil de estrategia óptimo en el que los jugadores 1 y 2 obtienen ambos 1 (su utilidad máxima) si y solo si hay una solución al problema de la COBERTURA DE VÉRTICES EQUILIBRADA. (De lo contrario, estos jugadores obtendrán ambos 0). Primero, supongamos que existe una solución al problema de la cubierta de vértices balanceada. Entonces, deja que el jugador 1 juegue cada rv de manera que v esté en la cobertura con probabilidad 2 |V|, y deja que el jugador 2 juegue cada sv de manera que v no esté en la cobertura con probabilidad 2 |V|. Entonces, para el jugador 3, la utilidad esperada de jugar tv (para cualquier v) es (1 − 2 |V|) |V| |V|−2 = 1, porque hay una probabilidad de 2 |V| de que se juegue rv o sv. Además, la utilidad esperada de jugar te (para cualquier e) es a lo sumo (1 − 2 |V | ) |V | |V |−2 = 1, porque hay una probabilidad de al menos 2 |V | de que algún rv con v ∈ e se juegue (debido a que el jugador 1 está aleatorizando sobre las estrategias puras correspondientes a la cobertura). Se deduce que jugar t0 es la mejor respuesta para el jugador 3, otorgando a los jugadores 1 y 2 una utilidad de 1. Ahora, supongamos que los jugadores 1 y 2 obtienen 1 en el juego óptimo. Entonces, debe ser el caso de que el jugador 3 juegue t0. Por lo tanto, para cada v ∈ V, debe haber una probabilidad de al menos 2 |V| de que se juegue rv o sv, de lo contrario, al jugador 3 le convendría más jugar tv. Dado que los jugadores 1 y 2 solo tienen una probabilidad total de 2 para distribuir, debe ser el caso que para cada v, ya sea rv o sv se juegue con una probabilidad de 2 |V|, y el otro se juegue con una probabilidad de 0. (No es posible que ambos tengan una probabilidad distinta de cero, porque entonces habría alguna probabilidad de que ambos se jugaran simultáneamente (la correlación no es posible), por lo tanto, la probabilidad total de que al menos uno se juegue no podría ser lo suficientemente alta para todos los vértices). Por lo tanto, para exactamente la mitad de los v ∈ V, el jugador 1 coloca una probabilidad de 2 |V| en rv. Además, para cada e ∈ E, debe haber una probabilidad de al menos 2 |V | de que se juegue algún rv con v ∈ e, de lo contrario, al jugador 3 le convendría más jugar te. Por lo tanto, el v ∈ V tal que el jugador 1 coloca una probabilidad de 2 |V | en rv constituye una cubierta de vértices equilibrada. 3. Juegos bayesianos. Hasta ahora, hemos restringido nuestra atención a los juegos en forma normal. En un juego en forma normal, se asume que cada agente conoce las preferencias de todos los demás agentes sobre los resultados del juego. En general, sin embargo, los agentes pueden tener información privada sobre sus preferencias que no es conocida por los otros agentes. Además, en el momento de comprometerse con una estrategia, los agentes pueden ni siquiera conocer sus propias preferencias (finales) sobre los resultados del juego aún, ya que estas preferencias pueden depender de un contexto que aún no se ha materializado. Por ejemplo, cuando se escribe el código para un agente de negociación, puede que aún no esté claro cómo ese agente valorará los recursos sobre los que negociará más adelante, porque esto depende de información que aún no está disponible en el momento en que se escribe el código (como órdenes que habrán sido colocadas al agente antes de la negociación). En esta sección, estudiaremos el compromiso en juegos bayesianos, los cuales pueden modelar tal incertidumbre sobre preferencias. 3.1 Definiciones En un <br>juego bayesiano</br>, cada jugador i tiene un conjunto de acciones Si, un conjunto de tipos Θi con una distribución de probabilidad asociada πi : Θi → [0, 1], y, para cada tipo θi, una función de utilidad uθi i : S1 × S2 × . . . × Sn → R. Una estrategia pura en un <br>juego bayesiano</br> es una asignación de los tipos de los jugadores a acciones, σi : Θi → Si. (Los juegos bayesianos pueden ser reescritos en forma normal enumerando cada estrategia pura σi, pero esto causará un crecimiento exponencial en el tamaño de la representación del juego y por lo tanto no puede llevar a algoritmos eficientes). La estrategia a la que el líder debería comprometerse depende de si, en el momento del compromiso, el líder conoce su propio tipo. Si la líder conoce su propio tipo, los otros tipos que la líder podría haber tenido se vuelven irrelevantes y la líder simplemente debería comprometerse con la estrategia que sea óptima para ese tipo. Sin embargo, como se argumentó anteriormente, la líder no necesariamente conoce su propio tipo en el momento de comprometerse (por ejemplo, en el momento en que se envía el código). En este caso, el líder debe comprometerse con una estrategia que dependa en un 86% del tipo eventual del líder. Estudiaremos este último modelo, aunque prestaremos atención específica al caso en el que el líder tiene un solo tipo, lo cual es efectivamente lo mismo que el modelo anterior. 3.2 Compromiso con estrategias puras Resulta que calcular una estrategia pura óptima a la que comprometerse es difícil en juegos bayesianos, incluso con dos jugadores. Teorema 5. Encontrar una estrategia pura óptima a comprometerse en juegos bayesianos de 2 jugadores es NP-difícil, incluso cuando el seguidor tiene solo un tipo. Prueba. Reducimos una instancia arbitraria de CUBRIMIENTO DE VÉRTICES al siguiente <br>juego bayesiano</br> entre el líder y el seguidor. El líder tiene K tipos θ1, θ2, . . . , θK, cada uno ocurriendo con probabilidad 1/K, y para cada vértice v ∈ V, el líder tiene una acción sv. El seguidor tiene solo un tipo; para cada borde e ∈ E, el seguidor tiene una acción te, y el seguidor tiene una acción adicional única t0. La función de utilidad para el líder está dada por, para todo θl ∈ Θl y todo s ∈ S, u θl l (s, t0) = 1, y para todo e ∈ E, u θl l (s, te) = 0. La utilidad de los seguidores se da por: • Para todo v ∈ V, para todo e ∈ E con v /∈ e, uf (sv, te) = 1; • Para todo v ∈ V, para todo e ∈ E con v ∈ e, uf (sv, te) = −K; • Para todo v ∈ V, uf (sv, t0) = 0. Sostenemos que el líder puede obtener una utilidad de 1 si y solo si hay una solución para la instancia de CUBRIMIENTO-DE-VÉRTICES. Primero, supongamos que hay una solución para la instancia de CUBRIRVÉRTICES. Entonces, el líder puede comprometerse con una estrategia pura tal que para cada vértice v en la cobertura, el líder juega sv para algún tipo. Entonces, la utilidad de los seguidores para jugar te (para cualquier e ∈ E) es a lo sumo K−1 K + 1 K (−K) = − 1 K , por lo que el seguidor preferirá jugar t0, lo que le da al líder una utilidad de 1, como se requiere. Ahora, supongamos que hay una estrategia pura para el líder que le dará al líder una utilidad de 1. Entonces, el seguidor debe jugar t0. Para que el seguidor no prefiera jugar te (para cualquier e ∈ E) en su lugar, al menos para un v ∈ e, el líder debe jugar sv para algún tipo θl. Por lo tanto, el conjunto de vértices v que el líder juega para algún tipo debe constituir una cubierta de vértices; y este conjunto puede tener un tamaño de como máximo K, ya que el líder solo tiene K tipos. Entonces hay una solución para la instancia de CUBRIMIENTODEVÉRTICES. Sin embargo, si el líder tiene solo un tipo, entonces el problema se vuelve fácil nuevamente (#tipos es el número de tipos para el seguidor): Teorema 6. En juegos bayesianos de 2 jugadores en los que el líder tiene solo un tipo, una estrategia pura óptima a comprometerse puede encontrarse en tiempo O(#resultados · #tipos). Prueba. Para cada acción de líder s, podemos calcular, para cada tipo de seguidor θf ∈ Θf, qué acciones t maximizan la utilidad de los seguidores; llamamos a este conjunto de acciones BRθf (s). Entonces, la utilidad que recibe el líder por comprometerse a la acción s se puede calcular como θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), y el líder puede elegir la mejor acción a la que comprometerse. 3.3 Compromiso con estrategias mixtas En juegos de información imperfecta de suma cero de dos jugadores con memoria perfecta (ningún jugador olvida algo que una vez supo), una estrategia minimax se puede construir en tiempo polinómico [12, 13]. Desafortunadamente, este resultado no se extiende a calcular estrategias mixtas óptimas a comprometerse en el caso de suma general, ni siquiera en juegos bayesianos. Demostraremos la NP-dificultad reduciendo desde el problema de CONJUNTOINDEPENDIENTE. Definición 2. En INDEPENDENT-SET, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que ninguna arista e ∈ E tenga ambos extremos en S. Nuevamente, este problema es NP-completo [9]. Teorema 7. Encontrar una estrategia mixta óptima a comprometerse en juegos bayesianos de 2 jugadores es NP-duro, incluso cuando el líder tiene solo un tipo y el seguidor tiene solo dos acciones. Prueba. Reducimos una instancia arbitraria de CONJUNTO-INDEPENDIENTE al siguiente <br>juego bayesiano</br> entre el líder y el seguidor. El líder tiene solo un tipo, y para cada vértice v ∈ V, el líder tiene una acción sv. El seguidor tiene un tipo θv para cada v ∈ V, que ocurre con una probabilidad de 1 (|E|+1)|V|, y un tipo θe para cada e ∈ E, que ocurre con una probabilidad de 1 |E|+1. El seguidor tiene dos acciones: t0 y t1. La utilidad de los líderes se da por, para todo s ∈ S, ul(s, t0) = 1 y ul(s, t1) = 0. La utilidad de los seguidores se da por: • Para todo v ∈ V, uθv f (sv, t1) = 0; • Para todo v ∈ V y s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • Para todo v ∈ V y s ∈ S, uθv f (s, t0) = 1; • Para todo e ∈ E, s ∈ S, uθe f (s, t0) = 1; • Para todo e ∈ E, para ambos v ∈ e, uθe f (sv, t1) = 2K 3 ; • Para todo e ∈ E, para todo v /∈ e, uθe f (sv, t1) = 0. Sostenemos que una estrategia óptima a comprometerse le otorga al líder una utilidad esperada de al menos |E| |E|+1 + K (|E|+1)|V | si y solo si hay una solución para la instancia de CONJUNTO-INDEPENDIENTE. Primero, supongamos que hay una solución para la instancia de CONJUNTO-INDEPENDIENTE. Entonces, el líder podría comprometerse con la siguiente estrategia: por cada vértice v en el conjunto independiente, jugar el correspondiente sv con una probabilidad de 1/K. Si el seguidor tiene el tipo θe para algún e ∈ E, la utilidad esperada para el seguidor al jugar t1 es a lo sumo 1 K 2K 3 = 2/3, porque hay a lo sumo un vértice v ∈ e tal que sv se juega con probabilidad distinta de cero. Por lo tanto, el seguidor jugará t0 y obtendrá una utilidad de 1. Si el seguidor tiene el tipo θv para algún vértice v en el conjunto independiente, la utilidad esperada para el seguidor al jugar t1 es K−1 K K K−1 = 1, porque el líder juega sv con probabilidad 1/K. Se deduce que el seguidor (quien rompe los empates para maximizar la utilidad de los líderes) jugará t0, lo que también otorga una utilidad de 1 y brinda al líder una mayor utilidad. Por lo tanto, la utilidad esperada de los líderes para esta estrategia es al menos |E| |E|+1 + K (|E|+1)|V |, como se requiere. Ahora, supongamos que hay una estrategia que le da al líder una utilidad esperada de al menos |E| |E|+1 + K (|E|+1)|V |. Entonces, esta estrategia debe inducir al seguidor a jugar t0 siempre que tenga un tipo de la forma θe (porque de lo contrario, la utilidad podría ser a lo sumo |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ). Por lo tanto, no puede ser el caso de que para alguna arista e = (v1, v2) ∈ E, la probabilidad de que el líder juegue uno de sv1 y sv2 sea al menos 2/K, porque entonces la utilidad esperada para el seguidor de jugar t1 cuando tiene el tipo θe sería al menos 2 K 2K 3 = 4/3 > 1. Además, la estrategia debe inducir al seguidor a jugar t0 durante al menos K tipos de la forma θv. Inducir al seguidor a jugar t0 cuando tiene el tipo θv solo se puede lograr jugando sv con una probabilidad de al menos 1/K, lo que le dará al seguidor una utilidad de como máximo K−1 K K K−1 = 1 por jugar t1. Pero entonces, el conjunto de vértices v tales que sv se juega con una probabilidad de al menos 1/K debe constituir un conjunto independiente de tamaño K (porque si hubiera una arista e entre dos de estos vértices, induciría al seguidor a jugar t1 para el tipo θe según lo mencionado anteriormente). Por el contrario, si el seguidor tiene solo un tipo, entonces podemos generalizar el enfoque de programación lineal para juegos en forma normal: Teorema 8. En juegos bayesianos de 2 jugadores en los que el seguidor tiene solo un tipo, una estrategia mixta óptima a comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal. Prueba. Generalizamos el enfoque en el Teorema 2 de la siguiente manera. Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder para cada uno de los tipos de líderes de manera que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad esperada ex ante de los líderes. Para hacerlo, generalizamos el programa lineal de la siguiente manera: maximizar θl∈Θl π(θl) s∈S pθl s uθl l (s, t) sujeto a para todo t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t) para todo θl ∈ Θl, s∈S p θl s = 1 Como en el Teorema 2, la solución para el programa lineal que maximiza el valor de la solución es una estrategia óptima a comprometerse. Esto muestra un contraste interesante entre el compromiso con estrategias puras y el compromiso con estrategias mixtas en juegos bayesianos: para las estrategias puras, el problema se vuelve fácil si el líder tiene solo un tipo (pero no si el seguidor tiene solo un tipo), mientras que para las estrategias mixtas, el problema se vuelve fácil si el seguidor tiene solo un tipo (pero no si el líder tiene solo un tipo). 4. CONCLUSIONES E INVESTIGACIONES FUTURAS En los sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias de forma simultánea. Esto requiere cierta noción de equilibrio (equilibrio de Nash y sus refinamientos), y a menudo conduce al problema de selección de equilibrio: no está claro para cada jugador individual según qué equilibrio debería jugar. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Por ejemplo, un agente puede llegar al sitio del juego (real o virtual) antes que el otro, o, en el caso específico de agentes de software, el código de un agente puede estar completo y comprometido antes que el de otro agente. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. Específicamente, si es posible el compromiso con estrategias mixtas, entonces el compromiso (óptimo) nunca perjudica al líder y a menudo lo beneficia. El reciente aumento del interés en las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas para comprometerse tanto a estrategias puras como a estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Para juegos en forma normal, demostramos que la estrategia pura óptima a comprometerse se puede encontrar eficientemente para cualquier número de jugadores. Una estrategia mixta óptima para comprometerse en un juego en forma normal puede encontrarse eficientemente para dos jugadores utilizando programación lineal (y no más eficientemente que eso, en el sentido de que cualquier programa lineal con una restricción de probabilidad puede ser codificado como tal problema). (Esta es una generalización de la computabilidad en tiempo polinómico de las estrategias minimax en juegos en forma normal). El problema se vuelve NP-duro para tres (o más) jugadores. En los juegos bayesianos, el problema de encontrar una estrategia pura óptima a la que comprometerse es NP-duro incluso en juegos de dos jugadores en los que el seguidor tiene solo un tipo, aunque los juegos de dos jugadores en los que el líder tiene solo un tipo pueden resolverse eficientemente. El problema de encontrar una estrategia mixta óptima a comprometerse en un <br>juego bayesiano</br> es NP-duro incluso en juegos de dos jugadores en los que el líder tiene solo un tipo, aunque los juegos de dos jugadores en los que el seguidor tiene solo un tipo pueden resolverse eficientemente utilizando una generalización del enfoque de programación lineal para juegos en forma normal. Las siguientes dos tablas resumen estos resultados. 2 jugadores ≥ 3 jugadores forma normal O(#resultados) O(#resultados· #jugadores) Bayesiano, O(#resultados· NP-completo 1-tipo líder #tipos) Bayesiano, NP-completo NP-completo 1-tipo seguidor Bayesiano (general) NP-completo NP-completo Resultados para el compromiso con estrategias puras. (Con más de 2 jugadores, el seguidor es el último jugador en comprometerse, el líder es el primero.) 88 2 jugadores ≥ 3 jugadores forma normal una resolución de LP por acción NP-completa del seguidor Bayesiano, NP-completo NP-completo 1-tipo líder Bayesiano, una resolución de LP por acción NP-completa del 1-tipo seguidor Bayesiano (general) NP-completo NP-completo Resultados para el compromiso con estrategias mixtas. (Con más de 2 jugadores, el seguidor es el último jugador en comprometerse, el líder es el primero.) La investigación futura puede tomar varias direcciones. Primero, podemos evaluar empíricamente las técnicas presentadas aquí en conjuntos de pruebas como GAMUT [19]. También podemos estudiar la computación de estrategias óptimas a comprometerse en otras representaciones concisas de juegos en forma normal, por ejemplo, en juegos gráficos [10] o juegos de grafo de efecto local/acción [14, 1]. Para los casos en los que calcular una estrategia óptima para comprometerse es NP-duro, también podemos estudiar la computación de estrategias aproximadamente óptimas para comprometerse. Si bien la definición correcta de una estrategia aproximadamente óptima en este contexto puede parecer simple al principio, debería ser una estrategia que, si los jugadores siguientes juegan de manera óptima, funcione casi tan bien como la estrategia óptima en promedio, esta definición se vuelve problemática cuando consideramos que los otros jugadores también podrían estar jugando solo de manera aproximadamente óptima. Uno también puede estudiar modelos en los que múltiples (pero no todos) jugadores se comprometen al mismo tiempo. Otra dirección interesante a explorar es ver si calcular estrategias mixtas óptimas a las que comprometerse puede ayudarnos, o de alguna manera arrojar luz sobre, el cálculo de equilibrios de Nash. A menudo, las estrategias mixtas óptimas a las que comprometerse también son estrategias de equilibrio de Nash (por ejemplo, en juegos de suma cero de dos jugadores esto siempre es cierto), aunque no siempre es el caso (por ejemplo, como ya señalamos, a veces la estrategia óptima a la que comprometerse es una estrategia estrictamente dominada, que nunca puede ser una estrategia de equilibrio de Nash). 5. REFERENCIAS [1] N. A. R. Bhat y K. Leyton-Brown. Calculando los equilibrios de Nash de juegos de gráficos de acción. En Actas de la 20ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI), Banff, Canadá, 2004. [2] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Actas de la Decimoctava Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 765-771, Acapulco, México, 2003. [3] V. Conitzer y T. Sandholm. Complejidad del dominio (iterado). En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 88-97, Vancouver, Canadá, 2005. [4] V. Conitzer y T. Sandholm. Un criterio de eliminabilidad de estrategias generalizado y métodos computacionales para aplicarlo. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 483-488, Pittsburgh, PA, EE. UU., 2005. [5] A. A. Cournot. Las investigaciones sobre los juegos bayesianos son una representación potencialmente concisa de los juegos en forma normal en los principios matemáticos de la teoría de la riqueza. Hachette, París, 1838. [6] G. Dantzig. Una prueba de la equivalencia del problema de programación y el problema de juego. En T. Koopmans, editor, Análisis de la actividad de producción y asignación, páginas 330-335. John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel. \n\nJohn Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, y E. Zemel. La complejidad de eliminar estrategias dominadas. Matemáticas de la Investigación de Operaciones, 18:553-565, 1993. [8] I. Gilboa y E. Zemel. Nash y equilibrios correlacionados: Algunas consideraciones de complejidad. Juegos y Comportamiento Económico, 1:80-93, 1989. [9] R. Karp. Reductibilidad entre problemas combinatorios. En R. E. Miller y J. W. Thatcher, editores, Complejidad de las Computaciones de Computadoras, páginas 85-103. Plenum Press, Nueva York, 1972. [10] M. Kearns, M. Littman y S. Singh. Modelos gráficos para teoría de juegos. En Actas de la Conferencia sobre Incertidumbre en Inteligencia Artificial (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou y J. N. Tsitsiklis. Una nota sobre la eliminación de estrategias en juegos bimatrix. Cartas de Investigación Operativa, 7(3):103-107, 1988. [12] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [14] K. Leyton-Brown y M. Tennenholtz. Juegos de efecto local. En Actas de la Decimoctava Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), Acapulco, México, 2003. [15] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 36-41, San Diego, CA, 2003. [16] M. Littman y P. Stone. Un algoritmo de equilibrio de Nash de tiempo polinómico para juegos repetidos. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 48-54, San Diego, CA, 2003. [17] R. D. Luce y H. Raiffa. Juegos y decisiones. John Wiley and Sons, Nueva York, 1957. Reedición de Dover 1989. [18] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown y Y. Shoham. Ejecutar el GAMUT: Un enfoque integral para evaluar algoritmos de teoría de juegos. En la Conferencia Internacional sobre Agentes Autónomos y Sistemas Multiagente (AAMAS), Nueva York, NY, EE. UU., 2004. [20] M. J. Osborne y A. Rubinstein. Un curso de teoría de juegos. MIT Press, 1994. [21] C. Papadimitriou. \n\nMIT Press, 1994. [21] C. Papadimitriou. Algoritmos, juegos e Internet. En Actas del Simposio Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. 89 [22] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 664-669, San José, CA, EE. UU., 2004. [23] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [24] J. von Neumann. A la teoría de los juegos sociales. Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg. \n\nMathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg. Forma de mercado y equilibrio. Springer, Viena, 1934. [26] B. von Stengel y S. Zamir. Liderazgo con compromiso hacia estrategias mixtas. Informe de investigación CDAM LSE-CDAM-2004-01, London School of Economics, febrero de 2004. 90 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "nash equilibrium": {
            "translated_key": "equilibrio de Nash",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Computing the Optimal Strategy to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "We give both positive results (efficient algorithms) and negative results (NP-hardness results).",
                "Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent systems with self-interested agents (including most economic settings), the optimal action for one agent to take depends on the actions that the other agents take.",
                "To analyze how an agent should behave in such settings, the tools of game theory need to be applied.",
                "Typically, when a strategic setting is modeled in the framework of game theory, it is assumed that players choose their strategies simultaneously.",
                "This is especially true when the setting is modeled as a normal-form game, which only specifies each agents utility as a function of the vector of strategies that the agents choose, and does not provide any information on the order in which agents make their decisions and what the agents observe about earlier decisions by other agents.",
                "Given that the game is modeled in normal form, it is typically analyzed using the concept of <br>nash equilibrium</br>.",
                "A <br>nash equilibrium</br> specifies a strategy for each player, such that no player has an incentive to individually deviate from this profile of strategies. (Typically, the strategies are allowed to be mixed, that is, probability distributions over the original (pure) strategies.)",
                "A (mixed-strategy) <br>nash equilibrium</br> is guaranteed to exist in finite games [18], but one problem is that there may be multiple Nash equilibria.",
                "This leads to the equilibrium selection problem of how an agent can know which strategy to play if it does not know which equilibrium is to be played.",
                "When the setting is modeled as an extensive-form game, it is possible to specify that some players receive some information about actions taken by others earlier in the game before deciding on their action.",
                "Nevertheless, in general, the players do not know everything that happened earlier in the game.",
                "Because of this, these games are typically still analyzed using an equilibrium concept, where one specifies a mixed strategy for each player, and requires that each players strategy is a best response to the others strategies. (Typically an additional constraint on the strategies is now imposed to ensure that players do not play in a way that is irrational with respect to the information that they have received so far.",
                "This leads to refinements of <br>nash equilibrium</br> such as subgame perfect and sequential equilibrium.)",
                "However, in many real-world settings, strategies are not selected in such a simultaneous manner.",
                "Oftentimes, one player (the leader) is able to commit to a strategy before another player (the follower).",
                "This can be due to a variety of reasons.",
                "For example, one of the players may arrive at the site at which the game is to be played before another agent (e.g., in economic settings, one player may enter a market earlier and commit to a way of doing busi82 ness).",
                "Such commitment power has a profound impact on how the game should be played.",
                "For example, the leader may be best off playing a strategy that is dominated in the normal-form representation of the game.",
                "Perhaps the earliest and best-known example of the effect of commitment is that by von Stackelberg [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution.",
                "In general, if commitment to mixed strategies is possible, then (under minor assumptions) it never hurts, and often helps, to commit to a strategy [26].",
                "Being forced to commit to a pure strategy sometimes helps, and sometimes hurts (for example, committing to a pure strategy in rock-paper-scissors before the other players decision will naturally result in a loss).",
                "In this paper, we will assume commitment is always forced; if it is not, the player who has the choice of whether to commit can simply compare the commitment outcome to the non-commitment (simultaneous-move) outcome.",
                "Models of leadership are especially important in settings with multiple self-interested software agents.",
                "Once the code for an agent (or for a team of agents) is finalized and the agent is deployed, the agent is committed to playing the (possibly randomized) strategy that the code prescribes.",
                "Thus, as long as one can credibly show that one cannot change the code later, the code serves as a commitment device.",
                "This holds true for recreational tournaments among agents (e.g., poker tournaments, RoboSoccer), and for industrial applications such as sensor webs.",
                "Finally, there is also an implicit leadership situation in the field of mechanism design, in which one player (the designer) gets to choose the rules of the game that the remaining players then play.",
                "Mechanism design is an extremely important topic to the EC community: the papers published on mechanism design in recent EC conferences are too numerous to cite.",
                "Indeed, the mechanism designer may benefit from committing to a choice that, if the (remaining) agents actions were fixed, would be suboptimal.",
                "For example, in a (first-price) auction, the seller may wish to set a positive (artificial) reserve price for the item, below which the item will not be sold-even if the seller values the item at 0.",
                "In hindsight (after the bids have come in), this (na¨ıvely) appears suboptimal: if a bid exceeding the reserve price came in, the reserve price had no effect, and if no such bid came in, the seller would have been better off accepting a lower bid.",
                "Of course, the reason for setting the reserve price is that it incentivizes the bidders to bid higher, and because of this, setting artificial reserve prices can actually increase expected revenue to the seller.",
                "A significant amount of research has recently been devoted to the computation of solutions according to various solution concepts for settings in which the agents choose their strategies simultaneously, such as dominance [7, 11, 3] and (especially) <br>nash equilibrium</br> [8, 21, 16, 15, 2, 22, 23, 4].",
                "However, the computation of the optimal strategy to commit to in a leadership situation has gone ignored.",
                "Theoretically, leadership situations can simply be thought of as an extensive-form game in which one player chooses a strategy (for the original game) first.",
                "The number of strategies in this extensive-form game, however, can be exceedingly large.",
                "For example, if the leader is able to commit to a mixed strategy in the original game, then every one of the (continuum of) mixed strategies constitutes a pure strategy in the extensive-form representation of the leadership situation. (We note that a commitment to a distribution is not the same as a distribution over commitments.)",
                "Moreover, if the original game is itself an extensive-form game, the number of strategies in the extensive-form representation of the leadership situation (which is a different extensive-form game) becomes even larger.",
                "Because of this, it is usually not computationally feasible to simply transform the original game into the extensive-form representation of the leadership situation; instead, we have to analyze the game in its original representation.",
                "In this paper, we study how to compute the optimal strategy to commit to, both in normal-form games (Section 2) and in Bayesian games, which are a special case of extensiveform games (Section 3). 2.",
                "NORMAL-FORM GAMES In this section, we study how to compute the optimal strategy to commit to for games represented in normal form. 2.1 Definitions In a normal-form game, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a pure strategy for every player, also known as a profile of pure strategies) to a real number.",
                "To ease notation, in the case of two players, we will refer to player 1s pure strategy set as S, and player 2s pure strategy set as T. Such games can be represented in (bi-)matrix form, in which the rows correspond to player 1s pure strategies, the columns correspond to player 2s pure strategies, and the entries of the matrix give the row and column players utilities (in that order) for the corresponding outcome of the game.",
                "In the case of three players, we will use R, S, and T, for player 1, 2, and 3s pure strategies, respectively.",
                "A mixed strategy for a player is a probability distribution over that players pure strategies.",
                "In the case of two-player games, we will refer to player 1 as the leader and player 2 as the follower.",
                "Before defining optimal leadership strategies, consider the following game which illustrates the effect of the leaders ability to commit. 2, 1 4, 0 1, 0 3, 1 In this normal-form representation, the bottom strategy for the row player is strictly dominated by the top strategy.",
                "Nevertheless, if the row player has the ability to commit to a pure strategy before the column player chooses his strategy, the row player should commit to the bottom strategy: doing so will make the column player prefer to play the right strategy, leading to a utility of 3 for the row player.",
                "By contrast, if the row player were to commit to the top strategy, the column player would prefer to play the left strategy, leading to a utility of only 2 for the row player.",
                "If the row player is able to commit to a mixed strategy, then she can get an even greater (expected) utility: if the row player commits to placing probability p > 1/2 on the bottom strategy, then the column player will still prefer to play the right strategy, and the row players expected utility will be 3p + 4(1 − p) = 4 − p ≥ 3.",
                "If the row player plays each strategy with probability exactly 1/2, the column player is 83 indifferent between the strategies.",
                "In such cases, we will assume that the column player will choose the strategy that maximizes the row players utility (in this case, the right strategy).",
                "Hence, the optimal mixed strategy to commit to for the row player is p = 1/2.",
                "There are a few good reasons for this assumption.",
                "If we were to assume the opposite, then there would not exist an optimal strategy for the row player in the example game: the row player would play the bottom strategy with probability p = 1/2 + with > 0, and the smaller , the better the utility for the row player.",
                "By contrast, if we assume that the follower always breaks ties in the leaders favor, then an optimal mixed strategy for the leader always exists, and this corresponds to a subgame perfect equilibrium of the extensive-form representation of the leadership situation.",
                "In any case, this is a standard assumption for such models (e.g. [20]), although some work has investigated what can happen in the other subgame perfect equilibria [26]. (For generic two-player games, the leaders subgame-perfect equilibrium payoff is unique.)",
                "Also, the same assumption is typically used in mechanism design, in that it is assumed that if an agent is indifferent between revealing his preferences truthfully and revealing them falsely, he will report them truthfully.",
                "Given this assumption, we can safely refer to optimal leadership strategies rather than having to use some equilibrium notion.",
                "Hence, for the purposes of this paper, an optimal strategy to commit to in a 2-player game is a strategy s ∈ S that maximizes maxt∈BR(s) ul(s, t), where BR(s) = arg maxt∈T uf (s, t). (ul and uf are the leader and followers utility functions, respectively.)",
                "We can have S = S for the case of commitment to pure strategies, or S = ∆(S), the set of probability distributions over S, for the case of commitment to mixed strategies. (We note that replacing T by ∆(T) makes no difference in this definition.)",
                "For games with more than two players, in which the players commit to their strategies in sequence, we define optimal strategies to commit to recursively.",
                "After the leader commits to a strategy, the game to be played by the remaining agents is itself a (smaller) leadership game.",
                "Thus, we define an optimal strategy to commit to as a strategy that maximizes the leaders utility, assuming that the play of the remaining agents is itself optimal under this definition, and maximizes the leaders utility among all optimal ways to play the remaining game.",
                "Again, commitment to mixed strategies may or may not be a possibility for every player (although for the last player it does not matter if we allow for commitment to mixed strategies). 2.2 Commitment to pure strategies We first study how to compute the optimal pure strategy to commit to.",
                "This is relatively simple, because the number of strategies to commit to is not very large. (In the following, #outcomes is the number of complete strategy profiles.)",
                "Theorem 1.",
                "Under commitment to pure strategies, the set of all optimal strategy profiles in a normal-form game can be found in O(#players · #outcomes) time.",
                "Proof.",
                "Each pure strategy that the first player may commit to will induce a subgame for the remaining players.",
                "We can solve each such subgame recursively to find all of its optimal strategy profiles; each of these will give the original leader some utility.",
                "Those that give the leader maximal utility correspond exactly to the optimal strategy profiles of the original game.",
                "We now present the algorithm formally.",
                "Let Su(G, s1) be the subgame that results after the first (remaining) player in G plays s1 ∈ SG 1 .",
                "A game with 0 players is simply an outcome of the game.",
                "The function Append(s, O) appends the strategy s to each of the vectors of strategies in the set O.",
                "Let e be the empty vector with no elements.",
                "In a slight abuse of notation, we will write uG 1 (C) when all strategy profiles in the set C give player 1 the same utility in the game G. (Here, player 1 is the first remaining player in the subgame G, not necessarily player 1 in the original game.)",
                "We note that arg max is set-valued.",
                "Then, the following algorithm computes all optimal strategy profiles: Algorithm Solve(G) if G has 0 players return {e} C ← ∅ for all s1 ∈ SG 1 { O ← Solve(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) if C = ∅ or uG 1 (s1, O ) = uG 1 (C) C ← C∪Append(s1, O ) if uG 1 (s1, O ) > uG 1 (C) C ←Append(s1, O ) } return C Every outcome is (potentially) examined by every player, which leads to the given runtime bound.",
                "As an example of how the algorithm works, consider the following 3-player game, in which the first player chooses the left or right matrix, the second player chooses a row, and the third player chooses a column. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 3,0,0 First we eliminate the outcomes that do not correspond to best responses for the third player (removing them from the matrix): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Next, we remove the entries in which the third player does not break ties in favor of the second player, as well as entries that do not correspond to best responses for the second player. 0,1,1 2,1,1 1,1,1 0,5,1 Finally, we remove the entries in which the second and third players do not break ties in favor of the first player, as well as entries that do not correspond to best responses for the first player. 2,1,1 84 Hence, in optimal play, the first player chooses the left matrix, the second player chooses the middle row, and the third player chooses the left column. (We note that this outcome is Pareto-dominated by (Right, Middle, Left).)",
                "For general normal-form games, each players utility for each of the outcomes has to be explicitly represented in the input, so that the input size is itself Ω(#players · #outcomes).",
                "Therefore, the algorithm is in fact a linear-time algorithm. 2.3 Commitment to mixed strategies In the special case of two-player zero-sum games, computing an optimal mixed strategy for the leader to commit to is equivalent to computing a minimax strategy, which minimizes the maximum expected utility that the opponent can obtain.",
                "Minimax strategies constitute the only natural solution concept for two-player zero-sum games: von Neumanns Minimax Theorem [24] states that in two-player zero-sum games, it does not matter (in terms of the players utilities) which player gets to commit to a mixed strategy first, and a profile of mixed strategies is a <br>nash equilibrium</br> if and only if both strategies are minimax strategies.",
                "It is well-known that a minimax strategy can be found in polynomial time, using linear programming [17].",
                "Our first result in this section generalizes this result, showing that an optimal mixed strategy for the leader to commit to can be efficiently computed in general-sum two-player games, again using linear programming.",
                "Theorem 2.",
                "In 2-player normal-form games, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders utility.",
                "Such a mixed strategy can be computed using the following simple linear program: maximize s∈S psul(s, t) subject to for all t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1 We note that this program may be infeasible for some follower strategies t, for example, if t is a strictly dominated strategy.",
                "Nevertheless, the program must be feasible for at least some follower strategies; among these follower strategies, choose a strategy t∗ that maximizes the linear programs solution value.",
                "Then, if the leader chooses as her mixed strategy the optimal settings of the variables ps for the linear program for t∗ , and the follower plays t∗ , this constitutes an optimal strategy profile.",
                "In the following result, we show that we cannot expect to solve the problem more efficiently than linear programming, because we can reduce any linear program with a probability constraint on its variables to a problem of computing the optimal mixed strategy to commit to in a 2-player normalform game.",
                "Theorem 3.",
                "Any linear program whose variables xi (with xi ∈ R≥0 ) must satsify i xi = 1 can be modeled as a problem of computing the optimal mixed strategy to commit to in a 2-player normal-form game.",
                "Proof.",
                "Let the leader have a pure strategy i for every variable xi.",
                "Let the column player have one pure strategy j for every constraint in the linear program (other than i xi = 1), and a single additional pure strategy 0.",
                "Let the utility functions be as follows.",
                "Writing the objective of the linear program as maximize i cixi, for any i, let ul(i, 0) = ci and uf (i, 0) = 0.",
                "Writing the jth constraint of the linear program (not including i xi = 1) as i aijxi ≤ bj, for any i, j > 0, let ul(i, j) = mini ci − 1 and uf (i, j) = aij − bj.",
                "For example, consider the following linear program. maximize 2x1 + x2 subject to x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 The optimal solution to this program is x1 = 1/3, x2 = 2/3.",
                "Our reduction transforms this program into the following leader-follower game (where the leader is the row player). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 Indeed, the optimal strategy for the leader is to play the top strategy with probability 1/3 and the bottom strategy with probability 2/3.",
                "We now show that the reduction works in general.",
                "Clearly, the leader wants to incentivize the follower to play 0, because the utility that the leader gets when the follower plays 0 is always greater than when the follower does not play 0.",
                "In order for the follower not to prefer playing j > 0 rather than 0, it must be the case that i pl(i)(aij − bj) ≤ 0, or equivalently i pl(i)aij ≤ bj.",
                "Hence the leader will get a utility of at least mini ci if and only if there is a feasible solution to the constraints.",
                "Given that the pl(i) incentivize the follower to play 0, the leader attempts to maximize i pl(i)ci.",
                "Thus the leader must solve the original linear program.",
                "As an alternative proof of Theorem 3, one may observe that it is known that finding a minimax strategy in a zerosum game is as hard as the linear programming problem [6], and as we pointed out at the beginning of this section, computing a minimax strategy in a zero-sum game is a special case of the problem of computing an optimal mixed strategy to commit to.",
                "This polynomial-time solvability of the problem of computing an optimal mixed strategy to commit to in two-player normal-form games contrasts with the unknown complexity of computing a <br>nash equilibrium</br> in such games [21], as well as with the NP-hardness of finding a <br>nash equilibrium</br> with maximum utility for a given player in such games [8, 2].",
                "Unfortunately, this result does not generalize to more than two players-here, the problem becomes NP-hard.",
                "To show this, we reduce from the VERTEX-COVER problem.",
                "Definition 1.",
                "In VERTEX-COVER, we are given a graph G = (V, E) and an integer K. We are asked whether there 85 exists a subset of the vertices S ⊆ V , with |S| = K, such that every edge e ∈ E has at least one of its endpoints in S. BALANCED-VERTEX-COVER is the special case of VERTEX-COVER in which K = |V |/2.",
                "VERTEX-COVER is NP-complete [9].",
                "The following lemma shows that the hardness remains if we require K = |V |/2. (Similar results have been shown for other NP-complete problems.)",
                "Lemma 1.",
                "BALANCED-VERTEX-COVER is NP-complete.",
                "Proof.",
                "Membership in NP follows from the fact that the problem is a special case of VERTEX-COVER, which is in NP.",
                "To show NP-hardness, we reduce an arbitrary VERTEX-COVER instance to a BALANCED-VERTEXCOVER instance, as follows.",
                "If, for the VERTEX-COVER instance, K > |V |/2, then we simply add isolated vertices that are disjoint from the rest of the graph, until K = |V |/2.",
                "If K < |V |/2, we add isolated triangles (that is, the complete graph on three vertices) to the graph, increasing K by 2 every time, until K = |V |/2.",
                "Theorem 4.",
                "In 3-player normal-form games, finding an optimal mixed strategy to commit to is NP-hard.",
                "Proof.",
                "We reduce an arbitrary BALANCED-VERTEXCOVER instance to the following 3-player normal-form game.",
                "For every vertex v, each of the three players has a pure strategy corresponding to that vertex (rv, sv, tv, respectively).",
                "In addition, for every edge e, the third player has a pure strategy te; and finally, the third player has one additional pure strategy t0.",
                "The utilities are as follows: • for all r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • for all r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • for all v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • for all v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • for all v ∈ V , for all r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V | |V |−2 ; • for all e ∈ E, s ∈ S, for both v ∈ e, u3(rv, s, te) = 0; • for all e ∈ E, s ∈ S, for all v /∈ e, u3(rv, s, te) = |V | |V |−2 . • for all r ∈ R, s ∈ S, u3(r, s, t0) = 1.",
                "We note that players 1 and 2 have the same utility function.",
                "We claim that there is an optimal strategy profile in which players 1 and 2 both obtain 1 (their maximum utility) if and only if there is a solution to the BALANCED-VERTEXCOVER problem. (Otherwise, these players will both obtain 0.)",
                "First, suppose there exists a solution to the BALANCEDVERTEX-COVER problem.",
                "Then, let player 1 play every rv such that v is in the cover with probability 2 |V | , and let player 2 play every sv such that v is not in the cover with probability 2 |V | .",
                "Then, for player 3, the expected utility of playing tv (for any v) is (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of 2 |V | that rv or sv is played.",
                "Additionally, the expected utility of playing te (for any e) is at most (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of at least 2 |V | that some rv with v ∈ e is played (because player 1 is randomizing over the pure strategies corresponding to the cover).",
                "It follows that playing t0 is a best response for player 3, giving players 1 and 2 a utility of 1.",
                "Now, suppose that players 1 and 2 obtain 1 in optimal play.",
                "Then, it must be the case that player 3 plays t0.",
                "Hence, for every v ∈ V , there must be a probability of at least 2 |V | that either rv or sv is played, for otherwise player 3 would be better off playing tv.",
                "Because players 1 and 2 have only a total probability of 2 to distribute, it must be the case that for each v, either rv or sv is played with probability 2 |V | , and the other is played with probability 0. (It is not possible for both to have nonzero probability, because then there would be some probability that both are played simultaneously (correlation is not possible), hence the total probability of at least one being played could not be high enough for all vertices.)",
                "Thus, for exactly half the v ∈ V , player 1 places probability 2 |V | on rv.",
                "Moreover, for every e ∈ E, there must be a probability of at least 2 |V | that some rv with v ∈ e is played, for otherwise player 3 would be better off playing te.",
                "Thus, the v ∈ V such that player 1 places probability 2 |V | on rv constitute a balanced vertex cover. 3.",
                "BAYESIAN GAMES So far, we have restricted our attention to normal-form games.",
                "In a normal-form game, it is assumed that every agent knows every other agents preferences over the outcomes of the game.",
                "In general, however, agents may have some private information about their preferences that is not known to the other agents.",
                "Moreover, at the time of commitment to a strategy, the agents may not even know their own (final) preferences over the outcomes of the game yet, because these preferences may be dependent on a context that has yet to materialize.",
                "For example, when the code for a trading agent is written, it may not yet be clear how that agent will value resources that it will negotiate over later, because this depends on information that is not yet available at the time at which the code is written (such as orders that will have been placed to the agent before the negotiation).",
                "In this section, we will study commitment in Bayesian games, which can model such uncertainty over preferences. 3.1 Definitions In a Bayesian game, every player i has a set of actions Si, a set of types Θi with an associated probability distribution πi : Θi → [0, 1], and, for each type θi, a utility function uθi i : S1 × S2 × . . . × Sn → R. A pure strategy in a Bayesian game is a mapping from the players types to actions, σi : Θi → Si. (Bayesian games can be rewritten in normal form by enumerating every pure strategy σi, but this will cause an exponential blowup in the size of the representation of the game and therefore cannot lead to efficient algorithms.)",
                "The strategy that the leader should commit to depends on whether, at the time of commitment, the leader knows her own type.",
                "If the leader does know her own type, the other types that the leader might have had become irrelevant and the leader should simply commit to the strategy that is optimal for the type.",
                "However, as argued above, the leader does not necessarily know her own type at the time of commitment (e.g., the time at which the code is submitted).",
                "In this case, the leader must commit to a strategy that is 86 dependent upon the leaders eventual type.",
                "We will study this latter model, although we will pay specific attention to the case where the leader has only a single type, which is effectively the same as the former model. 3.2 Commitment to pure strategies It turns out that computing an optimal pure strategy to commit to is hard in Bayesian games, even with two players.",
                "Theorem 5.",
                "Finding an optimal pure strategy to commit to in 2-player Bayesian games is NP-hard, even when the follower has only a single type.",
                "Proof.",
                "We reduce an arbitrary VERTEX-COVER instance to the following Bayesian game between the leader and the follower.",
                "The leader has K types θ1, θ2, . . . , θK , each occurring with probability 1/K, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has only a single type; for each edge e ∈ E, the follower has an action te, and the follower has a single additional action t0.",
                "The utility function for the leader is given by, for all θl ∈ Θl and all s ∈ S, u θl l (s, t0) = 1, and for all e ∈ E, u θl l (s, te) = 0.",
                "The followers utility is given by: • For all v ∈ V , for all e ∈ E with v /∈ e, uf (sv, te) = 1; • For all v ∈ V , for all e ∈ E with v ∈ e, uf (sv, te) = −K; • For all v ∈ V , uf (sv, t0) = 0.",
                "We claim that the leader can get a utility of 1 if and only if there is a solution to the VERTEX-COVER instance.",
                "First, suppose that there is a solution to the VERTEXCOVER instance.",
                "Then, the leader can commit to a pure strategy such that for each vertex v in the cover, the leader plays sv for some type.",
                "Then, the followers utility for playing te (for any e ∈ E) is at most K−1 K + 1 K (−K) = − 1 K , so that the follower will prefer to play t0, which gives the leader a utility of 1, as required.",
                "Now, suppose that there is a pure strategy for the leader that will give the leader a utility of 1.",
                "Then, the follower must play t0.",
                "In order for the follower not to prefer playing te (for any e ∈ E) instead, for at least one v ∈ e the leader must play sv for some type θl.",
                "Hence, the set of vertices v that the leader plays for some type must constitute a vertex cover; and this set can have size at most K, because the leader has only K types.",
                "So there is a solution to the VERTEXCOVER instance.",
                "However, if the leader has only a single type, then the problem becomes easy again (#types is the number of types for the follower): Theorem 6.",
                "In 2-player Bayesian games in which the leader has only a single type, an optimal pure strategy to commit to can be found in O(#outcomes · #types) time.",
                "Proof.",
                "For every leader action s, we can compute, for every follower type θf ∈ Θf , which actions t maximize the followers utility; call this set of actions BRθf (s).",
                "Then, the utility that the leader receives for committing to action s can be computed as θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), and the leader can choose the best action to commit to. 3.3 Commitment to mixed strategies In two-player zero-sum imperfect information games with perfect recall (no player ever forgets something that it once knew), a minimax strategy can be constructed in polynomial time [12, 13].",
                "Unfortunately, this result does not extend to computing optimal mixed strategies to commit to in the general-sum case-not even in Bayesian games.",
                "We will exhibit NP-hardness by reducing from the INDEPENDENTSET problem.",
                "Definition 2.",
                "In INDEPENDENT-SET, we are given a graph G = (V, E) and an integer K. We are asked whether there exists a subset of the vertices S ⊆ V , with |S| = K, such that no edge e ∈ E has both of its endpoints in S. Again, this problem is NP-complete [9].",
                "Theorem 7.",
                "Finding an optimal mixed strategy to commit to in 2-player Bayesian games is NP-hard, even when the leader has only a single type and the follower has only two actions.",
                "Proof.",
                "We reduce an arbitrary INDEPENDENT-SET instance to the following Bayesian game between the leader and the follower.",
                "The leader has only a single type, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has a type θv for every v ∈ V , occurring with probability 1 (|E|+1)|V | , and a type θe for every e ∈ E, occurring with probability 1 |E|+1 .",
                "The follower has two actions: t0 and t1.",
                "The leaders utility is given by, for all s ∈ S, ul(s, t0) = 1 and ul(s, t1) = 0.",
                "The followers utility is given by: • For all v ∈ V , uθv f (sv, t1) = 0; • For all v ∈ V and s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • For all v ∈ V and s ∈ S, uθv f (s, t0) = 1; • For all e ∈ E, s ∈ S, uθe f (s, t0) = 1; • For all e ∈ E, for both v ∈ e, uθe f (sv, t1) = 2K 3 ; • For all e ∈ E, for all v /∈ e, uθe f (sv, t1) = 0.",
                "We claim that an optimal strategy to commit to gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | if and only if there is a solution to the INDEPENDENT-SET instance.",
                "First, suppose that there is a solution to the INDEPENDENT-SET instance.",
                "Then, the leader could commit to the following strategy: for every vertex v in the independent set, play the corresponding sv with probability 1/K.",
                "If the follower has type θe for some e ∈ E, the expected utility for the follower of playing t1 is at most 1 K 2K 3 = 2/3, because there is at most one vertex v ∈ e such that sv is played with nonzero probability.",
                "Hence, the follower will play t0 and obtain a utility of 1.",
                "If the follower has type θv for some vertex v in the independent set, the expected utility for the follower of playing t1 is K−1 K K K−1 = 1, because the leader plays sv with probability 1/K.",
                "It follows that the follower (who breaks ties to maximize the leaders utility) will play t0, which also gives a utility of 1 and gives the leader a higher utility.",
                "Hence the leaders expected utility for this strategy is at least |E| |E|+1 + K (|E|+1)|V | , as required. 87 Now, suppose that there is a strategy that gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | .",
                "Then, this strategy must induce the follower to play t0 whenever it has a type of the form θe (because otherwise, the utility could be at most |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ).",
                "Thus, it cannot be the case that for some edge e = (v1, v2) ∈ E, the probability that the leader plays one of sv1 and sv2 is at least 2/K, because then the expected utility for the follower of playing t1 when it has type θe would be at least 2 K 2K 3 = 4/3 > 1.",
                "Moreover, the strategy must induce the follower to play t0 for at least K types of the form θv.",
                "Inducing the follower to play t0 when it has type θv can be done only by playing sv with probability at least 1/K, which will give the follower a utility of at most K−1 K K K−1 = 1 for playing t1.",
                "But then, the set of vertices v such that sv is played with probability at least 1/K must constitute an independent set of size K (because if there were an edge e between two such vertices, it would induce the follower to play t1 for type θe by the above).",
                "By contrast, if the follower has only a single type, then we can generalize the linear programming approach for normalform games: Theorem 8.",
                "In 2-player Bayesian games in which the follower has only a single type, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "We generalize the approach in Theorem 2 as follows.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader for every one of the leaders types such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders ex ante expected utility.",
                "To do so, we generalize the linear program as follows: maximize θl∈Θl π(θl) s∈S pθl s uθl l (s, t) subject to for all t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t ) for all θl ∈ Θl, s∈S p θl s = 1 As in Theorem 2, the solution for the linear program that maximizes the solution value is an optimal strategy to commit to.",
                "This shows an interesting contrast between commitment to pure strategies and commitment to mixed strategies in Bayesian games: for pure strategies, the problem becomes easy if the leader has only a single type (but not if the follower has only a single type), whereas for mixed strategies, the problem becomes easy if the follower has only a single type (but not if the leader has only a single type). 4.",
                "CONCLUSIONS AND FUTURE RESEARCH In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "This requires some equilibrium notion (<br>nash equilibrium</br> and its refinements), and often leads to the equilibrium selection problem: it is unclear to each individual player according to which equilibrium she should play.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "For example, one agent may arrive at the (real or virtual) site of the game before the other, or, in the specific case of software agents, the code for one agent may be completed and committed before that of another agent.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "Specifically, if commitment to mixed strategies is possible, then (optimal) commitment never hurts the leader, and often helps.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we studied how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "For normal-form games, we showed that the optimal pure strategy to commit to can be found efficiently for any number of players.",
                "An optimal mixed strategy to commit to in a normal-form game can be found efficiently for two players using linear programming (and no more efficiently than that, in the sense that any linear program with a probability constraint can be encoded as such a problem). (This is a generalization of the polynomial-time computability of minimax strategies in normal-form games.)",
                "The problem becomes NP-hard for three (or more) players.",
                "In Bayesian games, the problem of finding an optimal pure strategy to commit to is NP-hard even in two-player games in which the follower has only a single type, although two-player games in which the leader has only a single type can be solved efficiently.",
                "The problem of finding an optimal mixed strategy to commit to in a Bayesian game is NP-hard even in two-player games in which the leader has only a single type, although two-player games in which the follower has only a single type can be solved efficiently using a generalization of the linear progamming approach for normal-form games.",
                "The following two tables summarize these results. 2 players ≥ 3 players normal-form O(#outcomes) O(#outcomes· #players) Bayesian, O(#outcomes· NP-hard 1-type leader #types) Bayesian, NP-hard NP-hard 1-type follower Bayesian (general) NP-hard NP-hard Results for commitment to pure strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.) 88 2 players ≥ 3 players normal-form one LP-solve per NP-hard follower action Bayesian, NP-hard NP-hard 1-type leader Bayesian, one LP-solve per NP-hard 1-type follower follower action Bayesian (general) NP-hard NP-hard Results for commitment to mixed strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.)",
                "Future research can take a number of directions.",
                "First, we can empirically evaluate the techniques presented here on test suites such as GAMUT [19].",
                "We can also study the computation of optimal strategies to commit to in other1 concise representations of normal-form games-for example, in graphical games [10] or local-effect/action graph games [14, 1].",
                "For the cases where computing an optimal strategy to commit to is NP-hard, we can also study the computation of approximately optimal strategies to commit to.",
                "While the correct definition of an approximately optimal strategy is in this setting may appear simple at first-it should be a strategy that, if the following players play optimally, performs almost as well as the optimal strategy in expectation-this definition becomes problematic when we consider that the other players may also be playing only approximately optimally.",
                "One may also study models in which multiple (but not all) players commit at the same time.",
                "Another interesting direction to pursue is to see if computing optimal mixed strategies to commit to can help us in, or otherwise shed light on, computing Nash equilibria.",
                "Often, optimal mixed strategies to commit to are also <br>nash equilibrium</br> strategies (for example, in two-player zero-sum games this is always true), although this is not always the case (for example, as we already pointed out, sometimes the optimal strategy to commit to is a strictly dominated strategy, which can never be a <br>nash equilibrium</br> strategy). 5.",
                "REFERENCES [1] N. A. R. Bhat and K. Leyton-Brown.",
                "Computing Nash equilibria of action-graph games.",
                "In Proceedings of the 20th Annual Conference on Uncertainty in Artificial Intelligence (UAI), Banff, Canada, 2004. [2] V. Conitzer and T. Sandholm.",
                "Complexity results about Nash equilibria.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pages 765-771, Acapulco, Mexico, 2003. [3] V. Conitzer and T. Sandholm.",
                "Complexity of (iterated) dominance.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 88-97, Vancouver, Canada, 2005. [4] V. Conitzer and T. Sandholm.",
                "A generalized strategy eliminability criterion and computational methods for applying it.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 483-488, Pittsburgh, PA, USA, 2005. [5] A.",
                "A. Cournot.",
                "Recherches sur les principes math´ematiques de la th´eorie des richesses (Researches 1 Bayesian games are one potentially concise representation of normal-form games. into the Mathematical Principles of the Theory of Wealth).",
                "Hachette, Paris, 1838. [6] G. Dantzig.",
                "A proof of the equivalence of the programming problem and the game problem.",
                "In T. Koopmans, editor, Activity Analysis of Production and Allocation, pages 330-335.",
                "John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel.",
                "The complexity of eliminating dominated strategies.",
                "Mathematics of Operation Research, 18:553-565, 1993. [8] I. Gilboa and E. Zemel.",
                "Nash and correlated equilibria: Some complexity considerations.",
                "Games and Economic Behavior, 1:80-93, 1989. [9] R. Karp.",
                "Reducibility among combinatorial problems.",
                "In R. E. Miller and J. W. Thatcher, editors, Complexity of Computer Computations, pages 85-103.",
                "Plenum Press, NY, 1972. [10] M. Kearns, M. Littman, and S. Singh.",
                "Graphical models for game theory.",
                "In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou, and J. N. Tsitsiklis.",
                "A note on strategy elimination in bimatrix games.",
                "Operations Research Letters, 7(3):103-107, 1988. [12] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [14] K. Leyton-Brown and M. Tennenholtz.",
                "Local-effect games.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), Acapulco, Mexico, 2003. [15] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 36-41, San Diego, CA, 2003. [16] M. Littman and P. Stone.",
                "A polynomial-time <br>nash equilibrium</br> algorithm for repeated games.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 48-54, San Diego, CA, 2003. [17] R. D. Luce and H. Raiffa.",
                "Games and Decisions.",
                "John Wiley and Sons, New York, 1957.",
                "Dover republication 1989. [18] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown, and Y. Shoham.",
                "Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms.",
                "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), New York, NY, USA, 2004. [20] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "MIT Press, 1994. [21] C. Papadimitriou.",
                "Algorithms, games and the Internet.",
                "In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 749-753, 2001. 89 [22] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a <br>nash equilibrium</br>.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 664-669, San Jose, CA, USA, 2004. [23] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 495-501, Pittsburgh, PA, USA, 2005. [24] J. von Neumann.",
                "Zur Theorie der Gesellschaftsspiele.",
                "Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg.",
                "Marktform und Gleichgewicht.",
                "Springer, Vienna, 1934. [26] B. von Stengel and S. Zamir.",
                "Leadership with commitment to mixed strategies.",
                "CDAM Research Report LSE-CDAM-2004-01, London School of Economics, Feb. 2004. 90"
            ],
            "original_annotated_samples": [
                "Given that the game is modeled in normal form, it is typically analyzed using the concept of <br>nash equilibrium</br>.",
                "A <br>nash equilibrium</br> specifies a strategy for each player, such that no player has an incentive to individually deviate from this profile of strategies. (Typically, the strategies are allowed to be mixed, that is, probability distributions over the original (pure) strategies.)",
                "A (mixed-strategy) <br>nash equilibrium</br> is guaranteed to exist in finite games [18], but one problem is that there may be multiple Nash equilibria.",
                "This leads to refinements of <br>nash equilibrium</br> such as subgame perfect and sequential equilibrium.)",
                "A significant amount of research has recently been devoted to the computation of solutions according to various solution concepts for settings in which the agents choose their strategies simultaneously, such as dominance [7, 11, 3] and (especially) <br>nash equilibrium</br> [8, 21, 16, 15, 2, 22, 23, 4]."
            ],
            "translated_annotated_samples": [
                "Dado que el juego está modelado en forma normal, típicamente se analiza utilizando el concepto de <br>equilibrio de Nash</br>.",
                "Un <br>equilibrio de Nash</br> especifica una estrategia para cada jugador, de modo que ningún jugador tenga un incentivo para desviarse individualmente de este perfil de estrategias. (Por lo general, se permite que las estrategias sean mixtas, es decir, distribuciones de probabilidad sobre las estrategias originales (puras).)",
                "Un <br>equilibrio de Nash</br> (de estrategia mixta) está garantizado de existir en juegos finitos [18], pero un problema es que puede haber múltiples equilibrios de Nash.",
                "Esto conduce a refinamientos del <br>equilibrio de Nash</br> como el equilibrio perfecto en subjuegos y el equilibrio secuencial.",
                "Recientemente se ha dedicado una cantidad significativa de investigación al cálculo de soluciones de acuerdo con varios conceptos de solución para escenarios en los que los agentes eligen sus estrategias simultáneamente, como la dominancia [7, 11, 3] y (especialmente) el <br>equilibrio de Nash</br> [8, 21, 16, 15, 2, 22, 23, 4]."
            ],
            "translated_text": "En sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias simultáneamente. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. El reciente aumento en el interés por las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas a comprometerse tanto en el compromiso de estrategias puras como en el compromiso de estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Ofrecemos tanto resultados positivos (algoritmos eficientes) como resultados negativos (resultados de NP-hardness). Categorías y Descriptores de Asignaturas J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas Términos Generales Algoritmos, Economía, Teoría 1. En sistemas multiagentes con agentes auto-interesados (incluyendo la mayoría de los entornos económicos), la acción óptima que un agente debe tomar depende de las acciones que tomen los otros agentes. Para analizar cómo un agente debería comportarse en tales situaciones, es necesario aplicar las herramientas de la teoría de juegos. Normalmente, cuando se modela un escenario estratégico en el marco de la teoría de juegos, se asume que los jugadores eligen sus estrategias de forma simultánea. Esto es especialmente cierto cuando el escenario se modela como un juego en forma normal, que solo especifica la utilidad de cada agente como una función del vector de estrategias que los agentes eligen, y no proporciona información sobre el orden en que los agentes toman sus decisiones y lo que los agentes observan sobre las decisiones anteriores de otros agentes. Dado que el juego está modelado en forma normal, típicamente se analiza utilizando el concepto de <br>equilibrio de Nash</br>. Un <br>equilibrio de Nash</br> especifica una estrategia para cada jugador, de modo que ningún jugador tenga un incentivo para desviarse individualmente de este perfil de estrategias. (Por lo general, se permite que las estrategias sean mixtas, es decir, distribuciones de probabilidad sobre las estrategias originales (puras).) Un <br>equilibrio de Nash</br> (de estrategia mixta) está garantizado de existir en juegos finitos [18], pero un problema es que puede haber múltiples equilibrios de Nash. Esto conduce al problema de selección de equilibrio de cómo un agente puede saber qué estrategia jugar si no sabe qué equilibrio se va a jugar. Cuando el escenario se modela como un juego de forma extensiva, es posible especificar que algunos jugadores reciben información sobre las acciones tomadas por otros antes en el juego antes de decidir su acción. Sin embargo, en general, los jugadores no saben todo lo que sucedió anteriormente en el juego. Por lo tanto, estos juegos suelen ser analizados todavía utilizando un concepto de equilibrio, donde se especifica una estrategia mixta para cada jugador, y se requiere que la estrategia de cada jugador sea una mejor respuesta a las estrategias de los demás. (Normalmente se impone ahora una restricción adicional en las estrategias para garantizar que los jugadores no jueguen de una manera irracional con respecto a la información que han recibido hasta el momento). Esto conduce a refinamientos del <br>equilibrio de Nash</br> como el equilibrio perfecto en subjuegos y el equilibrio secuencial. Sin embargo, en muchos entornos del mundo real, las estrategias no se seleccionan de manera simultánea. A menudo, un jugador (el líder) puede comprometerse con una estrategia antes que otro jugador (el seguidor). Esto puede deberse a una variedad de razones. Por ejemplo, uno de los jugadores puede llegar al lugar donde se jugará el juego antes que otro agente (por ejemplo, en entornos económicos, un jugador puede ingresar al mercado antes y comprometerse con una forma de hacer negocios). Un compromiso tan poderoso tiene un impacto profundo en cómo debería jugarse el juego. Por ejemplo, el líder puede estar mejor jugando una estrategia que esté dominada en la representación de forma normal del juego. Quizás el ejemplo más temprano y conocido del efecto del compromiso es el de von Stackelberg [25], quien demostró que, en el modelo de duopolio de Cournot [5], si una empresa puede comprometerse con una cantidad de producción primero, esa empresa lo hará mucho mejor que en la solución de movimiento simultáneo (Nash). En general, si es posible comprometerse con estrategias mixtas, entonces (bajo suposiciones menores) nunca perjudica, y a menudo ayuda, comprometerse con una estrategia [26]. Verse obligado a comprometerse con una estrategia pura a veces ayuda y a veces perjudica (por ejemplo, comprometerse con una estrategia pura en piedra-papel-tijeras antes de la decisión de los otros jugadores naturalmente resultará en una derrota). En este documento, asumiremos que el compromiso siempre es forzado; si no lo es, el jugador que tiene la opción de comprometerse simplemente puede comparar el resultado del compromiso con el resultado de no comprometerse (movimiento simultáneo). Los modelos de liderazgo son especialmente importantes en entornos con múltiples agentes de software con intereses propios. Una vez que el código de un agente (o de un equipo de agentes) está finalizado y el agente es desplegado, el agente se compromete a jugar la estrategia (posiblemente aleatoria) que el código prescribe. Por lo tanto, siempre y cuando se pueda demostrar de manera creíble que no se puede cambiar el código más tarde, el código funciona como un dispositivo de compromiso. Esto es válido para torneos recreativos entre agentes (por ejemplo, torneos de póker, RoboSoccer) y para aplicaciones industriales como redes de sensores. Finalmente, también existe una situación de liderazgo implícito en el campo del diseño de mecanismos, en la cual un jugador (el diseñador) tiene la oportunidad de elegir las reglas del juego que los demás jugadores luego siguen. El diseño de mecanismos es un tema extremadamente importante para la comunidad de EC: los artículos publicados sobre diseño de mecanismos en las recientes conferencias de EC son demasiados para citar. De hecho, el diseñador del mecanismo puede beneficiarse al comprometerse con una elección que, si las acciones de los agentes (restantes) estuvieran fijas, sería subóptima. Por ejemplo, en una subasta (a precio fijo), el vendedor puede desear establecer un precio de reserva positivo (artificial) para el artículo, por debajo del cual el artículo no se venderá, incluso si el vendedor valora el artículo en 0. En retrospectiva (después de recibir las ofertas), esto (ingenuamente) parece subóptimo: si llegaba una oferta que superaba el precio de reserva, el precio de reserva no tenía efecto, y si no llegaba tal oferta, el vendedor hubiera estado mejor aceptando una oferta más baja. Por supuesto, la razón para establecer el precio de reserva es incentivar a los postores a ofertar más alto, y debido a esto, establecer precios de reserva artificiales puede aumentar realmente los ingresos esperados para el vendedor. Recientemente se ha dedicado una cantidad significativa de investigación al cálculo de soluciones de acuerdo con varios conceptos de solución para escenarios en los que los agentes eligen sus estrategias simultáneamente, como la dominancia [7, 11, 3] y (especialmente) el <br>equilibrio de Nash</br> [8, 21, 16, 15, 2, 22, 23, 4]. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "np-hardness": {
            "translated_key": "dureza np",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Computing the Optimal Strategy to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "We give both positive results (efficient algorithms) and negative results (<br>np-hardness</br> results).",
                "Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent systems with self-interested agents (including most economic settings), the optimal action for one agent to take depends on the actions that the other agents take.",
                "To analyze how an agent should behave in such settings, the tools of game theory need to be applied.",
                "Typically, when a strategic setting is modeled in the framework of game theory, it is assumed that players choose their strategies simultaneously.",
                "This is especially true when the setting is modeled as a normal-form game, which only specifies each agents utility as a function of the vector of strategies that the agents choose, and does not provide any information on the order in which agents make their decisions and what the agents observe about earlier decisions by other agents.",
                "Given that the game is modeled in normal form, it is typically analyzed using the concept of Nash equilibrium.",
                "A Nash equilibrium specifies a strategy for each player, such that no player has an incentive to individually deviate from this profile of strategies. (Typically, the strategies are allowed to be mixed, that is, probability distributions over the original (pure) strategies.)",
                "A (mixed-strategy) Nash equilibrium is guaranteed to exist in finite games [18], but one problem is that there may be multiple Nash equilibria.",
                "This leads to the equilibrium selection problem of how an agent can know which strategy to play if it does not know which equilibrium is to be played.",
                "When the setting is modeled as an extensive-form game, it is possible to specify that some players receive some information about actions taken by others earlier in the game before deciding on their action.",
                "Nevertheless, in general, the players do not know everything that happened earlier in the game.",
                "Because of this, these games are typically still analyzed using an equilibrium concept, where one specifies a mixed strategy for each player, and requires that each players strategy is a best response to the others strategies. (Typically an additional constraint on the strategies is now imposed to ensure that players do not play in a way that is irrational with respect to the information that they have received so far.",
                "This leads to refinements of Nash equilibrium such as subgame perfect and sequential equilibrium.)",
                "However, in many real-world settings, strategies are not selected in such a simultaneous manner.",
                "Oftentimes, one player (the leader) is able to commit to a strategy before another player (the follower).",
                "This can be due to a variety of reasons.",
                "For example, one of the players may arrive at the site at which the game is to be played before another agent (e.g., in economic settings, one player may enter a market earlier and commit to a way of doing busi82 ness).",
                "Such commitment power has a profound impact on how the game should be played.",
                "For example, the leader may be best off playing a strategy that is dominated in the normal-form representation of the game.",
                "Perhaps the earliest and best-known example of the effect of commitment is that by von Stackelberg [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution.",
                "In general, if commitment to mixed strategies is possible, then (under minor assumptions) it never hurts, and often helps, to commit to a strategy [26].",
                "Being forced to commit to a pure strategy sometimes helps, and sometimes hurts (for example, committing to a pure strategy in rock-paper-scissors before the other players decision will naturally result in a loss).",
                "In this paper, we will assume commitment is always forced; if it is not, the player who has the choice of whether to commit can simply compare the commitment outcome to the non-commitment (simultaneous-move) outcome.",
                "Models of leadership are especially important in settings with multiple self-interested software agents.",
                "Once the code for an agent (or for a team of agents) is finalized and the agent is deployed, the agent is committed to playing the (possibly randomized) strategy that the code prescribes.",
                "Thus, as long as one can credibly show that one cannot change the code later, the code serves as a commitment device.",
                "This holds true for recreational tournaments among agents (e.g., poker tournaments, RoboSoccer), and for industrial applications such as sensor webs.",
                "Finally, there is also an implicit leadership situation in the field of mechanism design, in which one player (the designer) gets to choose the rules of the game that the remaining players then play.",
                "Mechanism design is an extremely important topic to the EC community: the papers published on mechanism design in recent EC conferences are too numerous to cite.",
                "Indeed, the mechanism designer may benefit from committing to a choice that, if the (remaining) agents actions were fixed, would be suboptimal.",
                "For example, in a (first-price) auction, the seller may wish to set a positive (artificial) reserve price for the item, below which the item will not be sold-even if the seller values the item at 0.",
                "In hindsight (after the bids have come in), this (na¨ıvely) appears suboptimal: if a bid exceeding the reserve price came in, the reserve price had no effect, and if no such bid came in, the seller would have been better off accepting a lower bid.",
                "Of course, the reason for setting the reserve price is that it incentivizes the bidders to bid higher, and because of this, setting artificial reserve prices can actually increase expected revenue to the seller.",
                "A significant amount of research has recently been devoted to the computation of solutions according to various solution concepts for settings in which the agents choose their strategies simultaneously, such as dominance [7, 11, 3] and (especially) Nash equilibrium [8, 21, 16, 15, 2, 22, 23, 4].",
                "However, the computation of the optimal strategy to commit to in a leadership situation has gone ignored.",
                "Theoretically, leadership situations can simply be thought of as an extensive-form game in which one player chooses a strategy (for the original game) first.",
                "The number of strategies in this extensive-form game, however, can be exceedingly large.",
                "For example, if the leader is able to commit to a mixed strategy in the original game, then every one of the (continuum of) mixed strategies constitutes a pure strategy in the extensive-form representation of the leadership situation. (We note that a commitment to a distribution is not the same as a distribution over commitments.)",
                "Moreover, if the original game is itself an extensive-form game, the number of strategies in the extensive-form representation of the leadership situation (which is a different extensive-form game) becomes even larger.",
                "Because of this, it is usually not computationally feasible to simply transform the original game into the extensive-form representation of the leadership situation; instead, we have to analyze the game in its original representation.",
                "In this paper, we study how to compute the optimal strategy to commit to, both in normal-form games (Section 2) and in Bayesian games, which are a special case of extensiveform games (Section 3). 2.",
                "NORMAL-FORM GAMES In this section, we study how to compute the optimal strategy to commit to for games represented in normal form. 2.1 Definitions In a normal-form game, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a pure strategy for every player, also known as a profile of pure strategies) to a real number.",
                "To ease notation, in the case of two players, we will refer to player 1s pure strategy set as S, and player 2s pure strategy set as T. Such games can be represented in (bi-)matrix form, in which the rows correspond to player 1s pure strategies, the columns correspond to player 2s pure strategies, and the entries of the matrix give the row and column players utilities (in that order) for the corresponding outcome of the game.",
                "In the case of three players, we will use R, S, and T, for player 1, 2, and 3s pure strategies, respectively.",
                "A mixed strategy for a player is a probability distribution over that players pure strategies.",
                "In the case of two-player games, we will refer to player 1 as the leader and player 2 as the follower.",
                "Before defining optimal leadership strategies, consider the following game which illustrates the effect of the leaders ability to commit. 2, 1 4, 0 1, 0 3, 1 In this normal-form representation, the bottom strategy for the row player is strictly dominated by the top strategy.",
                "Nevertheless, if the row player has the ability to commit to a pure strategy before the column player chooses his strategy, the row player should commit to the bottom strategy: doing so will make the column player prefer to play the right strategy, leading to a utility of 3 for the row player.",
                "By contrast, if the row player were to commit to the top strategy, the column player would prefer to play the left strategy, leading to a utility of only 2 for the row player.",
                "If the row player is able to commit to a mixed strategy, then she can get an even greater (expected) utility: if the row player commits to placing probability p > 1/2 on the bottom strategy, then the column player will still prefer to play the right strategy, and the row players expected utility will be 3p + 4(1 − p) = 4 − p ≥ 3.",
                "If the row player plays each strategy with probability exactly 1/2, the column player is 83 indifferent between the strategies.",
                "In such cases, we will assume that the column player will choose the strategy that maximizes the row players utility (in this case, the right strategy).",
                "Hence, the optimal mixed strategy to commit to for the row player is p = 1/2.",
                "There are a few good reasons for this assumption.",
                "If we were to assume the opposite, then there would not exist an optimal strategy for the row player in the example game: the row player would play the bottom strategy with probability p = 1/2 + with > 0, and the smaller , the better the utility for the row player.",
                "By contrast, if we assume that the follower always breaks ties in the leaders favor, then an optimal mixed strategy for the leader always exists, and this corresponds to a subgame perfect equilibrium of the extensive-form representation of the leadership situation.",
                "In any case, this is a standard assumption for such models (e.g. [20]), although some work has investigated what can happen in the other subgame perfect equilibria [26]. (For generic two-player games, the leaders subgame-perfect equilibrium payoff is unique.)",
                "Also, the same assumption is typically used in mechanism design, in that it is assumed that if an agent is indifferent between revealing his preferences truthfully and revealing them falsely, he will report them truthfully.",
                "Given this assumption, we can safely refer to optimal leadership strategies rather than having to use some equilibrium notion.",
                "Hence, for the purposes of this paper, an optimal strategy to commit to in a 2-player game is a strategy s ∈ S that maximizes maxt∈BR(s) ul(s, t), where BR(s) = arg maxt∈T uf (s, t). (ul and uf are the leader and followers utility functions, respectively.)",
                "We can have S = S for the case of commitment to pure strategies, or S = ∆(S), the set of probability distributions over S, for the case of commitment to mixed strategies. (We note that replacing T by ∆(T) makes no difference in this definition.)",
                "For games with more than two players, in which the players commit to their strategies in sequence, we define optimal strategies to commit to recursively.",
                "After the leader commits to a strategy, the game to be played by the remaining agents is itself a (smaller) leadership game.",
                "Thus, we define an optimal strategy to commit to as a strategy that maximizes the leaders utility, assuming that the play of the remaining agents is itself optimal under this definition, and maximizes the leaders utility among all optimal ways to play the remaining game.",
                "Again, commitment to mixed strategies may or may not be a possibility for every player (although for the last player it does not matter if we allow for commitment to mixed strategies). 2.2 Commitment to pure strategies We first study how to compute the optimal pure strategy to commit to.",
                "This is relatively simple, because the number of strategies to commit to is not very large. (In the following, #outcomes is the number of complete strategy profiles.)",
                "Theorem 1.",
                "Under commitment to pure strategies, the set of all optimal strategy profiles in a normal-form game can be found in O(#players · #outcomes) time.",
                "Proof.",
                "Each pure strategy that the first player may commit to will induce a subgame for the remaining players.",
                "We can solve each such subgame recursively to find all of its optimal strategy profiles; each of these will give the original leader some utility.",
                "Those that give the leader maximal utility correspond exactly to the optimal strategy profiles of the original game.",
                "We now present the algorithm formally.",
                "Let Su(G, s1) be the subgame that results after the first (remaining) player in G plays s1 ∈ SG 1 .",
                "A game with 0 players is simply an outcome of the game.",
                "The function Append(s, O) appends the strategy s to each of the vectors of strategies in the set O.",
                "Let e be the empty vector with no elements.",
                "In a slight abuse of notation, we will write uG 1 (C) when all strategy profiles in the set C give player 1 the same utility in the game G. (Here, player 1 is the first remaining player in the subgame G, not necessarily player 1 in the original game.)",
                "We note that arg max is set-valued.",
                "Then, the following algorithm computes all optimal strategy profiles: Algorithm Solve(G) if G has 0 players return {e} C ← ∅ for all s1 ∈ SG 1 { O ← Solve(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) if C = ∅ or uG 1 (s1, O ) = uG 1 (C) C ← C∪Append(s1, O ) if uG 1 (s1, O ) > uG 1 (C) C ←Append(s1, O ) } return C Every outcome is (potentially) examined by every player, which leads to the given runtime bound.",
                "As an example of how the algorithm works, consider the following 3-player game, in which the first player chooses the left or right matrix, the second player chooses a row, and the third player chooses a column. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 3,0,0 First we eliminate the outcomes that do not correspond to best responses for the third player (removing them from the matrix): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Next, we remove the entries in which the third player does not break ties in favor of the second player, as well as entries that do not correspond to best responses for the second player. 0,1,1 2,1,1 1,1,1 0,5,1 Finally, we remove the entries in which the second and third players do not break ties in favor of the first player, as well as entries that do not correspond to best responses for the first player. 2,1,1 84 Hence, in optimal play, the first player chooses the left matrix, the second player chooses the middle row, and the third player chooses the left column. (We note that this outcome is Pareto-dominated by (Right, Middle, Left).)",
                "For general normal-form games, each players utility for each of the outcomes has to be explicitly represented in the input, so that the input size is itself Ω(#players · #outcomes).",
                "Therefore, the algorithm is in fact a linear-time algorithm. 2.3 Commitment to mixed strategies In the special case of two-player zero-sum games, computing an optimal mixed strategy for the leader to commit to is equivalent to computing a minimax strategy, which minimizes the maximum expected utility that the opponent can obtain.",
                "Minimax strategies constitute the only natural solution concept for two-player zero-sum games: von Neumanns Minimax Theorem [24] states that in two-player zero-sum games, it does not matter (in terms of the players utilities) which player gets to commit to a mixed strategy first, and a profile of mixed strategies is a Nash equilibrium if and only if both strategies are minimax strategies.",
                "It is well-known that a minimax strategy can be found in polynomial time, using linear programming [17].",
                "Our first result in this section generalizes this result, showing that an optimal mixed strategy for the leader to commit to can be efficiently computed in general-sum two-player games, again using linear programming.",
                "Theorem 2.",
                "In 2-player normal-form games, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders utility.",
                "Such a mixed strategy can be computed using the following simple linear program: maximize s∈S psul(s, t) subject to for all t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1 We note that this program may be infeasible for some follower strategies t, for example, if t is a strictly dominated strategy.",
                "Nevertheless, the program must be feasible for at least some follower strategies; among these follower strategies, choose a strategy t∗ that maximizes the linear programs solution value.",
                "Then, if the leader chooses as her mixed strategy the optimal settings of the variables ps for the linear program for t∗ , and the follower plays t∗ , this constitutes an optimal strategy profile.",
                "In the following result, we show that we cannot expect to solve the problem more efficiently than linear programming, because we can reduce any linear program with a probability constraint on its variables to a problem of computing the optimal mixed strategy to commit to in a 2-player normalform game.",
                "Theorem 3.",
                "Any linear program whose variables xi (with xi ∈ R≥0 ) must satsify i xi = 1 can be modeled as a problem of computing the optimal mixed strategy to commit to in a 2-player normal-form game.",
                "Proof.",
                "Let the leader have a pure strategy i for every variable xi.",
                "Let the column player have one pure strategy j for every constraint in the linear program (other than i xi = 1), and a single additional pure strategy 0.",
                "Let the utility functions be as follows.",
                "Writing the objective of the linear program as maximize i cixi, for any i, let ul(i, 0) = ci and uf (i, 0) = 0.",
                "Writing the jth constraint of the linear program (not including i xi = 1) as i aijxi ≤ bj, for any i, j > 0, let ul(i, j) = mini ci − 1 and uf (i, j) = aij − bj.",
                "For example, consider the following linear program. maximize 2x1 + x2 subject to x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 The optimal solution to this program is x1 = 1/3, x2 = 2/3.",
                "Our reduction transforms this program into the following leader-follower game (where the leader is the row player). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 Indeed, the optimal strategy for the leader is to play the top strategy with probability 1/3 and the bottom strategy with probability 2/3.",
                "We now show that the reduction works in general.",
                "Clearly, the leader wants to incentivize the follower to play 0, because the utility that the leader gets when the follower plays 0 is always greater than when the follower does not play 0.",
                "In order for the follower not to prefer playing j > 0 rather than 0, it must be the case that i pl(i)(aij − bj) ≤ 0, or equivalently i pl(i)aij ≤ bj.",
                "Hence the leader will get a utility of at least mini ci if and only if there is a feasible solution to the constraints.",
                "Given that the pl(i) incentivize the follower to play 0, the leader attempts to maximize i pl(i)ci.",
                "Thus the leader must solve the original linear program.",
                "As an alternative proof of Theorem 3, one may observe that it is known that finding a minimax strategy in a zerosum game is as hard as the linear programming problem [6], and as we pointed out at the beginning of this section, computing a minimax strategy in a zero-sum game is a special case of the problem of computing an optimal mixed strategy to commit to.",
                "This polynomial-time solvability of the problem of computing an optimal mixed strategy to commit to in two-player normal-form games contrasts with the unknown complexity of computing a Nash equilibrium in such games [21], as well as with the <br>np-hardness</br> of finding a Nash equilibrium with maximum utility for a given player in such games [8, 2].",
                "Unfortunately, this result does not generalize to more than two players-here, the problem becomes NP-hard.",
                "To show this, we reduce from the VERTEX-COVER problem.",
                "Definition 1.",
                "In VERTEX-COVER, we are given a graph G = (V, E) and an integer K. We are asked whether there 85 exists a subset of the vertices S ⊆ V , with |S| = K, such that every edge e ∈ E has at least one of its endpoints in S. BALANCED-VERTEX-COVER is the special case of VERTEX-COVER in which K = |V |/2.",
                "VERTEX-COVER is NP-complete [9].",
                "The following lemma shows that the hardness remains if we require K = |V |/2. (Similar results have been shown for other NP-complete problems.)",
                "Lemma 1.",
                "BALANCED-VERTEX-COVER is NP-complete.",
                "Proof.",
                "Membership in NP follows from the fact that the problem is a special case of VERTEX-COVER, which is in NP.",
                "To show <br>np-hardness</br>, we reduce an arbitrary VERTEX-COVER instance to a BALANCED-VERTEXCOVER instance, as follows.",
                "If, for the VERTEX-COVER instance, K > |V |/2, then we simply add isolated vertices that are disjoint from the rest of the graph, until K = |V |/2.",
                "If K < |V |/2, we add isolated triangles (that is, the complete graph on three vertices) to the graph, increasing K by 2 every time, until K = |V |/2.",
                "Theorem 4.",
                "In 3-player normal-form games, finding an optimal mixed strategy to commit to is NP-hard.",
                "Proof.",
                "We reduce an arbitrary BALANCED-VERTEXCOVER instance to the following 3-player normal-form game.",
                "For every vertex v, each of the three players has a pure strategy corresponding to that vertex (rv, sv, tv, respectively).",
                "In addition, for every edge e, the third player has a pure strategy te; and finally, the third player has one additional pure strategy t0.",
                "The utilities are as follows: • for all r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • for all r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • for all v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • for all v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • for all v ∈ V , for all r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V | |V |−2 ; • for all e ∈ E, s ∈ S, for both v ∈ e, u3(rv, s, te) = 0; • for all e ∈ E, s ∈ S, for all v /∈ e, u3(rv, s, te) = |V | |V |−2 . • for all r ∈ R, s ∈ S, u3(r, s, t0) = 1.",
                "We note that players 1 and 2 have the same utility function.",
                "We claim that there is an optimal strategy profile in which players 1 and 2 both obtain 1 (their maximum utility) if and only if there is a solution to the BALANCED-VERTEXCOVER problem. (Otherwise, these players will both obtain 0.)",
                "First, suppose there exists a solution to the BALANCEDVERTEX-COVER problem.",
                "Then, let player 1 play every rv such that v is in the cover with probability 2 |V | , and let player 2 play every sv such that v is not in the cover with probability 2 |V | .",
                "Then, for player 3, the expected utility of playing tv (for any v) is (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of 2 |V | that rv or sv is played.",
                "Additionally, the expected utility of playing te (for any e) is at most (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of at least 2 |V | that some rv with v ∈ e is played (because player 1 is randomizing over the pure strategies corresponding to the cover).",
                "It follows that playing t0 is a best response for player 3, giving players 1 and 2 a utility of 1.",
                "Now, suppose that players 1 and 2 obtain 1 in optimal play.",
                "Then, it must be the case that player 3 plays t0.",
                "Hence, for every v ∈ V , there must be a probability of at least 2 |V | that either rv or sv is played, for otherwise player 3 would be better off playing tv.",
                "Because players 1 and 2 have only a total probability of 2 to distribute, it must be the case that for each v, either rv or sv is played with probability 2 |V | , and the other is played with probability 0. (It is not possible for both to have nonzero probability, because then there would be some probability that both are played simultaneously (correlation is not possible), hence the total probability of at least one being played could not be high enough for all vertices.)",
                "Thus, for exactly half the v ∈ V , player 1 places probability 2 |V | on rv.",
                "Moreover, for every e ∈ E, there must be a probability of at least 2 |V | that some rv with v ∈ e is played, for otherwise player 3 would be better off playing te.",
                "Thus, the v ∈ V such that player 1 places probability 2 |V | on rv constitute a balanced vertex cover. 3.",
                "BAYESIAN GAMES So far, we have restricted our attention to normal-form games.",
                "In a normal-form game, it is assumed that every agent knows every other agents preferences over the outcomes of the game.",
                "In general, however, agents may have some private information about their preferences that is not known to the other agents.",
                "Moreover, at the time of commitment to a strategy, the agents may not even know their own (final) preferences over the outcomes of the game yet, because these preferences may be dependent on a context that has yet to materialize.",
                "For example, when the code for a trading agent is written, it may not yet be clear how that agent will value resources that it will negotiate over later, because this depends on information that is not yet available at the time at which the code is written (such as orders that will have been placed to the agent before the negotiation).",
                "In this section, we will study commitment in Bayesian games, which can model such uncertainty over preferences. 3.1 Definitions In a Bayesian game, every player i has a set of actions Si, a set of types Θi with an associated probability distribution πi : Θi → [0, 1], and, for each type θi, a utility function uθi i : S1 × S2 × . . . × Sn → R. A pure strategy in a Bayesian game is a mapping from the players types to actions, σi : Θi → Si. (Bayesian games can be rewritten in normal form by enumerating every pure strategy σi, but this will cause an exponential blowup in the size of the representation of the game and therefore cannot lead to efficient algorithms.)",
                "The strategy that the leader should commit to depends on whether, at the time of commitment, the leader knows her own type.",
                "If the leader does know her own type, the other types that the leader might have had become irrelevant and the leader should simply commit to the strategy that is optimal for the type.",
                "However, as argued above, the leader does not necessarily know her own type at the time of commitment (e.g., the time at which the code is submitted).",
                "In this case, the leader must commit to a strategy that is 86 dependent upon the leaders eventual type.",
                "We will study this latter model, although we will pay specific attention to the case where the leader has only a single type, which is effectively the same as the former model. 3.2 Commitment to pure strategies It turns out that computing an optimal pure strategy to commit to is hard in Bayesian games, even with two players.",
                "Theorem 5.",
                "Finding an optimal pure strategy to commit to in 2-player Bayesian games is NP-hard, even when the follower has only a single type.",
                "Proof.",
                "We reduce an arbitrary VERTEX-COVER instance to the following Bayesian game between the leader and the follower.",
                "The leader has K types θ1, θ2, . . . , θK , each occurring with probability 1/K, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has only a single type; for each edge e ∈ E, the follower has an action te, and the follower has a single additional action t0.",
                "The utility function for the leader is given by, for all θl ∈ Θl and all s ∈ S, u θl l (s, t0) = 1, and for all e ∈ E, u θl l (s, te) = 0.",
                "The followers utility is given by: • For all v ∈ V , for all e ∈ E with v /∈ e, uf (sv, te) = 1; • For all v ∈ V , for all e ∈ E with v ∈ e, uf (sv, te) = −K; • For all v ∈ V , uf (sv, t0) = 0.",
                "We claim that the leader can get a utility of 1 if and only if there is a solution to the VERTEX-COVER instance.",
                "First, suppose that there is a solution to the VERTEXCOVER instance.",
                "Then, the leader can commit to a pure strategy such that for each vertex v in the cover, the leader plays sv for some type.",
                "Then, the followers utility for playing te (for any e ∈ E) is at most K−1 K + 1 K (−K) = − 1 K , so that the follower will prefer to play t0, which gives the leader a utility of 1, as required.",
                "Now, suppose that there is a pure strategy for the leader that will give the leader a utility of 1.",
                "Then, the follower must play t0.",
                "In order for the follower not to prefer playing te (for any e ∈ E) instead, for at least one v ∈ e the leader must play sv for some type θl.",
                "Hence, the set of vertices v that the leader plays for some type must constitute a vertex cover; and this set can have size at most K, because the leader has only K types.",
                "So there is a solution to the VERTEXCOVER instance.",
                "However, if the leader has only a single type, then the problem becomes easy again (#types is the number of types for the follower): Theorem 6.",
                "In 2-player Bayesian games in which the leader has only a single type, an optimal pure strategy to commit to can be found in O(#outcomes · #types) time.",
                "Proof.",
                "For every leader action s, we can compute, for every follower type θf ∈ Θf , which actions t maximize the followers utility; call this set of actions BRθf (s).",
                "Then, the utility that the leader receives for committing to action s can be computed as θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), and the leader can choose the best action to commit to. 3.3 Commitment to mixed strategies In two-player zero-sum imperfect information games with perfect recall (no player ever forgets something that it once knew), a minimax strategy can be constructed in polynomial time [12, 13].",
                "Unfortunately, this result does not extend to computing optimal mixed strategies to commit to in the general-sum case-not even in Bayesian games.",
                "We will exhibit <br>np-hardness</br> by reducing from the INDEPENDENTSET problem.",
                "Definition 2.",
                "In INDEPENDENT-SET, we are given a graph G = (V, E) and an integer K. We are asked whether there exists a subset of the vertices S ⊆ V , with |S| = K, such that no edge e ∈ E has both of its endpoints in S. Again, this problem is NP-complete [9].",
                "Theorem 7.",
                "Finding an optimal mixed strategy to commit to in 2-player Bayesian games is NP-hard, even when the leader has only a single type and the follower has only two actions.",
                "Proof.",
                "We reduce an arbitrary INDEPENDENT-SET instance to the following Bayesian game between the leader and the follower.",
                "The leader has only a single type, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has a type θv for every v ∈ V , occurring with probability 1 (|E|+1)|V | , and a type θe for every e ∈ E, occurring with probability 1 |E|+1 .",
                "The follower has two actions: t0 and t1.",
                "The leaders utility is given by, for all s ∈ S, ul(s, t0) = 1 and ul(s, t1) = 0.",
                "The followers utility is given by: • For all v ∈ V , uθv f (sv, t1) = 0; • For all v ∈ V and s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • For all v ∈ V and s ∈ S, uθv f (s, t0) = 1; • For all e ∈ E, s ∈ S, uθe f (s, t0) = 1; • For all e ∈ E, for both v ∈ e, uθe f (sv, t1) = 2K 3 ; • For all e ∈ E, for all v /∈ e, uθe f (sv, t1) = 0.",
                "We claim that an optimal strategy to commit to gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | if and only if there is a solution to the INDEPENDENT-SET instance.",
                "First, suppose that there is a solution to the INDEPENDENT-SET instance.",
                "Then, the leader could commit to the following strategy: for every vertex v in the independent set, play the corresponding sv with probability 1/K.",
                "If the follower has type θe for some e ∈ E, the expected utility for the follower of playing t1 is at most 1 K 2K 3 = 2/3, because there is at most one vertex v ∈ e such that sv is played with nonzero probability.",
                "Hence, the follower will play t0 and obtain a utility of 1.",
                "If the follower has type θv for some vertex v in the independent set, the expected utility for the follower of playing t1 is K−1 K K K−1 = 1, because the leader plays sv with probability 1/K.",
                "It follows that the follower (who breaks ties to maximize the leaders utility) will play t0, which also gives a utility of 1 and gives the leader a higher utility.",
                "Hence the leaders expected utility for this strategy is at least |E| |E|+1 + K (|E|+1)|V | , as required. 87 Now, suppose that there is a strategy that gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | .",
                "Then, this strategy must induce the follower to play t0 whenever it has a type of the form θe (because otherwise, the utility could be at most |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ).",
                "Thus, it cannot be the case that for some edge e = (v1, v2) ∈ E, the probability that the leader plays one of sv1 and sv2 is at least 2/K, because then the expected utility for the follower of playing t1 when it has type θe would be at least 2 K 2K 3 = 4/3 > 1.",
                "Moreover, the strategy must induce the follower to play t0 for at least K types of the form θv.",
                "Inducing the follower to play t0 when it has type θv can be done only by playing sv with probability at least 1/K, which will give the follower a utility of at most K−1 K K K−1 = 1 for playing t1.",
                "But then, the set of vertices v such that sv is played with probability at least 1/K must constitute an independent set of size K (because if there were an edge e between two such vertices, it would induce the follower to play t1 for type θe by the above).",
                "By contrast, if the follower has only a single type, then we can generalize the linear programming approach for normalform games: Theorem 8.",
                "In 2-player Bayesian games in which the follower has only a single type, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "We generalize the approach in Theorem 2 as follows.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader for every one of the leaders types such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders ex ante expected utility.",
                "To do so, we generalize the linear program as follows: maximize θl∈Θl π(θl) s∈S pθl s uθl l (s, t) subject to for all t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t ) for all θl ∈ Θl, s∈S p θl s = 1 As in Theorem 2, the solution for the linear program that maximizes the solution value is an optimal strategy to commit to.",
                "This shows an interesting contrast between commitment to pure strategies and commitment to mixed strategies in Bayesian games: for pure strategies, the problem becomes easy if the leader has only a single type (but not if the follower has only a single type), whereas for mixed strategies, the problem becomes easy if the follower has only a single type (but not if the leader has only a single type). 4.",
                "CONCLUSIONS AND FUTURE RESEARCH In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "This requires some equilibrium notion (Nash equilibrium and its refinements), and often leads to the equilibrium selection problem: it is unclear to each individual player according to which equilibrium she should play.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "For example, one agent may arrive at the (real or virtual) site of the game before the other, or, in the specific case of software agents, the code for one agent may be completed and committed before that of another agent.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "Specifically, if commitment to mixed strategies is possible, then (optimal) commitment never hurts the leader, and often helps.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we studied how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "For normal-form games, we showed that the optimal pure strategy to commit to can be found efficiently for any number of players.",
                "An optimal mixed strategy to commit to in a normal-form game can be found efficiently for two players using linear programming (and no more efficiently than that, in the sense that any linear program with a probability constraint can be encoded as such a problem). (This is a generalization of the polynomial-time computability of minimax strategies in normal-form games.)",
                "The problem becomes NP-hard for three (or more) players.",
                "In Bayesian games, the problem of finding an optimal pure strategy to commit to is NP-hard even in two-player games in which the follower has only a single type, although two-player games in which the leader has only a single type can be solved efficiently.",
                "The problem of finding an optimal mixed strategy to commit to in a Bayesian game is NP-hard even in two-player games in which the leader has only a single type, although two-player games in which the follower has only a single type can be solved efficiently using a generalization of the linear progamming approach for normal-form games.",
                "The following two tables summarize these results. 2 players ≥ 3 players normal-form O(#outcomes) O(#outcomes· #players) Bayesian, O(#outcomes· NP-hard 1-type leader #types) Bayesian, NP-hard NP-hard 1-type follower Bayesian (general) NP-hard NP-hard Results for commitment to pure strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.) 88 2 players ≥ 3 players normal-form one LP-solve per NP-hard follower action Bayesian, NP-hard NP-hard 1-type leader Bayesian, one LP-solve per NP-hard 1-type follower follower action Bayesian (general) NP-hard NP-hard Results for commitment to mixed strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.)",
                "Future research can take a number of directions.",
                "First, we can empirically evaluate the techniques presented here on test suites such as GAMUT [19].",
                "We can also study the computation of optimal strategies to commit to in other1 concise representations of normal-form games-for example, in graphical games [10] or local-effect/action graph games [14, 1].",
                "For the cases where computing an optimal strategy to commit to is NP-hard, we can also study the computation of approximately optimal strategies to commit to.",
                "While the correct definition of an approximately optimal strategy is in this setting may appear simple at first-it should be a strategy that, if the following players play optimally, performs almost as well as the optimal strategy in expectation-this definition becomes problematic when we consider that the other players may also be playing only approximately optimally.",
                "One may also study models in which multiple (but not all) players commit at the same time.",
                "Another interesting direction to pursue is to see if computing optimal mixed strategies to commit to can help us in, or otherwise shed light on, computing Nash equilibria.",
                "Often, optimal mixed strategies to commit to are also Nash equilibrium strategies (for example, in two-player zero-sum games this is always true), although this is not always the case (for example, as we already pointed out, sometimes the optimal strategy to commit to is a strictly dominated strategy, which can never be a Nash equilibrium strategy). 5.",
                "REFERENCES [1] N. A. R. Bhat and K. Leyton-Brown.",
                "Computing Nash equilibria of action-graph games.",
                "In Proceedings of the 20th Annual Conference on Uncertainty in Artificial Intelligence (UAI), Banff, Canada, 2004. [2] V. Conitzer and T. Sandholm.",
                "Complexity results about Nash equilibria.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pages 765-771, Acapulco, Mexico, 2003. [3] V. Conitzer and T. Sandholm.",
                "Complexity of (iterated) dominance.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 88-97, Vancouver, Canada, 2005. [4] V. Conitzer and T. Sandholm.",
                "A generalized strategy eliminability criterion and computational methods for applying it.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 483-488, Pittsburgh, PA, USA, 2005. [5] A.",
                "A. Cournot.",
                "Recherches sur les principes math´ematiques de la th´eorie des richesses (Researches 1 Bayesian games are one potentially concise representation of normal-form games. into the Mathematical Principles of the Theory of Wealth).",
                "Hachette, Paris, 1838. [6] G. Dantzig.",
                "A proof of the equivalence of the programming problem and the game problem.",
                "In T. Koopmans, editor, Activity Analysis of Production and Allocation, pages 330-335.",
                "John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel.",
                "The complexity of eliminating dominated strategies.",
                "Mathematics of Operation Research, 18:553-565, 1993. [8] I. Gilboa and E. Zemel.",
                "Nash and correlated equilibria: Some complexity considerations.",
                "Games and Economic Behavior, 1:80-93, 1989. [9] R. Karp.",
                "Reducibility among combinatorial problems.",
                "In R. E. Miller and J. W. Thatcher, editors, Complexity of Computer Computations, pages 85-103.",
                "Plenum Press, NY, 1972. [10] M. Kearns, M. Littman, and S. Singh.",
                "Graphical models for game theory.",
                "In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou, and J. N. Tsitsiklis.",
                "A note on strategy elimination in bimatrix games.",
                "Operations Research Letters, 7(3):103-107, 1988. [12] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [14] K. Leyton-Brown and M. Tennenholtz.",
                "Local-effect games.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), Acapulco, Mexico, 2003. [15] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 36-41, San Diego, CA, 2003. [16] M. Littman and P. Stone.",
                "A polynomial-time Nash equilibrium algorithm for repeated games.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 48-54, San Diego, CA, 2003. [17] R. D. Luce and H. Raiffa.",
                "Games and Decisions.",
                "John Wiley and Sons, New York, 1957.",
                "Dover republication 1989. [18] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown, and Y. Shoham.",
                "Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms.",
                "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), New York, NY, USA, 2004. [20] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "MIT Press, 1994. [21] C. Papadimitriou.",
                "Algorithms, games and the Internet.",
                "In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 749-753, 2001. 89 [22] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 664-669, San Jose, CA, USA, 2004. [23] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 495-501, Pittsburgh, PA, USA, 2005. [24] J. von Neumann.",
                "Zur Theorie der Gesellschaftsspiele.",
                "Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg.",
                "Marktform und Gleichgewicht.",
                "Springer, Vienna, 1934. [26] B. von Stengel and S. Zamir.",
                "Leadership with commitment to mixed strategies.",
                "CDAM Research Report LSE-CDAM-2004-01, London School of Economics, Feb. 2004. 90"
            ],
            "original_annotated_samples": [
                "We give both positive results (efficient algorithms) and negative results (<br>np-hardness</br> results).",
                "This polynomial-time solvability of the problem of computing an optimal mixed strategy to commit to in two-player normal-form games contrasts with the unknown complexity of computing a Nash equilibrium in such games [21], as well as with the <br>np-hardness</br> of finding a Nash equilibrium with maximum utility for a given player in such games [8, 2].",
                "To show <br>np-hardness</br>, we reduce an arbitrary VERTEX-COVER instance to a BALANCED-VERTEXCOVER instance, as follows.",
                "We will exhibit <br>np-hardness</br> by reducing from the INDEPENDENTSET problem."
            ],
            "translated_annotated_samples": [
                "Ofrecemos tanto resultados positivos (algoritmos eficientes) como resultados negativos (resultados de <br>NP-hardness</br>).",
                "La solubilidad en tiempo polinómico del problema de calcular una estrategia mixta óptima a la que comprometerse en juegos de forma normal de dos jugadores contrasta con la complejidad desconocida de calcular un equilibrio de Nash en tales juegos [21], así como con la <br>NP-dificultad</br> de encontrar un equilibrio de Nash con utilidad máxima para un jugador dado en tales juegos [8, 2].",
                "Para demostrar la <br>NP-dificultad</br>, reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES a una instancia de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO, de la siguiente manera.",
                "Demostraremos la <br>NP-dificultad</br> reduciendo desde el problema de CONJUNTOINDEPENDIENTE."
            ],
            "translated_text": "En sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias simultáneamente. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. El reciente aumento en el interés por las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas a comprometerse tanto en el compromiso de estrategias puras como en el compromiso de estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Ofrecemos tanto resultados positivos (algoritmos eficientes) como resultados negativos (resultados de <br>NP-hardness</br>). Categorías y Descriptores de Asignaturas J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas Términos Generales Algoritmos, Economía, Teoría 1. En sistemas multiagentes con agentes auto-interesados (incluyendo la mayoría de los entornos económicos), la acción óptima que un agente debe tomar depende de las acciones que tomen los otros agentes. Para analizar cómo un agente debería comportarse en tales situaciones, es necesario aplicar las herramientas de la teoría de juegos. Normalmente, cuando se modela un escenario estratégico en el marco de la teoría de juegos, se asume que los jugadores eligen sus estrategias de forma simultánea. Esto es especialmente cierto cuando el escenario se modela como un juego en forma normal, que solo especifica la utilidad de cada agente como una función del vector de estrategias que los agentes eligen, y no proporciona información sobre el orden en que los agentes toman sus decisiones y lo que los agentes observan sobre las decisiones anteriores de otros agentes. Dado que el juego está modelado en forma normal, típicamente se analiza utilizando el concepto de equilibrio de Nash. Un equilibrio de Nash especifica una estrategia para cada jugador, de modo que ningún jugador tenga un incentivo para desviarse individualmente de este perfil de estrategias. (Por lo general, se permite que las estrategias sean mixtas, es decir, distribuciones de probabilidad sobre las estrategias originales (puras).) Un equilibrio de Nash (de estrategia mixta) está garantizado de existir en juegos finitos [18], pero un problema es que puede haber múltiples equilibrios de Nash. Esto conduce al problema de selección de equilibrio de cómo un agente puede saber qué estrategia jugar si no sabe qué equilibrio se va a jugar. Cuando el escenario se modela como un juego de forma extensiva, es posible especificar que algunos jugadores reciben información sobre las acciones tomadas por otros antes en el juego antes de decidir su acción. Sin embargo, en general, los jugadores no saben todo lo que sucedió anteriormente en el juego. Por lo tanto, estos juegos suelen ser analizados todavía utilizando un concepto de equilibrio, donde se especifica una estrategia mixta para cada jugador, y se requiere que la estrategia de cada jugador sea una mejor respuesta a las estrategias de los demás. (Normalmente se impone ahora una restricción adicional en las estrategias para garantizar que los jugadores no jueguen de una manera irracional con respecto a la información que han recibido hasta el momento). Esto conduce a refinamientos del equilibrio de Nash como el equilibrio perfecto en subjuegos y el equilibrio secuencial. Sin embargo, en muchos entornos del mundo real, las estrategias no se seleccionan de manera simultánea. A menudo, un jugador (el líder) puede comprometerse con una estrategia antes que otro jugador (el seguidor). Esto puede deberse a una variedad de razones. Por ejemplo, uno de los jugadores puede llegar al lugar donde se jugará el juego antes que otro agente (por ejemplo, en entornos económicos, un jugador puede ingresar al mercado antes y comprometerse con una forma de hacer negocios). Un compromiso tan poderoso tiene un impacto profundo en cómo debería jugarse el juego. Por ejemplo, el líder puede estar mejor jugando una estrategia que esté dominada en la representación de forma normal del juego. Quizás el ejemplo más temprano y conocido del efecto del compromiso es el de von Stackelberg [25], quien demostró que, en el modelo de duopolio de Cournot [5], si una empresa puede comprometerse con una cantidad de producción primero, esa empresa lo hará mucho mejor que en la solución de movimiento simultáneo (Nash). En general, si es posible comprometerse con estrategias mixtas, entonces (bajo suposiciones menores) nunca perjudica, y a menudo ayuda, comprometerse con una estrategia [26]. Verse obligado a comprometerse con una estrategia pura a veces ayuda y a veces perjudica (por ejemplo, comprometerse con una estrategia pura en piedra-papel-tijeras antes de la decisión de los otros jugadores naturalmente resultará en una derrota). En este documento, asumiremos que el compromiso siempre es forzado; si no lo es, el jugador que tiene la opción de comprometerse simplemente puede comparar el resultado del compromiso con el resultado de no comprometerse (movimiento simultáneo). Los modelos de liderazgo son especialmente importantes en entornos con múltiples agentes de software con intereses propios. Una vez que el código de un agente (o de un equipo de agentes) está finalizado y el agente es desplegado, el agente se compromete a jugar la estrategia (posiblemente aleatoria) que el código prescribe. Por lo tanto, siempre y cuando se pueda demostrar de manera creíble que no se puede cambiar el código más tarde, el código funciona como un dispositivo de compromiso. Esto es válido para torneos recreativos entre agentes (por ejemplo, torneos de póker, RoboSoccer) y para aplicaciones industriales como redes de sensores. Finalmente, también existe una situación de liderazgo implícito en el campo del diseño de mecanismos, en la cual un jugador (el diseñador) tiene la oportunidad de elegir las reglas del juego que los demás jugadores luego siguen. El diseño de mecanismos es un tema extremadamente importante para la comunidad de EC: los artículos publicados sobre diseño de mecanismos en las recientes conferencias de EC son demasiados para citar. De hecho, el diseñador del mecanismo puede beneficiarse al comprometerse con una elección que, si las acciones de los agentes (restantes) estuvieran fijas, sería subóptima. Por ejemplo, en una subasta (a precio fijo), el vendedor puede desear establecer un precio de reserva positivo (artificial) para el artículo, por debajo del cual el artículo no se venderá, incluso si el vendedor valora el artículo en 0. En retrospectiva (después de recibir las ofertas), esto (ingenuamente) parece subóptimo: si llegaba una oferta que superaba el precio de reserva, el precio de reserva no tenía efecto, y si no llegaba tal oferta, el vendedor hubiera estado mejor aceptando una oferta más baja. Por supuesto, la razón para establecer el precio de reserva es incentivar a los postores a ofertar más alto, y debido a esto, establecer precios de reserva artificiales puede aumentar realmente los ingresos esperados para el vendedor. Recientemente se ha dedicado una cantidad significativa de investigación al cálculo de soluciones de acuerdo con varios conceptos de solución para escenarios en los que los agentes eligen sus estrategias simultáneamente, como la dominancia [7, 11, 3] y (especialmente) el equilibrio de Nash [8, 21, 16, 15, 2, 22, 23, 4]. Sin embargo, se ha ignorado el cálculo de la estrategia óptima a comprometerse en una situación de liderazgo. Teóricamente, las situaciones de liderazgo simplemente pueden ser consideradas como un juego de forma extensiva en el que un jugador elige una estrategia (para el juego original) primero. El número de estrategias en este juego de forma extensiva, sin embargo, puede ser extremadamente grande. Por ejemplo, si el líder es capaz de comprometerse con una estrategia mixta en el juego original, entonces cada una de las estrategias mixtas (continuo de) constituye una estrategia pura en la representación de forma extensiva de la situación de liderazgo. (Se destaca que un compromiso con una distribución no es lo mismo que una distribución sobre compromisos). Además, si el juego original es en sí mismo un juego de forma extensiva, el número de estrategias en la representación de forma extensiva de la situación de liderazgo (que es un juego de forma extensiva diferente) se vuelve aún más grande. Por lo tanto, generalmente no es factible computacionalmente simplemente transformar el juego original en la representación de forma extensiva de la situación de liderazgo; en su lugar, debemos analizar el juego en su representación original. En este artículo, estudiamos cómo calcular la estrategia óptima a comprometerse, tanto en juegos de forma normal (Sección 2) como en juegos bayesianos, que son un caso especial de juegos de forma extensiva (Sección 3). JUEGOS EN FORMA NORMAL En esta sección, estudiamos cómo calcular la estrategia óptima a comprometerse para juegos representados en forma normal. 2.1 Definiciones En un juego en forma normal, cada jugador i ∈ {1, . . . , n} tiene un conjunto de estrategias puras (o acciones) Si, y una función de utilidad ui : S1×S2×. . .×Sn → R que mapea cada resultado (un vector que consiste en una estrategia pura para cada jugador, también conocido como un perfil de estrategias puras) a un número real. Para facilitar la notación, en el caso de dos jugadores, nos referiremos al conjunto de estrategias puras del jugador 1 como S, y al conjunto de estrategias puras del jugador 2 como T. Estos juegos pueden representarse en forma de matriz (bi-matriz), en la que las filas corresponden a las estrategias puras del jugador 1, las columnas corresponden a las estrategias puras del jugador 2, y las entradas de la matriz dan las utilidades de los jugadores de fila y columna (en ese orden) para el resultado correspondiente del juego. En el caso de tres jugadores, usaremos R, S y T, para las estrategias puras de los jugadores 1, 2 y 3, respectivamente. Una estrategia mixta para un jugador es una distribución de probabilidad sobre las estrategias puras de ese jugador. En el caso de juegos de dos jugadores, nos referiremos al jugador 1 como el líder y al jugador 2 como el seguidor. Antes de definir estrategias de liderazgo óptimas, considera el siguiente juego que ilustra el efecto de la capacidad del líder para comprometerse. 2, 1 4, 0 1, 0 3, 1 En esta representación en forma normal, la estrategia inferior para el jugador de la fila está estrictamente dominada por la estrategia superior. Sin embargo, si el jugador de la fila tiene la capacidad de comprometerse con una estrategia pura antes de que el jugador de la columna elija su estrategia, el jugador de la fila debería comprometerse con la estrategia inferior: al hacerlo, el jugador de la columna preferirá jugar la estrategia correcta, lo que llevará a una utilidad de 3 para el jugador de la fila. Por el contrario, si el jugador de la fila se comprometiera con la estrategia superior, el jugador de la columna preferiría jugar la estrategia izquierda, lo que llevaría a una utilidad de solo 2 para el jugador de la fila. Si el jugador de la fila puede comprometerse a una estrategia mixta, entonces puede obtener una utilidad aún mayor (esperada): si el jugador de la fila se compromete a colocar una probabilidad p > 1/2 en la estrategia inferior, entonces el jugador de la columna seguirá prefiriendo jugar la estrategia derecha, y la utilidad esperada de los jugadores de la fila será 3p + 4(1 − p) = 4 − p ≥ 3. Si el jugador de la fila juega cada estrategia con una probabilidad exacta de 1/2, el jugador de la columna está 83 indiferente entre las estrategias. En tales casos, asumiremos que el jugador de la columna elegirá la estrategia que maximiza la utilidad de los jugadores de la fila (en este caso, la estrategia correcta). Por lo tanto, la estrategia mixta óptima a la que debe comprometerse el jugador de la fila es p = 1/2. Hay algunas buenas razones para esta suposición. Si asumiéramos lo contrario, entonces no existiría una estrategia óptima para el jugador de la fila en el juego de ejemplo: el jugador de la fila jugaría la estrategia inferior con una probabilidad p = 1/2 + con > 0, y cuanto menor sea , mejor será la utilidad para el jugador de la fila. Por el contrario, si asumimos que el seguidor siempre rompe los empates a favor de los líderes, entonces siempre existe una estrategia mixta óptima para el líder, lo que corresponde a un equilibrio perfecto en subjuegos de la representación en forma extensiva de la situación de liderazgo. En cualquier caso, esta es una suposición estándar para tales modelos (por ejemplo, [20]), aunque algunos trabajos han investigado lo que puede suceder en los otros equilibrios perfectos de subjuego [26]. (Para juegos genéricos de dos jugadores, el pago del equilibrio perfecto de subjuego de los líderes es único). Además, la misma suposición se utiliza típicamente en el diseño de mecanismos, asumiendo que si un agente es indiferente entre revelar sus preferencias de manera veraz o falsa, las reportará de manera veraz. Dado este supuesto, podemos hacer referencia de manera segura a estrategias de liderazgo óptimas en lugar de tener que utilizar alguna noción de equilibrio. Por lo tanto, para los propósitos de este documento, una estrategia óptima a comprometerse en un juego de 2 jugadores es una estrategia s ∈ S que maximiza maxt∈BR(s) ul(s, t), donde BR(s) = arg maxt∈T uf (s, t). (ul y uf son las funciones de utilidad del líder y los seguidores, respectivamente). Podemos tener S = S para el caso de compromiso con estrategias puras, o S = ∆(S), el conjunto de distribuciones de probabilidad sobre S, para el caso de compromiso con estrategias mixtas. (Observamos que reemplazar T por ∆(T) no hace ninguna diferencia en esta definición). Para juegos con más de dos jugadores, en los que los jugadores se comprometen con sus estrategias en secuencia, definimos estrategias óptimas a las que comprometerse de forma recursiva. Después de que el líder se compromete con una estrategia, el juego que jugarán los agentes restantes es en sí mismo un juego de liderazgo (más pequeño). Por lo tanto, definimos una estrategia óptima a comprometerse como una estrategia que maximiza la utilidad del líder, asumiendo que el juego de los agentes restantes es óptimo bajo esta definición, y maximiza la utilidad del líder entre todas las formas óptimas de jugar el juego restante. Nuevamente, el compromiso con estrategias mixtas puede o no ser una posibilidad para cada jugador (aunque para el último jugador no importa si permitimos el compromiso con estrategias mixtas). 2.2 Compromiso con estrategias puras. Primero estudiamos cómo calcular la estrategia pura óptima a la que comprometerse. Esto es relativamente simple, porque el número de estrategias a comprometer no es muy grande. (En lo siguiente, #resultados es el número de perfiles de estrategia completos). Teorema 1. Bajo el compromiso de estrategias puras, el conjunto de todos los perfiles de estrategia óptimos en un juego en forma normal se puede encontrar en tiempo O(#jugadores · #resultados). Prueba. Cada estrategia pura a la que el primer jugador pueda comprometerse inducirá un subjuego para los jugadores restantes. Podemos resolver cada subjuego de esta manera de forma recursiva para encontrar todos sus perfiles de estrategia óptimos; cada uno de estos le dará al líder original cierta utilidad. Aquellos que proporcionan al líder la utilidad máxima corresponden exactamente a los perfiles de estrategia óptimos del juego original. Ahora presentamos el algoritmo de forma formal. Sea Su(G, s1) el subjuego que resulta después de que el primer jugador restante en G juega s1 ∈ SG 1. Un juego con 0 jugadores es simplemente un resultado del juego. La función Append(s, O) añade la estrategia s a cada uno de los vectores de estrategias en el conjunto O. Sea e el vector vacío sin elementos. En un ligero abuso de notación, escribiremos uG 1 (C) cuando todos los perfiles estratégicos en el conjunto C le den al jugador 1 la misma utilidad en el juego G. (Aquí, el jugador 1 es el primer jugador restante en el subjuego G, no necesariamente el jugador 1 en el juego original). Observamos que arg max es un conjunto de valores. Entonces, el siguiente algoritmo calcula todos los perfiles de estrategia óptimos: Algoritmo Resolver(G) si G tiene 0 jugadores, devuelve {e} C ← ∅ para todo s1 ∈ SG 1 { O ← Resolver(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) si C = ∅ o uG 1 (s1, O ) = uG 1 (C) C ← C∪Agregar(s1, O ) si uG 1 (s1, O ) > uG 1 (C) C ←Agregar(s1, O ) } devuelve C Cada resultado es examinado (potencialmente) por cada jugador, lo que lleva al límite de tiempo dado. Como ejemplo de cómo funciona el algoritmo, considera el siguiente juego de 3 jugadores, en el que el primer jugador elige la matriz izquierda o derecha, el segundo jugador elige una fila y el tercer jugador elige una columna. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 Primero eliminamos los resultados que no corresponden a las mejores respuestas para el tercer jugador (eliminándolos de la matriz): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Luego, eliminamos las entradas en las que el tercer jugador no resuelve los empates a favor del segundo jugador, así como las entradas que no corresponden a las mejores respuestas para el segundo jugador. 0,1,1 2,1,1 1,1,1 0,5,1 Finalmente, eliminamos las entradas en las que el segundo y tercer jugador no resuelven los empates a favor del primer jugador, así como las entradas que no corresponden a las mejores respuestas para el primer jugador. 2,1,1 Por lo tanto, en el juego óptimo, el primer jugador elige la matriz izquierda, el segundo jugador elige la fila del medio y el tercer jugador elige la columna izquierda. (Notamos que este resultado está dominado por Pareto por (Derecha, Medio, Izquierda).) Para juegos en forma normal general, la utilidad de cada jugador para cada uno de los resultados debe representarse explícitamente en la entrada, de modo que el tamaño de la entrada sea en sí mismo Ω(#jugadores · #resultados). Por lo tanto, el algoritmo es de hecho un algoritmo de tiempo lineal. 2.3 Compromiso con estrategias mixtas En el caso especial de juegos de dos jugadores de suma cero, calcular una estrategia mixta óptima para que el líder se comprometa es equivalente a calcular una estrategia minimax, que minimiza la utilidad esperada máxima que el oponente puede obtener. Las estrategias minimax constituyen el único concepto de solución natural para juegos de suma cero de dos jugadores: el Teorema Minimax de von Neumann [24] establece que en juegos de suma cero de dos jugadores, no importa (en términos de las utilidades de los jugadores) qué jugador se compromete primero a una estrategia mixta, y un perfil de estrategias mixtas es un equilibrio de Nash si y solo si ambas estrategias son estrategias minimax. Es bien sabido que una estrategia minimax se puede encontrar en tiempo polinómico, utilizando programación lineal [17]. Nuestro primer resultado en esta sección generaliza este resultado, mostrando que una estrategia mixta óptima para que el líder se comprometa puede ser calculada eficientemente en juegos de dos jugadores de suma general, nuevamente utilizando programación lineal. Teorema 2. En juegos de forma normal de 2 jugadores, una estrategia mixta óptima a la que comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal. Prueba. Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder de modo que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad del líder. Un programa lineal simple puede calcular una estrategia mixta como la siguiente: maximizar s∈S psul(s, t) sujeto a que para todo t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1. Se destaca que este programa puede ser inviable para algunas estrategias seguidoras t, por ejemplo, si t es una estrategia estrictamente dominada. Sin embargo, el programa debe ser factible para al menos algunas estrategias seguidoras; entre estas estrategias seguidoras, elige una estrategia t∗ que maximice el valor de la solución de los programas lineales. Entonces, si la líder elige como su estrategia mixta los ajustes óptimos de las variables ps para el programa lineal para t∗, y el seguidor juega t∗, esto constituye un perfil de estrategia óptimo. En el siguiente resultado, demostramos que no podemos esperar resolver el problema de manera más eficiente que la programación lineal, ya que podemos reducir cualquier programa lineal con una restricción de probabilidad en sus variables a un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores. Teorema 3. Cualquier programa lineal cuyas variables xi (con xi ∈ R≥0) deben satisfacer i xi = 1 puede ser modelado como un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores. Prueba. Que el líder tenga una estrategia pura i para cada variable xi. Que el jugador de la columna tenga una estrategia pura j para cada restricción en el programa lineal (distinta de i xi = 1), y una única estrategia pura adicional 0. Que las funciones de utilidad sean las siguientes. Escribiendo el objetivo del programa lineal como maximizar ci xi, para cualquier i, dejando ul(i, 0) = ci y uf(i, 0) = 0. Escribiendo la j-ésima restricción del programa lineal (sin incluir i xi = 1) como i aijxi ≤ bj, para cualquier i, j > 0, sea ul(i, j) = mini ci − 1 y uf(i, j) = aij − bj. Por ejemplo, considera el siguiente programa lineal. maximizar 2x1 + x2 sujeto a x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 La solución óptima de este programa es x1 = 1/3, x2 = 2/3. Nuestra reducción transforma este programa en el siguiente juego de líder-seguidor (donde el líder es el jugador de la fila). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 De hecho, la estrategia óptima para el líder es jugar la estrategia superior con una probabilidad de 1/3 y la estrategia inferior con una probabilidad de 2/3. Ahora demostramos que la reducción funciona en general. Claramente, el líder quiere incentivar al seguidor a jugar 0, porque la utilidad que el líder obtiene cuando el seguidor juega 0 siempre es mayor que cuando el seguidor no juega 0. Para que el seguidor no prefiera jugar j > 0 en lugar de 0, debe ser el caso que i pl(i)(aij − bj) ≤ 0, o equivalentemente i pl(i)aij ≤ bj. Por lo tanto, el líder obtendrá una utilidad de al menos mini ci si y solo si hay una solución factible a las restricciones. Dado que el pl(i) incentiva al seguidor a jugar 0, el líder intenta maximizar i pl(i)ci. Por lo tanto, el líder debe resolver el programa lineal original. Como prueba alternativa del Teorema 3, se puede observar que se sabe que encontrar una estrategia minimax en un juego de suma cero es tan difícil como el problema de programación lineal [6], y como señalamos al principio de esta sección, calcular una estrategia minimax en un juego de suma cero es un caso especial del problema de calcular una estrategia mixta óptima a la que comprometerse. La solubilidad en tiempo polinómico del problema de calcular una estrategia mixta óptima a la que comprometerse en juegos de forma normal de dos jugadores contrasta con la complejidad desconocida de calcular un equilibrio de Nash en tales juegos [21], así como con la <br>NP-dificultad</br> de encontrar un equilibrio de Nash con utilidad máxima para un jugador dado en tales juegos [8, 2]. Desafortunadamente, este resultado no se generaliza a más de dos jugadores; aquí, el problema se vuelve NP-duro. Para demostrar esto, reducimos desde el problema de CUBRIR-VÉRTICES. Definición 1. En VERTEX-COVER, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que cada arista e ∈ E tenga al menos uno de sus extremos en S. BALANCED-VERTEX-COVER es el caso especial de VERTEX-COVER en el que K = |V|/2. VERTEX-COVER es NP-completo [9]. El siguiente lema muestra que la dificultad persiste si requerimos K = |V|/2. (Resultados similares se han demostrado para otros problemas NP-completos). Lema 1. El problema de la COBERTURA DE VÉRTICES EQUILIBRADA es NP-completo. Prueba. La pertenencia a NP se deriva del hecho de que el problema es un caso especial de CUBRIMIENTO DE VÉRTICES, que está en NP. Para demostrar la <br>NP-dificultad</br>, reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES a una instancia de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO, de la siguiente manera. Si, para la instancia de CUBRIMIENTO DE VÉRTICES, K > |V|/2, simplemente agregamos vértices aislados que estén disjuntos del resto del grafo, hasta que K = |V|/2. Si K < |V|/2, agregamos triángulos aislados (es decir, el grafo completo de tres vértices) al grafo, aumentando K en 2 cada vez, hasta que K = |V|/2. Teorema 4. En juegos de forma normal de 3 jugadores, encontrar una estrategia mixta óptima a la que comprometerse es NP-difícil. Prueba. Reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO al siguiente juego de forma normal de 3 jugadores. Para cada vértice v, cada uno de los tres jugadores tiene una estrategia pura correspondiente a ese vértice (rv, sv, tv, respectivamente). Además, para cada arista e, el tercer jugador tiene una estrategia pura te; y finalmente, el tercer jugador tiene una estrategia pura adicional t0. Los servicios son los siguientes: • para todo r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • para todo r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • para todo v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • para todo v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • para todo v ∈ V, para todo r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V| |V|−2; • para todo e ∈ E, s ∈ S, para ambos v ∈ e, u3(rv, s, te) = 0; • para todo e ∈ E, s ∈ S, para todo v /∈ e, u3(rv, s, te) = |V| |V|−2. • para todo r ∈ R, s ∈ S, u3(r, s, t0) = 1. Observamos que los jugadores 1 y 2 tienen la misma función de utilidad. Sostenemos que existe un perfil de estrategia óptimo en el que los jugadores 1 y 2 obtienen ambos 1 (su utilidad máxima) si y solo si hay una solución al problema de la COBERTURA DE VÉRTICES EQUILIBRADA. (De lo contrario, estos jugadores obtendrán ambos 0). Primero, supongamos que existe una solución al problema de la cubierta de vértices balanceada. Entonces, deja que el jugador 1 juegue cada rv de manera que v esté en la cobertura con probabilidad 2 |V|, y deja que el jugador 2 juegue cada sv de manera que v no esté en la cobertura con probabilidad 2 |V|. Entonces, para el jugador 3, la utilidad esperada de jugar tv (para cualquier v) es (1 − 2 |V|) |V| |V|−2 = 1, porque hay una probabilidad de 2 |V| de que se juegue rv o sv. Además, la utilidad esperada de jugar te (para cualquier e) es a lo sumo (1 − 2 |V | ) |V | |V |−2 = 1, porque hay una probabilidad de al menos 2 |V | de que algún rv con v ∈ e se juegue (debido a que el jugador 1 está aleatorizando sobre las estrategias puras correspondientes a la cobertura). Se deduce que jugar t0 es la mejor respuesta para el jugador 3, otorgando a los jugadores 1 y 2 una utilidad de 1. Ahora, supongamos que los jugadores 1 y 2 obtienen 1 en el juego óptimo. Entonces, debe ser el caso de que el jugador 3 juegue t0. Por lo tanto, para cada v ∈ V, debe haber una probabilidad de al menos 2 |V| de que se juegue rv o sv, de lo contrario, al jugador 3 le convendría más jugar tv. Dado que los jugadores 1 y 2 solo tienen una probabilidad total de 2 para distribuir, debe ser el caso que para cada v, ya sea rv o sv se juegue con una probabilidad de 2 |V|, y el otro se juegue con una probabilidad de 0. (No es posible que ambos tengan una probabilidad distinta de cero, porque entonces habría alguna probabilidad de que ambos se jugaran simultáneamente (la correlación no es posible), por lo tanto, la probabilidad total de que al menos uno se juegue no podría ser lo suficientemente alta para todos los vértices). Por lo tanto, para exactamente la mitad de los v ∈ V, el jugador 1 coloca una probabilidad de 2 |V| en rv. Además, para cada e ∈ E, debe haber una probabilidad de al menos 2 |V | de que se juegue algún rv con v ∈ e, de lo contrario, al jugador 3 le convendría más jugar te. Por lo tanto, el v ∈ V tal que el jugador 1 coloca una probabilidad de 2 |V | en rv constituye una cubierta de vértices equilibrada. 3. Juegos bayesianos. Hasta ahora, hemos restringido nuestra atención a los juegos en forma normal. En un juego en forma normal, se asume que cada agente conoce las preferencias de todos los demás agentes sobre los resultados del juego. En general, sin embargo, los agentes pueden tener información privada sobre sus preferencias que no es conocida por los otros agentes. Además, en el momento de comprometerse con una estrategia, los agentes pueden ni siquiera conocer sus propias preferencias (finales) sobre los resultados del juego aún, ya que estas preferencias pueden depender de un contexto que aún no se ha materializado. Por ejemplo, cuando se escribe el código para un agente de negociación, puede que aún no esté claro cómo ese agente valorará los recursos sobre los que negociará más adelante, porque esto depende de información que aún no está disponible en el momento en que se escribe el código (como órdenes que habrán sido colocadas al agente antes de la negociación). En esta sección, estudiaremos el compromiso en juegos bayesianos, los cuales pueden modelar tal incertidumbre sobre preferencias. 3.1 Definiciones En un juego bayesiano, cada jugador i tiene un conjunto de acciones Si, un conjunto de tipos Θi con una distribución de probabilidad asociada πi : Θi → [0, 1], y, para cada tipo θi, una función de utilidad uθi i : S1 × S2 × . . . × Sn → R. Una estrategia pura en un juego bayesiano es una asignación de los tipos de los jugadores a acciones, σi : Θi → Si. (Los juegos bayesianos pueden ser reescritos en forma normal enumerando cada estrategia pura σi, pero esto causará un crecimiento exponencial en el tamaño de la representación del juego y por lo tanto no puede llevar a algoritmos eficientes). La estrategia a la que el líder debería comprometerse depende de si, en el momento del compromiso, el líder conoce su propio tipo. Si la líder conoce su propio tipo, los otros tipos que la líder podría haber tenido se vuelven irrelevantes y la líder simplemente debería comprometerse con la estrategia que sea óptima para ese tipo. Sin embargo, como se argumentó anteriormente, la líder no necesariamente conoce su propio tipo en el momento de comprometerse (por ejemplo, en el momento en que se envía el código). En este caso, el líder debe comprometerse con una estrategia que dependa en un 86% del tipo eventual del líder. Estudiaremos este último modelo, aunque prestaremos atención específica al caso en el que el líder tiene un solo tipo, lo cual es efectivamente lo mismo que el modelo anterior. 3.2 Compromiso con estrategias puras Resulta que calcular una estrategia pura óptima a la que comprometerse es difícil en juegos bayesianos, incluso con dos jugadores. Teorema 5. Encontrar una estrategia pura óptima a comprometerse en juegos bayesianos de 2 jugadores es NP-difícil, incluso cuando el seguidor tiene solo un tipo. Prueba. Reducimos una instancia arbitraria de CUBRIMIENTO DE VÉRTICES al siguiente juego bayesiano entre el líder y el seguidor. El líder tiene K tipos θ1, θ2, . . . , θK, cada uno ocurriendo con probabilidad 1/K, y para cada vértice v ∈ V, el líder tiene una acción sv. El seguidor tiene solo un tipo; para cada borde e ∈ E, el seguidor tiene una acción te, y el seguidor tiene una acción adicional única t0. La función de utilidad para el líder está dada por, para todo θl ∈ Θl y todo s ∈ S, u θl l (s, t0) = 1, y para todo e ∈ E, u θl l (s, te) = 0. La utilidad de los seguidores se da por: • Para todo v ∈ V, para todo e ∈ E con v /∈ e, uf (sv, te) = 1; • Para todo v ∈ V, para todo e ∈ E con v ∈ e, uf (sv, te) = −K; • Para todo v ∈ V, uf (sv, t0) = 0. Sostenemos que el líder puede obtener una utilidad de 1 si y solo si hay una solución para la instancia de CUBRIMIENTO-DE-VÉRTICES. Primero, supongamos que hay una solución para la instancia de CUBRIRVÉRTICES. Entonces, el líder puede comprometerse con una estrategia pura tal que para cada vértice v en la cobertura, el líder juega sv para algún tipo. Entonces, la utilidad de los seguidores para jugar te (para cualquier e ∈ E) es a lo sumo K−1 K + 1 K (−K) = − 1 K , por lo que el seguidor preferirá jugar t0, lo que le da al líder una utilidad de 1, como se requiere. Ahora, supongamos que hay una estrategia pura para el líder que le dará al líder una utilidad de 1. Entonces, el seguidor debe jugar t0. Para que el seguidor no prefiera jugar te (para cualquier e ∈ E) en su lugar, al menos para un v ∈ e, el líder debe jugar sv para algún tipo θl. Por lo tanto, el conjunto de vértices v que el líder juega para algún tipo debe constituir una cubierta de vértices; y este conjunto puede tener un tamaño de como máximo K, ya que el líder solo tiene K tipos. Entonces hay una solución para la instancia de CUBRIMIENTODEVÉRTICES. Sin embargo, si el líder tiene solo un tipo, entonces el problema se vuelve fácil nuevamente (#tipos es el número de tipos para el seguidor): Teorema 6. En juegos bayesianos de 2 jugadores en los que el líder tiene solo un tipo, una estrategia pura óptima a comprometerse puede encontrarse en tiempo O(#resultados · #tipos). Prueba. Para cada acción de líder s, podemos calcular, para cada tipo de seguidor θf ∈ Θf, qué acciones t maximizan la utilidad de los seguidores; llamamos a este conjunto de acciones BRθf (s). Entonces, la utilidad que recibe el líder por comprometerse a la acción s se puede calcular como θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), y el líder puede elegir la mejor acción a la que comprometerse. 3.3 Compromiso con estrategias mixtas En juegos de información imperfecta de suma cero de dos jugadores con memoria perfecta (ningún jugador olvida algo que una vez supo), una estrategia minimax se puede construir en tiempo polinómico [12, 13]. Desafortunadamente, este resultado no se extiende a calcular estrategias mixtas óptimas a comprometerse en el caso de suma general, ni siquiera en juegos bayesianos. Demostraremos la <br>NP-dificultad</br> reduciendo desde el problema de CONJUNTOINDEPENDIENTE. Definición 2. En INDEPENDENT-SET, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que ninguna arista e ∈ E tenga ambos extremos en S. Nuevamente, este problema es NP-completo [9]. Teorema 7. Encontrar una estrategia mixta óptima a comprometerse en juegos bayesianos de 2 jugadores es NP-duro, incluso cuando el líder tiene solo un tipo y el seguidor tiene solo dos acciones. Prueba. Reducimos una instancia arbitraria de CONJUNTO-INDEPENDIENTE al siguiente juego bayesiano entre el líder y el seguidor. El líder tiene solo un tipo, y para cada vértice v ∈ V, el líder tiene una acción sv. El seguidor tiene un tipo θv para cada v ∈ V, que ocurre con una probabilidad de 1 (|E|+1)|V|, y un tipo θe para cada e ∈ E, que ocurre con una probabilidad de 1 |E|+1. El seguidor tiene dos acciones: t0 y t1. La utilidad de los líderes se da por, para todo s ∈ S, ul(s, t0) = 1 y ul(s, t1) = 0. La utilidad de los seguidores se da por: • Para todo v ∈ V, uθv f (sv, t1) = 0; • Para todo v ∈ V y s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • Para todo v ∈ V y s ∈ S, uθv f (s, t0) = 1; • Para todo e ∈ E, s ∈ S, uθe f (s, t0) = 1; • Para todo e ∈ E, para ambos v ∈ e, uθe f (sv, t1) = 2K 3 ; • Para todo e ∈ E, para todo v /∈ e, uθe f (sv, t1) = 0. Sostenemos que una estrategia óptima a comprometerse le otorga al líder una utilidad esperada de al menos |E| |E|+1 + K (|E|+1)|V | si y solo si hay una solución para la instancia de CONJUNTO-INDEPENDIENTE. Primero, supongamos que hay una solución para la instancia de CONJUNTO-INDEPENDIENTE. Entonces, el líder podría comprometerse con la siguiente estrategia: por cada vértice v en el conjunto independiente, jugar el correspondiente sv con una probabilidad de 1/K. Si el seguidor tiene el tipo θe para algún e ∈ E, la utilidad esperada para el seguidor al jugar t1 es a lo sumo 1 K 2K 3 = 2/3, porque hay a lo sumo un vértice v ∈ e tal que sv se juega con probabilidad distinta de cero. Por lo tanto, el seguidor jugará t0 y obtendrá una utilidad de 1. Si el seguidor tiene el tipo θv para algún vértice v en el conjunto independiente, la utilidad esperada para el seguidor al jugar t1 es K−1 K K K−1 = 1, porque el líder juega sv con probabilidad 1/K. Se deduce que el seguidor (quien rompe los empates para maximizar la utilidad de los líderes) jugará t0, lo que también otorga una utilidad de 1 y brinda al líder una mayor utilidad. Por lo tanto, la utilidad esperada de los líderes para esta estrategia es al menos |E| |E|+1 + K (|E|+1)|V |, como se requiere. Ahora, supongamos que hay una estrategia que le da al líder una utilidad esperada de al menos |E| |E|+1 + K (|E|+1)|V |. Entonces, esta estrategia debe inducir al seguidor a jugar t0 siempre que tenga un tipo de la forma θe (porque de lo contrario, la utilidad podría ser a lo sumo |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ). Por lo tanto, no puede ser el caso de que para alguna arista e = (v1, v2) ∈ E, la probabilidad de que el líder juegue uno de sv1 y sv2 sea al menos 2/K, porque entonces la utilidad esperada para el seguidor de jugar t1 cuando tiene el tipo θe sería al menos 2 K 2K 3 = 4/3 > 1. Además, la estrategia debe inducir al seguidor a jugar t0 durante al menos K tipos de la forma θv. Inducir al seguidor a jugar t0 cuando tiene el tipo θv solo se puede lograr jugando sv con una probabilidad de al menos 1/K, lo que le dará al seguidor una utilidad de como máximo K−1 K K K−1 = 1 por jugar t1. Pero entonces, el conjunto de vértices v tales que sv se juega con una probabilidad de al menos 1/K debe constituir un conjunto independiente de tamaño K (porque si hubiera una arista e entre dos de estos vértices, induciría al seguidor a jugar t1 para el tipo θe según lo mencionado anteriormente). Por el contrario, si el seguidor tiene solo un tipo, entonces podemos generalizar el enfoque de programación lineal para juegos en forma normal: Teorema 8. En juegos bayesianos de 2 jugadores en los que el seguidor tiene solo un tipo, una estrategia mixta óptima a comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal. Prueba. Generalizamos el enfoque en el Teorema 2 de la siguiente manera. Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder para cada uno de los tipos de líderes de manera que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad esperada ex ante de los líderes. Para hacerlo, generalizamos el programa lineal de la siguiente manera: maximizar θl∈Θl π(θl) s∈S pθl s uθl l (s, t) sujeto a para todo t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t) para todo θl ∈ Θl, s∈S p θl s = 1 Como en el Teorema 2, la solución para el programa lineal que maximiza el valor de la solución es una estrategia óptima a comprometerse. Esto muestra un contraste interesante entre el compromiso con estrategias puras y el compromiso con estrategias mixtas en juegos bayesianos: para las estrategias puras, el problema se vuelve fácil si el líder tiene solo un tipo (pero no si el seguidor tiene solo un tipo), mientras que para las estrategias mixtas, el problema se vuelve fácil si el seguidor tiene solo un tipo (pero no si el líder tiene solo un tipo). 4. CONCLUSIONES E INVESTIGACIONES FUTURAS En los sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias de forma simultánea. Esto requiere cierta noción de equilibrio (equilibrio de Nash y sus refinamientos), y a menudo conduce al problema de selección de equilibrio: no está claro para cada jugador individual según qué equilibrio debería jugar. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Por ejemplo, un agente puede llegar al sitio del juego (real o virtual) antes que el otro, o, en el caso específico de agentes de software, el código de un agente puede estar completo y comprometido antes que el de otro agente. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. Específicamente, si es posible el compromiso con estrategias mixtas, entonces el compromiso (óptimo) nunca perjudica al líder y a menudo lo beneficia. El reciente aumento del interés en las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas para comprometerse tanto a estrategias puras como a estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Para juegos en forma normal, demostramos que la estrategia pura óptima a comprometerse se puede encontrar eficientemente para cualquier número de jugadores. Una estrategia mixta óptima para comprometerse en un juego en forma normal puede encontrarse eficientemente para dos jugadores utilizando programación lineal (y no más eficientemente que eso, en el sentido de que cualquier programa lineal con una restricción de probabilidad puede ser codificado como tal problema). (Esta es una generalización de la computabilidad en tiempo polinómico de las estrategias minimax en juegos en forma normal). El problema se vuelve NP-duro para tres (o más) jugadores. En los juegos bayesianos, el problema de encontrar una estrategia pura óptima a la que comprometerse es NP-duro incluso en juegos de dos jugadores en los que el seguidor tiene solo un tipo, aunque los juegos de dos jugadores en los que el líder tiene solo un tipo pueden resolverse eficientemente. El problema de encontrar una estrategia mixta óptima a comprometerse en un juego bayesiano es NP-duro incluso en juegos de dos jugadores en los que el líder tiene solo un tipo, aunque los juegos de dos jugadores en los que el seguidor tiene solo un tipo pueden resolverse eficientemente utilizando una generalización del enfoque de programación lineal para juegos en forma normal. Las siguientes dos tablas resumen estos resultados. 2 jugadores ≥ 3 jugadores forma normal O(#resultados) O(#resultados· #jugadores) Bayesiano, O(#resultados· NP-completo 1-tipo líder #tipos) Bayesiano, NP-completo NP-completo 1-tipo seguidor Bayesiano (general) NP-completo NP-completo Resultados para el compromiso con estrategias puras. (Con más de 2 jugadores, el seguidor es el último jugador en comprometerse, el líder es el primero.) 88 2 jugadores ≥ 3 jugadores forma normal una resolución de LP por acción NP-completa del seguidor Bayesiano, NP-completo NP-completo 1-tipo líder Bayesiano, una resolución de LP por acción NP-completa del 1-tipo seguidor Bayesiano (general) NP-completo NP-completo Resultados para el compromiso con estrategias mixtas. (Con más de 2 jugadores, el seguidor es el último jugador en comprometerse, el líder es el primero.) La investigación futura puede tomar varias direcciones. Primero, podemos evaluar empíricamente las técnicas presentadas aquí en conjuntos de pruebas como GAMUT [19]. También podemos estudiar la computación de estrategias óptimas a comprometerse en otras representaciones concisas de juegos en forma normal, por ejemplo, en juegos gráficos [10] o juegos de grafo de efecto local/acción [14, 1]. Para los casos en los que calcular una estrategia óptima para comprometerse es NP-duro, también podemos estudiar la computación de estrategias aproximadamente óptimas para comprometerse. Si bien la definición correcta de una estrategia aproximadamente óptima en este contexto puede parecer simple al principio, debería ser una estrategia que, si los jugadores siguientes juegan de manera óptima, funcione casi tan bien como la estrategia óptima en promedio, esta definición se vuelve problemática cuando consideramos que los otros jugadores también podrían estar jugando solo de manera aproximadamente óptima. Uno también puede estudiar modelos en los que múltiples (pero no todos) jugadores se comprometen al mismo tiempo. Otra dirección interesante a explorar es ver si calcular estrategias mixtas óptimas a las que comprometerse puede ayudarnos, o de alguna manera arrojar luz sobre, el cálculo de equilibrios de Nash. A menudo, las estrategias mixtas óptimas a las que comprometerse también son estrategias de equilibrio de Nash (por ejemplo, en juegos de suma cero de dos jugadores esto siempre es cierto), aunque no siempre es el caso (por ejemplo, como ya señalamos, a veces la estrategia óptima a la que comprometerse es una estrategia estrictamente dominada, que nunca puede ser una estrategia de equilibrio de Nash). 5. REFERENCIAS [1] N. A. R. Bhat y K. Leyton-Brown. Calculando los equilibrios de Nash de juegos de gráficos de acción. En Actas de la 20ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI), Banff, Canadá, 2004. [2] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Actas de la Decimoctava Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 765-771, Acapulco, México, 2003. [3] V. Conitzer y T. Sandholm. Complejidad del dominio (iterado). En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 88-97, Vancouver, Canadá, 2005. [4] V. Conitzer y T. Sandholm. Un criterio de eliminabilidad de estrategias generalizado y métodos computacionales para aplicarlo. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 483-488, Pittsburgh, PA, EE. UU., 2005. [5] A. A. Cournot. Las investigaciones sobre los juegos bayesianos son una representación potencialmente concisa de los juegos en forma normal en los principios matemáticos de la teoría de la riqueza. Hachette, París, 1838. [6] G. Dantzig. Una prueba de la equivalencia del problema de programación y el problema de juego. En T. Koopmans, editor, Análisis de la actividad de producción y asignación, páginas 330-335. John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel. \n\nJohn Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, y E. Zemel. La complejidad de eliminar estrategias dominadas. Matemáticas de la Investigación de Operaciones, 18:553-565, 1993. [8] I. Gilboa y E. Zemel. Nash y equilibrios correlacionados: Algunas consideraciones de complejidad. Juegos y Comportamiento Económico, 1:80-93, 1989. [9] R. Karp. Reductibilidad entre problemas combinatorios. En R. E. Miller y J. W. Thatcher, editores, Complejidad de las Computaciones de Computadoras, páginas 85-103. Plenum Press, Nueva York, 1972. [10] M. Kearns, M. Littman y S. Singh. Modelos gráficos para teoría de juegos. En Actas de la Conferencia sobre Incertidumbre en Inteligencia Artificial (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou y J. N. Tsitsiklis. Una nota sobre la eliminación de estrategias en juegos bimatrix. Cartas de Investigación Operativa, 7(3):103-107, 1988. [12] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [14] K. Leyton-Brown y M. Tennenholtz. Juegos de efecto local. En Actas de la Decimoctava Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), Acapulco, México, 2003. [15] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 36-41, San Diego, CA, 2003. [16] M. Littman y P. Stone. Un algoritmo de equilibrio de Nash de tiempo polinómico para juegos repetidos. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 48-54, San Diego, CA, 2003. [17] R. D. Luce y H. Raiffa. Juegos y decisiones. John Wiley and Sons, Nueva York, 1957. Reedición de Dover 1989. [18] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown y Y. Shoham. Ejecutar el GAMUT: Un enfoque integral para evaluar algoritmos de teoría de juegos. En la Conferencia Internacional sobre Agentes Autónomos y Sistemas Multiagente (AAMAS), Nueva York, NY, EE. UU., 2004. [20] M. J. Osborne y A. Rubinstein. Un curso de teoría de juegos. MIT Press, 1994. [21] C. Papadimitriou. \n\nMIT Press, 1994. [21] C. Papadimitriou. Algoritmos, juegos e Internet. En Actas del Simposio Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. 89 [22] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 664-669, San José, CA, EE. UU., 2004. [23] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [24] J. von Neumann. A la teoría de los juegos sociales. Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg. \n\nMathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg. Forma de mercado y equilibrio. Springer, Viena, 1934. [26] B. von Stengel y S. Zamir. Liderazgo con compromiso hacia estrategias mixtas. Informe de investigación CDAM LSE-CDAM-2004-01, London School of Economics, febrero de 2004. 90 ",
            "candidates": [],
            "error": [
                [
                    "NP-hardness",
                    "NP-dificultad",
                    "NP-dificultad",
                    "NP-dificultad"
                ]
            ]
        },
        "game theory": {
            "translated_key": "teoría de juegos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Computing the Optimal Strategy to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "We give both positive results (efficient algorithms) and negative results (NP-hardness results).",
                "Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent systems with self-interested agents (including most economic settings), the optimal action for one agent to take depends on the actions that the other agents take.",
                "To analyze how an agent should behave in such settings, the tools of <br>game theory</br> need to be applied.",
                "Typically, when a strategic setting is modeled in the framework of <br>game theory</br>, it is assumed that players choose their strategies simultaneously.",
                "This is especially true when the setting is modeled as a normal-form game, which only specifies each agents utility as a function of the vector of strategies that the agents choose, and does not provide any information on the order in which agents make their decisions and what the agents observe about earlier decisions by other agents.",
                "Given that the game is modeled in normal form, it is typically analyzed using the concept of Nash equilibrium.",
                "A Nash equilibrium specifies a strategy for each player, such that no player has an incentive to individually deviate from this profile of strategies. (Typically, the strategies are allowed to be mixed, that is, probability distributions over the original (pure) strategies.)",
                "A (mixed-strategy) Nash equilibrium is guaranteed to exist in finite games [18], but one problem is that there may be multiple Nash equilibria.",
                "This leads to the equilibrium selection problem of how an agent can know which strategy to play if it does not know which equilibrium is to be played.",
                "When the setting is modeled as an extensive-form game, it is possible to specify that some players receive some information about actions taken by others earlier in the game before deciding on their action.",
                "Nevertheless, in general, the players do not know everything that happened earlier in the game.",
                "Because of this, these games are typically still analyzed using an equilibrium concept, where one specifies a mixed strategy for each player, and requires that each players strategy is a best response to the others strategies. (Typically an additional constraint on the strategies is now imposed to ensure that players do not play in a way that is irrational with respect to the information that they have received so far.",
                "This leads to refinements of Nash equilibrium such as subgame perfect and sequential equilibrium.)",
                "However, in many real-world settings, strategies are not selected in such a simultaneous manner.",
                "Oftentimes, one player (the leader) is able to commit to a strategy before another player (the follower).",
                "This can be due to a variety of reasons.",
                "For example, one of the players may arrive at the site at which the game is to be played before another agent (e.g., in economic settings, one player may enter a market earlier and commit to a way of doing busi82 ness).",
                "Such commitment power has a profound impact on how the game should be played.",
                "For example, the leader may be best off playing a strategy that is dominated in the normal-form representation of the game.",
                "Perhaps the earliest and best-known example of the effect of commitment is that by von Stackelberg [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution.",
                "In general, if commitment to mixed strategies is possible, then (under minor assumptions) it never hurts, and often helps, to commit to a strategy [26].",
                "Being forced to commit to a pure strategy sometimes helps, and sometimes hurts (for example, committing to a pure strategy in rock-paper-scissors before the other players decision will naturally result in a loss).",
                "In this paper, we will assume commitment is always forced; if it is not, the player who has the choice of whether to commit can simply compare the commitment outcome to the non-commitment (simultaneous-move) outcome.",
                "Models of leadership are especially important in settings with multiple self-interested software agents.",
                "Once the code for an agent (or for a team of agents) is finalized and the agent is deployed, the agent is committed to playing the (possibly randomized) strategy that the code prescribes.",
                "Thus, as long as one can credibly show that one cannot change the code later, the code serves as a commitment device.",
                "This holds true for recreational tournaments among agents (e.g., poker tournaments, RoboSoccer), and for industrial applications such as sensor webs.",
                "Finally, there is also an implicit leadership situation in the field of mechanism design, in which one player (the designer) gets to choose the rules of the game that the remaining players then play.",
                "Mechanism design is an extremely important topic to the EC community: the papers published on mechanism design in recent EC conferences are too numerous to cite.",
                "Indeed, the mechanism designer may benefit from committing to a choice that, if the (remaining) agents actions were fixed, would be suboptimal.",
                "For example, in a (first-price) auction, the seller may wish to set a positive (artificial) reserve price for the item, below which the item will not be sold-even if the seller values the item at 0.",
                "In hindsight (after the bids have come in), this (na¨ıvely) appears suboptimal: if a bid exceeding the reserve price came in, the reserve price had no effect, and if no such bid came in, the seller would have been better off accepting a lower bid.",
                "Of course, the reason for setting the reserve price is that it incentivizes the bidders to bid higher, and because of this, setting artificial reserve prices can actually increase expected revenue to the seller.",
                "A significant amount of research has recently been devoted to the computation of solutions according to various solution concepts for settings in which the agents choose their strategies simultaneously, such as dominance [7, 11, 3] and (especially) Nash equilibrium [8, 21, 16, 15, 2, 22, 23, 4].",
                "However, the computation of the optimal strategy to commit to in a leadership situation has gone ignored.",
                "Theoretically, leadership situations can simply be thought of as an extensive-form game in which one player chooses a strategy (for the original game) first.",
                "The number of strategies in this extensive-form game, however, can be exceedingly large.",
                "For example, if the leader is able to commit to a mixed strategy in the original game, then every one of the (continuum of) mixed strategies constitutes a pure strategy in the extensive-form representation of the leadership situation. (We note that a commitment to a distribution is not the same as a distribution over commitments.)",
                "Moreover, if the original game is itself an extensive-form game, the number of strategies in the extensive-form representation of the leadership situation (which is a different extensive-form game) becomes even larger.",
                "Because of this, it is usually not computationally feasible to simply transform the original game into the extensive-form representation of the leadership situation; instead, we have to analyze the game in its original representation.",
                "In this paper, we study how to compute the optimal strategy to commit to, both in normal-form games (Section 2) and in Bayesian games, which are a special case of extensiveform games (Section 3). 2.",
                "NORMAL-FORM GAMES In this section, we study how to compute the optimal strategy to commit to for games represented in normal form. 2.1 Definitions In a normal-form game, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a pure strategy for every player, also known as a profile of pure strategies) to a real number.",
                "To ease notation, in the case of two players, we will refer to player 1s pure strategy set as S, and player 2s pure strategy set as T. Such games can be represented in (bi-)matrix form, in which the rows correspond to player 1s pure strategies, the columns correspond to player 2s pure strategies, and the entries of the matrix give the row and column players utilities (in that order) for the corresponding outcome of the game.",
                "In the case of three players, we will use R, S, and T, for player 1, 2, and 3s pure strategies, respectively.",
                "A mixed strategy for a player is a probability distribution over that players pure strategies.",
                "In the case of two-player games, we will refer to player 1 as the leader and player 2 as the follower.",
                "Before defining optimal leadership strategies, consider the following game which illustrates the effect of the leaders ability to commit. 2, 1 4, 0 1, 0 3, 1 In this normal-form representation, the bottom strategy for the row player is strictly dominated by the top strategy.",
                "Nevertheless, if the row player has the ability to commit to a pure strategy before the column player chooses his strategy, the row player should commit to the bottom strategy: doing so will make the column player prefer to play the right strategy, leading to a utility of 3 for the row player.",
                "By contrast, if the row player were to commit to the top strategy, the column player would prefer to play the left strategy, leading to a utility of only 2 for the row player.",
                "If the row player is able to commit to a mixed strategy, then she can get an even greater (expected) utility: if the row player commits to placing probability p > 1/2 on the bottom strategy, then the column player will still prefer to play the right strategy, and the row players expected utility will be 3p + 4(1 − p) = 4 − p ≥ 3.",
                "If the row player plays each strategy with probability exactly 1/2, the column player is 83 indifferent between the strategies.",
                "In such cases, we will assume that the column player will choose the strategy that maximizes the row players utility (in this case, the right strategy).",
                "Hence, the optimal mixed strategy to commit to for the row player is p = 1/2.",
                "There are a few good reasons for this assumption.",
                "If we were to assume the opposite, then there would not exist an optimal strategy for the row player in the example game: the row player would play the bottom strategy with probability p = 1/2 + with > 0, and the smaller , the better the utility for the row player.",
                "By contrast, if we assume that the follower always breaks ties in the leaders favor, then an optimal mixed strategy for the leader always exists, and this corresponds to a subgame perfect equilibrium of the extensive-form representation of the leadership situation.",
                "In any case, this is a standard assumption for such models (e.g. [20]), although some work has investigated what can happen in the other subgame perfect equilibria [26]. (For generic two-player games, the leaders subgame-perfect equilibrium payoff is unique.)",
                "Also, the same assumption is typically used in mechanism design, in that it is assumed that if an agent is indifferent between revealing his preferences truthfully and revealing them falsely, he will report them truthfully.",
                "Given this assumption, we can safely refer to optimal leadership strategies rather than having to use some equilibrium notion.",
                "Hence, for the purposes of this paper, an optimal strategy to commit to in a 2-player game is a strategy s ∈ S that maximizes maxt∈BR(s) ul(s, t), where BR(s) = arg maxt∈T uf (s, t). (ul and uf are the leader and followers utility functions, respectively.)",
                "We can have S = S for the case of commitment to pure strategies, or S = ∆(S), the set of probability distributions over S, for the case of commitment to mixed strategies. (We note that replacing T by ∆(T) makes no difference in this definition.)",
                "For games with more than two players, in which the players commit to their strategies in sequence, we define optimal strategies to commit to recursively.",
                "After the leader commits to a strategy, the game to be played by the remaining agents is itself a (smaller) leadership game.",
                "Thus, we define an optimal strategy to commit to as a strategy that maximizes the leaders utility, assuming that the play of the remaining agents is itself optimal under this definition, and maximizes the leaders utility among all optimal ways to play the remaining game.",
                "Again, commitment to mixed strategies may or may not be a possibility for every player (although for the last player it does not matter if we allow for commitment to mixed strategies). 2.2 Commitment to pure strategies We first study how to compute the optimal pure strategy to commit to.",
                "This is relatively simple, because the number of strategies to commit to is not very large. (In the following, #outcomes is the number of complete strategy profiles.)",
                "Theorem 1.",
                "Under commitment to pure strategies, the set of all optimal strategy profiles in a normal-form game can be found in O(#players · #outcomes) time.",
                "Proof.",
                "Each pure strategy that the first player may commit to will induce a subgame for the remaining players.",
                "We can solve each such subgame recursively to find all of its optimal strategy profiles; each of these will give the original leader some utility.",
                "Those that give the leader maximal utility correspond exactly to the optimal strategy profiles of the original game.",
                "We now present the algorithm formally.",
                "Let Su(G, s1) be the subgame that results after the first (remaining) player in G plays s1 ∈ SG 1 .",
                "A game with 0 players is simply an outcome of the game.",
                "The function Append(s, O) appends the strategy s to each of the vectors of strategies in the set O.",
                "Let e be the empty vector with no elements.",
                "In a slight abuse of notation, we will write uG 1 (C) when all strategy profiles in the set C give player 1 the same utility in the game G. (Here, player 1 is the first remaining player in the subgame G, not necessarily player 1 in the original game.)",
                "We note that arg max is set-valued.",
                "Then, the following algorithm computes all optimal strategy profiles: Algorithm Solve(G) if G has 0 players return {e} C ← ∅ for all s1 ∈ SG 1 { O ← Solve(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) if C = ∅ or uG 1 (s1, O ) = uG 1 (C) C ← C∪Append(s1, O ) if uG 1 (s1, O ) > uG 1 (C) C ←Append(s1, O ) } return C Every outcome is (potentially) examined by every player, which leads to the given runtime bound.",
                "As an example of how the algorithm works, consider the following 3-player game, in which the first player chooses the left or right matrix, the second player chooses a row, and the third player chooses a column. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 3,0,0 First we eliminate the outcomes that do not correspond to best responses for the third player (removing them from the matrix): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Next, we remove the entries in which the third player does not break ties in favor of the second player, as well as entries that do not correspond to best responses for the second player. 0,1,1 2,1,1 1,1,1 0,5,1 Finally, we remove the entries in which the second and third players do not break ties in favor of the first player, as well as entries that do not correspond to best responses for the first player. 2,1,1 84 Hence, in optimal play, the first player chooses the left matrix, the second player chooses the middle row, and the third player chooses the left column. (We note that this outcome is Pareto-dominated by (Right, Middle, Left).)",
                "For general normal-form games, each players utility for each of the outcomes has to be explicitly represented in the input, so that the input size is itself Ω(#players · #outcomes).",
                "Therefore, the algorithm is in fact a linear-time algorithm. 2.3 Commitment to mixed strategies In the special case of two-player zero-sum games, computing an optimal mixed strategy for the leader to commit to is equivalent to computing a minimax strategy, which minimizes the maximum expected utility that the opponent can obtain.",
                "Minimax strategies constitute the only natural solution concept for two-player zero-sum games: von Neumanns Minimax Theorem [24] states that in two-player zero-sum games, it does not matter (in terms of the players utilities) which player gets to commit to a mixed strategy first, and a profile of mixed strategies is a Nash equilibrium if and only if both strategies are minimax strategies.",
                "It is well-known that a minimax strategy can be found in polynomial time, using linear programming [17].",
                "Our first result in this section generalizes this result, showing that an optimal mixed strategy for the leader to commit to can be efficiently computed in general-sum two-player games, again using linear programming.",
                "Theorem 2.",
                "In 2-player normal-form games, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders utility.",
                "Such a mixed strategy can be computed using the following simple linear program: maximize s∈S psul(s, t) subject to for all t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1 We note that this program may be infeasible for some follower strategies t, for example, if t is a strictly dominated strategy.",
                "Nevertheless, the program must be feasible for at least some follower strategies; among these follower strategies, choose a strategy t∗ that maximizes the linear programs solution value.",
                "Then, if the leader chooses as her mixed strategy the optimal settings of the variables ps for the linear program for t∗ , and the follower plays t∗ , this constitutes an optimal strategy profile.",
                "In the following result, we show that we cannot expect to solve the problem more efficiently than linear programming, because we can reduce any linear program with a probability constraint on its variables to a problem of computing the optimal mixed strategy to commit to in a 2-player normalform game.",
                "Theorem 3.",
                "Any linear program whose variables xi (with xi ∈ R≥0 ) must satsify i xi = 1 can be modeled as a problem of computing the optimal mixed strategy to commit to in a 2-player normal-form game.",
                "Proof.",
                "Let the leader have a pure strategy i for every variable xi.",
                "Let the column player have one pure strategy j for every constraint in the linear program (other than i xi = 1), and a single additional pure strategy 0.",
                "Let the utility functions be as follows.",
                "Writing the objective of the linear program as maximize i cixi, for any i, let ul(i, 0) = ci and uf (i, 0) = 0.",
                "Writing the jth constraint of the linear program (not including i xi = 1) as i aijxi ≤ bj, for any i, j > 0, let ul(i, j) = mini ci − 1 and uf (i, j) = aij − bj.",
                "For example, consider the following linear program. maximize 2x1 + x2 subject to x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 The optimal solution to this program is x1 = 1/3, x2 = 2/3.",
                "Our reduction transforms this program into the following leader-follower game (where the leader is the row player). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 Indeed, the optimal strategy for the leader is to play the top strategy with probability 1/3 and the bottom strategy with probability 2/3.",
                "We now show that the reduction works in general.",
                "Clearly, the leader wants to incentivize the follower to play 0, because the utility that the leader gets when the follower plays 0 is always greater than when the follower does not play 0.",
                "In order for the follower not to prefer playing j > 0 rather than 0, it must be the case that i pl(i)(aij − bj) ≤ 0, or equivalently i pl(i)aij ≤ bj.",
                "Hence the leader will get a utility of at least mini ci if and only if there is a feasible solution to the constraints.",
                "Given that the pl(i) incentivize the follower to play 0, the leader attempts to maximize i pl(i)ci.",
                "Thus the leader must solve the original linear program.",
                "As an alternative proof of Theorem 3, one may observe that it is known that finding a minimax strategy in a zerosum game is as hard as the linear programming problem [6], and as we pointed out at the beginning of this section, computing a minimax strategy in a zero-sum game is a special case of the problem of computing an optimal mixed strategy to commit to.",
                "This polynomial-time solvability of the problem of computing an optimal mixed strategy to commit to in two-player normal-form games contrasts with the unknown complexity of computing a Nash equilibrium in such games [21], as well as with the NP-hardness of finding a Nash equilibrium with maximum utility for a given player in such games [8, 2].",
                "Unfortunately, this result does not generalize to more than two players-here, the problem becomes NP-hard.",
                "To show this, we reduce from the VERTEX-COVER problem.",
                "Definition 1.",
                "In VERTEX-COVER, we are given a graph G = (V, E) and an integer K. We are asked whether there 85 exists a subset of the vertices S ⊆ V , with |S| = K, such that every edge e ∈ E has at least one of its endpoints in S. BALANCED-VERTEX-COVER is the special case of VERTEX-COVER in which K = |V |/2.",
                "VERTEX-COVER is NP-complete [9].",
                "The following lemma shows that the hardness remains if we require K = |V |/2. (Similar results have been shown for other NP-complete problems.)",
                "Lemma 1.",
                "BALANCED-VERTEX-COVER is NP-complete.",
                "Proof.",
                "Membership in NP follows from the fact that the problem is a special case of VERTEX-COVER, which is in NP.",
                "To show NP-hardness, we reduce an arbitrary VERTEX-COVER instance to a BALANCED-VERTEXCOVER instance, as follows.",
                "If, for the VERTEX-COVER instance, K > |V |/2, then we simply add isolated vertices that are disjoint from the rest of the graph, until K = |V |/2.",
                "If K < |V |/2, we add isolated triangles (that is, the complete graph on three vertices) to the graph, increasing K by 2 every time, until K = |V |/2.",
                "Theorem 4.",
                "In 3-player normal-form games, finding an optimal mixed strategy to commit to is NP-hard.",
                "Proof.",
                "We reduce an arbitrary BALANCED-VERTEXCOVER instance to the following 3-player normal-form game.",
                "For every vertex v, each of the three players has a pure strategy corresponding to that vertex (rv, sv, tv, respectively).",
                "In addition, for every edge e, the third player has a pure strategy te; and finally, the third player has one additional pure strategy t0.",
                "The utilities are as follows: • for all r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • for all r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • for all v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • for all v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • for all v ∈ V , for all r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V | |V |−2 ; • for all e ∈ E, s ∈ S, for both v ∈ e, u3(rv, s, te) = 0; • for all e ∈ E, s ∈ S, for all v /∈ e, u3(rv, s, te) = |V | |V |−2 . • for all r ∈ R, s ∈ S, u3(r, s, t0) = 1.",
                "We note that players 1 and 2 have the same utility function.",
                "We claim that there is an optimal strategy profile in which players 1 and 2 both obtain 1 (their maximum utility) if and only if there is a solution to the BALANCED-VERTEXCOVER problem. (Otherwise, these players will both obtain 0.)",
                "First, suppose there exists a solution to the BALANCEDVERTEX-COVER problem.",
                "Then, let player 1 play every rv such that v is in the cover with probability 2 |V | , and let player 2 play every sv such that v is not in the cover with probability 2 |V | .",
                "Then, for player 3, the expected utility of playing tv (for any v) is (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of 2 |V | that rv or sv is played.",
                "Additionally, the expected utility of playing te (for any e) is at most (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of at least 2 |V | that some rv with v ∈ e is played (because player 1 is randomizing over the pure strategies corresponding to the cover).",
                "It follows that playing t0 is a best response for player 3, giving players 1 and 2 a utility of 1.",
                "Now, suppose that players 1 and 2 obtain 1 in optimal play.",
                "Then, it must be the case that player 3 plays t0.",
                "Hence, for every v ∈ V , there must be a probability of at least 2 |V | that either rv or sv is played, for otherwise player 3 would be better off playing tv.",
                "Because players 1 and 2 have only a total probability of 2 to distribute, it must be the case that for each v, either rv or sv is played with probability 2 |V | , and the other is played with probability 0. (It is not possible for both to have nonzero probability, because then there would be some probability that both are played simultaneously (correlation is not possible), hence the total probability of at least one being played could not be high enough for all vertices.)",
                "Thus, for exactly half the v ∈ V , player 1 places probability 2 |V | on rv.",
                "Moreover, for every e ∈ E, there must be a probability of at least 2 |V | that some rv with v ∈ e is played, for otherwise player 3 would be better off playing te.",
                "Thus, the v ∈ V such that player 1 places probability 2 |V | on rv constitute a balanced vertex cover. 3.",
                "BAYESIAN GAMES So far, we have restricted our attention to normal-form games.",
                "In a normal-form game, it is assumed that every agent knows every other agents preferences over the outcomes of the game.",
                "In general, however, agents may have some private information about their preferences that is not known to the other agents.",
                "Moreover, at the time of commitment to a strategy, the agents may not even know their own (final) preferences over the outcomes of the game yet, because these preferences may be dependent on a context that has yet to materialize.",
                "For example, when the code for a trading agent is written, it may not yet be clear how that agent will value resources that it will negotiate over later, because this depends on information that is not yet available at the time at which the code is written (such as orders that will have been placed to the agent before the negotiation).",
                "In this section, we will study commitment in Bayesian games, which can model such uncertainty over preferences. 3.1 Definitions In a Bayesian game, every player i has a set of actions Si, a set of types Θi with an associated probability distribution πi : Θi → [0, 1], and, for each type θi, a utility function uθi i : S1 × S2 × . . . × Sn → R. A pure strategy in a Bayesian game is a mapping from the players types to actions, σi : Θi → Si. (Bayesian games can be rewritten in normal form by enumerating every pure strategy σi, but this will cause an exponential blowup in the size of the representation of the game and therefore cannot lead to efficient algorithms.)",
                "The strategy that the leader should commit to depends on whether, at the time of commitment, the leader knows her own type.",
                "If the leader does know her own type, the other types that the leader might have had become irrelevant and the leader should simply commit to the strategy that is optimal for the type.",
                "However, as argued above, the leader does not necessarily know her own type at the time of commitment (e.g., the time at which the code is submitted).",
                "In this case, the leader must commit to a strategy that is 86 dependent upon the leaders eventual type.",
                "We will study this latter model, although we will pay specific attention to the case where the leader has only a single type, which is effectively the same as the former model. 3.2 Commitment to pure strategies It turns out that computing an optimal pure strategy to commit to is hard in Bayesian games, even with two players.",
                "Theorem 5.",
                "Finding an optimal pure strategy to commit to in 2-player Bayesian games is NP-hard, even when the follower has only a single type.",
                "Proof.",
                "We reduce an arbitrary VERTEX-COVER instance to the following Bayesian game between the leader and the follower.",
                "The leader has K types θ1, θ2, . . . , θK , each occurring with probability 1/K, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has only a single type; for each edge e ∈ E, the follower has an action te, and the follower has a single additional action t0.",
                "The utility function for the leader is given by, for all θl ∈ Θl and all s ∈ S, u θl l (s, t0) = 1, and for all e ∈ E, u θl l (s, te) = 0.",
                "The followers utility is given by: • For all v ∈ V , for all e ∈ E with v /∈ e, uf (sv, te) = 1; • For all v ∈ V , for all e ∈ E with v ∈ e, uf (sv, te) = −K; • For all v ∈ V , uf (sv, t0) = 0.",
                "We claim that the leader can get a utility of 1 if and only if there is a solution to the VERTEX-COVER instance.",
                "First, suppose that there is a solution to the VERTEXCOVER instance.",
                "Then, the leader can commit to a pure strategy such that for each vertex v in the cover, the leader plays sv for some type.",
                "Then, the followers utility for playing te (for any e ∈ E) is at most K−1 K + 1 K (−K) = − 1 K , so that the follower will prefer to play t0, which gives the leader a utility of 1, as required.",
                "Now, suppose that there is a pure strategy for the leader that will give the leader a utility of 1.",
                "Then, the follower must play t0.",
                "In order for the follower not to prefer playing te (for any e ∈ E) instead, for at least one v ∈ e the leader must play sv for some type θl.",
                "Hence, the set of vertices v that the leader plays for some type must constitute a vertex cover; and this set can have size at most K, because the leader has only K types.",
                "So there is a solution to the VERTEXCOVER instance.",
                "However, if the leader has only a single type, then the problem becomes easy again (#types is the number of types for the follower): Theorem 6.",
                "In 2-player Bayesian games in which the leader has only a single type, an optimal pure strategy to commit to can be found in O(#outcomes · #types) time.",
                "Proof.",
                "For every leader action s, we can compute, for every follower type θf ∈ Θf , which actions t maximize the followers utility; call this set of actions BRθf (s).",
                "Then, the utility that the leader receives for committing to action s can be computed as θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), and the leader can choose the best action to commit to. 3.3 Commitment to mixed strategies In two-player zero-sum imperfect information games with perfect recall (no player ever forgets something that it once knew), a minimax strategy can be constructed in polynomial time [12, 13].",
                "Unfortunately, this result does not extend to computing optimal mixed strategies to commit to in the general-sum case-not even in Bayesian games.",
                "We will exhibit NP-hardness by reducing from the INDEPENDENTSET problem.",
                "Definition 2.",
                "In INDEPENDENT-SET, we are given a graph G = (V, E) and an integer K. We are asked whether there exists a subset of the vertices S ⊆ V , with |S| = K, such that no edge e ∈ E has both of its endpoints in S. Again, this problem is NP-complete [9].",
                "Theorem 7.",
                "Finding an optimal mixed strategy to commit to in 2-player Bayesian games is NP-hard, even when the leader has only a single type and the follower has only two actions.",
                "Proof.",
                "We reduce an arbitrary INDEPENDENT-SET instance to the following Bayesian game between the leader and the follower.",
                "The leader has only a single type, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has a type θv for every v ∈ V , occurring with probability 1 (|E|+1)|V | , and a type θe for every e ∈ E, occurring with probability 1 |E|+1 .",
                "The follower has two actions: t0 and t1.",
                "The leaders utility is given by, for all s ∈ S, ul(s, t0) = 1 and ul(s, t1) = 0.",
                "The followers utility is given by: • For all v ∈ V , uθv f (sv, t1) = 0; • For all v ∈ V and s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • For all v ∈ V and s ∈ S, uθv f (s, t0) = 1; • For all e ∈ E, s ∈ S, uθe f (s, t0) = 1; • For all e ∈ E, for both v ∈ e, uθe f (sv, t1) = 2K 3 ; • For all e ∈ E, for all v /∈ e, uθe f (sv, t1) = 0.",
                "We claim that an optimal strategy to commit to gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | if and only if there is a solution to the INDEPENDENT-SET instance.",
                "First, suppose that there is a solution to the INDEPENDENT-SET instance.",
                "Then, the leader could commit to the following strategy: for every vertex v in the independent set, play the corresponding sv with probability 1/K.",
                "If the follower has type θe for some e ∈ E, the expected utility for the follower of playing t1 is at most 1 K 2K 3 = 2/3, because there is at most one vertex v ∈ e such that sv is played with nonzero probability.",
                "Hence, the follower will play t0 and obtain a utility of 1.",
                "If the follower has type θv for some vertex v in the independent set, the expected utility for the follower of playing t1 is K−1 K K K−1 = 1, because the leader plays sv with probability 1/K.",
                "It follows that the follower (who breaks ties to maximize the leaders utility) will play t0, which also gives a utility of 1 and gives the leader a higher utility.",
                "Hence the leaders expected utility for this strategy is at least |E| |E|+1 + K (|E|+1)|V | , as required. 87 Now, suppose that there is a strategy that gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | .",
                "Then, this strategy must induce the follower to play t0 whenever it has a type of the form θe (because otherwise, the utility could be at most |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ).",
                "Thus, it cannot be the case that for some edge e = (v1, v2) ∈ E, the probability that the leader plays one of sv1 and sv2 is at least 2/K, because then the expected utility for the follower of playing t1 when it has type θe would be at least 2 K 2K 3 = 4/3 > 1.",
                "Moreover, the strategy must induce the follower to play t0 for at least K types of the form θv.",
                "Inducing the follower to play t0 when it has type θv can be done only by playing sv with probability at least 1/K, which will give the follower a utility of at most K−1 K K K−1 = 1 for playing t1.",
                "But then, the set of vertices v such that sv is played with probability at least 1/K must constitute an independent set of size K (because if there were an edge e between two such vertices, it would induce the follower to play t1 for type θe by the above).",
                "By contrast, if the follower has only a single type, then we can generalize the linear programming approach for normalform games: Theorem 8.",
                "In 2-player Bayesian games in which the follower has only a single type, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "We generalize the approach in Theorem 2 as follows.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader for every one of the leaders types such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders ex ante expected utility.",
                "To do so, we generalize the linear program as follows: maximize θl∈Θl π(θl) s∈S pθl s uθl l (s, t) subject to for all t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t ) for all θl ∈ Θl, s∈S p θl s = 1 As in Theorem 2, the solution for the linear program that maximizes the solution value is an optimal strategy to commit to.",
                "This shows an interesting contrast between commitment to pure strategies and commitment to mixed strategies in Bayesian games: for pure strategies, the problem becomes easy if the leader has only a single type (but not if the follower has only a single type), whereas for mixed strategies, the problem becomes easy if the follower has only a single type (but not if the leader has only a single type). 4.",
                "CONCLUSIONS AND FUTURE RESEARCH In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "This requires some equilibrium notion (Nash equilibrium and its refinements), and often leads to the equilibrium selection problem: it is unclear to each individual player according to which equilibrium she should play.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "For example, one agent may arrive at the (real or virtual) site of the game before the other, or, in the specific case of software agents, the code for one agent may be completed and committed before that of another agent.",
                "Such models are synonymously referred to as leadership, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "Specifically, if commitment to mixed strategies is possible, then (optimal) commitment never hurts the leader, and often helps.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we studied how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "For normal-form games, we showed that the optimal pure strategy to commit to can be found efficiently for any number of players.",
                "An optimal mixed strategy to commit to in a normal-form game can be found efficiently for two players using linear programming (and no more efficiently than that, in the sense that any linear program with a probability constraint can be encoded as such a problem). (This is a generalization of the polynomial-time computability of minimax strategies in normal-form games.)",
                "The problem becomes NP-hard for three (or more) players.",
                "In Bayesian games, the problem of finding an optimal pure strategy to commit to is NP-hard even in two-player games in which the follower has only a single type, although two-player games in which the leader has only a single type can be solved efficiently.",
                "The problem of finding an optimal mixed strategy to commit to in a Bayesian game is NP-hard even in two-player games in which the leader has only a single type, although two-player games in which the follower has only a single type can be solved efficiently using a generalization of the linear progamming approach for normal-form games.",
                "The following two tables summarize these results. 2 players ≥ 3 players normal-form O(#outcomes) O(#outcomes· #players) Bayesian, O(#outcomes· NP-hard 1-type leader #types) Bayesian, NP-hard NP-hard 1-type follower Bayesian (general) NP-hard NP-hard Results for commitment to pure strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.) 88 2 players ≥ 3 players normal-form one LP-solve per NP-hard follower action Bayesian, NP-hard NP-hard 1-type leader Bayesian, one LP-solve per NP-hard 1-type follower follower action Bayesian (general) NP-hard NP-hard Results for commitment to mixed strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.)",
                "Future research can take a number of directions.",
                "First, we can empirically evaluate the techniques presented here on test suites such as GAMUT [19].",
                "We can also study the computation of optimal strategies to commit to in other1 concise representations of normal-form games-for example, in graphical games [10] or local-effect/action graph games [14, 1].",
                "For the cases where computing an optimal strategy to commit to is NP-hard, we can also study the computation of approximately optimal strategies to commit to.",
                "While the correct definition of an approximately optimal strategy is in this setting may appear simple at first-it should be a strategy that, if the following players play optimally, performs almost as well as the optimal strategy in expectation-this definition becomes problematic when we consider that the other players may also be playing only approximately optimally.",
                "One may also study models in which multiple (but not all) players commit at the same time.",
                "Another interesting direction to pursue is to see if computing optimal mixed strategies to commit to can help us in, or otherwise shed light on, computing Nash equilibria.",
                "Often, optimal mixed strategies to commit to are also Nash equilibrium strategies (for example, in two-player zero-sum games this is always true), although this is not always the case (for example, as we already pointed out, sometimes the optimal strategy to commit to is a strictly dominated strategy, which can never be a Nash equilibrium strategy). 5.",
                "REFERENCES [1] N. A. R. Bhat and K. Leyton-Brown.",
                "Computing Nash equilibria of action-graph games.",
                "In Proceedings of the 20th Annual Conference on Uncertainty in Artificial Intelligence (UAI), Banff, Canada, 2004. [2] V. Conitzer and T. Sandholm.",
                "Complexity results about Nash equilibria.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pages 765-771, Acapulco, Mexico, 2003. [3] V. Conitzer and T. Sandholm.",
                "Complexity of (iterated) dominance.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 88-97, Vancouver, Canada, 2005. [4] V. Conitzer and T. Sandholm.",
                "A generalized strategy eliminability criterion and computational methods for applying it.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 483-488, Pittsburgh, PA, USA, 2005. [5] A.",
                "A. Cournot.",
                "Recherches sur les principes math´ematiques de la th´eorie des richesses (Researches 1 Bayesian games are one potentially concise representation of normal-form games. into the Mathematical Principles of the Theory of Wealth).",
                "Hachette, Paris, 1838. [6] G. Dantzig.",
                "A proof of the equivalence of the programming problem and the game problem.",
                "In T. Koopmans, editor, Activity Analysis of Production and Allocation, pages 330-335.",
                "John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel.",
                "The complexity of eliminating dominated strategies.",
                "Mathematics of Operation Research, 18:553-565, 1993. [8] I. Gilboa and E. Zemel.",
                "Nash and correlated equilibria: Some complexity considerations.",
                "Games and Economic Behavior, 1:80-93, 1989. [9] R. Karp.",
                "Reducibility among combinatorial problems.",
                "In R. E. Miller and J. W. Thatcher, editors, Complexity of Computer Computations, pages 85-103.",
                "Plenum Press, NY, 1972. [10] M. Kearns, M. Littman, and S. Singh.",
                "Graphical models for <br>game theory</br>.",
                "In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou, and J. N. Tsitsiklis.",
                "A note on strategy elimination in bimatrix games.",
                "Operations Research Letters, 7(3):103-107, 1988. [12] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [14] K. Leyton-Brown and M. Tennenholtz.",
                "Local-effect games.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), Acapulco, Mexico, 2003. [15] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 36-41, San Diego, CA, 2003. [16] M. Littman and P. Stone.",
                "A polynomial-time Nash equilibrium algorithm for repeated games.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 48-54, San Diego, CA, 2003. [17] R. D. Luce and H. Raiffa.",
                "Games and Decisions.",
                "John Wiley and Sons, New York, 1957.",
                "Dover republication 1989. [18] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown, and Y. Shoham.",
                "Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms.",
                "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), New York, NY, USA, 2004. [20] M. J. Osborne and A. Rubinstein.",
                "A Course in <br>game theory</br>.",
                "MIT Press, 1994. [21] C. Papadimitriou.",
                "Algorithms, games and the Internet.",
                "In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 749-753, 2001. 89 [22] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 664-669, San Jose, CA, USA, 2004. [23] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 495-501, Pittsburgh, PA, USA, 2005. [24] J. von Neumann.",
                "Zur Theorie der Gesellschaftsspiele.",
                "Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg.",
                "Marktform und Gleichgewicht.",
                "Springer, Vienna, 1934. [26] B. von Stengel and S. Zamir.",
                "Leadership with commitment to mixed strategies.",
                "CDAM Research Report LSE-CDAM-2004-01, London School of Economics, Feb. 2004. 90"
            ],
            "original_annotated_samples": [
                "To analyze how an agent should behave in such settings, the tools of <br>game theory</br> need to be applied.",
                "Typically, when a strategic setting is modeled in the framework of <br>game theory</br>, it is assumed that players choose their strategies simultaneously.",
                "Graphical models for <br>game theory</br>.",
                "A Course in <br>game theory</br>."
            ],
            "translated_annotated_samples": [
                "Para analizar cómo un agente debería comportarse en tales situaciones, es necesario aplicar las herramientas de la <br>teoría de juegos</br>.",
                "Normalmente, cuando se modela un escenario estratégico en el marco de la <br>teoría de juegos</br>, se asume que los jugadores eligen sus estrategias de forma simultánea.",
                "Modelos gráficos para <br>teoría de juegos</br>.",
                "Un curso de <br>teoría de juegos</br>."
            ],
            "translated_text": "En sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias simultáneamente. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. El reciente aumento en el interés por las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas a comprometerse tanto en el compromiso de estrategias puras como en el compromiso de estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Ofrecemos tanto resultados positivos (algoritmos eficientes) como resultados negativos (resultados de NP-hardness). Categorías y Descriptores de Asignaturas J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas Términos Generales Algoritmos, Economía, Teoría 1. En sistemas multiagentes con agentes auto-interesados (incluyendo la mayoría de los entornos económicos), la acción óptima que un agente debe tomar depende de las acciones que tomen los otros agentes. Para analizar cómo un agente debería comportarse en tales situaciones, es necesario aplicar las herramientas de la <br>teoría de juegos</br>. Normalmente, cuando se modela un escenario estratégico en el marco de la <br>teoría de juegos</br>, se asume que los jugadores eligen sus estrategias de forma simultánea. Esto es especialmente cierto cuando el escenario se modela como un juego en forma normal, que solo especifica la utilidad de cada agente como una función del vector de estrategias que los agentes eligen, y no proporciona información sobre el orden en que los agentes toman sus decisiones y lo que los agentes observan sobre las decisiones anteriores de otros agentes. Dado que el juego está modelado en forma normal, típicamente se analiza utilizando el concepto de equilibrio de Nash. Un equilibrio de Nash especifica una estrategia para cada jugador, de modo que ningún jugador tenga un incentivo para desviarse individualmente de este perfil de estrategias. (Por lo general, se permite que las estrategias sean mixtas, es decir, distribuciones de probabilidad sobre las estrategias originales (puras).) Un equilibrio de Nash (de estrategia mixta) está garantizado de existir en juegos finitos [18], pero un problema es que puede haber múltiples equilibrios de Nash. Esto conduce al problema de selección de equilibrio de cómo un agente puede saber qué estrategia jugar si no sabe qué equilibrio se va a jugar. Cuando el escenario se modela como un juego de forma extensiva, es posible especificar que algunos jugadores reciben información sobre las acciones tomadas por otros antes en el juego antes de decidir su acción. Sin embargo, en general, los jugadores no saben todo lo que sucedió anteriormente en el juego. Por lo tanto, estos juegos suelen ser analizados todavía utilizando un concepto de equilibrio, donde se especifica una estrategia mixta para cada jugador, y se requiere que la estrategia de cada jugador sea una mejor respuesta a las estrategias de los demás. (Normalmente se impone ahora una restricción adicional en las estrategias para garantizar que los jugadores no jueguen de una manera irracional con respecto a la información que han recibido hasta el momento). Esto conduce a refinamientos del equilibrio de Nash como el equilibrio perfecto en subjuegos y el equilibrio secuencial. Sin embargo, en muchos entornos del mundo real, las estrategias no se seleccionan de manera simultánea. A menudo, un jugador (el líder) puede comprometerse con una estrategia antes que otro jugador (el seguidor). Esto puede deberse a una variedad de razones. Por ejemplo, uno de los jugadores puede llegar al lugar donde se jugará el juego antes que otro agente (por ejemplo, en entornos económicos, un jugador puede ingresar al mercado antes y comprometerse con una forma de hacer negocios). Un compromiso tan poderoso tiene un impacto profundo en cómo debería jugarse el juego. Por ejemplo, el líder puede estar mejor jugando una estrategia que esté dominada en la representación de forma normal del juego. Quizás el ejemplo más temprano y conocido del efecto del compromiso es el de von Stackelberg [25], quien demostró que, en el modelo de duopolio de Cournot [5], si una empresa puede comprometerse con una cantidad de producción primero, esa empresa lo hará mucho mejor que en la solución de movimiento simultáneo (Nash). En general, si es posible comprometerse con estrategias mixtas, entonces (bajo suposiciones menores) nunca perjudica, y a menudo ayuda, comprometerse con una estrategia [26]. Verse obligado a comprometerse con una estrategia pura a veces ayuda y a veces perjudica (por ejemplo, comprometerse con una estrategia pura en piedra-papel-tijeras antes de la decisión de los otros jugadores naturalmente resultará en una derrota). En este documento, asumiremos que el compromiso siempre es forzado; si no lo es, el jugador que tiene la opción de comprometerse simplemente puede comparar el resultado del compromiso con el resultado de no comprometerse (movimiento simultáneo). Los modelos de liderazgo son especialmente importantes en entornos con múltiples agentes de software con intereses propios. Una vez que el código de un agente (o de un equipo de agentes) está finalizado y el agente es desplegado, el agente se compromete a jugar la estrategia (posiblemente aleatoria) que el código prescribe. Por lo tanto, siempre y cuando se pueda demostrar de manera creíble que no se puede cambiar el código más tarde, el código funciona como un dispositivo de compromiso. Esto es válido para torneos recreativos entre agentes (por ejemplo, torneos de póker, RoboSoccer) y para aplicaciones industriales como redes de sensores. Finalmente, también existe una situación de liderazgo implícito en el campo del diseño de mecanismos, en la cual un jugador (el diseñador) tiene la oportunidad de elegir las reglas del juego que los demás jugadores luego siguen. El diseño de mecanismos es un tema extremadamente importante para la comunidad de EC: los artículos publicados sobre diseño de mecanismos en las recientes conferencias de EC son demasiados para citar. De hecho, el diseñador del mecanismo puede beneficiarse al comprometerse con una elección que, si las acciones de los agentes (restantes) estuvieran fijas, sería subóptima. Por ejemplo, en una subasta (a precio fijo), el vendedor puede desear establecer un precio de reserva positivo (artificial) para el artículo, por debajo del cual el artículo no se venderá, incluso si el vendedor valora el artículo en 0. En retrospectiva (después de recibir las ofertas), esto (ingenuamente) parece subóptimo: si llegaba una oferta que superaba el precio de reserva, el precio de reserva no tenía efecto, y si no llegaba tal oferta, el vendedor hubiera estado mejor aceptando una oferta más baja. Por supuesto, la razón para establecer el precio de reserva es incentivar a los postores a ofertar más alto, y debido a esto, establecer precios de reserva artificiales puede aumentar realmente los ingresos esperados para el vendedor. Recientemente se ha dedicado una cantidad significativa de investigación al cálculo de soluciones de acuerdo con varios conceptos de solución para escenarios en los que los agentes eligen sus estrategias simultáneamente, como la dominancia [7, 11, 3] y (especialmente) el equilibrio de Nash [8, 21, 16, 15, 2, 22, 23, 4]. Sin embargo, se ha ignorado el cálculo de la estrategia óptima a comprometerse en una situación de liderazgo. Teóricamente, las situaciones de liderazgo simplemente pueden ser consideradas como un juego de forma extensiva en el que un jugador elige una estrategia (para el juego original) primero. El número de estrategias en este juego de forma extensiva, sin embargo, puede ser extremadamente grande. Por ejemplo, si el líder es capaz de comprometerse con una estrategia mixta en el juego original, entonces cada una de las estrategias mixtas (continuo de) constituye una estrategia pura en la representación de forma extensiva de la situación de liderazgo. (Se destaca que un compromiso con una distribución no es lo mismo que una distribución sobre compromisos). Además, si el juego original es en sí mismo un juego de forma extensiva, el número de estrategias en la representación de forma extensiva de la situación de liderazgo (que es un juego de forma extensiva diferente) se vuelve aún más grande. Por lo tanto, generalmente no es factible computacionalmente simplemente transformar el juego original en la representación de forma extensiva de la situación de liderazgo; en su lugar, debemos analizar el juego en su representación original. En este artículo, estudiamos cómo calcular la estrategia óptima a comprometerse, tanto en juegos de forma normal (Sección 2) como en juegos bayesianos, que son un caso especial de juegos de forma extensiva (Sección 3). JUEGOS EN FORMA NORMAL En esta sección, estudiamos cómo calcular la estrategia óptima a comprometerse para juegos representados en forma normal. 2.1 Definiciones En un juego en forma normal, cada jugador i ∈ {1, . . . , n} tiene un conjunto de estrategias puras (o acciones) Si, y una función de utilidad ui : S1×S2×. . .×Sn → R que mapea cada resultado (un vector que consiste en una estrategia pura para cada jugador, también conocido como un perfil de estrategias puras) a un número real. Para facilitar la notación, en el caso de dos jugadores, nos referiremos al conjunto de estrategias puras del jugador 1 como S, y al conjunto de estrategias puras del jugador 2 como T. Estos juegos pueden representarse en forma de matriz (bi-matriz), en la que las filas corresponden a las estrategias puras del jugador 1, las columnas corresponden a las estrategias puras del jugador 2, y las entradas de la matriz dan las utilidades de los jugadores de fila y columna (en ese orden) para el resultado correspondiente del juego. En el caso de tres jugadores, usaremos R, S y T, para las estrategias puras de los jugadores 1, 2 y 3, respectivamente. Una estrategia mixta para un jugador es una distribución de probabilidad sobre las estrategias puras de ese jugador. En el caso de juegos de dos jugadores, nos referiremos al jugador 1 como el líder y al jugador 2 como el seguidor. Antes de definir estrategias de liderazgo óptimas, considera el siguiente juego que ilustra el efecto de la capacidad del líder para comprometerse. 2, 1 4, 0 1, 0 3, 1 En esta representación en forma normal, la estrategia inferior para el jugador de la fila está estrictamente dominada por la estrategia superior. Sin embargo, si el jugador de la fila tiene la capacidad de comprometerse con una estrategia pura antes de que el jugador de la columna elija su estrategia, el jugador de la fila debería comprometerse con la estrategia inferior: al hacerlo, el jugador de la columna preferirá jugar la estrategia correcta, lo que llevará a una utilidad de 3 para el jugador de la fila. Por el contrario, si el jugador de la fila se comprometiera con la estrategia superior, el jugador de la columna preferiría jugar la estrategia izquierda, lo que llevaría a una utilidad de solo 2 para el jugador de la fila. Si el jugador de la fila puede comprometerse a una estrategia mixta, entonces puede obtener una utilidad aún mayor (esperada): si el jugador de la fila se compromete a colocar una probabilidad p > 1/2 en la estrategia inferior, entonces el jugador de la columna seguirá prefiriendo jugar la estrategia derecha, y la utilidad esperada de los jugadores de la fila será 3p + 4(1 − p) = 4 − p ≥ 3. Si el jugador de la fila juega cada estrategia con una probabilidad exacta de 1/2, el jugador de la columna está 83 indiferente entre las estrategias. En tales casos, asumiremos que el jugador de la columna elegirá la estrategia que maximiza la utilidad de los jugadores de la fila (en este caso, la estrategia correcta). Por lo tanto, la estrategia mixta óptima a la que debe comprometerse el jugador de la fila es p = 1/2. Hay algunas buenas razones para esta suposición. Si asumiéramos lo contrario, entonces no existiría una estrategia óptima para el jugador de la fila en el juego de ejemplo: el jugador de la fila jugaría la estrategia inferior con una probabilidad p = 1/2 + con > 0, y cuanto menor sea , mejor será la utilidad para el jugador de la fila. Por el contrario, si asumimos que el seguidor siempre rompe los empates a favor de los líderes, entonces siempre existe una estrategia mixta óptima para el líder, lo que corresponde a un equilibrio perfecto en subjuegos de la representación en forma extensiva de la situación de liderazgo. En cualquier caso, esta es una suposición estándar para tales modelos (por ejemplo, [20]), aunque algunos trabajos han investigado lo que puede suceder en los otros equilibrios perfectos de subjuego [26]. (Para juegos genéricos de dos jugadores, el pago del equilibrio perfecto de subjuego de los líderes es único). Además, la misma suposición se utiliza típicamente en el diseño de mecanismos, asumiendo que si un agente es indiferente entre revelar sus preferencias de manera veraz o falsa, las reportará de manera veraz. Dado este supuesto, podemos hacer referencia de manera segura a estrategias de liderazgo óptimas en lugar de tener que utilizar alguna noción de equilibrio. Por lo tanto, para los propósitos de este documento, una estrategia óptima a comprometerse en un juego de 2 jugadores es una estrategia s ∈ S que maximiza maxt∈BR(s) ul(s, t), donde BR(s) = arg maxt∈T uf (s, t). (ul y uf son las funciones de utilidad del líder y los seguidores, respectivamente). Podemos tener S = S para el caso de compromiso con estrategias puras, o S = ∆(S), el conjunto de distribuciones de probabilidad sobre S, para el caso de compromiso con estrategias mixtas. (Observamos que reemplazar T por ∆(T) no hace ninguna diferencia en esta definición). Para juegos con más de dos jugadores, en los que los jugadores se comprometen con sus estrategias en secuencia, definimos estrategias óptimas a las que comprometerse de forma recursiva. Después de que el líder se compromete con una estrategia, el juego que jugarán los agentes restantes es en sí mismo un juego de liderazgo (más pequeño). Por lo tanto, definimos una estrategia óptima a comprometerse como una estrategia que maximiza la utilidad del líder, asumiendo que el juego de los agentes restantes es óptimo bajo esta definición, y maximiza la utilidad del líder entre todas las formas óptimas de jugar el juego restante. Nuevamente, el compromiso con estrategias mixtas puede o no ser una posibilidad para cada jugador (aunque para el último jugador no importa si permitimos el compromiso con estrategias mixtas). 2.2 Compromiso con estrategias puras. Primero estudiamos cómo calcular la estrategia pura óptima a la que comprometerse. Esto es relativamente simple, porque el número de estrategias a comprometer no es muy grande. (En lo siguiente, #resultados es el número de perfiles de estrategia completos). Teorema 1. Bajo el compromiso de estrategias puras, el conjunto de todos los perfiles de estrategia óptimos en un juego en forma normal se puede encontrar en tiempo O(#jugadores · #resultados). Prueba. Cada estrategia pura a la que el primer jugador pueda comprometerse inducirá un subjuego para los jugadores restantes. Podemos resolver cada subjuego de esta manera de forma recursiva para encontrar todos sus perfiles de estrategia óptimos; cada uno de estos le dará al líder original cierta utilidad. Aquellos que proporcionan al líder la utilidad máxima corresponden exactamente a los perfiles de estrategia óptimos del juego original. Ahora presentamos el algoritmo de forma formal. Sea Su(G, s1) el subjuego que resulta después de que el primer jugador restante en G juega s1 ∈ SG 1. Un juego con 0 jugadores es simplemente un resultado del juego. La función Append(s, O) añade la estrategia s a cada uno de los vectores de estrategias en el conjunto O. Sea e el vector vacío sin elementos. En un ligero abuso de notación, escribiremos uG 1 (C) cuando todos los perfiles estratégicos en el conjunto C le den al jugador 1 la misma utilidad en el juego G. (Aquí, el jugador 1 es el primer jugador restante en el subjuego G, no necesariamente el jugador 1 en el juego original). Observamos que arg max es un conjunto de valores. Entonces, el siguiente algoritmo calcula todos los perfiles de estrategia óptimos: Algoritmo Resolver(G) si G tiene 0 jugadores, devuelve {e} C ← ∅ para todo s1 ∈ SG 1 { O ← Resolver(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) si C = ∅ o uG 1 (s1, O ) = uG 1 (C) C ← C∪Agregar(s1, O ) si uG 1 (s1, O ) > uG 1 (C) C ←Agregar(s1, O ) } devuelve C Cada resultado es examinado (potencialmente) por cada jugador, lo que lleva al límite de tiempo dado. Como ejemplo de cómo funciona el algoritmo, considera el siguiente juego de 3 jugadores, en el que el primer jugador elige la matriz izquierda o derecha, el segundo jugador elige una fila y el tercer jugador elige una columna. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 Primero eliminamos los resultados que no corresponden a las mejores respuestas para el tercer jugador (eliminándolos de la matriz): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Luego, eliminamos las entradas en las que el tercer jugador no resuelve los empates a favor del segundo jugador, así como las entradas que no corresponden a las mejores respuestas para el segundo jugador. 0,1,1 2,1,1 1,1,1 0,5,1 Finalmente, eliminamos las entradas en las que el segundo y tercer jugador no resuelven los empates a favor del primer jugador, así como las entradas que no corresponden a las mejores respuestas para el primer jugador. 2,1,1 Por lo tanto, en el juego óptimo, el primer jugador elige la matriz izquierda, el segundo jugador elige la fila del medio y el tercer jugador elige la columna izquierda. (Notamos que este resultado está dominado por Pareto por (Derecha, Medio, Izquierda).) Para juegos en forma normal general, la utilidad de cada jugador para cada uno de los resultados debe representarse explícitamente en la entrada, de modo que el tamaño de la entrada sea en sí mismo Ω(#jugadores · #resultados). Por lo tanto, el algoritmo es de hecho un algoritmo de tiempo lineal. 2.3 Compromiso con estrategias mixtas En el caso especial de juegos de dos jugadores de suma cero, calcular una estrategia mixta óptima para que el líder se comprometa es equivalente a calcular una estrategia minimax, que minimiza la utilidad esperada máxima que el oponente puede obtener. Las estrategias minimax constituyen el único concepto de solución natural para juegos de suma cero de dos jugadores: el Teorema Minimax de von Neumann [24] establece que en juegos de suma cero de dos jugadores, no importa (en términos de las utilidades de los jugadores) qué jugador se compromete primero a una estrategia mixta, y un perfil de estrategias mixtas es un equilibrio de Nash si y solo si ambas estrategias son estrategias minimax. Es bien sabido que una estrategia minimax se puede encontrar en tiempo polinómico, utilizando programación lineal [17]. Nuestro primer resultado en esta sección generaliza este resultado, mostrando que una estrategia mixta óptima para que el líder se comprometa puede ser calculada eficientemente en juegos de dos jugadores de suma general, nuevamente utilizando programación lineal. Teorema 2. En juegos de forma normal de 2 jugadores, una estrategia mixta óptima a la que comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal. Prueba. Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder de modo que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad del líder. Un programa lineal simple puede calcular una estrategia mixta como la siguiente: maximizar s∈S psul(s, t) sujeto a que para todo t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1. Se destaca que este programa puede ser inviable para algunas estrategias seguidoras t, por ejemplo, si t es una estrategia estrictamente dominada. Sin embargo, el programa debe ser factible para al menos algunas estrategias seguidoras; entre estas estrategias seguidoras, elige una estrategia t∗ que maximice el valor de la solución de los programas lineales. Entonces, si la líder elige como su estrategia mixta los ajustes óptimos de las variables ps para el programa lineal para t∗, y el seguidor juega t∗, esto constituye un perfil de estrategia óptimo. En el siguiente resultado, demostramos que no podemos esperar resolver el problema de manera más eficiente que la programación lineal, ya que podemos reducir cualquier programa lineal con una restricción de probabilidad en sus variables a un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores. Teorema 3. Cualquier programa lineal cuyas variables xi (con xi ∈ R≥0) deben satisfacer i xi = 1 puede ser modelado como un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores. Prueba. Que el líder tenga una estrategia pura i para cada variable xi. Que el jugador de la columna tenga una estrategia pura j para cada restricción en el programa lineal (distinta de i xi = 1), y una única estrategia pura adicional 0. Que las funciones de utilidad sean las siguientes. Escribiendo el objetivo del programa lineal como maximizar ci xi, para cualquier i, dejando ul(i, 0) = ci y uf(i, 0) = 0. Escribiendo la j-ésima restricción del programa lineal (sin incluir i xi = 1) como i aijxi ≤ bj, para cualquier i, j > 0, sea ul(i, j) = mini ci − 1 y uf(i, j) = aij − bj. Por ejemplo, considera el siguiente programa lineal. maximizar 2x1 + x2 sujeto a x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 La solución óptima de este programa es x1 = 1/3, x2 = 2/3. Nuestra reducción transforma este programa en el siguiente juego de líder-seguidor (donde el líder es el jugador de la fila). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 De hecho, la estrategia óptima para el líder es jugar la estrategia superior con una probabilidad de 1/3 y la estrategia inferior con una probabilidad de 2/3. Ahora demostramos que la reducción funciona en general. Claramente, el líder quiere incentivar al seguidor a jugar 0, porque la utilidad que el líder obtiene cuando el seguidor juega 0 siempre es mayor que cuando el seguidor no juega 0. Para que el seguidor no prefiera jugar j > 0 en lugar de 0, debe ser el caso que i pl(i)(aij − bj) ≤ 0, o equivalentemente i pl(i)aij ≤ bj. Por lo tanto, el líder obtendrá una utilidad de al menos mini ci si y solo si hay una solución factible a las restricciones. Dado que el pl(i) incentiva al seguidor a jugar 0, el líder intenta maximizar i pl(i)ci. Por lo tanto, el líder debe resolver el programa lineal original. Como prueba alternativa del Teorema 3, se puede observar que se sabe que encontrar una estrategia minimax en un juego de suma cero es tan difícil como el problema de programación lineal [6], y como señalamos al principio de esta sección, calcular una estrategia minimax en un juego de suma cero es un caso especial del problema de calcular una estrategia mixta óptima a la que comprometerse. La solubilidad en tiempo polinómico del problema de calcular una estrategia mixta óptima a la que comprometerse en juegos de forma normal de dos jugadores contrasta con la complejidad desconocida de calcular un equilibrio de Nash en tales juegos [21], así como con la NP-dificultad de encontrar un equilibrio de Nash con utilidad máxima para un jugador dado en tales juegos [8, 2]. Desafortunadamente, este resultado no se generaliza a más de dos jugadores; aquí, el problema se vuelve NP-duro. Para demostrar esto, reducimos desde el problema de CUBRIR-VÉRTICES. Definición 1. En VERTEX-COVER, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que cada arista e ∈ E tenga al menos uno de sus extremos en S. BALANCED-VERTEX-COVER es el caso especial de VERTEX-COVER en el que K = |V|/2. VERTEX-COVER es NP-completo [9]. El siguiente lema muestra que la dificultad persiste si requerimos K = |V|/2. (Resultados similares se han demostrado para otros problemas NP-completos). Lema 1. El problema de la COBERTURA DE VÉRTICES EQUILIBRADA es NP-completo. Prueba. La pertenencia a NP se deriva del hecho de que el problema es un caso especial de CUBRIMIENTO DE VÉRTICES, que está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES a una instancia de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO, de la siguiente manera. Si, para la instancia de CUBRIMIENTO DE VÉRTICES, K > |V|/2, simplemente agregamos vértices aislados que estén disjuntos del resto del grafo, hasta que K = |V|/2. Si K < |V|/2, agregamos triángulos aislados (es decir, el grafo completo de tres vértices) al grafo, aumentando K en 2 cada vez, hasta que K = |V|/2. Teorema 4. En juegos de forma normal de 3 jugadores, encontrar una estrategia mixta óptima a la que comprometerse es NP-difícil. Prueba. Reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO al siguiente juego de forma normal de 3 jugadores. Para cada vértice v, cada uno de los tres jugadores tiene una estrategia pura correspondiente a ese vértice (rv, sv, tv, respectivamente). Además, para cada arista e, el tercer jugador tiene una estrategia pura te; y finalmente, el tercer jugador tiene una estrategia pura adicional t0. Los servicios son los siguientes: • para todo r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • para todo r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • para todo v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • para todo v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • para todo v ∈ V, para todo r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V| |V|−2; • para todo e ∈ E, s ∈ S, para ambos v ∈ e, u3(rv, s, te) = 0; • para todo e ∈ E, s ∈ S, para todo v /∈ e, u3(rv, s, te) = |V| |V|−2. • para todo r ∈ R, s ∈ S, u3(r, s, t0) = 1. Observamos que los jugadores 1 y 2 tienen la misma función de utilidad. Sostenemos que existe un perfil de estrategia óptimo en el que los jugadores 1 y 2 obtienen ambos 1 (su utilidad máxima) si y solo si hay una solución al problema de la COBERTURA DE VÉRTICES EQUILIBRADA. (De lo contrario, estos jugadores obtendrán ambos 0). Primero, supongamos que existe una solución al problema de la cubierta de vértices balanceada. Entonces, deja que el jugador 1 juegue cada rv de manera que v esté en la cobertura con probabilidad 2 |V|, y deja que el jugador 2 juegue cada sv de manera que v no esté en la cobertura con probabilidad 2 |V|. Entonces, para el jugador 3, la utilidad esperada de jugar tv (para cualquier v) es (1 − 2 |V|) |V| |V|−2 = 1, porque hay una probabilidad de 2 |V| de que se juegue rv o sv. Además, la utilidad esperada de jugar te (para cualquier e) es a lo sumo (1 − 2 |V | ) |V | |V |−2 = 1, porque hay una probabilidad de al menos 2 |V | de que algún rv con v ∈ e se juegue (debido a que el jugador 1 está aleatorizando sobre las estrategias puras correspondientes a la cobertura). Se deduce que jugar t0 es la mejor respuesta para el jugador 3, otorgando a los jugadores 1 y 2 una utilidad de 1. Ahora, supongamos que los jugadores 1 y 2 obtienen 1 en el juego óptimo. Entonces, debe ser el caso de que el jugador 3 juegue t0. Por lo tanto, para cada v ∈ V, debe haber una probabilidad de al menos 2 |V| de que se juegue rv o sv, de lo contrario, al jugador 3 le convendría más jugar tv. Dado que los jugadores 1 y 2 solo tienen una probabilidad total de 2 para distribuir, debe ser el caso que para cada v, ya sea rv o sv se juegue con una probabilidad de 2 |V|, y el otro se juegue con una probabilidad de 0. (No es posible que ambos tengan una probabilidad distinta de cero, porque entonces habría alguna probabilidad de que ambos se jugaran simultáneamente (la correlación no es posible), por lo tanto, la probabilidad total de que al menos uno se juegue no podría ser lo suficientemente alta para todos los vértices). Por lo tanto, para exactamente la mitad de los v ∈ V, el jugador 1 coloca una probabilidad de 2 |V| en rv. Además, para cada e ∈ E, debe haber una probabilidad de al menos 2 |V | de que se juegue algún rv con v ∈ e, de lo contrario, al jugador 3 le convendría más jugar te. Por lo tanto, el v ∈ V tal que el jugador 1 coloca una probabilidad de 2 |V | en rv constituye una cubierta de vértices equilibrada. 3. Juegos bayesianos. Hasta ahora, hemos restringido nuestra atención a los juegos en forma normal. En un juego en forma normal, se asume que cada agente conoce las preferencias de todos los demás agentes sobre los resultados del juego. En general, sin embargo, los agentes pueden tener información privada sobre sus preferencias que no es conocida por los otros agentes. Además, en el momento de comprometerse con una estrategia, los agentes pueden ni siquiera conocer sus propias preferencias (finales) sobre los resultados del juego aún, ya que estas preferencias pueden depender de un contexto que aún no se ha materializado. Por ejemplo, cuando se escribe el código para un agente de negociación, puede que aún no esté claro cómo ese agente valorará los recursos sobre los que negociará más adelante, porque esto depende de información que aún no está disponible en el momento en que se escribe el código (como órdenes que habrán sido colocadas al agente antes de la negociación). En esta sección, estudiaremos el compromiso en juegos bayesianos, los cuales pueden modelar tal incertidumbre sobre preferencias. 3.1 Definiciones En un juego bayesiano, cada jugador i tiene un conjunto de acciones Si, un conjunto de tipos Θi con una distribución de probabilidad asociada πi : Θi → [0, 1], y, para cada tipo θi, una función de utilidad uθi i : S1 × S2 × . . . × Sn → R. Una estrategia pura en un juego bayesiano es una asignación de los tipos de los jugadores a acciones, σi : Θi → Si. (Los juegos bayesianos pueden ser reescritos en forma normal enumerando cada estrategia pura σi, pero esto causará un crecimiento exponencial en el tamaño de la representación del juego y por lo tanto no puede llevar a algoritmos eficientes). La estrategia a la que el líder debería comprometerse depende de si, en el momento del compromiso, el líder conoce su propio tipo. Si la líder conoce su propio tipo, los otros tipos que la líder podría haber tenido se vuelven irrelevantes y la líder simplemente debería comprometerse con la estrategia que sea óptima para ese tipo. Sin embargo, como se argumentó anteriormente, la líder no necesariamente conoce su propio tipo en el momento de comprometerse (por ejemplo, en el momento en que se envía el código). En este caso, el líder debe comprometerse con una estrategia que dependa en un 86% del tipo eventual del líder. Estudiaremos este último modelo, aunque prestaremos atención específica al caso en el que el líder tiene un solo tipo, lo cual es efectivamente lo mismo que el modelo anterior. 3.2 Compromiso con estrategias puras Resulta que calcular una estrategia pura óptima a la que comprometerse es difícil en juegos bayesianos, incluso con dos jugadores. Teorema 5. Encontrar una estrategia pura óptima a comprometerse en juegos bayesianos de 2 jugadores es NP-difícil, incluso cuando el seguidor tiene solo un tipo. Prueba. Reducimos una instancia arbitraria de CUBRIMIENTO DE VÉRTICES al siguiente juego bayesiano entre el líder y el seguidor. El líder tiene K tipos θ1, θ2, . . . , θK, cada uno ocurriendo con probabilidad 1/K, y para cada vértice v ∈ V, el líder tiene una acción sv. El seguidor tiene solo un tipo; para cada borde e ∈ E, el seguidor tiene una acción te, y el seguidor tiene una acción adicional única t0. La función de utilidad para el líder está dada por, para todo θl ∈ Θl y todo s ∈ S, u θl l (s, t0) = 1, y para todo e ∈ E, u θl l (s, te) = 0. La utilidad de los seguidores se da por: • Para todo v ∈ V, para todo e ∈ E con v /∈ e, uf (sv, te) = 1; • Para todo v ∈ V, para todo e ∈ E con v ∈ e, uf (sv, te) = −K; • Para todo v ∈ V, uf (sv, t0) = 0. Sostenemos que el líder puede obtener una utilidad de 1 si y solo si hay una solución para la instancia de CUBRIMIENTO-DE-VÉRTICES. Primero, supongamos que hay una solución para la instancia de CUBRIRVÉRTICES. Entonces, el líder puede comprometerse con una estrategia pura tal que para cada vértice v en la cobertura, el líder juega sv para algún tipo. Entonces, la utilidad de los seguidores para jugar te (para cualquier e ∈ E) es a lo sumo K−1 K + 1 K (−K) = − 1 K , por lo que el seguidor preferirá jugar t0, lo que le da al líder una utilidad de 1, como se requiere. Ahora, supongamos que hay una estrategia pura para el líder que le dará al líder una utilidad de 1. Entonces, el seguidor debe jugar t0. Para que el seguidor no prefiera jugar te (para cualquier e ∈ E) en su lugar, al menos para un v ∈ e, el líder debe jugar sv para algún tipo θl. Por lo tanto, el conjunto de vértices v que el líder juega para algún tipo debe constituir una cubierta de vértices; y este conjunto puede tener un tamaño de como máximo K, ya que el líder solo tiene K tipos. Entonces hay una solución para la instancia de CUBRIMIENTODEVÉRTICES. Sin embargo, si el líder tiene solo un tipo, entonces el problema se vuelve fácil nuevamente (#tipos es el número de tipos para el seguidor): Teorema 6. En juegos bayesianos de 2 jugadores en los que el líder tiene solo un tipo, una estrategia pura óptima a comprometerse puede encontrarse en tiempo O(#resultados · #tipos). Prueba. Para cada acción de líder s, podemos calcular, para cada tipo de seguidor θf ∈ Θf, qué acciones t maximizan la utilidad de los seguidores; llamamos a este conjunto de acciones BRθf (s). Entonces, la utilidad que recibe el líder por comprometerse a la acción s se puede calcular como θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), y el líder puede elegir la mejor acción a la que comprometerse. 3.3 Compromiso con estrategias mixtas En juegos de información imperfecta de suma cero de dos jugadores con memoria perfecta (ningún jugador olvida algo que una vez supo), una estrategia minimax se puede construir en tiempo polinómico [12, 13]. Desafortunadamente, este resultado no se extiende a calcular estrategias mixtas óptimas a comprometerse en el caso de suma general, ni siquiera en juegos bayesianos. Demostraremos la NP-dificultad reduciendo desde el problema de CONJUNTOINDEPENDIENTE. Definición 2. En INDEPENDENT-SET, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que ninguna arista e ∈ E tenga ambos extremos en S. Nuevamente, este problema es NP-completo [9]. Teorema 7. Encontrar una estrategia mixta óptima a comprometerse en juegos bayesianos de 2 jugadores es NP-duro, incluso cuando el líder tiene solo un tipo y el seguidor tiene solo dos acciones. Prueba. Reducimos una instancia arbitraria de CONJUNTO-INDEPENDIENTE al siguiente juego bayesiano entre el líder y el seguidor. El líder tiene solo un tipo, y para cada vértice v ∈ V, el líder tiene una acción sv. El seguidor tiene un tipo θv para cada v ∈ V, que ocurre con una probabilidad de 1 (|E|+1)|V|, y un tipo θe para cada e ∈ E, que ocurre con una probabilidad de 1 |E|+1. El seguidor tiene dos acciones: t0 y t1. La utilidad de los líderes se da por, para todo s ∈ S, ul(s, t0) = 1 y ul(s, t1) = 0. La utilidad de los seguidores se da por: • Para todo v ∈ V, uθv f (sv, t1) = 0; • Para todo v ∈ V y s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • Para todo v ∈ V y s ∈ S, uθv f (s, t0) = 1; • Para todo e ∈ E, s ∈ S, uθe f (s, t0) = 1; • Para todo e ∈ E, para ambos v ∈ e, uθe f (sv, t1) = 2K 3 ; • Para todo e ∈ E, para todo v /∈ e, uθe f (sv, t1) = 0. Sostenemos que una estrategia óptima a comprometerse le otorga al líder una utilidad esperada de al menos |E| |E|+1 + K (|E|+1)|V | si y solo si hay una solución para la instancia de CONJUNTO-INDEPENDIENTE. Primero, supongamos que hay una solución para la instancia de CONJUNTO-INDEPENDIENTE. Entonces, el líder podría comprometerse con la siguiente estrategia: por cada vértice v en el conjunto independiente, jugar el correspondiente sv con una probabilidad de 1/K. Si el seguidor tiene el tipo θe para algún e ∈ E, la utilidad esperada para el seguidor al jugar t1 es a lo sumo 1 K 2K 3 = 2/3, porque hay a lo sumo un vértice v ∈ e tal que sv se juega con probabilidad distinta de cero. Por lo tanto, el seguidor jugará t0 y obtendrá una utilidad de 1. Si el seguidor tiene el tipo θv para algún vértice v en el conjunto independiente, la utilidad esperada para el seguidor al jugar t1 es K−1 K K K−1 = 1, porque el líder juega sv con probabilidad 1/K. Se deduce que el seguidor (quien rompe los empates para maximizar la utilidad de los líderes) jugará t0, lo que también otorga una utilidad de 1 y brinda al líder una mayor utilidad. Por lo tanto, la utilidad esperada de los líderes para esta estrategia es al menos |E| |E|+1 + K (|E|+1)|V |, como se requiere. Ahora, supongamos que hay una estrategia que le da al líder una utilidad esperada de al menos |E| |E|+1 + K (|E|+1)|V |. Entonces, esta estrategia debe inducir al seguidor a jugar t0 siempre que tenga un tipo de la forma θe (porque de lo contrario, la utilidad podría ser a lo sumo |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ). Por lo tanto, no puede ser el caso de que para alguna arista e = (v1, v2) ∈ E, la probabilidad de que el líder juegue uno de sv1 y sv2 sea al menos 2/K, porque entonces la utilidad esperada para el seguidor de jugar t1 cuando tiene el tipo θe sería al menos 2 K 2K 3 = 4/3 > 1. Además, la estrategia debe inducir al seguidor a jugar t0 durante al menos K tipos de la forma θv. Inducir al seguidor a jugar t0 cuando tiene el tipo θv solo se puede lograr jugando sv con una probabilidad de al menos 1/K, lo que le dará al seguidor una utilidad de como máximo K−1 K K K−1 = 1 por jugar t1. Pero entonces, el conjunto de vértices v tales que sv se juega con una probabilidad de al menos 1/K debe constituir un conjunto independiente de tamaño K (porque si hubiera una arista e entre dos de estos vértices, induciría al seguidor a jugar t1 para el tipo θe según lo mencionado anteriormente). Por el contrario, si el seguidor tiene solo un tipo, entonces podemos generalizar el enfoque de programación lineal para juegos en forma normal: Teorema 8. En juegos bayesianos de 2 jugadores en los que el seguidor tiene solo un tipo, una estrategia mixta óptima a comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal. Prueba. Generalizamos el enfoque en el Teorema 2 de la siguiente manera. Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder para cada uno de los tipos de líderes de manera que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad esperada ex ante de los líderes. Para hacerlo, generalizamos el programa lineal de la siguiente manera: maximizar θl∈Θl π(θl) s∈S pθl s uθl l (s, t) sujeto a para todo t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t) para todo θl ∈ Θl, s∈S p θl s = 1 Como en el Teorema 2, la solución para el programa lineal que maximiza el valor de la solución es una estrategia óptima a comprometerse. Esto muestra un contraste interesante entre el compromiso con estrategias puras y el compromiso con estrategias mixtas en juegos bayesianos: para las estrategias puras, el problema se vuelve fácil si el líder tiene solo un tipo (pero no si el seguidor tiene solo un tipo), mientras que para las estrategias mixtas, el problema se vuelve fácil si el seguidor tiene solo un tipo (pero no si el líder tiene solo un tipo). 4. CONCLUSIONES E INVESTIGACIONES FUTURAS En los sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias de forma simultánea. Esto requiere cierta noción de equilibrio (equilibrio de Nash y sus refinamientos), y a menudo conduce al problema de selección de equilibrio: no está claro para cada jugador individual según qué equilibrio debería jugar. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Por ejemplo, un agente puede llegar al sitio del juego (real o virtual) antes que el otro, o, en el caso específico de agentes de software, el código de un agente puede estar completo y comprometido antes que el de otro agente. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. Específicamente, si es posible el compromiso con estrategias mixtas, entonces el compromiso (óptimo) nunca perjudica al líder y a menudo lo beneficia. El reciente aumento del interés en las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas para comprometerse tanto a estrategias puras como a estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Para juegos en forma normal, demostramos que la estrategia pura óptima a comprometerse se puede encontrar eficientemente para cualquier número de jugadores. Una estrategia mixta óptima para comprometerse en un juego en forma normal puede encontrarse eficientemente para dos jugadores utilizando programación lineal (y no más eficientemente que eso, en el sentido de que cualquier programa lineal con una restricción de probabilidad puede ser codificado como tal problema). (Esta es una generalización de la computabilidad en tiempo polinómico de las estrategias minimax en juegos en forma normal). El problema se vuelve NP-duro para tres (o más) jugadores. En los juegos bayesianos, el problema de encontrar una estrategia pura óptima a la que comprometerse es NP-duro incluso en juegos de dos jugadores en los que el seguidor tiene solo un tipo, aunque los juegos de dos jugadores en los que el líder tiene solo un tipo pueden resolverse eficientemente. El problema de encontrar una estrategia mixta óptima a comprometerse en un juego bayesiano es NP-duro incluso en juegos de dos jugadores en los que el líder tiene solo un tipo, aunque los juegos de dos jugadores en los que el seguidor tiene solo un tipo pueden resolverse eficientemente utilizando una generalización del enfoque de programación lineal para juegos en forma normal. Las siguientes dos tablas resumen estos resultados. 2 jugadores ≥ 3 jugadores forma normal O(#resultados) O(#resultados· #jugadores) Bayesiano, O(#resultados· NP-completo 1-tipo líder #tipos) Bayesiano, NP-completo NP-completo 1-tipo seguidor Bayesiano (general) NP-completo NP-completo Resultados para el compromiso con estrategias puras. (Con más de 2 jugadores, el seguidor es el último jugador en comprometerse, el líder es el primero.) 88 2 jugadores ≥ 3 jugadores forma normal una resolución de LP por acción NP-completa del seguidor Bayesiano, NP-completo NP-completo 1-tipo líder Bayesiano, una resolución de LP por acción NP-completa del 1-tipo seguidor Bayesiano (general) NP-completo NP-completo Resultados para el compromiso con estrategias mixtas. (Con más de 2 jugadores, el seguidor es el último jugador en comprometerse, el líder es el primero.) La investigación futura puede tomar varias direcciones. Primero, podemos evaluar empíricamente las técnicas presentadas aquí en conjuntos de pruebas como GAMUT [19]. También podemos estudiar la computación de estrategias óptimas a comprometerse en otras representaciones concisas de juegos en forma normal, por ejemplo, en juegos gráficos [10] o juegos de grafo de efecto local/acción [14, 1]. Para los casos en los que calcular una estrategia óptima para comprometerse es NP-duro, también podemos estudiar la computación de estrategias aproximadamente óptimas para comprometerse. Si bien la definición correcta de una estrategia aproximadamente óptima en este contexto puede parecer simple al principio, debería ser una estrategia que, si los jugadores siguientes juegan de manera óptima, funcione casi tan bien como la estrategia óptima en promedio, esta definición se vuelve problemática cuando consideramos que los otros jugadores también podrían estar jugando solo de manera aproximadamente óptima. Uno también puede estudiar modelos en los que múltiples (pero no todos) jugadores se comprometen al mismo tiempo. Otra dirección interesante a explorar es ver si calcular estrategias mixtas óptimas a las que comprometerse puede ayudarnos, o de alguna manera arrojar luz sobre, el cálculo de equilibrios de Nash. A menudo, las estrategias mixtas óptimas a las que comprometerse también son estrategias de equilibrio de Nash (por ejemplo, en juegos de suma cero de dos jugadores esto siempre es cierto), aunque no siempre es el caso (por ejemplo, como ya señalamos, a veces la estrategia óptima a la que comprometerse es una estrategia estrictamente dominada, que nunca puede ser una estrategia de equilibrio de Nash). 5. REFERENCIAS [1] N. A. R. Bhat y K. Leyton-Brown. Calculando los equilibrios de Nash de juegos de gráficos de acción. En Actas de la 20ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI), Banff, Canadá, 2004. [2] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Actas de la Decimoctava Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 765-771, Acapulco, México, 2003. [3] V. Conitzer y T. Sandholm. Complejidad del dominio (iterado). En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 88-97, Vancouver, Canadá, 2005. [4] V. Conitzer y T. Sandholm. Un criterio de eliminabilidad de estrategias generalizado y métodos computacionales para aplicarlo. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 483-488, Pittsburgh, PA, EE. UU., 2005. [5] A. A. Cournot. Las investigaciones sobre los juegos bayesianos son una representación potencialmente concisa de los juegos en forma normal en los principios matemáticos de la teoría de la riqueza. Hachette, París, 1838. [6] G. Dantzig. Una prueba de la equivalencia del problema de programación y el problema de juego. En T. Koopmans, editor, Análisis de la actividad de producción y asignación, páginas 330-335. John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel. \n\nJohn Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, y E. Zemel. La complejidad de eliminar estrategias dominadas. Matemáticas de la Investigación de Operaciones, 18:553-565, 1993. [8] I. Gilboa y E. Zemel. Nash y equilibrios correlacionados: Algunas consideraciones de complejidad. Juegos y Comportamiento Económico, 1:80-93, 1989. [9] R. Karp. Reductibilidad entre problemas combinatorios. En R. E. Miller y J. W. Thatcher, editores, Complejidad de las Computaciones de Computadoras, páginas 85-103. Plenum Press, Nueva York, 1972. [10] M. Kearns, M. Littman y S. Singh. Modelos gráficos para <br>teoría de juegos</br>. En Actas de la Conferencia sobre Incertidumbre en Inteligencia Artificial (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou y J. N. Tsitsiklis. Una nota sobre la eliminación de estrategias en juegos bimatrix. Cartas de Investigación Operativa, 7(3):103-107, 1988. [12] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [14] K. Leyton-Brown y M. Tennenholtz. Juegos de efecto local. En Actas de la Decimoctava Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), Acapulco, México, 2003. [15] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 36-41, San Diego, CA, 2003. [16] M. Littman y P. Stone. Un algoritmo de equilibrio de Nash de tiempo polinómico para juegos repetidos. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 48-54, San Diego, CA, 2003. [17] R. D. Luce y H. Raiffa. Juegos y decisiones. John Wiley and Sons, Nueva York, 1957. Reedición de Dover 1989. [18] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown y Y. Shoham. Ejecutar el GAMUT: Un enfoque integral para evaluar algoritmos de teoría de juegos. En la Conferencia Internacional sobre Agentes Autónomos y Sistemas Multiagente (AAMAS), Nueva York, NY, EE. UU., 2004. [20] M. J. Osborne y A. Rubinstein. Un curso de <br>teoría de juegos</br>. MIT Press, 1994. [21] C. Papadimitriou. \n\nMIT Press, 1994. [21] C. Papadimitriou. Algoritmos, juegos e Internet. En Actas del Simposio Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. 89 [22] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 664-669, San José, CA, EE. UU., 2004. [23] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [24] J. von Neumann. A la teoría de los juegos sociales. Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg. \n\nMathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg. Forma de mercado y equilibrio. Springer, Viena, 1934. [26] B. von Stengel y S. Zamir. Liderazgo con compromiso hacia estrategias mixtas. Informe de investigación CDAM LSE-CDAM-2004-01, London School of Economics, febrero de 2004. 90 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "commitment": {
            "translated_key": "compromiso",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Computing the Optimal Strategy to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "Such models are synonymously referred to as leadership, <br>commitment</br>, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we study how to compute optimal strategies to commit to under both <br>commitment</br> to pure strategies and <br>commitment</br> to mixed strategies, in both normal-form and Bayesian games.",
                "We give both positive results (efficient algorithms) and negative results (NP-hardness results).",
                "Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent systems with self-interested agents (including most economic settings), the optimal action for one agent to take depends on the actions that the other agents take.",
                "To analyze how an agent should behave in such settings, the tools of game theory need to be applied.",
                "Typically, when a strategic setting is modeled in the framework of game theory, it is assumed that players choose their strategies simultaneously.",
                "This is especially true when the setting is modeled as a normal-form game, which only specifies each agents utility as a function of the vector of strategies that the agents choose, and does not provide any information on the order in which agents make their decisions and what the agents observe about earlier decisions by other agents.",
                "Given that the game is modeled in normal form, it is typically analyzed using the concept of Nash equilibrium.",
                "A Nash equilibrium specifies a strategy for each player, such that no player has an incentive to individually deviate from this profile of strategies. (Typically, the strategies are allowed to be mixed, that is, probability distributions over the original (pure) strategies.)",
                "A (mixed-strategy) Nash equilibrium is guaranteed to exist in finite games [18], but one problem is that there may be multiple Nash equilibria.",
                "This leads to the equilibrium selection problem of how an agent can know which strategy to play if it does not know which equilibrium is to be played.",
                "When the setting is modeled as an extensive-form game, it is possible to specify that some players receive some information about actions taken by others earlier in the game before deciding on their action.",
                "Nevertheless, in general, the players do not know everything that happened earlier in the game.",
                "Because of this, these games are typically still analyzed using an equilibrium concept, where one specifies a mixed strategy for each player, and requires that each players strategy is a best response to the others strategies. (Typically an additional constraint on the strategies is now imposed to ensure that players do not play in a way that is irrational with respect to the information that they have received so far.",
                "This leads to refinements of Nash equilibrium such as subgame perfect and sequential equilibrium.)",
                "However, in many real-world settings, strategies are not selected in such a simultaneous manner.",
                "Oftentimes, one player (the leader) is able to commit to a strategy before another player (the follower).",
                "This can be due to a variety of reasons.",
                "For example, one of the players may arrive at the site at which the game is to be played before another agent (e.g., in economic settings, one player may enter a market earlier and commit to a way of doing busi82 ness).",
                "Such <br>commitment</br> power has a profound impact on how the game should be played.",
                "For example, the leader may be best off playing a strategy that is dominated in the normal-form representation of the game.",
                "Perhaps the earliest and best-known example of the effect of <br>commitment</br> is that by von Stackelberg [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution.",
                "In general, if <br>commitment</br> to mixed strategies is possible, then (under minor assumptions) it never hurts, and often helps, to commit to a strategy [26].",
                "Being forced to commit to a pure strategy sometimes helps, and sometimes hurts (for example, committing to a pure strategy in rock-paper-scissors before the other players decision will naturally result in a loss).",
                "In this paper, we will assume <br>commitment</br> is always forced; if it is not, the player who has the choice of whether to commit can simply compare the <br>commitment</br> outcome to the non-commitment (simultaneous-move) outcome.",
                "Models of leadership are especially important in settings with multiple self-interested software agents.",
                "Once the code for an agent (or for a team of agents) is finalized and the agent is deployed, the agent is committed to playing the (possibly randomized) strategy that the code prescribes.",
                "Thus, as long as one can credibly show that one cannot change the code later, the code serves as a <br>commitment</br> device.",
                "This holds true for recreational tournaments among agents (e.g., poker tournaments, RoboSoccer), and for industrial applications such as sensor webs.",
                "Finally, there is also an implicit leadership situation in the field of mechanism design, in which one player (the designer) gets to choose the rules of the game that the remaining players then play.",
                "Mechanism design is an extremely important topic to the EC community: the papers published on mechanism design in recent EC conferences are too numerous to cite.",
                "Indeed, the mechanism designer may benefit from committing to a choice that, if the (remaining) agents actions were fixed, would be suboptimal.",
                "For example, in a (first-price) auction, the seller may wish to set a positive (artificial) reserve price for the item, below which the item will not be sold-even if the seller values the item at 0.",
                "In hindsight (after the bids have come in), this (na¨ıvely) appears suboptimal: if a bid exceeding the reserve price came in, the reserve price had no effect, and if no such bid came in, the seller would have been better off accepting a lower bid.",
                "Of course, the reason for setting the reserve price is that it incentivizes the bidders to bid higher, and because of this, setting artificial reserve prices can actually increase expected revenue to the seller.",
                "A significant amount of research has recently been devoted to the computation of solutions according to various solution concepts for settings in which the agents choose their strategies simultaneously, such as dominance [7, 11, 3] and (especially) Nash equilibrium [8, 21, 16, 15, 2, 22, 23, 4].",
                "However, the computation of the optimal strategy to commit to in a leadership situation has gone ignored.",
                "Theoretically, leadership situations can simply be thought of as an extensive-form game in which one player chooses a strategy (for the original game) first.",
                "The number of strategies in this extensive-form game, however, can be exceedingly large.",
                "For example, if the leader is able to commit to a mixed strategy in the original game, then every one of the (continuum of) mixed strategies constitutes a pure strategy in the extensive-form representation of the leadership situation. (We note that a <br>commitment</br> to a distribution is not the same as a distribution over commitments.)",
                "Moreover, if the original game is itself an extensive-form game, the number of strategies in the extensive-form representation of the leadership situation (which is a different extensive-form game) becomes even larger.",
                "Because of this, it is usually not computationally feasible to simply transform the original game into the extensive-form representation of the leadership situation; instead, we have to analyze the game in its original representation.",
                "In this paper, we study how to compute the optimal strategy to commit to, both in normal-form games (Section 2) and in Bayesian games, which are a special case of extensiveform games (Section 3). 2.",
                "NORMAL-FORM GAMES In this section, we study how to compute the optimal strategy to commit to for games represented in normal form. 2.1 Definitions In a normal-form game, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a pure strategy for every player, also known as a profile of pure strategies) to a real number.",
                "To ease notation, in the case of two players, we will refer to player 1s pure strategy set as S, and player 2s pure strategy set as T. Such games can be represented in (bi-)matrix form, in which the rows correspond to player 1s pure strategies, the columns correspond to player 2s pure strategies, and the entries of the matrix give the row and column players utilities (in that order) for the corresponding outcome of the game.",
                "In the case of three players, we will use R, S, and T, for player 1, 2, and 3s pure strategies, respectively.",
                "A mixed strategy for a player is a probability distribution over that players pure strategies.",
                "In the case of two-player games, we will refer to player 1 as the leader and player 2 as the follower.",
                "Before defining optimal leadership strategies, consider the following game which illustrates the effect of the leaders ability to commit. 2, 1 4, 0 1, 0 3, 1 In this normal-form representation, the bottom strategy for the row player is strictly dominated by the top strategy.",
                "Nevertheless, if the row player has the ability to commit to a pure strategy before the column player chooses his strategy, the row player should commit to the bottom strategy: doing so will make the column player prefer to play the right strategy, leading to a utility of 3 for the row player.",
                "By contrast, if the row player were to commit to the top strategy, the column player would prefer to play the left strategy, leading to a utility of only 2 for the row player.",
                "If the row player is able to commit to a mixed strategy, then she can get an even greater (expected) utility: if the row player commits to placing probability p > 1/2 on the bottom strategy, then the column player will still prefer to play the right strategy, and the row players expected utility will be 3p + 4(1 − p) = 4 − p ≥ 3.",
                "If the row player plays each strategy with probability exactly 1/2, the column player is 83 indifferent between the strategies.",
                "In such cases, we will assume that the column player will choose the strategy that maximizes the row players utility (in this case, the right strategy).",
                "Hence, the optimal mixed strategy to commit to for the row player is p = 1/2.",
                "There are a few good reasons for this assumption.",
                "If we were to assume the opposite, then there would not exist an optimal strategy for the row player in the example game: the row player would play the bottom strategy with probability p = 1/2 + with > 0, and the smaller , the better the utility for the row player.",
                "By contrast, if we assume that the follower always breaks ties in the leaders favor, then an optimal mixed strategy for the leader always exists, and this corresponds to a subgame perfect equilibrium of the extensive-form representation of the leadership situation.",
                "In any case, this is a standard assumption for such models (e.g. [20]), although some work has investigated what can happen in the other subgame perfect equilibria [26]. (For generic two-player games, the leaders subgame-perfect equilibrium payoff is unique.)",
                "Also, the same assumption is typically used in mechanism design, in that it is assumed that if an agent is indifferent between revealing his preferences truthfully and revealing them falsely, he will report them truthfully.",
                "Given this assumption, we can safely refer to optimal leadership strategies rather than having to use some equilibrium notion.",
                "Hence, for the purposes of this paper, an optimal strategy to commit to in a 2-player game is a strategy s ∈ S that maximizes maxt∈BR(s) ul(s, t), where BR(s) = arg maxt∈T uf (s, t). (ul and uf are the leader and followers utility functions, respectively.)",
                "We can have S = S for the case of <br>commitment</br> to pure strategies, or S = ∆(S), the set of probability distributions over S, for the case of <br>commitment</br> to mixed strategies. (We note that replacing T by ∆(T) makes no difference in this definition.)",
                "For games with more than two players, in which the players commit to their strategies in sequence, we define optimal strategies to commit to recursively.",
                "After the leader commits to a strategy, the game to be played by the remaining agents is itself a (smaller) leadership game.",
                "Thus, we define an optimal strategy to commit to as a strategy that maximizes the leaders utility, assuming that the play of the remaining agents is itself optimal under this definition, and maximizes the leaders utility among all optimal ways to play the remaining game.",
                "Again, <br>commitment</br> to mixed strategies may or may not be a possibility for every player (although for the last player it does not matter if we allow for <br>commitment</br> to mixed strategies). 2.2 Commitment to pure strategies We first study how to compute the optimal pure strategy to commit to.",
                "This is relatively simple, because the number of strategies to commit to is not very large. (In the following, #outcomes is the number of complete strategy profiles.)",
                "Theorem 1.",
                "Under <br>commitment</br> to pure strategies, the set of all optimal strategy profiles in a normal-form game can be found in O(#players · #outcomes) time.",
                "Proof.",
                "Each pure strategy that the first player may commit to will induce a subgame for the remaining players.",
                "We can solve each such subgame recursively to find all of its optimal strategy profiles; each of these will give the original leader some utility.",
                "Those that give the leader maximal utility correspond exactly to the optimal strategy profiles of the original game.",
                "We now present the algorithm formally.",
                "Let Su(G, s1) be the subgame that results after the first (remaining) player in G plays s1 ∈ SG 1 .",
                "A game with 0 players is simply an outcome of the game.",
                "The function Append(s, O) appends the strategy s to each of the vectors of strategies in the set O.",
                "Let e be the empty vector with no elements.",
                "In a slight abuse of notation, we will write uG 1 (C) when all strategy profiles in the set C give player 1 the same utility in the game G. (Here, player 1 is the first remaining player in the subgame G, not necessarily player 1 in the original game.)",
                "We note that arg max is set-valued.",
                "Then, the following algorithm computes all optimal strategy profiles: Algorithm Solve(G) if G has 0 players return {e} C ← ∅ for all s1 ∈ SG 1 { O ← Solve(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) if C = ∅ or uG 1 (s1, O ) = uG 1 (C) C ← C∪Append(s1, O ) if uG 1 (s1, O ) > uG 1 (C) C ←Append(s1, O ) } return C Every outcome is (potentially) examined by every player, which leads to the given runtime bound.",
                "As an example of how the algorithm works, consider the following 3-player game, in which the first player chooses the left or right matrix, the second player chooses a row, and the third player chooses a column. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 3,0,0 First we eliminate the outcomes that do not correspond to best responses for the third player (removing them from the matrix): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Next, we remove the entries in which the third player does not break ties in favor of the second player, as well as entries that do not correspond to best responses for the second player. 0,1,1 2,1,1 1,1,1 0,5,1 Finally, we remove the entries in which the second and third players do not break ties in favor of the first player, as well as entries that do not correspond to best responses for the first player. 2,1,1 84 Hence, in optimal play, the first player chooses the left matrix, the second player chooses the middle row, and the third player chooses the left column. (We note that this outcome is Pareto-dominated by (Right, Middle, Left).)",
                "For general normal-form games, each players utility for each of the outcomes has to be explicitly represented in the input, so that the input size is itself Ω(#players · #outcomes).",
                "Therefore, the algorithm is in fact a linear-time algorithm. 2.3 <br>commitment</br> to mixed strategies In the special case of two-player zero-sum games, computing an optimal mixed strategy for the leader to commit to is equivalent to computing a minimax strategy, which minimizes the maximum expected utility that the opponent can obtain.",
                "Minimax strategies constitute the only natural solution concept for two-player zero-sum games: von Neumanns Minimax Theorem [24] states that in two-player zero-sum games, it does not matter (in terms of the players utilities) which player gets to commit to a mixed strategy first, and a profile of mixed strategies is a Nash equilibrium if and only if both strategies are minimax strategies.",
                "It is well-known that a minimax strategy can be found in polynomial time, using linear programming [17].",
                "Our first result in this section generalizes this result, showing that an optimal mixed strategy for the leader to commit to can be efficiently computed in general-sum two-player games, again using linear programming.",
                "Theorem 2.",
                "In 2-player normal-form games, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders utility.",
                "Such a mixed strategy can be computed using the following simple linear program: maximize s∈S psul(s, t) subject to for all t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1 We note that this program may be infeasible for some follower strategies t, for example, if t is a strictly dominated strategy.",
                "Nevertheless, the program must be feasible for at least some follower strategies; among these follower strategies, choose a strategy t∗ that maximizes the linear programs solution value.",
                "Then, if the leader chooses as her mixed strategy the optimal settings of the variables ps for the linear program for t∗ , and the follower plays t∗ , this constitutes an optimal strategy profile.",
                "In the following result, we show that we cannot expect to solve the problem more efficiently than linear programming, because we can reduce any linear program with a probability constraint on its variables to a problem of computing the optimal mixed strategy to commit to in a 2-player normalform game.",
                "Theorem 3.",
                "Any linear program whose variables xi (with xi ∈ R≥0 ) must satsify i xi = 1 can be modeled as a problem of computing the optimal mixed strategy to commit to in a 2-player normal-form game.",
                "Proof.",
                "Let the leader have a pure strategy i for every variable xi.",
                "Let the column player have one pure strategy j for every constraint in the linear program (other than i xi = 1), and a single additional pure strategy 0.",
                "Let the utility functions be as follows.",
                "Writing the objective of the linear program as maximize i cixi, for any i, let ul(i, 0) = ci and uf (i, 0) = 0.",
                "Writing the jth constraint of the linear program (not including i xi = 1) as i aijxi ≤ bj, for any i, j > 0, let ul(i, j) = mini ci − 1 and uf (i, j) = aij − bj.",
                "For example, consider the following linear program. maximize 2x1 + x2 subject to x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 The optimal solution to this program is x1 = 1/3, x2 = 2/3.",
                "Our reduction transforms this program into the following leader-follower game (where the leader is the row player). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 Indeed, the optimal strategy for the leader is to play the top strategy with probability 1/3 and the bottom strategy with probability 2/3.",
                "We now show that the reduction works in general.",
                "Clearly, the leader wants to incentivize the follower to play 0, because the utility that the leader gets when the follower plays 0 is always greater than when the follower does not play 0.",
                "In order for the follower not to prefer playing j > 0 rather than 0, it must be the case that i pl(i)(aij − bj) ≤ 0, or equivalently i pl(i)aij ≤ bj.",
                "Hence the leader will get a utility of at least mini ci if and only if there is a feasible solution to the constraints.",
                "Given that the pl(i) incentivize the follower to play 0, the leader attempts to maximize i pl(i)ci.",
                "Thus the leader must solve the original linear program.",
                "As an alternative proof of Theorem 3, one may observe that it is known that finding a minimax strategy in a zerosum game is as hard as the linear programming problem [6], and as we pointed out at the beginning of this section, computing a minimax strategy in a zero-sum game is a special case of the problem of computing an optimal mixed strategy to commit to.",
                "This polynomial-time solvability of the problem of computing an optimal mixed strategy to commit to in two-player normal-form games contrasts with the unknown complexity of computing a Nash equilibrium in such games [21], as well as with the NP-hardness of finding a Nash equilibrium with maximum utility for a given player in such games [8, 2].",
                "Unfortunately, this result does not generalize to more than two players-here, the problem becomes NP-hard.",
                "To show this, we reduce from the VERTEX-COVER problem.",
                "Definition 1.",
                "In VERTEX-COVER, we are given a graph G = (V, E) and an integer K. We are asked whether there 85 exists a subset of the vertices S ⊆ V , with |S| = K, such that every edge e ∈ E has at least one of its endpoints in S. BALANCED-VERTEX-COVER is the special case of VERTEX-COVER in which K = |V |/2.",
                "VERTEX-COVER is NP-complete [9].",
                "The following lemma shows that the hardness remains if we require K = |V |/2. (Similar results have been shown for other NP-complete problems.)",
                "Lemma 1.",
                "BALANCED-VERTEX-COVER is NP-complete.",
                "Proof.",
                "Membership in NP follows from the fact that the problem is a special case of VERTEX-COVER, which is in NP.",
                "To show NP-hardness, we reduce an arbitrary VERTEX-COVER instance to a BALANCED-VERTEXCOVER instance, as follows.",
                "If, for the VERTEX-COVER instance, K > |V |/2, then we simply add isolated vertices that are disjoint from the rest of the graph, until K = |V |/2.",
                "If K < |V |/2, we add isolated triangles (that is, the complete graph on three vertices) to the graph, increasing K by 2 every time, until K = |V |/2.",
                "Theorem 4.",
                "In 3-player normal-form games, finding an optimal mixed strategy to commit to is NP-hard.",
                "Proof.",
                "We reduce an arbitrary BALANCED-VERTEXCOVER instance to the following 3-player normal-form game.",
                "For every vertex v, each of the three players has a pure strategy corresponding to that vertex (rv, sv, tv, respectively).",
                "In addition, for every edge e, the third player has a pure strategy te; and finally, the third player has one additional pure strategy t0.",
                "The utilities are as follows: • for all r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • for all r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • for all v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • for all v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • for all v ∈ V , for all r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V | |V |−2 ; • for all e ∈ E, s ∈ S, for both v ∈ e, u3(rv, s, te) = 0; • for all e ∈ E, s ∈ S, for all v /∈ e, u3(rv, s, te) = |V | |V |−2 . • for all r ∈ R, s ∈ S, u3(r, s, t0) = 1.",
                "We note that players 1 and 2 have the same utility function.",
                "We claim that there is an optimal strategy profile in which players 1 and 2 both obtain 1 (their maximum utility) if and only if there is a solution to the BALANCED-VERTEXCOVER problem. (Otherwise, these players will both obtain 0.)",
                "First, suppose there exists a solution to the BALANCEDVERTEX-COVER problem.",
                "Then, let player 1 play every rv such that v is in the cover with probability 2 |V | , and let player 2 play every sv such that v is not in the cover with probability 2 |V | .",
                "Then, for player 3, the expected utility of playing tv (for any v) is (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of 2 |V | that rv or sv is played.",
                "Additionally, the expected utility of playing te (for any e) is at most (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of at least 2 |V | that some rv with v ∈ e is played (because player 1 is randomizing over the pure strategies corresponding to the cover).",
                "It follows that playing t0 is a best response for player 3, giving players 1 and 2 a utility of 1.",
                "Now, suppose that players 1 and 2 obtain 1 in optimal play.",
                "Then, it must be the case that player 3 plays t0.",
                "Hence, for every v ∈ V , there must be a probability of at least 2 |V | that either rv or sv is played, for otherwise player 3 would be better off playing tv.",
                "Because players 1 and 2 have only a total probability of 2 to distribute, it must be the case that for each v, either rv or sv is played with probability 2 |V | , and the other is played with probability 0. (It is not possible for both to have nonzero probability, because then there would be some probability that both are played simultaneously (correlation is not possible), hence the total probability of at least one being played could not be high enough for all vertices.)",
                "Thus, for exactly half the v ∈ V , player 1 places probability 2 |V | on rv.",
                "Moreover, for every e ∈ E, there must be a probability of at least 2 |V | that some rv with v ∈ e is played, for otherwise player 3 would be better off playing te.",
                "Thus, the v ∈ V such that player 1 places probability 2 |V | on rv constitute a balanced vertex cover. 3.",
                "BAYESIAN GAMES So far, we have restricted our attention to normal-form games.",
                "In a normal-form game, it is assumed that every agent knows every other agents preferences over the outcomes of the game.",
                "In general, however, agents may have some private information about their preferences that is not known to the other agents.",
                "Moreover, at the time of <br>commitment</br> to a strategy, the agents may not even know their own (final) preferences over the outcomes of the game yet, because these preferences may be dependent on a context that has yet to materialize.",
                "For example, when the code for a trading agent is written, it may not yet be clear how that agent will value resources that it will negotiate over later, because this depends on information that is not yet available at the time at which the code is written (such as orders that will have been placed to the agent before the negotiation).",
                "In this section, we will study <br>commitment</br> in Bayesian games, which can model such uncertainty over preferences. 3.1 Definitions In a Bayesian game, every player i has a set of actions Si, a set of types Θi with an associated probability distribution πi : Θi → [0, 1], and, for each type θi, a utility function uθi i : S1 × S2 × . . . × Sn → R. A pure strategy in a Bayesian game is a mapping from the players types to actions, σi : Θi → Si. (Bayesian games can be rewritten in normal form by enumerating every pure strategy σi, but this will cause an exponential blowup in the size of the representation of the game and therefore cannot lead to efficient algorithms.)",
                "The strategy that the leader should commit to depends on whether, at the time of <br>commitment</br>, the leader knows her own type.",
                "If the leader does know her own type, the other types that the leader might have had become irrelevant and the leader should simply commit to the strategy that is optimal for the type.",
                "However, as argued above, the leader does not necessarily know her own type at the time of <br>commitment</br> (e.g., the time at which the code is submitted).",
                "In this case, the leader must commit to a strategy that is 86 dependent upon the leaders eventual type.",
                "We will study this latter model, although we will pay specific attention to the case where the leader has only a single type, which is effectively the same as the former model. 3.2 <br>commitment</br> to pure strategies It turns out that computing an optimal pure strategy to commit to is hard in Bayesian games, even with two players.",
                "Theorem 5.",
                "Finding an optimal pure strategy to commit to in 2-player Bayesian games is NP-hard, even when the follower has only a single type.",
                "Proof.",
                "We reduce an arbitrary VERTEX-COVER instance to the following Bayesian game between the leader and the follower.",
                "The leader has K types θ1, θ2, . . . , θK , each occurring with probability 1/K, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has only a single type; for each edge e ∈ E, the follower has an action te, and the follower has a single additional action t0.",
                "The utility function for the leader is given by, for all θl ∈ Θl and all s ∈ S, u θl l (s, t0) = 1, and for all e ∈ E, u θl l (s, te) = 0.",
                "The followers utility is given by: • For all v ∈ V , for all e ∈ E with v /∈ e, uf (sv, te) = 1; • For all v ∈ V , for all e ∈ E with v ∈ e, uf (sv, te) = −K; • For all v ∈ V , uf (sv, t0) = 0.",
                "We claim that the leader can get a utility of 1 if and only if there is a solution to the VERTEX-COVER instance.",
                "First, suppose that there is a solution to the VERTEXCOVER instance.",
                "Then, the leader can commit to a pure strategy such that for each vertex v in the cover, the leader plays sv for some type.",
                "Then, the followers utility for playing te (for any e ∈ E) is at most K−1 K + 1 K (−K) = − 1 K , so that the follower will prefer to play t0, which gives the leader a utility of 1, as required.",
                "Now, suppose that there is a pure strategy for the leader that will give the leader a utility of 1.",
                "Then, the follower must play t0.",
                "In order for the follower not to prefer playing te (for any e ∈ E) instead, for at least one v ∈ e the leader must play sv for some type θl.",
                "Hence, the set of vertices v that the leader plays for some type must constitute a vertex cover; and this set can have size at most K, because the leader has only K types.",
                "So there is a solution to the VERTEXCOVER instance.",
                "However, if the leader has only a single type, then the problem becomes easy again (#types is the number of types for the follower): Theorem 6.",
                "In 2-player Bayesian games in which the leader has only a single type, an optimal pure strategy to commit to can be found in O(#outcomes · #types) time.",
                "Proof.",
                "For every leader action s, we can compute, for every follower type θf ∈ Θf , which actions t maximize the followers utility; call this set of actions BRθf (s).",
                "Then, the utility that the leader receives for committing to action s can be computed as θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), and the leader can choose the best action to commit to. 3.3 <br>commitment</br> to mixed strategies In two-player zero-sum imperfect information games with perfect recall (no player ever forgets something that it once knew), a minimax strategy can be constructed in polynomial time [12, 13].",
                "Unfortunately, this result does not extend to computing optimal mixed strategies to commit to in the general-sum case-not even in Bayesian games.",
                "We will exhibit NP-hardness by reducing from the INDEPENDENTSET problem.",
                "Definition 2.",
                "In INDEPENDENT-SET, we are given a graph G = (V, E) and an integer K. We are asked whether there exists a subset of the vertices S ⊆ V , with |S| = K, such that no edge e ∈ E has both of its endpoints in S. Again, this problem is NP-complete [9].",
                "Theorem 7.",
                "Finding an optimal mixed strategy to commit to in 2-player Bayesian games is NP-hard, even when the leader has only a single type and the follower has only two actions.",
                "Proof.",
                "We reduce an arbitrary INDEPENDENT-SET instance to the following Bayesian game between the leader and the follower.",
                "The leader has only a single type, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has a type θv for every v ∈ V , occurring with probability 1 (|E|+1)|V | , and a type θe for every e ∈ E, occurring with probability 1 |E|+1 .",
                "The follower has two actions: t0 and t1.",
                "The leaders utility is given by, for all s ∈ S, ul(s, t0) = 1 and ul(s, t1) = 0.",
                "The followers utility is given by: • For all v ∈ V , uθv f (sv, t1) = 0; • For all v ∈ V and s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • For all v ∈ V and s ∈ S, uθv f (s, t0) = 1; • For all e ∈ E, s ∈ S, uθe f (s, t0) = 1; • For all e ∈ E, for both v ∈ e, uθe f (sv, t1) = 2K 3 ; • For all e ∈ E, for all v /∈ e, uθe f (sv, t1) = 0.",
                "We claim that an optimal strategy to commit to gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | if and only if there is a solution to the INDEPENDENT-SET instance.",
                "First, suppose that there is a solution to the INDEPENDENT-SET instance.",
                "Then, the leader could commit to the following strategy: for every vertex v in the independent set, play the corresponding sv with probability 1/K.",
                "If the follower has type θe for some e ∈ E, the expected utility for the follower of playing t1 is at most 1 K 2K 3 = 2/3, because there is at most one vertex v ∈ e such that sv is played with nonzero probability.",
                "Hence, the follower will play t0 and obtain a utility of 1.",
                "If the follower has type θv for some vertex v in the independent set, the expected utility for the follower of playing t1 is K−1 K K K−1 = 1, because the leader plays sv with probability 1/K.",
                "It follows that the follower (who breaks ties to maximize the leaders utility) will play t0, which also gives a utility of 1 and gives the leader a higher utility.",
                "Hence the leaders expected utility for this strategy is at least |E| |E|+1 + K (|E|+1)|V | , as required. 87 Now, suppose that there is a strategy that gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | .",
                "Then, this strategy must induce the follower to play t0 whenever it has a type of the form θe (because otherwise, the utility could be at most |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ).",
                "Thus, it cannot be the case that for some edge e = (v1, v2) ∈ E, the probability that the leader plays one of sv1 and sv2 is at least 2/K, because then the expected utility for the follower of playing t1 when it has type θe would be at least 2 K 2K 3 = 4/3 > 1.",
                "Moreover, the strategy must induce the follower to play t0 for at least K types of the form θv.",
                "Inducing the follower to play t0 when it has type θv can be done only by playing sv with probability at least 1/K, which will give the follower a utility of at most K−1 K K K−1 = 1 for playing t1.",
                "But then, the set of vertices v such that sv is played with probability at least 1/K must constitute an independent set of size K (because if there were an edge e between two such vertices, it would induce the follower to play t1 for type θe by the above).",
                "By contrast, if the follower has only a single type, then we can generalize the linear programming approach for normalform games: Theorem 8.",
                "In 2-player Bayesian games in which the follower has only a single type, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "We generalize the approach in Theorem 2 as follows.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader for every one of the leaders types such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders ex ante expected utility.",
                "To do so, we generalize the linear program as follows: maximize θl∈Θl π(θl) s∈S pθl s uθl l (s, t) subject to for all t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t ) for all θl ∈ Θl, s∈S p θl s = 1 As in Theorem 2, the solution for the linear program that maximizes the solution value is an optimal strategy to commit to.",
                "This shows an interesting contrast between <br>commitment</br> to pure strategies and <br>commitment</br> to mixed strategies in Bayesian games: for pure strategies, the problem becomes easy if the leader has only a single type (but not if the follower has only a single type), whereas for mixed strategies, the problem becomes easy if the follower has only a single type (but not if the leader has only a single type). 4.",
                "CONCLUSIONS AND FUTURE RESEARCH In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "This requires some equilibrium notion (Nash equilibrium and its refinements), and often leads to the equilibrium selection problem: it is unclear to each individual player according to which equilibrium she should play.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "For example, one agent may arrive at the (real or virtual) site of the game before the other, or, in the specific case of software agents, the code for one agent may be completed and committed before that of another agent.",
                "Such models are synonymously referred to as leadership, <br>commitment</br>, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "Specifically, if <br>commitment</br> to mixed strategies is possible, then (optimal) <br>commitment</br> never hurts the leader, and often helps.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we studied how to compute optimal strategies to commit to under both <br>commitment</br> to pure strategies and <br>commitment</br> to mixed strategies, in both normal-form and Bayesian games.",
                "For normal-form games, we showed that the optimal pure strategy to commit to can be found efficiently for any number of players.",
                "An optimal mixed strategy to commit to in a normal-form game can be found efficiently for two players using linear programming (and no more efficiently than that, in the sense that any linear program with a probability constraint can be encoded as such a problem). (This is a generalization of the polynomial-time computability of minimax strategies in normal-form games.)",
                "The problem becomes NP-hard for three (or more) players.",
                "In Bayesian games, the problem of finding an optimal pure strategy to commit to is NP-hard even in two-player games in which the follower has only a single type, although two-player games in which the leader has only a single type can be solved efficiently.",
                "The problem of finding an optimal mixed strategy to commit to in a Bayesian game is NP-hard even in two-player games in which the leader has only a single type, although two-player games in which the follower has only a single type can be solved efficiently using a generalization of the linear progamming approach for normal-form games.",
                "The following two tables summarize these results. 2 players ≥ 3 players normal-form O(#outcomes) O(#outcomes· #players) Bayesian, O(#outcomes· NP-hard 1-type leader #types) Bayesian, NP-hard NP-hard 1-type follower Bayesian (general) NP-hard NP-hard Results for <br>commitment</br> to pure strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.) 88 2 players ≥ 3 players normal-form one LP-solve per NP-hard follower action Bayesian, NP-hard NP-hard 1-type leader Bayesian, one LP-solve per NP-hard 1-type follower follower action Bayesian (general) NP-hard NP-hard Results for <br>commitment</br> to mixed strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.)",
                "Future research can take a number of directions.",
                "First, we can empirically evaluate the techniques presented here on test suites such as GAMUT [19].",
                "We can also study the computation of optimal strategies to commit to in other1 concise representations of normal-form games-for example, in graphical games [10] or local-effect/action graph games [14, 1].",
                "For the cases where computing an optimal strategy to commit to is NP-hard, we can also study the computation of approximately optimal strategies to commit to.",
                "While the correct definition of an approximately optimal strategy is in this setting may appear simple at first-it should be a strategy that, if the following players play optimally, performs almost as well as the optimal strategy in expectation-this definition becomes problematic when we consider that the other players may also be playing only approximately optimally.",
                "One may also study models in which multiple (but not all) players commit at the same time.",
                "Another interesting direction to pursue is to see if computing optimal mixed strategies to commit to can help us in, or otherwise shed light on, computing Nash equilibria.",
                "Often, optimal mixed strategies to commit to are also Nash equilibrium strategies (for example, in two-player zero-sum games this is always true), although this is not always the case (for example, as we already pointed out, sometimes the optimal strategy to commit to is a strictly dominated strategy, which can never be a Nash equilibrium strategy). 5.",
                "REFERENCES [1] N. A. R. Bhat and K. Leyton-Brown.",
                "Computing Nash equilibria of action-graph games.",
                "In Proceedings of the 20th Annual Conference on Uncertainty in Artificial Intelligence (UAI), Banff, Canada, 2004. [2] V. Conitzer and T. Sandholm.",
                "Complexity results about Nash equilibria.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pages 765-771, Acapulco, Mexico, 2003. [3] V. Conitzer and T. Sandholm.",
                "Complexity of (iterated) dominance.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 88-97, Vancouver, Canada, 2005. [4] V. Conitzer and T. Sandholm.",
                "A generalized strategy eliminability criterion and computational methods for applying it.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 483-488, Pittsburgh, PA, USA, 2005. [5] A.",
                "A. Cournot.",
                "Recherches sur les principes math´ematiques de la th´eorie des richesses (Researches 1 Bayesian games are one potentially concise representation of normal-form games. into the Mathematical Principles of the Theory of Wealth).",
                "Hachette, Paris, 1838. [6] G. Dantzig.",
                "A proof of the equivalence of the programming problem and the game problem.",
                "In T. Koopmans, editor, Activity Analysis of Production and Allocation, pages 330-335.",
                "John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel.",
                "The complexity of eliminating dominated strategies.",
                "Mathematics of Operation Research, 18:553-565, 1993. [8] I. Gilboa and E. Zemel.",
                "Nash and correlated equilibria: Some complexity considerations.",
                "Games and Economic Behavior, 1:80-93, 1989. [9] R. Karp.",
                "Reducibility among combinatorial problems.",
                "In R. E. Miller and J. W. Thatcher, editors, Complexity of Computer Computations, pages 85-103.",
                "Plenum Press, NY, 1972. [10] M. Kearns, M. Littman, and S. Singh.",
                "Graphical models for game theory.",
                "In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou, and J. N. Tsitsiklis.",
                "A note on strategy elimination in bimatrix games.",
                "Operations Research Letters, 7(3):103-107, 1988. [12] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [14] K. Leyton-Brown and M. Tennenholtz.",
                "Local-effect games.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), Acapulco, Mexico, 2003. [15] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 36-41, San Diego, CA, 2003. [16] M. Littman and P. Stone.",
                "A polynomial-time Nash equilibrium algorithm for repeated games.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 48-54, San Diego, CA, 2003. [17] R. D. Luce and H. Raiffa.",
                "Games and Decisions.",
                "John Wiley and Sons, New York, 1957.",
                "Dover republication 1989. [18] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown, and Y. Shoham.",
                "Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms.",
                "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), New York, NY, USA, 2004. [20] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "MIT Press, 1994. [21] C. Papadimitriou.",
                "Algorithms, games and the Internet.",
                "In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 749-753, 2001. 89 [22] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 664-669, San Jose, CA, USA, 2004. [23] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 495-501, Pittsburgh, PA, USA, 2005. [24] J. von Neumann.",
                "Zur Theorie der Gesellschaftsspiele.",
                "Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg.",
                "Marktform und Gleichgewicht.",
                "Springer, Vienna, 1934. [26] B. von Stengel and S. Zamir.",
                "Leadership with <br>commitment</br> to mixed strategies.",
                "CDAM Research Report LSE-CDAM-2004-01, London School of Economics, Feb. 2004. 90"
            ],
            "original_annotated_samples": [
                "Such models are synonymously referred to as leadership, <br>commitment</br>, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "In this paper, we study how to compute optimal strategies to commit to under both <br>commitment</br> to pure strategies and <br>commitment</br> to mixed strategies, in both normal-form and Bayesian games.",
                "Such <br>commitment</br> power has a profound impact on how the game should be played.",
                "Perhaps the earliest and best-known example of the effect of <br>commitment</br> is that by von Stackelberg [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution.",
                "In general, if <br>commitment</br> to mixed strategies is possible, then (under minor assumptions) it never hurts, and often helps, to commit to a strategy [26]."
            ],
            "translated_annotated_samples": [
                "Tales modelos son referidos indistintamente como modelos de liderazgo, <br>compromiso</br> o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente.",
                "En este artículo, estudiamos cómo calcular estrategias óptimas a comprometerse tanto en el <br>compromiso</br> de estrategias puras como en el <br>compromiso</br> de estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos.",
                "Un <br>compromiso</br> tan poderoso tiene un impacto profundo en cómo debería jugarse el juego.",
                "Quizás el ejemplo más temprano y conocido del efecto del <br>compromiso</br> es el de von Stackelberg [25], quien demostró que, en el modelo de duopolio de Cournot [5], si una empresa puede comprometerse con una cantidad de producción primero, esa empresa lo hará mucho mejor que en la solución de movimiento simultáneo (Nash).",
                "En general, si es posible <br>comprometerse</br> con estrategias mixtas, entonces (bajo suposiciones menores) nunca perjudica, y a menudo ayuda, <br>comprometerse</br> con una estrategia [26]."
            ],
            "translated_text": "En sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias simultáneamente. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Tales modelos son referidos indistintamente como modelos de liderazgo, <br>compromiso</br> o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. El reciente aumento en el interés por las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas a comprometerse tanto en el <br>compromiso</br> de estrategias puras como en el <br>compromiso</br> de estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Ofrecemos tanto resultados positivos (algoritmos eficientes) como resultados negativos (resultados de NP-hardness). Categorías y Descriptores de Asignaturas J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas Términos Generales Algoritmos, Economía, Teoría 1. En sistemas multiagentes con agentes auto-interesados (incluyendo la mayoría de los entornos económicos), la acción óptima que un agente debe tomar depende de las acciones que tomen los otros agentes. Para analizar cómo un agente debería comportarse en tales situaciones, es necesario aplicar las herramientas de la teoría de juegos. Normalmente, cuando se modela un escenario estratégico en el marco de la teoría de juegos, se asume que los jugadores eligen sus estrategias de forma simultánea. Esto es especialmente cierto cuando el escenario se modela como un juego en forma normal, que solo especifica la utilidad de cada agente como una función del vector de estrategias que los agentes eligen, y no proporciona información sobre el orden en que los agentes toman sus decisiones y lo que los agentes observan sobre las decisiones anteriores de otros agentes. Dado que el juego está modelado en forma normal, típicamente se analiza utilizando el concepto de equilibrio de Nash. Un equilibrio de Nash especifica una estrategia para cada jugador, de modo que ningún jugador tenga un incentivo para desviarse individualmente de este perfil de estrategias. (Por lo general, se permite que las estrategias sean mixtas, es decir, distribuciones de probabilidad sobre las estrategias originales (puras).) Un equilibrio de Nash (de estrategia mixta) está garantizado de existir en juegos finitos [18], pero un problema es que puede haber múltiples equilibrios de Nash. Esto conduce al problema de selección de equilibrio de cómo un agente puede saber qué estrategia jugar si no sabe qué equilibrio se va a jugar. Cuando el escenario se modela como un juego de forma extensiva, es posible especificar que algunos jugadores reciben información sobre las acciones tomadas por otros antes en el juego antes de decidir su acción. Sin embargo, en general, los jugadores no saben todo lo que sucedió anteriormente en el juego. Por lo tanto, estos juegos suelen ser analizados todavía utilizando un concepto de equilibrio, donde se especifica una estrategia mixta para cada jugador, y se requiere que la estrategia de cada jugador sea una mejor respuesta a las estrategias de los demás. (Normalmente se impone ahora una restricción adicional en las estrategias para garantizar que los jugadores no jueguen de una manera irracional con respecto a la información que han recibido hasta el momento). Esto conduce a refinamientos del equilibrio de Nash como el equilibrio perfecto en subjuegos y el equilibrio secuencial. Sin embargo, en muchos entornos del mundo real, las estrategias no se seleccionan de manera simultánea. A menudo, un jugador (el líder) puede comprometerse con una estrategia antes que otro jugador (el seguidor). Esto puede deberse a una variedad de razones. Por ejemplo, uno de los jugadores puede llegar al lugar donde se jugará el juego antes que otro agente (por ejemplo, en entornos económicos, un jugador puede ingresar al mercado antes y comprometerse con una forma de hacer negocios). Un <br>compromiso</br> tan poderoso tiene un impacto profundo en cómo debería jugarse el juego. Por ejemplo, el líder puede estar mejor jugando una estrategia que esté dominada en la representación de forma normal del juego. Quizás el ejemplo más temprano y conocido del efecto del <br>compromiso</br> es el de von Stackelberg [25], quien demostró que, en el modelo de duopolio de Cournot [5], si una empresa puede comprometerse con una cantidad de producción primero, esa empresa lo hará mucho mejor que en la solución de movimiento simultáneo (Nash). En general, si es posible <br>comprometerse</br> con estrategias mixtas, entonces (bajo suposiciones menores) nunca perjudica, y a menudo ayuda, <br>comprometerse</br> con una estrategia [26]. ",
            "candidates": [],
            "error": [
                [
                    "compromiso",
                    "compromiso",
                    "compromiso",
                    "compromiso",
                    "compromiso",
                    "comprometerse",
                    "comprometerse"
                ]
            ]
        },
        "leadership": {
            "translated_key": "liderazgo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Computing the Optimal Strategy to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "Such models are synonymously referred to as <br>leadership</br>, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored <br>leadership</br> models (with the exception of the interest in mechanism design, where the designer is implicitly in a <br>leadership</br> position).",
                "In this paper, we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "We give both positive results (efficient algorithms) and negative results (NP-hardness results).",
                "Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent systems with self-interested agents (including most economic settings), the optimal action for one agent to take depends on the actions that the other agents take.",
                "To analyze how an agent should behave in such settings, the tools of game theory need to be applied.",
                "Typically, when a strategic setting is modeled in the framework of game theory, it is assumed that players choose their strategies simultaneously.",
                "This is especially true when the setting is modeled as a normal-form game, which only specifies each agents utility as a function of the vector of strategies that the agents choose, and does not provide any information on the order in which agents make their decisions and what the agents observe about earlier decisions by other agents.",
                "Given that the game is modeled in normal form, it is typically analyzed using the concept of Nash equilibrium.",
                "A Nash equilibrium specifies a strategy for each player, such that no player has an incentive to individually deviate from this profile of strategies. (Typically, the strategies are allowed to be mixed, that is, probability distributions over the original (pure) strategies.)",
                "A (mixed-strategy) Nash equilibrium is guaranteed to exist in finite games [18], but one problem is that there may be multiple Nash equilibria.",
                "This leads to the equilibrium selection problem of how an agent can know which strategy to play if it does not know which equilibrium is to be played.",
                "When the setting is modeled as an extensive-form game, it is possible to specify that some players receive some information about actions taken by others earlier in the game before deciding on their action.",
                "Nevertheless, in general, the players do not know everything that happened earlier in the game.",
                "Because of this, these games are typically still analyzed using an equilibrium concept, where one specifies a mixed strategy for each player, and requires that each players strategy is a best response to the others strategies. (Typically an additional constraint on the strategies is now imposed to ensure that players do not play in a way that is irrational with respect to the information that they have received so far.",
                "This leads to refinements of Nash equilibrium such as subgame perfect and sequential equilibrium.)",
                "However, in many real-world settings, strategies are not selected in such a simultaneous manner.",
                "Oftentimes, one player (the leader) is able to commit to a strategy before another player (the follower).",
                "This can be due to a variety of reasons.",
                "For example, one of the players may arrive at the site at which the game is to be played before another agent (e.g., in economic settings, one player may enter a market earlier and commit to a way of doing busi82 ness).",
                "Such commitment power has a profound impact on how the game should be played.",
                "For example, the leader may be best off playing a strategy that is dominated in the normal-form representation of the game.",
                "Perhaps the earliest and best-known example of the effect of commitment is that by von Stackelberg [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution.",
                "In general, if commitment to mixed strategies is possible, then (under minor assumptions) it never hurts, and often helps, to commit to a strategy [26].",
                "Being forced to commit to a pure strategy sometimes helps, and sometimes hurts (for example, committing to a pure strategy in rock-paper-scissors before the other players decision will naturally result in a loss).",
                "In this paper, we will assume commitment is always forced; if it is not, the player who has the choice of whether to commit can simply compare the commitment outcome to the non-commitment (simultaneous-move) outcome.",
                "Models of <br>leadership</br> are especially important in settings with multiple self-interested software agents.",
                "Once the code for an agent (or for a team of agents) is finalized and the agent is deployed, the agent is committed to playing the (possibly randomized) strategy that the code prescribes.",
                "Thus, as long as one can credibly show that one cannot change the code later, the code serves as a commitment device.",
                "This holds true for recreational tournaments among agents (e.g., poker tournaments, RoboSoccer), and for industrial applications such as sensor webs.",
                "Finally, there is also an implicit <br>leadership</br> situation in the field of mechanism design, in which one player (the designer) gets to choose the rules of the game that the remaining players then play.",
                "Mechanism design is an extremely important topic to the EC community: the papers published on mechanism design in recent EC conferences are too numerous to cite.",
                "Indeed, the mechanism designer may benefit from committing to a choice that, if the (remaining) agents actions were fixed, would be suboptimal.",
                "For example, in a (first-price) auction, the seller may wish to set a positive (artificial) reserve price for the item, below which the item will not be sold-even if the seller values the item at 0.",
                "In hindsight (after the bids have come in), this (na¨ıvely) appears suboptimal: if a bid exceeding the reserve price came in, the reserve price had no effect, and if no such bid came in, the seller would have been better off accepting a lower bid.",
                "Of course, the reason for setting the reserve price is that it incentivizes the bidders to bid higher, and because of this, setting artificial reserve prices can actually increase expected revenue to the seller.",
                "A significant amount of research has recently been devoted to the computation of solutions according to various solution concepts for settings in which the agents choose their strategies simultaneously, such as dominance [7, 11, 3] and (especially) Nash equilibrium [8, 21, 16, 15, 2, 22, 23, 4].",
                "However, the computation of the optimal strategy to commit to in a <br>leadership</br> situation has gone ignored.",
                "Theoretically, <br>leadership</br> situations can simply be thought of as an extensive-form game in which one player chooses a strategy (for the original game) first.",
                "The number of strategies in this extensive-form game, however, can be exceedingly large.",
                "For example, if the leader is able to commit to a mixed strategy in the original game, then every one of the (continuum of) mixed strategies constitutes a pure strategy in the extensive-form representation of the <br>leadership</br> situation. (We note that a commitment to a distribution is not the same as a distribution over commitments.)",
                "Moreover, if the original game is itself an extensive-form game, the number of strategies in the extensive-form representation of the <br>leadership</br> situation (which is a different extensive-form game) becomes even larger.",
                "Because of this, it is usually not computationally feasible to simply transform the original game into the extensive-form representation of the <br>leadership</br> situation; instead, we have to analyze the game in its original representation.",
                "In this paper, we study how to compute the optimal strategy to commit to, both in normal-form games (Section 2) and in Bayesian games, which are a special case of extensiveform games (Section 3). 2.",
                "NORMAL-FORM GAMES In this section, we study how to compute the optimal strategy to commit to for games represented in normal form. 2.1 Definitions In a normal-form game, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a pure strategy for every player, also known as a profile of pure strategies) to a real number.",
                "To ease notation, in the case of two players, we will refer to player 1s pure strategy set as S, and player 2s pure strategy set as T. Such games can be represented in (bi-)matrix form, in which the rows correspond to player 1s pure strategies, the columns correspond to player 2s pure strategies, and the entries of the matrix give the row and column players utilities (in that order) for the corresponding outcome of the game.",
                "In the case of three players, we will use R, S, and T, for player 1, 2, and 3s pure strategies, respectively.",
                "A mixed strategy for a player is a probability distribution over that players pure strategies.",
                "In the case of two-player games, we will refer to player 1 as the leader and player 2 as the follower.",
                "Before defining optimal <br>leadership</br> strategies, consider the following game which illustrates the effect of the leaders ability to commit. 2, 1 4, 0 1, 0 3, 1 In this normal-form representation, the bottom strategy for the row player is strictly dominated by the top strategy.",
                "Nevertheless, if the row player has the ability to commit to a pure strategy before the column player chooses his strategy, the row player should commit to the bottom strategy: doing so will make the column player prefer to play the right strategy, leading to a utility of 3 for the row player.",
                "By contrast, if the row player were to commit to the top strategy, the column player would prefer to play the left strategy, leading to a utility of only 2 for the row player.",
                "If the row player is able to commit to a mixed strategy, then she can get an even greater (expected) utility: if the row player commits to placing probability p > 1/2 on the bottom strategy, then the column player will still prefer to play the right strategy, and the row players expected utility will be 3p + 4(1 − p) = 4 − p ≥ 3.",
                "If the row player plays each strategy with probability exactly 1/2, the column player is 83 indifferent between the strategies.",
                "In such cases, we will assume that the column player will choose the strategy that maximizes the row players utility (in this case, the right strategy).",
                "Hence, the optimal mixed strategy to commit to for the row player is p = 1/2.",
                "There are a few good reasons for this assumption.",
                "If we were to assume the opposite, then there would not exist an optimal strategy for the row player in the example game: the row player would play the bottom strategy with probability p = 1/2 + with > 0, and the smaller , the better the utility for the row player.",
                "By contrast, if we assume that the follower always breaks ties in the leaders favor, then an optimal mixed strategy for the leader always exists, and this corresponds to a subgame perfect equilibrium of the extensive-form representation of the <br>leadership</br> situation.",
                "In any case, this is a standard assumption for such models (e.g. [20]), although some work has investigated what can happen in the other subgame perfect equilibria [26]. (For generic two-player games, the leaders subgame-perfect equilibrium payoff is unique.)",
                "Also, the same assumption is typically used in mechanism design, in that it is assumed that if an agent is indifferent between revealing his preferences truthfully and revealing them falsely, he will report them truthfully.",
                "Given this assumption, we can safely refer to optimal <br>leadership</br> strategies rather than having to use some equilibrium notion.",
                "Hence, for the purposes of this paper, an optimal strategy to commit to in a 2-player game is a strategy s ∈ S that maximizes maxt∈BR(s) ul(s, t), where BR(s) = arg maxt∈T uf (s, t). (ul and uf are the leader and followers utility functions, respectively.)",
                "We can have S = S for the case of commitment to pure strategies, or S = ∆(S), the set of probability distributions over S, for the case of commitment to mixed strategies. (We note that replacing T by ∆(T) makes no difference in this definition.)",
                "For games with more than two players, in which the players commit to their strategies in sequence, we define optimal strategies to commit to recursively.",
                "After the leader commits to a strategy, the game to be played by the remaining agents is itself a (smaller) <br>leadership</br> game.",
                "Thus, we define an optimal strategy to commit to as a strategy that maximizes the leaders utility, assuming that the play of the remaining agents is itself optimal under this definition, and maximizes the leaders utility among all optimal ways to play the remaining game.",
                "Again, commitment to mixed strategies may or may not be a possibility for every player (although for the last player it does not matter if we allow for commitment to mixed strategies). 2.2 Commitment to pure strategies We first study how to compute the optimal pure strategy to commit to.",
                "This is relatively simple, because the number of strategies to commit to is not very large. (In the following, #outcomes is the number of complete strategy profiles.)",
                "Theorem 1.",
                "Under commitment to pure strategies, the set of all optimal strategy profiles in a normal-form game can be found in O(#players · #outcomes) time.",
                "Proof.",
                "Each pure strategy that the first player may commit to will induce a subgame for the remaining players.",
                "We can solve each such subgame recursively to find all of its optimal strategy profiles; each of these will give the original leader some utility.",
                "Those that give the leader maximal utility correspond exactly to the optimal strategy profiles of the original game.",
                "We now present the algorithm formally.",
                "Let Su(G, s1) be the subgame that results after the first (remaining) player in G plays s1 ∈ SG 1 .",
                "A game with 0 players is simply an outcome of the game.",
                "The function Append(s, O) appends the strategy s to each of the vectors of strategies in the set O.",
                "Let e be the empty vector with no elements.",
                "In a slight abuse of notation, we will write uG 1 (C) when all strategy profiles in the set C give player 1 the same utility in the game G. (Here, player 1 is the first remaining player in the subgame G, not necessarily player 1 in the original game.)",
                "We note that arg max is set-valued.",
                "Then, the following algorithm computes all optimal strategy profiles: Algorithm Solve(G) if G has 0 players return {e} C ← ∅ for all s1 ∈ SG 1 { O ← Solve(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) if C = ∅ or uG 1 (s1, O ) = uG 1 (C) C ← C∪Append(s1, O ) if uG 1 (s1, O ) > uG 1 (C) C ←Append(s1, O ) } return C Every outcome is (potentially) examined by every player, which leads to the given runtime bound.",
                "As an example of how the algorithm works, consider the following 3-player game, in which the first player chooses the left or right matrix, the second player chooses a row, and the third player chooses a column. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 3,0,0 First we eliminate the outcomes that do not correspond to best responses for the third player (removing them from the matrix): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Next, we remove the entries in which the third player does not break ties in favor of the second player, as well as entries that do not correspond to best responses for the second player. 0,1,1 2,1,1 1,1,1 0,5,1 Finally, we remove the entries in which the second and third players do not break ties in favor of the first player, as well as entries that do not correspond to best responses for the first player. 2,1,1 84 Hence, in optimal play, the first player chooses the left matrix, the second player chooses the middle row, and the third player chooses the left column. (We note that this outcome is Pareto-dominated by (Right, Middle, Left).)",
                "For general normal-form games, each players utility for each of the outcomes has to be explicitly represented in the input, so that the input size is itself Ω(#players · #outcomes).",
                "Therefore, the algorithm is in fact a linear-time algorithm. 2.3 Commitment to mixed strategies In the special case of two-player zero-sum games, computing an optimal mixed strategy for the leader to commit to is equivalent to computing a minimax strategy, which minimizes the maximum expected utility that the opponent can obtain.",
                "Minimax strategies constitute the only natural solution concept for two-player zero-sum games: von Neumanns Minimax Theorem [24] states that in two-player zero-sum games, it does not matter (in terms of the players utilities) which player gets to commit to a mixed strategy first, and a profile of mixed strategies is a Nash equilibrium if and only if both strategies are minimax strategies.",
                "It is well-known that a minimax strategy can be found in polynomial time, using linear programming [17].",
                "Our first result in this section generalizes this result, showing that an optimal mixed strategy for the leader to commit to can be efficiently computed in general-sum two-player games, again using linear programming.",
                "Theorem 2.",
                "In 2-player normal-form games, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders utility.",
                "Such a mixed strategy can be computed using the following simple linear program: maximize s∈S psul(s, t) subject to for all t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1 We note that this program may be infeasible for some follower strategies t, for example, if t is a strictly dominated strategy.",
                "Nevertheless, the program must be feasible for at least some follower strategies; among these follower strategies, choose a strategy t∗ that maximizes the linear programs solution value.",
                "Then, if the leader chooses as her mixed strategy the optimal settings of the variables ps for the linear program for t∗ , and the follower plays t∗ , this constitutes an optimal strategy profile.",
                "In the following result, we show that we cannot expect to solve the problem more efficiently than linear programming, because we can reduce any linear program with a probability constraint on its variables to a problem of computing the optimal mixed strategy to commit to in a 2-player normalform game.",
                "Theorem 3.",
                "Any linear program whose variables xi (with xi ∈ R≥0 ) must satsify i xi = 1 can be modeled as a problem of computing the optimal mixed strategy to commit to in a 2-player normal-form game.",
                "Proof.",
                "Let the leader have a pure strategy i for every variable xi.",
                "Let the column player have one pure strategy j for every constraint in the linear program (other than i xi = 1), and a single additional pure strategy 0.",
                "Let the utility functions be as follows.",
                "Writing the objective of the linear program as maximize i cixi, for any i, let ul(i, 0) = ci and uf (i, 0) = 0.",
                "Writing the jth constraint of the linear program (not including i xi = 1) as i aijxi ≤ bj, for any i, j > 0, let ul(i, j) = mini ci − 1 and uf (i, j) = aij − bj.",
                "For example, consider the following linear program. maximize 2x1 + x2 subject to x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 The optimal solution to this program is x1 = 1/3, x2 = 2/3.",
                "Our reduction transforms this program into the following leader-follower game (where the leader is the row player). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 Indeed, the optimal strategy for the leader is to play the top strategy with probability 1/3 and the bottom strategy with probability 2/3.",
                "We now show that the reduction works in general.",
                "Clearly, the leader wants to incentivize the follower to play 0, because the utility that the leader gets when the follower plays 0 is always greater than when the follower does not play 0.",
                "In order for the follower not to prefer playing j > 0 rather than 0, it must be the case that i pl(i)(aij − bj) ≤ 0, or equivalently i pl(i)aij ≤ bj.",
                "Hence the leader will get a utility of at least mini ci if and only if there is a feasible solution to the constraints.",
                "Given that the pl(i) incentivize the follower to play 0, the leader attempts to maximize i pl(i)ci.",
                "Thus the leader must solve the original linear program.",
                "As an alternative proof of Theorem 3, one may observe that it is known that finding a minimax strategy in a zerosum game is as hard as the linear programming problem [6], and as we pointed out at the beginning of this section, computing a minimax strategy in a zero-sum game is a special case of the problem of computing an optimal mixed strategy to commit to.",
                "This polynomial-time solvability of the problem of computing an optimal mixed strategy to commit to in two-player normal-form games contrasts with the unknown complexity of computing a Nash equilibrium in such games [21], as well as with the NP-hardness of finding a Nash equilibrium with maximum utility for a given player in such games [8, 2].",
                "Unfortunately, this result does not generalize to more than two players-here, the problem becomes NP-hard.",
                "To show this, we reduce from the VERTEX-COVER problem.",
                "Definition 1.",
                "In VERTEX-COVER, we are given a graph G = (V, E) and an integer K. We are asked whether there 85 exists a subset of the vertices S ⊆ V , with |S| = K, such that every edge e ∈ E has at least one of its endpoints in S. BALANCED-VERTEX-COVER is the special case of VERTEX-COVER in which K = |V |/2.",
                "VERTEX-COVER is NP-complete [9].",
                "The following lemma shows that the hardness remains if we require K = |V |/2. (Similar results have been shown for other NP-complete problems.)",
                "Lemma 1.",
                "BALANCED-VERTEX-COVER is NP-complete.",
                "Proof.",
                "Membership in NP follows from the fact that the problem is a special case of VERTEX-COVER, which is in NP.",
                "To show NP-hardness, we reduce an arbitrary VERTEX-COVER instance to a BALANCED-VERTEXCOVER instance, as follows.",
                "If, for the VERTEX-COVER instance, K > |V |/2, then we simply add isolated vertices that are disjoint from the rest of the graph, until K = |V |/2.",
                "If K < |V |/2, we add isolated triangles (that is, the complete graph on three vertices) to the graph, increasing K by 2 every time, until K = |V |/2.",
                "Theorem 4.",
                "In 3-player normal-form games, finding an optimal mixed strategy to commit to is NP-hard.",
                "Proof.",
                "We reduce an arbitrary BALANCED-VERTEXCOVER instance to the following 3-player normal-form game.",
                "For every vertex v, each of the three players has a pure strategy corresponding to that vertex (rv, sv, tv, respectively).",
                "In addition, for every edge e, the third player has a pure strategy te; and finally, the third player has one additional pure strategy t0.",
                "The utilities are as follows: • for all r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • for all r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • for all v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • for all v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • for all v ∈ V , for all r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V | |V |−2 ; • for all e ∈ E, s ∈ S, for both v ∈ e, u3(rv, s, te) = 0; • for all e ∈ E, s ∈ S, for all v /∈ e, u3(rv, s, te) = |V | |V |−2 . • for all r ∈ R, s ∈ S, u3(r, s, t0) = 1.",
                "We note that players 1 and 2 have the same utility function.",
                "We claim that there is an optimal strategy profile in which players 1 and 2 both obtain 1 (their maximum utility) if and only if there is a solution to the BALANCED-VERTEXCOVER problem. (Otherwise, these players will both obtain 0.)",
                "First, suppose there exists a solution to the BALANCEDVERTEX-COVER problem.",
                "Then, let player 1 play every rv such that v is in the cover with probability 2 |V | , and let player 2 play every sv such that v is not in the cover with probability 2 |V | .",
                "Then, for player 3, the expected utility of playing tv (for any v) is (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of 2 |V | that rv or sv is played.",
                "Additionally, the expected utility of playing te (for any e) is at most (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of at least 2 |V | that some rv with v ∈ e is played (because player 1 is randomizing over the pure strategies corresponding to the cover).",
                "It follows that playing t0 is a best response for player 3, giving players 1 and 2 a utility of 1.",
                "Now, suppose that players 1 and 2 obtain 1 in optimal play.",
                "Then, it must be the case that player 3 plays t0.",
                "Hence, for every v ∈ V , there must be a probability of at least 2 |V | that either rv or sv is played, for otherwise player 3 would be better off playing tv.",
                "Because players 1 and 2 have only a total probability of 2 to distribute, it must be the case that for each v, either rv or sv is played with probability 2 |V | , and the other is played with probability 0. (It is not possible for both to have nonzero probability, because then there would be some probability that both are played simultaneously (correlation is not possible), hence the total probability of at least one being played could not be high enough for all vertices.)",
                "Thus, for exactly half the v ∈ V , player 1 places probability 2 |V | on rv.",
                "Moreover, for every e ∈ E, there must be a probability of at least 2 |V | that some rv with v ∈ e is played, for otherwise player 3 would be better off playing te.",
                "Thus, the v ∈ V such that player 1 places probability 2 |V | on rv constitute a balanced vertex cover. 3.",
                "BAYESIAN GAMES So far, we have restricted our attention to normal-form games.",
                "In a normal-form game, it is assumed that every agent knows every other agents preferences over the outcomes of the game.",
                "In general, however, agents may have some private information about their preferences that is not known to the other agents.",
                "Moreover, at the time of commitment to a strategy, the agents may not even know their own (final) preferences over the outcomes of the game yet, because these preferences may be dependent on a context that has yet to materialize.",
                "For example, when the code for a trading agent is written, it may not yet be clear how that agent will value resources that it will negotiate over later, because this depends on information that is not yet available at the time at which the code is written (such as orders that will have been placed to the agent before the negotiation).",
                "In this section, we will study commitment in Bayesian games, which can model such uncertainty over preferences. 3.1 Definitions In a Bayesian game, every player i has a set of actions Si, a set of types Θi with an associated probability distribution πi : Θi → [0, 1], and, for each type θi, a utility function uθi i : S1 × S2 × . . . × Sn → R. A pure strategy in a Bayesian game is a mapping from the players types to actions, σi : Θi → Si. (Bayesian games can be rewritten in normal form by enumerating every pure strategy σi, but this will cause an exponential blowup in the size of the representation of the game and therefore cannot lead to efficient algorithms.)",
                "The strategy that the leader should commit to depends on whether, at the time of commitment, the leader knows her own type.",
                "If the leader does know her own type, the other types that the leader might have had become irrelevant and the leader should simply commit to the strategy that is optimal for the type.",
                "However, as argued above, the leader does not necessarily know her own type at the time of commitment (e.g., the time at which the code is submitted).",
                "In this case, the leader must commit to a strategy that is 86 dependent upon the leaders eventual type.",
                "We will study this latter model, although we will pay specific attention to the case where the leader has only a single type, which is effectively the same as the former model. 3.2 Commitment to pure strategies It turns out that computing an optimal pure strategy to commit to is hard in Bayesian games, even with two players.",
                "Theorem 5.",
                "Finding an optimal pure strategy to commit to in 2-player Bayesian games is NP-hard, even when the follower has only a single type.",
                "Proof.",
                "We reduce an arbitrary VERTEX-COVER instance to the following Bayesian game between the leader and the follower.",
                "The leader has K types θ1, θ2, . . . , θK , each occurring with probability 1/K, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has only a single type; for each edge e ∈ E, the follower has an action te, and the follower has a single additional action t0.",
                "The utility function for the leader is given by, for all θl ∈ Θl and all s ∈ S, u θl l (s, t0) = 1, and for all e ∈ E, u θl l (s, te) = 0.",
                "The followers utility is given by: • For all v ∈ V , for all e ∈ E with v /∈ e, uf (sv, te) = 1; • For all v ∈ V , for all e ∈ E with v ∈ e, uf (sv, te) = −K; • For all v ∈ V , uf (sv, t0) = 0.",
                "We claim that the leader can get a utility of 1 if and only if there is a solution to the VERTEX-COVER instance.",
                "First, suppose that there is a solution to the VERTEXCOVER instance.",
                "Then, the leader can commit to a pure strategy such that for each vertex v in the cover, the leader plays sv for some type.",
                "Then, the followers utility for playing te (for any e ∈ E) is at most K−1 K + 1 K (−K) = − 1 K , so that the follower will prefer to play t0, which gives the leader a utility of 1, as required.",
                "Now, suppose that there is a pure strategy for the leader that will give the leader a utility of 1.",
                "Then, the follower must play t0.",
                "In order for the follower not to prefer playing te (for any e ∈ E) instead, for at least one v ∈ e the leader must play sv for some type θl.",
                "Hence, the set of vertices v that the leader plays for some type must constitute a vertex cover; and this set can have size at most K, because the leader has only K types.",
                "So there is a solution to the VERTEXCOVER instance.",
                "However, if the leader has only a single type, then the problem becomes easy again (#types is the number of types for the follower): Theorem 6.",
                "In 2-player Bayesian games in which the leader has only a single type, an optimal pure strategy to commit to can be found in O(#outcomes · #types) time.",
                "Proof.",
                "For every leader action s, we can compute, for every follower type θf ∈ Θf , which actions t maximize the followers utility; call this set of actions BRθf (s).",
                "Then, the utility that the leader receives for committing to action s can be computed as θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), and the leader can choose the best action to commit to. 3.3 Commitment to mixed strategies In two-player zero-sum imperfect information games with perfect recall (no player ever forgets something that it once knew), a minimax strategy can be constructed in polynomial time [12, 13].",
                "Unfortunately, this result does not extend to computing optimal mixed strategies to commit to in the general-sum case-not even in Bayesian games.",
                "We will exhibit NP-hardness by reducing from the INDEPENDENTSET problem.",
                "Definition 2.",
                "In INDEPENDENT-SET, we are given a graph G = (V, E) and an integer K. We are asked whether there exists a subset of the vertices S ⊆ V , with |S| = K, such that no edge e ∈ E has both of its endpoints in S. Again, this problem is NP-complete [9].",
                "Theorem 7.",
                "Finding an optimal mixed strategy to commit to in 2-player Bayesian games is NP-hard, even when the leader has only a single type and the follower has only two actions.",
                "Proof.",
                "We reduce an arbitrary INDEPENDENT-SET instance to the following Bayesian game between the leader and the follower.",
                "The leader has only a single type, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has a type θv for every v ∈ V , occurring with probability 1 (|E|+1)|V | , and a type θe for every e ∈ E, occurring with probability 1 |E|+1 .",
                "The follower has two actions: t0 and t1.",
                "The leaders utility is given by, for all s ∈ S, ul(s, t0) = 1 and ul(s, t1) = 0.",
                "The followers utility is given by: • For all v ∈ V , uθv f (sv, t1) = 0; • For all v ∈ V and s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • For all v ∈ V and s ∈ S, uθv f (s, t0) = 1; • For all e ∈ E, s ∈ S, uθe f (s, t0) = 1; • For all e ∈ E, for both v ∈ e, uθe f (sv, t1) = 2K 3 ; • For all e ∈ E, for all v /∈ e, uθe f (sv, t1) = 0.",
                "We claim that an optimal strategy to commit to gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | if and only if there is a solution to the INDEPENDENT-SET instance.",
                "First, suppose that there is a solution to the INDEPENDENT-SET instance.",
                "Then, the leader could commit to the following strategy: for every vertex v in the independent set, play the corresponding sv with probability 1/K.",
                "If the follower has type θe for some e ∈ E, the expected utility for the follower of playing t1 is at most 1 K 2K 3 = 2/3, because there is at most one vertex v ∈ e such that sv is played with nonzero probability.",
                "Hence, the follower will play t0 and obtain a utility of 1.",
                "If the follower has type θv for some vertex v in the independent set, the expected utility for the follower of playing t1 is K−1 K K K−1 = 1, because the leader plays sv with probability 1/K.",
                "It follows that the follower (who breaks ties to maximize the leaders utility) will play t0, which also gives a utility of 1 and gives the leader a higher utility.",
                "Hence the leaders expected utility for this strategy is at least |E| |E|+1 + K (|E|+1)|V | , as required. 87 Now, suppose that there is a strategy that gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | .",
                "Then, this strategy must induce the follower to play t0 whenever it has a type of the form θe (because otherwise, the utility could be at most |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ).",
                "Thus, it cannot be the case that for some edge e = (v1, v2) ∈ E, the probability that the leader plays one of sv1 and sv2 is at least 2/K, because then the expected utility for the follower of playing t1 when it has type θe would be at least 2 K 2K 3 = 4/3 > 1.",
                "Moreover, the strategy must induce the follower to play t0 for at least K types of the form θv.",
                "Inducing the follower to play t0 when it has type θv can be done only by playing sv with probability at least 1/K, which will give the follower a utility of at most K−1 K K K−1 = 1 for playing t1.",
                "But then, the set of vertices v such that sv is played with probability at least 1/K must constitute an independent set of size K (because if there were an edge e between two such vertices, it would induce the follower to play t1 for type θe by the above).",
                "By contrast, if the follower has only a single type, then we can generalize the linear programming approach for normalform games: Theorem 8.",
                "In 2-player Bayesian games in which the follower has only a single type, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "We generalize the approach in Theorem 2 as follows.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader for every one of the leaders types such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders ex ante expected utility.",
                "To do so, we generalize the linear program as follows: maximize θl∈Θl π(θl) s∈S pθl s uθl l (s, t) subject to for all t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t ) for all θl ∈ Θl, s∈S p θl s = 1 As in Theorem 2, the solution for the linear program that maximizes the solution value is an optimal strategy to commit to.",
                "This shows an interesting contrast between commitment to pure strategies and commitment to mixed strategies in Bayesian games: for pure strategies, the problem becomes easy if the leader has only a single type (but not if the follower has only a single type), whereas for mixed strategies, the problem becomes easy if the follower has only a single type (but not if the leader has only a single type). 4.",
                "CONCLUSIONS AND FUTURE RESEARCH In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "This requires some equilibrium notion (Nash equilibrium and its refinements), and often leads to the equilibrium selection problem: it is unclear to each individual player according to which equilibrium she should play.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "For example, one agent may arrive at the (real or virtual) site of the game before the other, or, in the specific case of software agents, the code for one agent may be completed and committed before that of another agent.",
                "Such models are synonymously referred to as <br>leadership</br>, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "Specifically, if commitment to mixed strategies is possible, then (optimal) commitment never hurts the leader, and often helps.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored <br>leadership</br> models (with the exception of the interest in mechanism design, where the designer is implicitly in a <br>leadership</br> position).",
                "In this paper, we studied how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "For normal-form games, we showed that the optimal pure strategy to commit to can be found efficiently for any number of players.",
                "An optimal mixed strategy to commit to in a normal-form game can be found efficiently for two players using linear programming (and no more efficiently than that, in the sense that any linear program with a probability constraint can be encoded as such a problem). (This is a generalization of the polynomial-time computability of minimax strategies in normal-form games.)",
                "The problem becomes NP-hard for three (or more) players.",
                "In Bayesian games, the problem of finding an optimal pure strategy to commit to is NP-hard even in two-player games in which the follower has only a single type, although two-player games in which the leader has only a single type can be solved efficiently.",
                "The problem of finding an optimal mixed strategy to commit to in a Bayesian game is NP-hard even in two-player games in which the leader has only a single type, although two-player games in which the follower has only a single type can be solved efficiently using a generalization of the linear progamming approach for normal-form games.",
                "The following two tables summarize these results. 2 players ≥ 3 players normal-form O(#outcomes) O(#outcomes· #players) Bayesian, O(#outcomes· NP-hard 1-type leader #types) Bayesian, NP-hard NP-hard 1-type follower Bayesian (general) NP-hard NP-hard Results for commitment to pure strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.) 88 2 players ≥ 3 players normal-form one LP-solve per NP-hard follower action Bayesian, NP-hard NP-hard 1-type leader Bayesian, one LP-solve per NP-hard 1-type follower follower action Bayesian (general) NP-hard NP-hard Results for commitment to mixed strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.)",
                "Future research can take a number of directions.",
                "First, we can empirically evaluate the techniques presented here on test suites such as GAMUT [19].",
                "We can also study the computation of optimal strategies to commit to in other1 concise representations of normal-form games-for example, in graphical games [10] or local-effect/action graph games [14, 1].",
                "For the cases where computing an optimal strategy to commit to is NP-hard, we can also study the computation of approximately optimal strategies to commit to.",
                "While the correct definition of an approximately optimal strategy is in this setting may appear simple at first-it should be a strategy that, if the following players play optimally, performs almost as well as the optimal strategy in expectation-this definition becomes problematic when we consider that the other players may also be playing only approximately optimally.",
                "One may also study models in which multiple (but not all) players commit at the same time.",
                "Another interesting direction to pursue is to see if computing optimal mixed strategies to commit to can help us in, or otherwise shed light on, computing Nash equilibria.",
                "Often, optimal mixed strategies to commit to are also Nash equilibrium strategies (for example, in two-player zero-sum games this is always true), although this is not always the case (for example, as we already pointed out, sometimes the optimal strategy to commit to is a strictly dominated strategy, which can never be a Nash equilibrium strategy). 5.",
                "REFERENCES [1] N. A. R. Bhat and K. Leyton-Brown.",
                "Computing Nash equilibria of action-graph games.",
                "In Proceedings of the 20th Annual Conference on Uncertainty in Artificial Intelligence (UAI), Banff, Canada, 2004. [2] V. Conitzer and T. Sandholm.",
                "Complexity results about Nash equilibria.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pages 765-771, Acapulco, Mexico, 2003. [3] V. Conitzer and T. Sandholm.",
                "Complexity of (iterated) dominance.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 88-97, Vancouver, Canada, 2005. [4] V. Conitzer and T. Sandholm.",
                "A generalized strategy eliminability criterion and computational methods for applying it.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 483-488, Pittsburgh, PA, USA, 2005. [5] A.",
                "A. Cournot.",
                "Recherches sur les principes math´ematiques de la th´eorie des richesses (Researches 1 Bayesian games are one potentially concise representation of normal-form games. into the Mathematical Principles of the Theory of Wealth).",
                "Hachette, Paris, 1838. [6] G. Dantzig.",
                "A proof of the equivalence of the programming problem and the game problem.",
                "In T. Koopmans, editor, Activity Analysis of Production and Allocation, pages 330-335.",
                "John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel.",
                "The complexity of eliminating dominated strategies.",
                "Mathematics of Operation Research, 18:553-565, 1993. [8] I. Gilboa and E. Zemel.",
                "Nash and correlated equilibria: Some complexity considerations.",
                "Games and Economic Behavior, 1:80-93, 1989. [9] R. Karp.",
                "Reducibility among combinatorial problems.",
                "In R. E. Miller and J. W. Thatcher, editors, Complexity of Computer Computations, pages 85-103.",
                "Plenum Press, NY, 1972. [10] M. Kearns, M. Littman, and S. Singh.",
                "Graphical models for game theory.",
                "In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou, and J. N. Tsitsiklis.",
                "A note on strategy elimination in bimatrix games.",
                "Operations Research Letters, 7(3):103-107, 1988. [12] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [14] K. Leyton-Brown and M. Tennenholtz.",
                "Local-effect games.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), Acapulco, Mexico, 2003. [15] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 36-41, San Diego, CA, 2003. [16] M. Littman and P. Stone.",
                "A polynomial-time Nash equilibrium algorithm for repeated games.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 48-54, San Diego, CA, 2003. [17] R. D. Luce and H. Raiffa.",
                "Games and Decisions.",
                "John Wiley and Sons, New York, 1957.",
                "Dover republication 1989. [18] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown, and Y. Shoham.",
                "Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms.",
                "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), New York, NY, USA, 2004. [20] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "MIT Press, 1994. [21] C. Papadimitriou.",
                "Algorithms, games and the Internet.",
                "In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 749-753, 2001. 89 [22] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 664-669, San Jose, CA, USA, 2004. [23] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 495-501, Pittsburgh, PA, USA, 2005. [24] J. von Neumann.",
                "Zur Theorie der Gesellschaftsspiele.",
                "Mathematische Annalen, 100:295-320, 1927. [25] H. von Stackelberg.",
                "Marktform und Gleichgewicht.",
                "Springer, Vienna, 1934. [26] B. von Stengel and S. Zamir.",
                "<br>leadership</br> with commitment to mixed strategies.",
                "CDAM Research Report LSE-CDAM-2004-01, London School of Economics, Feb. 2004. 90"
            ],
            "original_annotated_samples": [
                "Such models are synonymously referred to as <br>leadership</br>, commitment, or Stackelberg models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored <br>leadership</br> models (with the exception of the interest in mechanism design, where the designer is implicitly in a <br>leadership</br> position).",
                "Models of <br>leadership</br> are especially important in settings with multiple self-interested software agents.",
                "Finally, there is also an implicit <br>leadership</br> situation in the field of mechanism design, in which one player (the designer) gets to choose the rules of the game that the remaining players then play.",
                "However, the computation of the optimal strategy to commit to in a <br>leadership</br> situation has gone ignored."
            ],
            "translated_annotated_samples": [
                "Tales modelos son referidos indistintamente como <br>modelos de liderazgo</br>, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente.",
                "El reciente aumento en el interés por las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de <br>liderazgo</br> (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de <br>liderazgo</br>).",
                "Los modelos de <br>liderazgo</br> son especialmente importantes en entornos con múltiples agentes de software con intereses propios.",
                "Finalmente, también existe una situación de <br>liderazgo</br> implícito en el campo del diseño de mecanismos, en la cual un jugador (el diseñador) tiene la oportunidad de elegir las reglas del juego que los demás jugadores luego siguen.",
                "Sin embargo, se ha ignorado el cálculo de la estrategia óptima a comprometerse en una situación de <br>liderazgo</br>."
            ],
            "translated_text": "En sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias simultáneamente. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Tales modelos son referidos indistintamente como <br>modelos de liderazgo</br>, compromiso o Stackelberg, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. El reciente aumento en el interés por las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de <br>liderazgo</br> (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de <br>liderazgo</br>). En este artículo, estudiamos cómo calcular estrategias óptimas a comprometerse tanto en el compromiso de estrategias puras como en el compromiso de estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Ofrecemos tanto resultados positivos (algoritmos eficientes) como resultados negativos (resultados de NP-hardness). Categorías y Descriptores de Asignaturas J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas Términos Generales Algoritmos, Economía, Teoría 1. En sistemas multiagentes con agentes auto-interesados (incluyendo la mayoría de los entornos económicos), la acción óptima que un agente debe tomar depende de las acciones que tomen los otros agentes. Para analizar cómo un agente debería comportarse en tales situaciones, es necesario aplicar las herramientas de la teoría de juegos. Normalmente, cuando se modela un escenario estratégico en el marco de la teoría de juegos, se asume que los jugadores eligen sus estrategias de forma simultánea. Esto es especialmente cierto cuando el escenario se modela como un juego en forma normal, que solo especifica la utilidad de cada agente como una función del vector de estrategias que los agentes eligen, y no proporciona información sobre el orden en que los agentes toman sus decisiones y lo que los agentes observan sobre las decisiones anteriores de otros agentes. Dado que el juego está modelado en forma normal, típicamente se analiza utilizando el concepto de equilibrio de Nash. Un equilibrio de Nash especifica una estrategia para cada jugador, de modo que ningún jugador tenga un incentivo para desviarse individualmente de este perfil de estrategias. (Por lo general, se permite que las estrategias sean mixtas, es decir, distribuciones de probabilidad sobre las estrategias originales (puras).) Un equilibrio de Nash (de estrategia mixta) está garantizado de existir en juegos finitos [18], pero un problema es que puede haber múltiples equilibrios de Nash. Esto conduce al problema de selección de equilibrio de cómo un agente puede saber qué estrategia jugar si no sabe qué equilibrio se va a jugar. Cuando el escenario se modela como un juego de forma extensiva, es posible especificar que algunos jugadores reciben información sobre las acciones tomadas por otros antes en el juego antes de decidir su acción. Sin embargo, en general, los jugadores no saben todo lo que sucedió anteriormente en el juego. Por lo tanto, estos juegos suelen ser analizados todavía utilizando un concepto de equilibrio, donde se especifica una estrategia mixta para cada jugador, y se requiere que la estrategia de cada jugador sea una mejor respuesta a las estrategias de los demás. (Normalmente se impone ahora una restricción adicional en las estrategias para garantizar que los jugadores no jueguen de una manera irracional con respecto a la información que han recibido hasta el momento). Esto conduce a refinamientos del equilibrio de Nash como el equilibrio perfecto en subjuegos y el equilibrio secuencial. Sin embargo, en muchos entornos del mundo real, las estrategias no se seleccionan de manera simultánea. A menudo, un jugador (el líder) puede comprometerse con una estrategia antes que otro jugador (el seguidor). Esto puede deberse a una variedad de razones. Por ejemplo, uno de los jugadores puede llegar al lugar donde se jugará el juego antes que otro agente (por ejemplo, en entornos económicos, un jugador puede ingresar al mercado antes y comprometerse con una forma de hacer negocios). Un compromiso tan poderoso tiene un impacto profundo en cómo debería jugarse el juego. Por ejemplo, el líder puede estar mejor jugando una estrategia que esté dominada en la representación de forma normal del juego. Quizás el ejemplo más temprano y conocido del efecto del compromiso es el de von Stackelberg [25], quien demostró que, en el modelo de duopolio de Cournot [5], si una empresa puede comprometerse con una cantidad de producción primero, esa empresa lo hará mucho mejor que en la solución de movimiento simultáneo (Nash). En general, si es posible comprometerse con estrategias mixtas, entonces (bajo suposiciones menores) nunca perjudica, y a menudo ayuda, comprometerse con una estrategia [26]. Verse obligado a comprometerse con una estrategia pura a veces ayuda y a veces perjudica (por ejemplo, comprometerse con una estrategia pura en piedra-papel-tijeras antes de la decisión de los otros jugadores naturalmente resultará en una derrota). En este documento, asumiremos que el compromiso siempre es forzado; si no lo es, el jugador que tiene la opción de comprometerse simplemente puede comparar el resultado del compromiso con el resultado de no comprometerse (movimiento simultáneo). Los modelos de <br>liderazgo</br> son especialmente importantes en entornos con múltiples agentes de software con intereses propios. Una vez que el código de un agente (o de un equipo de agentes) está finalizado y el agente es desplegado, el agente se compromete a jugar la estrategia (posiblemente aleatoria) que el código prescribe. Por lo tanto, siempre y cuando se pueda demostrar de manera creíble que no se puede cambiar el código más tarde, el código funciona como un dispositivo de compromiso. Esto es válido para torneos recreativos entre agentes (por ejemplo, torneos de póker, RoboSoccer) y para aplicaciones industriales como redes de sensores. Finalmente, también existe una situación de <br>liderazgo</br> implícito en el campo del diseño de mecanismos, en la cual un jugador (el diseñador) tiene la oportunidad de elegir las reglas del juego que los demás jugadores luego siguen. El diseño de mecanismos es un tema extremadamente importante para la comunidad de EC: los artículos publicados sobre diseño de mecanismos en las recientes conferencias de EC son demasiados para citar. De hecho, el diseñador del mecanismo puede beneficiarse al comprometerse con una elección que, si las acciones de los agentes (restantes) estuvieran fijas, sería subóptima. Por ejemplo, en una subasta (a precio fijo), el vendedor puede desear establecer un precio de reserva positivo (artificial) para el artículo, por debajo del cual el artículo no se venderá, incluso si el vendedor valora el artículo en 0. En retrospectiva (después de recibir las ofertas), esto (ingenuamente) parece subóptimo: si llegaba una oferta que superaba el precio de reserva, el precio de reserva no tenía efecto, y si no llegaba tal oferta, el vendedor hubiera estado mejor aceptando una oferta más baja. Por supuesto, la razón para establecer el precio de reserva es incentivar a los postores a ofertar más alto, y debido a esto, establecer precios de reserva artificiales puede aumentar realmente los ingresos esperados para el vendedor. Recientemente se ha dedicado una cantidad significativa de investigación al cálculo de soluciones de acuerdo con varios conceptos de solución para escenarios en los que los agentes eligen sus estrategias simultáneamente, como la dominancia [7, 11, 3] y (especialmente) el equilibrio de Nash [8, 21, 16, 15, 2, 22, 23, 4]. Sin embargo, se ha ignorado el cálculo de la estrategia óptima a comprometerse en una situación de <br>liderazgo</br>. ",
            "candidates": [],
            "error": [
                [
                    "modelos de liderazgo",
                    "liderazgo",
                    "liderazgo",
                    "liderazgo",
                    "liderazgo",
                    "liderazgo"
                ]
            ]
        },
        "stackelberg": {
            "translated_key": "Stackelberg",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Computing the Optimal Strategy to Commit to∗ Vincent Conitzer Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University Computer Science Department 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "Such models are synonymously referred to as leadership, commitment, or <br>stackelberg</br> models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "We give both positive results (efficient algorithms) and negative results (NP-hardness results).",
                "Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent systems with self-interested agents (including most economic settings), the optimal action for one agent to take depends on the actions that the other agents take.",
                "To analyze how an agent should behave in such settings, the tools of game theory need to be applied.",
                "Typically, when a strategic setting is modeled in the framework of game theory, it is assumed that players choose their strategies simultaneously.",
                "This is especially true when the setting is modeled as a normal-form game, which only specifies each agents utility as a function of the vector of strategies that the agents choose, and does not provide any information on the order in which agents make their decisions and what the agents observe about earlier decisions by other agents.",
                "Given that the game is modeled in normal form, it is typically analyzed using the concept of Nash equilibrium.",
                "A Nash equilibrium specifies a strategy for each player, such that no player has an incentive to individually deviate from this profile of strategies. (Typically, the strategies are allowed to be mixed, that is, probability distributions over the original (pure) strategies.)",
                "A (mixed-strategy) Nash equilibrium is guaranteed to exist in finite games [18], but one problem is that there may be multiple Nash equilibria.",
                "This leads to the equilibrium selection problem of how an agent can know which strategy to play if it does not know which equilibrium is to be played.",
                "When the setting is modeled as an extensive-form game, it is possible to specify that some players receive some information about actions taken by others earlier in the game before deciding on their action.",
                "Nevertheless, in general, the players do not know everything that happened earlier in the game.",
                "Because of this, these games are typically still analyzed using an equilibrium concept, where one specifies a mixed strategy for each player, and requires that each players strategy is a best response to the others strategies. (Typically an additional constraint on the strategies is now imposed to ensure that players do not play in a way that is irrational with respect to the information that they have received so far.",
                "This leads to refinements of Nash equilibrium such as subgame perfect and sequential equilibrium.)",
                "However, in many real-world settings, strategies are not selected in such a simultaneous manner.",
                "Oftentimes, one player (the leader) is able to commit to a strategy before another player (the follower).",
                "This can be due to a variety of reasons.",
                "For example, one of the players may arrive at the site at which the game is to be played before another agent (e.g., in economic settings, one player may enter a market earlier and commit to a way of doing busi82 ness).",
                "Such commitment power has a profound impact on how the game should be played.",
                "For example, the leader may be best off playing a strategy that is dominated in the normal-form representation of the game.",
                "Perhaps the earliest and best-known example of the effect of commitment is that by von <br>stackelberg</br> [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution.",
                "In general, if commitment to mixed strategies is possible, then (under minor assumptions) it never hurts, and often helps, to commit to a strategy [26].",
                "Being forced to commit to a pure strategy sometimes helps, and sometimes hurts (for example, committing to a pure strategy in rock-paper-scissors before the other players decision will naturally result in a loss).",
                "In this paper, we will assume commitment is always forced; if it is not, the player who has the choice of whether to commit can simply compare the commitment outcome to the non-commitment (simultaneous-move) outcome.",
                "Models of leadership are especially important in settings with multiple self-interested software agents.",
                "Once the code for an agent (or for a team of agents) is finalized and the agent is deployed, the agent is committed to playing the (possibly randomized) strategy that the code prescribes.",
                "Thus, as long as one can credibly show that one cannot change the code later, the code serves as a commitment device.",
                "This holds true for recreational tournaments among agents (e.g., poker tournaments, RoboSoccer), and for industrial applications such as sensor webs.",
                "Finally, there is also an implicit leadership situation in the field of mechanism design, in which one player (the designer) gets to choose the rules of the game that the remaining players then play.",
                "Mechanism design is an extremely important topic to the EC community: the papers published on mechanism design in recent EC conferences are too numerous to cite.",
                "Indeed, the mechanism designer may benefit from committing to a choice that, if the (remaining) agents actions were fixed, would be suboptimal.",
                "For example, in a (first-price) auction, the seller may wish to set a positive (artificial) reserve price for the item, below which the item will not be sold-even if the seller values the item at 0.",
                "In hindsight (after the bids have come in), this (na¨ıvely) appears suboptimal: if a bid exceeding the reserve price came in, the reserve price had no effect, and if no such bid came in, the seller would have been better off accepting a lower bid.",
                "Of course, the reason for setting the reserve price is that it incentivizes the bidders to bid higher, and because of this, setting artificial reserve prices can actually increase expected revenue to the seller.",
                "A significant amount of research has recently been devoted to the computation of solutions according to various solution concepts for settings in which the agents choose their strategies simultaneously, such as dominance [7, 11, 3] and (especially) Nash equilibrium [8, 21, 16, 15, 2, 22, 23, 4].",
                "However, the computation of the optimal strategy to commit to in a leadership situation has gone ignored.",
                "Theoretically, leadership situations can simply be thought of as an extensive-form game in which one player chooses a strategy (for the original game) first.",
                "The number of strategies in this extensive-form game, however, can be exceedingly large.",
                "For example, if the leader is able to commit to a mixed strategy in the original game, then every one of the (continuum of) mixed strategies constitutes a pure strategy in the extensive-form representation of the leadership situation. (We note that a commitment to a distribution is not the same as a distribution over commitments.)",
                "Moreover, if the original game is itself an extensive-form game, the number of strategies in the extensive-form representation of the leadership situation (which is a different extensive-form game) becomes even larger.",
                "Because of this, it is usually not computationally feasible to simply transform the original game into the extensive-form representation of the leadership situation; instead, we have to analyze the game in its original representation.",
                "In this paper, we study how to compute the optimal strategy to commit to, both in normal-form games (Section 2) and in Bayesian games, which are a special case of extensiveform games (Section 3). 2.",
                "NORMAL-FORM GAMES In this section, we study how to compute the optimal strategy to commit to for games represented in normal form. 2.1 Definitions In a normal-form game, every player i ∈ {1, . . . , n} has a set of pure strategies (or actions) Si, and a utility function ui : S1×S2×. . .×Sn → R that maps every outcome (a vector consisting of a pure strategy for every player, also known as a profile of pure strategies) to a real number.",
                "To ease notation, in the case of two players, we will refer to player 1s pure strategy set as S, and player 2s pure strategy set as T. Such games can be represented in (bi-)matrix form, in which the rows correspond to player 1s pure strategies, the columns correspond to player 2s pure strategies, and the entries of the matrix give the row and column players utilities (in that order) for the corresponding outcome of the game.",
                "In the case of three players, we will use R, S, and T, for player 1, 2, and 3s pure strategies, respectively.",
                "A mixed strategy for a player is a probability distribution over that players pure strategies.",
                "In the case of two-player games, we will refer to player 1 as the leader and player 2 as the follower.",
                "Before defining optimal leadership strategies, consider the following game which illustrates the effect of the leaders ability to commit. 2, 1 4, 0 1, 0 3, 1 In this normal-form representation, the bottom strategy for the row player is strictly dominated by the top strategy.",
                "Nevertheless, if the row player has the ability to commit to a pure strategy before the column player chooses his strategy, the row player should commit to the bottom strategy: doing so will make the column player prefer to play the right strategy, leading to a utility of 3 for the row player.",
                "By contrast, if the row player were to commit to the top strategy, the column player would prefer to play the left strategy, leading to a utility of only 2 for the row player.",
                "If the row player is able to commit to a mixed strategy, then she can get an even greater (expected) utility: if the row player commits to placing probability p > 1/2 on the bottom strategy, then the column player will still prefer to play the right strategy, and the row players expected utility will be 3p + 4(1 − p) = 4 − p ≥ 3.",
                "If the row player plays each strategy with probability exactly 1/2, the column player is 83 indifferent between the strategies.",
                "In such cases, we will assume that the column player will choose the strategy that maximizes the row players utility (in this case, the right strategy).",
                "Hence, the optimal mixed strategy to commit to for the row player is p = 1/2.",
                "There are a few good reasons for this assumption.",
                "If we were to assume the opposite, then there would not exist an optimal strategy for the row player in the example game: the row player would play the bottom strategy with probability p = 1/2 + with > 0, and the smaller , the better the utility for the row player.",
                "By contrast, if we assume that the follower always breaks ties in the leaders favor, then an optimal mixed strategy for the leader always exists, and this corresponds to a subgame perfect equilibrium of the extensive-form representation of the leadership situation.",
                "In any case, this is a standard assumption for such models (e.g. [20]), although some work has investigated what can happen in the other subgame perfect equilibria [26]. (For generic two-player games, the leaders subgame-perfect equilibrium payoff is unique.)",
                "Also, the same assumption is typically used in mechanism design, in that it is assumed that if an agent is indifferent between revealing his preferences truthfully and revealing them falsely, he will report them truthfully.",
                "Given this assumption, we can safely refer to optimal leadership strategies rather than having to use some equilibrium notion.",
                "Hence, for the purposes of this paper, an optimal strategy to commit to in a 2-player game is a strategy s ∈ S that maximizes maxt∈BR(s) ul(s, t), where BR(s) = arg maxt∈T uf (s, t). (ul and uf are the leader and followers utility functions, respectively.)",
                "We can have S = S for the case of commitment to pure strategies, or S = ∆(S), the set of probability distributions over S, for the case of commitment to mixed strategies. (We note that replacing T by ∆(T) makes no difference in this definition.)",
                "For games with more than two players, in which the players commit to their strategies in sequence, we define optimal strategies to commit to recursively.",
                "After the leader commits to a strategy, the game to be played by the remaining agents is itself a (smaller) leadership game.",
                "Thus, we define an optimal strategy to commit to as a strategy that maximizes the leaders utility, assuming that the play of the remaining agents is itself optimal under this definition, and maximizes the leaders utility among all optimal ways to play the remaining game.",
                "Again, commitment to mixed strategies may or may not be a possibility for every player (although for the last player it does not matter if we allow for commitment to mixed strategies). 2.2 Commitment to pure strategies We first study how to compute the optimal pure strategy to commit to.",
                "This is relatively simple, because the number of strategies to commit to is not very large. (In the following, #outcomes is the number of complete strategy profiles.)",
                "Theorem 1.",
                "Under commitment to pure strategies, the set of all optimal strategy profiles in a normal-form game can be found in O(#players · #outcomes) time.",
                "Proof.",
                "Each pure strategy that the first player may commit to will induce a subgame for the remaining players.",
                "We can solve each such subgame recursively to find all of its optimal strategy profiles; each of these will give the original leader some utility.",
                "Those that give the leader maximal utility correspond exactly to the optimal strategy profiles of the original game.",
                "We now present the algorithm formally.",
                "Let Su(G, s1) be the subgame that results after the first (remaining) player in G plays s1 ∈ SG 1 .",
                "A game with 0 players is simply an outcome of the game.",
                "The function Append(s, O) appends the strategy s to each of the vectors of strategies in the set O.",
                "Let e be the empty vector with no elements.",
                "In a slight abuse of notation, we will write uG 1 (C) when all strategy profiles in the set C give player 1 the same utility in the game G. (Here, player 1 is the first remaining player in the subgame G, not necessarily player 1 in the original game.)",
                "We note that arg max is set-valued.",
                "Then, the following algorithm computes all optimal strategy profiles: Algorithm Solve(G) if G has 0 players return {e} C ← ∅ for all s1 ∈ SG 1 { O ← Solve(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) if C = ∅ or uG 1 (s1, O ) = uG 1 (C) C ← C∪Append(s1, O ) if uG 1 (s1, O ) > uG 1 (C) C ←Append(s1, O ) } return C Every outcome is (potentially) examined by every player, which leads to the given runtime bound.",
                "As an example of how the algorithm works, consider the following 3-player game, in which the first player chooses the left or right matrix, the second player chooses a row, and the third player chooses a column. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 3,0,0 First we eliminate the outcomes that do not correspond to best responses for the third player (removing them from the matrix): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Next, we remove the entries in which the third player does not break ties in favor of the second player, as well as entries that do not correspond to best responses for the second player. 0,1,1 2,1,1 1,1,1 0,5,1 Finally, we remove the entries in which the second and third players do not break ties in favor of the first player, as well as entries that do not correspond to best responses for the first player. 2,1,1 84 Hence, in optimal play, the first player chooses the left matrix, the second player chooses the middle row, and the third player chooses the left column. (We note that this outcome is Pareto-dominated by (Right, Middle, Left).)",
                "For general normal-form games, each players utility for each of the outcomes has to be explicitly represented in the input, so that the input size is itself Ω(#players · #outcomes).",
                "Therefore, the algorithm is in fact a linear-time algorithm. 2.3 Commitment to mixed strategies In the special case of two-player zero-sum games, computing an optimal mixed strategy for the leader to commit to is equivalent to computing a minimax strategy, which minimizes the maximum expected utility that the opponent can obtain.",
                "Minimax strategies constitute the only natural solution concept for two-player zero-sum games: von Neumanns Minimax Theorem [24] states that in two-player zero-sum games, it does not matter (in terms of the players utilities) which player gets to commit to a mixed strategy first, and a profile of mixed strategies is a Nash equilibrium if and only if both strategies are minimax strategies.",
                "It is well-known that a minimax strategy can be found in polynomial time, using linear programming [17].",
                "Our first result in this section generalizes this result, showing that an optimal mixed strategy for the leader to commit to can be efficiently computed in general-sum two-player games, again using linear programming.",
                "Theorem 2.",
                "In 2-player normal-form games, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders utility.",
                "Such a mixed strategy can be computed using the following simple linear program: maximize s∈S psul(s, t) subject to for all t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1 We note that this program may be infeasible for some follower strategies t, for example, if t is a strictly dominated strategy.",
                "Nevertheless, the program must be feasible for at least some follower strategies; among these follower strategies, choose a strategy t∗ that maximizes the linear programs solution value.",
                "Then, if the leader chooses as her mixed strategy the optimal settings of the variables ps for the linear program for t∗ , and the follower plays t∗ , this constitutes an optimal strategy profile.",
                "In the following result, we show that we cannot expect to solve the problem more efficiently than linear programming, because we can reduce any linear program with a probability constraint on its variables to a problem of computing the optimal mixed strategy to commit to in a 2-player normalform game.",
                "Theorem 3.",
                "Any linear program whose variables xi (with xi ∈ R≥0 ) must satsify i xi = 1 can be modeled as a problem of computing the optimal mixed strategy to commit to in a 2-player normal-form game.",
                "Proof.",
                "Let the leader have a pure strategy i for every variable xi.",
                "Let the column player have one pure strategy j for every constraint in the linear program (other than i xi = 1), and a single additional pure strategy 0.",
                "Let the utility functions be as follows.",
                "Writing the objective of the linear program as maximize i cixi, for any i, let ul(i, 0) = ci and uf (i, 0) = 0.",
                "Writing the jth constraint of the linear program (not including i xi = 1) as i aijxi ≤ bj, for any i, j > 0, let ul(i, j) = mini ci − 1 and uf (i, j) = aij − bj.",
                "For example, consider the following linear program. maximize 2x1 + x2 subject to x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 The optimal solution to this program is x1 = 1/3, x2 = 2/3.",
                "Our reduction transforms this program into the following leader-follower game (where the leader is the row player). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 Indeed, the optimal strategy for the leader is to play the top strategy with probability 1/3 and the bottom strategy with probability 2/3.",
                "We now show that the reduction works in general.",
                "Clearly, the leader wants to incentivize the follower to play 0, because the utility that the leader gets when the follower plays 0 is always greater than when the follower does not play 0.",
                "In order for the follower not to prefer playing j > 0 rather than 0, it must be the case that i pl(i)(aij − bj) ≤ 0, or equivalently i pl(i)aij ≤ bj.",
                "Hence the leader will get a utility of at least mini ci if and only if there is a feasible solution to the constraints.",
                "Given that the pl(i) incentivize the follower to play 0, the leader attempts to maximize i pl(i)ci.",
                "Thus the leader must solve the original linear program.",
                "As an alternative proof of Theorem 3, one may observe that it is known that finding a minimax strategy in a zerosum game is as hard as the linear programming problem [6], and as we pointed out at the beginning of this section, computing a minimax strategy in a zero-sum game is a special case of the problem of computing an optimal mixed strategy to commit to.",
                "This polynomial-time solvability of the problem of computing an optimal mixed strategy to commit to in two-player normal-form games contrasts with the unknown complexity of computing a Nash equilibrium in such games [21], as well as with the NP-hardness of finding a Nash equilibrium with maximum utility for a given player in such games [8, 2].",
                "Unfortunately, this result does not generalize to more than two players-here, the problem becomes NP-hard.",
                "To show this, we reduce from the VERTEX-COVER problem.",
                "Definition 1.",
                "In VERTEX-COVER, we are given a graph G = (V, E) and an integer K. We are asked whether there 85 exists a subset of the vertices S ⊆ V , with |S| = K, such that every edge e ∈ E has at least one of its endpoints in S. BALANCED-VERTEX-COVER is the special case of VERTEX-COVER in which K = |V |/2.",
                "VERTEX-COVER is NP-complete [9].",
                "The following lemma shows that the hardness remains if we require K = |V |/2. (Similar results have been shown for other NP-complete problems.)",
                "Lemma 1.",
                "BALANCED-VERTEX-COVER is NP-complete.",
                "Proof.",
                "Membership in NP follows from the fact that the problem is a special case of VERTEX-COVER, which is in NP.",
                "To show NP-hardness, we reduce an arbitrary VERTEX-COVER instance to a BALANCED-VERTEXCOVER instance, as follows.",
                "If, for the VERTEX-COVER instance, K > |V |/2, then we simply add isolated vertices that are disjoint from the rest of the graph, until K = |V |/2.",
                "If K < |V |/2, we add isolated triangles (that is, the complete graph on three vertices) to the graph, increasing K by 2 every time, until K = |V |/2.",
                "Theorem 4.",
                "In 3-player normal-form games, finding an optimal mixed strategy to commit to is NP-hard.",
                "Proof.",
                "We reduce an arbitrary BALANCED-VERTEXCOVER instance to the following 3-player normal-form game.",
                "For every vertex v, each of the three players has a pure strategy corresponding to that vertex (rv, sv, tv, respectively).",
                "In addition, for every edge e, the third player has a pure strategy te; and finally, the third player has one additional pure strategy t0.",
                "The utilities are as follows: • for all r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • for all r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • for all v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • for all v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • for all v ∈ V , for all r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V | |V |−2 ; • for all e ∈ E, s ∈ S, for both v ∈ e, u3(rv, s, te) = 0; • for all e ∈ E, s ∈ S, for all v /∈ e, u3(rv, s, te) = |V | |V |−2 . • for all r ∈ R, s ∈ S, u3(r, s, t0) = 1.",
                "We note that players 1 and 2 have the same utility function.",
                "We claim that there is an optimal strategy profile in which players 1 and 2 both obtain 1 (their maximum utility) if and only if there is a solution to the BALANCED-VERTEXCOVER problem. (Otherwise, these players will both obtain 0.)",
                "First, suppose there exists a solution to the BALANCEDVERTEX-COVER problem.",
                "Then, let player 1 play every rv such that v is in the cover with probability 2 |V | , and let player 2 play every sv such that v is not in the cover with probability 2 |V | .",
                "Then, for player 3, the expected utility of playing tv (for any v) is (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of 2 |V | that rv or sv is played.",
                "Additionally, the expected utility of playing te (for any e) is at most (1 − 2 |V | ) |V | |V |−2 = 1, because there is a chance of at least 2 |V | that some rv with v ∈ e is played (because player 1 is randomizing over the pure strategies corresponding to the cover).",
                "It follows that playing t0 is a best response for player 3, giving players 1 and 2 a utility of 1.",
                "Now, suppose that players 1 and 2 obtain 1 in optimal play.",
                "Then, it must be the case that player 3 plays t0.",
                "Hence, for every v ∈ V , there must be a probability of at least 2 |V | that either rv or sv is played, for otherwise player 3 would be better off playing tv.",
                "Because players 1 and 2 have only a total probability of 2 to distribute, it must be the case that for each v, either rv or sv is played with probability 2 |V | , and the other is played with probability 0. (It is not possible for both to have nonzero probability, because then there would be some probability that both are played simultaneously (correlation is not possible), hence the total probability of at least one being played could not be high enough for all vertices.)",
                "Thus, for exactly half the v ∈ V , player 1 places probability 2 |V | on rv.",
                "Moreover, for every e ∈ E, there must be a probability of at least 2 |V | that some rv with v ∈ e is played, for otherwise player 3 would be better off playing te.",
                "Thus, the v ∈ V such that player 1 places probability 2 |V | on rv constitute a balanced vertex cover. 3.",
                "BAYESIAN GAMES So far, we have restricted our attention to normal-form games.",
                "In a normal-form game, it is assumed that every agent knows every other agents preferences over the outcomes of the game.",
                "In general, however, agents may have some private information about their preferences that is not known to the other agents.",
                "Moreover, at the time of commitment to a strategy, the agents may not even know their own (final) preferences over the outcomes of the game yet, because these preferences may be dependent on a context that has yet to materialize.",
                "For example, when the code for a trading agent is written, it may not yet be clear how that agent will value resources that it will negotiate over later, because this depends on information that is not yet available at the time at which the code is written (such as orders that will have been placed to the agent before the negotiation).",
                "In this section, we will study commitment in Bayesian games, which can model such uncertainty over preferences. 3.1 Definitions In a Bayesian game, every player i has a set of actions Si, a set of types Θi with an associated probability distribution πi : Θi → [0, 1], and, for each type θi, a utility function uθi i : S1 × S2 × . . . × Sn → R. A pure strategy in a Bayesian game is a mapping from the players types to actions, σi : Θi → Si. (Bayesian games can be rewritten in normal form by enumerating every pure strategy σi, but this will cause an exponential blowup in the size of the representation of the game and therefore cannot lead to efficient algorithms.)",
                "The strategy that the leader should commit to depends on whether, at the time of commitment, the leader knows her own type.",
                "If the leader does know her own type, the other types that the leader might have had become irrelevant and the leader should simply commit to the strategy that is optimal for the type.",
                "However, as argued above, the leader does not necessarily know her own type at the time of commitment (e.g., the time at which the code is submitted).",
                "In this case, the leader must commit to a strategy that is 86 dependent upon the leaders eventual type.",
                "We will study this latter model, although we will pay specific attention to the case where the leader has only a single type, which is effectively the same as the former model. 3.2 Commitment to pure strategies It turns out that computing an optimal pure strategy to commit to is hard in Bayesian games, even with two players.",
                "Theorem 5.",
                "Finding an optimal pure strategy to commit to in 2-player Bayesian games is NP-hard, even when the follower has only a single type.",
                "Proof.",
                "We reduce an arbitrary VERTEX-COVER instance to the following Bayesian game between the leader and the follower.",
                "The leader has K types θ1, θ2, . . . , θK , each occurring with probability 1/K, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has only a single type; for each edge e ∈ E, the follower has an action te, and the follower has a single additional action t0.",
                "The utility function for the leader is given by, for all θl ∈ Θl and all s ∈ S, u θl l (s, t0) = 1, and for all e ∈ E, u θl l (s, te) = 0.",
                "The followers utility is given by: • For all v ∈ V , for all e ∈ E with v /∈ e, uf (sv, te) = 1; • For all v ∈ V , for all e ∈ E with v ∈ e, uf (sv, te) = −K; • For all v ∈ V , uf (sv, t0) = 0.",
                "We claim that the leader can get a utility of 1 if and only if there is a solution to the VERTEX-COVER instance.",
                "First, suppose that there is a solution to the VERTEXCOVER instance.",
                "Then, the leader can commit to a pure strategy such that for each vertex v in the cover, the leader plays sv for some type.",
                "Then, the followers utility for playing te (for any e ∈ E) is at most K−1 K + 1 K (−K) = − 1 K , so that the follower will prefer to play t0, which gives the leader a utility of 1, as required.",
                "Now, suppose that there is a pure strategy for the leader that will give the leader a utility of 1.",
                "Then, the follower must play t0.",
                "In order for the follower not to prefer playing te (for any e ∈ E) instead, for at least one v ∈ e the leader must play sv for some type θl.",
                "Hence, the set of vertices v that the leader plays for some type must constitute a vertex cover; and this set can have size at most K, because the leader has only K types.",
                "So there is a solution to the VERTEXCOVER instance.",
                "However, if the leader has only a single type, then the problem becomes easy again (#types is the number of types for the follower): Theorem 6.",
                "In 2-player Bayesian games in which the leader has only a single type, an optimal pure strategy to commit to can be found in O(#outcomes · #types) time.",
                "Proof.",
                "For every leader action s, we can compute, for every follower type θf ∈ Θf , which actions t maximize the followers utility; call this set of actions BRθf (s).",
                "Then, the utility that the leader receives for committing to action s can be computed as θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), and the leader can choose the best action to commit to. 3.3 Commitment to mixed strategies In two-player zero-sum imperfect information games with perfect recall (no player ever forgets something that it once knew), a minimax strategy can be constructed in polynomial time [12, 13].",
                "Unfortunately, this result does not extend to computing optimal mixed strategies to commit to in the general-sum case-not even in Bayesian games.",
                "We will exhibit NP-hardness by reducing from the INDEPENDENTSET problem.",
                "Definition 2.",
                "In INDEPENDENT-SET, we are given a graph G = (V, E) and an integer K. We are asked whether there exists a subset of the vertices S ⊆ V , with |S| = K, such that no edge e ∈ E has both of its endpoints in S. Again, this problem is NP-complete [9].",
                "Theorem 7.",
                "Finding an optimal mixed strategy to commit to in 2-player Bayesian games is NP-hard, even when the leader has only a single type and the follower has only two actions.",
                "Proof.",
                "We reduce an arbitrary INDEPENDENT-SET instance to the following Bayesian game between the leader and the follower.",
                "The leader has only a single type, and for every vertex v ∈ V , the leader has an action sv.",
                "The follower has a type θv for every v ∈ V , occurring with probability 1 (|E|+1)|V | , and a type θe for every e ∈ E, occurring with probability 1 |E|+1 .",
                "The follower has two actions: t0 and t1.",
                "The leaders utility is given by, for all s ∈ S, ul(s, t0) = 1 and ul(s, t1) = 0.",
                "The followers utility is given by: • For all v ∈ V , uθv f (sv, t1) = 0; • For all v ∈ V and s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • For all v ∈ V and s ∈ S, uθv f (s, t0) = 1; • For all e ∈ E, s ∈ S, uθe f (s, t0) = 1; • For all e ∈ E, for both v ∈ e, uθe f (sv, t1) = 2K 3 ; • For all e ∈ E, for all v /∈ e, uθe f (sv, t1) = 0.",
                "We claim that an optimal strategy to commit to gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | if and only if there is a solution to the INDEPENDENT-SET instance.",
                "First, suppose that there is a solution to the INDEPENDENT-SET instance.",
                "Then, the leader could commit to the following strategy: for every vertex v in the independent set, play the corresponding sv with probability 1/K.",
                "If the follower has type θe for some e ∈ E, the expected utility for the follower of playing t1 is at most 1 K 2K 3 = 2/3, because there is at most one vertex v ∈ e such that sv is played with nonzero probability.",
                "Hence, the follower will play t0 and obtain a utility of 1.",
                "If the follower has type θv for some vertex v in the independent set, the expected utility for the follower of playing t1 is K−1 K K K−1 = 1, because the leader plays sv with probability 1/K.",
                "It follows that the follower (who breaks ties to maximize the leaders utility) will play t0, which also gives a utility of 1 and gives the leader a higher utility.",
                "Hence the leaders expected utility for this strategy is at least |E| |E|+1 + K (|E|+1)|V | , as required. 87 Now, suppose that there is a strategy that gives the leader an expected utility of at least |E| |E|+1 + K (|E|+1)|V | .",
                "Then, this strategy must induce the follower to play t0 whenever it has a type of the form θe (because otherwise, the utility could be at most |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ).",
                "Thus, it cannot be the case that for some edge e = (v1, v2) ∈ E, the probability that the leader plays one of sv1 and sv2 is at least 2/K, because then the expected utility for the follower of playing t1 when it has type θe would be at least 2 K 2K 3 = 4/3 > 1.",
                "Moreover, the strategy must induce the follower to play t0 for at least K types of the form θv.",
                "Inducing the follower to play t0 when it has type θv can be done only by playing sv with probability at least 1/K, which will give the follower a utility of at most K−1 K K K−1 = 1 for playing t1.",
                "But then, the set of vertices v such that sv is played with probability at least 1/K must constitute an independent set of size K (because if there were an edge e between two such vertices, it would induce the follower to play t1 for type θe by the above).",
                "By contrast, if the follower has only a single type, then we can generalize the linear programming approach for normalform games: Theorem 8.",
                "In 2-player Bayesian games in which the follower has only a single type, an optimal mixed strategy to commit to can be found in polynomial time using linear programming.",
                "Proof.",
                "We generalize the approach in Theorem 2 as follows.",
                "For every pure follower strategy t, we compute a mixed strategy for the leader for every one of the leaders types such that 1) playing t is a best response for the follower, and 2) under this constraint, the mixed strategy maximizes the leaders ex ante expected utility.",
                "To do so, we generalize the linear program as follows: maximize θl∈Θl π(θl) s∈S pθl s uθl l (s, t) subject to for all t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t ) for all θl ∈ Θl, s∈S p θl s = 1 As in Theorem 2, the solution for the linear program that maximizes the solution value is an optimal strategy to commit to.",
                "This shows an interesting contrast between commitment to pure strategies and commitment to mixed strategies in Bayesian games: for pure strategies, the problem becomes easy if the leader has only a single type (but not if the follower has only a single type), whereas for mixed strategies, the problem becomes easy if the follower has only a single type (but not if the leader has only a single type). 4.",
                "CONCLUSIONS AND FUTURE RESEARCH In multiagent systems, strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously.",
                "This requires some equilibrium notion (Nash equilibrium and its refinements), and often leads to the equilibrium selection problem: it is unclear to each individual player according to which equilibrium she should play.",
                "However, this model is not always realistic.",
                "In many settings, one player is able to commit to a strategy before the other player makes a decision.",
                "For example, one agent may arrive at the (real or virtual) site of the game before the other, or, in the specific case of software agents, the code for one agent may be completed and committed before that of another agent.",
                "Such models are synonymously referred to as leadership, commitment, or <br>stackelberg</br> models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "Specifically, if commitment to mixed strategies is possible, then (optimal) commitment never hurts the leader, and often helps.",
                "The recent surge in interest in computing game-theoretic solutions has so far ignored leadership models (with the exception of the interest in mechanism design, where the designer is implicitly in a leadership position).",
                "In this paper, we studied how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies, in both normal-form and Bayesian games.",
                "For normal-form games, we showed that the optimal pure strategy to commit to can be found efficiently for any number of players.",
                "An optimal mixed strategy to commit to in a normal-form game can be found efficiently for two players using linear programming (and no more efficiently than that, in the sense that any linear program with a probability constraint can be encoded as such a problem). (This is a generalization of the polynomial-time computability of minimax strategies in normal-form games.)",
                "The problem becomes NP-hard for three (or more) players.",
                "In Bayesian games, the problem of finding an optimal pure strategy to commit to is NP-hard even in two-player games in which the follower has only a single type, although two-player games in which the leader has only a single type can be solved efficiently.",
                "The problem of finding an optimal mixed strategy to commit to in a Bayesian game is NP-hard even in two-player games in which the leader has only a single type, although two-player games in which the follower has only a single type can be solved efficiently using a generalization of the linear progamming approach for normal-form games.",
                "The following two tables summarize these results. 2 players ≥ 3 players normal-form O(#outcomes) O(#outcomes· #players) Bayesian, O(#outcomes· NP-hard 1-type leader #types) Bayesian, NP-hard NP-hard 1-type follower Bayesian (general) NP-hard NP-hard Results for commitment to pure strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.) 88 2 players ≥ 3 players normal-form one LP-solve per NP-hard follower action Bayesian, NP-hard NP-hard 1-type leader Bayesian, one LP-solve per NP-hard 1-type follower follower action Bayesian (general) NP-hard NP-hard Results for commitment to mixed strategies. (With more than 2 players, the follower is the last player to commit, the leader is the first.)",
                "Future research can take a number of directions.",
                "First, we can empirically evaluate the techniques presented here on test suites such as GAMUT [19].",
                "We can also study the computation of optimal strategies to commit to in other1 concise representations of normal-form games-for example, in graphical games [10] or local-effect/action graph games [14, 1].",
                "For the cases where computing an optimal strategy to commit to is NP-hard, we can also study the computation of approximately optimal strategies to commit to.",
                "While the correct definition of an approximately optimal strategy is in this setting may appear simple at first-it should be a strategy that, if the following players play optimally, performs almost as well as the optimal strategy in expectation-this definition becomes problematic when we consider that the other players may also be playing only approximately optimally.",
                "One may also study models in which multiple (but not all) players commit at the same time.",
                "Another interesting direction to pursue is to see if computing optimal mixed strategies to commit to can help us in, or otherwise shed light on, computing Nash equilibria.",
                "Often, optimal mixed strategies to commit to are also Nash equilibrium strategies (for example, in two-player zero-sum games this is always true), although this is not always the case (for example, as we already pointed out, sometimes the optimal strategy to commit to is a strictly dominated strategy, which can never be a Nash equilibrium strategy). 5.",
                "REFERENCES [1] N. A. R. Bhat and K. Leyton-Brown.",
                "Computing Nash equilibria of action-graph games.",
                "In Proceedings of the 20th Annual Conference on Uncertainty in Artificial Intelligence (UAI), Banff, Canada, 2004. [2] V. Conitzer and T. Sandholm.",
                "Complexity results about Nash equilibria.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pages 765-771, Acapulco, Mexico, 2003. [3] V. Conitzer and T. Sandholm.",
                "Complexity of (iterated) dominance.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 88-97, Vancouver, Canada, 2005. [4] V. Conitzer and T. Sandholm.",
                "A generalized strategy eliminability criterion and computational methods for applying it.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 483-488, Pittsburgh, PA, USA, 2005. [5] A.",
                "A. Cournot.",
                "Recherches sur les principes math´ematiques de la th´eorie des richesses (Researches 1 Bayesian games are one potentially concise representation of normal-form games. into the Mathematical Principles of the Theory of Wealth).",
                "Hachette, Paris, 1838. [6] G. Dantzig.",
                "A proof of the equivalence of the programming problem and the game problem.",
                "In T. Koopmans, editor, Activity Analysis of Production and Allocation, pages 330-335.",
                "John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel.",
                "The complexity of eliminating dominated strategies.",
                "Mathematics of Operation Research, 18:553-565, 1993. [8] I. Gilboa and E. Zemel.",
                "Nash and correlated equilibria: Some complexity considerations.",
                "Games and Economic Behavior, 1:80-93, 1989. [9] R. Karp.",
                "Reducibility among combinatorial problems.",
                "In R. E. Miller and J. W. Thatcher, editors, Complexity of Computer Computations, pages 85-103.",
                "Plenum Press, NY, 1972. [10] M. Kearns, M. Littman, and S. Singh.",
                "Graphical models for game theory.",
                "In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou, and J. N. Tsitsiklis.",
                "A note on strategy elimination in bimatrix games.",
                "Operations Research Letters, 7(3):103-107, 1988. [12] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [14] K. Leyton-Brown and M. Tennenholtz.",
                "Local-effect games.",
                "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), Acapulco, Mexico, 2003. [15] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 36-41, San Diego, CA, 2003. [16] M. Littman and P. Stone.",
                "A polynomial-time Nash equilibrium algorithm for repeated games.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 48-54, San Diego, CA, 2003. [17] R. D. Luce and H. Raiffa.",
                "Games and Decisions.",
                "John Wiley and Sons, New York, 1957.",
                "Dover republication 1989. [18] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown, and Y. Shoham.",
                "Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms.",
                "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), New York, NY, USA, 2004. [20] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "MIT Press, 1994. [21] C. Papadimitriou.",
                "Algorithms, games and the Internet.",
                "In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 749-753, 2001. 89 [22] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 664-669, San Jose, CA, USA, 2004. [23] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 495-501, Pittsburgh, PA, USA, 2005. [24] J. von Neumann.",
                "Zur Theorie der Gesellschaftsspiele.",
                "Mathematische Annalen, 100:295-320, 1927. [25] H. von <br>stackelberg</br>.",
                "Marktform und Gleichgewicht.",
                "Springer, Vienna, 1934. [26] B. von Stengel and S. Zamir.",
                "Leadership with commitment to mixed strategies.",
                "CDAM Research Report LSE-CDAM-2004-01, London School of Economics, Feb. 2004. 90"
            ],
            "original_annotated_samples": [
                "Such models are synonymously referred to as leadership, commitment, or <br>stackelberg</br> models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "Perhaps the earliest and best-known example of the effect of commitment is that by von <br>stackelberg</br> [25], who showed that, in Cournots duopoly model [5], if one firm is able to commit to a production quantity first, that firm will do much better than in the simultaneous-move (Nash) solution.",
                "Such models are synonymously referred to as leadership, commitment, or <br>stackelberg</br> models, and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously.",
                "Mathematische Annalen, 100:295-320, 1927. [25] H. von <br>stackelberg</br>."
            ],
            "translated_annotated_samples": [
                "Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o <br>Stackelberg</br>, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente.",
                "Quizás el ejemplo más temprano y conocido del efecto del compromiso es el de <br>von Stackelberg</br> [25], quien demostró que, en el modelo de duopolio de Cournot [5], si una empresa puede comprometerse con una cantidad de producción primero, esa empresa lo hará mucho mejor que en la solución de movimiento simultáneo (Nash).",
                "Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o <br>Stackelberg</br>, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente.",
                "Mathematische Annalen, 100:295-320, 1927. [25] H. von <br>Stackelberg</br>. \n\nMathematische Annalen, 100:295-320, 1927. [25] H. von <br>Stackelberg</br>."
            ],
            "translated_text": "En sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias simultáneamente. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o <br>Stackelberg</br>, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. El reciente aumento en el interés por las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas a comprometerse tanto en el compromiso de estrategias puras como en el compromiso de estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Ofrecemos tanto resultados positivos (algoritmos eficientes) como resultados negativos (resultados de NP-hardness). Categorías y Descriptores de Asignaturas J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas Términos Generales Algoritmos, Economía, Teoría 1. En sistemas multiagentes con agentes auto-interesados (incluyendo la mayoría de los entornos económicos), la acción óptima que un agente debe tomar depende de las acciones que tomen los otros agentes. Para analizar cómo un agente debería comportarse en tales situaciones, es necesario aplicar las herramientas de la teoría de juegos. Normalmente, cuando se modela un escenario estratégico en el marco de la teoría de juegos, se asume que los jugadores eligen sus estrategias de forma simultánea. Esto es especialmente cierto cuando el escenario se modela como un juego en forma normal, que solo especifica la utilidad de cada agente como una función del vector de estrategias que los agentes eligen, y no proporciona información sobre el orden en que los agentes toman sus decisiones y lo que los agentes observan sobre las decisiones anteriores de otros agentes. Dado que el juego está modelado en forma normal, típicamente se analiza utilizando el concepto de equilibrio de Nash. Un equilibrio de Nash especifica una estrategia para cada jugador, de modo que ningún jugador tenga un incentivo para desviarse individualmente de este perfil de estrategias. (Por lo general, se permite que las estrategias sean mixtas, es decir, distribuciones de probabilidad sobre las estrategias originales (puras).) Un equilibrio de Nash (de estrategia mixta) está garantizado de existir en juegos finitos [18], pero un problema es que puede haber múltiples equilibrios de Nash. Esto conduce al problema de selección de equilibrio de cómo un agente puede saber qué estrategia jugar si no sabe qué equilibrio se va a jugar. Cuando el escenario se modela como un juego de forma extensiva, es posible especificar que algunos jugadores reciben información sobre las acciones tomadas por otros antes en el juego antes de decidir su acción. Sin embargo, en general, los jugadores no saben todo lo que sucedió anteriormente en el juego. Por lo tanto, estos juegos suelen ser analizados todavía utilizando un concepto de equilibrio, donde se especifica una estrategia mixta para cada jugador, y se requiere que la estrategia de cada jugador sea una mejor respuesta a las estrategias de los demás. (Normalmente se impone ahora una restricción adicional en las estrategias para garantizar que los jugadores no jueguen de una manera irracional con respecto a la información que han recibido hasta el momento). Esto conduce a refinamientos del equilibrio de Nash como el equilibrio perfecto en subjuegos y el equilibrio secuencial. Sin embargo, en muchos entornos del mundo real, las estrategias no se seleccionan de manera simultánea. A menudo, un jugador (el líder) puede comprometerse con una estrategia antes que otro jugador (el seguidor). Esto puede deberse a una variedad de razones. Por ejemplo, uno de los jugadores puede llegar al lugar donde se jugará el juego antes que otro agente (por ejemplo, en entornos económicos, un jugador puede ingresar al mercado antes y comprometerse con una forma de hacer negocios). Un compromiso tan poderoso tiene un impacto profundo en cómo debería jugarse el juego. Por ejemplo, el líder puede estar mejor jugando una estrategia que esté dominada en la representación de forma normal del juego. Quizás el ejemplo más temprano y conocido del efecto del compromiso es el de <br>von Stackelberg</br> [25], quien demostró que, en el modelo de duopolio de Cournot [5], si una empresa puede comprometerse con una cantidad de producción primero, esa empresa lo hará mucho mejor que en la solución de movimiento simultáneo (Nash). En general, si es posible comprometerse con estrategias mixtas, entonces (bajo suposiciones menores) nunca perjudica, y a menudo ayuda, comprometerse con una estrategia [26]. Verse obligado a comprometerse con una estrategia pura a veces ayuda y a veces perjudica (por ejemplo, comprometerse con una estrategia pura en piedra-papel-tijeras antes de la decisión de los otros jugadores naturalmente resultará en una derrota). En este documento, asumiremos que el compromiso siempre es forzado; si no lo es, el jugador que tiene la opción de comprometerse simplemente puede comparar el resultado del compromiso con el resultado de no comprometerse (movimiento simultáneo). Los modelos de liderazgo son especialmente importantes en entornos con múltiples agentes de software con intereses propios. Una vez que el código de un agente (o de un equipo de agentes) está finalizado y el agente es desplegado, el agente se compromete a jugar la estrategia (posiblemente aleatoria) que el código prescribe. Por lo tanto, siempre y cuando se pueda demostrar de manera creíble que no se puede cambiar el código más tarde, el código funciona como un dispositivo de compromiso. Esto es válido para torneos recreativos entre agentes (por ejemplo, torneos de póker, RoboSoccer) y para aplicaciones industriales como redes de sensores. Finalmente, también existe una situación de liderazgo implícito en el campo del diseño de mecanismos, en la cual un jugador (el diseñador) tiene la oportunidad de elegir las reglas del juego que los demás jugadores luego siguen. El diseño de mecanismos es un tema extremadamente importante para la comunidad de EC: los artículos publicados sobre diseño de mecanismos en las recientes conferencias de EC son demasiados para citar. De hecho, el diseñador del mecanismo puede beneficiarse al comprometerse con una elección que, si las acciones de los agentes (restantes) estuvieran fijas, sería subóptima. Por ejemplo, en una subasta (a precio fijo), el vendedor puede desear establecer un precio de reserva positivo (artificial) para el artículo, por debajo del cual el artículo no se venderá, incluso si el vendedor valora el artículo en 0. En retrospectiva (después de recibir las ofertas), esto (ingenuamente) parece subóptimo: si llegaba una oferta que superaba el precio de reserva, el precio de reserva no tenía efecto, y si no llegaba tal oferta, el vendedor hubiera estado mejor aceptando una oferta más baja. Por supuesto, la razón para establecer el precio de reserva es incentivar a los postores a ofertar más alto, y debido a esto, establecer precios de reserva artificiales puede aumentar realmente los ingresos esperados para el vendedor. Recientemente se ha dedicado una cantidad significativa de investigación al cálculo de soluciones de acuerdo con varios conceptos de solución para escenarios en los que los agentes eligen sus estrategias simultáneamente, como la dominancia [7, 11, 3] y (especialmente) el equilibrio de Nash [8, 21, 16, 15, 2, 22, 23, 4]. Sin embargo, se ha ignorado el cálculo de la estrategia óptima a comprometerse en una situación de liderazgo. Teóricamente, las situaciones de liderazgo simplemente pueden ser consideradas como un juego de forma extensiva en el que un jugador elige una estrategia (para el juego original) primero. El número de estrategias en este juego de forma extensiva, sin embargo, puede ser extremadamente grande. Por ejemplo, si el líder es capaz de comprometerse con una estrategia mixta en el juego original, entonces cada una de las estrategias mixtas (continuo de) constituye una estrategia pura en la representación de forma extensiva de la situación de liderazgo. (Se destaca que un compromiso con una distribución no es lo mismo que una distribución sobre compromisos). Además, si el juego original es en sí mismo un juego de forma extensiva, el número de estrategias en la representación de forma extensiva de la situación de liderazgo (que es un juego de forma extensiva diferente) se vuelve aún más grande. Por lo tanto, generalmente no es factible computacionalmente simplemente transformar el juego original en la representación de forma extensiva de la situación de liderazgo; en su lugar, debemos analizar el juego en su representación original. En este artículo, estudiamos cómo calcular la estrategia óptima a comprometerse, tanto en juegos de forma normal (Sección 2) como en juegos bayesianos, que son un caso especial de juegos de forma extensiva (Sección 3). JUEGOS EN FORMA NORMAL En esta sección, estudiamos cómo calcular la estrategia óptima a comprometerse para juegos representados en forma normal. 2.1 Definiciones En un juego en forma normal, cada jugador i ∈ {1, . . . , n} tiene un conjunto de estrategias puras (o acciones) Si, y una función de utilidad ui : S1×S2×. . .×Sn → R que mapea cada resultado (un vector que consiste en una estrategia pura para cada jugador, también conocido como un perfil de estrategias puras) a un número real. Para facilitar la notación, en el caso de dos jugadores, nos referiremos al conjunto de estrategias puras del jugador 1 como S, y al conjunto de estrategias puras del jugador 2 como T. Estos juegos pueden representarse en forma de matriz (bi-matriz), en la que las filas corresponden a las estrategias puras del jugador 1, las columnas corresponden a las estrategias puras del jugador 2, y las entradas de la matriz dan las utilidades de los jugadores de fila y columna (en ese orden) para el resultado correspondiente del juego. En el caso de tres jugadores, usaremos R, S y T, para las estrategias puras de los jugadores 1, 2 y 3, respectivamente. Una estrategia mixta para un jugador es una distribución de probabilidad sobre las estrategias puras de ese jugador. En el caso de juegos de dos jugadores, nos referiremos al jugador 1 como el líder y al jugador 2 como el seguidor. Antes de definir estrategias de liderazgo óptimas, considera el siguiente juego que ilustra el efecto de la capacidad del líder para comprometerse. 2, 1 4, 0 1, 0 3, 1 En esta representación en forma normal, la estrategia inferior para el jugador de la fila está estrictamente dominada por la estrategia superior. Sin embargo, si el jugador de la fila tiene la capacidad de comprometerse con una estrategia pura antes de que el jugador de la columna elija su estrategia, el jugador de la fila debería comprometerse con la estrategia inferior: al hacerlo, el jugador de la columna preferirá jugar la estrategia correcta, lo que llevará a una utilidad de 3 para el jugador de la fila. Por el contrario, si el jugador de la fila se comprometiera con la estrategia superior, el jugador de la columna preferiría jugar la estrategia izquierda, lo que llevaría a una utilidad de solo 2 para el jugador de la fila. Si el jugador de la fila puede comprometerse a una estrategia mixta, entonces puede obtener una utilidad aún mayor (esperada): si el jugador de la fila se compromete a colocar una probabilidad p > 1/2 en la estrategia inferior, entonces el jugador de la columna seguirá prefiriendo jugar la estrategia derecha, y la utilidad esperada de los jugadores de la fila será 3p + 4(1 − p) = 4 − p ≥ 3. Si el jugador de la fila juega cada estrategia con una probabilidad exacta de 1/2, el jugador de la columna está 83 indiferente entre las estrategias. En tales casos, asumiremos que el jugador de la columna elegirá la estrategia que maximiza la utilidad de los jugadores de la fila (en este caso, la estrategia correcta). Por lo tanto, la estrategia mixta óptima a la que debe comprometerse el jugador de la fila es p = 1/2. Hay algunas buenas razones para esta suposición. Si asumiéramos lo contrario, entonces no existiría una estrategia óptima para el jugador de la fila en el juego de ejemplo: el jugador de la fila jugaría la estrategia inferior con una probabilidad p = 1/2 + con > 0, y cuanto menor sea , mejor será la utilidad para el jugador de la fila. Por el contrario, si asumimos que el seguidor siempre rompe los empates a favor de los líderes, entonces siempre existe una estrategia mixta óptima para el líder, lo que corresponde a un equilibrio perfecto en subjuegos de la representación en forma extensiva de la situación de liderazgo. En cualquier caso, esta es una suposición estándar para tales modelos (por ejemplo, [20]), aunque algunos trabajos han investigado lo que puede suceder en los otros equilibrios perfectos de subjuego [26]. (Para juegos genéricos de dos jugadores, el pago del equilibrio perfecto de subjuego de los líderes es único). Además, la misma suposición se utiliza típicamente en el diseño de mecanismos, asumiendo que si un agente es indiferente entre revelar sus preferencias de manera veraz o falsa, las reportará de manera veraz. Dado este supuesto, podemos hacer referencia de manera segura a estrategias de liderazgo óptimas en lugar de tener que utilizar alguna noción de equilibrio. Por lo tanto, para los propósitos de este documento, una estrategia óptima a comprometerse en un juego de 2 jugadores es una estrategia s ∈ S que maximiza maxt∈BR(s) ul(s, t), donde BR(s) = arg maxt∈T uf (s, t). (ul y uf son las funciones de utilidad del líder y los seguidores, respectivamente). Podemos tener S = S para el caso de compromiso con estrategias puras, o S = ∆(S), el conjunto de distribuciones de probabilidad sobre S, para el caso de compromiso con estrategias mixtas. (Observamos que reemplazar T por ∆(T) no hace ninguna diferencia en esta definición). Para juegos con más de dos jugadores, en los que los jugadores se comprometen con sus estrategias en secuencia, definimos estrategias óptimas a las que comprometerse de forma recursiva. Después de que el líder se compromete con una estrategia, el juego que jugarán los agentes restantes es en sí mismo un juego de liderazgo (más pequeño). Por lo tanto, definimos una estrategia óptima a comprometerse como una estrategia que maximiza la utilidad del líder, asumiendo que el juego de los agentes restantes es óptimo bajo esta definición, y maximiza la utilidad del líder entre todas las formas óptimas de jugar el juego restante. Nuevamente, el compromiso con estrategias mixtas puede o no ser una posibilidad para cada jugador (aunque para el último jugador no importa si permitimos el compromiso con estrategias mixtas). 2.2 Compromiso con estrategias puras. Primero estudiamos cómo calcular la estrategia pura óptima a la que comprometerse. Esto es relativamente simple, porque el número de estrategias a comprometer no es muy grande. (En lo siguiente, #resultados es el número de perfiles de estrategia completos). Teorema 1. Bajo el compromiso de estrategias puras, el conjunto de todos los perfiles de estrategia óptimos en un juego en forma normal se puede encontrar en tiempo O(#jugadores · #resultados). Prueba. Cada estrategia pura a la que el primer jugador pueda comprometerse inducirá un subjuego para los jugadores restantes. Podemos resolver cada subjuego de esta manera de forma recursiva para encontrar todos sus perfiles de estrategia óptimos; cada uno de estos le dará al líder original cierta utilidad. Aquellos que proporcionan al líder la utilidad máxima corresponden exactamente a los perfiles de estrategia óptimos del juego original. Ahora presentamos el algoritmo de forma formal. Sea Su(G, s1) el subjuego que resulta después de que el primer jugador restante en G juega s1 ∈ SG 1. Un juego con 0 jugadores es simplemente un resultado del juego. La función Append(s, O) añade la estrategia s a cada uno de los vectores de estrategias en el conjunto O. Sea e el vector vacío sin elementos. En un ligero abuso de notación, escribiremos uG 1 (C) cuando todos los perfiles estratégicos en el conjunto C le den al jugador 1 la misma utilidad en el juego G. (Aquí, el jugador 1 es el primer jugador restante en el subjuego G, no necesariamente el jugador 1 en el juego original). Observamos que arg max es un conjunto de valores. Entonces, el siguiente algoritmo calcula todos los perfiles de estrategia óptimos: Algoritmo Resolver(G) si G tiene 0 jugadores, devuelve {e} C ← ∅ para todo s1 ∈ SG 1 { O ← Resolver(Su(G, s1)) O ← arg maxo∈O uG 1 (s1, o) si C = ∅ o uG 1 (s1, O ) = uG 1 (C) C ← C∪Agregar(s1, O ) si uG 1 (s1, O ) > uG 1 (C) C ←Agregar(s1, O ) } devuelve C Cada resultado es examinado (potencialmente) por cada jugador, lo que lleva al límite de tiempo dado. Como ejemplo de cómo funciona el algoritmo, considera el siguiente juego de 3 jugadores, en el que el primer jugador elige la matriz izquierda o derecha, el segundo jugador elige una fila y el tercer jugador elige una columna. 0,1,1 1,1,0 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 0,0,0 3,3,0 3,3,0 0,2,0 3,0,1 4,4,2 0,0,2 0,0,0 0,5,1 0,0,0 Primero eliminamos los resultados que no corresponden a las mejores respuestas para el tercer jugador (eliminándolos de la matriz): 0,1,1 1,0,1 2,1,1 3,0,1 1,1,1 0,0,1 3,0,1 4,4,2 0,0,2 0,5,1 Luego, eliminamos las entradas en las que el tercer jugador no resuelve los empates a favor del segundo jugador, así como las entradas que no corresponden a las mejores respuestas para el segundo jugador. 0,1,1 2,1,1 1,1,1 0,5,1 Finalmente, eliminamos las entradas en las que el segundo y tercer jugador no resuelven los empates a favor del primer jugador, así como las entradas que no corresponden a las mejores respuestas para el primer jugador. 2,1,1 Por lo tanto, en el juego óptimo, el primer jugador elige la matriz izquierda, el segundo jugador elige la fila del medio y el tercer jugador elige la columna izquierda. (Notamos que este resultado está dominado por Pareto por (Derecha, Medio, Izquierda).) Para juegos en forma normal general, la utilidad de cada jugador para cada uno de los resultados debe representarse explícitamente en la entrada, de modo que el tamaño de la entrada sea en sí mismo Ω(#jugadores · #resultados). Por lo tanto, el algoritmo es de hecho un algoritmo de tiempo lineal. 2.3 Compromiso con estrategias mixtas En el caso especial de juegos de dos jugadores de suma cero, calcular una estrategia mixta óptima para que el líder se comprometa es equivalente a calcular una estrategia minimax, que minimiza la utilidad esperada máxima que el oponente puede obtener. Las estrategias minimax constituyen el único concepto de solución natural para juegos de suma cero de dos jugadores: el Teorema Minimax de von Neumann [24] establece que en juegos de suma cero de dos jugadores, no importa (en términos de las utilidades de los jugadores) qué jugador se compromete primero a una estrategia mixta, y un perfil de estrategias mixtas es un equilibrio de Nash si y solo si ambas estrategias son estrategias minimax. Es bien sabido que una estrategia minimax se puede encontrar en tiempo polinómico, utilizando programación lineal [17]. Nuestro primer resultado en esta sección generaliza este resultado, mostrando que una estrategia mixta óptima para que el líder se comprometa puede ser calculada eficientemente en juegos de dos jugadores de suma general, nuevamente utilizando programación lineal. Teorema 2. En juegos de forma normal de 2 jugadores, una estrategia mixta óptima a la que comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal. Prueba. Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder de modo que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad del líder. Un programa lineal simple puede calcular una estrategia mixta como la siguiente: maximizar s∈S psul(s, t) sujeto a que para todo t ∈ T, s∈S psuf (s, t) ≥ s∈S psuf (s, t ) s∈S ps = 1. Se destaca que este programa puede ser inviable para algunas estrategias seguidoras t, por ejemplo, si t es una estrategia estrictamente dominada. Sin embargo, el programa debe ser factible para al menos algunas estrategias seguidoras; entre estas estrategias seguidoras, elige una estrategia t∗ que maximice el valor de la solución de los programas lineales. Entonces, si la líder elige como su estrategia mixta los ajustes óptimos de las variables ps para el programa lineal para t∗, y el seguidor juega t∗, esto constituye un perfil de estrategia óptimo. En el siguiente resultado, demostramos que no podemos esperar resolver el problema de manera más eficiente que la programación lineal, ya que podemos reducir cualquier programa lineal con una restricción de probabilidad en sus variables a un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores. Teorema 3. Cualquier programa lineal cuyas variables xi (con xi ∈ R≥0) deben satisfacer i xi = 1 puede ser modelado como un problema de calcular la estrategia mixta óptima a comprometerse en un juego de forma normal de 2 jugadores. Prueba. Que el líder tenga una estrategia pura i para cada variable xi. Que el jugador de la columna tenga una estrategia pura j para cada restricción en el programa lineal (distinta de i xi = 1), y una única estrategia pura adicional 0. Que las funciones de utilidad sean las siguientes. Escribiendo el objetivo del programa lineal como maximizar ci xi, para cualquier i, dejando ul(i, 0) = ci y uf(i, 0) = 0. Escribiendo la j-ésima restricción del programa lineal (sin incluir i xi = 1) como i aijxi ≤ bj, para cualquier i, j > 0, sea ul(i, j) = mini ci − 1 y uf(i, j) = aij − bj. Por ejemplo, considera el siguiente programa lineal. maximizar 2x1 + x2 sujeto a x1 + x2 = 1 5x1 + 2x2 ≤ 3 7x1 − 2x2 ≤ 2 La solución óptima de este programa es x1 = 1/3, x2 = 2/3. Nuestra reducción transforma este programa en el siguiente juego de líder-seguidor (donde el líder es el jugador de la fila). 2, 0 0, 2 0, 5 1, 0 0, -1 0, -4 De hecho, la estrategia óptima para el líder es jugar la estrategia superior con una probabilidad de 1/3 y la estrategia inferior con una probabilidad de 2/3. Ahora demostramos que la reducción funciona en general. Claramente, el líder quiere incentivar al seguidor a jugar 0, porque la utilidad que el líder obtiene cuando el seguidor juega 0 siempre es mayor que cuando el seguidor no juega 0. Para que el seguidor no prefiera jugar j > 0 en lugar de 0, debe ser el caso que i pl(i)(aij − bj) ≤ 0, o equivalentemente i pl(i)aij ≤ bj. Por lo tanto, el líder obtendrá una utilidad de al menos mini ci si y solo si hay una solución factible a las restricciones. Dado que el pl(i) incentiva al seguidor a jugar 0, el líder intenta maximizar i pl(i)ci. Por lo tanto, el líder debe resolver el programa lineal original. Como prueba alternativa del Teorema 3, se puede observar que se sabe que encontrar una estrategia minimax en un juego de suma cero es tan difícil como el problema de programación lineal [6], y como señalamos al principio de esta sección, calcular una estrategia minimax en un juego de suma cero es un caso especial del problema de calcular una estrategia mixta óptima a la que comprometerse. La solubilidad en tiempo polinómico del problema de calcular una estrategia mixta óptima a la que comprometerse en juegos de forma normal de dos jugadores contrasta con la complejidad desconocida de calcular un equilibrio de Nash en tales juegos [21], así como con la NP-dificultad de encontrar un equilibrio de Nash con utilidad máxima para un jugador dado en tales juegos [8, 2]. Desafortunadamente, este resultado no se generaliza a más de dos jugadores; aquí, el problema se vuelve NP-duro. Para demostrar esto, reducimos desde el problema de CUBRIR-VÉRTICES. Definición 1. En VERTEX-COVER, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que cada arista e ∈ E tenga al menos uno de sus extremos en S. BALANCED-VERTEX-COVER es el caso especial de VERTEX-COVER en el que K = |V|/2. VERTEX-COVER es NP-completo [9]. El siguiente lema muestra que la dificultad persiste si requerimos K = |V|/2. (Resultados similares se han demostrado para otros problemas NP-completos). Lema 1. El problema de la COBERTURA DE VÉRTICES EQUILIBRADA es NP-completo. Prueba. La pertenencia a NP se deriva del hecho de que el problema es un caso especial de CUBRIMIENTO DE VÉRTICES, que está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES a una instancia de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO, de la siguiente manera. Si, para la instancia de CUBRIMIENTO DE VÉRTICES, K > |V|/2, simplemente agregamos vértices aislados que estén disjuntos del resto del grafo, hasta que K = |V|/2. Si K < |V|/2, agregamos triángulos aislados (es decir, el grafo completo de tres vértices) al grafo, aumentando K en 2 cada vez, hasta que K = |V|/2. Teorema 4. En juegos de forma normal de 3 jugadores, encontrar una estrategia mixta óptima a la que comprometerse es NP-difícil. Prueba. Reducimos una instancia arbitraria de CUBRIMIENTO-DE-VÉRTICES-BALANCEADO al siguiente juego de forma normal de 3 jugadores. Para cada vértice v, cada uno de los tres jugadores tiene una estrategia pura correspondiente a ese vértice (rv, sv, tv, respectivamente). Además, para cada arista e, el tercer jugador tiene una estrategia pura te; y finalmente, el tercer jugador tiene una estrategia pura adicional t0. Los servicios son los siguientes: • para todo r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1; • para todo r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) = 0; • para todo v ∈ V, s ∈ S, u3(rv, s, tv) = 0; • para todo v ∈ V, r ∈ R, u3(r, sv, tv) = 0; • para todo v ∈ V, para todo r ∈ R − {rv}, s ∈ S − {sv}, u3(r, s, tv) = |V| |V|−2; • para todo e ∈ E, s ∈ S, para ambos v ∈ e, u3(rv, s, te) = 0; • para todo e ∈ E, s ∈ S, para todo v /∈ e, u3(rv, s, te) = |V| |V|−2. • para todo r ∈ R, s ∈ S, u3(r, s, t0) = 1. Observamos que los jugadores 1 y 2 tienen la misma función de utilidad. Sostenemos que existe un perfil de estrategia óptimo en el que los jugadores 1 y 2 obtienen ambos 1 (su utilidad máxima) si y solo si hay una solución al problema de la COBERTURA DE VÉRTICES EQUILIBRADA. (De lo contrario, estos jugadores obtendrán ambos 0). Primero, supongamos que existe una solución al problema de la cubierta de vértices balanceada. Entonces, deja que el jugador 1 juegue cada rv de manera que v esté en la cobertura con probabilidad 2 |V|, y deja que el jugador 2 juegue cada sv de manera que v no esté en la cobertura con probabilidad 2 |V|. Entonces, para el jugador 3, la utilidad esperada de jugar tv (para cualquier v) es (1 − 2 |V|) |V| |V|−2 = 1, porque hay una probabilidad de 2 |V| de que se juegue rv o sv. Además, la utilidad esperada de jugar te (para cualquier e) es a lo sumo (1 − 2 |V | ) |V | |V |−2 = 1, porque hay una probabilidad de al menos 2 |V | de que algún rv con v ∈ e se juegue (debido a que el jugador 1 está aleatorizando sobre las estrategias puras correspondientes a la cobertura). Se deduce que jugar t0 es la mejor respuesta para el jugador 3, otorgando a los jugadores 1 y 2 una utilidad de 1. Ahora, supongamos que los jugadores 1 y 2 obtienen 1 en el juego óptimo. Entonces, debe ser el caso de que el jugador 3 juegue t0. Por lo tanto, para cada v ∈ V, debe haber una probabilidad de al menos 2 |V| de que se juegue rv o sv, de lo contrario, al jugador 3 le convendría más jugar tv. Dado que los jugadores 1 y 2 solo tienen una probabilidad total de 2 para distribuir, debe ser el caso que para cada v, ya sea rv o sv se juegue con una probabilidad de 2 |V|, y el otro se juegue con una probabilidad de 0. (No es posible que ambos tengan una probabilidad distinta de cero, porque entonces habría alguna probabilidad de que ambos se jugaran simultáneamente (la correlación no es posible), por lo tanto, la probabilidad total de que al menos uno se juegue no podría ser lo suficientemente alta para todos los vértices). Por lo tanto, para exactamente la mitad de los v ∈ V, el jugador 1 coloca una probabilidad de 2 |V| en rv. Además, para cada e ∈ E, debe haber una probabilidad de al menos 2 |V | de que se juegue algún rv con v ∈ e, de lo contrario, al jugador 3 le convendría más jugar te. Por lo tanto, el v ∈ V tal que el jugador 1 coloca una probabilidad de 2 |V | en rv constituye una cubierta de vértices equilibrada. 3. Juegos bayesianos. Hasta ahora, hemos restringido nuestra atención a los juegos en forma normal. En un juego en forma normal, se asume que cada agente conoce las preferencias de todos los demás agentes sobre los resultados del juego. En general, sin embargo, los agentes pueden tener información privada sobre sus preferencias que no es conocida por los otros agentes. Además, en el momento de comprometerse con una estrategia, los agentes pueden ni siquiera conocer sus propias preferencias (finales) sobre los resultados del juego aún, ya que estas preferencias pueden depender de un contexto que aún no se ha materializado. Por ejemplo, cuando se escribe el código para un agente de negociación, puede que aún no esté claro cómo ese agente valorará los recursos sobre los que negociará más adelante, porque esto depende de información que aún no está disponible en el momento en que se escribe el código (como órdenes que habrán sido colocadas al agente antes de la negociación). En esta sección, estudiaremos el compromiso en juegos bayesianos, los cuales pueden modelar tal incertidumbre sobre preferencias. 3.1 Definiciones En un juego bayesiano, cada jugador i tiene un conjunto de acciones Si, un conjunto de tipos Θi con una distribución de probabilidad asociada πi : Θi → [0, 1], y, para cada tipo θi, una función de utilidad uθi i : S1 × S2 × . . . × Sn → R. Una estrategia pura en un juego bayesiano es una asignación de los tipos de los jugadores a acciones, σi : Θi → Si. (Los juegos bayesianos pueden ser reescritos en forma normal enumerando cada estrategia pura σi, pero esto causará un crecimiento exponencial en el tamaño de la representación del juego y por lo tanto no puede llevar a algoritmos eficientes). La estrategia a la que el líder debería comprometerse depende de si, en el momento del compromiso, el líder conoce su propio tipo. Si la líder conoce su propio tipo, los otros tipos que la líder podría haber tenido se vuelven irrelevantes y la líder simplemente debería comprometerse con la estrategia que sea óptima para ese tipo. Sin embargo, como se argumentó anteriormente, la líder no necesariamente conoce su propio tipo en el momento de comprometerse (por ejemplo, en el momento en que se envía el código). En este caso, el líder debe comprometerse con una estrategia que dependa en un 86% del tipo eventual del líder. Estudiaremos este último modelo, aunque prestaremos atención específica al caso en el que el líder tiene un solo tipo, lo cual es efectivamente lo mismo que el modelo anterior. 3.2 Compromiso con estrategias puras Resulta que calcular una estrategia pura óptima a la que comprometerse es difícil en juegos bayesianos, incluso con dos jugadores. Teorema 5. Encontrar una estrategia pura óptima a comprometerse en juegos bayesianos de 2 jugadores es NP-difícil, incluso cuando el seguidor tiene solo un tipo. Prueba. Reducimos una instancia arbitraria de CUBRIMIENTO DE VÉRTICES al siguiente juego bayesiano entre el líder y el seguidor. El líder tiene K tipos θ1, θ2, . . . , θK, cada uno ocurriendo con probabilidad 1/K, y para cada vértice v ∈ V, el líder tiene una acción sv. El seguidor tiene solo un tipo; para cada borde e ∈ E, el seguidor tiene una acción te, y el seguidor tiene una acción adicional única t0. La función de utilidad para el líder está dada por, para todo θl ∈ Θl y todo s ∈ S, u θl l (s, t0) = 1, y para todo e ∈ E, u θl l (s, te) = 0. La utilidad de los seguidores se da por: • Para todo v ∈ V, para todo e ∈ E con v /∈ e, uf (sv, te) = 1; • Para todo v ∈ V, para todo e ∈ E con v ∈ e, uf (sv, te) = −K; • Para todo v ∈ V, uf (sv, t0) = 0. Sostenemos que el líder puede obtener una utilidad de 1 si y solo si hay una solución para la instancia de CUBRIMIENTO-DE-VÉRTICES. Primero, supongamos que hay una solución para la instancia de CUBRIRVÉRTICES. Entonces, el líder puede comprometerse con una estrategia pura tal que para cada vértice v en la cobertura, el líder juega sv para algún tipo. Entonces, la utilidad de los seguidores para jugar te (para cualquier e ∈ E) es a lo sumo K−1 K + 1 K (−K) = − 1 K , por lo que el seguidor preferirá jugar t0, lo que le da al líder una utilidad de 1, como se requiere. Ahora, supongamos que hay una estrategia pura para el líder que le dará al líder una utilidad de 1. Entonces, el seguidor debe jugar t0. Para que el seguidor no prefiera jugar te (para cualquier e ∈ E) en su lugar, al menos para un v ∈ e, el líder debe jugar sv para algún tipo θl. Por lo tanto, el conjunto de vértices v que el líder juega para algún tipo debe constituir una cubierta de vértices; y este conjunto puede tener un tamaño de como máximo K, ya que el líder solo tiene K tipos. Entonces hay una solución para la instancia de CUBRIMIENTODEVÉRTICES. Sin embargo, si el líder tiene solo un tipo, entonces el problema se vuelve fácil nuevamente (#tipos es el número de tipos para el seguidor): Teorema 6. En juegos bayesianos de 2 jugadores en los que el líder tiene solo un tipo, una estrategia pura óptima a comprometerse puede encontrarse en tiempo O(#resultados · #tipos). Prueba. Para cada acción de líder s, podemos calcular, para cada tipo de seguidor θf ∈ Θf, qué acciones t maximizan la utilidad de los seguidores; llamamos a este conjunto de acciones BRθf (s). Entonces, la utilidad que recibe el líder por comprometerse a la acción s se puede calcular como θf ∈Θf π(θf ) maxt∈BRθf (s) ul(s, t), y el líder puede elegir la mejor acción a la que comprometerse. 3.3 Compromiso con estrategias mixtas En juegos de información imperfecta de suma cero de dos jugadores con memoria perfecta (ningún jugador olvida algo que una vez supo), una estrategia minimax se puede construir en tiempo polinómico [12, 13]. Desafortunadamente, este resultado no se extiende a calcular estrategias mixtas óptimas a comprometerse en el caso de suma general, ni siquiera en juegos bayesianos. Demostraremos la NP-dificultad reduciendo desde el problema de CONJUNTOINDEPENDIENTE. Definición 2. En INDEPENDENT-SET, se nos da un grafo G = (V, E) y un entero K. Se nos pregunta si existe un subconjunto de los vértices S ⊆ V, con |S| = K, tal que ninguna arista e ∈ E tenga ambos extremos en S. Nuevamente, este problema es NP-completo [9]. Teorema 7. Encontrar una estrategia mixta óptima a comprometerse en juegos bayesianos de 2 jugadores es NP-duro, incluso cuando el líder tiene solo un tipo y el seguidor tiene solo dos acciones. Prueba. Reducimos una instancia arbitraria de CONJUNTO-INDEPENDIENTE al siguiente juego bayesiano entre el líder y el seguidor. El líder tiene solo un tipo, y para cada vértice v ∈ V, el líder tiene una acción sv. El seguidor tiene un tipo θv para cada v ∈ V, que ocurre con una probabilidad de 1 (|E|+1)|V|, y un tipo θe para cada e ∈ E, que ocurre con una probabilidad de 1 |E|+1. El seguidor tiene dos acciones: t0 y t1. La utilidad de los líderes se da por, para todo s ∈ S, ul(s, t0) = 1 y ul(s, t1) = 0. La utilidad de los seguidores se da por: • Para todo v ∈ V, uθv f (sv, t1) = 0; • Para todo v ∈ V y s ∈ S − {sv}, uθv f (s, t1) = K K−1 ; • Para todo v ∈ V y s ∈ S, uθv f (s, t0) = 1; • Para todo e ∈ E, s ∈ S, uθe f (s, t0) = 1; • Para todo e ∈ E, para ambos v ∈ e, uθe f (sv, t1) = 2K 3 ; • Para todo e ∈ E, para todo v /∈ e, uθe f (sv, t1) = 0. Sostenemos que una estrategia óptima a comprometerse le otorga al líder una utilidad esperada de al menos |E| |E|+1 + K (|E|+1)|V | si y solo si hay una solución para la instancia de CONJUNTO-INDEPENDIENTE. Primero, supongamos que hay una solución para la instancia de CONJUNTO-INDEPENDIENTE. Entonces, el líder podría comprometerse con la siguiente estrategia: por cada vértice v en el conjunto independiente, jugar el correspondiente sv con una probabilidad de 1/K. Si el seguidor tiene el tipo θe para algún e ∈ E, la utilidad esperada para el seguidor al jugar t1 es a lo sumo 1 K 2K 3 = 2/3, porque hay a lo sumo un vértice v ∈ e tal que sv se juega con probabilidad distinta de cero. Por lo tanto, el seguidor jugará t0 y obtendrá una utilidad de 1. Si el seguidor tiene el tipo θv para algún vértice v en el conjunto independiente, la utilidad esperada para el seguidor al jugar t1 es K−1 K K K−1 = 1, porque el líder juega sv con probabilidad 1/K. Se deduce que el seguidor (quien rompe los empates para maximizar la utilidad de los líderes) jugará t0, lo que también otorga una utilidad de 1 y brinda al líder una mayor utilidad. Por lo tanto, la utilidad esperada de los líderes para esta estrategia es al menos |E| |E|+1 + K (|E|+1)|V |, como se requiere. Ahora, supongamos que hay una estrategia que le da al líder una utilidad esperada de al menos |E| |E|+1 + K (|E|+1)|V |. Entonces, esta estrategia debe inducir al seguidor a jugar t0 siempre que tenga un tipo de la forma θe (porque de lo contrario, la utilidad podría ser a lo sumo |E|−1 |E|+1 + |V | (|E|+1)|V | = |E| |E|+1 < |E| |E|+1 + K (|E|+1)|V | ). Por lo tanto, no puede ser el caso de que para alguna arista e = (v1, v2) ∈ E, la probabilidad de que el líder juegue uno de sv1 y sv2 sea al menos 2/K, porque entonces la utilidad esperada para el seguidor de jugar t1 cuando tiene el tipo θe sería al menos 2 K 2K 3 = 4/3 > 1. Además, la estrategia debe inducir al seguidor a jugar t0 durante al menos K tipos de la forma θv. Inducir al seguidor a jugar t0 cuando tiene el tipo θv solo se puede lograr jugando sv con una probabilidad de al menos 1/K, lo que le dará al seguidor una utilidad de como máximo K−1 K K K−1 = 1 por jugar t1. Pero entonces, el conjunto de vértices v tales que sv se juega con una probabilidad de al menos 1/K debe constituir un conjunto independiente de tamaño K (porque si hubiera una arista e entre dos de estos vértices, induciría al seguidor a jugar t1 para el tipo θe según lo mencionado anteriormente). Por el contrario, si el seguidor tiene solo un tipo, entonces podemos generalizar el enfoque de programación lineal para juegos en forma normal: Teorema 8. En juegos bayesianos de 2 jugadores en los que el seguidor tiene solo un tipo, una estrategia mixta óptima a comprometerse se puede encontrar en tiempo polinómico utilizando programación lineal. Prueba. Generalizamos el enfoque en el Teorema 2 de la siguiente manera. Para cada estrategia pura de seguidor t, calculamos una estrategia mixta para el líder para cada uno de los tipos de líderes de manera que 1) jugar t sea una mejor respuesta para el seguidor, y 2) bajo esta restricción, la estrategia mixta maximice la utilidad esperada ex ante de los líderes. Para hacerlo, generalizamos el programa lineal de la siguiente manera: maximizar θl∈Θl π(θl) s∈S pθl s uθl l (s, t) sujeto a para todo t ∈ T, θl∈Θl π(θl) s∈S p θl s uf (s, t) ≥ θl∈Θl π(θl) s∈S p θl s uf (s, t) para todo θl ∈ Θl, s∈S p θl s = 1 Como en el Teorema 2, la solución para el programa lineal que maximiza el valor de la solución es una estrategia óptima a comprometerse. Esto muestra un contraste interesante entre el compromiso con estrategias puras y el compromiso con estrategias mixtas en juegos bayesianos: para las estrategias puras, el problema se vuelve fácil si el líder tiene solo un tipo (pero no si el seguidor tiene solo un tipo), mientras que para las estrategias mixtas, el problema se vuelve fácil si el seguidor tiene solo un tipo (pero no si el líder tiene solo un tipo). 4. CONCLUSIONES E INVESTIGACIONES FUTURAS En los sistemas multiagentes, los escenarios estratégicos suelen ser analizados bajo la suposición de que los jugadores eligen sus estrategias de forma simultánea. Esto requiere cierta noción de equilibrio (equilibrio de Nash y sus refinamientos), y a menudo conduce al problema de selección de equilibrio: no está claro para cada jugador individual según qué equilibrio debería jugar. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisión. Por ejemplo, un agente puede llegar al sitio del juego (real o virtual) antes que el otro, o, en el caso específico de agentes de software, el código de un agente puede estar completo y comprometido antes que el de otro agente. Tales modelos son referidos indistintamente como modelos de liderazgo, compromiso o <br>Stackelberg</br>, y el juego óptimo en tales modelos suele ser significativamente diferente al juego óptimo en el modelo donde las estrategias se seleccionan simultáneamente. Específicamente, si es posible el compromiso con estrategias mixtas, entonces el compromiso (óptimo) nunca perjudica al líder y a menudo lo beneficia. El reciente aumento del interés en las soluciones computacionales de teoría de juegos ha ignorado hasta ahora los modelos de liderazgo (con la excepción del interés en el diseño de mecanismos, donde el diseñador está implícitamente en una posición de liderazgo). En este artículo, estudiamos cómo calcular estrategias óptimas para comprometerse tanto a estrategias puras como a estrategias mixtas, tanto en juegos de forma normal como en juegos bayesianos. Para juegos en forma normal, demostramos que la estrategia pura óptima a comprometerse se puede encontrar eficientemente para cualquier número de jugadores. Una estrategia mixta óptima para comprometerse en un juego en forma normal puede encontrarse eficientemente para dos jugadores utilizando programación lineal (y no más eficientemente que eso, en el sentido de que cualquier programa lineal con una restricción de probabilidad puede ser codificado como tal problema). (Esta es una generalización de la computabilidad en tiempo polinómico de las estrategias minimax en juegos en forma normal). El problema se vuelve NP-duro para tres (o más) jugadores. En los juegos bayesianos, el problema de encontrar una estrategia pura óptima a la que comprometerse es NP-duro incluso en juegos de dos jugadores en los que el seguidor tiene solo un tipo, aunque los juegos de dos jugadores en los que el líder tiene solo un tipo pueden resolverse eficientemente. El problema de encontrar una estrategia mixta óptima a comprometerse en un juego bayesiano es NP-duro incluso en juegos de dos jugadores en los que el líder tiene solo un tipo, aunque los juegos de dos jugadores en los que el seguidor tiene solo un tipo pueden resolverse eficientemente utilizando una generalización del enfoque de programación lineal para juegos en forma normal. Las siguientes dos tablas resumen estos resultados. 2 jugadores ≥ 3 jugadores forma normal O(#resultados) O(#resultados· #jugadores) Bayesiano, O(#resultados· NP-completo 1-tipo líder #tipos) Bayesiano, NP-completo NP-completo 1-tipo seguidor Bayesiano (general) NP-completo NP-completo Resultados para el compromiso con estrategias puras. (Con más de 2 jugadores, el seguidor es el último jugador en comprometerse, el líder es el primero.) 88 2 jugadores ≥ 3 jugadores forma normal una resolución de LP por acción NP-completa del seguidor Bayesiano, NP-completo NP-completo 1-tipo líder Bayesiano, una resolución de LP por acción NP-completa del 1-tipo seguidor Bayesiano (general) NP-completo NP-completo Resultados para el compromiso con estrategias mixtas. (Con más de 2 jugadores, el seguidor es el último jugador en comprometerse, el líder es el primero.) La investigación futura puede tomar varias direcciones. Primero, podemos evaluar empíricamente las técnicas presentadas aquí en conjuntos de pruebas como GAMUT [19]. También podemos estudiar la computación de estrategias óptimas a comprometerse en otras representaciones concisas de juegos en forma normal, por ejemplo, en juegos gráficos [10] o juegos de grafo de efecto local/acción [14, 1]. Para los casos en los que calcular una estrategia óptima para comprometerse es NP-duro, también podemos estudiar la computación de estrategias aproximadamente óptimas para comprometerse. Si bien la definición correcta de una estrategia aproximadamente óptima en este contexto puede parecer simple al principio, debería ser una estrategia que, si los jugadores siguientes juegan de manera óptima, funcione casi tan bien como la estrategia óptima en promedio, esta definición se vuelve problemática cuando consideramos que los otros jugadores también podrían estar jugando solo de manera aproximadamente óptima. Uno también puede estudiar modelos en los que múltiples (pero no todos) jugadores se comprometen al mismo tiempo. Otra dirección interesante a explorar es ver si calcular estrategias mixtas óptimas a las que comprometerse puede ayudarnos, o de alguna manera arrojar luz sobre, el cálculo de equilibrios de Nash. A menudo, las estrategias mixtas óptimas a las que comprometerse también son estrategias de equilibrio de Nash (por ejemplo, en juegos de suma cero de dos jugadores esto siempre es cierto), aunque no siempre es el caso (por ejemplo, como ya señalamos, a veces la estrategia óptima a la que comprometerse es una estrategia estrictamente dominada, que nunca puede ser una estrategia de equilibrio de Nash). 5. REFERENCIAS [1] N. A. R. Bhat y K. Leyton-Brown. Calculando los equilibrios de Nash de juegos de gráficos de acción. En Actas de la 20ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI), Banff, Canadá, 2004. [2] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Actas de la Decimoctava Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 765-771, Acapulco, México, 2003. [3] V. Conitzer y T. Sandholm. Complejidad del dominio (iterado). En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 88-97, Vancouver, Canadá, 2005. [4] V. Conitzer y T. Sandholm. Un criterio de eliminabilidad de estrategias generalizado y métodos computacionales para aplicarlo. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 483-488, Pittsburgh, PA, EE. UU., 2005. [5] A. A. Cournot. Las investigaciones sobre los juegos bayesianos son una representación potencialmente concisa de los juegos en forma normal en los principios matemáticos de la teoría de la riqueza. Hachette, París, 1838. [6] G. Dantzig. Una prueba de la equivalencia del problema de programación y el problema de juego. En T. Koopmans, editor, Análisis de la actividad de producción y asignación, páginas 330-335. John Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, and E. Zemel. \n\nJohn Wiley & Sons, 1951. [7] I. Gilboa, E. Kalai, y E. Zemel. La complejidad de eliminar estrategias dominadas. Matemáticas de la Investigación de Operaciones, 18:553-565, 1993. [8] I. Gilboa y E. Zemel. Nash y equilibrios correlacionados: Algunas consideraciones de complejidad. Juegos y Comportamiento Económico, 1:80-93, 1989. [9] R. Karp. Reductibilidad entre problemas combinatorios. En R. E. Miller y J. W. Thatcher, editores, Complejidad de las Computaciones de Computadoras, páginas 85-103. Plenum Press, Nueva York, 1972. [10] M. Kearns, M. Littman y S. Singh. Modelos gráficos para teoría de juegos. En Actas de la Conferencia sobre Incertidumbre en Inteligencia Artificial (UAI), 2001. [11] D. E. Knuth, C. H. Papadimitriou y J. N. Tsitsiklis. Una nota sobre la eliminación de estrategias en juegos bimatrix. Cartas de Investigación Operativa, 7(3):103-107, 1988. [12] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [13] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [14] K. Leyton-Brown y M. Tennenholtz. Juegos de efecto local. En Actas de la Decimoctava Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), Acapulco, México, 2003. [15] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 36-41, San Diego, CA, 2003. [16] M. Littman y P. Stone. Un algoritmo de equilibrio de Nash de tiempo polinómico para juegos repetidos. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 48-54, San Diego, CA, 2003. [17] R. D. Luce y H. Raiffa. Juegos y decisiones. John Wiley and Sons, Nueva York, 1957. Reedición de Dover 1989. [18] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [19] E. Nudelman, J. Wortman, K. Leyton-Brown y Y. Shoham. Ejecutar el GAMUT: Un enfoque integral para evaluar algoritmos de teoría de juegos. En la Conferencia Internacional sobre Agentes Autónomos y Sistemas Multiagente (AAMAS), Nueva York, NY, EE. UU., 2004. [20] M. J. Osborne y A. Rubinstein. Un curso de teoría de juegos. MIT Press, 1994. [21] C. Papadimitriou. \n\nMIT Press, 1994. [21] C. Papadimitriou. Algoritmos, juegos e Internet. En Actas del Simposio Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. 89 [22] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 664-669, San José, CA, EE. UU., 2004. [23] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [24] J. von Neumann. A la teoría de los juegos sociales. Mathematische Annalen, 100:295-320, 1927. [25] H. von <br>Stackelberg</br>. \n\nMathematische Annalen, 100:295-320, 1927. [25] H. von <br>Stackelberg</br>. Forma de mercado y equilibrio. Springer, Viena, 1934. [26] B. von Stengel y S. Zamir. Liderazgo con compromiso hacia estrategias mixtas. Informe de investigación CDAM LSE-CDAM-2004-01, London School of Economics, febrero de 2004. 90 ",
            "candidates": [],
            "error": [
                [
                    "Stackelberg",
                    "von Stackelberg",
                    "Stackelberg",
                    "Stackelberg",
                    "Stackelberg"
                ]
            ]
        }
    }
}