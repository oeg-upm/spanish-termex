{
    "id": "H-19",
    "original_text": "Analyzing Feature Trajectories for Event Detection Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg School of Computer Engineering Nanyang Technological University Block N4, Nanyang Avenue, Singapore 639798 ABSTRACT We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words. A set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner. The document frequency of each word across time is treated like a time series, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point. In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events. All of the above methods can be applied to time series data in general. We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events. Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Experimentation. 1. INTRODUCTION There are more than 4,000 online news sources in the world. Manually monitoring all of them for important events has become difficult or practically impossible. In fact, the topic detection and tracking (TDT) community has for many years been trying to come up with a practical solution to help people monitor news effectively. Unfortunately, the holy grail is still elusive, because the vast majority of TDT solutions proposed for event detection [20, 5, 17, 4, 21, 7, 14, 10] are either too simplistic (based on cosine similarity [5]) or impractical due to the need to tune a large number of parameters [9]. The ineffectiveness of current TDT technologies can be easily illustrated by subscribing to any of the many online news alerts services such as the industryleading Google News Alerts [2], which generates more than 50% false alarms [10]. As further proof, portals like Yahoo take a more pragmatic approach by requiring all machine generated news alerts to go through a human operator for confirmation before sending them out to subscribers. Instead of attacking the problem with variations of the same hammer (cosine similarity and TFIDF), a fundamental understanding of the characteristics of news stream data is necessary before any major breakthroughs can be made in TDT. Thus in this paper, we look at news stories and feature trends from the perspective of analyzing a time-series word signal. Previous work like [9] has attempted to reconstruct an event with its representative features. However, in many predictive event detection tasks (i.e., retrospective event detection), there is a vast set of potential features only for a fixed set of observations (i.e., the obvious bursts). Of these features, often only a small number are expected to be useful. In particular, we study the novel problem of analyzing feature trajectories for event detection, borrowing a well-known technique from signal processing: identifying distributional correlations among all features by spectral analysis. To evaluate our method, we subsequently propose an unsupervised event detection algorithm for news streams. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Easter April (a) aperiodic event 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Unaudited Ended (b) periodic event Figure 1: Feature correlation (DFIDF:time) between a) Easter and April b) Unaudited and Ended. As an illustrative example, consider the correlation between the words Easter and April from the Reuters Corpus1 . From the plot of their normalized DFIDF in Figure 1(a), we observe the heavy overlap between the two words circa 04/1997, which means they probably both belong to the same event during that time (Easter feast). In this example, the hidden event Easter feast is a typical important aperiodic event over 1-year data. Another example is given by Figure 1(b), where both the words Unaudited and Ended 1 Reuters Corpus is the default dataset for all examples. exhibit similar behaviour over periods of 3 months. These two words actually originated from the same periodic event, net income-loss reports, which are released quarterly by publicly listed companies. Other observations drawn from Figure 1 are: 1) the bursty period of April is much longer than Easter, which suggests that April may exist in other events during the same period; 2) Unaudited has a higher average DFIDF value than Ended, which indicates Unaudited to be more representative for the underlying event. These two examples are but the tip of the iceberg among all word trends and correlations hidden in a news stream like Reuters. If a large number of them can be uncovered, it could significantly aid TDT tasks. In particular, it indicates the significance of mining correlating features for detecting corresponding events. To summarize, we postulate that: 1) An event is described by its representative features. A periodic event has a list of periodic features and an aperiodic event has a list of aperiodic features; 2) Representative features from the same event share similar distributions over time and are highly correlated; 3) An important event has a set of active (largely reported) representative features, whereas an unimportant event has a set of inactive (less-reported) representative features; 4) A feature may be included by several events with overlaps in time frames. Based on these observations, we can either mine representative features given an event or detect an event from a list of highly correlated features. In this paper, we focus on the latter, i.e., how correlated features can be uncovered to form an event in an unsupervised manner. 1.1 Contributions This paper has three main contributions: • To the best of our knowledge, our approach is the first to categorize word features for heterogenous events. Specifically, every word feature is categorized into one of the following five feature types based on its power spectrum strength and periodicity: 1) HH (high power and high/long periodicity): important aperiodic events, 2) HL (high power and low periodicity): important periodic events, 3) LH (low power and high periodicity): unimportant aperiodic events, 4) LL (low power and low periodicity): non-events, and 5) SW (stopwords), a higher power and periodicity subset of LL comprising stopwords, which contains no information. • We propose a simple and effective mixture densitybased approach to model and detect feature bursts. • We come up with an unsupervised event detection algorithm to detect both aperiodic and periodic events. Our algorithm has been evaluated on a real news stream to show its effectiveness. 2. RELATED WORK This work is largely motivated by a broader family of problems collectively known as Topic Detection and Tracking (TDT) [20, 5, 17, 4, 21, 7, 14, 10]. Moreover, most TDT research so far has been concerned with clustering/classifying documents into topic types, identifying novel sentences [6] for new events, etc., without much regard to analyzing the word trajectory with respect to time. Swan and Allan [18] first attempted using co-occuring terms to construct an event. However, they only considered named entities and noun phrase pairs, without considering their periodicities. On the contrary, our paper considers all of the above. Recently, there has been significant interest in modeling an event in text streams as a burst of activities by incorporating temporal information. Kleinbergs seminal work described how bursty features can be extracted from text streams using an infinite automaton model [12], which inspired a whole series of applications such as Kumars identification of bursty communities from Weblog graphs [13], Meis summarization of evolutionary themes in text streams [15], Hes clustering of text streams using bursty features [11], etc. Nevertheless, none of the existing work specifically identified features for events, except for Fung et al. [9], who clustered busty features to identify various bursty events. Our work differs from [9] in several ways: 1) we analyze every single feature, not only bursty features; 2) we classify features along two categorical dimensions (periodicity and power), yielding altogether five primary feature types; 3) we do not restrict each feature to exclusively belong to only one event. Spectral analysis techniques have previously been used by Vlachos et al. [19] to identify periodicities and bursts from query logs. Their focus was on detecting multiple periodicities from the power spectrum graph, which were then used to index words for query-by-burst search. In this paper, we use spectral analysis to classify word features along two dimensions, namely periodicity and power spectrum, with the ultimate goal of identifying both periodic and aperiodic bursty events. 3. DATA REPRESENTATION Let T be the duration/period (in days) of a news stream, and F represents the complete word feature space in the classical static Vector Space Model (VSM). 3.1 Event Periodicity Classification Within T, there may exist certain events that occur only once, e.g., Tony Blair elected as Prime Minister of U.K., and other recurring events of various periodicities, e.g., weekly soccer matches. We thus categorize all events into two types: aperiodic and periodic, defined as follows. Definition 1. (Aperiodic Event) An event is aperiodic within T if it only happens once. Definition 2. (Periodic Event) If events of a certain event genre occur regularly with a fixed periodicity P ≤ T/2 , we say that this particular event genre is periodic, with each member event qualified as a periodic event. Note that the definition of aperiodic is relative, i.e., it is true only for a given T, and may be invalid for any other T > T. For example, the event Christmas feast is aperiodic for T ≤ 365 but periodic for T ≥ 730. 3.2 Representative Features Intuitively, an event can be described very concisely by a few discriminative and representative word features and vice-versa, e.g., hurricane, sweep, and strike could be representative features of a Hurricane genre event. Likewise, a set of strongly correlated features could be used to reconstruct an event description, assuming that strongly correlated features are representative. The representation vector of a word feature is defined as follows: Definition 3. (Feature Trajectory) The trajectory of a word feature f can be written as the sequence yf = [yf (1), yf (2), . . . , yf (T)], where each element yf (t) is a measure of feature f at time t, which could be defined using the normalized DFIDF score2 yf (t) = DFf (t) N(t) × log( N DFf ), where DFf (t) is the number of documents (local DF) containing feature f at day t, DFf is the total number of documents (global DF) containing feature f over T, N(t) is the number of documents for day t, and N is the total number of documents over T. 4. IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 Spectral Analysis for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. DFT can represent the original time series as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T. The original trajectory can be reconstructed with just the dominant frequencies, which can be determined from the power spectrum using the popular periodogram estimator. The periodogram is a sequence of the squared magnitude of the Fourier coefficients, Xk 2 , k = 1, 2, . . . , T/2 , which indicates the signal power at frequency k/T in the spectrum. From the power spectrum, the dominant period is chosen as the inverse of the frequency with the highest power spectrum, as follows. Definition 4. (Dominant Period) The dominant period (DP) of a given feature f is Pf = T/ arg max k Xk 2 . Accordingly, we have Definition 5. (Dominant Power Spectrum) The dominant power spectrum (DPS) of a given feature f is Sf = Xk 2 , with Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorizing Features The DPS of a feature trajectory is a strong indicator of its activeness at the specified frequency; the higher the DPS, the more likely for the feature to be bursty. Combining DPS with DP, we therefore categorize all features into four types: 2 We normalize yf (t) as yf (t) = yf (t)/ T i=1 yf (i) so that it could be interpreted as a probability. • HH: high Sf , aperiodic or long-term periodic (Pf > T/2 ); • HL: high Sf , short-term periodic (Pf ≤ T/2 ); • LH: low Sf , aperiodic or long-term periodic; • LL: low Sf , short-term periodic. The boundary between long-term and short-term periodic is set to T/2 . However, distinguishing between a high and low DPS is not straightforward, which will be tackled later. Properties of Different Feature Sets To better understand the properties of HH, HL, LH and LL, we select four features, Christmas, soccer, DBS and your as illustrative examples. Since the boundary between high and low power spectrum is unclear, these chosen examples have relative wide range of power spectrum values. Figure 2(a) shows the DFIDF trajectory for Christmas with a distinct burst around Christmas day. For the 1-year Reuters dataset, Christmas is classified as a typical aperiodic event with Pf = 365 and Sf = 135.68, as shown in Figure 2(b). Clearly, the value of Sf = 135.68 is reasonable for a well-known bursty event like Christmas. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Christmas(DFIDF:time) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Christmas(S:frequency) Figure 2: Feature Christmas with relative high Sf and long-term Pf . The DFIDF trajectory for soccer is shown in Figure 3(a), from which we can observe that there is a regular burst every 7 days, which is again verified by its computed value of Pf = 7, as shown in Figure 3(b). Using the domain knowledge that soccer games have more matches every Saturday, which makes it a typical and heavily reported periodic event, we thus consider the value of Sf = 155.13 to be high. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) soccer(DFIDF:time) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) soccer(S:frequency) Figure 3: Feature soccer with relative high Sf and short-term Pf . From the DFIDF trajectory for DBS in Figure 4(a), we can immediately deduce DBS to be an infrequent word with a trivial burst on 08/17/1997 corresponding to DBS Land Raﬄes Holdings plans. This is confirmed by the long period of Pf = 365 and low power of Sf = 0.3084 as shown in Figure 4(b). Moreover, since this aperiodic event is only reported in a few news stories over a very short time of few days, we therefore say that its low power value of Sf = 0.3084 is representative of unimportant events. The most confusing example is shown in Figure 5 for the word feature your, which looks very similar to the graph for soccer in Figure 3. At first glance, we may be tempted to group both your and soccer into the same category of HL or LL since both distributions look similar and have the same dominant period of approximately a week. However, further 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:time) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frequency) Figure 4: Feature DBS with relative low Sf and long-term Pf . analysis indicates that the periodicity of your is due to the differences in document counts for weekdays (average 2,919 per day) and weekends3 (average 479 per day). One would have expected the periodicity of a stopword like your to be a day. Moreover, despite our DFIDF normalization, the weekday/weekend imbalance still prevailed; stopwords occur 4 times more frequently on weekends than on weekdays. Thus, the DPS remains the only distinguishing factor between your (Sf = 9.42) and soccer (Sf = 155.13). However, it is very dangerous to simply conclude that a power value of S = 9.42 corresponds to a stopword feature. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) your(DFIDF:time) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) your(S:frequency) Figure 5: Feature your as an example confusing with feature soccer. Before introducing our solution to this problem, lets look at another LL example as shown in Figure 6 for beenb, which is actually a confirmed typo. We therefore classify beenb as a noisy feature that does not contribute to any event. Clearly, the trajectory of your is very different from beenb, which means that the former has to be considered separately. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figure 6: Feature beenb with relative low Sf and short-term Pf . Stop Words (SW) Feature Set Based on the above analysis, we realize that there must be another feature set between HL and LL that corresponds to the set of stopwords. Features from this set has moderate DPS and low but known dominant period. Since it is hard to distinguish this feature set from HL and LL only based on DPS, we introduce another factor called average DFIDF (DFIDF). As shown in Figure 5, features like your usually have a lower DPS than a HL feature like soccer, but have a much higher DFIDF than another LL noisy feature such as beenb. Since such properties are usually characteristics of stopwords, we group features like your into the newly defined stopword (SW) feature set. Since setting the DPS and DFIDF thresholds for identifying stopwords is more of an art than science, we proposed a heuristic HS algorithm, Algorithm 1. The basic idea is to only use news stories from weekdays to identify stopwords. 3 The weekends here also include public holidays falling on weekdays. The SW set is initially seeded with a small set of 29 popular stopwords utilized by Google search engine. Algorithm 1 Heuristic Stopwords detection (HS) Input: Seed SW set, weekday trajectories of all words 1: From the seed set SW, compute the maximum DPS as UDPS, maximum DFIDF as UDFIDF, and minimum of DFIDF as LDFIDF. 2: for fi ∈ F do 3: Compute DFT for fi. 4: if Sfi ≤ UDPS and DFIDFfi ∈ [LDFIDF, UDFIDF] then 5: fi → SW 6: F = F − fi 7: end if 8: end for Overview of Feature Categorization After the SW set is generated, all stopwords are removed from F. We then set the boundary between high and low DPS to be the upper bound of the SW sets DPS. An overview of all five feature sets is shown in Figure 7. Figure 7: The 5 feature sets for events. 5. IDENTIFYING BURSTS FOR FEATURES Since only features from HH, HL and LH are meaningful and could potentially be representative to some events, we pruned all other feature classified as LL or SW. In this section, we describe how bursts can be identified from the remaining features. Unlike Kleinbergs burst identification algorithm [12], we can identify both significant and trivial bursts without the need to set any parameters. 5.1 Detecting Aperiodic Features Bursts For each feature in HH and HL, we truncate its trajectory by keeping only the bursty period, which is modeled with a Gaussian distribution. For example, Figure 8 shows the word feature Iraq with a burst circa 09/06/1996 being modeled as a Gaussian. Its bursty period is defined by [μf − σf , μf + σf ] as shown in Figure 8(b). 5.2 Detecting Periodic Features Bursts Since we have computed the DP for a periodic feature f, we can easily model its periodic feature trajectory yf using 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) original DFIDF:time 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 burst= [μ-σ, μ+σ] (b) identifying burst Figure 8: Modeling Iraqs time series as a truncated Gaussian with μ = 09/06/1996 and σ = 6.26. a mixture of K = T/Pf Gaussians: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , where the parameter set θf = {αk, μk, σk}K k=1 comprises: • αk is the probability of assigning yf into the kth Gaussian. αk > 0, ∀k ∈ [1, K] and K k=1 αk = 1; • μk/σk is mean/standard deviation of the kth Gaussian. The well known Expectation Maximization (EM) [8] algorithm is used to compute the mixing proportions αk, as well as the individual Gaussian density parameters μk and σK . Each Gaussian represents one periodic event, and is modeled similarly as mentioned in Section 5.1. 6. EVENTS FROM FEATURES After identifying and modeling bursts for all features, the next task is to paint a picture of the event with a potential set of representative features. 6.1 Feature Correlation If two features fi and fj are representative of the same event, they must satisfy the following necessary conditions: 1. fi and fj are identically distributed: yfi ∼ yfj . 2. fi and fj have a high document overlap. Measuring Feature Distribution Similarity We measure the similarity between two features fi and fj using discrete KL-divergence defined as follows. Definition 6. (feature similarity) KL(fi, fj ) is given by max(KL(fi|fj ), KL(fj |fi)), where KL(fi|fj ) = T t=1 f(yfi (t)|θfi )log f(yfi (t)|θfi ) f(yfj (t)|θfj ) . (1) Since KL-divergence is not symmetric, we define the similarity between between fi and fj as the maximum of KL(fi|fj ) and KL(fj |fi). Further, the similarity between two aperiodic features can be computed using a closed form of the KL-divergence [16]. The same discrete KL-divergence formula of Eq. 1 is employed to compute the similarity between two periodic features, Next, we define the overal similarity among a set of features R using the maximum inter-feature KL-Divergence value as follows. Definition 7. (sets similarity)KL(R) = max ∀fi,fj ∈R KL(fi, fj ). Document Overlap Let Mi be the set of all documents containing feature fi. Given two features fi and fj , the overlapping document set containing both features is Mi ∩ Mj . Intuitively, the higher the |Mi ∩ Mj |, the more likelty that fi and fj will be highly correlated. We define the degree of document overlap between two features fi and fj as follows. Definition 8. (Feature DF Overlap) d(fi, fj ) = |Mi∩Mj| min(|Mi|,|Mj|) . Accordingly, the DF Overlap among a set of features R is also defined. Definition 9. (Set DF Overlap) d(R) = min ∀fi,fj ∈R d(fi, fj). 6.2 Unsupervised Greedy Event Detection We use features from HH to detect important aperiodic events, features from LH to detect less-reported/unimportant aperiodic events, and features from HL to detect periodic events. All of them share the same algorithm. Given bursty feature fi ∈ HH, the goal is to find highly correlated features from HH. The set of features similar to fi can then collectively describe an event. Specifically, we need to find a subset Ri of HH that minimizes the following cost function: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) The underlying event e (associated with the burst of fi) can be represented by Ri as y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) The burst analysis for event e is exactly the same as the feature trajectory. The cost in Eq. 2 can be minimized using our unsupervised greedy UG event detection algorithm, which is described in Algorithm 2. The UG algorithm allows a feature Algorithm 2 Unsupervised Greedy event detection (UG). Input: HH, document index for each feature. 1: Sort and select features in descending DPS order: Sf1 ≥ Sf2 ≥ . . . ≥ Sf|HH| . 2: k = 0. 3: for fi ∈ HH do 4: k = k + 1. 5: Init: Ri ← fi, C(Ri) = 1/Sfi and HH = HH − fi. 6: while HH not empty do 7: m = arg min m C(Ri ∪ fm). 8: if C(Ri ∪ fm) < C(Ri) then 9: Ri ← fm and HH = HH − fm. 10: else 11: break while. 12: end if 13: end while 14: Output ek as Eq. 3. 15: end for to be contained in multiple events so that we can detect several events happening at the same time. Furthermore, trivial events only containing year/month features (i.e., an event only containing 1 feature Aug could be identified over a 1year news stream) could be removed, although such events will have inherent high cost and should already be ranked very low. Note that our UG algorithm only requires one data-dependant parameter, the boundary between high and low power spectrum, to be set once, and this parameter can be easily estimated using the HS algorithm (Algorithm 1). 7. EXPERIMENTS In this section, we study the performances of our feature categorizing method and event detection algorithm. We first introduce the dataset and experimental setup, then we subjectively evaluate the categorization of features for HH, HL, LH, LL and SW. Finally, we study the (a)periodic event detection problem with Algorithm 2. 7.1 Dataset and Experimental Setup The Reuters Corpus contains 806,791 English news stories from 08/20/1996 to 08/19/1997 at a day resolution. Version 2 of the open source Lucene software [1] was used to tokenize the news text content and generate the document-word vector. In order to preserve the time-sensitive past/present/future tenses of verbs and the differences between lower case nouns and upper case named entities, no stemming was done. Since dynamic stopword removal is one of the functionalities of our method, no stopword was removed. We did remove nonEnglish characters, however, after which the number of word features amounts to 423,433. All experiments were implemented in Java and conducted on a 3.2 GHz Pentium 4 PC running Windows 2003 Server with 1 GB of memory. 7.2 Categorizing Features We downloaded 34 well-known stopwords utilized by the Google search engine as our seed training features, which includes a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en and www. We excluded the last five stopwords as they are uncommon in news stories. By only analyzing news stories over 259 weekdays, we computed the upper bound of the power spectrum for stopwords at 11.18 and corresponding DFIDF ranges from 0.1182 to 0.3691. Any feature f satisfying Sf <= 11.18 and 0.1182 <= DFIDFf <= 0.3691 over weekdays will be considered a stopword. In this manner, 470 stopwords were found and removed as visualized in Figure 9. Some detected stopwords are A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) and much (P = 22, S = 0.80, DFIDF = 0.1865). After the removal of these stopwords, the distribution of weekday and weekend news are more or less matched, and in the ensuing experiments, we shall make use of the full corpus (weekdays and weekends). The upper bound power spectrum value of 11.18 for stopwords training was selected as the boundary between the high power and low power spectrum. The boundary between high and low periodicity was set to 365/2 = 183. All 422,963 (423433 − 470) word features were categorized into 4 feature sets: HH (69 features), HL (1,087 features), LH (83,471 features), and LL (338,806 features) as shown in Figure 10. In Figure 10, each gray level denotes the relative density of features in a square region, measured by log10(1 + Dk), where Dk is the number of features within the k-th square region. From the figure, we can make the 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figure 9: Distribution of SW (stopwords) in the HH, HL, LH, and LL regions. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figure 10: Distribution of categorized features over the four quadrants (shading in log scale). following observations: 1. Most features have low S and are easily distinguishable from those features having a much higher S, which allows us to detect important (a)periodic events from trivial events by selecting features with high S. 2. Features in the HH and LH quadrants are aperiodic, which are nicely separated (big horizontal gap) from the periodic features. This allows reliably detecting aperiodic events and periodic events independently. 3. The (vertical) boundary between high and low power spectrum is not as clearcut and the exact value will be application specific. By checking the scatter distribution of features from SW on HH, HL, LH, and LL as shown in Figure 9, we found that 87.02%(409/470) of the detected stopwords originated from LL. The LL classification and high DFIDF scores of stopwords agree with the generally accepted notion that stopwords are equally frequent over all time. Therefore, setting the boundary between high and low power spectrum using the upper bound Sf of SW is a reasonable heuristic. 7.3 Detecting Aperiodic Events We shall evaluate our two hypotheses, 1)important aperiodic events can be defined by a set of HH features, and 2)less reported aperiodic events can be defined by a set of LH features. Since no benchmark news streams exist for event detection (TDT datasets are not proper streams), we evaluate the quality of the automatically detected events by comparing them to manually-confirmed events by searching through the corpus. Among the 69 HH features, we detected 17 important aperiodic events as shown in Table 1 (e1 − e17). Note that the entire identification took less than 1 second, after removing events containing only the month feature. Among the 17 events, other than the overlaps between e3 and e4 (both describes the same hostage event), e11 and e16 (both about company reports), the 14 identified events are extremely accurate and correspond very well to the major events of the period. For example, the defeat of Bob Dole, election of Tony Blair, Missile attack on Iraq, etc. Recall that selecting the features for one event should minimize the cost in Eq. 2 such that 1) the number of features span different events, and 2) not all features relevant to an event will be selected, e.g., the feature Clinton is representative to e12 but since Clinton relates to many other events, its time domain signal is far different from those of other representative features like Dole and Bob. The number of documents of a detected event is roughly estimated by the number of indexed documents containing the representative features. We can see that all 17 important aperiodic events are popularly reported events. After 742 minutes of computation time, we detected 23, 525 less reported aperiodic events from 83,471 LH features. Table 1 lists the top 5 detected aperiodic events (e18 − e22) with respect to the cost. We found that these 5 events are actually very trivial events with only a few news reports, and are usually subsumed by some larger topics. For example, e22 is one of the rescue events in an airplane hijack topic. One advantage of our UG Algorithm for discovering less-reported aperiodic events is that we are able to precisely detect the true event period. 7.4 Detecting Periodic Events Among the 1,087 HL features, 330 important periodic events were detected within 10 minutes of computing time. Table 1 lists the top 5 detected periodic events with respect to the cost (e23 − e27). All of the detected periodic events are indeed valid, and correspond to real life periodic events. The GMM model is able to detect and estimate the bursty period nicely although it cannot distinguish the slight difference between every Monday-Friday and all weekdays as shown in e23. We also notice that e26 is actually a subset of e27 (soccer game), which is acceptable since the Sheffield league results are announced independently every weekend. 8. CONCLUSIONS This paper took a whole new perspective of analyzing feature trajectories as time domain signals. By considering the word document frequencies in both time and frequency domains, we were able to derive many new characteristics about news streams that were previously unknown, e.g., the different distributions of stopwords during weekdays and weekends. For the first time in the area of TDT, we applied a systematic approach to automatically detect important and less-reported, periodic and aperiodic events. The key idea of our work lies in the observations that (a)periodic events have (a)periodic representative features and (un)important events have (in)active representative features, differentiated by their power spectrums and time periods. To address the real event detection problem, a simple and effective mixture density-based approach was used to identify feature bursts and their associated bursty periods. We also designed an unsupervised greedy algorithm to detect both aperiodic and periodic events, which was successful in detecting real events as shown in the evaluation on a real news stream. Although we have not made any benchmark comparison against another approach, simply because there is no previous work in the addressed problem. Future work includes evaluating the recall of detected events for a labeled news stream, and comparing our model against the closest equivalent methods, which currently are limited to the methods of Kleinberg [12] (which can only detect certain type of bursty events depending on parameter settings), Fung et al. [9], and Swan and Allan [18]. Nevertheless, we believe our simple and effective method will be useful for all TDT practitioners, and will be especially useful for the initial exploratory analysis of news streams. 9. REFERENCES [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Google news alerts, http://www.google.com/alerts. [3] Reuters corpus, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan. Topic Detection and Tracking. Event-based Information Organization. Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, and H. Jin. First story detection in tdt is hard. In CIKM, pages 374-381, 2000. [6] J. Allan, C. Wade, and A. Bolivar. Retrieval and novelty detection at the sentence level. In SIGIR, pages 314-321, 2003. [7] T. Brants, F. Chen, and A. Farahat. A system for new event detection. In SIGIR, pages 330-337, 2003. [8] A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu, and H. Lu. Parameter free bursty events detection in text streams. In VLDB, pages 181-192, 2005. [10] Q. He, K. Chang, and E.-P. Lim. A model for anticipatory event detection. In ER, pages 168-181, 2006. [11] Q. He, K. Chang, E.-P. Lim, and J. Zhang. Bursty feature reprensentation for clustering text streams. In SDM, accepted, 2007. [12] J. Kleinberg. Bursty and hierarchical structure in streams. In SIGKDD, pages 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins. On the bursty evolution of blogspace. In WWW, pages 159-178, 2005. [14] G. Kumaran and J. Allan. Text classification and named entities for new event detection. In SIGIR, pages 297-304, 2004. [15] Q. Mei and C. Zhai. Discovering evolutionary theme patterns from text: an exploration of temporal text mining. In SIGKDD, pages 198-207, 2005. [16] W. D. Penny. Kullback-liebler divergences of normal, gamma, dirichlet and wishart densities. Technical report, 2001. [17] N. Stokes and J. Carthy. Combining semantic and syntactic document classifiers to improve first story detection. In SIGIR, pages 424-425, 2001. [18] R. Swan and J. Allan. Automatic generation of overview timelines. In SIGIR, pages 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena, and D. Gunopulos. Identifying similarities, periodicities and bursts for online search queries. In SIGMOD, pages 131-142, 2004. [20] Y. Yang, T. Pierce, and J. Carbonell. A study of retrospective and on-line event detection. In SIGIR, pages 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell, and C. Jin. Topic-conditioned novelty detection. In SIGKDD, pages 688-693, 2002. Table 1: All important aperiodic events (e1 − e17), top 5 less-reported aperiodic events (e18 − e22) and top 5 important periodic events (e23 − e27). Detected Event and Bursty Period Doc # True Event e1(Sali,Berisha,Albania,Albanian,March) 02/02/199705/29/1997 1409 Albanians president Sali Berisha lost in an early election and resigned, 12/1996-07/1997. e2(Seko,Mobutu,Sese,Kabila) 03/22/1997-06/09/1997 2273 Zaires president Mobutu Sese coordinated the native rebellion and failed on 05/16/1997. e3(Marxist,Peruvian) 11/19/1996-03/05/1997 824 Peru rebels (Tupac Amaru revolutionary Movement) led a hostage siege in Lima in early 1997. e4(Movement,Tupac,Amaru,Lima,hostage,hostages) 11/16/1996-03/20/1997 824 The same as e3. e5(Kinshasa,Kabila,Laurent,Congo) 03/26/199706/15/1997 1378 Zaire was renamed the Democratic Republic of Congo on 05/16/1997. e6(Jospin,Lionel,June) 05/10/1997-07/09/1997 605 Following the early General Elections circa 06/1997, Lionel Jospin was appointed Prime Minister on 06/02/1997. e7(Iraq,missile) 08/31/1996-09/13/1996 1262 U.S. fired missile at Iraq on 09/03/1996 and 09/04/1996. e8(Kurdish,Baghdad,Iraqi) 08/29/1996-09/09/1996 1132 Iraqi troop fought with Kurdish faction circa 09/1996. e9(May,Blair) 03/24/1997-07/04/1997 1049 Tony Blair became the Primary Minister of the United Kingdom on 05/02/1997. e10(slalom,skiing) 12/05/1996-03/21/1997 253 Slalom Game of Alpine Skiing in 01/1997-02/1997. e11(Interim,months) 09/24/1996-12/31/1996 3063 Tokyo released company interim results for the past several months in 09/1996-12/1996. e12(Dole,Bob) 09/09/1996-11/24/1996 1599 Dole Bob lost the 1996 US presidential election. e13(July,Sen) 06/25/1997-06/25/1997 344 Cambodias Prime Minister Hun Sen launched a bloody military coup in 07/1997. e14(Hebron) 10/15/1996-02/14/1997 2098 Hebron was divided into two sectors in early 1997. e15(April,Easter) 02/23/1997-05/04/1997 480 Easter feasts circa 04/1997 (for western and Orthodox). e16(Diluted,Group) 04/27/1997-07/20/1997 1888 Tokyo released all 96/97 group results in 04/199707/1997. e17(December,Christmas) 11/17/1996-01/26/1997 1326 Christmas feast in late 12/1997. e18(Kolaceva,winter,Together,promenades,Zajedno, Slobodan,Belgrade,Serbian,Serbia,Draskovic,municipal, Kragujevac) 1/25/1997 3 University students organized a vigil on Kolaceva street against government on 1/25/1997. e19(Tutsi,Luvengi,Burundi,Uvira,fuel,Banyamulenge, Burundian,Kivu,Kiliba,Runingo,Kagunga,Bwegera) 10/19/1996 6 Fresh fighting erupted around Uvira between Zaire armed forces and Banyamulengs Tutsi rebels on 10/19/1996. e20(Malantacchi,Korea,Guy,Rider,Unions,labour, Trade,unions,Confederation,rammed,Geneva,stoppages, Virgin,hire,Myongdong,Metalworkers) 1/11/1997 2 Marcello Malantacchi secretary general of the International Metalworkers Federation and Guy Rider who heads the Geneva office of the International Confederation of Free Trade Unions attacked the new labour law of South Korea on 1/11/1997. e21(DBS,Raﬄes) 8/17/1997 9 The list of the unit of Singapore DBS Land Raﬄes Holdings plans on 8/17/1997. e22(preserver,fuel,Galawa,Huddle,Leul,Beausse) 11/24/1996 3 Rescued a woman and her baby during a hijacked Ethiopian plane that ran out of fuel and crashed into the sea near Le Galawa beach on 11/24/1996. e23(PRICE,LISTING,MLN,MATURITY,COUPON, MOODY,AMT,FIRST,ISS,TYPE,PAY,BORROWER) Monday-Friday/week 7966 Announce bond price on all weekdays. e24(Unaudited,Ended,Months,Weighted,Provision,Cost, Selling,Revenues,Loss,Income,except,Shrs,Revs) every season 2264 Net income-loss reports released by companies in every season. e25(rating,Wall,Street,Ian) Monday-Friday/week 21767 Stock reports from Wall Street on all weekdays. e26(Sheffield,league,scoring,goals,striker,games) every Friday, Saturday and Sunday 574 Match results of Sheffield soccer league were published on Friday, Saturday and Sunday 10 times than other 4 days. e27(soccer,matches,Results,season,game,Cup,match, victory,beat,played,play,division) every Friday, Saturday and Sunday 2396 Soccer games held on Friday, Saturday and Sunday 7 times than other 4 days.",
    "original_translation": "Analizando Trayectorias de Características para la Detección de Eventos Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg Escuela de Ingeniería Informática Universidad Tecnológica de Nanyang Bloque N4, Avenida Nanyang, Singapur 639798 RESUMEN Consideramos el problema de analizar trayectorias de palabras en los dominios del tiempo y la frecuencia, con el objetivo específico de identificar palabras importantes y menos reportadas, periódicas y aperiódicas. Un conjunto de palabras con tendencias idénticas puede agruparse para reconstruir un evento de manera completamente no supervisada. La frecuencia del documento de cada palabra a lo largo del tiempo se trata como una serie temporal, donde cada elemento es el puntaje de frecuencia del documento - frecuencia inversa del documento (DFIDF) en un punto temporal. En este artículo, 1) primero aplicamos análisis espectral para categorizar características de diferentes tipos de eventos: importantes y poco reportados, periódicos y aperiódicos; 2) modelamos las características aperiódicas con densidad gaussiana y las características periódicas con densidades de mezcla gaussiana, y posteriormente detectamos cada ráfaga de características mediante el enfoque gaussiano truncado; 3) propusimos un algoritmo de detección de eventos codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos. Todos los métodos anteriores se pueden aplicar a datos de series temporales en general. Evaluamos exhaustivamente nuestros métodos en el Corpus de Noticias de Reuters de 1 año [3] y demostramos que fueron capaces de descubrir eventos significativos aperiódicos y periódicos. Categorías y Descriptores de Asignaturas: H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales: Algoritmos, Experimentación. 1. INTRODUCCIÓN Hay más de 4,000 fuentes de noticias en línea en el mundo. Supervisar manualmente todos ellos en busca de eventos importantes se ha vuelto difícil o prácticamente imposible. De hecho, la comunidad de detección y seguimiento de temas (TDT) ha estado tratando durante muchos años de encontrar una solución práctica para ayudar a las personas a monitorear las noticias de manera efectiva. Desafortunadamente, el Santo Grial sigue siendo esquivo, ya que la gran mayoría de las soluciones de TDT propuestas para la detección de eventos [20, 5, 17, 4, 21, 7, 14, 10] son demasiado simplistas (basadas en la similitud del coseno [5]) o impracticables debido a la necesidad de ajustar un gran número de parámetros [9]. La ineficacia de las tecnologías actuales de TDT se puede ilustrar fácilmente suscribiéndose a cualquiera de los muchos servicios de alertas de noticias en línea, como el líder de la industria Google News Alerts, que genera más del 50% de falsas alarmas. Como prueba adicional, portales como Yahoo adoptan un enfoque más pragmático al requerir que todas las alertas de noticias generadas por máquinas pasen por un operador humano para su confirmación antes de enviarlas a los suscriptores. En lugar de abordar el problema con variaciones del mismo martillo (similitud coseno y TFIDF), es necesario contar con una comprensión fundamental de las características de los datos de flujo de noticias antes de que se puedan lograr avances importantes en TDT. Por lo tanto, en este artículo, examinamos noticias y tendencias de características desde la perspectiva de analizar una señal de palabras de series temporales. Trabajos anteriores como [9] han intentado reconstruir un evento con sus características representativas. Sin embargo, en muchas tareas de detección de eventos predictivos (es decir, detección de eventos retrospectivos), hay un vasto conjunto de características potenciales solo para un conjunto fijo de observaciones (es decir, los estallidos obvios). De estas características, a menudo solo se espera que un pequeño número sea útil. En particular, estudiamos el novedoso problema de analizar trayectorias de características para la detección de eventos, utilizando una técnica conocida de procesamiento de señales: identificar correlaciones distribucionales entre todas las características mediante análisis espectral. Para evaluar nuestro método, posteriormente proponemos un algoritmo de detección de eventos no supervisado para flujos de noticias. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Pascua Abril (a) evento aperiódico 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 No auditado Finalizado (b) evento periódico Figura 1: Correlación de características (DFIDF:tiempo) entre a) Pascua y Abril b) No auditado y Finalizado. Como ejemplo ilustrativo, considera la correlación entre las palabras Pascua y abril del Corpus de Reuters. A partir del gráfico de su DFIDF normalizado en la Figura 1(a), observamos la gran superposición entre las dos palabras alrededor de 04/1997, lo que significa que probablemente ambas pertenecen al mismo evento durante ese tiempo (festividad de Pascua). En este ejemplo, el evento oculto de la festividad de Pascua es un evento aperiódico típico e importante en datos de 1 año. Otro ejemplo se muestra en la Figura 1(b), donde las palabras \"No auditado\" y \"Finalizado 1\" del Corpus de Reuters son el conjunto de datos predeterminado para todos los ejemplos y presentan un comportamiento similar durante períodos de 3 meses. Estas dos palabras en realidad se originaron a partir del mismo evento periódico, informes de ganancias y pérdidas, que son publicados trimestralmente por empresas cotizadas en bolsa. Otras observaciones extraídas de la Figura 1 son: 1) el período de actividad intensa de abril es mucho más largo que el de Semana Santa, lo que sugiere que abril puede estar presente en otros eventos durante el mismo período; 2) No auditado tiene un valor promedio de DFIDF más alto que Finalizado, lo que indica que No auditado es más representativo para el evento subyacente. Estos dos ejemplos son solo la punta del iceberg entre todas las tendencias de palabras y correlaciones ocultas en un flujo de noticias como Reuters. Si se puede descubrir un gran número de ellos, podría ayudar significativamente en las tareas de TDT. En particular, indica la importancia de extraer características correlacionadas para detectar eventos correspondientes. Para resumir, postulamos que: 1) Un evento se describe por sus características representativas. Un evento periódico tiene una lista de características periódicas y un evento aperiódico tiene una lista de características aperiódicas; 2) Las características representativas del mismo evento comparten distribuciones similares en el tiempo y están altamente correlacionadas; 3) Un evento importante tiene un conjunto de características representativas activas (ampliamente reportadas), mientras que un evento no importante tiene un conjunto de características representativas inactivas (menos reportadas); 4) Una característica puede ser incluida por varios eventos con superposiciones en los marcos de tiempo. Basándonos en estas observaciones, podemos extraer características representativas dadas un evento o detectar un evento a partir de una lista de características altamente correlacionadas. En este artículo, nos enfocamos en este último aspecto, es decir, cómo se pueden descubrir características correlacionadas para formar un evento de manera no supervisada. 1.1 Contribuciones Este artículo tiene tres contribuciones principales: • Hasta donde sabemos, nuestro enfoque es el primero en categorizar características de palabras para eventos heterogéneos. Específicamente, cada característica de palabra se clasifica en uno de los siguientes cinco tipos de características basados en la fuerza de su espectro de potencia y periodicidad: 1) HH (alta potencia y alta/larga periodicidad): eventos aperiódicos importantes, 2) HL (alta potencia y baja periodicidad): eventos periódicos importantes, 3) LH (baja potencia y alta periodicidad): eventos aperiódicos no importantes, 4) LL (baja potencia y baja periodicidad): no eventos, y 5) SW (palabras vacías), un subconjunto de LL con mayor potencia y periodicidad que comprende palabras vacías, que no contienen información. • Proponemos un enfoque simple y efectivo basado en densidad de mezcla para modelar y detectar ráfagas de características. • Presentamos un algoritmo de detección de eventos no supervisado para detectar eventos tanto aperiódicos como periódicos. Nuestro algoritmo ha sido evaluado en un flujo de noticias reales para demostrar su efectividad. 2. TRABAJO RELACIONADO Este trabajo está motivado en gran medida por una familia más amplia de problemas conocidos colectivamente como Detección y Seguimiento de Temas (TDT) [20, 5, 17, 4, 21, 7, 14, 10]. Además, la mayoría de las investigaciones de TDT hasta ahora se han centrado en agrupar/clasificar documentos en tipos de temas, identificar oraciones novedosas para eventos nuevos, etc., sin prestar mucha atención al análisis de la trayectoria de las palabras con respecto al tiempo. Swan y Allan [18] intentaron por primera vez usar términos que co-ocurren para construir un evento. Sin embargo, solo consideraron entidades nombradas y pares de frases nominales, sin tener en cuenta sus periodicidades. Por el contrario, nuestro artículo considera todo lo anterior. Recientemente, ha habido un gran interés en modelar un evento en flujos de texto como un estallido de actividades al incorporar información temporal. El trabajo seminal de Kleinberg describió cómo se pueden extraer características explosivas de flujos de texto utilizando un modelo de autómata infinito [12], lo que inspiró toda una serie de aplicaciones como la identificación de comunidades explosivas de Kumar a partir de gráficos de blogs [13], la sumarización de temas evolutivos en flujos de texto de Meis [15], el agrupamiento de flujos de texto utilizando características explosivas de Hes [11], etc. Sin embargo, ninguno de los trabajos existentes identificó específicamente características para eventos, excepto Fung et al. [9], quienes agruparon características llamativas para identificar varios eventos llamativos. Nuestro trabajo difiere de [9] en varias formas: 1) analizamos cada característica individual, no solo las características explosivas; 2) clasificamos las características a lo largo de dos dimensiones categóricas (periodicidad y potencia), dando en total cinco tipos de características principales; 3) no restringimos que cada característica pertenezca exclusivamente a un solo evento. Las técnicas de análisis espectral han sido utilizadas previamente por Vlachos et al. [19] para identificar periodicidades y ráfagas en los registros de consultas. Su enfoque estaba en detectar múltiples periodicidades a partir del gráfico del espectro de potencia, las cuales luego se utilizaron para indexar palabras para la búsqueda por ráfagas. En este artículo, utilizamos análisis espectral para clasificar las características de las palabras a lo largo de dos dimensiones, a saber, periodicidad y espectro de potencia, con el objetivo final de identificar eventos tanto periódicos como no periódicos y explosivos. 3. REPRESENTACIÓN DE DATOS Sea T la duración/período (en días) de un flujo de noticias, y F representa el espacio de características de palabras completo en el Modelo de Espacio Vectorial (VSM) estático clásico. 3.1 Clasificación de Periodicidad de Eventos Dentro de T, pueden existir ciertos eventos que ocurren solo una vez, por ejemplo, la elección de Tony Blair como Primer Ministro del Reino Unido, y otros eventos recurrentes de diversas periodicidades, por ejemplo, partidos de fútbol semanales. Por lo tanto, categorizamos todos los eventos en dos tipos: aperiódicos y periódicos, definidos de la siguiente manera. Definición 1. (Evento aperiódico) Un evento es aperiódico dentro de T si solo ocurre una vez. Definición 2. (Evento periódico) Si los eventos de un cierto género de eventos ocurren regularmente con una periodicidad fija P ≤ T/2, decimos que este género particular de eventos es periódico, y cada evento miembro se califica como un evento periódico. Ten en cuenta que la definición de aperiódico es relativa, es decir, es verdadera solo para un T dado y puede ser inválida para cualquier otro T > T. Por ejemplo, el evento de la fiesta de Navidad es aperiódico para T ≤ 365 pero periódico para T ≥ 730. 3.2 Características Representativas Intuitivamente, un evento puede ser descrito de manera muy concisa por unas pocas características de palabras discriminativas y representativas y viceversa, por ejemplo, huracán, barrido y golpe podrían ser características representativas de un evento del género de huracanes. Asimismo, un conjunto de características fuertemente correlacionadas podría ser utilizado para reconstruir una descripción de un evento, asumiendo que las características fuertemente correlacionadas son representativas. El vector de representación de una característica de palabra se define de la siguiente manera: Definición 3. (Trayectoria de la Característica) La trayectoria de una característica de palabra f puede escribirse como la secuencia yf = [yf (1), yf (2), . . . , yf (T)], donde cada elemento yf (t) es una medida de la característica f en el tiempo t, que podría definirse utilizando la puntuación normalizada DFIDF yf (t) = DFf (t) N(t) × log( N DFf ), donde DFf (t) es el número de documentos (DF local) que contienen la característica f en el día t, DFf es el número total de documentos (DF global) que contienen la característica f en T, N(t) es el número de documentos para el día t, y N es el número total de documentos en T. 4. En esta sección, mostramos cómo se pueden extraer características representativas para eventos (poco) importantes o (a)periódicos. 4.1 Análisis Espectral para el Período Dominante Dada una característica f, descomponemos su trayectoria de características yf = [yf (1), yf (2), ..., yf (T)] en la secuencia de T números complejos [X1, . . . , XT ] a través de la transformada discreta de Fourier (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. La DFT puede representar la serie temporal original como una combinación lineal de sinusoides complejas, lo cual se ilustra mediante la transformada discreta de Fourier inversa (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, donde el coeficiente de Fourier Xk denota la amplitud del sinusoides con frecuencia k/T. La trayectoria original puede ser reconstruida con solo las frecuencias dominantes, las cuales pueden ser determinadas a partir del espectro de potencia utilizando el popular estimador periodograma. El periodograma es una secuencia de la magnitud al cuadrado de los coeficientes de Fourier, Xk^2, k = 1, 2, . . . , T/2, que indica la potencia de la señal en la frecuencia k/T en el espectro. A partir del espectro de potencia, se elige el período dominante como el inverso de la frecuencia con el espectro de potencia más alto, de la siguiente manera. Definición 4. (Período Dominante) El período dominante (DP) de una característica dada f es Pf = T/ arg max k Xk 2. Por lo tanto, tenemos la Definición 5. (Espectro de Potencia Dominante) El espectro de potencia dominante (DPS) de una característica dada f es Sf = Xk 2 , con Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorización de Características El DPS de una trayectoria de características es un indicador fuerte de su actividad en la frecuencia especificada; cuanto mayor sea el DPS, es más probable que la característica sea explosiva. Al combinar DPS con DP, categorizamos todas las características en cuatro tipos: 2 Normalizamos yf (t) como yf (t) = yf (t)/ T i=1 yf (i) para que pueda interpretarse como una probabilidad. • HH: alta Sf, aperiódico o periódico a largo plazo (Pf > T/2); • HL: alta Sf, periódico a corto plazo (Pf ≤ T/2); • LH: baja Sf, aperiódico o periódico a largo plazo; • LL: baja Sf, periódico a corto plazo. La frontera entre los periodos a largo plazo y a corto plazo se establece en T/2. Sin embargo, distinguir entre un DPS alto y bajo no es sencillo, lo cual se abordará más adelante. Propiedades de diferentes conjuntos de características Para comprender mejor las propiedades de HH, HL, LH y LL, seleccionamos cuatro características, Navidad, fútbol, DBS y tu como ejemplos ilustrativos. Dado que la frontera entre el espectro de alta y baja potencia no está clara, estos ejemplos seleccionados tienen un rango relativo amplio de valores de espectro de potencia. La figura 2(a) muestra la trayectoria de DFIDF para la Navidad con un pico distintivo alrededor del día de Navidad. Para el conjunto de datos de Reuters de 1 año, la Navidad se clasifica como un evento aperiódico típico con Pf = 365 y Sf = 135.68, como se muestra en la Figura 2(b). Claramente, el valor de Sf = 135.68 es razonable para un evento conocido por ser intermitente como la Navidad. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Navidad(DFIDF:tiempo) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Navidad(S:frecuencia) Figura 2: Característica Navidad con un Sf relativamente alto y un Pf a largo plazo. La trayectoria de DFIDF para el fútbol se muestra en la Figura 3(a), de la cual podemos observar que hay un estallido regular cada 7 días, lo cual es nuevamente verificado por su valor calculado de Pf = 7, como se muestra en la Figura 3(b). Usando el conocimiento del dominio de que los partidos de fútbol tienen más encuentros cada sábado, lo que lo convierte en un evento periódico típico y ampliamente reportado, consideramos que el valor de Sf = 155.13 es alto. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) fútbol (DFIDF:tiempo) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) fútbol (S:frecuencia) Figura 3: Característica fútbol con un Sf relativamente alto y un Pf a corto plazo. A partir de la trayectoria de DFIDF para DBS en la Figura 4(a), podemos deducir de inmediato que DBS es una palabra poco frecuente con un aumento trivial el 17/08/1997 correspondiente a los planes de DBS Land Raﬄes Holdings. Esto se confirma por el largo período de Pf = 365 y la baja potencia de Sf = 0.3084 como se muestra en la Figura 4(b). Además, dado que este evento aperiódico solo se informa en algunas noticias durante un corto período de unos pocos días, por lo tanto, decimos que su bajo valor de potencia de Sf = 0.3084 es representativo de eventos poco importantes. El ejemplo más confuso se muestra en la Figura 5 para la palabra \"your\", que se ve muy similar al gráfico para fútbol en la Figura 3. A primera vista, podríamos sentirnos tentados a agrupar tanto tu como el fútbol en la misma categoría de HL o LL, ya que ambas distribuciones se ven similares y tienen el mismo período dominante de aproximadamente una semana. Sin embargo, más adelante 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:tiempo) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frecuencia) Figura 4: Característica DBS con Sf relativamente bajo y Pf a largo plazo. El análisis indica que la periodicidad de su es debido a las diferencias en el recuento de documentos para los días de la semana (promedio de 2,919 por día) y los fines de semana (promedio de 479 por día). Uno habría esperado que la periodicidad de una palabra vacía como \"tu\" fuera de un día. Además, a pesar de nuestra normalización de DFIDF, el desequilibrio entre los días de la semana y los fines de semana aún prevalecía; las palabras vacías ocurren 4 veces más frecuentemente los fines de semana que los días de semana. Por lo tanto, el DPS sigue siendo el único factor distintivo entre tu (Sf = 9.42) y el fútbol (Sf = 155.13). Sin embargo, es muy peligroso concluir simplemente que un valor de potencia de S = 9.42 corresponde a una característica de palabra vacía. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) tu(DFIDF:tiempo) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) tu(S:frecuencia) Figura 5: Característica tu como un ejemplo confundido con la característica fútbol. Antes de presentar nuestra solución a este problema, veamos otro ejemplo de LL como se muestra en la Figura 6 para beenb, que en realidad es un error tipográfico confirmado. Por lo tanto, clasificamos beenb como una característica ruidosa que no contribuye a ningún evento. Claramente, la trayectoria de tu es muy diferente de beenb, lo que significa que el primero debe considerarse por separado. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figura 6: Característica beenb con Sf relativamente bajo y Pf a corto plazo. Conjunto de características de palabras vacías (SW) Basándonos en el análisis anterior, nos damos cuenta de que debe haber otro conjunto de características entre HL y LL que corresponda al conjunto de palabras vacías. Las características de este conjunto tienen un DPS moderado y un período dominante bajo pero conocido. Dado que es difícil distinguir este conjunto de características de HL y LL solo basándose en DPS, introducimos otro factor llamado promedio de DFIDF (DFIDF). Como se muestra en la Figura 5, características como la tuya suelen tener un DPS más bajo que una característica HL como el fútbol, pero tienen un DFIDF mucho más alto que otra característica ruidosa LL como \"beenb\". Dado que tales propiedades suelen ser características de las palabras vacías, agrupamos características como \"tu\" en el conjunto de características de palabras vacías (SW) recién definido. Dado que establecer los umbrales de DPS y DFIDF para identificar las palabras vacías es más un arte que una ciencia, propusimos un algoritmo heurístico HS, Algoritmo 1. La idea básica es utilizar solo noticias de días laborables para identificar palabras vacías. Los fines de semana aquí también incluyen días festivos que caen en días laborables. El conjunto SW se inicialmente alimenta con un pequeño conjunto de 29 stopwords populares utilizadas por el motor de búsqueda de Google. Algoritmo 1 Detección heurística de palabras vacías (HS) Entrada: Conjunto de palabras vacías semilla, trayectorias semanales de todas las palabras 1: A partir del conjunto semilla SW, calcular el DPS máximo como UDPS, el DFIDF máximo como UDFIDF y el mínimo de DFIDF como LDFIDF. 2: para fi ∈ F hacer 3: Calcular DFT para fi. 4: si Sfi ≤ UDPS y DFIDFfi ∈ [LDFIDF, UDFIDF] entonces 5: fi → SW 6: F = F - fi 7: fin si 8: fin para Resumen de la Categorización de Características Después de generar el conjunto SW, se eliminan todas las palabras vacías de F. Luego, establecemos el límite entre DPS alto y bajo como el límite superior de los DPS de los conjuntos SW. Una visión general de los cinco conjuntos de características se muestra en la Figura 7. Figura 7: Los 5 conjuntos de características para eventos. 5. IDENTIFICACIÓN DE RÁFAGAS PARA CARACTERÍSTICAS Dado que solo las características de HH, HL y LH son significativas y podrían ser representativas de algunos eventos, eliminamos todas las demás características clasificadas como LL o SW. En esta sección, describimos cómo se pueden identificar los estallidos a partir de las características restantes. A diferencia del algoritmo de identificación de ráfagas de Kleinberg [12], podemos identificar tanto ráfagas significativas como triviales sin necesidad de establecer ningún parámetro. 5.1 Detección de ráfagas de características aperiódicas Para cada característica en HH y HL, truncamos su trayectoria manteniendo solo el período de ráfagas, el cual está modelado con una distribución gaussiana. Por ejemplo, la Figura 8 muestra la característica de la palabra Iraq con una explosión alrededor del 09/06/1996 modelada como una Gaussiana. Su período de ráfagas está definido por [μf − σf , μf + σf ] como se muestra en la Figura 8(b). 5.2 Detección de características periódicas de ráfagas Dado que hemos calculado el DP para una característica periódica f, podemos modelar fácilmente su trayectoria de características periódicas yf usando 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) DFIDF original: tiempo 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 ráfaga= [μ-σ, μ+σ] (b) identificación de ráfaga Figura 8: Modelando la serie temporal de Iraq como una Gaussiana truncada con μ = 09/06/1996 y σ = 6.26. una mezcla de K = T/Pf Gaussianas: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , donde el conjunto de parámetros θf = {αk, μk, σk}K k=1 comprende: • αk es la probabilidad de asignar yf a la k-ésima Gaussiana. αk > 0, ∀k ∈ [1, K] y K k=1 αk = 1; • μk/σk es la media/desviación estándar de la k-ésima Gaussiana. El conocido algoritmo Expectation Maximization (EM) [8] se utiliza para calcular las proporciones de mezcla αk, así como los parámetros individuales de densidad gaussiana μk y σK. Cada Gaussiana representa un evento periódico, y se modela de manera similar como se menciona en la Sección 5.1. 6. EVENTOS A PARTIR DE CARACTERÍSTICAS Después de identificar y modelar ráfagas para todas las características, la siguiente tarea es pintar un cuadro del evento con un posible conjunto de características representativas. 6.1 Correlación de Características Si dos características fi y fj son representativas del mismo evento, deben cumplir las siguientes condiciones necesarias: 1. fi y fj están distribuidas de manera idéntica: yfi ∼ yfj. 2. fi y fj tienen una alta superposición de documentos. Medición de la similitud de la distribución de características. Medimos la similitud entre dos características fi y fj utilizando la divergencia KL discreta definida de la siguiente manera. Definición 6. (similitud de características) KL(fi, fj) se da por max(KL(fi|fj), KL(fj|fi)), donde KL(fi|fj) = T t=1 f(yfi(t)|θfi)log f(yfi(t)|θfi) f(yfj(t)|θfj). (1) Dado que la divergencia KL no es simétrica, definimos la similitud entre fi y fj como el máximo entre KL(fi|fj) y KL(fj|fi). Además, la similitud entre dos características aperiódicas puede calcularse utilizando una forma cerrada de la divergencia de Kullback-Leibler [16]. La misma fórmula discreta de divergencia KL de la Ecuación 1 se emplea para calcular la similitud entre dos características periódicas. A continuación, definimos la similitud general entre un conjunto de características R utilizando el valor máximo de divergencia KL entre características como sigue. Definición 7. (similitud de conjuntos) KL(R) = max ∀fi, fj ∈R KL(fi, fj). Superposición de documentos: Sea Mi el conjunto de todos los documentos que contienen la característica fi. Dadas dos características fi y fj, el conjunto de documentos superpuestos que contienen ambas características es Mi ∩ Mj. De manera intuitiva, cuanto mayor sea |Mi ∩ Mj|, es más probable que fi y fj estén altamente correlacionados. Definimos el grado de superposición de documentos entre dos características fi y fj de la siguiente manera. Definición 8. (Superposición de características DF) d(fi, fj) = |Mi∩Mj| min(|Mi|, |Mj|). En consecuencia, la superposición de DF entre un conjunto de características R también está definida. Definición 9. (Superposición de Conjuntos DF) d(R) = min ∀fi, fj ∈R d(fi, fj). 6.2 Detección de Eventos Codiciosa No Supervisada Utilizamos características de HH para detectar eventos aperiódicos importantes, características de LH para detectar eventos aperiódicos menos reportados/poco importantes, y características de HL para detectar eventos periódicos. Todos comparten el mismo algoritmo. Dado el rasgo explosivo fi ∈ HH, el objetivo es encontrar rasgos altamente correlacionados de HH. El conjunto de características similares a fi puede describir colectivamente un evento. Específicamente, necesitamos encontrar un subconjunto Ri de HH que minimice la siguiente función de costo: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) El evento subyacente e (asociado con la explosión de fi) puede ser representado por Ri como y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) El análisis de la explosión para el evento e es exactamente el mismo que la trayectoria de características. El costo en la Ecuación 2 se puede minimizar utilizando nuestro algoritmo de detección de eventos UG codicioso no supervisado, que se describe en el Algoritmo 2. El algoritmo UG permite una característica Algoritmo 2 Detección de eventos codiciosos no supervisados (UG). Salida: ek como Ec. 3. Además, los eventos triviales que solo contienen características de año/mes (es decir, un evento que solo contiene una característica de agosto podría ser identificado en un flujo de noticias de 1 año) podrían ser eliminados, aunque dichos eventos tendrán un costo inherente alto y deberían estar clasificados muy bajos. Tenga en cuenta que nuestro algoritmo UG solo requiere un parámetro dependiente de los datos, el límite entre el espectro de alta y baja potencia, que debe establecerse una vez, y este parámetro puede estimarse fácilmente utilizando el algoritmo HS (Algoritmo 1). 7. EXPERIMENTOS En esta sección, estudiamos el rendimiento de nuestro método de categorización de características y algoritmo de detección de eventos. Primero presentamos el conjunto de datos y la configuración experimental, luego evaluamos subjetivamente la categorización de características para HH, HL, LH, LL y SW. Finalmente, estudiamos el problema de detección de eventos (a)periódicos con el Algoritmo 2. 7.1. Conjunto de datos y configuración experimental El Corpus de Reuters contiene 806,791 noticias en inglés desde el 20/08/1996 hasta el 19/08/1997 con una resolución diaria. La versión 2 del software de código abierto Lucene [1] se utilizó para tokenizar el contenido de texto de noticias y generar el vector documento-palabra. Con el fin de preservar los tiempos verbales pasados/presentes/futuros sensibles al tiempo y las diferencias entre los sustantivos en minúscula y las entidades nombradas en mayúscula, no se realizó ningún truncamiento. Dado que la eliminación dinámica de palabras vacías es una de las funcionalidades de nuestro método, no se eliminó ninguna palabra vacía. Eliminamos los caracteres no ingleses, sin embargo, después de eso, el número de características de palabras asciende a 423,433. Todos los experimentos se implementaron en Java y se llevaron a cabo en una PC Pentium 4 de 3.2 GHz con Windows 2003 Server y 1 GB de memoria. 7.2 Categorización de características Descargamos 34 stopwords bien conocidos utilizados por el motor de búsqueda de Google como nuestras características de entrenamiento iniciales, que incluyen a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en y www. Excluimos las últimas cinco palabras vacías ya que son poco comunes en noticias. Al analizar solo historias de noticias durante 259 días laborables, calculamos el límite superior del espectro de potencia para las palabras vacías en 11.18 y los rangos correspondientes de DFIDF van desde 0.1182 hasta 0.3691. Cualquier característica f que cumpla con Sf <= 11.18 y 0.1182 <= DFIDFf <= 0.3691 durante los días de la semana se considerará una palabra vacía. De esta manera, se encontraron y eliminaron 470 palabras vacías como se muestra en la Figura 9. Algunas palabras vacías detectadas son A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) y much (P = 22, S = 0.80, DFIDF = 0.1865). Después de la eliminación de estas palabras vacías, la distribución de las noticias entre semana y los fines de semana están más o menos equilibradas, y en los experimentos subsiguientes, haremos uso del corpus completo (entre semana y fines de semana). El valor del espectro de potencia límite superior de 11.18 para el entrenamiento de palabras vacías fue seleccionado como el límite entre el espectro de alta potencia y baja potencia. El límite entre alta y baja periodicidad se estableció en 365/2 = 183. Todos los 422,963 (423433 − 470) rasgos de palabras fueron categorizados en 4 conjuntos de rasgos: HH (69 rasgos), HL (1,087 rasgos), LH (83,471 rasgos) y LL (338,806 rasgos) como se muestra en la Figura 10. En la Figura 10, cada nivel de gris denota la densidad relativa de características en una región cuadrada, medida por log10(1 + Dk), donde Dk es el número de características dentro de la k-ésima región cuadrada. A partir de la figura, podemos hacer el 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figura 9: Distribución de SW (palabras vacías) en las regiones HH, HL, LH y LL. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figura 10: Distribución de características categorizadas en los cuatro cuadrantes (sombreado en escala logarítmica). siguientes observaciones: 1. La mayoría de las características tienen un valor bajo de S y son fácilmente distinguibles de aquellas características que tienen un valor mucho más alto de S, lo que nos permite detectar eventos importantes (a)periódicos de eventos triviales seleccionando características con un alto valor de S. 2. Las características en los cuadrantes HH y LH son aperiódicas, las cuales están bien separadas (gran brecha horizontal) de las características periódicas. Esto permite detectar de manera confiable eventos aperiódicos y eventos periódicos de forma independiente. 3. La frontera (vertical) entre el espectro de alta y baja potencia no es tan clara y el valor exacto dependerá de la aplicación específica. Al revisar la distribución de dispersión de las características de SW en HH, HL, LH y LL como se muestra en la Figura 9, encontramos que el 87.02% (409/470) de las stopwords detectadas se originaron en LL. La clasificación LL y las altas puntuaciones de DFIDF de las palabras vacías concuerdan con la noción generalmente aceptada de que las palabras vacías son igualmente frecuentes en todo momento. Por lo tanto, establecer el límite entre el espectro de alta y baja potencia utilizando el límite superior Sf de SW es una heurística razonable. 7.3 Detección de Eventos Aperiódicos Evaluaremos nuestras dos hipótesis, 1)los eventos aperiódicos importantes pueden ser definidos por un conjunto de características HH, y 2)los eventos aperiódicos menos reportados pueden ser definidos por un conjunto de características LH. Dado que no existen flujos de noticias de referencia para la detección de eventos (los conjuntos de datos de TDT no son flujos adecuados), evaluamos la calidad de los eventos detectados automáticamente comparándolos con eventos confirmados manualmente mediante la búsqueda en el corpus. Entre las 69 características de HH, detectamos 17 eventos aperiódicos importantes como se muestra en la Tabla 1 (e1 - e17). Ten en cuenta que toda la identificación tomó menos de 1 segundo, después de eliminar los eventos que solo contenían la característica del mes. De los 17 eventos, aparte de las superposiciones entre e3 y e4 (ambos describen el mismo evento de rehenes), e11 y e16 (ambos sobre informes de empresas), los 14 eventos identificados son extremadamente precisos y corresponden muy bien a los principales eventos del período. Por ejemplo, la derrota de Bob Dole, la elección de Tony Blair, el ataque con misiles a Iraq, etc. Recuerde que seleccionar las características para un evento debería minimizar el costo en la Ecuación 2 de tal manera que 1) el número de características abarque diferentes eventos, y 2) no se seleccionarán todas las características relevantes para un evento, por ejemplo, la característica Clinton es representativa para e12, pero dado que Clinton se relaciona con muchos otros eventos, su señal de dominio temporal es muy diferente de la de otras características representativas como Dole y Bob. El número de documentos de un evento detectado se estima aproximadamente por el número de documentos indexados que contienen las características representativas. Podemos ver que los 17 eventos aperiódicos importantes son eventos reportados popularmente. Después de 742 minutos de tiempo de computación, detectamos 23,525 eventos aperiódicos menos reportados de 83,471 características de LH. La Tabla 1 enumera los 5 principales eventos aperiódicos detectados (e18 - e22) con respecto al costo. Descubrimos que estos 5 eventos son en realidad eventos muy triviales con solo unos pocos informes de noticias, y suelen ser englobados por algunos temas más grandes. Por ejemplo, e22 es uno de los eventos de rescate en un tema de secuestro de avión. Una ventaja de nuestro Algoritmo UG para descubrir eventos aperiódicos poco reportados es que podemos detectar con precisión el verdadero período del evento. 7.4 Detección de Eventos Periódicos Entre las 1,087 características de HL, se detectaron 330 eventos periódicos importantes en un tiempo de cálculo de 10 minutos. La Tabla 1 enumera los 5 eventos periódicos detectados con respecto al costo (e23 - e27). Todos los eventos periódicos detectados son realmente válidos y corresponden a eventos periódicos de la vida real. El modelo GMM es capaz de detectar y estimar el período de ráfagas de manera precisa, aunque no puede distinguir la ligera diferencia entre cada lunes a viernes y todos los días de la semana, como se muestra en e23. También observamos que e26 es en realidad un subconjunto de e27 (partido de fútbol), lo cual es aceptable ya que los resultados de la liga de Sheffield se anuncian de forma independiente cada fin de semana. 8. CONCLUSIONES Este artículo adoptó una perspectiva completamente nueva para analizar las trayectorias de características como señales en el dominio del tiempo. Al considerar las frecuencias de los documentos en el dominio del tiempo y de la frecuencia, pudimos derivar muchas nuevas características sobre los flujos de noticias que antes eran desconocidas, por ejemplo, las diferentes distribuciones de palabras vacías durante los días de la semana y los fines de semana. Por primera vez en el área de TDT, aplicamos un enfoque sistemático para detectar automáticamente eventos importantes y menos reportados, periódicos y aperiódicos. La idea clave de nuestro trabajo radica en las observaciones de que los eventos periódicos tienen características representativas periódicas y los eventos (in)importantes tienen características representativas (in)activas, diferenciadas por sus espectros de potencia y períodos de tiempo. Para abordar el problema de detección de eventos reales, se utilizó un enfoque basado en densidad de mezcla simple y efectivo para identificar ráfagas de características y sus períodos asociados de ráfagas. También diseñamos un algoritmo codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos, el cual tuvo éxito en detectar eventos reales como se muestra en la evaluación en un flujo de noticias reales. Aunque no hemos realizado ninguna comparación de referencia con otro enfoque, simplemente porque no hay trabajos previos en el problema abordado. El trabajo futuro incluye evaluar la recuperación de eventos detectados en un flujo de noticias etiquetado, y comparar nuestro modelo con los métodos equivalentes más cercanos, que actualmente se limitan a los métodos de Kleinberg [12] (que solo pueden detectar ciertos tipos de eventos explosivos dependiendo de la configuración de parámetros), Fung et al. [9], y Swan y Allan [18]. Sin embargo, creemos que nuestro método simple y efectivo será útil para todos los practicantes de TDT, y será especialmente útil para el análisis exploratorio inicial de flujos de noticias. REFERENCIAS [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Alertas de noticias de Google, http://www.google.com/alerts. [3] Corpus de Reuters, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan. Detección y seguimiento de temas. Organización de la información basada en eventos. Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, y H. Jin. La detección de la primera historia en tdt es difícil. En CIKM, páginas 374-381, 2000. [6] J. Allan, C. Wade y A. Bolivar. Recuperación y detección de novedades a nivel de oración. En SIGIR, páginas 314-321, 2003. [7] T. Brants, F. Chen y A. Farahat. Un sistema para la detección de nuevos eventos. En SIGIR, páginas 330-337, 2003. [8] A. P. Dempster, N. M. Laird y D. B. Rubin. Máxima verosimilitud a partir de datos incompletos a través del algoritmo EM. Revista de la Real Sociedad Estadística, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu y H. Lu. Detección de eventos explosivos sin parámetros en flujos de texto. En VLDB, páginas 181-192, 2005. [10] Q. Él, K. Chang y E.-P. Lim. Un modelo para la detección anticipada de eventos. En ER, páginas 168-181, 2006. [11] Q. Él, K. Chang, E.-P. Lim y J. Zhang. Representación de características intermitentes para la agrupación de flujos de texto. En SDM, aceptado, 2007. [12] J. Kleinberg. Estructura explosiva y jerárquica en arroyos. En SIGKDD, páginas 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan y A. Tomkins. Sobre la evolución explosiva del blogosfera. En WWW, páginas 159-178, 2005. [14] G. Kumaran y J. Allan. Clasificación de texto y entidades nombradas para la detección de nuevos eventos. En SIGIR, páginas 297-304, 2004. [15] Q. Mei y C. Zhai. Descubriendo patrones temáticos evolutivos a partir de texto: una exploración de la minería de texto temporal. En SIGKDD, páginas 198-207, 2005. [16] W. D. Penny. Divergencias de Kullback-Leibler de densidades normales, gamma, dirichlet y wishart. Informe técnico, 2001. [17] N. Stokes y J. Carthy. Combinando clasificadores de documentos semánticos y sintácticos para mejorar la detección de la primera noticia. En SIGIR, páginas 424-425, 2001. [18] R. Swan y J. Allan. Generación automática de líneas de tiempo de resumen. En SIGIR, páginas 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena y D. Gunopulos. Identificando similitudes, periodicidades y ráfagas en las consultas de búsqueda en línea. En SIGMOD, páginas 131-142, 2004. [20] Y. Yang, T. Pierce y J. Carbonell. Un estudio de detección de eventos retrospectivos y en línea. En SIGIR, páginas 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell y C. Jin. Detección de novedades condicionada por el tema. En SIGKDD, páginas 688-693, 2002. Tabla 1: Todos los eventos aperiódicos importantes (e1 - e17), los 5 eventos aperiódicos menos reportados (e18 - e22) y los 5 eventos periódicos importantes (e23 - e27). Evento detectado y período de actividad intensa Doc # Verdadero evento e1 (Sali, Berisha, Albania, albanés, marzo) 02/02/199705/29/1997 1409 El presidente albanés Sali Berisha perdió en una elección temprana y renunció, 12/1996-07/1997. e2 (Seko, Mobutu, Sese, Kabila) 03/22/1997-06/09/1997 2273 El presidente de Zaire, Mobutu Sese, coordinó la rebelión nativa y fracasó el 16/05/1997. e3 (Marxista, peruano) 11/19/1996-03/05/1997 824 Los rebeldes de Perú (Movimiento Revolucionario Tupac Amaru) lideraron un asedio de rehenes en Lima a principios de 1997. e4 (Movimiento, Tupac, Amaru, Lima, rehén, rehenes) 11/16/1996-03/20/1997 824 Lo mismo que e3. e5 (Kinshasa, Kabila, Laurent, Congo) 03/26/199706/15/1997 1378 Zaire fue renombrado República Democrática del Congo el 16/05/1997. e6 (Jospin, Lionel, junio) 05/10/1997-07/09/1997 605 Tras las elecciones generales tempranas alrededor de 06/1997, Lionel Jospin fue nombrado Primer Ministro el 02/06/1997. e7 (Irak, misil) 08/31/1996-09/13/1996 1262 EE. UU. disparó un misil a Irak el 03/09/1996 y el 04/09/1996. e8 (kurdo, Bagdad, iraquí) 08/29/1996-09/09/1996 1132 Tropas iraquíes lucharon con facciones kurdas alrededor de 09/1996. e9 (mayo, Blair) 03/24/1997-07/04/1997 1049 Tony Blair se convirtió en el Primer Ministro del Reino Unido el 02/05/1997. e10 (slalom, esquí) 12/05/1996-03/21/1997 253 Juego de eslalon de esquí alpino en 01/1997-02/1997. e11 (Interino, meses) 09/24/1996-12/31/1996 3063 Tokio publicó los resultados interinos de la empresa para los últimos meses en 09/1996-12/1996. e12 (Dole, Bob) 09/09/1996-11/24/1996 1599 Bob Dole perdió las elecciones presidenciales de EE. UU. de 1996. e13 (julio, Sen) 06/25/1997-06/25/1997 344 El Primer Ministro de Camboya, Hun Sen, lanzó un sangriento golpe militar en 07/1997. e14 (Hebrón) 10/15/1996-02/14/1997 2098 Hebrón fue dividida en dos sectores a principios de 1997. e15 (abril, Pascua) 02/23/1997-05/04/1997 480 Festividades de Pascua alrededor de 04/1997 (para occidentales y ortodoxos). e16 (Diluido, Grupo) 04/27/1997-07/20/1997 1888 Tokio publicó todos los resultados del grupo 96/97 en 04/199707/1997. e17 (diciembre, Navidad) 11/17/1996-01/26/1997 1326 Festín de Navidad a finales de 12/1997. e18 (Kolaceva, invierno, Juntos, paseos, Zajedno, Slobodan, Belgrado, serbio, Serbia, Draskovic, municipal, Kragujevac) 1/25/1997 3 Estudiantes universitarios organizaron una vigilia en la calle Kolaceva contra el gobierno el 25/01/1997. e19 (Tutsi, Luvengi, Burundi, Uvira, combustible, Banyamulenge, burundés, Kivu, Kiliba, Runingo, Kagunga, Bwegera) 10/19/1996 6 Estallaron nuevos enfrentamientos alrededor de Uvira entre las fuerzas armadas de Zaire y los rebeldes Tutsi de Banyamulenge el 19/10/1996. e20 (Malantacchi, Corea, Guy, Rider, Sindicatos, trabajo, Confederación, embestido, Ginebra, paradas, Virgin, contratar, Myongdong, Metalúrgicos) 1/11/1997 2 Marcello Malantacchi, secretario general de la Federación Internacional de Metalúrgicos, y Guy Rider, quien dirige la oficina de Ginebra de la Confederación Internacional de Sindicatos Libres, atacaron la nueva ley laboral de Corea del Sur el 11/01/1997. e21 (DBS, Raﬄes) 8/17/1997 9 La lista de la unidad de DBS Land Raﬄes Holdings de Singapur planea el 17/08/1997. e22 (conservador, combustible, Galawa, Huddle, Leul, Beausse) 11/24/1996 3 Rescataron a una mujer y a su bebé durante un secuestro de un avión etíope que se quedó sin combustible y se estrelló en el mar cerca de la playa Le Galawa el 24/11/1996. e23 (PRECIO, LISTADO, MLN, VENCIMIENTO, CUPÓN, MOODY, MONTO, PRIMERO, ISS, TIPO, PAGO, PRESTAMISTA) Lunes a viernes/semana 7966 Anuncian el precio de los bonos todos los días de la semana. e24 (No auditado, Terminado, Meses, Ponderado, Provisión, Costo, Venta, Ingresos, Pérdida, Ingreso, excepto, Shrs, Revs) cada temporada 2264 Informes de ingresos netos-pérdidas publicados por empresas en cada temporada. e25 (calificación, Wall Street, Ian) Lunes a viernes/semana 21767 Informes de acciones de Wall Street todos los días de la semana. e26 (Sheffield, liga, goles de puntuación, delantero, juegos) cada viernes, sábado y domingo 574 Resultados de partidos de la liga de fútbol de Sheffield publicados los viernes, sábados y domingos 10 veces más que en los otros 4 días. e27 (fútbol, partidos, Resultados, temporada, juego, Copa, partido, victoria, vencer, jugado, jugar, división) cada viernes, sábado y domingo 2396 Juegos de fútbol celebrados los viernes, sábados y domingos 7 veces más que en los otros 4 días.",
    "original_sentences": [
        "Analyzing Feature Trajectories for Event Detection Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg School of Computer Engineering Nanyang Technological University Block N4, Nanyang Avenue, Singapore 639798 ABSTRACT We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words.",
        "A set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner.",
        "The document frequency of each word across time is treated like a time series, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point.",
        "In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events.",
        "All of the above methods can be applied to time series data in general.",
        "We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events.",
        "Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Experimentation. 1.",
        "INTRODUCTION There are more than 4,000 online news sources in the world.",
        "Manually monitoring all of them for important events has become difficult or practically impossible.",
        "In fact, the topic detection and tracking (TDT) community has for many years been trying to come up with a practical solution to help people monitor news effectively.",
        "Unfortunately, the holy grail is still elusive, because the vast majority of TDT solutions proposed for event detection [20, 5, 17, 4, 21, 7, 14, 10] are either too simplistic (based on cosine similarity [5]) or impractical due to the need to tune a large number of parameters [9].",
        "The ineffectiveness of current TDT technologies can be easily illustrated by subscribing to any of the many online news alerts services such as the industryleading Google News Alerts [2], which generates more than 50% false alarms [10].",
        "As further proof, portals like Yahoo take a more pragmatic approach by requiring all machine generated news alerts to go through a human operator for confirmation before sending them out to subscribers.",
        "Instead of attacking the problem with variations of the same hammer (cosine similarity and TFIDF), a fundamental understanding of the characteristics of news stream data is necessary before any major breakthroughs can be made in TDT.",
        "Thus in this paper, we look at news stories and feature trends from the perspective of analyzing a time-series word signal.",
        "Previous work like [9] has attempted to reconstruct an event with its representative features.",
        "However, in many predictive event detection tasks (i.e., retrospective event detection), there is a vast set of potential features only for a fixed set of observations (i.e., the obvious bursts).",
        "Of these features, often only a small number are expected to be useful.",
        "In particular, we study the novel problem of analyzing feature trajectories for event detection, borrowing a well-known technique from signal processing: identifying distributional correlations among all features by spectral analysis.",
        "To evaluate our method, we subsequently propose an unsupervised event detection algorithm for news streams. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Easter April (a) aperiodic event 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Unaudited Ended (b) periodic event Figure 1: Feature correlation (DFIDF:time) between a) Easter and April b) Unaudited and Ended.",
        "As an illustrative example, consider the correlation between the words Easter and April from the Reuters Corpus1 .",
        "From the plot of their normalized DFIDF in Figure 1(a), we observe the heavy overlap between the two words circa 04/1997, which means they probably both belong to the same event during that time (Easter feast).",
        "In this example, the hidden event Easter feast is a typical important aperiodic event over 1-year data.",
        "Another example is given by Figure 1(b), where both the words Unaudited and Ended 1 Reuters Corpus is the default dataset for all examples. exhibit similar behaviour over periods of 3 months.",
        "These two words actually originated from the same periodic event, net income-loss reports, which are released quarterly by publicly listed companies.",
        "Other observations drawn from Figure 1 are: 1) the bursty period of April is much longer than Easter, which suggests that April may exist in other events during the same period; 2) Unaudited has a higher average DFIDF value than Ended, which indicates Unaudited to be more representative for the underlying event.",
        "These two examples are but the tip of the iceberg among all word trends and correlations hidden in a news stream like Reuters.",
        "If a large number of them can be uncovered, it could significantly aid TDT tasks.",
        "In particular, it indicates the significance of mining correlating features for detecting corresponding events.",
        "To summarize, we postulate that: 1) An event is described by its representative features.",
        "A periodic event has a list of periodic features and an aperiodic event has a list of aperiodic features; 2) Representative features from the same event share similar distributions over time and are highly correlated; 3) An important event has a set of active (largely reported) representative features, whereas an unimportant event has a set of inactive (less-reported) representative features; 4) A feature may be included by several events with overlaps in time frames.",
        "Based on these observations, we can either mine representative features given an event or detect an event from a list of highly correlated features.",
        "In this paper, we focus on the latter, i.e., how correlated features can be uncovered to form an event in an unsupervised manner. 1.1 Contributions This paper has three main contributions: • To the best of our knowledge, our approach is the first to categorize word features for heterogenous events.",
        "Specifically, every word feature is categorized into one of the following five feature types based on its power spectrum strength and periodicity: 1) HH (high power and high/long periodicity): important aperiodic events, 2) HL (high power and low periodicity): important periodic events, 3) LH (low power and high periodicity): unimportant aperiodic events, 4) LL (low power and low periodicity): non-events, and 5) SW (stopwords), a higher power and periodicity subset of LL comprising stopwords, which contains no information. • We propose a simple and effective mixture densitybased approach to model and detect feature bursts. • We come up with an unsupervised event detection algorithm to detect both aperiodic and periodic events.",
        "Our algorithm has been evaluated on a real news stream to show its effectiveness. 2.",
        "RELATED WORK This work is largely motivated by a broader family of problems collectively known as Topic Detection and Tracking (TDT) [20, 5, 17, 4, 21, 7, 14, 10].",
        "Moreover, most TDT research so far has been concerned with clustering/classifying documents into topic types, identifying novel sentences [6] for new events, etc., without much regard to analyzing the word trajectory with respect to time.",
        "Swan and Allan [18] first attempted using co-occuring terms to construct an event.",
        "However, they only considered named entities and noun phrase pairs, without considering their periodicities.",
        "On the contrary, our paper considers all of the above.",
        "Recently, there has been significant interest in modeling an event in text streams as a burst of activities by incorporating temporal information.",
        "Kleinbergs seminal work described how bursty features can be extracted from text streams using an infinite automaton model [12], which inspired a whole series of applications such as Kumars identification of bursty communities from Weblog graphs [13], Meis summarization of evolutionary themes in text streams [15], Hes clustering of text streams using bursty features [11], etc.",
        "Nevertheless, none of the existing work specifically identified features for events, except for Fung et al. [9], who clustered busty features to identify various bursty events.",
        "Our work differs from [9] in several ways: 1) we analyze every single feature, not only bursty features; 2) we classify features along two categorical dimensions (periodicity and power), yielding altogether five primary feature types; 3) we do not restrict each feature to exclusively belong to only one event.",
        "Spectral analysis techniques have previously been used by Vlachos et al. [19] to identify periodicities and bursts from query logs.",
        "Their focus was on detecting multiple periodicities from the power spectrum graph, which were then used to index words for query-by-burst search.",
        "In this paper, we use spectral analysis to classify word features along two dimensions, namely periodicity and power spectrum, with the ultimate goal of identifying both periodic and aperiodic bursty events. 3.",
        "DATA REPRESENTATION Let T be the duration/period (in days) of a news stream, and F represents the complete word feature space in the classical static Vector Space Model (VSM). 3.1 Event Periodicity Classification Within T, there may exist certain events that occur only once, e.g., Tony Blair elected as Prime Minister of U.K., and other recurring events of various periodicities, e.g., weekly soccer matches.",
        "We thus categorize all events into two types: aperiodic and periodic, defined as follows.",
        "Definition 1. (Aperiodic Event) An event is aperiodic within T if it only happens once.",
        "Definition 2. (Periodic Event) If events of a certain event genre occur regularly with a fixed periodicity P ≤ T/2 , we say that this particular event genre is periodic, with each member event qualified as a periodic event.",
        "Note that the definition of aperiodic is relative, i.e., it is true only for a given T, and may be invalid for any other T > T. For example, the event Christmas feast is aperiodic for T ≤ 365 but periodic for T ≥ 730. 3.2 Representative Features Intuitively, an event can be described very concisely by a few discriminative and representative word features and vice-versa, e.g., hurricane, sweep, and strike could be representative features of a Hurricane genre event.",
        "Likewise, a set of strongly correlated features could be used to reconstruct an event description, assuming that strongly correlated features are representative.",
        "The representation vector of a word feature is defined as follows: Definition 3. (Feature Trajectory) The trajectory of a word feature f can be written as the sequence yf = [yf (1), yf (2), . . . , yf (T)], where each element yf (t) is a measure of feature f at time t, which could be defined using the normalized DFIDF score2 yf (t) = DFf (t) N(t) × log( N DFf ), where DFf (t) is the number of documents (local DF) containing feature f at day t, DFf is the total number of documents (global DF) containing feature f over T, N(t) is the number of documents for day t, and N is the total number of documents over T. 4.",
        "IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 Spectral Analysis for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. DFT can represent the original time series as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T.",
        "The original trajectory can be reconstructed with just the dominant frequencies, which can be determined from the power spectrum using the popular periodogram estimator.",
        "The periodogram is a sequence of the squared magnitude of the Fourier coefficients, Xk 2 , k = 1, 2, . . . , T/2 , which indicates the signal power at frequency k/T in the spectrum.",
        "From the power spectrum, the dominant period is chosen as the inverse of the frequency with the highest power spectrum, as follows.",
        "Definition 4. (Dominant Period) The dominant period (DP) of a given feature f is Pf = T/ arg max k Xk 2 .",
        "Accordingly, we have Definition 5. (Dominant Power Spectrum) The dominant power spectrum (DPS) of a given feature f is Sf = Xk 2 , with Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorizing Features The DPS of a feature trajectory is a strong indicator of its activeness at the specified frequency; the higher the DPS, the more likely for the feature to be bursty.",
        "Combining DPS with DP, we therefore categorize all features into four types: 2 We normalize yf (t) as yf (t) = yf (t)/ T i=1 yf (i) so that it could be interpreted as a probability. • HH: high Sf , aperiodic or long-term periodic (Pf > T/2 ); • HL: high Sf , short-term periodic (Pf ≤ T/2 ); • LH: low Sf , aperiodic or long-term periodic; • LL: low Sf , short-term periodic.",
        "The boundary between long-term and short-term periodic is set to T/2 .",
        "However, distinguishing between a high and low DPS is not straightforward, which will be tackled later.",
        "Properties of Different Feature Sets To better understand the properties of HH, HL, LH and LL, we select four features, Christmas, soccer, DBS and your as illustrative examples.",
        "Since the boundary between high and low power spectrum is unclear, these chosen examples have relative wide range of power spectrum values.",
        "Figure 2(a) shows the DFIDF trajectory for Christmas with a distinct burst around Christmas day.",
        "For the 1-year Reuters dataset, Christmas is classified as a typical aperiodic event with Pf = 365 and Sf = 135.68, as shown in Figure 2(b).",
        "Clearly, the value of Sf = 135.68 is reasonable for a well-known bursty event like Christmas. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Christmas(DFIDF:time) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Christmas(S:frequency) Figure 2: Feature Christmas with relative high Sf and long-term Pf .",
        "The DFIDF trajectory for soccer is shown in Figure 3(a), from which we can observe that there is a regular burst every 7 days, which is again verified by its computed value of Pf = 7, as shown in Figure 3(b).",
        "Using the domain knowledge that soccer games have more matches every Saturday, which makes it a typical and heavily reported periodic event, we thus consider the value of Sf = 155.13 to be high. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) soccer(DFIDF:time) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) soccer(S:frequency) Figure 3: Feature soccer with relative high Sf and short-term Pf .",
        "From the DFIDF trajectory for DBS in Figure 4(a), we can immediately deduce DBS to be an infrequent word with a trivial burst on 08/17/1997 corresponding to DBS Land Raﬄes Holdings plans.",
        "This is confirmed by the long period of Pf = 365 and low power of Sf = 0.3084 as shown in Figure 4(b).",
        "Moreover, since this aperiodic event is only reported in a few news stories over a very short time of few days, we therefore say that its low power value of Sf = 0.3084 is representative of unimportant events.",
        "The most confusing example is shown in Figure 5 for the word feature your, which looks very similar to the graph for soccer in Figure 3.",
        "At first glance, we may be tempted to group both your and soccer into the same category of HL or LL since both distributions look similar and have the same dominant period of approximately a week.",
        "However, further 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:time) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frequency) Figure 4: Feature DBS with relative low Sf and long-term Pf . analysis indicates that the periodicity of your is due to the differences in document counts for weekdays (average 2,919 per day) and weekends3 (average 479 per day).",
        "One would have expected the periodicity of a stopword like your to be a day.",
        "Moreover, despite our DFIDF normalization, the weekday/weekend imbalance still prevailed; stopwords occur 4 times more frequently on weekends than on weekdays.",
        "Thus, the DPS remains the only distinguishing factor between your (Sf = 9.42) and soccer (Sf = 155.13).",
        "However, it is very dangerous to simply conclude that a power value of S = 9.42 corresponds to a stopword feature. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) your(DFIDF:time) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) your(S:frequency) Figure 5: Feature your as an example confusing with feature soccer.",
        "Before introducing our solution to this problem, lets look at another LL example as shown in Figure 6 for beenb, which is actually a confirmed typo.",
        "We therefore classify beenb as a noisy feature that does not contribute to any event.",
        "Clearly, the trajectory of your is very different from beenb, which means that the former has to be considered separately. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figure 6: Feature beenb with relative low Sf and short-term Pf .",
        "Stop Words (SW) Feature Set Based on the above analysis, we realize that there must be another feature set between HL and LL that corresponds to the set of stopwords.",
        "Features from this set has moderate DPS and low but known dominant period.",
        "Since it is hard to distinguish this feature set from HL and LL only based on DPS, we introduce another factor called average DFIDF (DFIDF).",
        "As shown in Figure 5, features like your usually have a lower DPS than a HL feature like soccer, but have a much higher DFIDF than another LL noisy feature such as beenb.",
        "Since such properties are usually characteristics of stopwords, we group features like your into the newly defined stopword (SW) feature set.",
        "Since setting the DPS and DFIDF thresholds for identifying stopwords is more of an art than science, we proposed a heuristic HS algorithm, Algorithm 1.",
        "The basic idea is to only use news stories from weekdays to identify stopwords. 3 The weekends here also include public holidays falling on weekdays.",
        "The SW set is initially seeded with a small set of 29 popular stopwords utilized by Google search engine.",
        "Algorithm 1 Heuristic Stopwords detection (HS) Input: Seed SW set, weekday trajectories of all words 1: From the seed set SW, compute the maximum DPS as UDPS, maximum DFIDF as UDFIDF, and minimum of DFIDF as LDFIDF. 2: for fi ∈ F do 3: Compute DFT for fi. 4: if Sfi ≤ UDPS and DFIDFfi ∈ [LDFIDF, UDFIDF] then 5: fi → SW 6: F = F − fi 7: end if 8: end for Overview of Feature Categorization After the SW set is generated, all stopwords are removed from F. We then set the boundary between high and low DPS to be the upper bound of the SW sets DPS.",
        "An overview of all five feature sets is shown in Figure 7.",
        "Figure 7: The 5 feature sets for events. 5.",
        "IDENTIFYING BURSTS FOR FEATURES Since only features from HH, HL and LH are meaningful and could potentially be representative to some events, we pruned all other feature classified as LL or SW.",
        "In this section, we describe how bursts can be identified from the remaining features.",
        "Unlike Kleinbergs burst identification algorithm [12], we can identify both significant and trivial bursts without the need to set any parameters. 5.1 Detecting Aperiodic Features Bursts For each feature in HH and HL, we truncate its trajectory by keeping only the bursty period, which is modeled with a Gaussian distribution.",
        "For example, Figure 8 shows the word feature Iraq with a burst circa 09/06/1996 being modeled as a Gaussian.",
        "Its bursty period is defined by [μf − σf , μf + σf ] as shown in Figure 8(b). 5.2 Detecting Periodic Features Bursts Since we have computed the DP for a periodic feature f, we can easily model its periodic feature trajectory yf using 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) original DFIDF:time 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 burst= [μ-σ, μ+σ] (b) identifying burst Figure 8: Modeling Iraqs time series as a truncated Gaussian with μ = 09/06/1996 and σ = 6.26. a mixture of K = T/Pf Gaussians: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , where the parameter set θf = {αk, μk, σk}K k=1 comprises: • αk is the probability of assigning yf into the kth Gaussian. αk > 0, ∀k ∈ [1, K] and K k=1 αk = 1; • μk/σk is mean/standard deviation of the kth Gaussian.",
        "The well known Expectation Maximization (EM) [8] algorithm is used to compute the mixing proportions αk, as well as the individual Gaussian density parameters μk and σK .",
        "Each Gaussian represents one periodic event, and is modeled similarly as mentioned in Section 5.1. 6.",
        "EVENTS FROM FEATURES After identifying and modeling bursts for all features, the next task is to paint a picture of the event with a potential set of representative features. 6.1 Feature Correlation If two features fi and fj are representative of the same event, they must satisfy the following necessary conditions: 1. fi and fj are identically distributed: yfi ∼ yfj . 2. fi and fj have a high document overlap.",
        "Measuring Feature Distribution Similarity We measure the similarity between two features fi and fj using discrete KL-divergence defined as follows.",
        "Definition 6. (feature similarity) KL(fi, fj ) is given by max(KL(fi|fj ), KL(fj |fi)), where KL(fi|fj ) = T t=1 f(yfi (t)|θfi )log f(yfi (t)|θfi ) f(yfj (t)|θfj ) . (1) Since KL-divergence is not symmetric, we define the similarity between between fi and fj as the maximum of KL(fi|fj ) and KL(fj |fi).",
        "Further, the similarity between two aperiodic features can be computed using a closed form of the KL-divergence [16].",
        "The same discrete KL-divergence formula of Eq. 1 is employed to compute the similarity between two periodic features, Next, we define the overal similarity among a set of features R using the maximum inter-feature KL-Divergence value as follows.",
        "Definition 7. (sets similarity)KL(R) = max ∀fi,fj ∈R KL(fi, fj ).",
        "Document Overlap Let Mi be the set of all documents containing feature fi.",
        "Given two features fi and fj , the overlapping document set containing both features is Mi ∩ Mj .",
        "Intuitively, the higher the |Mi ∩ Mj |, the more likelty that fi and fj will be highly correlated.",
        "We define the degree of document overlap between two features fi and fj as follows.",
        "Definition 8. (Feature DF Overlap) d(fi, fj ) = |Mi∩Mj| min(|Mi|,|Mj|) .",
        "Accordingly, the DF Overlap among a set of features R is also defined.",
        "Definition 9. (Set DF Overlap) d(R) = min ∀fi,fj ∈R d(fi, fj). 6.2 Unsupervised Greedy Event Detection We use features from HH to detect important aperiodic events, features from LH to detect less-reported/unimportant aperiodic events, and features from HL to detect periodic events.",
        "All of them share the same algorithm.",
        "Given bursty feature fi ∈ HH, the goal is to find highly correlated features from HH.",
        "The set of features similar to fi can then collectively describe an event.",
        "Specifically, we need to find a subset Ri of HH that minimizes the following cost function: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) The underlying event e (associated with the burst of fi) can be represented by Ri as y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) The burst analysis for event e is exactly the same as the feature trajectory.",
        "The cost in Eq. 2 can be minimized using our unsupervised greedy UG event detection algorithm, which is described in Algorithm 2.",
        "The UG algorithm allows a feature Algorithm 2 Unsupervised Greedy event detection (UG).",
        "Input: HH, document index for each feature. 1: Sort and select features in descending DPS order: Sf1 ≥ Sf2 ≥ . . . ≥ Sf|HH| . 2: k = 0. 3: for fi ∈ HH do 4: k = k + 1. 5: Init: Ri ← fi, C(Ri) = 1/Sfi and HH = HH − fi. 6: while HH not empty do 7: m = arg min m C(Ri ∪ fm). 8: if C(Ri ∪ fm) < C(Ri) then 9: Ri ← fm and HH = HH − fm. 10: else 11: break while. 12: end if 13: end while 14: Output ek as Eq. 3. 15: end for to be contained in multiple events so that we can detect several events happening at the same time.",
        "Furthermore, trivial events only containing year/month features (i.e., an event only containing 1 feature Aug could be identified over a 1year news stream) could be removed, although such events will have inherent high cost and should already be ranked very low.",
        "Note that our UG algorithm only requires one data-dependant parameter, the boundary between high and low power spectrum, to be set once, and this parameter can be easily estimated using the HS algorithm (Algorithm 1). 7.",
        "EXPERIMENTS In this section, we study the performances of our feature categorizing method and event detection algorithm.",
        "We first introduce the dataset and experimental setup, then we subjectively evaluate the categorization of features for HH, HL, LH, LL and SW.",
        "Finally, we study the (a)periodic event detection problem with Algorithm 2. 7.1 Dataset and Experimental Setup The Reuters Corpus contains 806,791 English news stories from 08/20/1996 to 08/19/1997 at a day resolution.",
        "Version 2 of the open source Lucene software [1] was used to tokenize the news text content and generate the document-word vector.",
        "In order to preserve the time-sensitive past/present/future tenses of verbs and the differences between lower case nouns and upper case named entities, no stemming was done.",
        "Since dynamic stopword removal is one of the functionalities of our method, no stopword was removed.",
        "We did remove nonEnglish characters, however, after which the number of word features amounts to 423,433.",
        "All experiments were implemented in Java and conducted on a 3.2 GHz Pentium 4 PC running Windows 2003 Server with 1 GB of memory. 7.2 Categorizing Features We downloaded 34 well-known stopwords utilized by the Google search engine as our seed training features, which includes a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en and www.",
        "We excluded the last five stopwords as they are uncommon in news stories.",
        "By only analyzing news stories over 259 weekdays, we computed the upper bound of the power spectrum for stopwords at 11.18 and corresponding DFIDF ranges from 0.1182 to 0.3691.",
        "Any feature f satisfying Sf <= 11.18 and 0.1182 <= DFIDFf <= 0.3691 over weekdays will be considered a stopword.",
        "In this manner, 470 stopwords were found and removed as visualized in Figure 9.",
        "Some detected stopwords are A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) and much (P = 22, S = 0.80, DFIDF = 0.1865).",
        "After the removal of these stopwords, the distribution of weekday and weekend news are more or less matched, and in the ensuing experiments, we shall make use of the full corpus (weekdays and weekends).",
        "The upper bound power spectrum value of 11.18 for stopwords training was selected as the boundary between the high power and low power spectrum.",
        "The boundary between high and low periodicity was set to 365/2 = 183.",
        "All 422,963 (423433 − 470) word features were categorized into 4 feature sets: HH (69 features), HL (1,087 features), LH (83,471 features), and LL (338,806 features) as shown in Figure 10.",
        "In Figure 10, each gray level denotes the relative density of features in a square region, measured by log10(1 + Dk), where Dk is the number of features within the k-th square region.",
        "From the figure, we can make the 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figure 9: Distribution of SW (stopwords) in the HH, HL, LH, and LL regions. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figure 10: Distribution of categorized features over the four quadrants (shading in log scale). following observations: 1.",
        "Most features have low S and are easily distinguishable from those features having a much higher S, which allows us to detect important (a)periodic events from trivial events by selecting features with high S. 2.",
        "Features in the HH and LH quadrants are aperiodic, which are nicely separated (big horizontal gap) from the periodic features.",
        "This allows reliably detecting aperiodic events and periodic events independently. 3.",
        "The (vertical) boundary between high and low power spectrum is not as clearcut and the exact value will be application specific.",
        "By checking the scatter distribution of features from SW on HH, HL, LH, and LL as shown in Figure 9, we found that 87.02%(409/470) of the detected stopwords originated from LL.",
        "The LL classification and high DFIDF scores of stopwords agree with the generally accepted notion that stopwords are equally frequent over all time.",
        "Therefore, setting the boundary between high and low power spectrum using the upper bound Sf of SW is a reasonable heuristic. 7.3 Detecting Aperiodic Events We shall evaluate our two hypotheses, 1)important aperiodic events can be defined by a set of HH features, and 2)less reported aperiodic events can be defined by a set of LH features.",
        "Since no benchmark news streams exist for event detection (TDT datasets are not proper streams), we evaluate the quality of the automatically detected events by comparing them to manually-confirmed events by searching through the corpus.",
        "Among the 69 HH features, we detected 17 important aperiodic events as shown in Table 1 (e1 − e17).",
        "Note that the entire identification took less than 1 second, after removing events containing only the month feature.",
        "Among the 17 events, other than the overlaps between e3 and e4 (both describes the same hostage event), e11 and e16 (both about company reports), the 14 identified events are extremely accurate and correspond very well to the major events of the period.",
        "For example, the defeat of Bob Dole, election of Tony Blair, Missile attack on Iraq, etc.",
        "Recall that selecting the features for one event should minimize the cost in Eq. 2 such that 1) the number of features span different events, and 2) not all features relevant to an event will be selected, e.g., the feature Clinton is representative to e12 but since Clinton relates to many other events, its time domain signal is far different from those of other representative features like Dole and Bob.",
        "The number of documents of a detected event is roughly estimated by the number of indexed documents containing the representative features.",
        "We can see that all 17 important aperiodic events are popularly reported events.",
        "After 742 minutes of computation time, we detected 23, 525 less reported aperiodic events from 83,471 LH features.",
        "Table 1 lists the top 5 detected aperiodic events (e18 − e22) with respect to the cost.",
        "We found that these 5 events are actually very trivial events with only a few news reports, and are usually subsumed by some larger topics.",
        "For example, e22 is one of the rescue events in an airplane hijack topic.",
        "One advantage of our UG Algorithm for discovering less-reported aperiodic events is that we are able to precisely detect the true event period. 7.4 Detecting Periodic Events Among the 1,087 HL features, 330 important periodic events were detected within 10 minutes of computing time.",
        "Table 1 lists the top 5 detected periodic events with respect to the cost (e23 − e27).",
        "All of the detected periodic events are indeed valid, and correspond to real life periodic events.",
        "The GMM model is able to detect and estimate the bursty period nicely although it cannot distinguish the slight difference between every Monday-Friday and all weekdays as shown in e23.",
        "We also notice that e26 is actually a subset of e27 (soccer game), which is acceptable since the Sheffield league results are announced independently every weekend. 8.",
        "CONCLUSIONS This paper took a whole new perspective of analyzing feature trajectories as time domain signals.",
        "By considering the word document frequencies in both time and frequency domains, we were able to derive many new characteristics about news streams that were previously unknown, e.g., the different distributions of stopwords during weekdays and weekends.",
        "For the first time in the area of TDT, we applied a systematic approach to automatically detect important and less-reported, periodic and aperiodic events.",
        "The key idea of our work lies in the observations that (a)periodic events have (a)periodic representative features and (un)important events have (in)active representative features, differentiated by their power spectrums and time periods.",
        "To address the real event detection problem, a simple and effective mixture density-based approach was used to identify feature bursts and their associated bursty periods.",
        "We also designed an unsupervised greedy algorithm to detect both aperiodic and periodic events, which was successful in detecting real events as shown in the evaluation on a real news stream.",
        "Although we have not made any benchmark comparison against another approach, simply because there is no previous work in the addressed problem.",
        "Future work includes evaluating the recall of detected events for a labeled news stream, and comparing our model against the closest equivalent methods, which currently are limited to the methods of Kleinberg [12] (which can only detect certain type of bursty events depending on parameter settings), Fung et al. [9], and Swan and Allan [18].",
        "Nevertheless, we believe our simple and effective method will be useful for all TDT practitioners, and will be especially useful for the initial exploratory analysis of news streams. 9.",
        "REFERENCES [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Google news alerts, http://www.google.com/alerts. [3] Reuters corpus, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan.",
        "Topic Detection and Tracking.",
        "Event-based Information Organization.",
        "Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, and H. Jin.",
        "First story detection in tdt is hard.",
        "In CIKM, pages 374-381, 2000. [6] J. Allan, C. Wade, and A. Bolivar.",
        "Retrieval and novelty detection at the sentence level.",
        "In SIGIR, pages 314-321, 2003. [7] T. Brants, F. Chen, and A. Farahat.",
        "A system for new event detection.",
        "In SIGIR, pages 330-337, 2003. [8] A. P. Dempster, N. M. Laird, and D. B. Rubin.",
        "Maximum likelihood from incomplete data via the EM algorithm.",
        "Journal of the Royal Statistical Society, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu, and H. Lu.",
        "Parameter free bursty events detection in text streams.",
        "In VLDB, pages 181-192, 2005. [10] Q.",
        "He, K. Chang, and E.-P. Lim.",
        "A model for anticipatory event detection.",
        "In ER, pages 168-181, 2006. [11] Q.",
        "He, K. Chang, E.-P. Lim, and J. Zhang.",
        "Bursty feature reprensentation for clustering text streams.",
        "In SDM, accepted, 2007. [12] J. Kleinberg.",
        "Bursty and hierarchical structure in streams.",
        "In SIGKDD, pages 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins.",
        "On the bursty evolution of blogspace.",
        "In WWW, pages 159-178, 2005. [14] G. Kumaran and J. Allan.",
        "Text classification and named entities for new event detection.",
        "In SIGIR, pages 297-304, 2004. [15] Q. Mei and C. Zhai.",
        "Discovering evolutionary theme patterns from text: an exploration of temporal text mining.",
        "In SIGKDD, pages 198-207, 2005. [16] W. D. Penny.",
        "Kullback-liebler divergences of normal, gamma, dirichlet and wishart densities.",
        "Technical report, 2001. [17] N. Stokes and J. Carthy.",
        "Combining semantic and syntactic document classifiers to improve first story detection.",
        "In SIGIR, pages 424-425, 2001. [18] R. Swan and J. Allan.",
        "Automatic generation of overview timelines.",
        "In SIGIR, pages 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena, and D. Gunopulos.",
        "Identifying similarities, periodicities and bursts for online search queries.",
        "In SIGMOD, pages 131-142, 2004. [20] Y. Yang, T. Pierce, and J. Carbonell.",
        "A study of retrospective and on-line event detection.",
        "In SIGIR, pages 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
        "Topic-conditioned novelty detection.",
        "In SIGKDD, pages 688-693, 2002.",
        "Table 1: All important aperiodic events (e1 − e17), top 5 less-reported aperiodic events (e18 − e22) and top 5 important periodic events (e23 − e27).",
        "Detected Event and Bursty Period Doc # True Event e1(Sali,Berisha,Albania,Albanian,March) 02/02/199705/29/1997 1409 Albanians president Sali Berisha lost in an early election and resigned, 12/1996-07/1997. e2(Seko,Mobutu,Sese,Kabila) 03/22/1997-06/09/1997 2273 Zaires president Mobutu Sese coordinated the native rebellion and failed on 05/16/1997. e3(Marxist,Peruvian) 11/19/1996-03/05/1997 824 Peru rebels (Tupac Amaru revolutionary Movement) led a hostage siege in Lima in early 1997. e4(Movement,Tupac,Amaru,Lima,hostage,hostages) 11/16/1996-03/20/1997 824 The same as e3. e5(Kinshasa,Kabila,Laurent,Congo) 03/26/199706/15/1997 1378 Zaire was renamed the Democratic Republic of Congo on 05/16/1997. e6(Jospin,Lionel,June) 05/10/1997-07/09/1997 605 Following the early General Elections circa 06/1997, Lionel Jospin was appointed Prime Minister on 06/02/1997. e7(Iraq,missile) 08/31/1996-09/13/1996 1262 U.S. fired missile at Iraq on 09/03/1996 and 09/04/1996. e8(Kurdish,Baghdad,Iraqi) 08/29/1996-09/09/1996 1132 Iraqi troop fought with Kurdish faction circa 09/1996. e9(May,Blair) 03/24/1997-07/04/1997 1049 Tony Blair became the Primary Minister of the United Kingdom on 05/02/1997. e10(slalom,skiing) 12/05/1996-03/21/1997 253 Slalom Game of Alpine Skiing in 01/1997-02/1997. e11(Interim,months) 09/24/1996-12/31/1996 3063 Tokyo released company interim results for the past several months in 09/1996-12/1996. e12(Dole,Bob) 09/09/1996-11/24/1996 1599 Dole Bob lost the 1996 US presidential election. e13(July,Sen) 06/25/1997-06/25/1997 344 Cambodias Prime Minister Hun Sen launched a bloody military coup in 07/1997. e14(Hebron) 10/15/1996-02/14/1997 2098 Hebron was divided into two sectors in early 1997. e15(April,Easter) 02/23/1997-05/04/1997 480 Easter feasts circa 04/1997 (for western and Orthodox). e16(Diluted,Group) 04/27/1997-07/20/1997 1888 Tokyo released all 96/97 group results in 04/199707/1997. e17(December,Christmas) 11/17/1996-01/26/1997 1326 Christmas feast in late 12/1997. e18(Kolaceva,winter,Together,promenades,Zajedno, Slobodan,Belgrade,Serbian,Serbia,Draskovic,municipal, Kragujevac) 1/25/1997 3 University students organized a vigil on Kolaceva street against government on 1/25/1997. e19(Tutsi,Luvengi,Burundi,Uvira,fuel,Banyamulenge, Burundian,Kivu,Kiliba,Runingo,Kagunga,Bwegera) 10/19/1996 6 Fresh fighting erupted around Uvira between Zaire armed forces and Banyamulengs Tutsi rebels on 10/19/1996. e20(Malantacchi,Korea,Guy,Rider,Unions,labour, Trade,unions,Confederation,rammed,Geneva,stoppages, Virgin,hire,Myongdong,Metalworkers) 1/11/1997 2 Marcello Malantacchi secretary general of the International Metalworkers Federation and Guy Rider who heads the Geneva office of the International Confederation of Free Trade Unions attacked the new labour law of South Korea on 1/11/1997. e21(DBS,Raﬄes) 8/17/1997 9 The list of the unit of Singapore DBS Land Raﬄes Holdings plans on 8/17/1997. e22(preserver,fuel,Galawa,Huddle,Leul,Beausse) 11/24/1996 3 Rescued a woman and her baby during a hijacked Ethiopian plane that ran out of fuel and crashed into the sea near Le Galawa beach on 11/24/1996. e23(PRICE,LISTING,MLN,MATURITY,COUPON, MOODY,AMT,FIRST,ISS,TYPE,PAY,BORROWER) Monday-Friday/week 7966 Announce bond price on all weekdays. e24(Unaudited,Ended,Months,Weighted,Provision,Cost, Selling,Revenues,Loss,Income,except,Shrs,Revs) every season 2264 Net income-loss reports released by companies in every season. e25(rating,Wall,Street,Ian) Monday-Friday/week 21767 Stock reports from Wall Street on all weekdays. e26(Sheffield,league,scoring,goals,striker,games) every Friday, Saturday and Sunday 574 Match results of Sheffield soccer league were published on Friday, Saturday and Sunday 10 times than other 4 days. e27(soccer,matches,Results,season,game,Cup,match, victory,beat,played,play,division) every Friday, Saturday and Sunday 2396 Soccer games held on Friday, Saturday and Sunday 7 times than other 4 days."
    ],
    "translated_text_sentences": [
        "Analizando Trayectorias de Características para la Detección de Eventos Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg Escuela de Ingeniería Informática Universidad Tecnológica de Nanyang Bloque N4, Avenida Nanyang, Singapur 639798 RESUMEN Consideramos el problema de analizar trayectorias de palabras en los dominios del tiempo y la frecuencia, con el objetivo específico de identificar palabras importantes y menos reportadas, periódicas y aperiódicas.",
        "Un conjunto de palabras con tendencias idénticas puede agruparse para reconstruir un evento de manera completamente no supervisada.",
        "La frecuencia del documento de cada palabra a lo largo del tiempo se trata como una serie temporal, donde cada elemento es el puntaje de frecuencia del documento - frecuencia inversa del documento (DFIDF) en un punto temporal.",
        "En este artículo, 1) primero aplicamos análisis espectral para categorizar características de diferentes tipos de eventos: importantes y poco reportados, periódicos y aperiódicos; 2) modelamos las características aperiódicas con densidad gaussiana y las características periódicas con densidades de mezcla gaussiana, y posteriormente detectamos cada ráfaga de características mediante el enfoque gaussiano truncado; 3) propusimos un algoritmo de detección de eventos codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos.",
        "Todos los métodos anteriores se pueden aplicar a datos de series temporales en general.",
        "Evaluamos exhaustivamente nuestros métodos en el Corpus de Noticias de Reuters de 1 año [3] y demostramos que fueron capaces de descubrir eventos significativos aperiódicos y periódicos.",
        "Categorías y Descriptores de Asignaturas: H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales: Algoritmos, Experimentación. 1.",
        "INTRODUCCIÓN Hay más de 4,000 fuentes de noticias en línea en el mundo.",
        "Supervisar manualmente todos ellos en busca de eventos importantes se ha vuelto difícil o prácticamente imposible.",
        "De hecho, la comunidad de detección y seguimiento de temas (TDT) ha estado tratando durante muchos años de encontrar una solución práctica para ayudar a las personas a monitorear las noticias de manera efectiva.",
        "Desafortunadamente, el Santo Grial sigue siendo esquivo, ya que la gran mayoría de las soluciones de TDT propuestas para la detección de eventos [20, 5, 17, 4, 21, 7, 14, 10] son demasiado simplistas (basadas en la similitud del coseno [5]) o impracticables debido a la necesidad de ajustar un gran número de parámetros [9].",
        "La ineficacia de las tecnologías actuales de TDT se puede ilustrar fácilmente suscribiéndose a cualquiera de los muchos servicios de alertas de noticias en línea, como el líder de la industria Google News Alerts, que genera más del 50% de falsas alarmas.",
        "Como prueba adicional, portales como Yahoo adoptan un enfoque más pragmático al requerir que todas las alertas de noticias generadas por máquinas pasen por un operador humano para su confirmación antes de enviarlas a los suscriptores.",
        "En lugar de abordar el problema con variaciones del mismo martillo (similitud coseno y TFIDF), es necesario contar con una comprensión fundamental de las características de los datos de flujo de noticias antes de que se puedan lograr avances importantes en TDT.",
        "Por lo tanto, en este artículo, examinamos noticias y tendencias de características desde la perspectiva de analizar una señal de palabras de series temporales.",
        "Trabajos anteriores como [9] han intentado reconstruir un evento con sus características representativas.",
        "Sin embargo, en muchas tareas de detección de eventos predictivos (es decir, detección de eventos retrospectivos), hay un vasto conjunto de características potenciales solo para un conjunto fijo de observaciones (es decir, los estallidos obvios).",
        "De estas características, a menudo solo se espera que un pequeño número sea útil.",
        "En particular, estudiamos el novedoso problema de analizar trayectorias de características para la detección de eventos, utilizando una técnica conocida de procesamiento de señales: identificar correlaciones distribucionales entre todas las características mediante análisis espectral.",
        "Para evaluar nuestro método, posteriormente proponemos un algoritmo de detección de eventos no supervisado para flujos de noticias. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Pascua Abril (a) evento aperiódico 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 No auditado Finalizado (b) evento periódico Figura 1: Correlación de características (DFIDF:tiempo) entre a) Pascua y Abril b) No auditado y Finalizado.",
        "Como ejemplo ilustrativo, considera la correlación entre las palabras Pascua y abril del Corpus de Reuters.",
        "A partir del gráfico de su DFIDF normalizado en la Figura 1(a), observamos la gran superposición entre las dos palabras alrededor de 04/1997, lo que significa que probablemente ambas pertenecen al mismo evento durante ese tiempo (festividad de Pascua).",
        "En este ejemplo, el evento oculto de la festividad de Pascua es un evento aperiódico típico e importante en datos de 1 año.",
        "Otro ejemplo se muestra en la Figura 1(b), donde las palabras \"No auditado\" y \"Finalizado 1\" del Corpus de Reuters son el conjunto de datos predeterminado para todos los ejemplos y presentan un comportamiento similar durante períodos de 3 meses.",
        "Estas dos palabras en realidad se originaron a partir del mismo evento periódico, informes de ganancias y pérdidas, que son publicados trimestralmente por empresas cotizadas en bolsa.",
        "Otras observaciones extraídas de la Figura 1 son: 1) el período de actividad intensa de abril es mucho más largo que el de Semana Santa, lo que sugiere que abril puede estar presente en otros eventos durante el mismo período; 2) No auditado tiene un valor promedio de DFIDF más alto que Finalizado, lo que indica que No auditado es más representativo para el evento subyacente.",
        "Estos dos ejemplos son solo la punta del iceberg entre todas las tendencias de palabras y correlaciones ocultas en un flujo de noticias como Reuters.",
        "Si se puede descubrir un gran número de ellos, podría ayudar significativamente en las tareas de TDT.",
        "En particular, indica la importancia de extraer características correlacionadas para detectar eventos correspondientes.",
        "Para resumir, postulamos que: 1) Un evento se describe por sus características representativas.",
        "Un evento periódico tiene una lista de características periódicas y un evento aperiódico tiene una lista de características aperiódicas; 2) Las características representativas del mismo evento comparten distribuciones similares en el tiempo y están altamente correlacionadas; 3) Un evento importante tiene un conjunto de características representativas activas (ampliamente reportadas), mientras que un evento no importante tiene un conjunto de características representativas inactivas (menos reportadas); 4) Una característica puede ser incluida por varios eventos con superposiciones en los marcos de tiempo.",
        "Basándonos en estas observaciones, podemos extraer características representativas dadas un evento o detectar un evento a partir de una lista de características altamente correlacionadas.",
        "En este artículo, nos enfocamos en este último aspecto, es decir, cómo se pueden descubrir características correlacionadas para formar un evento de manera no supervisada. 1.1 Contribuciones Este artículo tiene tres contribuciones principales: • Hasta donde sabemos, nuestro enfoque es el primero en categorizar características de palabras para eventos heterogéneos.",
        "Específicamente, cada característica de palabra se clasifica en uno de los siguientes cinco tipos de características basados en la fuerza de su espectro de potencia y periodicidad: 1) HH (alta potencia y alta/larga periodicidad): eventos aperiódicos importantes, 2) HL (alta potencia y baja periodicidad): eventos periódicos importantes, 3) LH (baja potencia y alta periodicidad): eventos aperiódicos no importantes, 4) LL (baja potencia y baja periodicidad): no eventos, y 5) SW (palabras vacías), un subconjunto de LL con mayor potencia y periodicidad que comprende palabras vacías, que no contienen información. • Proponemos un enfoque simple y efectivo basado en densidad de mezcla para modelar y detectar ráfagas de características. • Presentamos un algoritmo de detección de eventos no supervisado para detectar eventos tanto aperiódicos como periódicos.",
        "Nuestro algoritmo ha sido evaluado en un flujo de noticias reales para demostrar su efectividad. 2.",
        "TRABAJO RELACIONADO Este trabajo está motivado en gran medida por una familia más amplia de problemas conocidos colectivamente como Detección y Seguimiento de Temas (TDT) [20, 5, 17, 4, 21, 7, 14, 10].",
        "Además, la mayoría de las investigaciones de TDT hasta ahora se han centrado en agrupar/clasificar documentos en tipos de temas, identificar oraciones novedosas para eventos nuevos, etc., sin prestar mucha atención al análisis de la trayectoria de las palabras con respecto al tiempo.",
        "Swan y Allan [18] intentaron por primera vez usar términos que co-ocurren para construir un evento.",
        "Sin embargo, solo consideraron entidades nombradas y pares de frases nominales, sin tener en cuenta sus periodicidades.",
        "Por el contrario, nuestro artículo considera todo lo anterior.",
        "Recientemente, ha habido un gran interés en modelar un evento en flujos de texto como un estallido de actividades al incorporar información temporal.",
        "El trabajo seminal de Kleinberg describió cómo se pueden extraer características explosivas de flujos de texto utilizando un modelo de autómata infinito [12], lo que inspiró toda una serie de aplicaciones como la identificación de comunidades explosivas de Kumar a partir de gráficos de blogs [13], la sumarización de temas evolutivos en flujos de texto de Meis [15], el agrupamiento de flujos de texto utilizando características explosivas de Hes [11], etc.",
        "Sin embargo, ninguno de los trabajos existentes identificó específicamente características para eventos, excepto Fung et al. [9], quienes agruparon características llamativas para identificar varios eventos llamativos.",
        "Nuestro trabajo difiere de [9] en varias formas: 1) analizamos cada característica individual, no solo las características explosivas; 2) clasificamos las características a lo largo de dos dimensiones categóricas (periodicidad y potencia), dando en total cinco tipos de características principales; 3) no restringimos que cada característica pertenezca exclusivamente a un solo evento.",
        "Las técnicas de análisis espectral han sido utilizadas previamente por Vlachos et al. [19] para identificar periodicidades y ráfagas en los registros de consultas.",
        "Su enfoque estaba en detectar múltiples periodicidades a partir del gráfico del espectro de potencia, las cuales luego se utilizaron para indexar palabras para la búsqueda por ráfagas.",
        "En este artículo, utilizamos análisis espectral para clasificar las características de las palabras a lo largo de dos dimensiones, a saber, periodicidad y espectro de potencia, con el objetivo final de identificar eventos tanto periódicos como no periódicos y explosivos. 3.",
        "REPRESENTACIÓN DE DATOS Sea T la duración/período (en días) de un flujo de noticias, y F representa el espacio de características de palabras completo en el Modelo de Espacio Vectorial (VSM) estático clásico. 3.1 Clasificación de Periodicidad de Eventos Dentro de T, pueden existir ciertos eventos que ocurren solo una vez, por ejemplo, la elección de Tony Blair como Primer Ministro del Reino Unido, y otros eventos recurrentes de diversas periodicidades, por ejemplo, partidos de fútbol semanales.",
        "Por lo tanto, categorizamos todos los eventos en dos tipos: aperiódicos y periódicos, definidos de la siguiente manera.",
        "Definición 1. (Evento aperiódico) Un evento es aperiódico dentro de T si solo ocurre una vez.",
        "Definición 2. (Evento periódico) Si los eventos de un cierto género de eventos ocurren regularmente con una periodicidad fija P ≤ T/2, decimos que este género particular de eventos es periódico, y cada evento miembro se califica como un evento periódico.",
        "Ten en cuenta que la definición de aperiódico es relativa, es decir, es verdadera solo para un T dado y puede ser inválida para cualquier otro T > T. Por ejemplo, el evento de la fiesta de Navidad es aperiódico para T ≤ 365 pero periódico para T ≥ 730. 3.2 Características Representativas Intuitivamente, un evento puede ser descrito de manera muy concisa por unas pocas características de palabras discriminativas y representativas y viceversa, por ejemplo, huracán, barrido y golpe podrían ser características representativas de un evento del género de huracanes.",
        "Asimismo, un conjunto de características fuertemente correlacionadas podría ser utilizado para reconstruir una descripción de un evento, asumiendo que las características fuertemente correlacionadas son representativas.",
        "El vector de representación de una característica de palabra se define de la siguiente manera: Definición 3. (Trayectoria de la Característica) La trayectoria de una característica de palabra f puede escribirse como la secuencia yf = [yf (1), yf (2), . . . , yf (T)], donde cada elemento yf (t) es una medida de la característica f en el tiempo t, que podría definirse utilizando la puntuación normalizada DFIDF yf (t) = DFf (t) N(t) × log( N DFf ), donde DFf (t) es el número de documentos (DF local) que contienen la característica f en el día t, DFf es el número total de documentos (DF global) que contienen la característica f en T, N(t) es el número de documentos para el día t, y N es el número total de documentos en T. 4.",
        "En esta sección, mostramos cómo se pueden extraer características representativas para eventos (poco) importantes o (a)periódicos. 4.1 Análisis Espectral para el Período Dominante Dada una característica f, descomponemos su trayectoria de características yf = [yf (1), yf (2), ..., yf (T)] en la secuencia de T números complejos [X1, . . . , XT ] a través de la transformada discreta de Fourier (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. La DFT puede representar la serie temporal original como una combinación lineal de sinusoides complejas, lo cual se ilustra mediante la transformada discreta de Fourier inversa (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, donde el coeficiente de Fourier Xk denota la amplitud del sinusoides con frecuencia k/T.",
        "La trayectoria original puede ser reconstruida con solo las frecuencias dominantes, las cuales pueden ser determinadas a partir del espectro de potencia utilizando el popular estimador periodograma.",
        "El periodograma es una secuencia de la magnitud al cuadrado de los coeficientes de Fourier, Xk^2, k = 1, 2, . . . , T/2, que indica la potencia de la señal en la frecuencia k/T en el espectro.",
        "A partir del espectro de potencia, se elige el período dominante como el inverso de la frecuencia con el espectro de potencia más alto, de la siguiente manera.",
        "Definición 4. (Período Dominante) El período dominante (DP) de una característica dada f es Pf = T/ arg max k Xk 2.",
        "Por lo tanto, tenemos la Definición 5. (Espectro de Potencia Dominante) El espectro de potencia dominante (DPS) de una característica dada f es Sf = Xk 2 , con Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorización de Características El DPS de una trayectoria de características es un indicador fuerte de su actividad en la frecuencia especificada; cuanto mayor sea el DPS, es más probable que la característica sea explosiva.",
        "Al combinar DPS con DP, categorizamos todas las características en cuatro tipos: 2 Normalizamos yf (t) como yf (t) = yf (t)/ T i=1 yf (i) para que pueda interpretarse como una probabilidad. • HH: alta Sf, aperiódico o periódico a largo plazo (Pf > T/2); • HL: alta Sf, periódico a corto plazo (Pf ≤ T/2); • LH: baja Sf, aperiódico o periódico a largo plazo; • LL: baja Sf, periódico a corto plazo.",
        "La frontera entre los periodos a largo plazo y a corto plazo se establece en T/2.",
        "Sin embargo, distinguir entre un DPS alto y bajo no es sencillo, lo cual se abordará más adelante.",
        "Propiedades de diferentes conjuntos de características Para comprender mejor las propiedades de HH, HL, LH y LL, seleccionamos cuatro características, Navidad, fútbol, DBS y tu como ejemplos ilustrativos.",
        "Dado que la frontera entre el espectro de alta y baja potencia no está clara, estos ejemplos seleccionados tienen un rango relativo amplio de valores de espectro de potencia.",
        "La figura 2(a) muestra la trayectoria de DFIDF para la Navidad con un pico distintivo alrededor del día de Navidad.",
        "Para el conjunto de datos de Reuters de 1 año, la Navidad se clasifica como un evento aperiódico típico con Pf = 365 y Sf = 135.68, como se muestra en la Figura 2(b).",
        "Claramente, el valor de Sf = 135.68 es razonable para un evento conocido por ser intermitente como la Navidad. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Navidad(DFIDF:tiempo) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Navidad(S:frecuencia) Figura 2: Característica Navidad con un Sf relativamente alto y un Pf a largo plazo.",
        "La trayectoria de DFIDF para el fútbol se muestra en la Figura 3(a), de la cual podemos observar que hay un estallido regular cada 7 días, lo cual es nuevamente verificado por su valor calculado de Pf = 7, como se muestra en la Figura 3(b).",
        "Usando el conocimiento del dominio de que los partidos de fútbol tienen más encuentros cada sábado, lo que lo convierte en un evento periódico típico y ampliamente reportado, consideramos que el valor de Sf = 155.13 es alto. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) fútbol (DFIDF:tiempo) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) fútbol (S:frecuencia) Figura 3: Característica fútbol con un Sf relativamente alto y un Pf a corto plazo.",
        "A partir de la trayectoria de DFIDF para DBS en la Figura 4(a), podemos deducir de inmediato que DBS es una palabra poco frecuente con un aumento trivial el 17/08/1997 correspondiente a los planes de DBS Land Raﬄes Holdings.",
        "Esto se confirma por el largo período de Pf = 365 y la baja potencia de Sf = 0.3084 como se muestra en la Figura 4(b).",
        "Además, dado que este evento aperiódico solo se informa en algunas noticias durante un corto período de unos pocos días, por lo tanto, decimos que su bajo valor de potencia de Sf = 0.3084 es representativo de eventos poco importantes.",
        "El ejemplo más confuso se muestra en la Figura 5 para la palabra \"your\", que se ve muy similar al gráfico para fútbol en la Figura 3.",
        "A primera vista, podríamos sentirnos tentados a agrupar tanto tu como el fútbol en la misma categoría de HL o LL, ya que ambas distribuciones se ven similares y tienen el mismo período dominante de aproximadamente una semana.",
        "Sin embargo, más adelante 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:tiempo) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frecuencia) Figura 4: Característica DBS con Sf relativamente bajo y Pf a largo plazo. El análisis indica que la periodicidad de su es debido a las diferencias en el recuento de documentos para los días de la semana (promedio de 2,919 por día) y los fines de semana (promedio de 479 por día).",
        "Uno habría esperado que la periodicidad de una palabra vacía como \"tu\" fuera de un día.",
        "Además, a pesar de nuestra normalización de DFIDF, el desequilibrio entre los días de la semana y los fines de semana aún prevalecía; las palabras vacías ocurren 4 veces más frecuentemente los fines de semana que los días de semana.",
        "Por lo tanto, el DPS sigue siendo el único factor distintivo entre tu (Sf = 9.42) y el fútbol (Sf = 155.13).",
        "Sin embargo, es muy peligroso concluir simplemente que un valor de potencia de S = 9.42 corresponde a una característica de palabra vacía. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) tu(DFIDF:tiempo) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) tu(S:frecuencia) Figura 5: Característica tu como un ejemplo confundido con la característica fútbol.",
        "Antes de presentar nuestra solución a este problema, veamos otro ejemplo de LL como se muestra en la Figura 6 para beenb, que en realidad es un error tipográfico confirmado.",
        "Por lo tanto, clasificamos beenb como una característica ruidosa que no contribuye a ningún evento.",
        "Claramente, la trayectoria de tu es muy diferente de beenb, lo que significa que el primero debe considerarse por separado. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figura 6: Característica beenb con Sf relativamente bajo y Pf a corto plazo.",
        "Conjunto de características de palabras vacías (SW) Basándonos en el análisis anterior, nos damos cuenta de que debe haber otro conjunto de características entre HL y LL que corresponda al conjunto de palabras vacías.",
        "Las características de este conjunto tienen un DPS moderado y un período dominante bajo pero conocido.",
        "Dado que es difícil distinguir este conjunto de características de HL y LL solo basándose en DPS, introducimos otro factor llamado promedio de DFIDF (DFIDF).",
        "Como se muestra en la Figura 5, características como la tuya suelen tener un DPS más bajo que una característica HL como el fútbol, pero tienen un DFIDF mucho más alto que otra característica ruidosa LL como \"beenb\".",
        "Dado que tales propiedades suelen ser características de las palabras vacías, agrupamos características como \"tu\" en el conjunto de características de palabras vacías (SW) recién definido.",
        "Dado que establecer los umbrales de DPS y DFIDF para identificar las palabras vacías es más un arte que una ciencia, propusimos un algoritmo heurístico HS, Algoritmo 1.",
        "La idea básica es utilizar solo noticias de días laborables para identificar palabras vacías. Los fines de semana aquí también incluyen días festivos que caen en días laborables.",
        "El conjunto SW se inicialmente alimenta con un pequeño conjunto de 29 stopwords populares utilizadas por el motor de búsqueda de Google.",
        "Algoritmo 1 Detección heurística de palabras vacías (HS) Entrada: Conjunto de palabras vacías semilla, trayectorias semanales de todas las palabras 1: A partir del conjunto semilla SW, calcular el DPS máximo como UDPS, el DFIDF máximo como UDFIDF y el mínimo de DFIDF como LDFIDF. 2: para fi ∈ F hacer 3: Calcular DFT para fi. 4: si Sfi ≤ UDPS y DFIDFfi ∈ [LDFIDF, UDFIDF] entonces 5: fi → SW 6: F = F - fi 7: fin si 8: fin para Resumen de la Categorización de Características Después de generar el conjunto SW, se eliminan todas las palabras vacías de F. Luego, establecemos el límite entre DPS alto y bajo como el límite superior de los DPS de los conjuntos SW.",
        "Una visión general de los cinco conjuntos de características se muestra en la Figura 7.",
        "Figura 7: Los 5 conjuntos de características para eventos. 5.",
        "IDENTIFICACIÓN DE RÁFAGAS PARA CARACTERÍSTICAS Dado que solo las características de HH, HL y LH son significativas y podrían ser representativas de algunos eventos, eliminamos todas las demás características clasificadas como LL o SW.",
        "En esta sección, describimos cómo se pueden identificar los estallidos a partir de las características restantes.",
        "A diferencia del algoritmo de identificación de ráfagas de Kleinberg [12], podemos identificar tanto ráfagas significativas como triviales sin necesidad de establecer ningún parámetro. 5.1 Detección de ráfagas de características aperiódicas Para cada característica en HH y HL, truncamos su trayectoria manteniendo solo el período de ráfagas, el cual está modelado con una distribución gaussiana.",
        "Por ejemplo, la Figura 8 muestra la característica de la palabra Iraq con una explosión alrededor del 09/06/1996 modelada como una Gaussiana.",
        "Su período de ráfagas está definido por [μf − σf , μf + σf ] como se muestra en la Figura 8(b). 5.2 Detección de características periódicas de ráfagas Dado que hemos calculado el DP para una característica periódica f, podemos modelar fácilmente su trayectoria de características periódicas yf usando 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) DFIDF original: tiempo 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 ráfaga= [μ-σ, μ+σ] (b) identificación de ráfaga Figura 8: Modelando la serie temporal de Iraq como una Gaussiana truncada con μ = 09/06/1996 y σ = 6.26. una mezcla de K = T/Pf Gaussianas: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , donde el conjunto de parámetros θf = {αk, μk, σk}K k=1 comprende: • αk es la probabilidad de asignar yf a la k-ésima Gaussiana. αk > 0, ∀k ∈ [1, K] y K k=1 αk = 1; • μk/σk es la media/desviación estándar de la k-ésima Gaussiana.",
        "El conocido algoritmo Expectation Maximization (EM) [8] se utiliza para calcular las proporciones de mezcla αk, así como los parámetros individuales de densidad gaussiana μk y σK.",
        "Cada Gaussiana representa un evento periódico, y se modela de manera similar como se menciona en la Sección 5.1. 6.",
        "EVENTOS A PARTIR DE CARACTERÍSTICAS Después de identificar y modelar ráfagas para todas las características, la siguiente tarea es pintar un cuadro del evento con un posible conjunto de características representativas. 6.1 Correlación de Características Si dos características fi y fj son representativas del mismo evento, deben cumplir las siguientes condiciones necesarias: 1. fi y fj están distribuidas de manera idéntica: yfi ∼ yfj. 2. fi y fj tienen una alta superposición de documentos.",
        "Medición de la similitud de la distribución de características. Medimos la similitud entre dos características fi y fj utilizando la divergencia KL discreta definida de la siguiente manera.",
        "Definición 6. (similitud de características) KL(fi, fj) se da por max(KL(fi|fj), KL(fj|fi)), donde KL(fi|fj) = T t=1 f(yfi(t)|θfi)log f(yfi(t)|θfi) f(yfj(t)|θfj). (1) Dado que la divergencia KL no es simétrica, definimos la similitud entre fi y fj como el máximo entre KL(fi|fj) y KL(fj|fi).",
        "Además, la similitud entre dos características aperiódicas puede calcularse utilizando una forma cerrada de la divergencia de Kullback-Leibler [16].",
        "La misma fórmula discreta de divergencia KL de la Ecuación 1 se emplea para calcular la similitud entre dos características periódicas. A continuación, definimos la similitud general entre un conjunto de características R utilizando el valor máximo de divergencia KL entre características como sigue.",
        "Definición 7. (similitud de conjuntos) KL(R) = max ∀fi, fj ∈R KL(fi, fj).",
        "Superposición de documentos: Sea Mi el conjunto de todos los documentos que contienen la característica fi.",
        "Dadas dos características fi y fj, el conjunto de documentos superpuestos que contienen ambas características es Mi ∩ Mj.",
        "De manera intuitiva, cuanto mayor sea |Mi ∩ Mj|, es más probable que fi y fj estén altamente correlacionados.",
        "Definimos el grado de superposición de documentos entre dos características fi y fj de la siguiente manera.",
        "Definición 8. (Superposición de características DF) d(fi, fj) = |Mi∩Mj| min(|Mi|, |Mj|).",
        "En consecuencia, la superposición de DF entre un conjunto de características R también está definida.",
        "Definición 9. (Superposición de Conjuntos DF) d(R) = min ∀fi, fj ∈R d(fi, fj). 6.2 Detección de Eventos Codiciosa No Supervisada Utilizamos características de HH para detectar eventos aperiódicos importantes, características de LH para detectar eventos aperiódicos menos reportados/poco importantes, y características de HL para detectar eventos periódicos.",
        "Todos comparten el mismo algoritmo.",
        "Dado el rasgo explosivo fi ∈ HH, el objetivo es encontrar rasgos altamente correlacionados de HH.",
        "El conjunto de características similares a fi puede describir colectivamente un evento.",
        "Específicamente, necesitamos encontrar un subconjunto Ri de HH que minimice la siguiente función de costo: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) El evento subyacente e (asociado con la explosión de fi) puede ser representado por Ri como y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) El análisis de la explosión para el evento e es exactamente el mismo que la trayectoria de características.",
        "El costo en la Ecuación 2 se puede minimizar utilizando nuestro algoritmo de detección de eventos UG codicioso no supervisado, que se describe en el Algoritmo 2.",
        "El algoritmo UG permite una característica Algoritmo 2 Detección de eventos codiciosos no supervisados (UG).",
        "Salida: ek como Ec. 3.",
        "Además, los eventos triviales que solo contienen características de año/mes (es decir, un evento que solo contiene una característica de agosto podría ser identificado en un flujo de noticias de 1 año) podrían ser eliminados, aunque dichos eventos tendrán un costo inherente alto y deberían estar clasificados muy bajos.",
        "Tenga en cuenta que nuestro algoritmo UG solo requiere un parámetro dependiente de los datos, el límite entre el espectro de alta y baja potencia, que debe establecerse una vez, y este parámetro puede estimarse fácilmente utilizando el algoritmo HS (Algoritmo 1). 7.",
        "EXPERIMENTOS En esta sección, estudiamos el rendimiento de nuestro método de categorización de características y algoritmo de detección de eventos.",
        "Primero presentamos el conjunto de datos y la configuración experimental, luego evaluamos subjetivamente la categorización de características para HH, HL, LH, LL y SW.",
        "Finalmente, estudiamos el problema de detección de eventos (a)periódicos con el Algoritmo 2. 7.1. Conjunto de datos y configuración experimental El Corpus de Reuters contiene 806,791 noticias en inglés desde el 20/08/1996 hasta el 19/08/1997 con una resolución diaria.",
        "La versión 2 del software de código abierto Lucene [1] se utilizó para tokenizar el contenido de texto de noticias y generar el vector documento-palabra.",
        "Con el fin de preservar los tiempos verbales pasados/presentes/futuros sensibles al tiempo y las diferencias entre los sustantivos en minúscula y las entidades nombradas en mayúscula, no se realizó ningún truncamiento.",
        "Dado que la eliminación dinámica de palabras vacías es una de las funcionalidades de nuestro método, no se eliminó ninguna palabra vacía.",
        "Eliminamos los caracteres no ingleses, sin embargo, después de eso, el número de características de palabras asciende a 423,433.",
        "Todos los experimentos se implementaron en Java y se llevaron a cabo en una PC Pentium 4 de 3.2 GHz con Windows 2003 Server y 1 GB de memoria. 7.2 Categorización de características Descargamos 34 stopwords bien conocidos utilizados por el motor de búsqueda de Google como nuestras características de entrenamiento iniciales, que incluyen a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en y www.",
        "Excluimos las últimas cinco palabras vacías ya que son poco comunes en noticias.",
        "Al analizar solo historias de noticias durante 259 días laborables, calculamos el límite superior del espectro de potencia para las palabras vacías en 11.18 y los rangos correspondientes de DFIDF van desde 0.1182 hasta 0.3691.",
        "Cualquier característica f que cumpla con Sf <= 11.18 y 0.1182 <= DFIDFf <= 0.3691 durante los días de la semana se considerará una palabra vacía.",
        "De esta manera, se encontraron y eliminaron 470 palabras vacías como se muestra en la Figura 9.",
        "Algunas palabras vacías detectadas son A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) y much (P = 22, S = 0.80, DFIDF = 0.1865).",
        "Después de la eliminación de estas palabras vacías, la distribución de las noticias entre semana y los fines de semana están más o menos equilibradas, y en los experimentos subsiguientes, haremos uso del corpus completo (entre semana y fines de semana).",
        "El valor del espectro de potencia límite superior de 11.18 para el entrenamiento de palabras vacías fue seleccionado como el límite entre el espectro de alta potencia y baja potencia.",
        "El límite entre alta y baja periodicidad se estableció en 365/2 = 183.",
        "Todos los 422,963 (423433 − 470) rasgos de palabras fueron categorizados en 4 conjuntos de rasgos: HH (69 rasgos), HL (1,087 rasgos), LH (83,471 rasgos) y LL (338,806 rasgos) como se muestra en la Figura 10.",
        "En la Figura 10, cada nivel de gris denota la densidad relativa de características en una región cuadrada, medida por log10(1 + Dk), donde Dk es el número de características dentro de la k-ésima región cuadrada.",
        "A partir de la figura, podemos hacer el 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figura 9: Distribución de SW (palabras vacías) en las regiones HH, HL, LH y LL. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figura 10: Distribución de características categorizadas en los cuatro cuadrantes (sombreado en escala logarítmica). siguientes observaciones: 1.",
        "La mayoría de las características tienen un valor bajo de S y son fácilmente distinguibles de aquellas características que tienen un valor mucho más alto de S, lo que nos permite detectar eventos importantes (a)periódicos de eventos triviales seleccionando características con un alto valor de S. 2.",
        "Las características en los cuadrantes HH y LH son aperiódicas, las cuales están bien separadas (gran brecha horizontal) de las características periódicas.",
        "Esto permite detectar de manera confiable eventos aperiódicos y eventos periódicos de forma independiente. 3.",
        "La frontera (vertical) entre el espectro de alta y baja potencia no es tan clara y el valor exacto dependerá de la aplicación específica.",
        "Al revisar la distribución de dispersión de las características de SW en HH, HL, LH y LL como se muestra en la Figura 9, encontramos que el 87.02% (409/470) de las stopwords detectadas se originaron en LL.",
        "La clasificación LL y las altas puntuaciones de DFIDF de las palabras vacías concuerdan con la noción generalmente aceptada de que las palabras vacías son igualmente frecuentes en todo momento.",
        "Por lo tanto, establecer el límite entre el espectro de alta y baja potencia utilizando el límite superior Sf de SW es una heurística razonable. 7.3 Detección de Eventos Aperiódicos Evaluaremos nuestras dos hipótesis, 1)los eventos aperiódicos importantes pueden ser definidos por un conjunto de características HH, y 2)los eventos aperiódicos menos reportados pueden ser definidos por un conjunto de características LH.",
        "Dado que no existen flujos de noticias de referencia para la detección de eventos (los conjuntos de datos de TDT no son flujos adecuados), evaluamos la calidad de los eventos detectados automáticamente comparándolos con eventos confirmados manualmente mediante la búsqueda en el corpus.",
        "Entre las 69 características de HH, detectamos 17 eventos aperiódicos importantes como se muestra en la Tabla 1 (e1 - e17).",
        "Ten en cuenta que toda la identificación tomó menos de 1 segundo, después de eliminar los eventos que solo contenían la característica del mes.",
        "De los 17 eventos, aparte de las superposiciones entre e3 y e4 (ambos describen el mismo evento de rehenes), e11 y e16 (ambos sobre informes de empresas), los 14 eventos identificados son extremadamente precisos y corresponden muy bien a los principales eventos del período.",
        "Por ejemplo, la derrota de Bob Dole, la elección de Tony Blair, el ataque con misiles a Iraq, etc.",
        "Recuerde que seleccionar las características para un evento debería minimizar el costo en la Ecuación 2 de tal manera que 1) el número de características abarque diferentes eventos, y 2) no se seleccionarán todas las características relevantes para un evento, por ejemplo, la característica Clinton es representativa para e12, pero dado que Clinton se relaciona con muchos otros eventos, su señal de dominio temporal es muy diferente de la de otras características representativas como Dole y Bob.",
        "El número de documentos de un evento detectado se estima aproximadamente por el número de documentos indexados que contienen las características representativas.",
        "Podemos ver que los 17 eventos aperiódicos importantes son eventos reportados popularmente.",
        "Después de 742 minutos de tiempo de computación, detectamos 23,525 eventos aperiódicos menos reportados de 83,471 características de LH.",
        "La Tabla 1 enumera los 5 principales eventos aperiódicos detectados (e18 - e22) con respecto al costo.",
        "Descubrimos que estos 5 eventos son en realidad eventos muy triviales con solo unos pocos informes de noticias, y suelen ser englobados por algunos temas más grandes.",
        "Por ejemplo, e22 es uno de los eventos de rescate en un tema de secuestro de avión.",
        "Una ventaja de nuestro Algoritmo UG para descubrir eventos aperiódicos poco reportados es que podemos detectar con precisión el verdadero período del evento. 7.4 Detección de Eventos Periódicos Entre las 1,087 características de HL, se detectaron 330 eventos periódicos importantes en un tiempo de cálculo de 10 minutos.",
        "La Tabla 1 enumera los 5 eventos periódicos detectados con respecto al costo (e23 - e27).",
        "Todos los eventos periódicos detectados son realmente válidos y corresponden a eventos periódicos de la vida real.",
        "El modelo GMM es capaz de detectar y estimar el período de ráfagas de manera precisa, aunque no puede distinguir la ligera diferencia entre cada lunes a viernes y todos los días de la semana, como se muestra en e23.",
        "También observamos que e26 es en realidad un subconjunto de e27 (partido de fútbol), lo cual es aceptable ya que los resultados de la liga de Sheffield se anuncian de forma independiente cada fin de semana. 8.",
        "CONCLUSIONES Este artículo adoptó una perspectiva completamente nueva para analizar las trayectorias de características como señales en el dominio del tiempo.",
        "Al considerar las frecuencias de los documentos en el dominio del tiempo y de la frecuencia, pudimos derivar muchas nuevas características sobre los flujos de noticias que antes eran desconocidas, por ejemplo, las diferentes distribuciones de palabras vacías durante los días de la semana y los fines de semana.",
        "Por primera vez en el área de TDT, aplicamos un enfoque sistemático para detectar automáticamente eventos importantes y menos reportados, periódicos y aperiódicos.",
        "La idea clave de nuestro trabajo radica en las observaciones de que los eventos periódicos tienen características representativas periódicas y los eventos (in)importantes tienen características representativas (in)activas, diferenciadas por sus espectros de potencia y períodos de tiempo.",
        "Para abordar el problema de detección de eventos reales, se utilizó un enfoque basado en densidad de mezcla simple y efectivo para identificar ráfagas de características y sus períodos asociados de ráfagas.",
        "También diseñamos un algoritmo codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos, el cual tuvo éxito en detectar eventos reales como se muestra en la evaluación en un flujo de noticias reales.",
        "Aunque no hemos realizado ninguna comparación de referencia con otro enfoque, simplemente porque no hay trabajos previos en el problema abordado.",
        "El trabajo futuro incluye evaluar la recuperación de eventos detectados en un flujo de noticias etiquetado, y comparar nuestro modelo con los métodos equivalentes más cercanos, que actualmente se limitan a los métodos de Kleinberg [12] (que solo pueden detectar ciertos tipos de eventos explosivos dependiendo de la configuración de parámetros), Fung et al. [9], y Swan y Allan [18].",
        "Sin embargo, creemos que nuestro método simple y efectivo será útil para todos los practicantes de TDT, y será especialmente útil para el análisis exploratorio inicial de flujos de noticias.",
        "REFERENCIAS [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Alertas de noticias de Google, http://www.google.com/alerts. [3] Corpus de Reuters, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan.",
        "Detección y seguimiento de temas.",
        "Organización de la información basada en eventos.",
        "Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, y H. Jin.",
        "La detección de la primera historia en tdt es difícil.",
        "En CIKM, páginas 374-381, 2000. [6] J. Allan, C. Wade y A. Bolivar.",
        "Recuperación y detección de novedades a nivel de oración.",
        "En SIGIR, páginas 314-321, 2003. [7] T. Brants, F. Chen y A. Farahat.",
        "Un sistema para la detección de nuevos eventos.",
        "En SIGIR, páginas 330-337, 2003. [8] A. P. Dempster, N. M. Laird y D. B. Rubin.",
        "Máxima verosimilitud a partir de datos incompletos a través del algoritmo EM.",
        "Revista de la Real Sociedad Estadística, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu y H. Lu.",
        "Detección de eventos explosivos sin parámetros en flujos de texto.",
        "En VLDB, páginas 181-192, 2005. [10] Q.",
        "Él, K. Chang y E.-P. Lim.",
        "Un modelo para la detección anticipada de eventos.",
        "En ER, páginas 168-181, 2006. [11] Q.",
        "Él, K. Chang, E.-P. Lim y J. Zhang.",
        "Representación de características intermitentes para la agrupación de flujos de texto.",
        "En SDM, aceptado, 2007. [12] J. Kleinberg.",
        "Estructura explosiva y jerárquica en arroyos.",
        "En SIGKDD, páginas 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan y A. Tomkins.",
        "Sobre la evolución explosiva del blogosfera.",
        "En WWW, páginas 159-178, 2005. [14] G. Kumaran y J. Allan.",
        "Clasificación de texto y entidades nombradas para la detección de nuevos eventos.",
        "En SIGIR, páginas 297-304, 2004. [15] Q. Mei y C. Zhai.",
        "Descubriendo patrones temáticos evolutivos a partir de texto: una exploración de la minería de texto temporal.",
        "En SIGKDD, páginas 198-207, 2005. [16] W. D. Penny.",
        "Divergencias de Kullback-Leibler de densidades normales, gamma, dirichlet y wishart.",
        "Informe técnico, 2001. [17] N. Stokes y J. Carthy.",
        "Combinando clasificadores de documentos semánticos y sintácticos para mejorar la detección de la primera noticia.",
        "En SIGIR, páginas 424-425, 2001. [18] R. Swan y J. Allan.",
        "Generación automática de líneas de tiempo de resumen.",
        "En SIGIR, páginas 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena y D. Gunopulos.",
        "Identificando similitudes, periodicidades y ráfagas en las consultas de búsqueda en línea.",
        "En SIGMOD, páginas 131-142, 2004. [20] Y. Yang, T. Pierce y J. Carbonell.",
        "Un estudio de detección de eventos retrospectivos y en línea.",
        "En SIGIR, páginas 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell y C. Jin.",
        "Detección de novedades condicionada por el tema.",
        "En SIGKDD, páginas 688-693, 2002.",
        "Tabla 1: Todos los eventos aperiódicos importantes (e1 - e17), los 5 eventos aperiódicos menos reportados (e18 - e22) y los 5 eventos periódicos importantes (e23 - e27).",
        "Evento detectado y período de actividad intensa Doc # Verdadero evento e1 (Sali, Berisha, Albania, albanés, marzo) 02/02/199705/29/1997 1409 El presidente albanés Sali Berisha perdió en una elección temprana y renunció, 12/1996-07/1997. e2 (Seko, Mobutu, Sese, Kabila) 03/22/1997-06/09/1997 2273 El presidente de Zaire, Mobutu Sese, coordinó la rebelión nativa y fracasó el 16/05/1997. e3 (Marxista, peruano) 11/19/1996-03/05/1997 824 Los rebeldes de Perú (Movimiento Revolucionario Tupac Amaru) lideraron un asedio de rehenes en Lima a principios de 1997. e4 (Movimiento, Tupac, Amaru, Lima, rehén, rehenes) 11/16/1996-03/20/1997 824 Lo mismo que e3. e5 (Kinshasa, Kabila, Laurent, Congo) 03/26/199706/15/1997 1378 Zaire fue renombrado República Democrática del Congo el 16/05/1997. e6 (Jospin, Lionel, junio) 05/10/1997-07/09/1997 605 Tras las elecciones generales tempranas alrededor de 06/1997, Lionel Jospin fue nombrado Primer Ministro el 02/06/1997. e7 (Irak, misil) 08/31/1996-09/13/1996 1262 EE. UU. disparó un misil a Irak el 03/09/1996 y el 04/09/1996. e8 (kurdo, Bagdad, iraquí) 08/29/1996-09/09/1996 1132 Tropas iraquíes lucharon con facciones kurdas alrededor de 09/1996. e9 (mayo, Blair) 03/24/1997-07/04/1997 1049 Tony Blair se convirtió en el Primer Ministro del Reino Unido el 02/05/1997. e10 (slalom, esquí) 12/05/1996-03/21/1997 253 Juego de eslalon de esquí alpino en 01/1997-02/1997. e11 (Interino, meses) 09/24/1996-12/31/1996 3063 Tokio publicó los resultados interinos de la empresa para los últimos meses en 09/1996-12/1996. e12 (Dole, Bob) 09/09/1996-11/24/1996 1599 Bob Dole perdió las elecciones presidenciales de EE. UU. de 1996. e13 (julio, Sen) 06/25/1997-06/25/1997 344 El Primer Ministro de Camboya, Hun Sen, lanzó un sangriento golpe militar en 07/1997. e14 (Hebrón) 10/15/1996-02/14/1997 2098 Hebrón fue dividida en dos sectores a principios de 1997. e15 (abril, Pascua) 02/23/1997-05/04/1997 480 Festividades de Pascua alrededor de 04/1997 (para occidentales y ortodoxos). e16 (Diluido, Grupo) 04/27/1997-07/20/1997 1888 Tokio publicó todos los resultados del grupo 96/97 en 04/199707/1997. e17 (diciembre, Navidad) 11/17/1996-01/26/1997 1326 Festín de Navidad a finales de 12/1997. e18 (Kolaceva, invierno, Juntos, paseos, Zajedno, Slobodan, Belgrado, serbio, Serbia, Draskovic, municipal, Kragujevac) 1/25/1997 3 Estudiantes universitarios organizaron una vigilia en la calle Kolaceva contra el gobierno el 25/01/1997. e19 (Tutsi, Luvengi, Burundi, Uvira, combustible, Banyamulenge, burundés, Kivu, Kiliba, Runingo, Kagunga, Bwegera) 10/19/1996 6 Estallaron nuevos enfrentamientos alrededor de Uvira entre las fuerzas armadas de Zaire y los rebeldes Tutsi de Banyamulenge el 19/10/1996. e20 (Malantacchi, Corea, Guy, Rider, Sindicatos, trabajo, Confederación, embestido, Ginebra, paradas, Virgin, contratar, Myongdong, Metalúrgicos) 1/11/1997 2 Marcello Malantacchi, secretario general de la Federación Internacional de Metalúrgicos, y Guy Rider, quien dirige la oficina de Ginebra de la Confederación Internacional de Sindicatos Libres, atacaron la nueva ley laboral de Corea del Sur el 11/01/1997. e21 (DBS, Raﬄes) 8/17/1997 9 La lista de la unidad de DBS Land Raﬄes Holdings de Singapur planea el 17/08/1997. e22 (conservador, combustible, Galawa, Huddle, Leul, Beausse) 11/24/1996 3 Rescataron a una mujer y a su bebé durante un secuestro de un avión etíope que se quedó sin combustible y se estrelló en el mar cerca de la playa Le Galawa el 24/11/1996. e23 (PRECIO, LISTADO, MLN, VENCIMIENTO, CUPÓN, MOODY, MONTO, PRIMERO, ISS, TIPO, PAGO, PRESTAMISTA) Lunes a viernes/semana 7966 Anuncian el precio de los bonos todos los días de la semana. e24 (No auditado, Terminado, Meses, Ponderado, Provisión, Costo, Venta, Ingresos, Pérdida, Ingreso, excepto, Shrs, Revs) cada temporada 2264 Informes de ingresos netos-pérdidas publicados por empresas en cada temporada. e25 (calificación, Wall Street, Ian) Lunes a viernes/semana 21767 Informes de acciones de Wall Street todos los días de la semana. e26 (Sheffield, liga, goles de puntuación, delantero, juegos) cada viernes, sábado y domingo 574 Resultados de partidos de la liga de fútbol de Sheffield publicados los viernes, sábados y domingos 10 veces más que en los otros 4 días. e27 (fútbol, partidos, Resultados, temporada, juego, Copa, partido, victoria, vencer, jugado, jugar, división) cada viernes, sábado y domingo 2396 Juegos de fútbol celebrados los viernes, sábados y domingos 7 veces más que en los otros 4 días."
    ],
    "error_count": 1,
    "keys": {
        "event detection": {
            "translated_key": "detección de eventos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Analyzing Feature Trajectories for <br>event detection</br> Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg School of Computer Engineering Nanyang Technological University Block N4, Nanyang Avenue, Singapore 639798 ABSTRACT We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words.",
                "A set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner.",
                "The document frequency of each word across time is treated like a time series, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point.",
                "In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy <br>event detection</br> algorithm to detect both aperiodic and periodic events.",
                "All of the above methods can be applied to time series data in general.",
                "We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events.",
                "Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Experimentation. 1.",
                "INTRODUCTION There are more than 4,000 online news sources in the world.",
                "Manually monitoring all of them for important events has become difficult or practically impossible.",
                "In fact, the topic detection and tracking (TDT) community has for many years been trying to come up with a practical solution to help people monitor news effectively.",
                "Unfortunately, the holy grail is still elusive, because the vast majority of TDT solutions proposed for <br>event detection</br> [20, 5, 17, 4, 21, 7, 14, 10] are either too simplistic (based on cosine similarity [5]) or impractical due to the need to tune a large number of parameters [9].",
                "The ineffectiveness of current TDT technologies can be easily illustrated by subscribing to any of the many online news alerts services such as the industryleading Google News Alerts [2], which generates more than 50% false alarms [10].",
                "As further proof, portals like Yahoo take a more pragmatic approach by requiring all machine generated news alerts to go through a human operator for confirmation before sending them out to subscribers.",
                "Instead of attacking the problem with variations of the same hammer (cosine similarity and TFIDF), a fundamental understanding of the characteristics of news stream data is necessary before any major breakthroughs can be made in TDT.",
                "Thus in this paper, we look at news stories and feature trends from the perspective of analyzing a time-series word signal.",
                "Previous work like [9] has attempted to reconstruct an event with its representative features.",
                "However, in many predictive <br>event detection</br> tasks (i.e., retrospective <br>event detection</br>), there is a vast set of potential features only for a fixed set of observations (i.e., the obvious bursts).",
                "Of these features, often only a small number are expected to be useful.",
                "In particular, we study the novel problem of analyzing feature trajectories for <br>event detection</br>, borrowing a well-known technique from signal processing: identifying distributional correlations among all features by spectral analysis.",
                "To evaluate our method, we subsequently propose an unsupervised <br>event detection</br> algorithm for news streams. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Easter April (a) aperiodic event 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Unaudited Ended (b) periodic event Figure 1: Feature correlation (DFIDF:time) between a) Easter and April b) Unaudited and Ended.",
                "As an illustrative example, consider the correlation between the words Easter and April from the Reuters Corpus1 .",
                "From the plot of their normalized DFIDF in Figure 1(a), we observe the heavy overlap between the two words circa 04/1997, which means they probably both belong to the same event during that time (Easter feast).",
                "In this example, the hidden event Easter feast is a typical important aperiodic event over 1-year data.",
                "Another example is given by Figure 1(b), where both the words Unaudited and Ended 1 Reuters Corpus is the default dataset for all examples. exhibit similar behaviour over periods of 3 months.",
                "These two words actually originated from the same periodic event, net income-loss reports, which are released quarterly by publicly listed companies.",
                "Other observations drawn from Figure 1 are: 1) the bursty period of April is much longer than Easter, which suggests that April may exist in other events during the same period; 2) Unaudited has a higher average DFIDF value than Ended, which indicates Unaudited to be more representative for the underlying event.",
                "These two examples are but the tip of the iceberg among all word trends and correlations hidden in a news stream like Reuters.",
                "If a large number of them can be uncovered, it could significantly aid TDT tasks.",
                "In particular, it indicates the significance of mining correlating features for detecting corresponding events.",
                "To summarize, we postulate that: 1) An event is described by its representative features.",
                "A periodic event has a list of periodic features and an aperiodic event has a list of aperiodic features; 2) Representative features from the same event share similar distributions over time and are highly correlated; 3) An important event has a set of active (largely reported) representative features, whereas an unimportant event has a set of inactive (less-reported) representative features; 4) A feature may be included by several events with overlaps in time frames.",
                "Based on these observations, we can either mine representative features given an event or detect an event from a list of highly correlated features.",
                "In this paper, we focus on the latter, i.e., how correlated features can be uncovered to form an event in an unsupervised manner. 1.1 Contributions This paper has three main contributions: • To the best of our knowledge, our approach is the first to categorize word features for heterogenous events.",
                "Specifically, every word feature is categorized into one of the following five feature types based on its power spectrum strength and periodicity: 1) HH (high power and high/long periodicity): important aperiodic events, 2) HL (high power and low periodicity): important periodic events, 3) LH (low power and high periodicity): unimportant aperiodic events, 4) LL (low power and low periodicity): non-events, and 5) SW (stopwords), a higher power and periodicity subset of LL comprising stopwords, which contains no information. • We propose a simple and effective mixture densitybased approach to model and detect feature bursts. • We come up with an unsupervised <br>event detection</br> algorithm to detect both aperiodic and periodic events.",
                "Our algorithm has been evaluated on a real news stream to show its effectiveness. 2.",
                "RELATED WORK This work is largely motivated by a broader family of problems collectively known as Topic Detection and Tracking (TDT) [20, 5, 17, 4, 21, 7, 14, 10].",
                "Moreover, most TDT research so far has been concerned with clustering/classifying documents into topic types, identifying novel sentences [6] for new events, etc., without much regard to analyzing the word trajectory with respect to time.",
                "Swan and Allan [18] first attempted using co-occuring terms to construct an event.",
                "However, they only considered named entities and noun phrase pairs, without considering their periodicities.",
                "On the contrary, our paper considers all of the above.",
                "Recently, there has been significant interest in modeling an event in text streams as a burst of activities by incorporating temporal information.",
                "Kleinbergs seminal work described how bursty features can be extracted from text streams using an infinite automaton model [12], which inspired a whole series of applications such as Kumars identification of bursty communities from Weblog graphs [13], Meis summarization of evolutionary themes in text streams [15], Hes clustering of text streams using bursty features [11], etc.",
                "Nevertheless, none of the existing work specifically identified features for events, except for Fung et al. [9], who clustered busty features to identify various bursty events.",
                "Our work differs from [9] in several ways: 1) we analyze every single feature, not only bursty features; 2) we classify features along two categorical dimensions (periodicity and power), yielding altogether five primary feature types; 3) we do not restrict each feature to exclusively belong to only one event.",
                "Spectral analysis techniques have previously been used by Vlachos et al. [19] to identify periodicities and bursts from query logs.",
                "Their focus was on detecting multiple periodicities from the power spectrum graph, which were then used to index words for query-by-burst search.",
                "In this paper, we use spectral analysis to classify word features along two dimensions, namely periodicity and power spectrum, with the ultimate goal of identifying both periodic and aperiodic bursty events. 3.",
                "DATA REPRESENTATION Let T be the duration/period (in days) of a news stream, and F represents the complete word feature space in the classical static Vector Space Model (VSM). 3.1 Event Periodicity Classification Within T, there may exist certain events that occur only once, e.g., Tony Blair elected as Prime Minister of U.K., and other recurring events of various periodicities, e.g., weekly soccer matches.",
                "We thus categorize all events into two types: aperiodic and periodic, defined as follows.",
                "Definition 1. (Aperiodic Event) An event is aperiodic within T if it only happens once.",
                "Definition 2. (Periodic Event) If events of a certain event genre occur regularly with a fixed periodicity P ≤ T/2 , we say that this particular event genre is periodic, with each member event qualified as a periodic event.",
                "Note that the definition of aperiodic is relative, i.e., it is true only for a given T, and may be invalid for any other T > T. For example, the event Christmas feast is aperiodic for T ≤ 365 but periodic for T ≥ 730. 3.2 Representative Features Intuitively, an event can be described very concisely by a few discriminative and representative word features and vice-versa, e.g., hurricane, sweep, and strike could be representative features of a Hurricane genre event.",
                "Likewise, a set of strongly correlated features could be used to reconstruct an event description, assuming that strongly correlated features are representative.",
                "The representation vector of a word feature is defined as follows: Definition 3. (Feature Trajectory) The trajectory of a word feature f can be written as the sequence yf = [yf (1), yf (2), . . . , yf (T)], where each element yf (t) is a measure of feature f at time t, which could be defined using the normalized DFIDF score2 yf (t) = DFf (t) N(t) × log( N DFf ), where DFf (t) is the number of documents (local DF) containing feature f at day t, DFf is the total number of documents (global DF) containing feature f over T, N(t) is the number of documents for day t, and N is the total number of documents over T. 4.",
                "IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 Spectral Analysis for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. DFT can represent the original time series as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T.",
                "The original trajectory can be reconstructed with just the dominant frequencies, which can be determined from the power spectrum using the popular periodogram estimator.",
                "The periodogram is a sequence of the squared magnitude of the Fourier coefficients, Xk 2 , k = 1, 2, . . . , T/2 , which indicates the signal power at frequency k/T in the spectrum.",
                "From the power spectrum, the dominant period is chosen as the inverse of the frequency with the highest power spectrum, as follows.",
                "Definition 4. (Dominant Period) The dominant period (DP) of a given feature f is Pf = T/ arg max k Xk 2 .",
                "Accordingly, we have Definition 5. (Dominant Power Spectrum) The dominant power spectrum (DPS) of a given feature f is Sf = Xk 2 , with Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorizing Features The DPS of a feature trajectory is a strong indicator of its activeness at the specified frequency; the higher the DPS, the more likely for the feature to be bursty.",
                "Combining DPS with DP, we therefore categorize all features into four types: 2 We normalize yf (t) as yf (t) = yf (t)/ T i=1 yf (i) so that it could be interpreted as a probability. • HH: high Sf , aperiodic or long-term periodic (Pf > T/2 ); • HL: high Sf , short-term periodic (Pf ≤ T/2 ); • LH: low Sf , aperiodic or long-term periodic; • LL: low Sf , short-term periodic.",
                "The boundary between long-term and short-term periodic is set to T/2 .",
                "However, distinguishing between a high and low DPS is not straightforward, which will be tackled later.",
                "Properties of Different Feature Sets To better understand the properties of HH, HL, LH and LL, we select four features, Christmas, soccer, DBS and your as illustrative examples.",
                "Since the boundary between high and low power spectrum is unclear, these chosen examples have relative wide range of power spectrum values.",
                "Figure 2(a) shows the DFIDF trajectory for Christmas with a distinct burst around Christmas day.",
                "For the 1-year Reuters dataset, Christmas is classified as a typical aperiodic event with Pf = 365 and Sf = 135.68, as shown in Figure 2(b).",
                "Clearly, the value of Sf = 135.68 is reasonable for a well-known bursty event like Christmas. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Christmas(DFIDF:time) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Christmas(S:frequency) Figure 2: Feature Christmas with relative high Sf and long-term Pf .",
                "The DFIDF trajectory for soccer is shown in Figure 3(a), from which we can observe that there is a regular burst every 7 days, which is again verified by its computed value of Pf = 7, as shown in Figure 3(b).",
                "Using the domain knowledge that soccer games have more matches every Saturday, which makes it a typical and heavily reported periodic event, we thus consider the value of Sf = 155.13 to be high. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) soccer(DFIDF:time) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) soccer(S:frequency) Figure 3: Feature soccer with relative high Sf and short-term Pf .",
                "From the DFIDF trajectory for DBS in Figure 4(a), we can immediately deduce DBS to be an infrequent word with a trivial burst on 08/17/1997 corresponding to DBS Land Raﬄes Holdings plans.",
                "This is confirmed by the long period of Pf = 365 and low power of Sf = 0.3084 as shown in Figure 4(b).",
                "Moreover, since this aperiodic event is only reported in a few news stories over a very short time of few days, we therefore say that its low power value of Sf = 0.3084 is representative of unimportant events.",
                "The most confusing example is shown in Figure 5 for the word feature your, which looks very similar to the graph for soccer in Figure 3.",
                "At first glance, we may be tempted to group both your and soccer into the same category of HL or LL since both distributions look similar and have the same dominant period of approximately a week.",
                "However, further 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:time) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frequency) Figure 4: Feature DBS with relative low Sf and long-term Pf . analysis indicates that the periodicity of your is due to the differences in document counts for weekdays (average 2,919 per day) and weekends3 (average 479 per day).",
                "One would have expected the periodicity of a stopword like your to be a day.",
                "Moreover, despite our DFIDF normalization, the weekday/weekend imbalance still prevailed; stopwords occur 4 times more frequently on weekends than on weekdays.",
                "Thus, the DPS remains the only distinguishing factor between your (Sf = 9.42) and soccer (Sf = 155.13).",
                "However, it is very dangerous to simply conclude that a power value of S = 9.42 corresponds to a stopword feature. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) your(DFIDF:time) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) your(S:frequency) Figure 5: Feature your as an example confusing with feature soccer.",
                "Before introducing our solution to this problem, lets look at another LL example as shown in Figure 6 for beenb, which is actually a confirmed typo.",
                "We therefore classify beenb as a noisy feature that does not contribute to any event.",
                "Clearly, the trajectory of your is very different from beenb, which means that the former has to be considered separately. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figure 6: Feature beenb with relative low Sf and short-term Pf .",
                "Stop Words (SW) Feature Set Based on the above analysis, we realize that there must be another feature set between HL and LL that corresponds to the set of stopwords.",
                "Features from this set has moderate DPS and low but known dominant period.",
                "Since it is hard to distinguish this feature set from HL and LL only based on DPS, we introduce another factor called average DFIDF (DFIDF).",
                "As shown in Figure 5, features like your usually have a lower DPS than a HL feature like soccer, but have a much higher DFIDF than another LL noisy feature such as beenb.",
                "Since such properties are usually characteristics of stopwords, we group features like your into the newly defined stopword (SW) feature set.",
                "Since setting the DPS and DFIDF thresholds for identifying stopwords is more of an art than science, we proposed a heuristic HS algorithm, Algorithm 1.",
                "The basic idea is to only use news stories from weekdays to identify stopwords. 3 The weekends here also include public holidays falling on weekdays.",
                "The SW set is initially seeded with a small set of 29 popular stopwords utilized by Google search engine.",
                "Algorithm 1 Heuristic Stopwords detection (HS) Input: Seed SW set, weekday trajectories of all words 1: From the seed set SW, compute the maximum DPS as UDPS, maximum DFIDF as UDFIDF, and minimum of DFIDF as LDFIDF. 2: for fi ∈ F do 3: Compute DFT for fi. 4: if Sfi ≤ UDPS and DFIDFfi ∈ [LDFIDF, UDFIDF] then 5: fi → SW 6: F = F − fi 7: end if 8: end for Overview of Feature Categorization After the SW set is generated, all stopwords are removed from F. We then set the boundary between high and low DPS to be the upper bound of the SW sets DPS.",
                "An overview of all five feature sets is shown in Figure 7.",
                "Figure 7: The 5 feature sets for events. 5.",
                "IDENTIFYING BURSTS FOR FEATURES Since only features from HH, HL and LH are meaningful and could potentially be representative to some events, we pruned all other feature classified as LL or SW.",
                "In this section, we describe how bursts can be identified from the remaining features.",
                "Unlike Kleinbergs burst identification algorithm [12], we can identify both significant and trivial bursts without the need to set any parameters. 5.1 Detecting Aperiodic Features Bursts For each feature in HH and HL, we truncate its trajectory by keeping only the bursty period, which is modeled with a Gaussian distribution.",
                "For example, Figure 8 shows the word feature Iraq with a burst circa 09/06/1996 being modeled as a Gaussian.",
                "Its bursty period is defined by [μf − σf , μf + σf ] as shown in Figure 8(b). 5.2 Detecting Periodic Features Bursts Since we have computed the DP for a periodic feature f, we can easily model its periodic feature trajectory yf using 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) original DFIDF:time 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 burst= [μ-σ, μ+σ] (b) identifying burst Figure 8: Modeling Iraqs time series as a truncated Gaussian with μ = 09/06/1996 and σ = 6.26. a mixture of K = T/Pf Gaussians: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , where the parameter set θf = {αk, μk, σk}K k=1 comprises: • αk is the probability of assigning yf into the kth Gaussian. αk > 0, ∀k ∈ [1, K] and K k=1 αk = 1; • μk/σk is mean/standard deviation of the kth Gaussian.",
                "The well known Expectation Maximization (EM) [8] algorithm is used to compute the mixing proportions αk, as well as the individual Gaussian density parameters μk and σK .",
                "Each Gaussian represents one periodic event, and is modeled similarly as mentioned in Section 5.1. 6.",
                "EVENTS FROM FEATURES After identifying and modeling bursts for all features, the next task is to paint a picture of the event with a potential set of representative features. 6.1 Feature Correlation If two features fi and fj are representative of the same event, they must satisfy the following necessary conditions: 1. fi and fj are identically distributed: yfi ∼ yfj . 2. fi and fj have a high document overlap.",
                "Measuring Feature Distribution Similarity We measure the similarity between two features fi and fj using discrete KL-divergence defined as follows.",
                "Definition 6. (feature similarity) KL(fi, fj ) is given by max(KL(fi|fj ), KL(fj |fi)), where KL(fi|fj ) = T t=1 f(yfi (t)|θfi )log f(yfi (t)|θfi ) f(yfj (t)|θfj ) . (1) Since KL-divergence is not symmetric, we define the similarity between between fi and fj as the maximum of KL(fi|fj ) and KL(fj |fi).",
                "Further, the similarity between two aperiodic features can be computed using a closed form of the KL-divergence [16].",
                "The same discrete KL-divergence formula of Eq. 1 is employed to compute the similarity between two periodic features, Next, we define the overal similarity among a set of features R using the maximum inter-feature KL-Divergence value as follows.",
                "Definition 7. (sets similarity)KL(R) = max ∀fi,fj ∈R KL(fi, fj ).",
                "Document Overlap Let Mi be the set of all documents containing feature fi.",
                "Given two features fi and fj , the overlapping document set containing both features is Mi ∩ Mj .",
                "Intuitively, the higher the |Mi ∩ Mj |, the more likelty that fi and fj will be highly correlated.",
                "We define the degree of document overlap between two features fi and fj as follows.",
                "Definition 8. (Feature DF Overlap) d(fi, fj ) = |Mi∩Mj| min(|Mi|,|Mj|) .",
                "Accordingly, the DF Overlap among a set of features R is also defined.",
                "Definition 9. (Set DF Overlap) d(R) = min ∀fi,fj ∈R d(fi, fj). 6.2 Unsupervised Greedy <br>event detection</br> We use features from HH to detect important aperiodic events, features from LH to detect less-reported/unimportant aperiodic events, and features from HL to detect periodic events.",
                "All of them share the same algorithm.",
                "Given bursty feature fi ∈ HH, the goal is to find highly correlated features from HH.",
                "The set of features similar to fi can then collectively describe an event.",
                "Specifically, we need to find a subset Ri of HH that minimizes the following cost function: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) The underlying event e (associated with the burst of fi) can be represented by Ri as y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) The burst analysis for event e is exactly the same as the feature trajectory.",
                "The cost in Eq. 2 can be minimized using our unsupervised greedy UG <br>event detection</br> algorithm, which is described in Algorithm 2.",
                "The UG algorithm allows a feature Algorithm 2 Unsupervised Greedy <br>event detection</br> (UG).",
                "Input: HH, document index for each feature. 1: Sort and select features in descending DPS order: Sf1 ≥ Sf2 ≥ . . . ≥ Sf|HH| . 2: k = 0. 3: for fi ∈ HH do 4: k = k + 1. 5: Init: Ri ← fi, C(Ri) = 1/Sfi and HH = HH − fi. 6: while HH not empty do 7: m = arg min m C(Ri ∪ fm). 8: if C(Ri ∪ fm) < C(Ri) then 9: Ri ← fm and HH = HH − fm. 10: else 11: break while. 12: end if 13: end while 14: Output ek as Eq. 3. 15: end for to be contained in multiple events so that we can detect several events happening at the same time.",
                "Furthermore, trivial events only containing year/month features (i.e., an event only containing 1 feature Aug could be identified over a 1year news stream) could be removed, although such events will have inherent high cost and should already be ranked very low.",
                "Note that our UG algorithm only requires one data-dependant parameter, the boundary between high and low power spectrum, to be set once, and this parameter can be easily estimated using the HS algorithm (Algorithm 1). 7.",
                "EXPERIMENTS In this section, we study the performances of our feature categorizing method and <br>event detection</br> algorithm.",
                "We first introduce the dataset and experimental setup, then we subjectively evaluate the categorization of features for HH, HL, LH, LL and SW.",
                "Finally, we study the (a)periodic <br>event detection</br> problem with Algorithm 2. 7.1 Dataset and Experimental Setup The Reuters Corpus contains 806,791 English news stories from 08/20/1996 to 08/19/1997 at a day resolution.",
                "Version 2 of the open source Lucene software [1] was used to tokenize the news text content and generate the document-word vector.",
                "In order to preserve the time-sensitive past/present/future tenses of verbs and the differences between lower case nouns and upper case named entities, no stemming was done.",
                "Since dynamic stopword removal is one of the functionalities of our method, no stopword was removed.",
                "We did remove nonEnglish characters, however, after which the number of word features amounts to 423,433.",
                "All experiments were implemented in Java and conducted on a 3.2 GHz Pentium 4 PC running Windows 2003 Server with 1 GB of memory. 7.2 Categorizing Features We downloaded 34 well-known stopwords utilized by the Google search engine as our seed training features, which includes a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en and www.",
                "We excluded the last five stopwords as they are uncommon in news stories.",
                "By only analyzing news stories over 259 weekdays, we computed the upper bound of the power spectrum for stopwords at 11.18 and corresponding DFIDF ranges from 0.1182 to 0.3691.",
                "Any feature f satisfying Sf <= 11.18 and 0.1182 <= DFIDFf <= 0.3691 over weekdays will be considered a stopword.",
                "In this manner, 470 stopwords were found and removed as visualized in Figure 9.",
                "Some detected stopwords are A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) and much (P = 22, S = 0.80, DFIDF = 0.1865).",
                "After the removal of these stopwords, the distribution of weekday and weekend news are more or less matched, and in the ensuing experiments, we shall make use of the full corpus (weekdays and weekends).",
                "The upper bound power spectrum value of 11.18 for stopwords training was selected as the boundary between the high power and low power spectrum.",
                "The boundary between high and low periodicity was set to 365/2 = 183.",
                "All 422,963 (423433 − 470) word features were categorized into 4 feature sets: HH (69 features), HL (1,087 features), LH (83,471 features), and LL (338,806 features) as shown in Figure 10.",
                "In Figure 10, each gray level denotes the relative density of features in a square region, measured by log10(1 + Dk), where Dk is the number of features within the k-th square region.",
                "From the figure, we can make the 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figure 9: Distribution of SW (stopwords) in the HH, HL, LH, and LL regions. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figure 10: Distribution of categorized features over the four quadrants (shading in log scale). following observations: 1.",
                "Most features have low S and are easily distinguishable from those features having a much higher S, which allows us to detect important (a)periodic events from trivial events by selecting features with high S. 2.",
                "Features in the HH and LH quadrants are aperiodic, which are nicely separated (big horizontal gap) from the periodic features.",
                "This allows reliably detecting aperiodic events and periodic events independently. 3.",
                "The (vertical) boundary between high and low power spectrum is not as clearcut and the exact value will be application specific.",
                "By checking the scatter distribution of features from SW on HH, HL, LH, and LL as shown in Figure 9, we found that 87.02%(409/470) of the detected stopwords originated from LL.",
                "The LL classification and high DFIDF scores of stopwords agree with the generally accepted notion that stopwords are equally frequent over all time.",
                "Therefore, setting the boundary between high and low power spectrum using the upper bound Sf of SW is a reasonable heuristic. 7.3 Detecting Aperiodic Events We shall evaluate our two hypotheses, 1)important aperiodic events can be defined by a set of HH features, and 2)less reported aperiodic events can be defined by a set of LH features.",
                "Since no benchmark news streams exist for <br>event detection</br> (TDT datasets are not proper streams), we evaluate the quality of the automatically detected events by comparing them to manually-confirmed events by searching through the corpus.",
                "Among the 69 HH features, we detected 17 important aperiodic events as shown in Table 1 (e1 − e17).",
                "Note that the entire identification took less than 1 second, after removing events containing only the month feature.",
                "Among the 17 events, other than the overlaps between e3 and e4 (both describes the same hostage event), e11 and e16 (both about company reports), the 14 identified events are extremely accurate and correspond very well to the major events of the period.",
                "For example, the defeat of Bob Dole, election of Tony Blair, Missile attack on Iraq, etc.",
                "Recall that selecting the features for one event should minimize the cost in Eq. 2 such that 1) the number of features span different events, and 2) not all features relevant to an event will be selected, e.g., the feature Clinton is representative to e12 but since Clinton relates to many other events, its time domain signal is far different from those of other representative features like Dole and Bob.",
                "The number of documents of a detected event is roughly estimated by the number of indexed documents containing the representative features.",
                "We can see that all 17 important aperiodic events are popularly reported events.",
                "After 742 minutes of computation time, we detected 23, 525 less reported aperiodic events from 83,471 LH features.",
                "Table 1 lists the top 5 detected aperiodic events (e18 − e22) with respect to the cost.",
                "We found that these 5 events are actually very trivial events with only a few news reports, and are usually subsumed by some larger topics.",
                "For example, e22 is one of the rescue events in an airplane hijack topic.",
                "One advantage of our UG Algorithm for discovering less-reported aperiodic events is that we are able to precisely detect the true event period. 7.4 Detecting Periodic Events Among the 1,087 HL features, 330 important periodic events were detected within 10 minutes of computing time.",
                "Table 1 lists the top 5 detected periodic events with respect to the cost (e23 − e27).",
                "All of the detected periodic events are indeed valid, and correspond to real life periodic events.",
                "The GMM model is able to detect and estimate the bursty period nicely although it cannot distinguish the slight difference between every Monday-Friday and all weekdays as shown in e23.",
                "We also notice that e26 is actually a subset of e27 (soccer game), which is acceptable since the Sheffield league results are announced independently every weekend. 8.",
                "CONCLUSIONS This paper took a whole new perspective of analyzing feature trajectories as time domain signals.",
                "By considering the word document frequencies in both time and frequency domains, we were able to derive many new characteristics about news streams that were previously unknown, e.g., the different distributions of stopwords during weekdays and weekends.",
                "For the first time in the area of TDT, we applied a systematic approach to automatically detect important and less-reported, periodic and aperiodic events.",
                "The key idea of our work lies in the observations that (a)periodic events have (a)periodic representative features and (un)important events have (in)active representative features, differentiated by their power spectrums and time periods.",
                "To address the real <br>event detection</br> problem, a simple and effective mixture density-based approach was used to identify feature bursts and their associated bursty periods.",
                "We also designed an unsupervised greedy algorithm to detect both aperiodic and periodic events, which was successful in detecting real events as shown in the evaluation on a real news stream.",
                "Although we have not made any benchmark comparison against another approach, simply because there is no previous work in the addressed problem.",
                "Future work includes evaluating the recall of detected events for a labeled news stream, and comparing our model against the closest equivalent methods, which currently are limited to the methods of Kleinberg [12] (which can only detect certain type of bursty events depending on parameter settings), Fung et al. [9], and Swan and Allan [18].",
                "Nevertheless, we believe our simple and effective method will be useful for all TDT practitioners, and will be especially useful for the initial exploratory analysis of news streams. 9.",
                "REFERENCES [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Google news alerts, http://www.google.com/alerts. [3] Reuters corpus, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan.",
                "Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, and H. Jin.",
                "First story detection in tdt is hard.",
                "In CIKM, pages 374-381, 2000. [6] J. Allan, C. Wade, and A. Bolivar.",
                "Retrieval and novelty detection at the sentence level.",
                "In SIGIR, pages 314-321, 2003. [7] T. Brants, F. Chen, and A. Farahat.",
                "A system for new <br>event detection</br>.",
                "In SIGIR, pages 330-337, 2003. [8] A. P. Dempster, N. M. Laird, and D. B. Rubin.",
                "Maximum likelihood from incomplete data via the EM algorithm.",
                "Journal of the Royal Statistical Society, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu, and H. Lu.",
                "Parameter free bursty events detection in text streams.",
                "In VLDB, pages 181-192, 2005. [10] Q.",
                "He, K. Chang, and E.-P. Lim.",
                "A model for anticipatory <br>event detection</br>.",
                "In ER, pages 168-181, 2006. [11] Q.",
                "He, K. Chang, E.-P. Lim, and J. Zhang.",
                "Bursty feature reprensentation for clustering text streams.",
                "In SDM, accepted, 2007. [12] J. Kleinberg.",
                "Bursty and hierarchical structure in streams.",
                "In SIGKDD, pages 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins.",
                "On the bursty evolution of blogspace.",
                "In WWW, pages 159-178, 2005. [14] G. Kumaran and J. Allan.",
                "Text classification and named entities for new <br>event detection</br>.",
                "In SIGIR, pages 297-304, 2004. [15] Q. Mei and C. Zhai.",
                "Discovering evolutionary theme patterns from text: an exploration of temporal text mining.",
                "In SIGKDD, pages 198-207, 2005. [16] W. D. Penny.",
                "Kullback-liebler divergences of normal, gamma, dirichlet and wishart densities.",
                "Technical report, 2001. [17] N. Stokes and J. Carthy.",
                "Combining semantic and syntactic document classifiers to improve first story detection.",
                "In SIGIR, pages 424-425, 2001. [18] R. Swan and J. Allan.",
                "Automatic generation of overview timelines.",
                "In SIGIR, pages 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena, and D. Gunopulos.",
                "Identifying similarities, periodicities and bursts for online search queries.",
                "In SIGMOD, pages 131-142, 2004. [20] Y. Yang, T. Pierce, and J. Carbonell.",
                "A study of retrospective and on-line <br>event detection</br>.",
                "In SIGIR, pages 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topic-conditioned novelty detection.",
                "In SIGKDD, pages 688-693, 2002.",
                "Table 1: All important aperiodic events (e1 − e17), top 5 less-reported aperiodic events (e18 − e22) and top 5 important periodic events (e23 − e27).",
                "Detected Event and Bursty Period Doc # True Event e1(Sali,Berisha,Albania,Albanian,March) 02/02/199705/29/1997 1409 Albanians president Sali Berisha lost in an early election and resigned, 12/1996-07/1997. e2(Seko,Mobutu,Sese,Kabila) 03/22/1997-06/09/1997 2273 Zaires president Mobutu Sese coordinated the native rebellion and failed on 05/16/1997. e3(Marxist,Peruvian) 11/19/1996-03/05/1997 824 Peru rebels (Tupac Amaru revolutionary Movement) led a hostage siege in Lima in early 1997. e4(Movement,Tupac,Amaru,Lima,hostage,hostages) 11/16/1996-03/20/1997 824 The same as e3. e5(Kinshasa,Kabila,Laurent,Congo) 03/26/199706/15/1997 1378 Zaire was renamed the Democratic Republic of Congo on 05/16/1997. e6(Jospin,Lionel,June) 05/10/1997-07/09/1997 605 Following the early General Elections circa 06/1997, Lionel Jospin was appointed Prime Minister on 06/02/1997. e7(Iraq,missile) 08/31/1996-09/13/1996 1262 U.S. fired missile at Iraq on 09/03/1996 and 09/04/1996. e8(Kurdish,Baghdad,Iraqi) 08/29/1996-09/09/1996 1132 Iraqi troop fought with Kurdish faction circa 09/1996. e9(May,Blair) 03/24/1997-07/04/1997 1049 Tony Blair became the Primary Minister of the United Kingdom on 05/02/1997. e10(slalom,skiing) 12/05/1996-03/21/1997 253 Slalom Game of Alpine Skiing in 01/1997-02/1997. e11(Interim,months) 09/24/1996-12/31/1996 3063 Tokyo released company interim results for the past several months in 09/1996-12/1996. e12(Dole,Bob) 09/09/1996-11/24/1996 1599 Dole Bob lost the 1996 US presidential election. e13(July,Sen) 06/25/1997-06/25/1997 344 Cambodias Prime Minister Hun Sen launched a bloody military coup in 07/1997. e14(Hebron) 10/15/1996-02/14/1997 2098 Hebron was divided into two sectors in early 1997. e15(April,Easter) 02/23/1997-05/04/1997 480 Easter feasts circa 04/1997 (for western and Orthodox). e16(Diluted,Group) 04/27/1997-07/20/1997 1888 Tokyo released all 96/97 group results in 04/199707/1997. e17(December,Christmas) 11/17/1996-01/26/1997 1326 Christmas feast in late 12/1997. e18(Kolaceva,winter,Together,promenades,Zajedno, Slobodan,Belgrade,Serbian,Serbia,Draskovic,municipal, Kragujevac) 1/25/1997 3 University students organized a vigil on Kolaceva street against government on 1/25/1997. e19(Tutsi,Luvengi,Burundi,Uvira,fuel,Banyamulenge, Burundian,Kivu,Kiliba,Runingo,Kagunga,Bwegera) 10/19/1996 6 Fresh fighting erupted around Uvira between Zaire armed forces and Banyamulengs Tutsi rebels on 10/19/1996. e20(Malantacchi,Korea,Guy,Rider,Unions,labour, Trade,unions,Confederation,rammed,Geneva,stoppages, Virgin,hire,Myongdong,Metalworkers) 1/11/1997 2 Marcello Malantacchi secretary general of the International Metalworkers Federation and Guy Rider who heads the Geneva office of the International Confederation of Free Trade Unions attacked the new labour law of South Korea on 1/11/1997. e21(DBS,Raﬄes) 8/17/1997 9 The list of the unit of Singapore DBS Land Raﬄes Holdings plans on 8/17/1997. e22(preserver,fuel,Galawa,Huddle,Leul,Beausse) 11/24/1996 3 Rescued a woman and her baby during a hijacked Ethiopian plane that ran out of fuel and crashed into the sea near Le Galawa beach on 11/24/1996. e23(PRICE,LISTING,MLN,MATURITY,COUPON, MOODY,AMT,FIRST,ISS,TYPE,PAY,BORROWER) Monday-Friday/week 7966 Announce bond price on all weekdays. e24(Unaudited,Ended,Months,Weighted,Provision,Cost, Selling,Revenues,Loss,Income,except,Shrs,Revs) every season 2264 Net income-loss reports released by companies in every season. e25(rating,Wall,Street,Ian) Monday-Friday/week 21767 Stock reports from Wall Street on all weekdays. e26(Sheffield,league,scoring,goals,striker,games) every Friday, Saturday and Sunday 574 Match results of Sheffield soccer league were published on Friday, Saturday and Sunday 10 times than other 4 days. e27(soccer,matches,Results,season,game,Cup,match, victory,beat,played,play,division) every Friday, Saturday and Sunday 2396 Soccer games held on Friday, Saturday and Sunday 7 times than other 4 days."
            ],
            "original_annotated_samples": [
                "Analyzing Feature Trajectories for <br>event detection</br> Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg School of Computer Engineering Nanyang Technological University Block N4, Nanyang Avenue, Singapore 639798 ABSTRACT We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words.",
                "In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy <br>event detection</br> algorithm to detect both aperiodic and periodic events.",
                "Unfortunately, the holy grail is still elusive, because the vast majority of TDT solutions proposed for <br>event detection</br> [20, 5, 17, 4, 21, 7, 14, 10] are either too simplistic (based on cosine similarity [5]) or impractical due to the need to tune a large number of parameters [9].",
                "However, in many predictive <br>event detection</br> tasks (i.e., retrospective <br>event detection</br>), there is a vast set of potential features only for a fixed set of observations (i.e., the obvious bursts).",
                "In particular, we study the novel problem of analyzing feature trajectories for <br>event detection</br>, borrowing a well-known technique from signal processing: identifying distributional correlations among all features by spectral analysis."
            ],
            "translated_annotated_samples": [
                "Analizando Trayectorias de Características para la Detección de Eventos Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg Escuela de Ingeniería Informática Universidad Tecnológica de Nanyang Bloque N4, Avenida Nanyang, Singapur 639798 RESUMEN Consideramos el problema de analizar trayectorias de palabras en los dominios del tiempo y la frecuencia, con el objetivo específico de identificar palabras importantes y menos reportadas, periódicas y aperiódicas.",
                "En este artículo, 1) primero aplicamos análisis espectral para categorizar características de diferentes tipos de eventos: importantes y poco reportados, periódicos y aperiódicos; 2) modelamos las características aperiódicas con densidad gaussiana y las características periódicas con densidades de mezcla gaussiana, y posteriormente detectamos cada ráfaga de características mediante el enfoque gaussiano truncado; 3) propusimos un algoritmo de <br>detección de eventos</br> codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos.",
                "Desafortunadamente, el Santo Grial sigue siendo esquivo, ya que la gran mayoría de las soluciones de TDT propuestas para la <br>detección de eventos</br> [20, 5, 17, 4, 21, 7, 14, 10] son demasiado simplistas (basadas en la similitud del coseno [5]) o impracticables debido a la necesidad de ajustar un gran número de parámetros [9].",
                "Sin embargo, en muchas tareas de <br>detección de eventos</br> predictivos (es decir, <br>detección de eventos</br> retrospectivos), hay un vasto conjunto de características potenciales solo para un conjunto fijo de observaciones (es decir, los estallidos obvios).",
                "En particular, estudiamos el novedoso problema de analizar trayectorias de características para la <br>detección de eventos</br>, utilizando una técnica conocida de procesamiento de señales: identificar correlaciones distribucionales entre todas las características mediante análisis espectral."
            ],
            "translated_text": "Analizando Trayectorias de Características para la Detección de Eventos Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg Escuela de Ingeniería Informática Universidad Tecnológica de Nanyang Bloque N4, Avenida Nanyang, Singapur 639798 RESUMEN Consideramos el problema de analizar trayectorias de palabras en los dominios del tiempo y la frecuencia, con el objetivo específico de identificar palabras importantes y menos reportadas, periódicas y aperiódicas. Un conjunto de palabras con tendencias idénticas puede agruparse para reconstruir un evento de manera completamente no supervisada. La frecuencia del documento de cada palabra a lo largo del tiempo se trata como una serie temporal, donde cada elemento es el puntaje de frecuencia del documento - frecuencia inversa del documento (DFIDF) en un punto temporal. En este artículo, 1) primero aplicamos análisis espectral para categorizar características de diferentes tipos de eventos: importantes y poco reportados, periódicos y aperiódicos; 2) modelamos las características aperiódicas con densidad gaussiana y las características periódicas con densidades de mezcla gaussiana, y posteriormente detectamos cada ráfaga de características mediante el enfoque gaussiano truncado; 3) propusimos un algoritmo de <br>detección de eventos</br> codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos. Todos los métodos anteriores se pueden aplicar a datos de series temporales en general. Evaluamos exhaustivamente nuestros métodos en el Corpus de Noticias de Reuters de 1 año [3] y demostramos que fueron capaces de descubrir eventos significativos aperiódicos y periódicos. Categorías y Descriptores de Asignaturas: H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales: Algoritmos, Experimentación. 1. INTRODUCCIÓN Hay más de 4,000 fuentes de noticias en línea en el mundo. Supervisar manualmente todos ellos en busca de eventos importantes se ha vuelto difícil o prácticamente imposible. De hecho, la comunidad de detección y seguimiento de temas (TDT) ha estado tratando durante muchos años de encontrar una solución práctica para ayudar a las personas a monitorear las noticias de manera efectiva. Desafortunadamente, el Santo Grial sigue siendo esquivo, ya que la gran mayoría de las soluciones de TDT propuestas para la <br>detección de eventos</br> [20, 5, 17, 4, 21, 7, 14, 10] son demasiado simplistas (basadas en la similitud del coseno [5]) o impracticables debido a la necesidad de ajustar un gran número de parámetros [9]. La ineficacia de las tecnologías actuales de TDT se puede ilustrar fácilmente suscribiéndose a cualquiera de los muchos servicios de alertas de noticias en línea, como el líder de la industria Google News Alerts, que genera más del 50% de falsas alarmas. Como prueba adicional, portales como Yahoo adoptan un enfoque más pragmático al requerir que todas las alertas de noticias generadas por máquinas pasen por un operador humano para su confirmación antes de enviarlas a los suscriptores. En lugar de abordar el problema con variaciones del mismo martillo (similitud coseno y TFIDF), es necesario contar con una comprensión fundamental de las características de los datos de flujo de noticias antes de que se puedan lograr avances importantes en TDT. Por lo tanto, en este artículo, examinamos noticias y tendencias de características desde la perspectiva de analizar una señal de palabras de series temporales. Trabajos anteriores como [9] han intentado reconstruir un evento con sus características representativas. Sin embargo, en muchas tareas de <br>detección de eventos</br> predictivos (es decir, <br>detección de eventos</br> retrospectivos), hay un vasto conjunto de características potenciales solo para un conjunto fijo de observaciones (es decir, los estallidos obvios). De estas características, a menudo solo se espera que un pequeño número sea útil. En particular, estudiamos el novedoso problema de analizar trayectorias de características para la <br>detección de eventos</br>, utilizando una técnica conocida de procesamiento de señales: identificar correlaciones distribucionales entre todas las características mediante análisis espectral. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "word trajectory": {
            "translated_key": "trayectoria de las palabras",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Analyzing Feature Trajectories for Event Detection Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg School of Computer Engineering Nanyang Technological University Block N4, Nanyang Avenue, Singapore 639798 ABSTRACT We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words.",
                "A set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner.",
                "The document frequency of each word across time is treated like a time series, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point.",
                "In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events.",
                "All of the above methods can be applied to time series data in general.",
                "We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events.",
                "Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Experimentation. 1.",
                "INTRODUCTION There are more than 4,000 online news sources in the world.",
                "Manually monitoring all of them for important events has become difficult or practically impossible.",
                "In fact, the topic detection and tracking (TDT) community has for many years been trying to come up with a practical solution to help people monitor news effectively.",
                "Unfortunately, the holy grail is still elusive, because the vast majority of TDT solutions proposed for event detection [20, 5, 17, 4, 21, 7, 14, 10] are either too simplistic (based on cosine similarity [5]) or impractical due to the need to tune a large number of parameters [9].",
                "The ineffectiveness of current TDT technologies can be easily illustrated by subscribing to any of the many online news alerts services such as the industryleading Google News Alerts [2], which generates more than 50% false alarms [10].",
                "As further proof, portals like Yahoo take a more pragmatic approach by requiring all machine generated news alerts to go through a human operator for confirmation before sending them out to subscribers.",
                "Instead of attacking the problem with variations of the same hammer (cosine similarity and TFIDF), a fundamental understanding of the characteristics of news stream data is necessary before any major breakthroughs can be made in TDT.",
                "Thus in this paper, we look at news stories and feature trends from the perspective of analyzing a time-series word signal.",
                "Previous work like [9] has attempted to reconstruct an event with its representative features.",
                "However, in many predictive event detection tasks (i.e., retrospective event detection), there is a vast set of potential features only for a fixed set of observations (i.e., the obvious bursts).",
                "Of these features, often only a small number are expected to be useful.",
                "In particular, we study the novel problem of analyzing feature trajectories for event detection, borrowing a well-known technique from signal processing: identifying distributional correlations among all features by spectral analysis.",
                "To evaluate our method, we subsequently propose an unsupervised event detection algorithm for news streams. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Easter April (a) aperiodic event 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Unaudited Ended (b) periodic event Figure 1: Feature correlation (DFIDF:time) between a) Easter and April b) Unaudited and Ended.",
                "As an illustrative example, consider the correlation between the words Easter and April from the Reuters Corpus1 .",
                "From the plot of their normalized DFIDF in Figure 1(a), we observe the heavy overlap between the two words circa 04/1997, which means they probably both belong to the same event during that time (Easter feast).",
                "In this example, the hidden event Easter feast is a typical important aperiodic event over 1-year data.",
                "Another example is given by Figure 1(b), where both the words Unaudited and Ended 1 Reuters Corpus is the default dataset for all examples. exhibit similar behaviour over periods of 3 months.",
                "These two words actually originated from the same periodic event, net income-loss reports, which are released quarterly by publicly listed companies.",
                "Other observations drawn from Figure 1 are: 1) the bursty period of April is much longer than Easter, which suggests that April may exist in other events during the same period; 2) Unaudited has a higher average DFIDF value than Ended, which indicates Unaudited to be more representative for the underlying event.",
                "These two examples are but the tip of the iceberg among all word trends and correlations hidden in a news stream like Reuters.",
                "If a large number of them can be uncovered, it could significantly aid TDT tasks.",
                "In particular, it indicates the significance of mining correlating features for detecting corresponding events.",
                "To summarize, we postulate that: 1) An event is described by its representative features.",
                "A periodic event has a list of periodic features and an aperiodic event has a list of aperiodic features; 2) Representative features from the same event share similar distributions over time and are highly correlated; 3) An important event has a set of active (largely reported) representative features, whereas an unimportant event has a set of inactive (less-reported) representative features; 4) A feature may be included by several events with overlaps in time frames.",
                "Based on these observations, we can either mine representative features given an event or detect an event from a list of highly correlated features.",
                "In this paper, we focus on the latter, i.e., how correlated features can be uncovered to form an event in an unsupervised manner. 1.1 Contributions This paper has three main contributions: • To the best of our knowledge, our approach is the first to categorize word features for heterogenous events.",
                "Specifically, every word feature is categorized into one of the following five feature types based on its power spectrum strength and periodicity: 1) HH (high power and high/long periodicity): important aperiodic events, 2) HL (high power and low periodicity): important periodic events, 3) LH (low power and high periodicity): unimportant aperiodic events, 4) LL (low power and low periodicity): non-events, and 5) SW (stopwords), a higher power and periodicity subset of LL comprising stopwords, which contains no information. • We propose a simple and effective mixture densitybased approach to model and detect feature bursts. • We come up with an unsupervised event detection algorithm to detect both aperiodic and periodic events.",
                "Our algorithm has been evaluated on a real news stream to show its effectiveness. 2.",
                "RELATED WORK This work is largely motivated by a broader family of problems collectively known as Topic Detection and Tracking (TDT) [20, 5, 17, 4, 21, 7, 14, 10].",
                "Moreover, most TDT research so far has been concerned with clustering/classifying documents into topic types, identifying novel sentences [6] for new events, etc., without much regard to analyzing the <br>word trajectory</br> with respect to time.",
                "Swan and Allan [18] first attempted using co-occuring terms to construct an event.",
                "However, they only considered named entities and noun phrase pairs, without considering their periodicities.",
                "On the contrary, our paper considers all of the above.",
                "Recently, there has been significant interest in modeling an event in text streams as a burst of activities by incorporating temporal information.",
                "Kleinbergs seminal work described how bursty features can be extracted from text streams using an infinite automaton model [12], which inspired a whole series of applications such as Kumars identification of bursty communities from Weblog graphs [13], Meis summarization of evolutionary themes in text streams [15], Hes clustering of text streams using bursty features [11], etc.",
                "Nevertheless, none of the existing work specifically identified features for events, except for Fung et al. [9], who clustered busty features to identify various bursty events.",
                "Our work differs from [9] in several ways: 1) we analyze every single feature, not only bursty features; 2) we classify features along two categorical dimensions (periodicity and power), yielding altogether five primary feature types; 3) we do not restrict each feature to exclusively belong to only one event.",
                "Spectral analysis techniques have previously been used by Vlachos et al. [19] to identify periodicities and bursts from query logs.",
                "Their focus was on detecting multiple periodicities from the power spectrum graph, which were then used to index words for query-by-burst search.",
                "In this paper, we use spectral analysis to classify word features along two dimensions, namely periodicity and power spectrum, with the ultimate goal of identifying both periodic and aperiodic bursty events. 3.",
                "DATA REPRESENTATION Let T be the duration/period (in days) of a news stream, and F represents the complete word feature space in the classical static Vector Space Model (VSM). 3.1 Event Periodicity Classification Within T, there may exist certain events that occur only once, e.g., Tony Blair elected as Prime Minister of U.K., and other recurring events of various periodicities, e.g., weekly soccer matches.",
                "We thus categorize all events into two types: aperiodic and periodic, defined as follows.",
                "Definition 1. (Aperiodic Event) An event is aperiodic within T if it only happens once.",
                "Definition 2. (Periodic Event) If events of a certain event genre occur regularly with a fixed periodicity P ≤ T/2 , we say that this particular event genre is periodic, with each member event qualified as a periodic event.",
                "Note that the definition of aperiodic is relative, i.e., it is true only for a given T, and may be invalid for any other T > T. For example, the event Christmas feast is aperiodic for T ≤ 365 but periodic for T ≥ 730. 3.2 Representative Features Intuitively, an event can be described very concisely by a few discriminative and representative word features and vice-versa, e.g., hurricane, sweep, and strike could be representative features of a Hurricane genre event.",
                "Likewise, a set of strongly correlated features could be used to reconstruct an event description, assuming that strongly correlated features are representative.",
                "The representation vector of a word feature is defined as follows: Definition 3. (Feature Trajectory) The trajectory of a word feature f can be written as the sequence yf = [yf (1), yf (2), . . . , yf (T)], where each element yf (t) is a measure of feature f at time t, which could be defined using the normalized DFIDF score2 yf (t) = DFf (t) N(t) × log( N DFf ), where DFf (t) is the number of documents (local DF) containing feature f at day t, DFf is the total number of documents (global DF) containing feature f over T, N(t) is the number of documents for day t, and N is the total number of documents over T. 4.",
                "IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 Spectral Analysis for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. DFT can represent the original time series as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T.",
                "The original trajectory can be reconstructed with just the dominant frequencies, which can be determined from the power spectrum using the popular periodogram estimator.",
                "The periodogram is a sequence of the squared magnitude of the Fourier coefficients, Xk 2 , k = 1, 2, . . . , T/2 , which indicates the signal power at frequency k/T in the spectrum.",
                "From the power spectrum, the dominant period is chosen as the inverse of the frequency with the highest power spectrum, as follows.",
                "Definition 4. (Dominant Period) The dominant period (DP) of a given feature f is Pf = T/ arg max k Xk 2 .",
                "Accordingly, we have Definition 5. (Dominant Power Spectrum) The dominant power spectrum (DPS) of a given feature f is Sf = Xk 2 , with Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorizing Features The DPS of a feature trajectory is a strong indicator of its activeness at the specified frequency; the higher the DPS, the more likely for the feature to be bursty.",
                "Combining DPS with DP, we therefore categorize all features into four types: 2 We normalize yf (t) as yf (t) = yf (t)/ T i=1 yf (i) so that it could be interpreted as a probability. • HH: high Sf , aperiodic or long-term periodic (Pf > T/2 ); • HL: high Sf , short-term periodic (Pf ≤ T/2 ); • LH: low Sf , aperiodic or long-term periodic; • LL: low Sf , short-term periodic.",
                "The boundary between long-term and short-term periodic is set to T/2 .",
                "However, distinguishing between a high and low DPS is not straightforward, which will be tackled later.",
                "Properties of Different Feature Sets To better understand the properties of HH, HL, LH and LL, we select four features, Christmas, soccer, DBS and your as illustrative examples.",
                "Since the boundary between high and low power spectrum is unclear, these chosen examples have relative wide range of power spectrum values.",
                "Figure 2(a) shows the DFIDF trajectory for Christmas with a distinct burst around Christmas day.",
                "For the 1-year Reuters dataset, Christmas is classified as a typical aperiodic event with Pf = 365 and Sf = 135.68, as shown in Figure 2(b).",
                "Clearly, the value of Sf = 135.68 is reasonable for a well-known bursty event like Christmas. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Christmas(DFIDF:time) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Christmas(S:frequency) Figure 2: Feature Christmas with relative high Sf and long-term Pf .",
                "The DFIDF trajectory for soccer is shown in Figure 3(a), from which we can observe that there is a regular burst every 7 days, which is again verified by its computed value of Pf = 7, as shown in Figure 3(b).",
                "Using the domain knowledge that soccer games have more matches every Saturday, which makes it a typical and heavily reported periodic event, we thus consider the value of Sf = 155.13 to be high. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) soccer(DFIDF:time) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) soccer(S:frequency) Figure 3: Feature soccer with relative high Sf and short-term Pf .",
                "From the DFIDF trajectory for DBS in Figure 4(a), we can immediately deduce DBS to be an infrequent word with a trivial burst on 08/17/1997 corresponding to DBS Land Raﬄes Holdings plans.",
                "This is confirmed by the long period of Pf = 365 and low power of Sf = 0.3084 as shown in Figure 4(b).",
                "Moreover, since this aperiodic event is only reported in a few news stories over a very short time of few days, we therefore say that its low power value of Sf = 0.3084 is representative of unimportant events.",
                "The most confusing example is shown in Figure 5 for the word feature your, which looks very similar to the graph for soccer in Figure 3.",
                "At first glance, we may be tempted to group both your and soccer into the same category of HL or LL since both distributions look similar and have the same dominant period of approximately a week.",
                "However, further 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:time) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frequency) Figure 4: Feature DBS with relative low Sf and long-term Pf . analysis indicates that the periodicity of your is due to the differences in document counts for weekdays (average 2,919 per day) and weekends3 (average 479 per day).",
                "One would have expected the periodicity of a stopword like your to be a day.",
                "Moreover, despite our DFIDF normalization, the weekday/weekend imbalance still prevailed; stopwords occur 4 times more frequently on weekends than on weekdays.",
                "Thus, the DPS remains the only distinguishing factor between your (Sf = 9.42) and soccer (Sf = 155.13).",
                "However, it is very dangerous to simply conclude that a power value of S = 9.42 corresponds to a stopword feature. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) your(DFIDF:time) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) your(S:frequency) Figure 5: Feature your as an example confusing with feature soccer.",
                "Before introducing our solution to this problem, lets look at another LL example as shown in Figure 6 for beenb, which is actually a confirmed typo.",
                "We therefore classify beenb as a noisy feature that does not contribute to any event.",
                "Clearly, the trajectory of your is very different from beenb, which means that the former has to be considered separately. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figure 6: Feature beenb with relative low Sf and short-term Pf .",
                "Stop Words (SW) Feature Set Based on the above analysis, we realize that there must be another feature set between HL and LL that corresponds to the set of stopwords.",
                "Features from this set has moderate DPS and low but known dominant period.",
                "Since it is hard to distinguish this feature set from HL and LL only based on DPS, we introduce another factor called average DFIDF (DFIDF).",
                "As shown in Figure 5, features like your usually have a lower DPS than a HL feature like soccer, but have a much higher DFIDF than another LL noisy feature such as beenb.",
                "Since such properties are usually characteristics of stopwords, we group features like your into the newly defined stopword (SW) feature set.",
                "Since setting the DPS and DFIDF thresholds for identifying stopwords is more of an art than science, we proposed a heuristic HS algorithm, Algorithm 1.",
                "The basic idea is to only use news stories from weekdays to identify stopwords. 3 The weekends here also include public holidays falling on weekdays.",
                "The SW set is initially seeded with a small set of 29 popular stopwords utilized by Google search engine.",
                "Algorithm 1 Heuristic Stopwords detection (HS) Input: Seed SW set, weekday trajectories of all words 1: From the seed set SW, compute the maximum DPS as UDPS, maximum DFIDF as UDFIDF, and minimum of DFIDF as LDFIDF. 2: for fi ∈ F do 3: Compute DFT for fi. 4: if Sfi ≤ UDPS and DFIDFfi ∈ [LDFIDF, UDFIDF] then 5: fi → SW 6: F = F − fi 7: end if 8: end for Overview of Feature Categorization After the SW set is generated, all stopwords are removed from F. We then set the boundary between high and low DPS to be the upper bound of the SW sets DPS.",
                "An overview of all five feature sets is shown in Figure 7.",
                "Figure 7: The 5 feature sets for events. 5.",
                "IDENTIFYING BURSTS FOR FEATURES Since only features from HH, HL and LH are meaningful and could potentially be representative to some events, we pruned all other feature classified as LL or SW.",
                "In this section, we describe how bursts can be identified from the remaining features.",
                "Unlike Kleinbergs burst identification algorithm [12], we can identify both significant and trivial bursts without the need to set any parameters. 5.1 Detecting Aperiodic Features Bursts For each feature in HH and HL, we truncate its trajectory by keeping only the bursty period, which is modeled with a Gaussian distribution.",
                "For example, Figure 8 shows the word feature Iraq with a burst circa 09/06/1996 being modeled as a Gaussian.",
                "Its bursty period is defined by [μf − σf , μf + σf ] as shown in Figure 8(b). 5.2 Detecting Periodic Features Bursts Since we have computed the DP for a periodic feature f, we can easily model its periodic feature trajectory yf using 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) original DFIDF:time 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 burst= [μ-σ, μ+σ] (b) identifying burst Figure 8: Modeling Iraqs time series as a truncated Gaussian with μ = 09/06/1996 and σ = 6.26. a mixture of K = T/Pf Gaussians: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , where the parameter set θf = {αk, μk, σk}K k=1 comprises: • αk is the probability of assigning yf into the kth Gaussian. αk > 0, ∀k ∈ [1, K] and K k=1 αk = 1; • μk/σk is mean/standard deviation of the kth Gaussian.",
                "The well known Expectation Maximization (EM) [8] algorithm is used to compute the mixing proportions αk, as well as the individual Gaussian density parameters μk and σK .",
                "Each Gaussian represents one periodic event, and is modeled similarly as mentioned in Section 5.1. 6.",
                "EVENTS FROM FEATURES After identifying and modeling bursts for all features, the next task is to paint a picture of the event with a potential set of representative features. 6.1 Feature Correlation If two features fi and fj are representative of the same event, they must satisfy the following necessary conditions: 1. fi and fj are identically distributed: yfi ∼ yfj . 2. fi and fj have a high document overlap.",
                "Measuring Feature Distribution Similarity We measure the similarity between two features fi and fj using discrete KL-divergence defined as follows.",
                "Definition 6. (feature similarity) KL(fi, fj ) is given by max(KL(fi|fj ), KL(fj |fi)), where KL(fi|fj ) = T t=1 f(yfi (t)|θfi )log f(yfi (t)|θfi ) f(yfj (t)|θfj ) . (1) Since KL-divergence is not symmetric, we define the similarity between between fi and fj as the maximum of KL(fi|fj ) and KL(fj |fi).",
                "Further, the similarity between two aperiodic features can be computed using a closed form of the KL-divergence [16].",
                "The same discrete KL-divergence formula of Eq. 1 is employed to compute the similarity between two periodic features, Next, we define the overal similarity among a set of features R using the maximum inter-feature KL-Divergence value as follows.",
                "Definition 7. (sets similarity)KL(R) = max ∀fi,fj ∈R KL(fi, fj ).",
                "Document Overlap Let Mi be the set of all documents containing feature fi.",
                "Given two features fi and fj , the overlapping document set containing both features is Mi ∩ Mj .",
                "Intuitively, the higher the |Mi ∩ Mj |, the more likelty that fi and fj will be highly correlated.",
                "We define the degree of document overlap between two features fi and fj as follows.",
                "Definition 8. (Feature DF Overlap) d(fi, fj ) = |Mi∩Mj| min(|Mi|,|Mj|) .",
                "Accordingly, the DF Overlap among a set of features R is also defined.",
                "Definition 9. (Set DF Overlap) d(R) = min ∀fi,fj ∈R d(fi, fj). 6.2 Unsupervised Greedy Event Detection We use features from HH to detect important aperiodic events, features from LH to detect less-reported/unimportant aperiodic events, and features from HL to detect periodic events.",
                "All of them share the same algorithm.",
                "Given bursty feature fi ∈ HH, the goal is to find highly correlated features from HH.",
                "The set of features similar to fi can then collectively describe an event.",
                "Specifically, we need to find a subset Ri of HH that minimizes the following cost function: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) The underlying event e (associated with the burst of fi) can be represented by Ri as y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) The burst analysis for event e is exactly the same as the feature trajectory.",
                "The cost in Eq. 2 can be minimized using our unsupervised greedy UG event detection algorithm, which is described in Algorithm 2.",
                "The UG algorithm allows a feature Algorithm 2 Unsupervised Greedy event detection (UG).",
                "Input: HH, document index for each feature. 1: Sort and select features in descending DPS order: Sf1 ≥ Sf2 ≥ . . . ≥ Sf|HH| . 2: k = 0. 3: for fi ∈ HH do 4: k = k + 1. 5: Init: Ri ← fi, C(Ri) = 1/Sfi and HH = HH − fi. 6: while HH not empty do 7: m = arg min m C(Ri ∪ fm). 8: if C(Ri ∪ fm) < C(Ri) then 9: Ri ← fm and HH = HH − fm. 10: else 11: break while. 12: end if 13: end while 14: Output ek as Eq. 3. 15: end for to be contained in multiple events so that we can detect several events happening at the same time.",
                "Furthermore, trivial events only containing year/month features (i.e., an event only containing 1 feature Aug could be identified over a 1year news stream) could be removed, although such events will have inherent high cost and should already be ranked very low.",
                "Note that our UG algorithm only requires one data-dependant parameter, the boundary between high and low power spectrum, to be set once, and this parameter can be easily estimated using the HS algorithm (Algorithm 1). 7.",
                "EXPERIMENTS In this section, we study the performances of our feature categorizing method and event detection algorithm.",
                "We first introduce the dataset and experimental setup, then we subjectively evaluate the categorization of features for HH, HL, LH, LL and SW.",
                "Finally, we study the (a)periodic event detection problem with Algorithm 2. 7.1 Dataset and Experimental Setup The Reuters Corpus contains 806,791 English news stories from 08/20/1996 to 08/19/1997 at a day resolution.",
                "Version 2 of the open source Lucene software [1] was used to tokenize the news text content and generate the document-word vector.",
                "In order to preserve the time-sensitive past/present/future tenses of verbs and the differences between lower case nouns and upper case named entities, no stemming was done.",
                "Since dynamic stopword removal is one of the functionalities of our method, no stopword was removed.",
                "We did remove nonEnglish characters, however, after which the number of word features amounts to 423,433.",
                "All experiments were implemented in Java and conducted on a 3.2 GHz Pentium 4 PC running Windows 2003 Server with 1 GB of memory. 7.2 Categorizing Features We downloaded 34 well-known stopwords utilized by the Google search engine as our seed training features, which includes a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en and www.",
                "We excluded the last five stopwords as they are uncommon in news stories.",
                "By only analyzing news stories over 259 weekdays, we computed the upper bound of the power spectrum for stopwords at 11.18 and corresponding DFIDF ranges from 0.1182 to 0.3691.",
                "Any feature f satisfying Sf <= 11.18 and 0.1182 <= DFIDFf <= 0.3691 over weekdays will be considered a stopword.",
                "In this manner, 470 stopwords were found and removed as visualized in Figure 9.",
                "Some detected stopwords are A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) and much (P = 22, S = 0.80, DFIDF = 0.1865).",
                "After the removal of these stopwords, the distribution of weekday and weekend news are more or less matched, and in the ensuing experiments, we shall make use of the full corpus (weekdays and weekends).",
                "The upper bound power spectrum value of 11.18 for stopwords training was selected as the boundary between the high power and low power spectrum.",
                "The boundary between high and low periodicity was set to 365/2 = 183.",
                "All 422,963 (423433 − 470) word features were categorized into 4 feature sets: HH (69 features), HL (1,087 features), LH (83,471 features), and LL (338,806 features) as shown in Figure 10.",
                "In Figure 10, each gray level denotes the relative density of features in a square region, measured by log10(1 + Dk), where Dk is the number of features within the k-th square region.",
                "From the figure, we can make the 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figure 9: Distribution of SW (stopwords) in the HH, HL, LH, and LL regions. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figure 10: Distribution of categorized features over the four quadrants (shading in log scale). following observations: 1.",
                "Most features have low S and are easily distinguishable from those features having a much higher S, which allows us to detect important (a)periodic events from trivial events by selecting features with high S. 2.",
                "Features in the HH and LH quadrants are aperiodic, which are nicely separated (big horizontal gap) from the periodic features.",
                "This allows reliably detecting aperiodic events and periodic events independently. 3.",
                "The (vertical) boundary between high and low power spectrum is not as clearcut and the exact value will be application specific.",
                "By checking the scatter distribution of features from SW on HH, HL, LH, and LL as shown in Figure 9, we found that 87.02%(409/470) of the detected stopwords originated from LL.",
                "The LL classification and high DFIDF scores of stopwords agree with the generally accepted notion that stopwords are equally frequent over all time.",
                "Therefore, setting the boundary between high and low power spectrum using the upper bound Sf of SW is a reasonable heuristic. 7.3 Detecting Aperiodic Events We shall evaluate our two hypotheses, 1)important aperiodic events can be defined by a set of HH features, and 2)less reported aperiodic events can be defined by a set of LH features.",
                "Since no benchmark news streams exist for event detection (TDT datasets are not proper streams), we evaluate the quality of the automatically detected events by comparing them to manually-confirmed events by searching through the corpus.",
                "Among the 69 HH features, we detected 17 important aperiodic events as shown in Table 1 (e1 − e17).",
                "Note that the entire identification took less than 1 second, after removing events containing only the month feature.",
                "Among the 17 events, other than the overlaps between e3 and e4 (both describes the same hostage event), e11 and e16 (both about company reports), the 14 identified events are extremely accurate and correspond very well to the major events of the period.",
                "For example, the defeat of Bob Dole, election of Tony Blair, Missile attack on Iraq, etc.",
                "Recall that selecting the features for one event should minimize the cost in Eq. 2 such that 1) the number of features span different events, and 2) not all features relevant to an event will be selected, e.g., the feature Clinton is representative to e12 but since Clinton relates to many other events, its time domain signal is far different from those of other representative features like Dole and Bob.",
                "The number of documents of a detected event is roughly estimated by the number of indexed documents containing the representative features.",
                "We can see that all 17 important aperiodic events are popularly reported events.",
                "After 742 minutes of computation time, we detected 23, 525 less reported aperiodic events from 83,471 LH features.",
                "Table 1 lists the top 5 detected aperiodic events (e18 − e22) with respect to the cost.",
                "We found that these 5 events are actually very trivial events with only a few news reports, and are usually subsumed by some larger topics.",
                "For example, e22 is one of the rescue events in an airplane hijack topic.",
                "One advantage of our UG Algorithm for discovering less-reported aperiodic events is that we are able to precisely detect the true event period. 7.4 Detecting Periodic Events Among the 1,087 HL features, 330 important periodic events were detected within 10 minutes of computing time.",
                "Table 1 lists the top 5 detected periodic events with respect to the cost (e23 − e27).",
                "All of the detected periodic events are indeed valid, and correspond to real life periodic events.",
                "The GMM model is able to detect and estimate the bursty period nicely although it cannot distinguish the slight difference between every Monday-Friday and all weekdays as shown in e23.",
                "We also notice that e26 is actually a subset of e27 (soccer game), which is acceptable since the Sheffield league results are announced independently every weekend. 8.",
                "CONCLUSIONS This paper took a whole new perspective of analyzing feature trajectories as time domain signals.",
                "By considering the word document frequencies in both time and frequency domains, we were able to derive many new characteristics about news streams that were previously unknown, e.g., the different distributions of stopwords during weekdays and weekends.",
                "For the first time in the area of TDT, we applied a systematic approach to automatically detect important and less-reported, periodic and aperiodic events.",
                "The key idea of our work lies in the observations that (a)periodic events have (a)periodic representative features and (un)important events have (in)active representative features, differentiated by their power spectrums and time periods.",
                "To address the real event detection problem, a simple and effective mixture density-based approach was used to identify feature bursts and their associated bursty periods.",
                "We also designed an unsupervised greedy algorithm to detect both aperiodic and periodic events, which was successful in detecting real events as shown in the evaluation on a real news stream.",
                "Although we have not made any benchmark comparison against another approach, simply because there is no previous work in the addressed problem.",
                "Future work includes evaluating the recall of detected events for a labeled news stream, and comparing our model against the closest equivalent methods, which currently are limited to the methods of Kleinberg [12] (which can only detect certain type of bursty events depending on parameter settings), Fung et al. [9], and Swan and Allan [18].",
                "Nevertheless, we believe our simple and effective method will be useful for all TDT practitioners, and will be especially useful for the initial exploratory analysis of news streams. 9.",
                "REFERENCES [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Google news alerts, http://www.google.com/alerts. [3] Reuters corpus, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan.",
                "Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, and H. Jin.",
                "First story detection in tdt is hard.",
                "In CIKM, pages 374-381, 2000. [6] J. Allan, C. Wade, and A. Bolivar.",
                "Retrieval and novelty detection at the sentence level.",
                "In SIGIR, pages 314-321, 2003. [7] T. Brants, F. Chen, and A. Farahat.",
                "A system for new event detection.",
                "In SIGIR, pages 330-337, 2003. [8] A. P. Dempster, N. M. Laird, and D. B. Rubin.",
                "Maximum likelihood from incomplete data via the EM algorithm.",
                "Journal of the Royal Statistical Society, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu, and H. Lu.",
                "Parameter free bursty events detection in text streams.",
                "In VLDB, pages 181-192, 2005. [10] Q.",
                "He, K. Chang, and E.-P. Lim.",
                "A model for anticipatory event detection.",
                "In ER, pages 168-181, 2006. [11] Q.",
                "He, K. Chang, E.-P. Lim, and J. Zhang.",
                "Bursty feature reprensentation for clustering text streams.",
                "In SDM, accepted, 2007. [12] J. Kleinberg.",
                "Bursty and hierarchical structure in streams.",
                "In SIGKDD, pages 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins.",
                "On the bursty evolution of blogspace.",
                "In WWW, pages 159-178, 2005. [14] G. Kumaran and J. Allan.",
                "Text classification and named entities for new event detection.",
                "In SIGIR, pages 297-304, 2004. [15] Q. Mei and C. Zhai.",
                "Discovering evolutionary theme patterns from text: an exploration of temporal text mining.",
                "In SIGKDD, pages 198-207, 2005. [16] W. D. Penny.",
                "Kullback-liebler divergences of normal, gamma, dirichlet and wishart densities.",
                "Technical report, 2001. [17] N. Stokes and J. Carthy.",
                "Combining semantic and syntactic document classifiers to improve first story detection.",
                "In SIGIR, pages 424-425, 2001. [18] R. Swan and J. Allan.",
                "Automatic generation of overview timelines.",
                "In SIGIR, pages 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena, and D. Gunopulos.",
                "Identifying similarities, periodicities and bursts for online search queries.",
                "In SIGMOD, pages 131-142, 2004. [20] Y. Yang, T. Pierce, and J. Carbonell.",
                "A study of retrospective and on-line event detection.",
                "In SIGIR, pages 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topic-conditioned novelty detection.",
                "In SIGKDD, pages 688-693, 2002.",
                "Table 1: All important aperiodic events (e1 − e17), top 5 less-reported aperiodic events (e18 − e22) and top 5 important periodic events (e23 − e27).",
                "Detected Event and Bursty Period Doc # True Event e1(Sali,Berisha,Albania,Albanian,March) 02/02/199705/29/1997 1409 Albanians president Sali Berisha lost in an early election and resigned, 12/1996-07/1997. e2(Seko,Mobutu,Sese,Kabila) 03/22/1997-06/09/1997 2273 Zaires president Mobutu Sese coordinated the native rebellion and failed on 05/16/1997. e3(Marxist,Peruvian) 11/19/1996-03/05/1997 824 Peru rebels (Tupac Amaru revolutionary Movement) led a hostage siege in Lima in early 1997. e4(Movement,Tupac,Amaru,Lima,hostage,hostages) 11/16/1996-03/20/1997 824 The same as e3. e5(Kinshasa,Kabila,Laurent,Congo) 03/26/199706/15/1997 1378 Zaire was renamed the Democratic Republic of Congo on 05/16/1997. e6(Jospin,Lionel,June) 05/10/1997-07/09/1997 605 Following the early General Elections circa 06/1997, Lionel Jospin was appointed Prime Minister on 06/02/1997. e7(Iraq,missile) 08/31/1996-09/13/1996 1262 U.S. fired missile at Iraq on 09/03/1996 and 09/04/1996. e8(Kurdish,Baghdad,Iraqi) 08/29/1996-09/09/1996 1132 Iraqi troop fought with Kurdish faction circa 09/1996. e9(May,Blair) 03/24/1997-07/04/1997 1049 Tony Blair became the Primary Minister of the United Kingdom on 05/02/1997. e10(slalom,skiing) 12/05/1996-03/21/1997 253 Slalom Game of Alpine Skiing in 01/1997-02/1997. e11(Interim,months) 09/24/1996-12/31/1996 3063 Tokyo released company interim results for the past several months in 09/1996-12/1996. e12(Dole,Bob) 09/09/1996-11/24/1996 1599 Dole Bob lost the 1996 US presidential election. e13(July,Sen) 06/25/1997-06/25/1997 344 Cambodias Prime Minister Hun Sen launched a bloody military coup in 07/1997. e14(Hebron) 10/15/1996-02/14/1997 2098 Hebron was divided into two sectors in early 1997. e15(April,Easter) 02/23/1997-05/04/1997 480 Easter feasts circa 04/1997 (for western and Orthodox). e16(Diluted,Group) 04/27/1997-07/20/1997 1888 Tokyo released all 96/97 group results in 04/199707/1997. e17(December,Christmas) 11/17/1996-01/26/1997 1326 Christmas feast in late 12/1997. e18(Kolaceva,winter,Together,promenades,Zajedno, Slobodan,Belgrade,Serbian,Serbia,Draskovic,municipal, Kragujevac) 1/25/1997 3 University students organized a vigil on Kolaceva street against government on 1/25/1997. e19(Tutsi,Luvengi,Burundi,Uvira,fuel,Banyamulenge, Burundian,Kivu,Kiliba,Runingo,Kagunga,Bwegera) 10/19/1996 6 Fresh fighting erupted around Uvira between Zaire armed forces and Banyamulengs Tutsi rebels on 10/19/1996. e20(Malantacchi,Korea,Guy,Rider,Unions,labour, Trade,unions,Confederation,rammed,Geneva,stoppages, Virgin,hire,Myongdong,Metalworkers) 1/11/1997 2 Marcello Malantacchi secretary general of the International Metalworkers Federation and Guy Rider who heads the Geneva office of the International Confederation of Free Trade Unions attacked the new labour law of South Korea on 1/11/1997. e21(DBS,Raﬄes) 8/17/1997 9 The list of the unit of Singapore DBS Land Raﬄes Holdings plans on 8/17/1997. e22(preserver,fuel,Galawa,Huddle,Leul,Beausse) 11/24/1996 3 Rescued a woman and her baby during a hijacked Ethiopian plane that ran out of fuel and crashed into the sea near Le Galawa beach on 11/24/1996. e23(PRICE,LISTING,MLN,MATURITY,COUPON, MOODY,AMT,FIRST,ISS,TYPE,PAY,BORROWER) Monday-Friday/week 7966 Announce bond price on all weekdays. e24(Unaudited,Ended,Months,Weighted,Provision,Cost, Selling,Revenues,Loss,Income,except,Shrs,Revs) every season 2264 Net income-loss reports released by companies in every season. e25(rating,Wall,Street,Ian) Monday-Friday/week 21767 Stock reports from Wall Street on all weekdays. e26(Sheffield,league,scoring,goals,striker,games) every Friday, Saturday and Sunday 574 Match results of Sheffield soccer league were published on Friday, Saturday and Sunday 10 times than other 4 days. e27(soccer,matches,Results,season,game,Cup,match, victory,beat,played,play,division) every Friday, Saturday and Sunday 2396 Soccer games held on Friday, Saturday and Sunday 7 times than other 4 days."
            ],
            "original_annotated_samples": [
                "Moreover, most TDT research so far has been concerned with clustering/classifying documents into topic types, identifying novel sentences [6] for new events, etc., without much regard to analyzing the <br>word trajectory</br> with respect to time."
            ],
            "translated_annotated_samples": [
                "Además, la mayoría de las investigaciones de TDT hasta ahora se han centrado en agrupar/clasificar documentos en tipos de temas, identificar oraciones novedosas para eventos nuevos, etc., sin prestar mucha atención al análisis de la <br>trayectoria de las palabras</br> con respecto al tiempo."
            ],
            "translated_text": "Analizando Trayectorias de Características para la Detección de Eventos Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg Escuela de Ingeniería Informática Universidad Tecnológica de Nanyang Bloque N4, Avenida Nanyang, Singapur 639798 RESUMEN Consideramos el problema de analizar trayectorias de palabras en los dominios del tiempo y la frecuencia, con el objetivo específico de identificar palabras importantes y menos reportadas, periódicas y aperiódicas. Un conjunto de palabras con tendencias idénticas puede agruparse para reconstruir un evento de manera completamente no supervisada. La frecuencia del documento de cada palabra a lo largo del tiempo se trata como una serie temporal, donde cada elemento es el puntaje de frecuencia del documento - frecuencia inversa del documento (DFIDF) en un punto temporal. En este artículo, 1) primero aplicamos análisis espectral para categorizar características de diferentes tipos de eventos: importantes y poco reportados, periódicos y aperiódicos; 2) modelamos las características aperiódicas con densidad gaussiana y las características periódicas con densidades de mezcla gaussiana, y posteriormente detectamos cada ráfaga de características mediante el enfoque gaussiano truncado; 3) propusimos un algoritmo de detección de eventos codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos. Todos los métodos anteriores se pueden aplicar a datos de series temporales en general. Evaluamos exhaustivamente nuestros métodos en el Corpus de Noticias de Reuters de 1 año [3] y demostramos que fueron capaces de descubrir eventos significativos aperiódicos y periódicos. Categorías y Descriptores de Asignaturas: H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales: Algoritmos, Experimentación. 1. INTRODUCCIÓN Hay más de 4,000 fuentes de noticias en línea en el mundo. Supervisar manualmente todos ellos en busca de eventos importantes se ha vuelto difícil o prácticamente imposible. De hecho, la comunidad de detección y seguimiento de temas (TDT) ha estado tratando durante muchos años de encontrar una solución práctica para ayudar a las personas a monitorear las noticias de manera efectiva. Desafortunadamente, el Santo Grial sigue siendo esquivo, ya que la gran mayoría de las soluciones de TDT propuestas para la detección de eventos [20, 5, 17, 4, 21, 7, 14, 10] son demasiado simplistas (basadas en la similitud del coseno [5]) o impracticables debido a la necesidad de ajustar un gran número de parámetros [9]. La ineficacia de las tecnologías actuales de TDT se puede ilustrar fácilmente suscribiéndose a cualquiera de los muchos servicios de alertas de noticias en línea, como el líder de la industria Google News Alerts, que genera más del 50% de falsas alarmas. Como prueba adicional, portales como Yahoo adoptan un enfoque más pragmático al requerir que todas las alertas de noticias generadas por máquinas pasen por un operador humano para su confirmación antes de enviarlas a los suscriptores. En lugar de abordar el problema con variaciones del mismo martillo (similitud coseno y TFIDF), es necesario contar con una comprensión fundamental de las características de los datos de flujo de noticias antes de que se puedan lograr avances importantes en TDT. Por lo tanto, en este artículo, examinamos noticias y tendencias de características desde la perspectiva de analizar una señal de palabras de series temporales. Trabajos anteriores como [9] han intentado reconstruir un evento con sus características representativas. Sin embargo, en muchas tareas de detección de eventos predictivos (es decir, detección de eventos retrospectivos), hay un vasto conjunto de características potenciales solo para un conjunto fijo de observaciones (es decir, los estallidos obvios). De estas características, a menudo solo se espera que un pequeño número sea útil. En particular, estudiamos el novedoso problema de analizar trayectorias de características para la detección de eventos, utilizando una técnica conocida de procesamiento de señales: identificar correlaciones distribucionales entre todas las características mediante análisis espectral. Para evaluar nuestro método, posteriormente proponemos un algoritmo de detección de eventos no supervisado para flujos de noticias. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Pascua Abril (a) evento aperiódico 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 No auditado Finalizado (b) evento periódico Figura 1: Correlación de características (DFIDF:tiempo) entre a) Pascua y Abril b) No auditado y Finalizado. Como ejemplo ilustrativo, considera la correlación entre las palabras Pascua y abril del Corpus de Reuters. A partir del gráfico de su DFIDF normalizado en la Figura 1(a), observamos la gran superposición entre las dos palabras alrededor de 04/1997, lo que significa que probablemente ambas pertenecen al mismo evento durante ese tiempo (festividad de Pascua). En este ejemplo, el evento oculto de la festividad de Pascua es un evento aperiódico típico e importante en datos de 1 año. Otro ejemplo se muestra en la Figura 1(b), donde las palabras \"No auditado\" y \"Finalizado 1\" del Corpus de Reuters son el conjunto de datos predeterminado para todos los ejemplos y presentan un comportamiento similar durante períodos de 3 meses. Estas dos palabras en realidad se originaron a partir del mismo evento periódico, informes de ganancias y pérdidas, que son publicados trimestralmente por empresas cotizadas en bolsa. Otras observaciones extraídas de la Figura 1 son: 1) el período de actividad intensa de abril es mucho más largo que el de Semana Santa, lo que sugiere que abril puede estar presente en otros eventos durante el mismo período; 2) No auditado tiene un valor promedio de DFIDF más alto que Finalizado, lo que indica que No auditado es más representativo para el evento subyacente. Estos dos ejemplos son solo la punta del iceberg entre todas las tendencias de palabras y correlaciones ocultas en un flujo de noticias como Reuters. Si se puede descubrir un gran número de ellos, podría ayudar significativamente en las tareas de TDT. En particular, indica la importancia de extraer características correlacionadas para detectar eventos correspondientes. Para resumir, postulamos que: 1) Un evento se describe por sus características representativas. Un evento periódico tiene una lista de características periódicas y un evento aperiódico tiene una lista de características aperiódicas; 2) Las características representativas del mismo evento comparten distribuciones similares en el tiempo y están altamente correlacionadas; 3) Un evento importante tiene un conjunto de características representativas activas (ampliamente reportadas), mientras que un evento no importante tiene un conjunto de características representativas inactivas (menos reportadas); 4) Una característica puede ser incluida por varios eventos con superposiciones en los marcos de tiempo. Basándonos en estas observaciones, podemos extraer características representativas dadas un evento o detectar un evento a partir de una lista de características altamente correlacionadas. En este artículo, nos enfocamos en este último aspecto, es decir, cómo se pueden descubrir características correlacionadas para formar un evento de manera no supervisada. 1.1 Contribuciones Este artículo tiene tres contribuciones principales: • Hasta donde sabemos, nuestro enfoque es el primero en categorizar características de palabras para eventos heterogéneos. Específicamente, cada característica de palabra se clasifica en uno de los siguientes cinco tipos de características basados en la fuerza de su espectro de potencia y periodicidad: 1) HH (alta potencia y alta/larga periodicidad): eventos aperiódicos importantes, 2) HL (alta potencia y baja periodicidad): eventos periódicos importantes, 3) LH (baja potencia y alta periodicidad): eventos aperiódicos no importantes, 4) LL (baja potencia y baja periodicidad): no eventos, y 5) SW (palabras vacías), un subconjunto de LL con mayor potencia y periodicidad que comprende palabras vacías, que no contienen información. • Proponemos un enfoque simple y efectivo basado en densidad de mezcla para modelar y detectar ráfagas de características. • Presentamos un algoritmo de detección de eventos no supervisado para detectar eventos tanto aperiódicos como periódicos. Nuestro algoritmo ha sido evaluado en un flujo de noticias reales para demostrar su efectividad. 2. TRABAJO RELACIONADO Este trabajo está motivado en gran medida por una familia más amplia de problemas conocidos colectivamente como Detección y Seguimiento de Temas (TDT) [20, 5, 17, 4, 21, 7, 14, 10]. Además, la mayoría de las investigaciones de TDT hasta ahora se han centrado en agrupar/clasificar documentos en tipos de temas, identificar oraciones novedosas para eventos nuevos, etc., sin prestar mucha atención al análisis de la <br>trayectoria de las palabras</br> con respecto al tiempo. Swan y Allan [18] intentaron por primera vez usar términos que co-ocurren para construir un evento. Sin embargo, solo consideraron entidades nombradas y pares de frases nominales, sin tener en cuenta sus periodicidades. Por el contrario, nuestro artículo considera todo lo anterior. Recientemente, ha habido un gran interés en modelar un evento en flujos de texto como un estallido de actividades al incorporar información temporal. El trabajo seminal de Kleinberg describió cómo se pueden extraer características explosivas de flujos de texto utilizando un modelo de autómata infinito [12], lo que inspiró toda una serie de aplicaciones como la identificación de comunidades explosivas de Kumar a partir de gráficos de blogs [13], la sumarización de temas evolutivos en flujos de texto de Meis [15], el agrupamiento de flujos de texto utilizando características explosivas de Hes [11], etc. Sin embargo, ninguno de los trabajos existentes identificó específicamente características para eventos, excepto Fung et al. [9], quienes agruparon características llamativas para identificar varios eventos llamativos. Nuestro trabajo difiere de [9] en varias formas: 1) analizamos cada característica individual, no solo las características explosivas; 2) clasificamos las características a lo largo de dos dimensiones categóricas (periodicidad y potencia), dando en total cinco tipos de características principales; 3) no restringimos que cada característica pertenezca exclusivamente a un solo evento. Las técnicas de análisis espectral han sido utilizadas previamente por Vlachos et al. [19] para identificar periodicidades y ráfagas en los registros de consultas. Su enfoque estaba en detectar múltiples periodicidades a partir del gráfico del espectro de potencia, las cuales luego se utilizaron para indexar palabras para la búsqueda por ráfagas. En este artículo, utilizamos análisis espectral para clasificar las características de las palabras a lo largo de dos dimensiones, a saber, periodicidad y espectro de potencia, con el objetivo final de identificar eventos tanto periódicos como no periódicos y explosivos. 3. REPRESENTACIÓN DE DATOS Sea T la duración/período (en días) de un flujo de noticias, y F representa el espacio de características de palabras completo en el Modelo de Espacio Vectorial (VSM) estático clásico. 3.1 Clasificación de Periodicidad de Eventos Dentro de T, pueden existir ciertos eventos que ocurren solo una vez, por ejemplo, la elección de Tony Blair como Primer Ministro del Reino Unido, y otros eventos recurrentes de diversas periodicidades, por ejemplo, partidos de fútbol semanales. Por lo tanto, categorizamos todos los eventos en dos tipos: aperiódicos y periódicos, definidos de la siguiente manera. Definición 1. (Evento aperiódico) Un evento es aperiódico dentro de T si solo ocurre una vez. Definición 2. (Evento periódico) Si los eventos de un cierto género de eventos ocurren regularmente con una periodicidad fija P ≤ T/2, decimos que este género particular de eventos es periódico, y cada evento miembro se califica como un evento periódico. Ten en cuenta que la definición de aperiódico es relativa, es decir, es verdadera solo para un T dado y puede ser inválida para cualquier otro T > T. Por ejemplo, el evento de la fiesta de Navidad es aperiódico para T ≤ 365 pero periódico para T ≥ 730. 3.2 Características Representativas Intuitivamente, un evento puede ser descrito de manera muy concisa por unas pocas características de palabras discriminativas y representativas y viceversa, por ejemplo, huracán, barrido y golpe podrían ser características representativas de un evento del género de huracanes. Asimismo, un conjunto de características fuertemente correlacionadas podría ser utilizado para reconstruir una descripción de un evento, asumiendo que las características fuertemente correlacionadas son representativas. El vector de representación de una característica de palabra se define de la siguiente manera: Definición 3. (Trayectoria de la Característica) La trayectoria de una característica de palabra f puede escribirse como la secuencia yf = [yf (1), yf (2), . . . , yf (T)], donde cada elemento yf (t) es una medida de la característica f en el tiempo t, que podría definirse utilizando la puntuación normalizada DFIDF yf (t) = DFf (t) N(t) × log( N DFf ), donde DFf (t) es el número de documentos (DF local) que contienen la característica f en el día t, DFf es el número total de documentos (DF global) que contienen la característica f en T, N(t) es el número de documentos para el día t, y N es el número total de documentos en T. 4. En esta sección, mostramos cómo se pueden extraer características representativas para eventos (poco) importantes o (a)periódicos. 4.1 Análisis Espectral para el Período Dominante Dada una característica f, descomponemos su trayectoria de características yf = [yf (1), yf (2), ..., yf (T)] en la secuencia de T números complejos [X1, . . . , XT ] a través de la transformada discreta de Fourier (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. La DFT puede representar la serie temporal original como una combinación lineal de sinusoides complejas, lo cual se ilustra mediante la transformada discreta de Fourier inversa (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, donde el coeficiente de Fourier Xk denota la amplitud del sinusoides con frecuencia k/T. La trayectoria original puede ser reconstruida con solo las frecuencias dominantes, las cuales pueden ser determinadas a partir del espectro de potencia utilizando el popular estimador periodograma. El periodograma es una secuencia de la magnitud al cuadrado de los coeficientes de Fourier, Xk^2, k = 1, 2, . . . , T/2, que indica la potencia de la señal en la frecuencia k/T en el espectro. A partir del espectro de potencia, se elige el período dominante como el inverso de la frecuencia con el espectro de potencia más alto, de la siguiente manera. Definición 4. (Período Dominante) El período dominante (DP) de una característica dada f es Pf = T/ arg max k Xk 2. Por lo tanto, tenemos la Definición 5. (Espectro de Potencia Dominante) El espectro de potencia dominante (DPS) de una característica dada f es Sf = Xk 2 , con Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorización de Características El DPS de una trayectoria de características es un indicador fuerte de su actividad en la frecuencia especificada; cuanto mayor sea el DPS, es más probable que la característica sea explosiva. Al combinar DPS con DP, categorizamos todas las características en cuatro tipos: 2 Normalizamos yf (t) como yf (t) = yf (t)/ T i=1 yf (i) para que pueda interpretarse como una probabilidad. • HH: alta Sf, aperiódico o periódico a largo plazo (Pf > T/2); • HL: alta Sf, periódico a corto plazo (Pf ≤ T/2); • LH: baja Sf, aperiódico o periódico a largo plazo; • LL: baja Sf, periódico a corto plazo. La frontera entre los periodos a largo plazo y a corto plazo se establece en T/2. Sin embargo, distinguir entre un DPS alto y bajo no es sencillo, lo cual se abordará más adelante. Propiedades de diferentes conjuntos de características Para comprender mejor las propiedades de HH, HL, LH y LL, seleccionamos cuatro características, Navidad, fútbol, DBS y tu como ejemplos ilustrativos. Dado que la frontera entre el espectro de alta y baja potencia no está clara, estos ejemplos seleccionados tienen un rango relativo amplio de valores de espectro de potencia. La figura 2(a) muestra la trayectoria de DFIDF para la Navidad con un pico distintivo alrededor del día de Navidad. Para el conjunto de datos de Reuters de 1 año, la Navidad se clasifica como un evento aperiódico típico con Pf = 365 y Sf = 135.68, como se muestra en la Figura 2(b). Claramente, el valor de Sf = 135.68 es razonable para un evento conocido por ser intermitente como la Navidad. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Navidad(DFIDF:tiempo) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Navidad(S:frecuencia) Figura 2: Característica Navidad con un Sf relativamente alto y un Pf a largo plazo. La trayectoria de DFIDF para el fútbol se muestra en la Figura 3(a), de la cual podemos observar que hay un estallido regular cada 7 días, lo cual es nuevamente verificado por su valor calculado de Pf = 7, como se muestra en la Figura 3(b). Usando el conocimiento del dominio de que los partidos de fútbol tienen más encuentros cada sábado, lo que lo convierte en un evento periódico típico y ampliamente reportado, consideramos que el valor de Sf = 155.13 es alto. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) fútbol (DFIDF:tiempo) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) fútbol (S:frecuencia) Figura 3: Característica fútbol con un Sf relativamente alto y un Pf a corto plazo. A partir de la trayectoria de DFIDF para DBS en la Figura 4(a), podemos deducir de inmediato que DBS es una palabra poco frecuente con un aumento trivial el 17/08/1997 correspondiente a los planes de DBS Land Raﬄes Holdings. Esto se confirma por el largo período de Pf = 365 y la baja potencia de Sf = 0.3084 como se muestra en la Figura 4(b). Además, dado que este evento aperiódico solo se informa en algunas noticias durante un corto período de unos pocos días, por lo tanto, decimos que su bajo valor de potencia de Sf = 0.3084 es representativo de eventos poco importantes. El ejemplo más confuso se muestra en la Figura 5 para la palabra \"your\", que se ve muy similar al gráfico para fútbol en la Figura 3. A primera vista, podríamos sentirnos tentados a agrupar tanto tu como el fútbol en la misma categoría de HL o LL, ya que ambas distribuciones se ven similares y tienen el mismo período dominante de aproximadamente una semana. Sin embargo, más adelante 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:tiempo) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frecuencia) Figura 4: Característica DBS con Sf relativamente bajo y Pf a largo plazo. El análisis indica que la periodicidad de su es debido a las diferencias en el recuento de documentos para los días de la semana (promedio de 2,919 por día) y los fines de semana (promedio de 479 por día). Uno habría esperado que la periodicidad de una palabra vacía como \"tu\" fuera de un día. Además, a pesar de nuestra normalización de DFIDF, el desequilibrio entre los días de la semana y los fines de semana aún prevalecía; las palabras vacías ocurren 4 veces más frecuentemente los fines de semana que los días de semana. Por lo tanto, el DPS sigue siendo el único factor distintivo entre tu (Sf = 9.42) y el fútbol (Sf = 155.13). Sin embargo, es muy peligroso concluir simplemente que un valor de potencia de S = 9.42 corresponde a una característica de palabra vacía. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) tu(DFIDF:tiempo) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) tu(S:frecuencia) Figura 5: Característica tu como un ejemplo confundido con la característica fútbol. Antes de presentar nuestra solución a este problema, veamos otro ejemplo de LL como se muestra en la Figura 6 para beenb, que en realidad es un error tipográfico confirmado. Por lo tanto, clasificamos beenb como una característica ruidosa que no contribuye a ningún evento. Claramente, la trayectoria de tu es muy diferente de beenb, lo que significa que el primero debe considerarse por separado. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figura 6: Característica beenb con Sf relativamente bajo y Pf a corto plazo. Conjunto de características de palabras vacías (SW) Basándonos en el análisis anterior, nos damos cuenta de que debe haber otro conjunto de características entre HL y LL que corresponda al conjunto de palabras vacías. Las características de este conjunto tienen un DPS moderado y un período dominante bajo pero conocido. Dado que es difícil distinguir este conjunto de características de HL y LL solo basándose en DPS, introducimos otro factor llamado promedio de DFIDF (DFIDF). Como se muestra en la Figura 5, características como la tuya suelen tener un DPS más bajo que una característica HL como el fútbol, pero tienen un DFIDF mucho más alto que otra característica ruidosa LL como \"beenb\". Dado que tales propiedades suelen ser características de las palabras vacías, agrupamos características como \"tu\" en el conjunto de características de palabras vacías (SW) recién definido. Dado que establecer los umbrales de DPS y DFIDF para identificar las palabras vacías es más un arte que una ciencia, propusimos un algoritmo heurístico HS, Algoritmo 1. La idea básica es utilizar solo noticias de días laborables para identificar palabras vacías. Los fines de semana aquí también incluyen días festivos que caen en días laborables. El conjunto SW se inicialmente alimenta con un pequeño conjunto de 29 stopwords populares utilizadas por el motor de búsqueda de Google. Algoritmo 1 Detección heurística de palabras vacías (HS) Entrada: Conjunto de palabras vacías semilla, trayectorias semanales de todas las palabras 1: A partir del conjunto semilla SW, calcular el DPS máximo como UDPS, el DFIDF máximo como UDFIDF y el mínimo de DFIDF como LDFIDF. 2: para fi ∈ F hacer 3: Calcular DFT para fi. 4: si Sfi ≤ UDPS y DFIDFfi ∈ [LDFIDF, UDFIDF] entonces 5: fi → SW 6: F = F - fi 7: fin si 8: fin para Resumen de la Categorización de Características Después de generar el conjunto SW, se eliminan todas las palabras vacías de F. Luego, establecemos el límite entre DPS alto y bajo como el límite superior de los DPS de los conjuntos SW. Una visión general de los cinco conjuntos de características se muestra en la Figura 7. Figura 7: Los 5 conjuntos de características para eventos. 5. IDENTIFICACIÓN DE RÁFAGAS PARA CARACTERÍSTICAS Dado que solo las características de HH, HL y LH son significativas y podrían ser representativas de algunos eventos, eliminamos todas las demás características clasificadas como LL o SW. En esta sección, describimos cómo se pueden identificar los estallidos a partir de las características restantes. A diferencia del algoritmo de identificación de ráfagas de Kleinberg [12], podemos identificar tanto ráfagas significativas como triviales sin necesidad de establecer ningún parámetro. 5.1 Detección de ráfagas de características aperiódicas Para cada característica en HH y HL, truncamos su trayectoria manteniendo solo el período de ráfagas, el cual está modelado con una distribución gaussiana. Por ejemplo, la Figura 8 muestra la característica de la palabra Iraq con una explosión alrededor del 09/06/1996 modelada como una Gaussiana. Su período de ráfagas está definido por [μf − σf , μf + σf ] como se muestra en la Figura 8(b). 5.2 Detección de características periódicas de ráfagas Dado que hemos calculado el DP para una característica periódica f, podemos modelar fácilmente su trayectoria de características periódicas yf usando 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) DFIDF original: tiempo 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 ráfaga= [μ-σ, μ+σ] (b) identificación de ráfaga Figura 8: Modelando la serie temporal de Iraq como una Gaussiana truncada con μ = 09/06/1996 y σ = 6.26. una mezcla de K = T/Pf Gaussianas: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , donde el conjunto de parámetros θf = {αk, μk, σk}K k=1 comprende: • αk es la probabilidad de asignar yf a la k-ésima Gaussiana. αk > 0, ∀k ∈ [1, K] y K k=1 αk = 1; • μk/σk es la media/desviación estándar de la k-ésima Gaussiana. El conocido algoritmo Expectation Maximization (EM) [8] se utiliza para calcular las proporciones de mezcla αk, así como los parámetros individuales de densidad gaussiana μk y σK. Cada Gaussiana representa un evento periódico, y se modela de manera similar como se menciona en la Sección 5.1. 6. EVENTOS A PARTIR DE CARACTERÍSTICAS Después de identificar y modelar ráfagas para todas las características, la siguiente tarea es pintar un cuadro del evento con un posible conjunto de características representativas. 6.1 Correlación de Características Si dos características fi y fj son representativas del mismo evento, deben cumplir las siguientes condiciones necesarias: 1. fi y fj están distribuidas de manera idéntica: yfi ∼ yfj. 2. fi y fj tienen una alta superposición de documentos. Medición de la similitud de la distribución de características. Medimos la similitud entre dos características fi y fj utilizando la divergencia KL discreta definida de la siguiente manera. Definición 6. (similitud de características) KL(fi, fj) se da por max(KL(fi|fj), KL(fj|fi)), donde KL(fi|fj) = T t=1 f(yfi(t)|θfi)log f(yfi(t)|θfi) f(yfj(t)|θfj). (1) Dado que la divergencia KL no es simétrica, definimos la similitud entre fi y fj como el máximo entre KL(fi|fj) y KL(fj|fi). Además, la similitud entre dos características aperiódicas puede calcularse utilizando una forma cerrada de la divergencia de Kullback-Leibler [16]. La misma fórmula discreta de divergencia KL de la Ecuación 1 se emplea para calcular la similitud entre dos características periódicas. A continuación, definimos la similitud general entre un conjunto de características R utilizando el valor máximo de divergencia KL entre características como sigue. Definición 7. (similitud de conjuntos) KL(R) = max ∀fi, fj ∈R KL(fi, fj). Superposición de documentos: Sea Mi el conjunto de todos los documentos que contienen la característica fi. Dadas dos características fi y fj, el conjunto de documentos superpuestos que contienen ambas características es Mi ∩ Mj. De manera intuitiva, cuanto mayor sea |Mi ∩ Mj|, es más probable que fi y fj estén altamente correlacionados. Definimos el grado de superposición de documentos entre dos características fi y fj de la siguiente manera. Definición 8. (Superposición de características DF) d(fi, fj) = |Mi∩Mj| min(|Mi|, |Mj|). En consecuencia, la superposición de DF entre un conjunto de características R también está definida. Definición 9. (Superposición de Conjuntos DF) d(R) = min ∀fi, fj ∈R d(fi, fj). 6.2 Detección de Eventos Codiciosa No Supervisada Utilizamos características de HH para detectar eventos aperiódicos importantes, características de LH para detectar eventos aperiódicos menos reportados/poco importantes, y características de HL para detectar eventos periódicos. Todos comparten el mismo algoritmo. Dado el rasgo explosivo fi ∈ HH, el objetivo es encontrar rasgos altamente correlacionados de HH. El conjunto de características similares a fi puede describir colectivamente un evento. Específicamente, necesitamos encontrar un subconjunto Ri de HH que minimice la siguiente función de costo: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) El evento subyacente e (asociado con la explosión de fi) puede ser representado por Ri como y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) El análisis de la explosión para el evento e es exactamente el mismo que la trayectoria de características. El costo en la Ecuación 2 se puede minimizar utilizando nuestro algoritmo de detección de eventos UG codicioso no supervisado, que se describe en el Algoritmo 2. El algoritmo UG permite una característica Algoritmo 2 Detección de eventos codiciosos no supervisados (UG). Salida: ek como Ec. 3. Además, los eventos triviales que solo contienen características de año/mes (es decir, un evento que solo contiene una característica de agosto podría ser identificado en un flujo de noticias de 1 año) podrían ser eliminados, aunque dichos eventos tendrán un costo inherente alto y deberían estar clasificados muy bajos. Tenga en cuenta que nuestro algoritmo UG solo requiere un parámetro dependiente de los datos, el límite entre el espectro de alta y baja potencia, que debe establecerse una vez, y este parámetro puede estimarse fácilmente utilizando el algoritmo HS (Algoritmo 1). 7. EXPERIMENTOS En esta sección, estudiamos el rendimiento de nuestro método de categorización de características y algoritmo de detección de eventos. Primero presentamos el conjunto de datos y la configuración experimental, luego evaluamos subjetivamente la categorización de características para HH, HL, LH, LL y SW. Finalmente, estudiamos el problema de detección de eventos (a)periódicos con el Algoritmo 2. 7.1. Conjunto de datos y configuración experimental El Corpus de Reuters contiene 806,791 noticias en inglés desde el 20/08/1996 hasta el 19/08/1997 con una resolución diaria. La versión 2 del software de código abierto Lucene [1] se utilizó para tokenizar el contenido de texto de noticias y generar el vector documento-palabra. Con el fin de preservar los tiempos verbales pasados/presentes/futuros sensibles al tiempo y las diferencias entre los sustantivos en minúscula y las entidades nombradas en mayúscula, no se realizó ningún truncamiento. Dado que la eliminación dinámica de palabras vacías es una de las funcionalidades de nuestro método, no se eliminó ninguna palabra vacía. Eliminamos los caracteres no ingleses, sin embargo, después de eso, el número de características de palabras asciende a 423,433. Todos los experimentos se implementaron en Java y se llevaron a cabo en una PC Pentium 4 de 3.2 GHz con Windows 2003 Server y 1 GB de memoria. 7.2 Categorización de características Descargamos 34 stopwords bien conocidos utilizados por el motor de búsqueda de Google como nuestras características de entrenamiento iniciales, que incluyen a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en y www. Excluimos las últimas cinco palabras vacías ya que son poco comunes en noticias. Al analizar solo historias de noticias durante 259 días laborables, calculamos el límite superior del espectro de potencia para las palabras vacías en 11.18 y los rangos correspondientes de DFIDF van desde 0.1182 hasta 0.3691. Cualquier característica f que cumpla con Sf <= 11.18 y 0.1182 <= DFIDFf <= 0.3691 durante los días de la semana se considerará una palabra vacía. De esta manera, se encontraron y eliminaron 470 palabras vacías como se muestra en la Figura 9. Algunas palabras vacías detectadas son A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) y much (P = 22, S = 0.80, DFIDF = 0.1865). Después de la eliminación de estas palabras vacías, la distribución de las noticias entre semana y los fines de semana están más o menos equilibradas, y en los experimentos subsiguientes, haremos uso del corpus completo (entre semana y fines de semana). El valor del espectro de potencia límite superior de 11.18 para el entrenamiento de palabras vacías fue seleccionado como el límite entre el espectro de alta potencia y baja potencia. El límite entre alta y baja periodicidad se estableció en 365/2 = 183. Todos los 422,963 (423433 − 470) rasgos de palabras fueron categorizados en 4 conjuntos de rasgos: HH (69 rasgos), HL (1,087 rasgos), LH (83,471 rasgos) y LL (338,806 rasgos) como se muestra en la Figura 10. En la Figura 10, cada nivel de gris denota la densidad relativa de características en una región cuadrada, medida por log10(1 + Dk), donde Dk es el número de características dentro de la k-ésima región cuadrada. A partir de la figura, podemos hacer el 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figura 9: Distribución de SW (palabras vacías) en las regiones HH, HL, LH y LL. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figura 10: Distribución de características categorizadas en los cuatro cuadrantes (sombreado en escala logarítmica). siguientes observaciones: 1. La mayoría de las características tienen un valor bajo de S y son fácilmente distinguibles de aquellas características que tienen un valor mucho más alto de S, lo que nos permite detectar eventos importantes (a)periódicos de eventos triviales seleccionando características con un alto valor de S. 2. Las características en los cuadrantes HH y LH son aperiódicas, las cuales están bien separadas (gran brecha horizontal) de las características periódicas. Esto permite detectar de manera confiable eventos aperiódicos y eventos periódicos de forma independiente. 3. La frontera (vertical) entre el espectro de alta y baja potencia no es tan clara y el valor exacto dependerá de la aplicación específica. Al revisar la distribución de dispersión de las características de SW en HH, HL, LH y LL como se muestra en la Figura 9, encontramos que el 87.02% (409/470) de las stopwords detectadas se originaron en LL. La clasificación LL y las altas puntuaciones de DFIDF de las palabras vacías concuerdan con la noción generalmente aceptada de que las palabras vacías son igualmente frecuentes en todo momento. Por lo tanto, establecer el límite entre el espectro de alta y baja potencia utilizando el límite superior Sf de SW es una heurística razonable. 7.3 Detección de Eventos Aperiódicos Evaluaremos nuestras dos hipótesis, 1)los eventos aperiódicos importantes pueden ser definidos por un conjunto de características HH, y 2)los eventos aperiódicos menos reportados pueden ser definidos por un conjunto de características LH. Dado que no existen flujos de noticias de referencia para la detección de eventos (los conjuntos de datos de TDT no son flujos adecuados), evaluamos la calidad de los eventos detectados automáticamente comparándolos con eventos confirmados manualmente mediante la búsqueda en el corpus. Entre las 69 características de HH, detectamos 17 eventos aperiódicos importantes como se muestra en la Tabla 1 (e1 - e17). Ten en cuenta que toda la identificación tomó menos de 1 segundo, después de eliminar los eventos que solo contenían la característica del mes. De los 17 eventos, aparte de las superposiciones entre e3 y e4 (ambos describen el mismo evento de rehenes), e11 y e16 (ambos sobre informes de empresas), los 14 eventos identificados son extremadamente precisos y corresponden muy bien a los principales eventos del período. Por ejemplo, la derrota de Bob Dole, la elección de Tony Blair, el ataque con misiles a Iraq, etc. Recuerde que seleccionar las características para un evento debería minimizar el costo en la Ecuación 2 de tal manera que 1) el número de características abarque diferentes eventos, y 2) no se seleccionarán todas las características relevantes para un evento, por ejemplo, la característica Clinton es representativa para e12, pero dado que Clinton se relaciona con muchos otros eventos, su señal de dominio temporal es muy diferente de la de otras características representativas como Dole y Bob. El número de documentos de un evento detectado se estima aproximadamente por el número de documentos indexados que contienen las características representativas. Podemos ver que los 17 eventos aperiódicos importantes son eventos reportados popularmente. Después de 742 minutos de tiempo de computación, detectamos 23,525 eventos aperiódicos menos reportados de 83,471 características de LH. La Tabla 1 enumera los 5 principales eventos aperiódicos detectados (e18 - e22) con respecto al costo. Descubrimos que estos 5 eventos son en realidad eventos muy triviales con solo unos pocos informes de noticias, y suelen ser englobados por algunos temas más grandes. Por ejemplo, e22 es uno de los eventos de rescate en un tema de secuestro de avión. Una ventaja de nuestro Algoritmo UG para descubrir eventos aperiódicos poco reportados es que podemos detectar con precisión el verdadero período del evento. 7.4 Detección de Eventos Periódicos Entre las 1,087 características de HL, se detectaron 330 eventos periódicos importantes en un tiempo de cálculo de 10 minutos. La Tabla 1 enumera los 5 eventos periódicos detectados con respecto al costo (e23 - e27). Todos los eventos periódicos detectados son realmente válidos y corresponden a eventos periódicos de la vida real. El modelo GMM es capaz de detectar y estimar el período de ráfagas de manera precisa, aunque no puede distinguir la ligera diferencia entre cada lunes a viernes y todos los días de la semana, como se muestra en e23. También observamos que e26 es en realidad un subconjunto de e27 (partido de fútbol), lo cual es aceptable ya que los resultados de la liga de Sheffield se anuncian de forma independiente cada fin de semana. 8. CONCLUSIONES Este artículo adoptó una perspectiva completamente nueva para analizar las trayectorias de características como señales en el dominio del tiempo. Al considerar las frecuencias de los documentos en el dominio del tiempo y de la frecuencia, pudimos derivar muchas nuevas características sobre los flujos de noticias que antes eran desconocidas, por ejemplo, las diferentes distribuciones de palabras vacías durante los días de la semana y los fines de semana. Por primera vez en el área de TDT, aplicamos un enfoque sistemático para detectar automáticamente eventos importantes y menos reportados, periódicos y aperiódicos. La idea clave de nuestro trabajo radica en las observaciones de que los eventos periódicos tienen características representativas periódicas y los eventos (in)importantes tienen características representativas (in)activas, diferenciadas por sus espectros de potencia y períodos de tiempo. Para abordar el problema de detección de eventos reales, se utilizó un enfoque basado en densidad de mezcla simple y efectivo para identificar ráfagas de características y sus períodos asociados de ráfagas. También diseñamos un algoritmo codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos, el cual tuvo éxito en detectar eventos reales como se muestra en la evaluación en un flujo de noticias reales. Aunque no hemos realizado ninguna comparación de referencia con otro enfoque, simplemente porque no hay trabajos previos en el problema abordado. El trabajo futuro incluye evaluar la recuperación de eventos detectados en un flujo de noticias etiquetado, y comparar nuestro modelo con los métodos equivalentes más cercanos, que actualmente se limitan a los métodos de Kleinberg [12] (que solo pueden detectar ciertos tipos de eventos explosivos dependiendo de la configuración de parámetros), Fung et al. [9], y Swan y Allan [18]. Sin embargo, creemos que nuestro método simple y efectivo será útil para todos los practicantes de TDT, y será especialmente útil para el análisis exploratorio inicial de flujos de noticias. REFERENCIAS [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Alertas de noticias de Google, http://www.google.com/alerts. [3] Corpus de Reuters, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan. Detección y seguimiento de temas. Organización de la información basada en eventos. Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, y H. Jin. La detección de la primera historia en tdt es difícil. En CIKM, páginas 374-381, 2000. [6] J. Allan, C. Wade y A. Bolivar. Recuperación y detección de novedades a nivel de oración. En SIGIR, páginas 314-321, 2003. [7] T. Brants, F. Chen y A. Farahat. Un sistema para la detección de nuevos eventos. En SIGIR, páginas 330-337, 2003. [8] A. P. Dempster, N. M. Laird y D. B. Rubin. Máxima verosimilitud a partir de datos incompletos a través del algoritmo EM. Revista de la Real Sociedad Estadística, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu y H. Lu. Detección de eventos explosivos sin parámetros en flujos de texto. En VLDB, páginas 181-192, 2005. [10] Q. Él, K. Chang y E.-P. Lim. Un modelo para la detección anticipada de eventos. En ER, páginas 168-181, 2006. [11] Q. Él, K. Chang, E.-P. Lim y J. Zhang. Representación de características intermitentes para la agrupación de flujos de texto. En SDM, aceptado, 2007. [12] J. Kleinberg. Estructura explosiva y jerárquica en arroyos. En SIGKDD, páginas 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan y A. Tomkins. Sobre la evolución explosiva del blogosfera. En WWW, páginas 159-178, 2005. [14] G. Kumaran y J. Allan. Clasificación de texto y entidades nombradas para la detección de nuevos eventos. En SIGIR, páginas 297-304, 2004. [15] Q. Mei y C. Zhai. Descubriendo patrones temáticos evolutivos a partir de texto: una exploración de la minería de texto temporal. En SIGKDD, páginas 198-207, 2005. [16] W. D. Penny. Divergencias de Kullback-Leibler de densidades normales, gamma, dirichlet y wishart. Informe técnico, 2001. [17] N. Stokes y J. Carthy. Combinando clasificadores de documentos semánticos y sintácticos para mejorar la detección de la primera noticia. En SIGIR, páginas 424-425, 2001. [18] R. Swan y J. Allan. Generación automática de líneas de tiempo de resumen. En SIGIR, páginas 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena y D. Gunopulos. Identificando similitudes, periodicidades y ráfagas en las consultas de búsqueda en línea. En SIGMOD, páginas 131-142, 2004. [20] Y. Yang, T. Pierce y J. Carbonell. Un estudio de detección de eventos retrospectivos y en línea. En SIGIR, páginas 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell y C. Jin. Detección de novedades condicionada por el tema. En SIGKDD, páginas 688-693, 2002. Tabla 1: Todos los eventos aperiódicos importantes (e1 - e17), los 5 eventos aperiódicos menos reportados (e18 - e22) y los 5 eventos periódicos importantes (e23 - e27). Evento detectado y período de actividad intensa Doc # Verdadero evento e1 (Sali, Berisha, Albania, albanés, marzo) 02/02/199705/29/1997 1409 El presidente albanés Sali Berisha perdió en una elección temprana y renunció, 12/1996-07/1997. e2 (Seko, Mobutu, Sese, Kabila) 03/22/1997-06/09/1997 2273 El presidente de Zaire, Mobutu Sese, coordinó la rebelión nativa y fracasó el 16/05/1997. e3 (Marxista, peruano) 11/19/1996-03/05/1997 824 Los rebeldes de Perú (Movimiento Revolucionario Tupac Amaru) lideraron un asedio de rehenes en Lima a principios de 1997. e4 (Movimiento, Tupac, Amaru, Lima, rehén, rehenes) 11/16/1996-03/20/1997 824 Lo mismo que e3. e5 (Kinshasa, Kabila, Laurent, Congo) 03/26/199706/15/1997 1378 Zaire fue renombrado República Democrática del Congo el 16/05/1997. e6 (Jospin, Lionel, junio) 05/10/1997-07/09/1997 605 Tras las elecciones generales tempranas alrededor de 06/1997, Lionel Jospin fue nombrado Primer Ministro el 02/06/1997. e7 (Irak, misil) 08/31/1996-09/13/1996 1262 EE. UU. disparó un misil a Irak el 03/09/1996 y el 04/09/1996. e8 (kurdo, Bagdad, iraquí) 08/29/1996-09/09/1996 1132 Tropas iraquíes lucharon con facciones kurdas alrededor de 09/1996. e9 (mayo, Blair) 03/24/1997-07/04/1997 1049 Tony Blair se convirtió en el Primer Ministro del Reino Unido el 02/05/1997. e10 (slalom, esquí) 12/05/1996-03/21/1997 253 Juego de eslalon de esquí alpino en 01/1997-02/1997. e11 (Interino, meses) 09/24/1996-12/31/1996 3063 Tokio publicó los resultados interinos de la empresa para los últimos meses en 09/1996-12/1996. e12 (Dole, Bob) 09/09/1996-11/24/1996 1599 Bob Dole perdió las elecciones presidenciales de EE. UU. de 1996. e13 (julio, Sen) 06/25/1997-06/25/1997 344 El Primer Ministro de Camboya, Hun Sen, lanzó un sangriento golpe militar en 07/1997. e14 (Hebrón) 10/15/1996-02/14/1997 2098 Hebrón fue dividida en dos sectores a principios de 1997. e15 (abril, Pascua) 02/23/1997-05/04/1997 480 Festividades de Pascua alrededor de 04/1997 (para occidentales y ortodoxos). e16 (Diluido, Grupo) 04/27/1997-07/20/1997 1888 Tokio publicó todos los resultados del grupo 96/97 en 04/199707/1997. e17 (diciembre, Navidad) 11/17/1996-01/26/1997 1326 Festín de Navidad a finales de 12/1997. e18 (Kolaceva, invierno, Juntos, paseos, Zajedno, Slobodan, Belgrado, serbio, Serbia, Draskovic, municipal, Kragujevac) 1/25/1997 3 Estudiantes universitarios organizaron una vigilia en la calle Kolaceva contra el gobierno el 25/01/1997. e19 (Tutsi, Luvengi, Burundi, Uvira, combustible, Banyamulenge, burundés, Kivu, Kiliba, Runingo, Kagunga, Bwegera) 10/19/1996 6 Estallaron nuevos enfrentamientos alrededor de Uvira entre las fuerzas armadas de Zaire y los rebeldes Tutsi de Banyamulenge el 19/10/1996. e20 (Malantacchi, Corea, Guy, Rider, Sindicatos, trabajo, Confederación, embestido, Ginebra, paradas, Virgin, contratar, Myongdong, Metalúrgicos) 1/11/1997 2 Marcello Malantacchi, secretario general de la Federación Internacional de Metalúrgicos, y Guy Rider, quien dirige la oficina de Ginebra de la Confederación Internacional de Sindicatos Libres, atacaron la nueva ley laboral de Corea del Sur el 11/01/1997. e21 (DBS, Raﬄes) 8/17/1997 9 La lista de la unidad de DBS Land Raﬄes Holdings de Singapur planea el 17/08/1997. e22 (conservador, combustible, Galawa, Huddle, Leul, Beausse) 11/24/1996 3 Rescataron a una mujer y a su bebé durante un secuestro de un avión etíope que se quedó sin combustible y se estrelló en el mar cerca de la playa Le Galawa el 24/11/1996. e23 (PRECIO, LISTADO, MLN, VENCIMIENTO, CUPÓN, MOODY, MONTO, PRIMERO, ISS, TIPO, PAGO, PRESTAMISTA) Lunes a viernes/semana 7966 Anuncian el precio de los bonos todos los días de la semana. e24 (No auditado, Terminado, Meses, Ponderado, Provisión, Costo, Venta, Ingresos, Pérdida, Ingreso, excepto, Shrs, Revs) cada temporada 2264 Informes de ingresos netos-pérdidas publicados por empresas en cada temporada. e25 (calificación, Wall Street, Ian) Lunes a viernes/semana 21767 Informes de acciones de Wall Street todos los días de la semana. e26 (Sheffield, liga, goles de puntuación, delantero, juegos) cada viernes, sábado y domingo 574 Resultados de partidos de la liga de fútbol de Sheffield publicados los viernes, sábados y domingos 10 veces más que en los otros 4 días. e27 (fútbol, partidos, Resultados, temporada, juego, Copa, partido, victoria, vencer, jugado, jugar, división) cada viernes, sábado y domingo 2396 Juegos de fútbol celebrados los viernes, sábados y domingos 7 veces más que en los otros 4 días. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "aperiodic event": {
            "translated_key": "evento aperiódico",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Analyzing Feature Trajectories for Event Detection Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg School of Computer Engineering Nanyang Technological University Block N4, Nanyang Avenue, Singapore 639798 ABSTRACT We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words.",
                "A set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner.",
                "The document frequency of each word across time is treated like a time series, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point.",
                "In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events.",
                "All of the above methods can be applied to time series data in general.",
                "We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events.",
                "Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Experimentation. 1.",
                "INTRODUCTION There are more than 4,000 online news sources in the world.",
                "Manually monitoring all of them for important events has become difficult or practically impossible.",
                "In fact, the topic detection and tracking (TDT) community has for many years been trying to come up with a practical solution to help people monitor news effectively.",
                "Unfortunately, the holy grail is still elusive, because the vast majority of TDT solutions proposed for event detection [20, 5, 17, 4, 21, 7, 14, 10] are either too simplistic (based on cosine similarity [5]) or impractical due to the need to tune a large number of parameters [9].",
                "The ineffectiveness of current TDT technologies can be easily illustrated by subscribing to any of the many online news alerts services such as the industryleading Google News Alerts [2], which generates more than 50% false alarms [10].",
                "As further proof, portals like Yahoo take a more pragmatic approach by requiring all machine generated news alerts to go through a human operator for confirmation before sending them out to subscribers.",
                "Instead of attacking the problem with variations of the same hammer (cosine similarity and TFIDF), a fundamental understanding of the characteristics of news stream data is necessary before any major breakthroughs can be made in TDT.",
                "Thus in this paper, we look at news stories and feature trends from the perspective of analyzing a time-series word signal.",
                "Previous work like [9] has attempted to reconstruct an event with its representative features.",
                "However, in many predictive event detection tasks (i.e., retrospective event detection), there is a vast set of potential features only for a fixed set of observations (i.e., the obvious bursts).",
                "Of these features, often only a small number are expected to be useful.",
                "In particular, we study the novel problem of analyzing feature trajectories for event detection, borrowing a well-known technique from signal processing: identifying distributional correlations among all features by spectral analysis.",
                "To evaluate our method, we subsequently propose an unsupervised event detection algorithm for news streams. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Easter April (a) <br>aperiodic event</br> 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Unaudited Ended (b) periodic event Figure 1: Feature correlation (DFIDF:time) between a) Easter and April b) Unaudited and Ended.",
                "As an illustrative example, consider the correlation between the words Easter and April from the Reuters Corpus1 .",
                "From the plot of their normalized DFIDF in Figure 1(a), we observe the heavy overlap between the two words circa 04/1997, which means they probably both belong to the same event during that time (Easter feast).",
                "In this example, the hidden event Easter feast is a typical important <br>aperiodic event</br> over 1-year data.",
                "Another example is given by Figure 1(b), where both the words Unaudited and Ended 1 Reuters Corpus is the default dataset for all examples. exhibit similar behaviour over periods of 3 months.",
                "These two words actually originated from the same periodic event, net income-loss reports, which are released quarterly by publicly listed companies.",
                "Other observations drawn from Figure 1 are: 1) the bursty period of April is much longer than Easter, which suggests that April may exist in other events during the same period; 2) Unaudited has a higher average DFIDF value than Ended, which indicates Unaudited to be more representative for the underlying event.",
                "These two examples are but the tip of the iceberg among all word trends and correlations hidden in a news stream like Reuters.",
                "If a large number of them can be uncovered, it could significantly aid TDT tasks.",
                "In particular, it indicates the significance of mining correlating features for detecting corresponding events.",
                "To summarize, we postulate that: 1) An event is described by its representative features.",
                "A periodic event has a list of periodic features and an <br>aperiodic event</br> has a list of aperiodic features; 2) Representative features from the same event share similar distributions over time and are highly correlated; 3) An important event has a set of active (largely reported) representative features, whereas an unimportant event has a set of inactive (less-reported) representative features; 4) A feature may be included by several events with overlaps in time frames.",
                "Based on these observations, we can either mine representative features given an event or detect an event from a list of highly correlated features.",
                "In this paper, we focus on the latter, i.e., how correlated features can be uncovered to form an event in an unsupervised manner. 1.1 Contributions This paper has three main contributions: • To the best of our knowledge, our approach is the first to categorize word features for heterogenous events.",
                "Specifically, every word feature is categorized into one of the following five feature types based on its power spectrum strength and periodicity: 1) HH (high power and high/long periodicity): important aperiodic events, 2) HL (high power and low periodicity): important periodic events, 3) LH (low power and high periodicity): unimportant aperiodic events, 4) LL (low power and low periodicity): non-events, and 5) SW (stopwords), a higher power and periodicity subset of LL comprising stopwords, which contains no information. • We propose a simple and effective mixture densitybased approach to model and detect feature bursts. • We come up with an unsupervised event detection algorithm to detect both aperiodic and periodic events.",
                "Our algorithm has been evaluated on a real news stream to show its effectiveness. 2.",
                "RELATED WORK This work is largely motivated by a broader family of problems collectively known as Topic Detection and Tracking (TDT) [20, 5, 17, 4, 21, 7, 14, 10].",
                "Moreover, most TDT research so far has been concerned with clustering/classifying documents into topic types, identifying novel sentences [6] for new events, etc., without much regard to analyzing the word trajectory with respect to time.",
                "Swan and Allan [18] first attempted using co-occuring terms to construct an event.",
                "However, they only considered named entities and noun phrase pairs, without considering their periodicities.",
                "On the contrary, our paper considers all of the above.",
                "Recently, there has been significant interest in modeling an event in text streams as a burst of activities by incorporating temporal information.",
                "Kleinbergs seminal work described how bursty features can be extracted from text streams using an infinite automaton model [12], which inspired a whole series of applications such as Kumars identification of bursty communities from Weblog graphs [13], Meis summarization of evolutionary themes in text streams [15], Hes clustering of text streams using bursty features [11], etc.",
                "Nevertheless, none of the existing work specifically identified features for events, except for Fung et al. [9], who clustered busty features to identify various bursty events.",
                "Our work differs from [9] in several ways: 1) we analyze every single feature, not only bursty features; 2) we classify features along two categorical dimensions (periodicity and power), yielding altogether five primary feature types; 3) we do not restrict each feature to exclusively belong to only one event.",
                "Spectral analysis techniques have previously been used by Vlachos et al. [19] to identify periodicities and bursts from query logs.",
                "Their focus was on detecting multiple periodicities from the power spectrum graph, which were then used to index words for query-by-burst search.",
                "In this paper, we use spectral analysis to classify word features along two dimensions, namely periodicity and power spectrum, with the ultimate goal of identifying both periodic and aperiodic bursty events. 3.",
                "DATA REPRESENTATION Let T be the duration/period (in days) of a news stream, and F represents the complete word feature space in the classical static Vector Space Model (VSM). 3.1 Event Periodicity Classification Within T, there may exist certain events that occur only once, e.g., Tony Blair elected as Prime Minister of U.K., and other recurring events of various periodicities, e.g., weekly soccer matches.",
                "We thus categorize all events into two types: aperiodic and periodic, defined as follows.",
                "Definition 1. (<br>aperiodic event</br>) An event is aperiodic within T if it only happens once.",
                "Definition 2. (Periodic Event) If events of a certain event genre occur regularly with a fixed periodicity P ≤ T/2 , we say that this particular event genre is periodic, with each member event qualified as a periodic event.",
                "Note that the definition of aperiodic is relative, i.e., it is true only for a given T, and may be invalid for any other T > T. For example, the event Christmas feast is aperiodic for T ≤ 365 but periodic for T ≥ 730. 3.2 Representative Features Intuitively, an event can be described very concisely by a few discriminative and representative word features and vice-versa, e.g., hurricane, sweep, and strike could be representative features of a Hurricane genre event.",
                "Likewise, a set of strongly correlated features could be used to reconstruct an event description, assuming that strongly correlated features are representative.",
                "The representation vector of a word feature is defined as follows: Definition 3. (Feature Trajectory) The trajectory of a word feature f can be written as the sequence yf = [yf (1), yf (2), . . . , yf (T)], where each element yf (t) is a measure of feature f at time t, which could be defined using the normalized DFIDF score2 yf (t) = DFf (t) N(t) × log( N DFf ), where DFf (t) is the number of documents (local DF) containing feature f at day t, DFf is the total number of documents (global DF) containing feature f over T, N(t) is the number of documents for day t, and N is the total number of documents over T. 4.",
                "IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 Spectral Analysis for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. DFT can represent the original time series as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T.",
                "The original trajectory can be reconstructed with just the dominant frequencies, which can be determined from the power spectrum using the popular periodogram estimator.",
                "The periodogram is a sequence of the squared magnitude of the Fourier coefficients, Xk 2 , k = 1, 2, . . . , T/2 , which indicates the signal power at frequency k/T in the spectrum.",
                "From the power spectrum, the dominant period is chosen as the inverse of the frequency with the highest power spectrum, as follows.",
                "Definition 4. (Dominant Period) The dominant period (DP) of a given feature f is Pf = T/ arg max k Xk 2 .",
                "Accordingly, we have Definition 5. (Dominant Power Spectrum) The dominant power spectrum (DPS) of a given feature f is Sf = Xk 2 , with Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorizing Features The DPS of a feature trajectory is a strong indicator of its activeness at the specified frequency; the higher the DPS, the more likely for the feature to be bursty.",
                "Combining DPS with DP, we therefore categorize all features into four types: 2 We normalize yf (t) as yf (t) = yf (t)/ T i=1 yf (i) so that it could be interpreted as a probability. • HH: high Sf , aperiodic or long-term periodic (Pf > T/2 ); • HL: high Sf , short-term periodic (Pf ≤ T/2 ); • LH: low Sf , aperiodic or long-term periodic; • LL: low Sf , short-term periodic.",
                "The boundary between long-term and short-term periodic is set to T/2 .",
                "However, distinguishing between a high and low DPS is not straightforward, which will be tackled later.",
                "Properties of Different Feature Sets To better understand the properties of HH, HL, LH and LL, we select four features, Christmas, soccer, DBS and your as illustrative examples.",
                "Since the boundary between high and low power spectrum is unclear, these chosen examples have relative wide range of power spectrum values.",
                "Figure 2(a) shows the DFIDF trajectory for Christmas with a distinct burst around Christmas day.",
                "For the 1-year Reuters dataset, Christmas is classified as a typical <br>aperiodic event</br> with Pf = 365 and Sf = 135.68, as shown in Figure 2(b).",
                "Clearly, the value of Sf = 135.68 is reasonable for a well-known bursty event like Christmas. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Christmas(DFIDF:time) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Christmas(S:frequency) Figure 2: Feature Christmas with relative high Sf and long-term Pf .",
                "The DFIDF trajectory for soccer is shown in Figure 3(a), from which we can observe that there is a regular burst every 7 days, which is again verified by its computed value of Pf = 7, as shown in Figure 3(b).",
                "Using the domain knowledge that soccer games have more matches every Saturday, which makes it a typical and heavily reported periodic event, we thus consider the value of Sf = 155.13 to be high. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) soccer(DFIDF:time) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) soccer(S:frequency) Figure 3: Feature soccer with relative high Sf and short-term Pf .",
                "From the DFIDF trajectory for DBS in Figure 4(a), we can immediately deduce DBS to be an infrequent word with a trivial burst on 08/17/1997 corresponding to DBS Land Raﬄes Holdings plans.",
                "This is confirmed by the long period of Pf = 365 and low power of Sf = 0.3084 as shown in Figure 4(b).",
                "Moreover, since this <br>aperiodic event</br> is only reported in a few news stories over a very short time of few days, we therefore say that its low power value of Sf = 0.3084 is representative of unimportant events.",
                "The most confusing example is shown in Figure 5 for the word feature your, which looks very similar to the graph for soccer in Figure 3.",
                "At first glance, we may be tempted to group both your and soccer into the same category of HL or LL since both distributions look similar and have the same dominant period of approximately a week.",
                "However, further 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:time) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frequency) Figure 4: Feature DBS with relative low Sf and long-term Pf . analysis indicates that the periodicity of your is due to the differences in document counts for weekdays (average 2,919 per day) and weekends3 (average 479 per day).",
                "One would have expected the periodicity of a stopword like your to be a day.",
                "Moreover, despite our DFIDF normalization, the weekday/weekend imbalance still prevailed; stopwords occur 4 times more frequently on weekends than on weekdays.",
                "Thus, the DPS remains the only distinguishing factor between your (Sf = 9.42) and soccer (Sf = 155.13).",
                "However, it is very dangerous to simply conclude that a power value of S = 9.42 corresponds to a stopword feature. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) your(DFIDF:time) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) your(S:frequency) Figure 5: Feature your as an example confusing with feature soccer.",
                "Before introducing our solution to this problem, lets look at another LL example as shown in Figure 6 for beenb, which is actually a confirmed typo.",
                "We therefore classify beenb as a noisy feature that does not contribute to any event.",
                "Clearly, the trajectory of your is very different from beenb, which means that the former has to be considered separately. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figure 6: Feature beenb with relative low Sf and short-term Pf .",
                "Stop Words (SW) Feature Set Based on the above analysis, we realize that there must be another feature set between HL and LL that corresponds to the set of stopwords.",
                "Features from this set has moderate DPS and low but known dominant period.",
                "Since it is hard to distinguish this feature set from HL and LL only based on DPS, we introduce another factor called average DFIDF (DFIDF).",
                "As shown in Figure 5, features like your usually have a lower DPS than a HL feature like soccer, but have a much higher DFIDF than another LL noisy feature such as beenb.",
                "Since such properties are usually characteristics of stopwords, we group features like your into the newly defined stopword (SW) feature set.",
                "Since setting the DPS and DFIDF thresholds for identifying stopwords is more of an art than science, we proposed a heuristic HS algorithm, Algorithm 1.",
                "The basic idea is to only use news stories from weekdays to identify stopwords. 3 The weekends here also include public holidays falling on weekdays.",
                "The SW set is initially seeded with a small set of 29 popular stopwords utilized by Google search engine.",
                "Algorithm 1 Heuristic Stopwords detection (HS) Input: Seed SW set, weekday trajectories of all words 1: From the seed set SW, compute the maximum DPS as UDPS, maximum DFIDF as UDFIDF, and minimum of DFIDF as LDFIDF. 2: for fi ∈ F do 3: Compute DFT for fi. 4: if Sfi ≤ UDPS and DFIDFfi ∈ [LDFIDF, UDFIDF] then 5: fi → SW 6: F = F − fi 7: end if 8: end for Overview of Feature Categorization After the SW set is generated, all stopwords are removed from F. We then set the boundary between high and low DPS to be the upper bound of the SW sets DPS.",
                "An overview of all five feature sets is shown in Figure 7.",
                "Figure 7: The 5 feature sets for events. 5.",
                "IDENTIFYING BURSTS FOR FEATURES Since only features from HH, HL and LH are meaningful and could potentially be representative to some events, we pruned all other feature classified as LL or SW.",
                "In this section, we describe how bursts can be identified from the remaining features.",
                "Unlike Kleinbergs burst identification algorithm [12], we can identify both significant and trivial bursts without the need to set any parameters. 5.1 Detecting Aperiodic Features Bursts For each feature in HH and HL, we truncate its trajectory by keeping only the bursty period, which is modeled with a Gaussian distribution.",
                "For example, Figure 8 shows the word feature Iraq with a burst circa 09/06/1996 being modeled as a Gaussian.",
                "Its bursty period is defined by [μf − σf , μf + σf ] as shown in Figure 8(b). 5.2 Detecting Periodic Features Bursts Since we have computed the DP for a periodic feature f, we can easily model its periodic feature trajectory yf using 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) original DFIDF:time 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 burst= [μ-σ, μ+σ] (b) identifying burst Figure 8: Modeling Iraqs time series as a truncated Gaussian with μ = 09/06/1996 and σ = 6.26. a mixture of K = T/Pf Gaussians: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , where the parameter set θf = {αk, μk, σk}K k=1 comprises: • αk is the probability of assigning yf into the kth Gaussian. αk > 0, ∀k ∈ [1, K] and K k=1 αk = 1; • μk/σk is mean/standard deviation of the kth Gaussian.",
                "The well known Expectation Maximization (EM) [8] algorithm is used to compute the mixing proportions αk, as well as the individual Gaussian density parameters μk and σK .",
                "Each Gaussian represents one periodic event, and is modeled similarly as mentioned in Section 5.1. 6.",
                "EVENTS FROM FEATURES After identifying and modeling bursts for all features, the next task is to paint a picture of the event with a potential set of representative features. 6.1 Feature Correlation If two features fi and fj are representative of the same event, they must satisfy the following necessary conditions: 1. fi and fj are identically distributed: yfi ∼ yfj . 2. fi and fj have a high document overlap.",
                "Measuring Feature Distribution Similarity We measure the similarity between two features fi and fj using discrete KL-divergence defined as follows.",
                "Definition 6. (feature similarity) KL(fi, fj ) is given by max(KL(fi|fj ), KL(fj |fi)), where KL(fi|fj ) = T t=1 f(yfi (t)|θfi )log f(yfi (t)|θfi ) f(yfj (t)|θfj ) . (1) Since KL-divergence is not symmetric, we define the similarity between between fi and fj as the maximum of KL(fi|fj ) and KL(fj |fi).",
                "Further, the similarity between two aperiodic features can be computed using a closed form of the KL-divergence [16].",
                "The same discrete KL-divergence formula of Eq. 1 is employed to compute the similarity between two periodic features, Next, we define the overal similarity among a set of features R using the maximum inter-feature KL-Divergence value as follows.",
                "Definition 7. (sets similarity)KL(R) = max ∀fi,fj ∈R KL(fi, fj ).",
                "Document Overlap Let Mi be the set of all documents containing feature fi.",
                "Given two features fi and fj , the overlapping document set containing both features is Mi ∩ Mj .",
                "Intuitively, the higher the |Mi ∩ Mj |, the more likelty that fi and fj will be highly correlated.",
                "We define the degree of document overlap between two features fi and fj as follows.",
                "Definition 8. (Feature DF Overlap) d(fi, fj ) = |Mi∩Mj| min(|Mi|,|Mj|) .",
                "Accordingly, the DF Overlap among a set of features R is also defined.",
                "Definition 9. (Set DF Overlap) d(R) = min ∀fi,fj ∈R d(fi, fj). 6.2 Unsupervised Greedy Event Detection We use features from HH to detect important aperiodic events, features from LH to detect less-reported/unimportant aperiodic events, and features from HL to detect periodic events.",
                "All of them share the same algorithm.",
                "Given bursty feature fi ∈ HH, the goal is to find highly correlated features from HH.",
                "The set of features similar to fi can then collectively describe an event.",
                "Specifically, we need to find a subset Ri of HH that minimizes the following cost function: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) The underlying event e (associated with the burst of fi) can be represented by Ri as y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) The burst analysis for event e is exactly the same as the feature trajectory.",
                "The cost in Eq. 2 can be minimized using our unsupervised greedy UG event detection algorithm, which is described in Algorithm 2.",
                "The UG algorithm allows a feature Algorithm 2 Unsupervised Greedy event detection (UG).",
                "Input: HH, document index for each feature. 1: Sort and select features in descending DPS order: Sf1 ≥ Sf2 ≥ . . . ≥ Sf|HH| . 2: k = 0. 3: for fi ∈ HH do 4: k = k + 1. 5: Init: Ri ← fi, C(Ri) = 1/Sfi and HH = HH − fi. 6: while HH not empty do 7: m = arg min m C(Ri ∪ fm). 8: if C(Ri ∪ fm) < C(Ri) then 9: Ri ← fm and HH = HH − fm. 10: else 11: break while. 12: end if 13: end while 14: Output ek as Eq. 3. 15: end for to be contained in multiple events so that we can detect several events happening at the same time.",
                "Furthermore, trivial events only containing year/month features (i.e., an event only containing 1 feature Aug could be identified over a 1year news stream) could be removed, although such events will have inherent high cost and should already be ranked very low.",
                "Note that our UG algorithm only requires one data-dependant parameter, the boundary between high and low power spectrum, to be set once, and this parameter can be easily estimated using the HS algorithm (Algorithm 1). 7.",
                "EXPERIMENTS In this section, we study the performances of our feature categorizing method and event detection algorithm.",
                "We first introduce the dataset and experimental setup, then we subjectively evaluate the categorization of features for HH, HL, LH, LL and SW.",
                "Finally, we study the (a)periodic event detection problem with Algorithm 2. 7.1 Dataset and Experimental Setup The Reuters Corpus contains 806,791 English news stories from 08/20/1996 to 08/19/1997 at a day resolution.",
                "Version 2 of the open source Lucene software [1] was used to tokenize the news text content and generate the document-word vector.",
                "In order to preserve the time-sensitive past/present/future tenses of verbs and the differences between lower case nouns and upper case named entities, no stemming was done.",
                "Since dynamic stopword removal is one of the functionalities of our method, no stopword was removed.",
                "We did remove nonEnglish characters, however, after which the number of word features amounts to 423,433.",
                "All experiments were implemented in Java and conducted on a 3.2 GHz Pentium 4 PC running Windows 2003 Server with 1 GB of memory. 7.2 Categorizing Features We downloaded 34 well-known stopwords utilized by the Google search engine as our seed training features, which includes a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en and www.",
                "We excluded the last five stopwords as they are uncommon in news stories.",
                "By only analyzing news stories over 259 weekdays, we computed the upper bound of the power spectrum for stopwords at 11.18 and corresponding DFIDF ranges from 0.1182 to 0.3691.",
                "Any feature f satisfying Sf <= 11.18 and 0.1182 <= DFIDFf <= 0.3691 over weekdays will be considered a stopword.",
                "In this manner, 470 stopwords were found and removed as visualized in Figure 9.",
                "Some detected stopwords are A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) and much (P = 22, S = 0.80, DFIDF = 0.1865).",
                "After the removal of these stopwords, the distribution of weekday and weekend news are more or less matched, and in the ensuing experiments, we shall make use of the full corpus (weekdays and weekends).",
                "The upper bound power spectrum value of 11.18 for stopwords training was selected as the boundary between the high power and low power spectrum.",
                "The boundary between high and low periodicity was set to 365/2 = 183.",
                "All 422,963 (423433 − 470) word features were categorized into 4 feature sets: HH (69 features), HL (1,087 features), LH (83,471 features), and LL (338,806 features) as shown in Figure 10.",
                "In Figure 10, each gray level denotes the relative density of features in a square region, measured by log10(1 + Dk), where Dk is the number of features within the k-th square region.",
                "From the figure, we can make the 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figure 9: Distribution of SW (stopwords) in the HH, HL, LH, and LL regions. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figure 10: Distribution of categorized features over the four quadrants (shading in log scale). following observations: 1.",
                "Most features have low S and are easily distinguishable from those features having a much higher S, which allows us to detect important (a)periodic events from trivial events by selecting features with high S. 2.",
                "Features in the HH and LH quadrants are aperiodic, which are nicely separated (big horizontal gap) from the periodic features.",
                "This allows reliably detecting aperiodic events and periodic events independently. 3.",
                "The (vertical) boundary between high and low power spectrum is not as clearcut and the exact value will be application specific.",
                "By checking the scatter distribution of features from SW on HH, HL, LH, and LL as shown in Figure 9, we found that 87.02%(409/470) of the detected stopwords originated from LL.",
                "The LL classification and high DFIDF scores of stopwords agree with the generally accepted notion that stopwords are equally frequent over all time.",
                "Therefore, setting the boundary between high and low power spectrum using the upper bound Sf of SW is a reasonable heuristic. 7.3 Detecting Aperiodic Events We shall evaluate our two hypotheses, 1)important aperiodic events can be defined by a set of HH features, and 2)less reported aperiodic events can be defined by a set of LH features.",
                "Since no benchmark news streams exist for event detection (TDT datasets are not proper streams), we evaluate the quality of the automatically detected events by comparing them to manually-confirmed events by searching through the corpus.",
                "Among the 69 HH features, we detected 17 important aperiodic events as shown in Table 1 (e1 − e17).",
                "Note that the entire identification took less than 1 second, after removing events containing only the month feature.",
                "Among the 17 events, other than the overlaps between e3 and e4 (both describes the same hostage event), e11 and e16 (both about company reports), the 14 identified events are extremely accurate and correspond very well to the major events of the period.",
                "For example, the defeat of Bob Dole, election of Tony Blair, Missile attack on Iraq, etc.",
                "Recall that selecting the features for one event should minimize the cost in Eq. 2 such that 1) the number of features span different events, and 2) not all features relevant to an event will be selected, e.g., the feature Clinton is representative to e12 but since Clinton relates to many other events, its time domain signal is far different from those of other representative features like Dole and Bob.",
                "The number of documents of a detected event is roughly estimated by the number of indexed documents containing the representative features.",
                "We can see that all 17 important aperiodic events are popularly reported events.",
                "After 742 minutes of computation time, we detected 23, 525 less reported aperiodic events from 83,471 LH features.",
                "Table 1 lists the top 5 detected aperiodic events (e18 − e22) with respect to the cost.",
                "We found that these 5 events are actually very trivial events with only a few news reports, and are usually subsumed by some larger topics.",
                "For example, e22 is one of the rescue events in an airplane hijack topic.",
                "One advantage of our UG Algorithm for discovering less-reported aperiodic events is that we are able to precisely detect the true event period. 7.4 Detecting Periodic Events Among the 1,087 HL features, 330 important periodic events were detected within 10 minutes of computing time.",
                "Table 1 lists the top 5 detected periodic events with respect to the cost (e23 − e27).",
                "All of the detected periodic events are indeed valid, and correspond to real life periodic events.",
                "The GMM model is able to detect and estimate the bursty period nicely although it cannot distinguish the slight difference between every Monday-Friday and all weekdays as shown in e23.",
                "We also notice that e26 is actually a subset of e27 (soccer game), which is acceptable since the Sheffield league results are announced independently every weekend. 8.",
                "CONCLUSIONS This paper took a whole new perspective of analyzing feature trajectories as time domain signals.",
                "By considering the word document frequencies in both time and frequency domains, we were able to derive many new characteristics about news streams that were previously unknown, e.g., the different distributions of stopwords during weekdays and weekends.",
                "For the first time in the area of TDT, we applied a systematic approach to automatically detect important and less-reported, periodic and aperiodic events.",
                "The key idea of our work lies in the observations that (a)periodic events have (a)periodic representative features and (un)important events have (in)active representative features, differentiated by their power spectrums and time periods.",
                "To address the real event detection problem, a simple and effective mixture density-based approach was used to identify feature bursts and their associated bursty periods.",
                "We also designed an unsupervised greedy algorithm to detect both aperiodic and periodic events, which was successful in detecting real events as shown in the evaluation on a real news stream.",
                "Although we have not made any benchmark comparison against another approach, simply because there is no previous work in the addressed problem.",
                "Future work includes evaluating the recall of detected events for a labeled news stream, and comparing our model against the closest equivalent methods, which currently are limited to the methods of Kleinberg [12] (which can only detect certain type of bursty events depending on parameter settings), Fung et al. [9], and Swan and Allan [18].",
                "Nevertheless, we believe our simple and effective method will be useful for all TDT practitioners, and will be especially useful for the initial exploratory analysis of news streams. 9.",
                "REFERENCES [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Google news alerts, http://www.google.com/alerts. [3] Reuters corpus, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan.",
                "Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, and H. Jin.",
                "First story detection in tdt is hard.",
                "In CIKM, pages 374-381, 2000. [6] J. Allan, C. Wade, and A. Bolivar.",
                "Retrieval and novelty detection at the sentence level.",
                "In SIGIR, pages 314-321, 2003. [7] T. Brants, F. Chen, and A. Farahat.",
                "A system for new event detection.",
                "In SIGIR, pages 330-337, 2003. [8] A. P. Dempster, N. M. Laird, and D. B. Rubin.",
                "Maximum likelihood from incomplete data via the EM algorithm.",
                "Journal of the Royal Statistical Society, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu, and H. Lu.",
                "Parameter free bursty events detection in text streams.",
                "In VLDB, pages 181-192, 2005. [10] Q.",
                "He, K. Chang, and E.-P. Lim.",
                "A model for anticipatory event detection.",
                "In ER, pages 168-181, 2006. [11] Q.",
                "He, K. Chang, E.-P. Lim, and J. Zhang.",
                "Bursty feature reprensentation for clustering text streams.",
                "In SDM, accepted, 2007. [12] J. Kleinberg.",
                "Bursty and hierarchical structure in streams.",
                "In SIGKDD, pages 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins.",
                "On the bursty evolution of blogspace.",
                "In WWW, pages 159-178, 2005. [14] G. Kumaran and J. Allan.",
                "Text classification and named entities for new event detection.",
                "In SIGIR, pages 297-304, 2004. [15] Q. Mei and C. Zhai.",
                "Discovering evolutionary theme patterns from text: an exploration of temporal text mining.",
                "In SIGKDD, pages 198-207, 2005. [16] W. D. Penny.",
                "Kullback-liebler divergences of normal, gamma, dirichlet and wishart densities.",
                "Technical report, 2001. [17] N. Stokes and J. Carthy.",
                "Combining semantic and syntactic document classifiers to improve first story detection.",
                "In SIGIR, pages 424-425, 2001. [18] R. Swan and J. Allan.",
                "Automatic generation of overview timelines.",
                "In SIGIR, pages 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena, and D. Gunopulos.",
                "Identifying similarities, periodicities and bursts for online search queries.",
                "In SIGMOD, pages 131-142, 2004. [20] Y. Yang, T. Pierce, and J. Carbonell.",
                "A study of retrospective and on-line event detection.",
                "In SIGIR, pages 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topic-conditioned novelty detection.",
                "In SIGKDD, pages 688-693, 2002.",
                "Table 1: All important aperiodic events (e1 − e17), top 5 less-reported aperiodic events (e18 − e22) and top 5 important periodic events (e23 − e27).",
                "Detected Event and Bursty Period Doc # True Event e1(Sali,Berisha,Albania,Albanian,March) 02/02/199705/29/1997 1409 Albanians president Sali Berisha lost in an early election and resigned, 12/1996-07/1997. e2(Seko,Mobutu,Sese,Kabila) 03/22/1997-06/09/1997 2273 Zaires president Mobutu Sese coordinated the native rebellion and failed on 05/16/1997. e3(Marxist,Peruvian) 11/19/1996-03/05/1997 824 Peru rebels (Tupac Amaru revolutionary Movement) led a hostage siege in Lima in early 1997. e4(Movement,Tupac,Amaru,Lima,hostage,hostages) 11/16/1996-03/20/1997 824 The same as e3. e5(Kinshasa,Kabila,Laurent,Congo) 03/26/199706/15/1997 1378 Zaire was renamed the Democratic Republic of Congo on 05/16/1997. e6(Jospin,Lionel,June) 05/10/1997-07/09/1997 605 Following the early General Elections circa 06/1997, Lionel Jospin was appointed Prime Minister on 06/02/1997. e7(Iraq,missile) 08/31/1996-09/13/1996 1262 U.S. fired missile at Iraq on 09/03/1996 and 09/04/1996. e8(Kurdish,Baghdad,Iraqi) 08/29/1996-09/09/1996 1132 Iraqi troop fought with Kurdish faction circa 09/1996. e9(May,Blair) 03/24/1997-07/04/1997 1049 Tony Blair became the Primary Minister of the United Kingdom on 05/02/1997. e10(slalom,skiing) 12/05/1996-03/21/1997 253 Slalom Game of Alpine Skiing in 01/1997-02/1997. e11(Interim,months) 09/24/1996-12/31/1996 3063 Tokyo released company interim results for the past several months in 09/1996-12/1996. e12(Dole,Bob) 09/09/1996-11/24/1996 1599 Dole Bob lost the 1996 US presidential election. e13(July,Sen) 06/25/1997-06/25/1997 344 Cambodias Prime Minister Hun Sen launched a bloody military coup in 07/1997. e14(Hebron) 10/15/1996-02/14/1997 2098 Hebron was divided into two sectors in early 1997. e15(April,Easter) 02/23/1997-05/04/1997 480 Easter feasts circa 04/1997 (for western and Orthodox). e16(Diluted,Group) 04/27/1997-07/20/1997 1888 Tokyo released all 96/97 group results in 04/199707/1997. e17(December,Christmas) 11/17/1996-01/26/1997 1326 Christmas feast in late 12/1997. e18(Kolaceva,winter,Together,promenades,Zajedno, Slobodan,Belgrade,Serbian,Serbia,Draskovic,municipal, Kragujevac) 1/25/1997 3 University students organized a vigil on Kolaceva street against government on 1/25/1997. e19(Tutsi,Luvengi,Burundi,Uvira,fuel,Banyamulenge, Burundian,Kivu,Kiliba,Runingo,Kagunga,Bwegera) 10/19/1996 6 Fresh fighting erupted around Uvira between Zaire armed forces and Banyamulengs Tutsi rebels on 10/19/1996. e20(Malantacchi,Korea,Guy,Rider,Unions,labour, Trade,unions,Confederation,rammed,Geneva,stoppages, Virgin,hire,Myongdong,Metalworkers) 1/11/1997 2 Marcello Malantacchi secretary general of the International Metalworkers Federation and Guy Rider who heads the Geneva office of the International Confederation of Free Trade Unions attacked the new labour law of South Korea on 1/11/1997. e21(DBS,Raﬄes) 8/17/1997 9 The list of the unit of Singapore DBS Land Raﬄes Holdings plans on 8/17/1997. e22(preserver,fuel,Galawa,Huddle,Leul,Beausse) 11/24/1996 3 Rescued a woman and her baby during a hijacked Ethiopian plane that ran out of fuel and crashed into the sea near Le Galawa beach on 11/24/1996. e23(PRICE,LISTING,MLN,MATURITY,COUPON, MOODY,AMT,FIRST,ISS,TYPE,PAY,BORROWER) Monday-Friday/week 7966 Announce bond price on all weekdays. e24(Unaudited,Ended,Months,Weighted,Provision,Cost, Selling,Revenues,Loss,Income,except,Shrs,Revs) every season 2264 Net income-loss reports released by companies in every season. e25(rating,Wall,Street,Ian) Monday-Friday/week 21767 Stock reports from Wall Street on all weekdays. e26(Sheffield,league,scoring,goals,striker,games) every Friday, Saturday and Sunday 574 Match results of Sheffield soccer league were published on Friday, Saturday and Sunday 10 times than other 4 days. e27(soccer,matches,Results,season,game,Cup,match, victory,beat,played,play,division) every Friday, Saturday and Sunday 2396 Soccer games held on Friday, Saturday and Sunday 7 times than other 4 days."
            ],
            "original_annotated_samples": [
                "To evaluate our method, we subsequently propose an unsupervised event detection algorithm for news streams. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Easter April (a) <br>aperiodic event</br> 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Unaudited Ended (b) periodic event Figure 1: Feature correlation (DFIDF:time) between a) Easter and April b) Unaudited and Ended.",
                "In this example, the hidden event Easter feast is a typical important <br>aperiodic event</br> over 1-year data.",
                "A periodic event has a list of periodic features and an <br>aperiodic event</br> has a list of aperiodic features; 2) Representative features from the same event share similar distributions over time and are highly correlated; 3) An important event has a set of active (largely reported) representative features, whereas an unimportant event has a set of inactive (less-reported) representative features; 4) A feature may be included by several events with overlaps in time frames.",
                "Definition 1. (<br>aperiodic event</br>) An event is aperiodic within T if it only happens once.",
                "For the 1-year Reuters dataset, Christmas is classified as a typical <br>aperiodic event</br> with Pf = 365 and Sf = 135.68, as shown in Figure 2(b)."
            ],
            "translated_annotated_samples": [
                "Para evaluar nuestro método, posteriormente proponemos un algoritmo de detección de eventos no supervisado para flujos de noticias. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Pascua Abril (a) <br>evento aperiódico</br> 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 No auditado Finalizado (b) evento periódico Figura 1: Correlación de características (DFIDF:tiempo) entre a) Pascua y Abril b) No auditado y Finalizado.",
                "En este ejemplo, el evento oculto de la festividad de Pascua es un <br>evento aperiódico</br> típico e importante en datos de 1 año.",
                "Un evento periódico tiene una lista de características periódicas y un evento aperiódico tiene una lista de <br>características aperiódicas</br>; 2) Las características representativas del mismo evento comparten distribuciones similares en el tiempo y están altamente correlacionadas; 3) Un evento importante tiene un conjunto de características representativas activas (ampliamente reportadas), mientras que un evento no importante tiene un conjunto de características representativas inactivas (menos reportadas); 4) Una característica puede ser incluida por varios eventos con superposiciones en los marcos de tiempo.",
                "Definición 1. (Evento aperiódico) Un evento es aperiódico dentro de T si solo ocurre una vez.",
                "Para el conjunto de datos de Reuters de 1 año, la Navidad se clasifica como un <br>evento aperiódico</br> típico con Pf = 365 y Sf = 135.68, como se muestra en la Figura 2(b)."
            ],
            "translated_text": "Analizando Trayectorias de Características para la Detección de Eventos Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg Escuela de Ingeniería Informática Universidad Tecnológica de Nanyang Bloque N4, Avenida Nanyang, Singapur 639798 RESUMEN Consideramos el problema de analizar trayectorias de palabras en los dominios del tiempo y la frecuencia, con el objetivo específico de identificar palabras importantes y menos reportadas, periódicas y aperiódicas. Un conjunto de palabras con tendencias idénticas puede agruparse para reconstruir un evento de manera completamente no supervisada. La frecuencia del documento de cada palabra a lo largo del tiempo se trata como una serie temporal, donde cada elemento es el puntaje de frecuencia del documento - frecuencia inversa del documento (DFIDF) en un punto temporal. En este artículo, 1) primero aplicamos análisis espectral para categorizar características de diferentes tipos de eventos: importantes y poco reportados, periódicos y aperiódicos; 2) modelamos las características aperiódicas con densidad gaussiana y las características periódicas con densidades de mezcla gaussiana, y posteriormente detectamos cada ráfaga de características mediante el enfoque gaussiano truncado; 3) propusimos un algoritmo de detección de eventos codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos. Todos los métodos anteriores se pueden aplicar a datos de series temporales en general. Evaluamos exhaustivamente nuestros métodos en el Corpus de Noticias de Reuters de 1 año [3] y demostramos que fueron capaces de descubrir eventos significativos aperiódicos y periódicos. Categorías y Descriptores de Asignaturas: H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales: Algoritmos, Experimentación. 1. INTRODUCCIÓN Hay más de 4,000 fuentes de noticias en línea en el mundo. Supervisar manualmente todos ellos en busca de eventos importantes se ha vuelto difícil o prácticamente imposible. De hecho, la comunidad de detección y seguimiento de temas (TDT) ha estado tratando durante muchos años de encontrar una solución práctica para ayudar a las personas a monitorear las noticias de manera efectiva. Desafortunadamente, el Santo Grial sigue siendo esquivo, ya que la gran mayoría de las soluciones de TDT propuestas para la detección de eventos [20, 5, 17, 4, 21, 7, 14, 10] son demasiado simplistas (basadas en la similitud del coseno [5]) o impracticables debido a la necesidad de ajustar un gran número de parámetros [9]. La ineficacia de las tecnologías actuales de TDT se puede ilustrar fácilmente suscribiéndose a cualquiera de los muchos servicios de alertas de noticias en línea, como el líder de la industria Google News Alerts, que genera más del 50% de falsas alarmas. Como prueba adicional, portales como Yahoo adoptan un enfoque más pragmático al requerir que todas las alertas de noticias generadas por máquinas pasen por un operador humano para su confirmación antes de enviarlas a los suscriptores. En lugar de abordar el problema con variaciones del mismo martillo (similitud coseno y TFIDF), es necesario contar con una comprensión fundamental de las características de los datos de flujo de noticias antes de que se puedan lograr avances importantes en TDT. Por lo tanto, en este artículo, examinamos noticias y tendencias de características desde la perspectiva de analizar una señal de palabras de series temporales. Trabajos anteriores como [9] han intentado reconstruir un evento con sus características representativas. Sin embargo, en muchas tareas de detección de eventos predictivos (es decir, detección de eventos retrospectivos), hay un vasto conjunto de características potenciales solo para un conjunto fijo de observaciones (es decir, los estallidos obvios). De estas características, a menudo solo se espera que un pequeño número sea útil. En particular, estudiamos el novedoso problema de analizar trayectorias de características para la detección de eventos, utilizando una técnica conocida de procesamiento de señales: identificar correlaciones distribucionales entre todas las características mediante análisis espectral. Para evaluar nuestro método, posteriormente proponemos un algoritmo de detección de eventos no supervisado para flujos de noticias. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Pascua Abril (a) <br>evento aperiódico</br> 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 No auditado Finalizado (b) evento periódico Figura 1: Correlación de características (DFIDF:tiempo) entre a) Pascua y Abril b) No auditado y Finalizado. Como ejemplo ilustrativo, considera la correlación entre las palabras Pascua y abril del Corpus de Reuters. A partir del gráfico de su DFIDF normalizado en la Figura 1(a), observamos la gran superposición entre las dos palabras alrededor de 04/1997, lo que significa que probablemente ambas pertenecen al mismo evento durante ese tiempo (festividad de Pascua). En este ejemplo, el evento oculto de la festividad de Pascua es un <br>evento aperiódico</br> típico e importante en datos de 1 año. Otro ejemplo se muestra en la Figura 1(b), donde las palabras \"No auditado\" y \"Finalizado 1\" del Corpus de Reuters son el conjunto de datos predeterminado para todos los ejemplos y presentan un comportamiento similar durante períodos de 3 meses. Estas dos palabras en realidad se originaron a partir del mismo evento periódico, informes de ganancias y pérdidas, que son publicados trimestralmente por empresas cotizadas en bolsa. Otras observaciones extraídas de la Figura 1 son: 1) el período de actividad intensa de abril es mucho más largo que el de Semana Santa, lo que sugiere que abril puede estar presente en otros eventos durante el mismo período; 2) No auditado tiene un valor promedio de DFIDF más alto que Finalizado, lo que indica que No auditado es más representativo para el evento subyacente. Estos dos ejemplos son solo la punta del iceberg entre todas las tendencias de palabras y correlaciones ocultas en un flujo de noticias como Reuters. Si se puede descubrir un gran número de ellos, podría ayudar significativamente en las tareas de TDT. En particular, indica la importancia de extraer características correlacionadas para detectar eventos correspondientes. Para resumir, postulamos que: 1) Un evento se describe por sus características representativas. Un evento periódico tiene una lista de características periódicas y un evento aperiódico tiene una lista de <br>características aperiódicas</br>; 2) Las características representativas del mismo evento comparten distribuciones similares en el tiempo y están altamente correlacionadas; 3) Un evento importante tiene un conjunto de características representativas activas (ampliamente reportadas), mientras que un evento no importante tiene un conjunto de características representativas inactivas (menos reportadas); 4) Una característica puede ser incluida por varios eventos con superposiciones en los marcos de tiempo. Basándonos en estas observaciones, podemos extraer características representativas dadas un evento o detectar un evento a partir de una lista de características altamente correlacionadas. En este artículo, nos enfocamos en este último aspecto, es decir, cómo se pueden descubrir características correlacionadas para formar un evento de manera no supervisada. 1.1 Contribuciones Este artículo tiene tres contribuciones principales: • Hasta donde sabemos, nuestro enfoque es el primero en categorizar características de palabras para eventos heterogéneos. Específicamente, cada característica de palabra se clasifica en uno de los siguientes cinco tipos de características basados en la fuerza de su espectro de potencia y periodicidad: 1) HH (alta potencia y alta/larga periodicidad): eventos aperiódicos importantes, 2) HL (alta potencia y baja periodicidad): eventos periódicos importantes, 3) LH (baja potencia y alta periodicidad): eventos aperiódicos no importantes, 4) LL (baja potencia y baja periodicidad): no eventos, y 5) SW (palabras vacías), un subconjunto de LL con mayor potencia y periodicidad que comprende palabras vacías, que no contienen información. • Proponemos un enfoque simple y efectivo basado en densidad de mezcla para modelar y detectar ráfagas de características. • Presentamos un algoritmo de detección de eventos no supervisado para detectar eventos tanto aperiódicos como periódicos. Nuestro algoritmo ha sido evaluado en un flujo de noticias reales para demostrar su efectividad. 2. TRABAJO RELACIONADO Este trabajo está motivado en gran medida por una familia más amplia de problemas conocidos colectivamente como Detección y Seguimiento de Temas (TDT) [20, 5, 17, 4, 21, 7, 14, 10]. Además, la mayoría de las investigaciones de TDT hasta ahora se han centrado en agrupar/clasificar documentos en tipos de temas, identificar oraciones novedosas para eventos nuevos, etc., sin prestar mucha atención al análisis de la trayectoria de las palabras con respecto al tiempo. Swan y Allan [18] intentaron por primera vez usar términos que co-ocurren para construir un evento. Sin embargo, solo consideraron entidades nombradas y pares de frases nominales, sin tener en cuenta sus periodicidades. Por el contrario, nuestro artículo considera todo lo anterior. Recientemente, ha habido un gran interés en modelar un evento en flujos de texto como un estallido de actividades al incorporar información temporal. El trabajo seminal de Kleinberg describió cómo se pueden extraer características explosivas de flujos de texto utilizando un modelo de autómata infinito [12], lo que inspiró toda una serie de aplicaciones como la identificación de comunidades explosivas de Kumar a partir de gráficos de blogs [13], la sumarización de temas evolutivos en flujos de texto de Meis [15], el agrupamiento de flujos de texto utilizando características explosivas de Hes [11], etc. Sin embargo, ninguno de los trabajos existentes identificó específicamente características para eventos, excepto Fung et al. [9], quienes agruparon características llamativas para identificar varios eventos llamativos. Nuestro trabajo difiere de [9] en varias formas: 1) analizamos cada característica individual, no solo las características explosivas; 2) clasificamos las características a lo largo de dos dimensiones categóricas (periodicidad y potencia), dando en total cinco tipos de características principales; 3) no restringimos que cada característica pertenezca exclusivamente a un solo evento. Las técnicas de análisis espectral han sido utilizadas previamente por Vlachos et al. [19] para identificar periodicidades y ráfagas en los registros de consultas. Su enfoque estaba en detectar múltiples periodicidades a partir del gráfico del espectro de potencia, las cuales luego se utilizaron para indexar palabras para la búsqueda por ráfagas. En este artículo, utilizamos análisis espectral para clasificar las características de las palabras a lo largo de dos dimensiones, a saber, periodicidad y espectro de potencia, con el objetivo final de identificar eventos tanto periódicos como no periódicos y explosivos. 3. REPRESENTACIÓN DE DATOS Sea T la duración/período (en días) de un flujo de noticias, y F representa el espacio de características de palabras completo en el Modelo de Espacio Vectorial (VSM) estático clásico. 3.1 Clasificación de Periodicidad de Eventos Dentro de T, pueden existir ciertos eventos que ocurren solo una vez, por ejemplo, la elección de Tony Blair como Primer Ministro del Reino Unido, y otros eventos recurrentes de diversas periodicidades, por ejemplo, partidos de fútbol semanales. Por lo tanto, categorizamos todos los eventos en dos tipos: aperiódicos y periódicos, definidos de la siguiente manera. Definición 1. (Evento aperiódico) Un evento es aperiódico dentro de T si solo ocurre una vez. Definición 2. (Evento periódico) Si los eventos de un cierto género de eventos ocurren regularmente con una periodicidad fija P ≤ T/2, decimos que este género particular de eventos es periódico, y cada evento miembro se califica como un evento periódico. Ten en cuenta que la definición de aperiódico es relativa, es decir, es verdadera solo para un T dado y puede ser inválida para cualquier otro T > T. Por ejemplo, el evento de la fiesta de Navidad es aperiódico para T ≤ 365 pero periódico para T ≥ 730. 3.2 Características Representativas Intuitivamente, un evento puede ser descrito de manera muy concisa por unas pocas características de palabras discriminativas y representativas y viceversa, por ejemplo, huracán, barrido y golpe podrían ser características representativas de un evento del género de huracanes. Asimismo, un conjunto de características fuertemente correlacionadas podría ser utilizado para reconstruir una descripción de un evento, asumiendo que las características fuertemente correlacionadas son representativas. El vector de representación de una característica de palabra se define de la siguiente manera: Definición 3. (Trayectoria de la Característica) La trayectoria de una característica de palabra f puede escribirse como la secuencia yf = [yf (1), yf (2), . . . , yf (T)], donde cada elemento yf (t) es una medida de la característica f en el tiempo t, que podría definirse utilizando la puntuación normalizada DFIDF yf (t) = DFf (t) N(t) × log( N DFf ), donde DFf (t) es el número de documentos (DF local) que contienen la característica f en el día t, DFf es el número total de documentos (DF global) que contienen la característica f en T, N(t) es el número de documentos para el día t, y N es el número total de documentos en T. 4. En esta sección, mostramos cómo se pueden extraer características representativas para eventos (poco) importantes o (a)periódicos. 4.1 Análisis Espectral para el Período Dominante Dada una característica f, descomponemos su trayectoria de características yf = [yf (1), yf (2), ..., yf (T)] en la secuencia de T números complejos [X1, . . . , XT ] a través de la transformada discreta de Fourier (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. La DFT puede representar la serie temporal original como una combinación lineal de sinusoides complejas, lo cual se ilustra mediante la transformada discreta de Fourier inversa (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, donde el coeficiente de Fourier Xk denota la amplitud del sinusoides con frecuencia k/T. La trayectoria original puede ser reconstruida con solo las frecuencias dominantes, las cuales pueden ser determinadas a partir del espectro de potencia utilizando el popular estimador periodograma. El periodograma es una secuencia de la magnitud al cuadrado de los coeficientes de Fourier, Xk^2, k = 1, 2, . . . , T/2, que indica la potencia de la señal en la frecuencia k/T en el espectro. A partir del espectro de potencia, se elige el período dominante como el inverso de la frecuencia con el espectro de potencia más alto, de la siguiente manera. Definición 4. (Período Dominante) El período dominante (DP) de una característica dada f es Pf = T/ arg max k Xk 2. Por lo tanto, tenemos la Definición 5. (Espectro de Potencia Dominante) El espectro de potencia dominante (DPS) de una característica dada f es Sf = Xk 2 , con Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorización de Características El DPS de una trayectoria de características es un indicador fuerte de su actividad en la frecuencia especificada; cuanto mayor sea el DPS, es más probable que la característica sea explosiva. Al combinar DPS con DP, categorizamos todas las características en cuatro tipos: 2 Normalizamos yf (t) como yf (t) = yf (t)/ T i=1 yf (i) para que pueda interpretarse como una probabilidad. • HH: alta Sf, aperiódico o periódico a largo plazo (Pf > T/2); • HL: alta Sf, periódico a corto plazo (Pf ≤ T/2); • LH: baja Sf, aperiódico o periódico a largo plazo; • LL: baja Sf, periódico a corto plazo. La frontera entre los periodos a largo plazo y a corto plazo se establece en T/2. Sin embargo, distinguir entre un DPS alto y bajo no es sencillo, lo cual se abordará más adelante. Propiedades de diferentes conjuntos de características Para comprender mejor las propiedades de HH, HL, LH y LL, seleccionamos cuatro características, Navidad, fútbol, DBS y tu como ejemplos ilustrativos. Dado que la frontera entre el espectro de alta y baja potencia no está clara, estos ejemplos seleccionados tienen un rango relativo amplio de valores de espectro de potencia. La figura 2(a) muestra la trayectoria de DFIDF para la Navidad con un pico distintivo alrededor del día de Navidad. Para el conjunto de datos de Reuters de 1 año, la Navidad se clasifica como un <br>evento aperiódico</br> típico con Pf = 365 y Sf = 135.68, como se muestra en la Figura 2(b). ",
            "candidates": [],
            "error": [
                [
                    "evento aperiódico",
                    "evento aperiódico",
                    "características aperiódicas",
                    "evento aperiódico"
                ]
            ]
        },
        "periodic event": {
            "translated_key": "evento periódico",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Analyzing Feature Trajectories for Event Detection Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg School of Computer Engineering Nanyang Technological University Block N4, Nanyang Avenue, Singapore 639798 ABSTRACT We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words.",
                "A set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner.",
                "The document frequency of each word across time is treated like a time series, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point.",
                "In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events.",
                "All of the above methods can be applied to time series data in general.",
                "We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events.",
                "Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Experimentation. 1.",
                "INTRODUCTION There are more than 4,000 online news sources in the world.",
                "Manually monitoring all of them for important events has become difficult or practically impossible.",
                "In fact, the topic detection and tracking (TDT) community has for many years been trying to come up with a practical solution to help people monitor news effectively.",
                "Unfortunately, the holy grail is still elusive, because the vast majority of TDT solutions proposed for event detection [20, 5, 17, 4, 21, 7, 14, 10] are either too simplistic (based on cosine similarity [5]) or impractical due to the need to tune a large number of parameters [9].",
                "The ineffectiveness of current TDT technologies can be easily illustrated by subscribing to any of the many online news alerts services such as the industryleading Google News Alerts [2], which generates more than 50% false alarms [10].",
                "As further proof, portals like Yahoo take a more pragmatic approach by requiring all machine generated news alerts to go through a human operator for confirmation before sending them out to subscribers.",
                "Instead of attacking the problem with variations of the same hammer (cosine similarity and TFIDF), a fundamental understanding of the characteristics of news stream data is necessary before any major breakthroughs can be made in TDT.",
                "Thus in this paper, we look at news stories and feature trends from the perspective of analyzing a time-series word signal.",
                "Previous work like [9] has attempted to reconstruct an event with its representative features.",
                "However, in many predictive event detection tasks (i.e., retrospective event detection), there is a vast set of potential features only for a fixed set of observations (i.e., the obvious bursts).",
                "Of these features, often only a small number are expected to be useful.",
                "In particular, we study the novel problem of analyzing feature trajectories for event detection, borrowing a well-known technique from signal processing: identifying distributional correlations among all features by spectral analysis.",
                "To evaluate our method, we subsequently propose an unsupervised event detection algorithm for news streams. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Easter April (a) aperiodic event 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Unaudited Ended (b) <br>periodic event</br> Figure 1: Feature correlation (DFIDF:time) between a) Easter and April b) Unaudited and Ended.",
                "As an illustrative example, consider the correlation between the words Easter and April from the Reuters Corpus1 .",
                "From the plot of their normalized DFIDF in Figure 1(a), we observe the heavy overlap between the two words circa 04/1997, which means they probably both belong to the same event during that time (Easter feast).",
                "In this example, the hidden event Easter feast is a typical important aperiodic event over 1-year data.",
                "Another example is given by Figure 1(b), where both the words Unaudited and Ended 1 Reuters Corpus is the default dataset for all examples. exhibit similar behaviour over periods of 3 months.",
                "These two words actually originated from the same <br>periodic event</br>, net income-loss reports, which are released quarterly by publicly listed companies.",
                "Other observations drawn from Figure 1 are: 1) the bursty period of April is much longer than Easter, which suggests that April may exist in other events during the same period; 2) Unaudited has a higher average DFIDF value than Ended, which indicates Unaudited to be more representative for the underlying event.",
                "These two examples are but the tip of the iceberg among all word trends and correlations hidden in a news stream like Reuters.",
                "If a large number of them can be uncovered, it could significantly aid TDT tasks.",
                "In particular, it indicates the significance of mining correlating features for detecting corresponding events.",
                "To summarize, we postulate that: 1) An event is described by its representative features.",
                "A <br>periodic event</br> has a list of periodic features and an aperiodic event has a list of aperiodic features; 2) Representative features from the same event share similar distributions over time and are highly correlated; 3) An important event has a set of active (largely reported) representative features, whereas an unimportant event has a set of inactive (less-reported) representative features; 4) A feature may be included by several events with overlaps in time frames.",
                "Based on these observations, we can either mine representative features given an event or detect an event from a list of highly correlated features.",
                "In this paper, we focus on the latter, i.e., how correlated features can be uncovered to form an event in an unsupervised manner. 1.1 Contributions This paper has three main contributions: • To the best of our knowledge, our approach is the first to categorize word features for heterogenous events.",
                "Specifically, every word feature is categorized into one of the following five feature types based on its power spectrum strength and periodicity: 1) HH (high power and high/long periodicity): important aperiodic events, 2) HL (high power and low periodicity): important periodic events, 3) LH (low power and high periodicity): unimportant aperiodic events, 4) LL (low power and low periodicity): non-events, and 5) SW (stopwords), a higher power and periodicity subset of LL comprising stopwords, which contains no information. • We propose a simple and effective mixture densitybased approach to model and detect feature bursts. • We come up with an unsupervised event detection algorithm to detect both aperiodic and periodic events.",
                "Our algorithm has been evaluated on a real news stream to show its effectiveness. 2.",
                "RELATED WORK This work is largely motivated by a broader family of problems collectively known as Topic Detection and Tracking (TDT) [20, 5, 17, 4, 21, 7, 14, 10].",
                "Moreover, most TDT research so far has been concerned with clustering/classifying documents into topic types, identifying novel sentences [6] for new events, etc., without much regard to analyzing the word trajectory with respect to time.",
                "Swan and Allan [18] first attempted using co-occuring terms to construct an event.",
                "However, they only considered named entities and noun phrase pairs, without considering their periodicities.",
                "On the contrary, our paper considers all of the above.",
                "Recently, there has been significant interest in modeling an event in text streams as a burst of activities by incorporating temporal information.",
                "Kleinbergs seminal work described how bursty features can be extracted from text streams using an infinite automaton model [12], which inspired a whole series of applications such as Kumars identification of bursty communities from Weblog graphs [13], Meis summarization of evolutionary themes in text streams [15], Hes clustering of text streams using bursty features [11], etc.",
                "Nevertheless, none of the existing work specifically identified features for events, except for Fung et al. [9], who clustered busty features to identify various bursty events.",
                "Our work differs from [9] in several ways: 1) we analyze every single feature, not only bursty features; 2) we classify features along two categorical dimensions (periodicity and power), yielding altogether five primary feature types; 3) we do not restrict each feature to exclusively belong to only one event.",
                "Spectral analysis techniques have previously been used by Vlachos et al. [19] to identify periodicities and bursts from query logs.",
                "Their focus was on detecting multiple periodicities from the power spectrum graph, which were then used to index words for query-by-burst search.",
                "In this paper, we use spectral analysis to classify word features along two dimensions, namely periodicity and power spectrum, with the ultimate goal of identifying both periodic and aperiodic bursty events. 3.",
                "DATA REPRESENTATION Let T be the duration/period (in days) of a news stream, and F represents the complete word feature space in the classical static Vector Space Model (VSM). 3.1 Event Periodicity Classification Within T, there may exist certain events that occur only once, e.g., Tony Blair elected as Prime Minister of U.K., and other recurring events of various periodicities, e.g., weekly soccer matches.",
                "We thus categorize all events into two types: aperiodic and periodic, defined as follows.",
                "Definition 1. (Aperiodic Event) An event is aperiodic within T if it only happens once.",
                "Definition 2. (<br>periodic event</br>) If events of a certain event genre occur regularly with a fixed periodicity P ≤ T/2 , we say that this particular event genre is periodic, with each member event qualified as a <br>periodic event</br>.",
                "Note that the definition of aperiodic is relative, i.e., it is true only for a given T, and may be invalid for any other T > T. For example, the event Christmas feast is aperiodic for T ≤ 365 but periodic for T ≥ 730. 3.2 Representative Features Intuitively, an event can be described very concisely by a few discriminative and representative word features and vice-versa, e.g., hurricane, sweep, and strike could be representative features of a Hurricane genre event.",
                "Likewise, a set of strongly correlated features could be used to reconstruct an event description, assuming that strongly correlated features are representative.",
                "The representation vector of a word feature is defined as follows: Definition 3. (Feature Trajectory) The trajectory of a word feature f can be written as the sequence yf = [yf (1), yf (2), . . . , yf (T)], where each element yf (t) is a measure of feature f at time t, which could be defined using the normalized DFIDF score2 yf (t) = DFf (t) N(t) × log( N DFf ), where DFf (t) is the number of documents (local DF) containing feature f at day t, DFf is the total number of documents (global DF) containing feature f over T, N(t) is the number of documents for day t, and N is the total number of documents over T. 4.",
                "IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 Spectral Analysis for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. DFT can represent the original time series as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T.",
                "The original trajectory can be reconstructed with just the dominant frequencies, which can be determined from the power spectrum using the popular periodogram estimator.",
                "The periodogram is a sequence of the squared magnitude of the Fourier coefficients, Xk 2 , k = 1, 2, . . . , T/2 , which indicates the signal power at frequency k/T in the spectrum.",
                "From the power spectrum, the dominant period is chosen as the inverse of the frequency with the highest power spectrum, as follows.",
                "Definition 4. (Dominant Period) The dominant period (DP) of a given feature f is Pf = T/ arg max k Xk 2 .",
                "Accordingly, we have Definition 5. (Dominant Power Spectrum) The dominant power spectrum (DPS) of a given feature f is Sf = Xk 2 , with Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorizing Features The DPS of a feature trajectory is a strong indicator of its activeness at the specified frequency; the higher the DPS, the more likely for the feature to be bursty.",
                "Combining DPS with DP, we therefore categorize all features into four types: 2 We normalize yf (t) as yf (t) = yf (t)/ T i=1 yf (i) so that it could be interpreted as a probability. • HH: high Sf , aperiodic or long-term periodic (Pf > T/2 ); • HL: high Sf , short-term periodic (Pf ≤ T/2 ); • LH: low Sf , aperiodic or long-term periodic; • LL: low Sf , short-term periodic.",
                "The boundary between long-term and short-term periodic is set to T/2 .",
                "However, distinguishing between a high and low DPS is not straightforward, which will be tackled later.",
                "Properties of Different Feature Sets To better understand the properties of HH, HL, LH and LL, we select four features, Christmas, soccer, DBS and your as illustrative examples.",
                "Since the boundary between high and low power spectrum is unclear, these chosen examples have relative wide range of power spectrum values.",
                "Figure 2(a) shows the DFIDF trajectory for Christmas with a distinct burst around Christmas day.",
                "For the 1-year Reuters dataset, Christmas is classified as a typical aperiodic event with Pf = 365 and Sf = 135.68, as shown in Figure 2(b).",
                "Clearly, the value of Sf = 135.68 is reasonable for a well-known bursty event like Christmas. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Christmas(DFIDF:time) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Christmas(S:frequency) Figure 2: Feature Christmas with relative high Sf and long-term Pf .",
                "The DFIDF trajectory for soccer is shown in Figure 3(a), from which we can observe that there is a regular burst every 7 days, which is again verified by its computed value of Pf = 7, as shown in Figure 3(b).",
                "Using the domain knowledge that soccer games have more matches every Saturday, which makes it a typical and heavily reported <br>periodic event</br>, we thus consider the value of Sf = 155.13 to be high. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) soccer(DFIDF:time) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) soccer(S:frequency) Figure 3: Feature soccer with relative high Sf and short-term Pf .",
                "From the DFIDF trajectory for DBS in Figure 4(a), we can immediately deduce DBS to be an infrequent word with a trivial burst on 08/17/1997 corresponding to DBS Land Raﬄes Holdings plans.",
                "This is confirmed by the long period of Pf = 365 and low power of Sf = 0.3084 as shown in Figure 4(b).",
                "Moreover, since this aperiodic event is only reported in a few news stories over a very short time of few days, we therefore say that its low power value of Sf = 0.3084 is representative of unimportant events.",
                "The most confusing example is shown in Figure 5 for the word feature your, which looks very similar to the graph for soccer in Figure 3.",
                "At first glance, we may be tempted to group both your and soccer into the same category of HL or LL since both distributions look similar and have the same dominant period of approximately a week.",
                "However, further 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:time) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frequency) Figure 4: Feature DBS with relative low Sf and long-term Pf . analysis indicates that the periodicity of your is due to the differences in document counts for weekdays (average 2,919 per day) and weekends3 (average 479 per day).",
                "One would have expected the periodicity of a stopword like your to be a day.",
                "Moreover, despite our DFIDF normalization, the weekday/weekend imbalance still prevailed; stopwords occur 4 times more frequently on weekends than on weekdays.",
                "Thus, the DPS remains the only distinguishing factor between your (Sf = 9.42) and soccer (Sf = 155.13).",
                "However, it is very dangerous to simply conclude that a power value of S = 9.42 corresponds to a stopword feature. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) your(DFIDF:time) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) your(S:frequency) Figure 5: Feature your as an example confusing with feature soccer.",
                "Before introducing our solution to this problem, lets look at another LL example as shown in Figure 6 for beenb, which is actually a confirmed typo.",
                "We therefore classify beenb as a noisy feature that does not contribute to any event.",
                "Clearly, the trajectory of your is very different from beenb, which means that the former has to be considered separately. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figure 6: Feature beenb with relative low Sf and short-term Pf .",
                "Stop Words (SW) Feature Set Based on the above analysis, we realize that there must be another feature set between HL and LL that corresponds to the set of stopwords.",
                "Features from this set has moderate DPS and low but known dominant period.",
                "Since it is hard to distinguish this feature set from HL and LL only based on DPS, we introduce another factor called average DFIDF (DFIDF).",
                "As shown in Figure 5, features like your usually have a lower DPS than a HL feature like soccer, but have a much higher DFIDF than another LL noisy feature such as beenb.",
                "Since such properties are usually characteristics of stopwords, we group features like your into the newly defined stopword (SW) feature set.",
                "Since setting the DPS and DFIDF thresholds for identifying stopwords is more of an art than science, we proposed a heuristic HS algorithm, Algorithm 1.",
                "The basic idea is to only use news stories from weekdays to identify stopwords. 3 The weekends here also include public holidays falling on weekdays.",
                "The SW set is initially seeded with a small set of 29 popular stopwords utilized by Google search engine.",
                "Algorithm 1 Heuristic Stopwords detection (HS) Input: Seed SW set, weekday trajectories of all words 1: From the seed set SW, compute the maximum DPS as UDPS, maximum DFIDF as UDFIDF, and minimum of DFIDF as LDFIDF. 2: for fi ∈ F do 3: Compute DFT for fi. 4: if Sfi ≤ UDPS and DFIDFfi ∈ [LDFIDF, UDFIDF] then 5: fi → SW 6: F = F − fi 7: end if 8: end for Overview of Feature Categorization After the SW set is generated, all stopwords are removed from F. We then set the boundary between high and low DPS to be the upper bound of the SW sets DPS.",
                "An overview of all five feature sets is shown in Figure 7.",
                "Figure 7: The 5 feature sets for events. 5.",
                "IDENTIFYING BURSTS FOR FEATURES Since only features from HH, HL and LH are meaningful and could potentially be representative to some events, we pruned all other feature classified as LL or SW.",
                "In this section, we describe how bursts can be identified from the remaining features.",
                "Unlike Kleinbergs burst identification algorithm [12], we can identify both significant and trivial bursts without the need to set any parameters. 5.1 Detecting Aperiodic Features Bursts For each feature in HH and HL, we truncate its trajectory by keeping only the bursty period, which is modeled with a Gaussian distribution.",
                "For example, Figure 8 shows the word feature Iraq with a burst circa 09/06/1996 being modeled as a Gaussian.",
                "Its bursty period is defined by [μf − σf , μf + σf ] as shown in Figure 8(b). 5.2 Detecting Periodic Features Bursts Since we have computed the DP for a periodic feature f, we can easily model its periodic feature trajectory yf using 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) original DFIDF:time 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 burst= [μ-σ, μ+σ] (b) identifying burst Figure 8: Modeling Iraqs time series as a truncated Gaussian with μ = 09/06/1996 and σ = 6.26. a mixture of K = T/Pf Gaussians: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , where the parameter set θf = {αk, μk, σk}K k=1 comprises: • αk is the probability of assigning yf into the kth Gaussian. αk > 0, ∀k ∈ [1, K] and K k=1 αk = 1; • μk/σk is mean/standard deviation of the kth Gaussian.",
                "The well known Expectation Maximization (EM) [8] algorithm is used to compute the mixing proportions αk, as well as the individual Gaussian density parameters μk and σK .",
                "Each Gaussian represents one <br>periodic event</br>, and is modeled similarly as mentioned in Section 5.1. 6.",
                "EVENTS FROM FEATURES After identifying and modeling bursts for all features, the next task is to paint a picture of the event with a potential set of representative features. 6.1 Feature Correlation If two features fi and fj are representative of the same event, they must satisfy the following necessary conditions: 1. fi and fj are identically distributed: yfi ∼ yfj . 2. fi and fj have a high document overlap.",
                "Measuring Feature Distribution Similarity We measure the similarity between two features fi and fj using discrete KL-divergence defined as follows.",
                "Definition 6. (feature similarity) KL(fi, fj ) is given by max(KL(fi|fj ), KL(fj |fi)), where KL(fi|fj ) = T t=1 f(yfi (t)|θfi )log f(yfi (t)|θfi ) f(yfj (t)|θfj ) . (1) Since KL-divergence is not symmetric, we define the similarity between between fi and fj as the maximum of KL(fi|fj ) and KL(fj |fi).",
                "Further, the similarity between two aperiodic features can be computed using a closed form of the KL-divergence [16].",
                "The same discrete KL-divergence formula of Eq. 1 is employed to compute the similarity between two periodic features, Next, we define the overal similarity among a set of features R using the maximum inter-feature KL-Divergence value as follows.",
                "Definition 7. (sets similarity)KL(R) = max ∀fi,fj ∈R KL(fi, fj ).",
                "Document Overlap Let Mi be the set of all documents containing feature fi.",
                "Given two features fi and fj , the overlapping document set containing both features is Mi ∩ Mj .",
                "Intuitively, the higher the |Mi ∩ Mj |, the more likelty that fi and fj will be highly correlated.",
                "We define the degree of document overlap between two features fi and fj as follows.",
                "Definition 8. (Feature DF Overlap) d(fi, fj ) = |Mi∩Mj| min(|Mi|,|Mj|) .",
                "Accordingly, the DF Overlap among a set of features R is also defined.",
                "Definition 9. (Set DF Overlap) d(R) = min ∀fi,fj ∈R d(fi, fj). 6.2 Unsupervised Greedy Event Detection We use features from HH to detect important aperiodic events, features from LH to detect less-reported/unimportant aperiodic events, and features from HL to detect periodic events.",
                "All of them share the same algorithm.",
                "Given bursty feature fi ∈ HH, the goal is to find highly correlated features from HH.",
                "The set of features similar to fi can then collectively describe an event.",
                "Specifically, we need to find a subset Ri of HH that minimizes the following cost function: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) The underlying event e (associated with the burst of fi) can be represented by Ri as y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) The burst analysis for event e is exactly the same as the feature trajectory.",
                "The cost in Eq. 2 can be minimized using our unsupervised greedy UG event detection algorithm, which is described in Algorithm 2.",
                "The UG algorithm allows a feature Algorithm 2 Unsupervised Greedy event detection (UG).",
                "Input: HH, document index for each feature. 1: Sort and select features in descending DPS order: Sf1 ≥ Sf2 ≥ . . . ≥ Sf|HH| . 2: k = 0. 3: for fi ∈ HH do 4: k = k + 1. 5: Init: Ri ← fi, C(Ri) = 1/Sfi and HH = HH − fi. 6: while HH not empty do 7: m = arg min m C(Ri ∪ fm). 8: if C(Ri ∪ fm) < C(Ri) then 9: Ri ← fm and HH = HH − fm. 10: else 11: break while. 12: end if 13: end while 14: Output ek as Eq. 3. 15: end for to be contained in multiple events so that we can detect several events happening at the same time.",
                "Furthermore, trivial events only containing year/month features (i.e., an event only containing 1 feature Aug could be identified over a 1year news stream) could be removed, although such events will have inherent high cost and should already be ranked very low.",
                "Note that our UG algorithm only requires one data-dependant parameter, the boundary between high and low power spectrum, to be set once, and this parameter can be easily estimated using the HS algorithm (Algorithm 1). 7.",
                "EXPERIMENTS In this section, we study the performances of our feature categorizing method and event detection algorithm.",
                "We first introduce the dataset and experimental setup, then we subjectively evaluate the categorization of features for HH, HL, LH, LL and SW.",
                "Finally, we study the (a)<br>periodic event</br> detection problem with Algorithm 2. 7.1 Dataset and Experimental Setup The Reuters Corpus contains 806,791 English news stories from 08/20/1996 to 08/19/1997 at a day resolution.",
                "Version 2 of the open source Lucene software [1] was used to tokenize the news text content and generate the document-word vector.",
                "In order to preserve the time-sensitive past/present/future tenses of verbs and the differences between lower case nouns and upper case named entities, no stemming was done.",
                "Since dynamic stopword removal is one of the functionalities of our method, no stopword was removed.",
                "We did remove nonEnglish characters, however, after which the number of word features amounts to 423,433.",
                "All experiments were implemented in Java and conducted on a 3.2 GHz Pentium 4 PC running Windows 2003 Server with 1 GB of memory. 7.2 Categorizing Features We downloaded 34 well-known stopwords utilized by the Google search engine as our seed training features, which includes a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en and www.",
                "We excluded the last five stopwords as they are uncommon in news stories.",
                "By only analyzing news stories over 259 weekdays, we computed the upper bound of the power spectrum for stopwords at 11.18 and corresponding DFIDF ranges from 0.1182 to 0.3691.",
                "Any feature f satisfying Sf <= 11.18 and 0.1182 <= DFIDFf <= 0.3691 over weekdays will be considered a stopword.",
                "In this manner, 470 stopwords were found and removed as visualized in Figure 9.",
                "Some detected stopwords are A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) and much (P = 22, S = 0.80, DFIDF = 0.1865).",
                "After the removal of these stopwords, the distribution of weekday and weekend news are more or less matched, and in the ensuing experiments, we shall make use of the full corpus (weekdays and weekends).",
                "The upper bound power spectrum value of 11.18 for stopwords training was selected as the boundary between the high power and low power spectrum.",
                "The boundary between high and low periodicity was set to 365/2 = 183.",
                "All 422,963 (423433 − 470) word features were categorized into 4 feature sets: HH (69 features), HL (1,087 features), LH (83,471 features), and LL (338,806 features) as shown in Figure 10.",
                "In Figure 10, each gray level denotes the relative density of features in a square region, measured by log10(1 + Dk), where Dk is the number of features within the k-th square region.",
                "From the figure, we can make the 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figure 9: Distribution of SW (stopwords) in the HH, HL, LH, and LL regions. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figure 10: Distribution of categorized features over the four quadrants (shading in log scale). following observations: 1.",
                "Most features have low S and are easily distinguishable from those features having a much higher S, which allows us to detect important (a)periodic events from trivial events by selecting features with high S. 2.",
                "Features in the HH and LH quadrants are aperiodic, which are nicely separated (big horizontal gap) from the periodic features.",
                "This allows reliably detecting aperiodic events and periodic events independently. 3.",
                "The (vertical) boundary between high and low power spectrum is not as clearcut and the exact value will be application specific.",
                "By checking the scatter distribution of features from SW on HH, HL, LH, and LL as shown in Figure 9, we found that 87.02%(409/470) of the detected stopwords originated from LL.",
                "The LL classification and high DFIDF scores of stopwords agree with the generally accepted notion that stopwords are equally frequent over all time.",
                "Therefore, setting the boundary between high and low power spectrum using the upper bound Sf of SW is a reasonable heuristic. 7.3 Detecting Aperiodic Events We shall evaluate our two hypotheses, 1)important aperiodic events can be defined by a set of HH features, and 2)less reported aperiodic events can be defined by a set of LH features.",
                "Since no benchmark news streams exist for event detection (TDT datasets are not proper streams), we evaluate the quality of the automatically detected events by comparing them to manually-confirmed events by searching through the corpus.",
                "Among the 69 HH features, we detected 17 important aperiodic events as shown in Table 1 (e1 − e17).",
                "Note that the entire identification took less than 1 second, after removing events containing only the month feature.",
                "Among the 17 events, other than the overlaps between e3 and e4 (both describes the same hostage event), e11 and e16 (both about company reports), the 14 identified events are extremely accurate and correspond very well to the major events of the period.",
                "For example, the defeat of Bob Dole, election of Tony Blair, Missile attack on Iraq, etc.",
                "Recall that selecting the features for one event should minimize the cost in Eq. 2 such that 1) the number of features span different events, and 2) not all features relevant to an event will be selected, e.g., the feature Clinton is representative to e12 but since Clinton relates to many other events, its time domain signal is far different from those of other representative features like Dole and Bob.",
                "The number of documents of a detected event is roughly estimated by the number of indexed documents containing the representative features.",
                "We can see that all 17 important aperiodic events are popularly reported events.",
                "After 742 minutes of computation time, we detected 23, 525 less reported aperiodic events from 83,471 LH features.",
                "Table 1 lists the top 5 detected aperiodic events (e18 − e22) with respect to the cost.",
                "We found that these 5 events are actually very trivial events with only a few news reports, and are usually subsumed by some larger topics.",
                "For example, e22 is one of the rescue events in an airplane hijack topic.",
                "One advantage of our UG Algorithm for discovering less-reported aperiodic events is that we are able to precisely detect the true event period. 7.4 Detecting Periodic Events Among the 1,087 HL features, 330 important periodic events were detected within 10 minutes of computing time.",
                "Table 1 lists the top 5 detected periodic events with respect to the cost (e23 − e27).",
                "All of the detected periodic events are indeed valid, and correspond to real life periodic events.",
                "The GMM model is able to detect and estimate the bursty period nicely although it cannot distinguish the slight difference between every Monday-Friday and all weekdays as shown in e23.",
                "We also notice that e26 is actually a subset of e27 (soccer game), which is acceptable since the Sheffield league results are announced independently every weekend. 8.",
                "CONCLUSIONS This paper took a whole new perspective of analyzing feature trajectories as time domain signals.",
                "By considering the word document frequencies in both time and frequency domains, we were able to derive many new characteristics about news streams that were previously unknown, e.g., the different distributions of stopwords during weekdays and weekends.",
                "For the first time in the area of TDT, we applied a systematic approach to automatically detect important and less-reported, periodic and aperiodic events.",
                "The key idea of our work lies in the observations that (a)periodic events have (a)periodic representative features and (un)important events have (in)active representative features, differentiated by their power spectrums and time periods.",
                "To address the real event detection problem, a simple and effective mixture density-based approach was used to identify feature bursts and their associated bursty periods.",
                "We also designed an unsupervised greedy algorithm to detect both aperiodic and periodic events, which was successful in detecting real events as shown in the evaluation on a real news stream.",
                "Although we have not made any benchmark comparison against another approach, simply because there is no previous work in the addressed problem.",
                "Future work includes evaluating the recall of detected events for a labeled news stream, and comparing our model against the closest equivalent methods, which currently are limited to the methods of Kleinberg [12] (which can only detect certain type of bursty events depending on parameter settings), Fung et al. [9], and Swan and Allan [18].",
                "Nevertheless, we believe our simple and effective method will be useful for all TDT practitioners, and will be especially useful for the initial exploratory analysis of news streams. 9.",
                "REFERENCES [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Google news alerts, http://www.google.com/alerts. [3] Reuters corpus, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan.",
                "Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, and H. Jin.",
                "First story detection in tdt is hard.",
                "In CIKM, pages 374-381, 2000. [6] J. Allan, C. Wade, and A. Bolivar.",
                "Retrieval and novelty detection at the sentence level.",
                "In SIGIR, pages 314-321, 2003. [7] T. Brants, F. Chen, and A. Farahat.",
                "A system for new event detection.",
                "In SIGIR, pages 330-337, 2003. [8] A. P. Dempster, N. M. Laird, and D. B. Rubin.",
                "Maximum likelihood from incomplete data via the EM algorithm.",
                "Journal of the Royal Statistical Society, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu, and H. Lu.",
                "Parameter free bursty events detection in text streams.",
                "In VLDB, pages 181-192, 2005. [10] Q.",
                "He, K. Chang, and E.-P. Lim.",
                "A model for anticipatory event detection.",
                "In ER, pages 168-181, 2006. [11] Q.",
                "He, K. Chang, E.-P. Lim, and J. Zhang.",
                "Bursty feature reprensentation for clustering text streams.",
                "In SDM, accepted, 2007. [12] J. Kleinberg.",
                "Bursty and hierarchical structure in streams.",
                "In SIGKDD, pages 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins.",
                "On the bursty evolution of blogspace.",
                "In WWW, pages 159-178, 2005. [14] G. Kumaran and J. Allan.",
                "Text classification and named entities for new event detection.",
                "In SIGIR, pages 297-304, 2004. [15] Q. Mei and C. Zhai.",
                "Discovering evolutionary theme patterns from text: an exploration of temporal text mining.",
                "In SIGKDD, pages 198-207, 2005. [16] W. D. Penny.",
                "Kullback-liebler divergences of normal, gamma, dirichlet and wishart densities.",
                "Technical report, 2001. [17] N. Stokes and J. Carthy.",
                "Combining semantic and syntactic document classifiers to improve first story detection.",
                "In SIGIR, pages 424-425, 2001. [18] R. Swan and J. Allan.",
                "Automatic generation of overview timelines.",
                "In SIGIR, pages 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena, and D. Gunopulos.",
                "Identifying similarities, periodicities and bursts for online search queries.",
                "In SIGMOD, pages 131-142, 2004. [20] Y. Yang, T. Pierce, and J. Carbonell.",
                "A study of retrospective and on-line event detection.",
                "In SIGIR, pages 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topic-conditioned novelty detection.",
                "In SIGKDD, pages 688-693, 2002.",
                "Table 1: All important aperiodic events (e1 − e17), top 5 less-reported aperiodic events (e18 − e22) and top 5 important periodic events (e23 − e27).",
                "Detected Event and Bursty Period Doc # True Event e1(Sali,Berisha,Albania,Albanian,March) 02/02/199705/29/1997 1409 Albanians president Sali Berisha lost in an early election and resigned, 12/1996-07/1997. e2(Seko,Mobutu,Sese,Kabila) 03/22/1997-06/09/1997 2273 Zaires president Mobutu Sese coordinated the native rebellion and failed on 05/16/1997. e3(Marxist,Peruvian) 11/19/1996-03/05/1997 824 Peru rebels (Tupac Amaru revolutionary Movement) led a hostage siege in Lima in early 1997. e4(Movement,Tupac,Amaru,Lima,hostage,hostages) 11/16/1996-03/20/1997 824 The same as e3. e5(Kinshasa,Kabila,Laurent,Congo) 03/26/199706/15/1997 1378 Zaire was renamed the Democratic Republic of Congo on 05/16/1997. e6(Jospin,Lionel,June) 05/10/1997-07/09/1997 605 Following the early General Elections circa 06/1997, Lionel Jospin was appointed Prime Minister on 06/02/1997. e7(Iraq,missile) 08/31/1996-09/13/1996 1262 U.S. fired missile at Iraq on 09/03/1996 and 09/04/1996. e8(Kurdish,Baghdad,Iraqi) 08/29/1996-09/09/1996 1132 Iraqi troop fought with Kurdish faction circa 09/1996. e9(May,Blair) 03/24/1997-07/04/1997 1049 Tony Blair became the Primary Minister of the United Kingdom on 05/02/1997. e10(slalom,skiing) 12/05/1996-03/21/1997 253 Slalom Game of Alpine Skiing in 01/1997-02/1997. e11(Interim,months) 09/24/1996-12/31/1996 3063 Tokyo released company interim results for the past several months in 09/1996-12/1996. e12(Dole,Bob) 09/09/1996-11/24/1996 1599 Dole Bob lost the 1996 US presidential election. e13(July,Sen) 06/25/1997-06/25/1997 344 Cambodias Prime Minister Hun Sen launched a bloody military coup in 07/1997. e14(Hebron) 10/15/1996-02/14/1997 2098 Hebron was divided into two sectors in early 1997. e15(April,Easter) 02/23/1997-05/04/1997 480 Easter feasts circa 04/1997 (for western and Orthodox). e16(Diluted,Group) 04/27/1997-07/20/1997 1888 Tokyo released all 96/97 group results in 04/199707/1997. e17(December,Christmas) 11/17/1996-01/26/1997 1326 Christmas feast in late 12/1997. e18(Kolaceva,winter,Together,promenades,Zajedno, Slobodan,Belgrade,Serbian,Serbia,Draskovic,municipal, Kragujevac) 1/25/1997 3 University students organized a vigil on Kolaceva street against government on 1/25/1997. e19(Tutsi,Luvengi,Burundi,Uvira,fuel,Banyamulenge, Burundian,Kivu,Kiliba,Runingo,Kagunga,Bwegera) 10/19/1996 6 Fresh fighting erupted around Uvira between Zaire armed forces and Banyamulengs Tutsi rebels on 10/19/1996. e20(Malantacchi,Korea,Guy,Rider,Unions,labour, Trade,unions,Confederation,rammed,Geneva,stoppages, Virgin,hire,Myongdong,Metalworkers) 1/11/1997 2 Marcello Malantacchi secretary general of the International Metalworkers Federation and Guy Rider who heads the Geneva office of the International Confederation of Free Trade Unions attacked the new labour law of South Korea on 1/11/1997. e21(DBS,Raﬄes) 8/17/1997 9 The list of the unit of Singapore DBS Land Raﬄes Holdings plans on 8/17/1997. e22(preserver,fuel,Galawa,Huddle,Leul,Beausse) 11/24/1996 3 Rescued a woman and her baby during a hijacked Ethiopian plane that ran out of fuel and crashed into the sea near Le Galawa beach on 11/24/1996. e23(PRICE,LISTING,MLN,MATURITY,COUPON, MOODY,AMT,FIRST,ISS,TYPE,PAY,BORROWER) Monday-Friday/week 7966 Announce bond price on all weekdays. e24(Unaudited,Ended,Months,Weighted,Provision,Cost, Selling,Revenues,Loss,Income,except,Shrs,Revs) every season 2264 Net income-loss reports released by companies in every season. e25(rating,Wall,Street,Ian) Monday-Friday/week 21767 Stock reports from Wall Street on all weekdays. e26(Sheffield,league,scoring,goals,striker,games) every Friday, Saturday and Sunday 574 Match results of Sheffield soccer league were published on Friday, Saturday and Sunday 10 times than other 4 days. e27(soccer,matches,Results,season,game,Cup,match, victory,beat,played,play,division) every Friday, Saturday and Sunday 2396 Soccer games held on Friday, Saturday and Sunday 7 times than other 4 days."
            ],
            "original_annotated_samples": [
                "To evaluate our method, we subsequently propose an unsupervised event detection algorithm for news streams. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Easter April (a) aperiodic event 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Unaudited Ended (b) <br>periodic event</br> Figure 1: Feature correlation (DFIDF:time) between a) Easter and April b) Unaudited and Ended.",
                "These two words actually originated from the same <br>periodic event</br>, net income-loss reports, which are released quarterly by publicly listed companies.",
                "A <br>periodic event</br> has a list of periodic features and an aperiodic event has a list of aperiodic features; 2) Representative features from the same event share similar distributions over time and are highly correlated; 3) An important event has a set of active (largely reported) representative features, whereas an unimportant event has a set of inactive (less-reported) representative features; 4) A feature may be included by several events with overlaps in time frames.",
                "Definition 2. (<br>periodic event</br>) If events of a certain event genre occur regularly with a fixed periodicity P ≤ T/2 , we say that this particular event genre is periodic, with each member event qualified as a <br>periodic event</br>.",
                "Using the domain knowledge that soccer games have more matches every Saturday, which makes it a typical and heavily reported <br>periodic event</br>, we thus consider the value of Sf = 155.13 to be high. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) soccer(DFIDF:time) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) soccer(S:frequency) Figure 3: Feature soccer with relative high Sf and short-term Pf ."
            ],
            "translated_annotated_samples": [
                "Para evaluar nuestro método, posteriormente proponemos un algoritmo de detección de eventos no supervisado para flujos de noticias. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Pascua Abril (a) evento aperiódico 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 No auditado Finalizado (b) <br>evento periódico</br> Figura 1: Correlación de características (DFIDF:tiempo) entre a) Pascua y Abril b) No auditado y Finalizado.",
                "Estas dos palabras en realidad se originaron a partir del mismo <br>evento periódico</br>, informes de ganancias y pérdidas, que son publicados trimestralmente por empresas cotizadas en bolsa.",
                "Un <br>evento periódico</br> tiene una lista de características periódicas y un evento aperiódico tiene una lista de características aperiódicas; 2) Las características representativas del mismo evento comparten distribuciones similares en el tiempo y están altamente correlacionadas; 3) Un evento importante tiene un conjunto de características representativas activas (ampliamente reportadas), mientras que un evento no importante tiene un conjunto de características representativas inactivas (menos reportadas); 4) Una característica puede ser incluida por varios eventos con superposiciones en los marcos de tiempo.",
                "Definición 2. (Evento periódico) Si los eventos de un cierto género de eventos ocurren regularmente con una periodicidad fija P ≤ T/2, decimos que este género particular de eventos es periódico, y cada evento miembro se califica como un <br>evento periódico</br>.",
                "Usando el conocimiento del dominio de que los partidos de fútbol tienen más encuentros cada sábado, lo que lo convierte en un <br>evento periódico</br> típico y ampliamente reportado, consideramos que el valor de Sf = 155.13 es alto. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) fútbol (DFIDF:tiempo) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) fútbol (S:frecuencia) Figura 3: Característica fútbol con un Sf relativamente alto y un Pf a corto plazo."
            ],
            "translated_text": "Analizando Trayectorias de Características para la Detección de Eventos Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg Escuela de Ingeniería Informática Universidad Tecnológica de Nanyang Bloque N4, Avenida Nanyang, Singapur 639798 RESUMEN Consideramos el problema de analizar trayectorias de palabras en los dominios del tiempo y la frecuencia, con el objetivo específico de identificar palabras importantes y menos reportadas, periódicas y aperiódicas. Un conjunto de palabras con tendencias idénticas puede agruparse para reconstruir un evento de manera completamente no supervisada. La frecuencia del documento de cada palabra a lo largo del tiempo se trata como una serie temporal, donde cada elemento es el puntaje de frecuencia del documento - frecuencia inversa del documento (DFIDF) en un punto temporal. En este artículo, 1) primero aplicamos análisis espectral para categorizar características de diferentes tipos de eventos: importantes y poco reportados, periódicos y aperiódicos; 2) modelamos las características aperiódicas con densidad gaussiana y las características periódicas con densidades de mezcla gaussiana, y posteriormente detectamos cada ráfaga de características mediante el enfoque gaussiano truncado; 3) propusimos un algoritmo de detección de eventos codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos. Todos los métodos anteriores se pueden aplicar a datos de series temporales en general. Evaluamos exhaustivamente nuestros métodos en el Corpus de Noticias de Reuters de 1 año [3] y demostramos que fueron capaces de descubrir eventos significativos aperiódicos y periódicos. Categorías y Descriptores de Asignaturas: H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales: Algoritmos, Experimentación. 1. INTRODUCCIÓN Hay más de 4,000 fuentes de noticias en línea en el mundo. Supervisar manualmente todos ellos en busca de eventos importantes se ha vuelto difícil o prácticamente imposible. De hecho, la comunidad de detección y seguimiento de temas (TDT) ha estado tratando durante muchos años de encontrar una solución práctica para ayudar a las personas a monitorear las noticias de manera efectiva. Desafortunadamente, el Santo Grial sigue siendo esquivo, ya que la gran mayoría de las soluciones de TDT propuestas para la detección de eventos [20, 5, 17, 4, 21, 7, 14, 10] son demasiado simplistas (basadas en la similitud del coseno [5]) o impracticables debido a la necesidad de ajustar un gran número de parámetros [9]. La ineficacia de las tecnologías actuales de TDT se puede ilustrar fácilmente suscribiéndose a cualquiera de los muchos servicios de alertas de noticias en línea, como el líder de la industria Google News Alerts, que genera más del 50% de falsas alarmas. Como prueba adicional, portales como Yahoo adoptan un enfoque más pragmático al requerir que todas las alertas de noticias generadas por máquinas pasen por un operador humano para su confirmación antes de enviarlas a los suscriptores. En lugar de abordar el problema con variaciones del mismo martillo (similitud coseno y TFIDF), es necesario contar con una comprensión fundamental de las características de los datos de flujo de noticias antes de que se puedan lograr avances importantes en TDT. Por lo tanto, en este artículo, examinamos noticias y tendencias de características desde la perspectiva de analizar una señal de palabras de series temporales. Trabajos anteriores como [9] han intentado reconstruir un evento con sus características representativas. Sin embargo, en muchas tareas de detección de eventos predictivos (es decir, detección de eventos retrospectivos), hay un vasto conjunto de características potenciales solo para un conjunto fijo de observaciones (es decir, los estallidos obvios). De estas características, a menudo solo se espera que un pequeño número sea útil. En particular, estudiamos el novedoso problema de analizar trayectorias de características para la detección de eventos, utilizando una técnica conocida de procesamiento de señales: identificar correlaciones distribucionales entre todas las características mediante análisis espectral. Para evaluar nuestro método, posteriormente proponemos un algoritmo de detección de eventos no supervisado para flujos de noticias. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Pascua Abril (a) evento aperiódico 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 No auditado Finalizado (b) <br>evento periódico</br> Figura 1: Correlación de características (DFIDF:tiempo) entre a) Pascua y Abril b) No auditado y Finalizado. Como ejemplo ilustrativo, considera la correlación entre las palabras Pascua y abril del Corpus de Reuters. A partir del gráfico de su DFIDF normalizado en la Figura 1(a), observamos la gran superposición entre las dos palabras alrededor de 04/1997, lo que significa que probablemente ambas pertenecen al mismo evento durante ese tiempo (festividad de Pascua). En este ejemplo, el evento oculto de la festividad de Pascua es un evento aperiódico típico e importante en datos de 1 año. Otro ejemplo se muestra en la Figura 1(b), donde las palabras \"No auditado\" y \"Finalizado 1\" del Corpus de Reuters son el conjunto de datos predeterminado para todos los ejemplos y presentan un comportamiento similar durante períodos de 3 meses. Estas dos palabras en realidad se originaron a partir del mismo <br>evento periódico</br>, informes de ganancias y pérdidas, que son publicados trimestralmente por empresas cotizadas en bolsa. Otras observaciones extraídas de la Figura 1 son: 1) el período de actividad intensa de abril es mucho más largo que el de Semana Santa, lo que sugiere que abril puede estar presente en otros eventos durante el mismo período; 2) No auditado tiene un valor promedio de DFIDF más alto que Finalizado, lo que indica que No auditado es más representativo para el evento subyacente. Estos dos ejemplos son solo la punta del iceberg entre todas las tendencias de palabras y correlaciones ocultas en un flujo de noticias como Reuters. Si se puede descubrir un gran número de ellos, podría ayudar significativamente en las tareas de TDT. En particular, indica la importancia de extraer características correlacionadas para detectar eventos correspondientes. Para resumir, postulamos que: 1) Un evento se describe por sus características representativas. Un <br>evento periódico</br> tiene una lista de características periódicas y un evento aperiódico tiene una lista de características aperiódicas; 2) Las características representativas del mismo evento comparten distribuciones similares en el tiempo y están altamente correlacionadas; 3) Un evento importante tiene un conjunto de características representativas activas (ampliamente reportadas), mientras que un evento no importante tiene un conjunto de características representativas inactivas (menos reportadas); 4) Una característica puede ser incluida por varios eventos con superposiciones en los marcos de tiempo. Basándonos en estas observaciones, podemos extraer características representativas dadas un evento o detectar un evento a partir de una lista de características altamente correlacionadas. En este artículo, nos enfocamos en este último aspecto, es decir, cómo se pueden descubrir características correlacionadas para formar un evento de manera no supervisada. 1.1 Contribuciones Este artículo tiene tres contribuciones principales: • Hasta donde sabemos, nuestro enfoque es el primero en categorizar características de palabras para eventos heterogéneos. Específicamente, cada característica de palabra se clasifica en uno de los siguientes cinco tipos de características basados en la fuerza de su espectro de potencia y periodicidad: 1) HH (alta potencia y alta/larga periodicidad): eventos aperiódicos importantes, 2) HL (alta potencia y baja periodicidad): eventos periódicos importantes, 3) LH (baja potencia y alta periodicidad): eventos aperiódicos no importantes, 4) LL (baja potencia y baja periodicidad): no eventos, y 5) SW (palabras vacías), un subconjunto de LL con mayor potencia y periodicidad que comprende palabras vacías, que no contienen información. • Proponemos un enfoque simple y efectivo basado en densidad de mezcla para modelar y detectar ráfagas de características. • Presentamos un algoritmo de detección de eventos no supervisado para detectar eventos tanto aperiódicos como periódicos. Nuestro algoritmo ha sido evaluado en un flujo de noticias reales para demostrar su efectividad. 2. TRABAJO RELACIONADO Este trabajo está motivado en gran medida por una familia más amplia de problemas conocidos colectivamente como Detección y Seguimiento de Temas (TDT) [20, 5, 17, 4, 21, 7, 14, 10]. Además, la mayoría de las investigaciones de TDT hasta ahora se han centrado en agrupar/clasificar documentos en tipos de temas, identificar oraciones novedosas para eventos nuevos, etc., sin prestar mucha atención al análisis de la trayectoria de las palabras con respecto al tiempo. Swan y Allan [18] intentaron por primera vez usar términos que co-ocurren para construir un evento. Sin embargo, solo consideraron entidades nombradas y pares de frases nominales, sin tener en cuenta sus periodicidades. Por el contrario, nuestro artículo considera todo lo anterior. Recientemente, ha habido un gran interés en modelar un evento en flujos de texto como un estallido de actividades al incorporar información temporal. El trabajo seminal de Kleinberg describió cómo se pueden extraer características explosivas de flujos de texto utilizando un modelo de autómata infinito [12], lo que inspiró toda una serie de aplicaciones como la identificación de comunidades explosivas de Kumar a partir de gráficos de blogs [13], la sumarización de temas evolutivos en flujos de texto de Meis [15], el agrupamiento de flujos de texto utilizando características explosivas de Hes [11], etc. Sin embargo, ninguno de los trabajos existentes identificó específicamente características para eventos, excepto Fung et al. [9], quienes agruparon características llamativas para identificar varios eventos llamativos. Nuestro trabajo difiere de [9] en varias formas: 1) analizamos cada característica individual, no solo las características explosivas; 2) clasificamos las características a lo largo de dos dimensiones categóricas (periodicidad y potencia), dando en total cinco tipos de características principales; 3) no restringimos que cada característica pertenezca exclusivamente a un solo evento. Las técnicas de análisis espectral han sido utilizadas previamente por Vlachos et al. [19] para identificar periodicidades y ráfagas en los registros de consultas. Su enfoque estaba en detectar múltiples periodicidades a partir del gráfico del espectro de potencia, las cuales luego se utilizaron para indexar palabras para la búsqueda por ráfagas. En este artículo, utilizamos análisis espectral para clasificar las características de las palabras a lo largo de dos dimensiones, a saber, periodicidad y espectro de potencia, con el objetivo final de identificar eventos tanto periódicos como no periódicos y explosivos. 3. REPRESENTACIÓN DE DATOS Sea T la duración/período (en días) de un flujo de noticias, y F representa el espacio de características de palabras completo en el Modelo de Espacio Vectorial (VSM) estático clásico. 3.1 Clasificación de Periodicidad de Eventos Dentro de T, pueden existir ciertos eventos que ocurren solo una vez, por ejemplo, la elección de Tony Blair como Primer Ministro del Reino Unido, y otros eventos recurrentes de diversas periodicidades, por ejemplo, partidos de fútbol semanales. Por lo tanto, categorizamos todos los eventos en dos tipos: aperiódicos y periódicos, definidos de la siguiente manera. Definición 1. (Evento aperiódico) Un evento es aperiódico dentro de T si solo ocurre una vez. Definición 2. (Evento periódico) Si los eventos de un cierto género de eventos ocurren regularmente con una periodicidad fija P ≤ T/2, decimos que este género particular de eventos es periódico, y cada evento miembro se califica como un <br>evento periódico</br>. Ten en cuenta que la definición de aperiódico es relativa, es decir, es verdadera solo para un T dado y puede ser inválida para cualquier otro T > T. Por ejemplo, el evento de la fiesta de Navidad es aperiódico para T ≤ 365 pero periódico para T ≥ 730. 3.2 Características Representativas Intuitivamente, un evento puede ser descrito de manera muy concisa por unas pocas características de palabras discriminativas y representativas y viceversa, por ejemplo, huracán, barrido y golpe podrían ser características representativas de un evento del género de huracanes. Asimismo, un conjunto de características fuertemente correlacionadas podría ser utilizado para reconstruir una descripción de un evento, asumiendo que las características fuertemente correlacionadas son representativas. El vector de representación de una característica de palabra se define de la siguiente manera: Definición 3. (Trayectoria de la Característica) La trayectoria de una característica de palabra f puede escribirse como la secuencia yf = [yf (1), yf (2), . . . , yf (T)], donde cada elemento yf (t) es una medida de la característica f en el tiempo t, que podría definirse utilizando la puntuación normalizada DFIDF yf (t) = DFf (t) N(t) × log( N DFf ), donde DFf (t) es el número de documentos (DF local) que contienen la característica f en el día t, DFf es el número total de documentos (DF global) que contienen la característica f en T, N(t) es el número de documentos para el día t, y N es el número total de documentos en T. 4. En esta sección, mostramos cómo se pueden extraer características representativas para eventos (poco) importantes o (a)periódicos. 4.1 Análisis Espectral para el Período Dominante Dada una característica f, descomponemos su trayectoria de características yf = [yf (1), yf (2), ..., yf (T)] en la secuencia de T números complejos [X1, . . . , XT ] a través de la transformada discreta de Fourier (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. La DFT puede representar la serie temporal original como una combinación lineal de sinusoides complejas, lo cual se ilustra mediante la transformada discreta de Fourier inversa (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, donde el coeficiente de Fourier Xk denota la amplitud del sinusoides con frecuencia k/T. La trayectoria original puede ser reconstruida con solo las frecuencias dominantes, las cuales pueden ser determinadas a partir del espectro de potencia utilizando el popular estimador periodograma. El periodograma es una secuencia de la magnitud al cuadrado de los coeficientes de Fourier, Xk^2, k = 1, 2, . . . , T/2, que indica la potencia de la señal en la frecuencia k/T en el espectro. A partir del espectro de potencia, se elige el período dominante como el inverso de la frecuencia con el espectro de potencia más alto, de la siguiente manera. Definición 4. (Período Dominante) El período dominante (DP) de una característica dada f es Pf = T/ arg max k Xk 2. Por lo tanto, tenemos la Definición 5. (Espectro de Potencia Dominante) El espectro de potencia dominante (DPS) de una característica dada f es Sf = Xk 2 , con Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorización de Características El DPS de una trayectoria de características es un indicador fuerte de su actividad en la frecuencia especificada; cuanto mayor sea el DPS, es más probable que la característica sea explosiva. Al combinar DPS con DP, categorizamos todas las características en cuatro tipos: 2 Normalizamos yf (t) como yf (t) = yf (t)/ T i=1 yf (i) para que pueda interpretarse como una probabilidad. • HH: alta Sf, aperiódico o periódico a largo plazo (Pf > T/2); • HL: alta Sf, periódico a corto plazo (Pf ≤ T/2); • LH: baja Sf, aperiódico o periódico a largo plazo; • LL: baja Sf, periódico a corto plazo. La frontera entre los periodos a largo plazo y a corto plazo se establece en T/2. Sin embargo, distinguir entre un DPS alto y bajo no es sencillo, lo cual se abordará más adelante. Propiedades de diferentes conjuntos de características Para comprender mejor las propiedades de HH, HL, LH y LL, seleccionamos cuatro características, Navidad, fútbol, DBS y tu como ejemplos ilustrativos. Dado que la frontera entre el espectro de alta y baja potencia no está clara, estos ejemplos seleccionados tienen un rango relativo amplio de valores de espectro de potencia. La figura 2(a) muestra la trayectoria de DFIDF para la Navidad con un pico distintivo alrededor del día de Navidad. Para el conjunto de datos de Reuters de 1 año, la Navidad se clasifica como un evento aperiódico típico con Pf = 365 y Sf = 135.68, como se muestra en la Figura 2(b). Claramente, el valor de Sf = 135.68 es razonable para un evento conocido por ser intermitente como la Navidad. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Navidad(DFIDF:tiempo) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Navidad(S:frecuencia) Figura 2: Característica Navidad con un Sf relativamente alto y un Pf a largo plazo. La trayectoria de DFIDF para el fútbol se muestra en la Figura 3(a), de la cual podemos observar que hay un estallido regular cada 7 días, lo cual es nuevamente verificado por su valor calculado de Pf = 7, como se muestra en la Figura 3(b). Usando el conocimiento del dominio de que los partidos de fútbol tienen más encuentros cada sábado, lo que lo convierte en un <br>evento periódico</br> típico y ampliamente reportado, consideramos que el valor de Sf = 155.13 es alto. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) fútbol (DFIDF:tiempo) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) fútbol (S:frecuencia) Figura 3: Característica fútbol con un Sf relativamente alto y un Pf a corto plazo. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "word signal": {
            "translated_key": "señal de palabras",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Analyzing Feature Trajectories for Event Detection Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg School of Computer Engineering Nanyang Technological University Block N4, Nanyang Avenue, Singapore 639798 ABSTRACT We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words.",
                "A set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner.",
                "The document frequency of each word across time is treated like a time series, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point.",
                "In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events.",
                "All of the above methods can be applied to time series data in general.",
                "We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events.",
                "Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Experimentation. 1.",
                "INTRODUCTION There are more than 4,000 online news sources in the world.",
                "Manually monitoring all of them for important events has become difficult or practically impossible.",
                "In fact, the topic detection and tracking (TDT) community has for many years been trying to come up with a practical solution to help people monitor news effectively.",
                "Unfortunately, the holy grail is still elusive, because the vast majority of TDT solutions proposed for event detection [20, 5, 17, 4, 21, 7, 14, 10] are either too simplistic (based on cosine similarity [5]) or impractical due to the need to tune a large number of parameters [9].",
                "The ineffectiveness of current TDT technologies can be easily illustrated by subscribing to any of the many online news alerts services such as the industryleading Google News Alerts [2], which generates more than 50% false alarms [10].",
                "As further proof, portals like Yahoo take a more pragmatic approach by requiring all machine generated news alerts to go through a human operator for confirmation before sending them out to subscribers.",
                "Instead of attacking the problem with variations of the same hammer (cosine similarity and TFIDF), a fundamental understanding of the characteristics of news stream data is necessary before any major breakthroughs can be made in TDT.",
                "Thus in this paper, we look at news stories and feature trends from the perspective of analyzing a time-series <br>word signal</br>.",
                "Previous work like [9] has attempted to reconstruct an event with its representative features.",
                "However, in many predictive event detection tasks (i.e., retrospective event detection), there is a vast set of potential features only for a fixed set of observations (i.e., the obvious bursts).",
                "Of these features, often only a small number are expected to be useful.",
                "In particular, we study the novel problem of analyzing feature trajectories for event detection, borrowing a well-known technique from signal processing: identifying distributional correlations among all features by spectral analysis.",
                "To evaluate our method, we subsequently propose an unsupervised event detection algorithm for news streams. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Easter April (a) aperiodic event 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Unaudited Ended (b) periodic event Figure 1: Feature correlation (DFIDF:time) between a) Easter and April b) Unaudited and Ended.",
                "As an illustrative example, consider the correlation between the words Easter and April from the Reuters Corpus1 .",
                "From the plot of their normalized DFIDF in Figure 1(a), we observe the heavy overlap between the two words circa 04/1997, which means they probably both belong to the same event during that time (Easter feast).",
                "In this example, the hidden event Easter feast is a typical important aperiodic event over 1-year data.",
                "Another example is given by Figure 1(b), where both the words Unaudited and Ended 1 Reuters Corpus is the default dataset for all examples. exhibit similar behaviour over periods of 3 months.",
                "These two words actually originated from the same periodic event, net income-loss reports, which are released quarterly by publicly listed companies.",
                "Other observations drawn from Figure 1 are: 1) the bursty period of April is much longer than Easter, which suggests that April may exist in other events during the same period; 2) Unaudited has a higher average DFIDF value than Ended, which indicates Unaudited to be more representative for the underlying event.",
                "These two examples are but the tip of the iceberg among all word trends and correlations hidden in a news stream like Reuters.",
                "If a large number of them can be uncovered, it could significantly aid TDT tasks.",
                "In particular, it indicates the significance of mining correlating features for detecting corresponding events.",
                "To summarize, we postulate that: 1) An event is described by its representative features.",
                "A periodic event has a list of periodic features and an aperiodic event has a list of aperiodic features; 2) Representative features from the same event share similar distributions over time and are highly correlated; 3) An important event has a set of active (largely reported) representative features, whereas an unimportant event has a set of inactive (less-reported) representative features; 4) A feature may be included by several events with overlaps in time frames.",
                "Based on these observations, we can either mine representative features given an event or detect an event from a list of highly correlated features.",
                "In this paper, we focus on the latter, i.e., how correlated features can be uncovered to form an event in an unsupervised manner. 1.1 Contributions This paper has three main contributions: • To the best of our knowledge, our approach is the first to categorize word features for heterogenous events.",
                "Specifically, every word feature is categorized into one of the following five feature types based on its power spectrum strength and periodicity: 1) HH (high power and high/long periodicity): important aperiodic events, 2) HL (high power and low periodicity): important periodic events, 3) LH (low power and high periodicity): unimportant aperiodic events, 4) LL (low power and low periodicity): non-events, and 5) SW (stopwords), a higher power and periodicity subset of LL comprising stopwords, which contains no information. • We propose a simple and effective mixture densitybased approach to model and detect feature bursts. • We come up with an unsupervised event detection algorithm to detect both aperiodic and periodic events.",
                "Our algorithm has been evaluated on a real news stream to show its effectiveness. 2.",
                "RELATED WORK This work is largely motivated by a broader family of problems collectively known as Topic Detection and Tracking (TDT) [20, 5, 17, 4, 21, 7, 14, 10].",
                "Moreover, most TDT research so far has been concerned with clustering/classifying documents into topic types, identifying novel sentences [6] for new events, etc., without much regard to analyzing the word trajectory with respect to time.",
                "Swan and Allan [18] first attempted using co-occuring terms to construct an event.",
                "However, they only considered named entities and noun phrase pairs, without considering their periodicities.",
                "On the contrary, our paper considers all of the above.",
                "Recently, there has been significant interest in modeling an event in text streams as a burst of activities by incorporating temporal information.",
                "Kleinbergs seminal work described how bursty features can be extracted from text streams using an infinite automaton model [12], which inspired a whole series of applications such as Kumars identification of bursty communities from Weblog graphs [13], Meis summarization of evolutionary themes in text streams [15], Hes clustering of text streams using bursty features [11], etc.",
                "Nevertheless, none of the existing work specifically identified features for events, except for Fung et al. [9], who clustered busty features to identify various bursty events.",
                "Our work differs from [9] in several ways: 1) we analyze every single feature, not only bursty features; 2) we classify features along two categorical dimensions (periodicity and power), yielding altogether five primary feature types; 3) we do not restrict each feature to exclusively belong to only one event.",
                "Spectral analysis techniques have previously been used by Vlachos et al. [19] to identify periodicities and bursts from query logs.",
                "Their focus was on detecting multiple periodicities from the power spectrum graph, which were then used to index words for query-by-burst search.",
                "In this paper, we use spectral analysis to classify word features along two dimensions, namely periodicity and power spectrum, with the ultimate goal of identifying both periodic and aperiodic bursty events. 3.",
                "DATA REPRESENTATION Let T be the duration/period (in days) of a news stream, and F represents the complete word feature space in the classical static Vector Space Model (VSM). 3.1 Event Periodicity Classification Within T, there may exist certain events that occur only once, e.g., Tony Blair elected as Prime Minister of U.K., and other recurring events of various periodicities, e.g., weekly soccer matches.",
                "We thus categorize all events into two types: aperiodic and periodic, defined as follows.",
                "Definition 1. (Aperiodic Event) An event is aperiodic within T if it only happens once.",
                "Definition 2. (Periodic Event) If events of a certain event genre occur regularly with a fixed periodicity P ≤ T/2 , we say that this particular event genre is periodic, with each member event qualified as a periodic event.",
                "Note that the definition of aperiodic is relative, i.e., it is true only for a given T, and may be invalid for any other T > T. For example, the event Christmas feast is aperiodic for T ≤ 365 but periodic for T ≥ 730. 3.2 Representative Features Intuitively, an event can be described very concisely by a few discriminative and representative word features and vice-versa, e.g., hurricane, sweep, and strike could be representative features of a Hurricane genre event.",
                "Likewise, a set of strongly correlated features could be used to reconstruct an event description, assuming that strongly correlated features are representative.",
                "The representation vector of a word feature is defined as follows: Definition 3. (Feature Trajectory) The trajectory of a word feature f can be written as the sequence yf = [yf (1), yf (2), . . . , yf (T)], where each element yf (t) is a measure of feature f at time t, which could be defined using the normalized DFIDF score2 yf (t) = DFf (t) N(t) × log( N DFf ), where DFf (t) is the number of documents (local DF) containing feature f at day t, DFf is the total number of documents (global DF) containing feature f over T, N(t) is the number of documents for day t, and N is the total number of documents over T. 4.",
                "IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 Spectral Analysis for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. DFT can represent the original time series as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T.",
                "The original trajectory can be reconstructed with just the dominant frequencies, which can be determined from the power spectrum using the popular periodogram estimator.",
                "The periodogram is a sequence of the squared magnitude of the Fourier coefficients, Xk 2 , k = 1, 2, . . . , T/2 , which indicates the signal power at frequency k/T in the spectrum.",
                "From the power spectrum, the dominant period is chosen as the inverse of the frequency with the highest power spectrum, as follows.",
                "Definition 4. (Dominant Period) The dominant period (DP) of a given feature f is Pf = T/ arg max k Xk 2 .",
                "Accordingly, we have Definition 5. (Dominant Power Spectrum) The dominant power spectrum (DPS) of a given feature f is Sf = Xk 2 , with Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorizing Features The DPS of a feature trajectory is a strong indicator of its activeness at the specified frequency; the higher the DPS, the more likely for the feature to be bursty.",
                "Combining DPS with DP, we therefore categorize all features into four types: 2 We normalize yf (t) as yf (t) = yf (t)/ T i=1 yf (i) so that it could be interpreted as a probability. • HH: high Sf , aperiodic or long-term periodic (Pf > T/2 ); • HL: high Sf , short-term periodic (Pf ≤ T/2 ); • LH: low Sf , aperiodic or long-term periodic; • LL: low Sf , short-term periodic.",
                "The boundary between long-term and short-term periodic is set to T/2 .",
                "However, distinguishing between a high and low DPS is not straightforward, which will be tackled later.",
                "Properties of Different Feature Sets To better understand the properties of HH, HL, LH and LL, we select four features, Christmas, soccer, DBS and your as illustrative examples.",
                "Since the boundary between high and low power spectrum is unclear, these chosen examples have relative wide range of power spectrum values.",
                "Figure 2(a) shows the DFIDF trajectory for Christmas with a distinct burst around Christmas day.",
                "For the 1-year Reuters dataset, Christmas is classified as a typical aperiodic event with Pf = 365 and Sf = 135.68, as shown in Figure 2(b).",
                "Clearly, the value of Sf = 135.68 is reasonable for a well-known bursty event like Christmas. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Christmas(DFIDF:time) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Christmas(S:frequency) Figure 2: Feature Christmas with relative high Sf and long-term Pf .",
                "The DFIDF trajectory for soccer is shown in Figure 3(a), from which we can observe that there is a regular burst every 7 days, which is again verified by its computed value of Pf = 7, as shown in Figure 3(b).",
                "Using the domain knowledge that soccer games have more matches every Saturday, which makes it a typical and heavily reported periodic event, we thus consider the value of Sf = 155.13 to be high. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) soccer(DFIDF:time) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) soccer(S:frequency) Figure 3: Feature soccer with relative high Sf and short-term Pf .",
                "From the DFIDF trajectory for DBS in Figure 4(a), we can immediately deduce DBS to be an infrequent word with a trivial burst on 08/17/1997 corresponding to DBS Land Raﬄes Holdings plans.",
                "This is confirmed by the long period of Pf = 365 and low power of Sf = 0.3084 as shown in Figure 4(b).",
                "Moreover, since this aperiodic event is only reported in a few news stories over a very short time of few days, we therefore say that its low power value of Sf = 0.3084 is representative of unimportant events.",
                "The most confusing example is shown in Figure 5 for the word feature your, which looks very similar to the graph for soccer in Figure 3.",
                "At first glance, we may be tempted to group both your and soccer into the same category of HL or LL since both distributions look similar and have the same dominant period of approximately a week.",
                "However, further 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:time) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frequency) Figure 4: Feature DBS with relative low Sf and long-term Pf . analysis indicates that the periodicity of your is due to the differences in document counts for weekdays (average 2,919 per day) and weekends3 (average 479 per day).",
                "One would have expected the periodicity of a stopword like your to be a day.",
                "Moreover, despite our DFIDF normalization, the weekday/weekend imbalance still prevailed; stopwords occur 4 times more frequently on weekends than on weekdays.",
                "Thus, the DPS remains the only distinguishing factor between your (Sf = 9.42) and soccer (Sf = 155.13).",
                "However, it is very dangerous to simply conclude that a power value of S = 9.42 corresponds to a stopword feature. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) your(DFIDF:time) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) your(S:frequency) Figure 5: Feature your as an example confusing with feature soccer.",
                "Before introducing our solution to this problem, lets look at another LL example as shown in Figure 6 for beenb, which is actually a confirmed typo.",
                "We therefore classify beenb as a noisy feature that does not contribute to any event.",
                "Clearly, the trajectory of your is very different from beenb, which means that the former has to be considered separately. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figure 6: Feature beenb with relative low Sf and short-term Pf .",
                "Stop Words (SW) Feature Set Based on the above analysis, we realize that there must be another feature set between HL and LL that corresponds to the set of stopwords.",
                "Features from this set has moderate DPS and low but known dominant period.",
                "Since it is hard to distinguish this feature set from HL and LL only based on DPS, we introduce another factor called average DFIDF (DFIDF).",
                "As shown in Figure 5, features like your usually have a lower DPS than a HL feature like soccer, but have a much higher DFIDF than another LL noisy feature such as beenb.",
                "Since such properties are usually characteristics of stopwords, we group features like your into the newly defined stopword (SW) feature set.",
                "Since setting the DPS and DFIDF thresholds for identifying stopwords is more of an art than science, we proposed a heuristic HS algorithm, Algorithm 1.",
                "The basic idea is to only use news stories from weekdays to identify stopwords. 3 The weekends here also include public holidays falling on weekdays.",
                "The SW set is initially seeded with a small set of 29 popular stopwords utilized by Google search engine.",
                "Algorithm 1 Heuristic Stopwords detection (HS) Input: Seed SW set, weekday trajectories of all words 1: From the seed set SW, compute the maximum DPS as UDPS, maximum DFIDF as UDFIDF, and minimum of DFIDF as LDFIDF. 2: for fi ∈ F do 3: Compute DFT for fi. 4: if Sfi ≤ UDPS and DFIDFfi ∈ [LDFIDF, UDFIDF] then 5: fi → SW 6: F = F − fi 7: end if 8: end for Overview of Feature Categorization After the SW set is generated, all stopwords are removed from F. We then set the boundary between high and low DPS to be the upper bound of the SW sets DPS.",
                "An overview of all five feature sets is shown in Figure 7.",
                "Figure 7: The 5 feature sets for events. 5.",
                "IDENTIFYING BURSTS FOR FEATURES Since only features from HH, HL and LH are meaningful and could potentially be representative to some events, we pruned all other feature classified as LL or SW.",
                "In this section, we describe how bursts can be identified from the remaining features.",
                "Unlike Kleinbergs burst identification algorithm [12], we can identify both significant and trivial bursts without the need to set any parameters. 5.1 Detecting Aperiodic Features Bursts For each feature in HH and HL, we truncate its trajectory by keeping only the bursty period, which is modeled with a Gaussian distribution.",
                "For example, Figure 8 shows the word feature Iraq with a burst circa 09/06/1996 being modeled as a Gaussian.",
                "Its bursty period is defined by [μf − σf , μf + σf ] as shown in Figure 8(b). 5.2 Detecting Periodic Features Bursts Since we have computed the DP for a periodic feature f, we can easily model its periodic feature trajectory yf using 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) original DFIDF:time 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 burst= [μ-σ, μ+σ] (b) identifying burst Figure 8: Modeling Iraqs time series as a truncated Gaussian with μ = 09/06/1996 and σ = 6.26. a mixture of K = T/Pf Gaussians: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , where the parameter set θf = {αk, μk, σk}K k=1 comprises: • αk is the probability of assigning yf into the kth Gaussian. αk > 0, ∀k ∈ [1, K] and K k=1 αk = 1; • μk/σk is mean/standard deviation of the kth Gaussian.",
                "The well known Expectation Maximization (EM) [8] algorithm is used to compute the mixing proportions αk, as well as the individual Gaussian density parameters μk and σK .",
                "Each Gaussian represents one periodic event, and is modeled similarly as mentioned in Section 5.1. 6.",
                "EVENTS FROM FEATURES After identifying and modeling bursts for all features, the next task is to paint a picture of the event with a potential set of representative features. 6.1 Feature Correlation If two features fi and fj are representative of the same event, they must satisfy the following necessary conditions: 1. fi and fj are identically distributed: yfi ∼ yfj . 2. fi and fj have a high document overlap.",
                "Measuring Feature Distribution Similarity We measure the similarity between two features fi and fj using discrete KL-divergence defined as follows.",
                "Definition 6. (feature similarity) KL(fi, fj ) is given by max(KL(fi|fj ), KL(fj |fi)), where KL(fi|fj ) = T t=1 f(yfi (t)|θfi )log f(yfi (t)|θfi ) f(yfj (t)|θfj ) . (1) Since KL-divergence is not symmetric, we define the similarity between between fi and fj as the maximum of KL(fi|fj ) and KL(fj |fi).",
                "Further, the similarity between two aperiodic features can be computed using a closed form of the KL-divergence [16].",
                "The same discrete KL-divergence formula of Eq. 1 is employed to compute the similarity between two periodic features, Next, we define the overal similarity among a set of features R using the maximum inter-feature KL-Divergence value as follows.",
                "Definition 7. (sets similarity)KL(R) = max ∀fi,fj ∈R KL(fi, fj ).",
                "Document Overlap Let Mi be the set of all documents containing feature fi.",
                "Given two features fi and fj , the overlapping document set containing both features is Mi ∩ Mj .",
                "Intuitively, the higher the |Mi ∩ Mj |, the more likelty that fi and fj will be highly correlated.",
                "We define the degree of document overlap between two features fi and fj as follows.",
                "Definition 8. (Feature DF Overlap) d(fi, fj ) = |Mi∩Mj| min(|Mi|,|Mj|) .",
                "Accordingly, the DF Overlap among a set of features R is also defined.",
                "Definition 9. (Set DF Overlap) d(R) = min ∀fi,fj ∈R d(fi, fj). 6.2 Unsupervised Greedy Event Detection We use features from HH to detect important aperiodic events, features from LH to detect less-reported/unimportant aperiodic events, and features from HL to detect periodic events.",
                "All of them share the same algorithm.",
                "Given bursty feature fi ∈ HH, the goal is to find highly correlated features from HH.",
                "The set of features similar to fi can then collectively describe an event.",
                "Specifically, we need to find a subset Ri of HH that minimizes the following cost function: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) The underlying event e (associated with the burst of fi) can be represented by Ri as y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) The burst analysis for event e is exactly the same as the feature trajectory.",
                "The cost in Eq. 2 can be minimized using our unsupervised greedy UG event detection algorithm, which is described in Algorithm 2.",
                "The UG algorithm allows a feature Algorithm 2 Unsupervised Greedy event detection (UG).",
                "Input: HH, document index for each feature. 1: Sort and select features in descending DPS order: Sf1 ≥ Sf2 ≥ . . . ≥ Sf|HH| . 2: k = 0. 3: for fi ∈ HH do 4: k = k + 1. 5: Init: Ri ← fi, C(Ri) = 1/Sfi and HH = HH − fi. 6: while HH not empty do 7: m = arg min m C(Ri ∪ fm). 8: if C(Ri ∪ fm) < C(Ri) then 9: Ri ← fm and HH = HH − fm. 10: else 11: break while. 12: end if 13: end while 14: Output ek as Eq. 3. 15: end for to be contained in multiple events so that we can detect several events happening at the same time.",
                "Furthermore, trivial events only containing year/month features (i.e., an event only containing 1 feature Aug could be identified over a 1year news stream) could be removed, although such events will have inherent high cost and should already be ranked very low.",
                "Note that our UG algorithm only requires one data-dependant parameter, the boundary between high and low power spectrum, to be set once, and this parameter can be easily estimated using the HS algorithm (Algorithm 1). 7.",
                "EXPERIMENTS In this section, we study the performances of our feature categorizing method and event detection algorithm.",
                "We first introduce the dataset and experimental setup, then we subjectively evaluate the categorization of features for HH, HL, LH, LL and SW.",
                "Finally, we study the (a)periodic event detection problem with Algorithm 2. 7.1 Dataset and Experimental Setup The Reuters Corpus contains 806,791 English news stories from 08/20/1996 to 08/19/1997 at a day resolution.",
                "Version 2 of the open source Lucene software [1] was used to tokenize the news text content and generate the document-word vector.",
                "In order to preserve the time-sensitive past/present/future tenses of verbs and the differences between lower case nouns and upper case named entities, no stemming was done.",
                "Since dynamic stopword removal is one of the functionalities of our method, no stopword was removed.",
                "We did remove nonEnglish characters, however, after which the number of word features amounts to 423,433.",
                "All experiments were implemented in Java and conducted on a 3.2 GHz Pentium 4 PC running Windows 2003 Server with 1 GB of memory. 7.2 Categorizing Features We downloaded 34 well-known stopwords utilized by the Google search engine as our seed training features, which includes a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en and www.",
                "We excluded the last five stopwords as they are uncommon in news stories.",
                "By only analyzing news stories over 259 weekdays, we computed the upper bound of the power spectrum for stopwords at 11.18 and corresponding DFIDF ranges from 0.1182 to 0.3691.",
                "Any feature f satisfying Sf <= 11.18 and 0.1182 <= DFIDFf <= 0.3691 over weekdays will be considered a stopword.",
                "In this manner, 470 stopwords were found and removed as visualized in Figure 9.",
                "Some detected stopwords are A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) and much (P = 22, S = 0.80, DFIDF = 0.1865).",
                "After the removal of these stopwords, the distribution of weekday and weekend news are more or less matched, and in the ensuing experiments, we shall make use of the full corpus (weekdays and weekends).",
                "The upper bound power spectrum value of 11.18 for stopwords training was selected as the boundary between the high power and low power spectrum.",
                "The boundary between high and low periodicity was set to 365/2 = 183.",
                "All 422,963 (423433 − 470) word features were categorized into 4 feature sets: HH (69 features), HL (1,087 features), LH (83,471 features), and LL (338,806 features) as shown in Figure 10.",
                "In Figure 10, each gray level denotes the relative density of features in a square region, measured by log10(1 + Dk), where Dk is the number of features within the k-th square region.",
                "From the figure, we can make the 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figure 9: Distribution of SW (stopwords) in the HH, HL, LH, and LL regions. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figure 10: Distribution of categorized features over the four quadrants (shading in log scale). following observations: 1.",
                "Most features have low S and are easily distinguishable from those features having a much higher S, which allows us to detect important (a)periodic events from trivial events by selecting features with high S. 2.",
                "Features in the HH and LH quadrants are aperiodic, which are nicely separated (big horizontal gap) from the periodic features.",
                "This allows reliably detecting aperiodic events and periodic events independently. 3.",
                "The (vertical) boundary between high and low power spectrum is not as clearcut and the exact value will be application specific.",
                "By checking the scatter distribution of features from SW on HH, HL, LH, and LL as shown in Figure 9, we found that 87.02%(409/470) of the detected stopwords originated from LL.",
                "The LL classification and high DFIDF scores of stopwords agree with the generally accepted notion that stopwords are equally frequent over all time.",
                "Therefore, setting the boundary between high and low power spectrum using the upper bound Sf of SW is a reasonable heuristic. 7.3 Detecting Aperiodic Events We shall evaluate our two hypotheses, 1)important aperiodic events can be defined by a set of HH features, and 2)less reported aperiodic events can be defined by a set of LH features.",
                "Since no benchmark news streams exist for event detection (TDT datasets are not proper streams), we evaluate the quality of the automatically detected events by comparing them to manually-confirmed events by searching through the corpus.",
                "Among the 69 HH features, we detected 17 important aperiodic events as shown in Table 1 (e1 − e17).",
                "Note that the entire identification took less than 1 second, after removing events containing only the month feature.",
                "Among the 17 events, other than the overlaps between e3 and e4 (both describes the same hostage event), e11 and e16 (both about company reports), the 14 identified events are extremely accurate and correspond very well to the major events of the period.",
                "For example, the defeat of Bob Dole, election of Tony Blair, Missile attack on Iraq, etc.",
                "Recall that selecting the features for one event should minimize the cost in Eq. 2 such that 1) the number of features span different events, and 2) not all features relevant to an event will be selected, e.g., the feature Clinton is representative to e12 but since Clinton relates to many other events, its time domain signal is far different from those of other representative features like Dole and Bob.",
                "The number of documents of a detected event is roughly estimated by the number of indexed documents containing the representative features.",
                "We can see that all 17 important aperiodic events are popularly reported events.",
                "After 742 minutes of computation time, we detected 23, 525 less reported aperiodic events from 83,471 LH features.",
                "Table 1 lists the top 5 detected aperiodic events (e18 − e22) with respect to the cost.",
                "We found that these 5 events are actually very trivial events with only a few news reports, and are usually subsumed by some larger topics.",
                "For example, e22 is one of the rescue events in an airplane hijack topic.",
                "One advantage of our UG Algorithm for discovering less-reported aperiodic events is that we are able to precisely detect the true event period. 7.4 Detecting Periodic Events Among the 1,087 HL features, 330 important periodic events were detected within 10 minutes of computing time.",
                "Table 1 lists the top 5 detected periodic events with respect to the cost (e23 − e27).",
                "All of the detected periodic events are indeed valid, and correspond to real life periodic events.",
                "The GMM model is able to detect and estimate the bursty period nicely although it cannot distinguish the slight difference between every Monday-Friday and all weekdays as shown in e23.",
                "We also notice that e26 is actually a subset of e27 (soccer game), which is acceptable since the Sheffield league results are announced independently every weekend. 8.",
                "CONCLUSIONS This paper took a whole new perspective of analyzing feature trajectories as time domain signals.",
                "By considering the word document frequencies in both time and frequency domains, we were able to derive many new characteristics about news streams that were previously unknown, e.g., the different distributions of stopwords during weekdays and weekends.",
                "For the first time in the area of TDT, we applied a systematic approach to automatically detect important and less-reported, periodic and aperiodic events.",
                "The key idea of our work lies in the observations that (a)periodic events have (a)periodic representative features and (un)important events have (in)active representative features, differentiated by their power spectrums and time periods.",
                "To address the real event detection problem, a simple and effective mixture density-based approach was used to identify feature bursts and their associated bursty periods.",
                "We also designed an unsupervised greedy algorithm to detect both aperiodic and periodic events, which was successful in detecting real events as shown in the evaluation on a real news stream.",
                "Although we have not made any benchmark comparison against another approach, simply because there is no previous work in the addressed problem.",
                "Future work includes evaluating the recall of detected events for a labeled news stream, and comparing our model against the closest equivalent methods, which currently are limited to the methods of Kleinberg [12] (which can only detect certain type of bursty events depending on parameter settings), Fung et al. [9], and Swan and Allan [18].",
                "Nevertheless, we believe our simple and effective method will be useful for all TDT practitioners, and will be especially useful for the initial exploratory analysis of news streams. 9.",
                "REFERENCES [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Google news alerts, http://www.google.com/alerts. [3] Reuters corpus, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan.",
                "Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, and H. Jin.",
                "First story detection in tdt is hard.",
                "In CIKM, pages 374-381, 2000. [6] J. Allan, C. Wade, and A. Bolivar.",
                "Retrieval and novelty detection at the sentence level.",
                "In SIGIR, pages 314-321, 2003. [7] T. Brants, F. Chen, and A. Farahat.",
                "A system for new event detection.",
                "In SIGIR, pages 330-337, 2003. [8] A. P. Dempster, N. M. Laird, and D. B. Rubin.",
                "Maximum likelihood from incomplete data via the EM algorithm.",
                "Journal of the Royal Statistical Society, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu, and H. Lu.",
                "Parameter free bursty events detection in text streams.",
                "In VLDB, pages 181-192, 2005. [10] Q.",
                "He, K. Chang, and E.-P. Lim.",
                "A model for anticipatory event detection.",
                "In ER, pages 168-181, 2006. [11] Q.",
                "He, K. Chang, E.-P. Lim, and J. Zhang.",
                "Bursty feature reprensentation for clustering text streams.",
                "In SDM, accepted, 2007. [12] J. Kleinberg.",
                "Bursty and hierarchical structure in streams.",
                "In SIGKDD, pages 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins.",
                "On the bursty evolution of blogspace.",
                "In WWW, pages 159-178, 2005. [14] G. Kumaran and J. Allan.",
                "Text classification and named entities for new event detection.",
                "In SIGIR, pages 297-304, 2004. [15] Q. Mei and C. Zhai.",
                "Discovering evolutionary theme patterns from text: an exploration of temporal text mining.",
                "In SIGKDD, pages 198-207, 2005. [16] W. D. Penny.",
                "Kullback-liebler divergences of normal, gamma, dirichlet and wishart densities.",
                "Technical report, 2001. [17] N. Stokes and J. Carthy.",
                "Combining semantic and syntactic document classifiers to improve first story detection.",
                "In SIGIR, pages 424-425, 2001. [18] R. Swan and J. Allan.",
                "Automatic generation of overview timelines.",
                "In SIGIR, pages 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena, and D. Gunopulos.",
                "Identifying similarities, periodicities and bursts for online search queries.",
                "In SIGMOD, pages 131-142, 2004. [20] Y. Yang, T. Pierce, and J. Carbonell.",
                "A study of retrospective and on-line event detection.",
                "In SIGIR, pages 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topic-conditioned novelty detection.",
                "In SIGKDD, pages 688-693, 2002.",
                "Table 1: All important aperiodic events (e1 − e17), top 5 less-reported aperiodic events (e18 − e22) and top 5 important periodic events (e23 − e27).",
                "Detected Event and Bursty Period Doc # True Event e1(Sali,Berisha,Albania,Albanian,March) 02/02/199705/29/1997 1409 Albanians president Sali Berisha lost in an early election and resigned, 12/1996-07/1997. e2(Seko,Mobutu,Sese,Kabila) 03/22/1997-06/09/1997 2273 Zaires president Mobutu Sese coordinated the native rebellion and failed on 05/16/1997. e3(Marxist,Peruvian) 11/19/1996-03/05/1997 824 Peru rebels (Tupac Amaru revolutionary Movement) led a hostage siege in Lima in early 1997. e4(Movement,Tupac,Amaru,Lima,hostage,hostages) 11/16/1996-03/20/1997 824 The same as e3. e5(Kinshasa,Kabila,Laurent,Congo) 03/26/199706/15/1997 1378 Zaire was renamed the Democratic Republic of Congo on 05/16/1997. e6(Jospin,Lionel,June) 05/10/1997-07/09/1997 605 Following the early General Elections circa 06/1997, Lionel Jospin was appointed Prime Minister on 06/02/1997. e7(Iraq,missile) 08/31/1996-09/13/1996 1262 U.S. fired missile at Iraq on 09/03/1996 and 09/04/1996. e8(Kurdish,Baghdad,Iraqi) 08/29/1996-09/09/1996 1132 Iraqi troop fought with Kurdish faction circa 09/1996. e9(May,Blair) 03/24/1997-07/04/1997 1049 Tony Blair became the Primary Minister of the United Kingdom on 05/02/1997. e10(slalom,skiing) 12/05/1996-03/21/1997 253 Slalom Game of Alpine Skiing in 01/1997-02/1997. e11(Interim,months) 09/24/1996-12/31/1996 3063 Tokyo released company interim results for the past several months in 09/1996-12/1996. e12(Dole,Bob) 09/09/1996-11/24/1996 1599 Dole Bob lost the 1996 US presidential election. e13(July,Sen) 06/25/1997-06/25/1997 344 Cambodias Prime Minister Hun Sen launched a bloody military coup in 07/1997. e14(Hebron) 10/15/1996-02/14/1997 2098 Hebron was divided into two sectors in early 1997. e15(April,Easter) 02/23/1997-05/04/1997 480 Easter feasts circa 04/1997 (for western and Orthodox). e16(Diluted,Group) 04/27/1997-07/20/1997 1888 Tokyo released all 96/97 group results in 04/199707/1997. e17(December,Christmas) 11/17/1996-01/26/1997 1326 Christmas feast in late 12/1997. e18(Kolaceva,winter,Together,promenades,Zajedno, Slobodan,Belgrade,Serbian,Serbia,Draskovic,municipal, Kragujevac) 1/25/1997 3 University students organized a vigil on Kolaceva street against government on 1/25/1997. e19(Tutsi,Luvengi,Burundi,Uvira,fuel,Banyamulenge, Burundian,Kivu,Kiliba,Runingo,Kagunga,Bwegera) 10/19/1996 6 Fresh fighting erupted around Uvira between Zaire armed forces and Banyamulengs Tutsi rebels on 10/19/1996. e20(Malantacchi,Korea,Guy,Rider,Unions,labour, Trade,unions,Confederation,rammed,Geneva,stoppages, Virgin,hire,Myongdong,Metalworkers) 1/11/1997 2 Marcello Malantacchi secretary general of the International Metalworkers Federation and Guy Rider who heads the Geneva office of the International Confederation of Free Trade Unions attacked the new labour law of South Korea on 1/11/1997. e21(DBS,Raﬄes) 8/17/1997 9 The list of the unit of Singapore DBS Land Raﬄes Holdings plans on 8/17/1997. e22(preserver,fuel,Galawa,Huddle,Leul,Beausse) 11/24/1996 3 Rescued a woman and her baby during a hijacked Ethiopian plane that ran out of fuel and crashed into the sea near Le Galawa beach on 11/24/1996. e23(PRICE,LISTING,MLN,MATURITY,COUPON, MOODY,AMT,FIRST,ISS,TYPE,PAY,BORROWER) Monday-Friday/week 7966 Announce bond price on all weekdays. e24(Unaudited,Ended,Months,Weighted,Provision,Cost, Selling,Revenues,Loss,Income,except,Shrs,Revs) every season 2264 Net income-loss reports released by companies in every season. e25(rating,Wall,Street,Ian) Monday-Friday/week 21767 Stock reports from Wall Street on all weekdays. e26(Sheffield,league,scoring,goals,striker,games) every Friday, Saturday and Sunday 574 Match results of Sheffield soccer league were published on Friday, Saturday and Sunday 10 times than other 4 days. e27(soccer,matches,Results,season,game,Cup,match, victory,beat,played,play,division) every Friday, Saturday and Sunday 2396 Soccer games held on Friday, Saturday and Sunday 7 times than other 4 days."
            ],
            "original_annotated_samples": [
                "Thus in this paper, we look at news stories and feature trends from the perspective of analyzing a time-series <br>word signal</br>."
            ],
            "translated_annotated_samples": [
                "Por lo tanto, en este artículo, examinamos noticias y tendencias de características desde la perspectiva de analizar una <br>señal de palabras</br> de series temporales."
            ],
            "translated_text": "Analizando Trayectorias de Características para la Detección de Eventos Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg Escuela de Ingeniería Informática Universidad Tecnológica de Nanyang Bloque N4, Avenida Nanyang, Singapur 639798 RESUMEN Consideramos el problema de analizar trayectorias de palabras en los dominios del tiempo y la frecuencia, con el objetivo específico de identificar palabras importantes y menos reportadas, periódicas y aperiódicas. Un conjunto de palabras con tendencias idénticas puede agruparse para reconstruir un evento de manera completamente no supervisada. La frecuencia del documento de cada palabra a lo largo del tiempo se trata como una serie temporal, donde cada elemento es el puntaje de frecuencia del documento - frecuencia inversa del documento (DFIDF) en un punto temporal. En este artículo, 1) primero aplicamos análisis espectral para categorizar características de diferentes tipos de eventos: importantes y poco reportados, periódicos y aperiódicos; 2) modelamos las características aperiódicas con densidad gaussiana y las características periódicas con densidades de mezcla gaussiana, y posteriormente detectamos cada ráfaga de características mediante el enfoque gaussiano truncado; 3) propusimos un algoritmo de detección de eventos codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos. Todos los métodos anteriores se pueden aplicar a datos de series temporales en general. Evaluamos exhaustivamente nuestros métodos en el Corpus de Noticias de Reuters de 1 año [3] y demostramos que fueron capaces de descubrir eventos significativos aperiódicos y periódicos. Categorías y Descriptores de Asignaturas: H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales: Algoritmos, Experimentación. 1. INTRODUCCIÓN Hay más de 4,000 fuentes de noticias en línea en el mundo. Supervisar manualmente todos ellos en busca de eventos importantes se ha vuelto difícil o prácticamente imposible. De hecho, la comunidad de detección y seguimiento de temas (TDT) ha estado tratando durante muchos años de encontrar una solución práctica para ayudar a las personas a monitorear las noticias de manera efectiva. Desafortunadamente, el Santo Grial sigue siendo esquivo, ya que la gran mayoría de las soluciones de TDT propuestas para la detección de eventos [20, 5, 17, 4, 21, 7, 14, 10] son demasiado simplistas (basadas en la similitud del coseno [5]) o impracticables debido a la necesidad de ajustar un gran número de parámetros [9]. La ineficacia de las tecnologías actuales de TDT se puede ilustrar fácilmente suscribiéndose a cualquiera de los muchos servicios de alertas de noticias en línea, como el líder de la industria Google News Alerts, que genera más del 50% de falsas alarmas. Como prueba adicional, portales como Yahoo adoptan un enfoque más pragmático al requerir que todas las alertas de noticias generadas por máquinas pasen por un operador humano para su confirmación antes de enviarlas a los suscriptores. En lugar de abordar el problema con variaciones del mismo martillo (similitud coseno y TFIDF), es necesario contar con una comprensión fundamental de las características de los datos de flujo de noticias antes de que se puedan lograr avances importantes en TDT. Por lo tanto, en este artículo, examinamos noticias y tendencias de características desde la perspectiva de analizar una <br>señal de palabras</br> de series temporales. Trabajos anteriores como [9] han intentado reconstruir un evento con sus características representativas. Sin embargo, en muchas tareas de detección de eventos predictivos (es decir, detección de eventos retrospectivos), hay un vasto conjunto de características potenciales solo para un conjunto fijo de observaciones (es decir, los estallidos obvios). De estas características, a menudo solo se espera que un pequeño número sea útil. En particular, estudiamos el novedoso problema de analizar trayectorias de características para la detección de eventos, utilizando una técnica conocida de procesamiento de señales: identificar correlaciones distribucionales entre todas las características mediante análisis espectral. Para evaluar nuestro método, posteriormente proponemos un algoritmo de detección de eventos no supervisado para flujos de noticias. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Pascua Abril (a) evento aperiódico 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 No auditado Finalizado (b) evento periódico Figura 1: Correlación de características (DFIDF:tiempo) entre a) Pascua y Abril b) No auditado y Finalizado. Como ejemplo ilustrativo, considera la correlación entre las palabras Pascua y abril del Corpus de Reuters. A partir del gráfico de su DFIDF normalizado en la Figura 1(a), observamos la gran superposición entre las dos palabras alrededor de 04/1997, lo que significa que probablemente ambas pertenecen al mismo evento durante ese tiempo (festividad de Pascua). En este ejemplo, el evento oculto de la festividad de Pascua es un evento aperiódico típico e importante en datos de 1 año. Otro ejemplo se muestra en la Figura 1(b), donde las palabras \"No auditado\" y \"Finalizado 1\" del Corpus de Reuters son el conjunto de datos predeterminado para todos los ejemplos y presentan un comportamiento similar durante períodos de 3 meses. Estas dos palabras en realidad se originaron a partir del mismo evento periódico, informes de ganancias y pérdidas, que son publicados trimestralmente por empresas cotizadas en bolsa. Otras observaciones extraídas de la Figura 1 son: 1) el período de actividad intensa de abril es mucho más largo que el de Semana Santa, lo que sugiere que abril puede estar presente en otros eventos durante el mismo período; 2) No auditado tiene un valor promedio de DFIDF más alto que Finalizado, lo que indica que No auditado es más representativo para el evento subyacente. Estos dos ejemplos son solo la punta del iceberg entre todas las tendencias de palabras y correlaciones ocultas en un flujo de noticias como Reuters. Si se puede descubrir un gran número de ellos, podría ayudar significativamente en las tareas de TDT. En particular, indica la importancia de extraer características correlacionadas para detectar eventos correspondientes. Para resumir, postulamos que: 1) Un evento se describe por sus características representativas. Un evento periódico tiene una lista de características periódicas y un evento aperiódico tiene una lista de características aperiódicas; 2) Las características representativas del mismo evento comparten distribuciones similares en el tiempo y están altamente correlacionadas; 3) Un evento importante tiene un conjunto de características representativas activas (ampliamente reportadas), mientras que un evento no importante tiene un conjunto de características representativas inactivas (menos reportadas); 4) Una característica puede ser incluida por varios eventos con superposiciones en los marcos de tiempo. Basándonos en estas observaciones, podemos extraer características representativas dadas un evento o detectar un evento a partir de una lista de características altamente correlacionadas. En este artículo, nos enfocamos en este último aspecto, es decir, cómo se pueden descubrir características correlacionadas para formar un evento de manera no supervisada. 1.1 Contribuciones Este artículo tiene tres contribuciones principales: • Hasta donde sabemos, nuestro enfoque es el primero en categorizar características de palabras para eventos heterogéneos. Específicamente, cada característica de palabra se clasifica en uno de los siguientes cinco tipos de características basados en la fuerza de su espectro de potencia y periodicidad: 1) HH (alta potencia y alta/larga periodicidad): eventos aperiódicos importantes, 2) HL (alta potencia y baja periodicidad): eventos periódicos importantes, 3) LH (baja potencia y alta periodicidad): eventos aperiódicos no importantes, 4) LL (baja potencia y baja periodicidad): no eventos, y 5) SW (palabras vacías), un subconjunto de LL con mayor potencia y periodicidad que comprende palabras vacías, que no contienen información. • Proponemos un enfoque simple y efectivo basado en densidad de mezcla para modelar y detectar ráfagas de características. • Presentamos un algoritmo de detección de eventos no supervisado para detectar eventos tanto aperiódicos como periódicos. Nuestro algoritmo ha sido evaluado en un flujo de noticias reales para demostrar su efectividad. 2. TRABAJO RELACIONADO Este trabajo está motivado en gran medida por una familia más amplia de problemas conocidos colectivamente como Detección y Seguimiento de Temas (TDT) [20, 5, 17, 4, 21, 7, 14, 10]. Además, la mayoría de las investigaciones de TDT hasta ahora se han centrado en agrupar/clasificar documentos en tipos de temas, identificar oraciones novedosas para eventos nuevos, etc., sin prestar mucha atención al análisis de la trayectoria de las palabras con respecto al tiempo. Swan y Allan [18] intentaron por primera vez usar términos que co-ocurren para construir un evento. Sin embargo, solo consideraron entidades nombradas y pares de frases nominales, sin tener en cuenta sus periodicidades. Por el contrario, nuestro artículo considera todo lo anterior. Recientemente, ha habido un gran interés en modelar un evento en flujos de texto como un estallido de actividades al incorporar información temporal. El trabajo seminal de Kleinberg describió cómo se pueden extraer características explosivas de flujos de texto utilizando un modelo de autómata infinito [12], lo que inspiró toda una serie de aplicaciones como la identificación de comunidades explosivas de Kumar a partir de gráficos de blogs [13], la sumarización de temas evolutivos en flujos de texto de Meis [15], el agrupamiento de flujos de texto utilizando características explosivas de Hes [11], etc. Sin embargo, ninguno de los trabajos existentes identificó específicamente características para eventos, excepto Fung et al. [9], quienes agruparon características llamativas para identificar varios eventos llamativos. Nuestro trabajo difiere de [9] en varias formas: 1) analizamos cada característica individual, no solo las características explosivas; 2) clasificamos las características a lo largo de dos dimensiones categóricas (periodicidad y potencia), dando en total cinco tipos de características principales; 3) no restringimos que cada característica pertenezca exclusivamente a un solo evento. Las técnicas de análisis espectral han sido utilizadas previamente por Vlachos et al. [19] para identificar periodicidades y ráfagas en los registros de consultas. Su enfoque estaba en detectar múltiples periodicidades a partir del gráfico del espectro de potencia, las cuales luego se utilizaron para indexar palabras para la búsqueda por ráfagas. En este artículo, utilizamos análisis espectral para clasificar las características de las palabras a lo largo de dos dimensiones, a saber, periodicidad y espectro de potencia, con el objetivo final de identificar eventos tanto periódicos como no periódicos y explosivos. 3. REPRESENTACIÓN DE DATOS Sea T la duración/período (en días) de un flujo de noticias, y F representa el espacio de características de palabras completo en el Modelo de Espacio Vectorial (VSM) estático clásico. 3.1 Clasificación de Periodicidad de Eventos Dentro de T, pueden existir ciertos eventos que ocurren solo una vez, por ejemplo, la elección de Tony Blair como Primer Ministro del Reino Unido, y otros eventos recurrentes de diversas periodicidades, por ejemplo, partidos de fútbol semanales. Por lo tanto, categorizamos todos los eventos en dos tipos: aperiódicos y periódicos, definidos de la siguiente manera. Definición 1. (Evento aperiódico) Un evento es aperiódico dentro de T si solo ocurre una vez. Definición 2. (Evento periódico) Si los eventos de un cierto género de eventos ocurren regularmente con una periodicidad fija P ≤ T/2, decimos que este género particular de eventos es periódico, y cada evento miembro se califica como un evento periódico. Ten en cuenta que la definición de aperiódico es relativa, es decir, es verdadera solo para un T dado y puede ser inválida para cualquier otro T > T. Por ejemplo, el evento de la fiesta de Navidad es aperiódico para T ≤ 365 pero periódico para T ≥ 730. 3.2 Características Representativas Intuitivamente, un evento puede ser descrito de manera muy concisa por unas pocas características de palabras discriminativas y representativas y viceversa, por ejemplo, huracán, barrido y golpe podrían ser características representativas de un evento del género de huracanes. Asimismo, un conjunto de características fuertemente correlacionadas podría ser utilizado para reconstruir una descripción de un evento, asumiendo que las características fuertemente correlacionadas son representativas. El vector de representación de una característica de palabra se define de la siguiente manera: Definición 3. (Trayectoria de la Característica) La trayectoria de una característica de palabra f puede escribirse como la secuencia yf = [yf (1), yf (2), . . . , yf (T)], donde cada elemento yf (t) es una medida de la característica f en el tiempo t, que podría definirse utilizando la puntuación normalizada DFIDF yf (t) = DFf (t) N(t) × log( N DFf ), donde DFf (t) es el número de documentos (DF local) que contienen la característica f en el día t, DFf es el número total de documentos (DF global) que contienen la característica f en T, N(t) es el número de documentos para el día t, y N es el número total de documentos en T. 4. En esta sección, mostramos cómo se pueden extraer características representativas para eventos (poco) importantes o (a)periódicos. 4.1 Análisis Espectral para el Período Dominante Dada una característica f, descomponemos su trayectoria de características yf = [yf (1), yf (2), ..., yf (T)] en la secuencia de T números complejos [X1, . . . , XT ] a través de la transformada discreta de Fourier (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. La DFT puede representar la serie temporal original como una combinación lineal de sinusoides complejas, lo cual se ilustra mediante la transformada discreta de Fourier inversa (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, donde el coeficiente de Fourier Xk denota la amplitud del sinusoides con frecuencia k/T. La trayectoria original puede ser reconstruida con solo las frecuencias dominantes, las cuales pueden ser determinadas a partir del espectro de potencia utilizando el popular estimador periodograma. El periodograma es una secuencia de la magnitud al cuadrado de los coeficientes de Fourier, Xk^2, k = 1, 2, . . . , T/2, que indica la potencia de la señal en la frecuencia k/T en el espectro. A partir del espectro de potencia, se elige el período dominante como el inverso de la frecuencia con el espectro de potencia más alto, de la siguiente manera. Definición 4. (Período Dominante) El período dominante (DP) de una característica dada f es Pf = T/ arg max k Xk 2. Por lo tanto, tenemos la Definición 5. (Espectro de Potencia Dominante) El espectro de potencia dominante (DPS) de una característica dada f es Sf = Xk 2 , con Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorización de Características El DPS de una trayectoria de características es un indicador fuerte de su actividad en la frecuencia especificada; cuanto mayor sea el DPS, es más probable que la característica sea explosiva. Al combinar DPS con DP, categorizamos todas las características en cuatro tipos: 2 Normalizamos yf (t) como yf (t) = yf (t)/ T i=1 yf (i) para que pueda interpretarse como una probabilidad. • HH: alta Sf, aperiódico o periódico a largo plazo (Pf > T/2); • HL: alta Sf, periódico a corto plazo (Pf ≤ T/2); • LH: baja Sf, aperiódico o periódico a largo plazo; • LL: baja Sf, periódico a corto plazo. La frontera entre los periodos a largo plazo y a corto plazo se establece en T/2. Sin embargo, distinguir entre un DPS alto y bajo no es sencillo, lo cual se abordará más adelante. Propiedades de diferentes conjuntos de características Para comprender mejor las propiedades de HH, HL, LH y LL, seleccionamos cuatro características, Navidad, fútbol, DBS y tu como ejemplos ilustrativos. Dado que la frontera entre el espectro de alta y baja potencia no está clara, estos ejemplos seleccionados tienen un rango relativo amplio de valores de espectro de potencia. La figura 2(a) muestra la trayectoria de DFIDF para la Navidad con un pico distintivo alrededor del día de Navidad. Para el conjunto de datos de Reuters de 1 año, la Navidad se clasifica como un evento aperiódico típico con Pf = 365 y Sf = 135.68, como se muestra en la Figura 2(b). Claramente, el valor de Sf = 135.68 es razonable para un evento conocido por ser intermitente como la Navidad. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Navidad(DFIDF:tiempo) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Navidad(S:frecuencia) Figura 2: Característica Navidad con un Sf relativamente alto y un Pf a largo plazo. La trayectoria de DFIDF para el fútbol se muestra en la Figura 3(a), de la cual podemos observar que hay un estallido regular cada 7 días, lo cual es nuevamente verificado por su valor calculado de Pf = 7, como se muestra en la Figura 3(b). Usando el conocimiento del dominio de que los partidos de fútbol tienen más encuentros cada sábado, lo que lo convierte en un evento periódico típico y ampliamente reportado, consideramos que el valor de Sf = 155.13 es alto. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) fútbol (DFIDF:tiempo) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) fútbol (S:frecuencia) Figura 3: Característica fútbol con un Sf relativamente alto y un Pf a corto plazo. A partir de la trayectoria de DFIDF para DBS en la Figura 4(a), podemos deducir de inmediato que DBS es una palabra poco frecuente con un aumento trivial el 17/08/1997 correspondiente a los planes de DBS Land Raﬄes Holdings. Esto se confirma por el largo período de Pf = 365 y la baja potencia de Sf = 0.3084 como se muestra en la Figura 4(b). Además, dado que este evento aperiódico solo se informa en algunas noticias durante un corto período de unos pocos días, por lo tanto, decimos que su bajo valor de potencia de Sf = 0.3084 es representativo de eventos poco importantes. El ejemplo más confuso se muestra en la Figura 5 para la palabra \"your\", que se ve muy similar al gráfico para fútbol en la Figura 3. A primera vista, podríamos sentirnos tentados a agrupar tanto tu como el fútbol en la misma categoría de HL o LL, ya que ambas distribuciones se ven similares y tienen el mismo período dominante de aproximadamente una semana. Sin embargo, más adelante 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:tiempo) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frecuencia) Figura 4: Característica DBS con Sf relativamente bajo y Pf a largo plazo. El análisis indica que la periodicidad de su es debido a las diferencias en el recuento de documentos para los días de la semana (promedio de 2,919 por día) y los fines de semana (promedio de 479 por día). Uno habría esperado que la periodicidad de una palabra vacía como \"tu\" fuera de un día. Además, a pesar de nuestra normalización de DFIDF, el desequilibrio entre los días de la semana y los fines de semana aún prevalecía; las palabras vacías ocurren 4 veces más frecuentemente los fines de semana que los días de semana. Por lo tanto, el DPS sigue siendo el único factor distintivo entre tu (Sf = 9.42) y el fútbol (Sf = 155.13). Sin embargo, es muy peligroso concluir simplemente que un valor de potencia de S = 9.42 corresponde a una característica de palabra vacía. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) tu(DFIDF:tiempo) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) tu(S:frecuencia) Figura 5: Característica tu como un ejemplo confundido con la característica fútbol. Antes de presentar nuestra solución a este problema, veamos otro ejemplo de LL como se muestra en la Figura 6 para beenb, que en realidad es un error tipográfico confirmado. Por lo tanto, clasificamos beenb como una característica ruidosa que no contribuye a ningún evento. Claramente, la trayectoria de tu es muy diferente de beenb, lo que significa que el primero debe considerarse por separado. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figura 6: Característica beenb con Sf relativamente bajo y Pf a corto plazo. Conjunto de características de palabras vacías (SW) Basándonos en el análisis anterior, nos damos cuenta de que debe haber otro conjunto de características entre HL y LL que corresponda al conjunto de palabras vacías. Las características de este conjunto tienen un DPS moderado y un período dominante bajo pero conocido. Dado que es difícil distinguir este conjunto de características de HL y LL solo basándose en DPS, introducimos otro factor llamado promedio de DFIDF (DFIDF). Como se muestra en la Figura 5, características como la tuya suelen tener un DPS más bajo que una característica HL como el fútbol, pero tienen un DFIDF mucho más alto que otra característica ruidosa LL como \"beenb\". Dado que tales propiedades suelen ser características de las palabras vacías, agrupamos características como \"tu\" en el conjunto de características de palabras vacías (SW) recién definido. Dado que establecer los umbrales de DPS y DFIDF para identificar las palabras vacías es más un arte que una ciencia, propusimos un algoritmo heurístico HS, Algoritmo 1. La idea básica es utilizar solo noticias de días laborables para identificar palabras vacías. Los fines de semana aquí también incluyen días festivos que caen en días laborables. El conjunto SW se inicialmente alimenta con un pequeño conjunto de 29 stopwords populares utilizadas por el motor de búsqueda de Google. Algoritmo 1 Detección heurística de palabras vacías (HS) Entrada: Conjunto de palabras vacías semilla, trayectorias semanales de todas las palabras 1: A partir del conjunto semilla SW, calcular el DPS máximo como UDPS, el DFIDF máximo como UDFIDF y el mínimo de DFIDF como LDFIDF. 2: para fi ∈ F hacer 3: Calcular DFT para fi. 4: si Sfi ≤ UDPS y DFIDFfi ∈ [LDFIDF, UDFIDF] entonces 5: fi → SW 6: F = F - fi 7: fin si 8: fin para Resumen de la Categorización de Características Después de generar el conjunto SW, se eliminan todas las palabras vacías de F. Luego, establecemos el límite entre DPS alto y bajo como el límite superior de los DPS de los conjuntos SW. Una visión general de los cinco conjuntos de características se muestra en la Figura 7. Figura 7: Los 5 conjuntos de características para eventos. 5. IDENTIFICACIÓN DE RÁFAGAS PARA CARACTERÍSTICAS Dado que solo las características de HH, HL y LH son significativas y podrían ser representativas de algunos eventos, eliminamos todas las demás características clasificadas como LL o SW. En esta sección, describimos cómo se pueden identificar los estallidos a partir de las características restantes. A diferencia del algoritmo de identificación de ráfagas de Kleinberg [12], podemos identificar tanto ráfagas significativas como triviales sin necesidad de establecer ningún parámetro. 5.1 Detección de ráfagas de características aperiódicas Para cada característica en HH y HL, truncamos su trayectoria manteniendo solo el período de ráfagas, el cual está modelado con una distribución gaussiana. Por ejemplo, la Figura 8 muestra la característica de la palabra Iraq con una explosión alrededor del 09/06/1996 modelada como una Gaussiana. Su período de ráfagas está definido por [μf − σf , μf + σf ] como se muestra en la Figura 8(b). 5.2 Detección de características periódicas de ráfagas Dado que hemos calculado el DP para una característica periódica f, podemos modelar fácilmente su trayectoria de características periódicas yf usando 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) DFIDF original: tiempo 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 ráfaga= [μ-σ, μ+σ] (b) identificación de ráfaga Figura 8: Modelando la serie temporal de Iraq como una Gaussiana truncada con μ = 09/06/1996 y σ = 6.26. una mezcla de K = T/Pf Gaussianas: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , donde el conjunto de parámetros θf = {αk, μk, σk}K k=1 comprende: • αk es la probabilidad de asignar yf a la k-ésima Gaussiana. αk > 0, ∀k ∈ [1, K] y K k=1 αk = 1; • μk/σk es la media/desviación estándar de la k-ésima Gaussiana. El conocido algoritmo Expectation Maximization (EM) [8] se utiliza para calcular las proporciones de mezcla αk, así como los parámetros individuales de densidad gaussiana μk y σK. Cada Gaussiana representa un evento periódico, y se modela de manera similar como se menciona en la Sección 5.1. 6. EVENTOS A PARTIR DE CARACTERÍSTICAS Después de identificar y modelar ráfagas para todas las características, la siguiente tarea es pintar un cuadro del evento con un posible conjunto de características representativas. 6.1 Correlación de Características Si dos características fi y fj son representativas del mismo evento, deben cumplir las siguientes condiciones necesarias: 1. fi y fj están distribuidas de manera idéntica: yfi ∼ yfj. 2. fi y fj tienen una alta superposición de documentos. Medición de la similitud de la distribución de características. Medimos la similitud entre dos características fi y fj utilizando la divergencia KL discreta definida de la siguiente manera. Definición 6. (similitud de características) KL(fi, fj) se da por max(KL(fi|fj), KL(fj|fi)), donde KL(fi|fj) = T t=1 f(yfi(t)|θfi)log f(yfi(t)|θfi) f(yfj(t)|θfj). (1) Dado que la divergencia KL no es simétrica, definimos la similitud entre fi y fj como el máximo entre KL(fi|fj) y KL(fj|fi). Además, la similitud entre dos características aperiódicas puede calcularse utilizando una forma cerrada de la divergencia de Kullback-Leibler [16]. La misma fórmula discreta de divergencia KL de la Ecuación 1 se emplea para calcular la similitud entre dos características periódicas. A continuación, definimos la similitud general entre un conjunto de características R utilizando el valor máximo de divergencia KL entre características como sigue. Definición 7. (similitud de conjuntos) KL(R) = max ∀fi, fj ∈R KL(fi, fj). Superposición de documentos: Sea Mi el conjunto de todos los documentos que contienen la característica fi. Dadas dos características fi y fj, el conjunto de documentos superpuestos que contienen ambas características es Mi ∩ Mj. De manera intuitiva, cuanto mayor sea |Mi ∩ Mj|, es más probable que fi y fj estén altamente correlacionados. Definimos el grado de superposición de documentos entre dos características fi y fj de la siguiente manera. Definición 8. (Superposición de características DF) d(fi, fj) = |Mi∩Mj| min(|Mi|, |Mj|). En consecuencia, la superposición de DF entre un conjunto de características R también está definida. Definición 9. (Superposición de Conjuntos DF) d(R) = min ∀fi, fj ∈R d(fi, fj). 6.2 Detección de Eventos Codiciosa No Supervisada Utilizamos características de HH para detectar eventos aperiódicos importantes, características de LH para detectar eventos aperiódicos menos reportados/poco importantes, y características de HL para detectar eventos periódicos. Todos comparten el mismo algoritmo. Dado el rasgo explosivo fi ∈ HH, el objetivo es encontrar rasgos altamente correlacionados de HH. El conjunto de características similares a fi puede describir colectivamente un evento. Específicamente, necesitamos encontrar un subconjunto Ri de HH que minimice la siguiente función de costo: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) El evento subyacente e (asociado con la explosión de fi) puede ser representado por Ri como y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) El análisis de la explosión para el evento e es exactamente el mismo que la trayectoria de características. El costo en la Ecuación 2 se puede minimizar utilizando nuestro algoritmo de detección de eventos UG codicioso no supervisado, que se describe en el Algoritmo 2. El algoritmo UG permite una característica Algoritmo 2 Detección de eventos codiciosos no supervisados (UG). Salida: ek como Ec. 3. Además, los eventos triviales que solo contienen características de año/mes (es decir, un evento que solo contiene una característica de agosto podría ser identificado en un flujo de noticias de 1 año) podrían ser eliminados, aunque dichos eventos tendrán un costo inherente alto y deberían estar clasificados muy bajos. Tenga en cuenta que nuestro algoritmo UG solo requiere un parámetro dependiente de los datos, el límite entre el espectro de alta y baja potencia, que debe establecerse una vez, y este parámetro puede estimarse fácilmente utilizando el algoritmo HS (Algoritmo 1). 7. EXPERIMENTOS En esta sección, estudiamos el rendimiento de nuestro método de categorización de características y algoritmo de detección de eventos. Primero presentamos el conjunto de datos y la configuración experimental, luego evaluamos subjetivamente la categorización de características para HH, HL, LH, LL y SW. Finalmente, estudiamos el problema de detección de eventos (a)periódicos con el Algoritmo 2. 7.1. Conjunto de datos y configuración experimental El Corpus de Reuters contiene 806,791 noticias en inglés desde el 20/08/1996 hasta el 19/08/1997 con una resolución diaria. La versión 2 del software de código abierto Lucene [1] se utilizó para tokenizar el contenido de texto de noticias y generar el vector documento-palabra. Con el fin de preservar los tiempos verbales pasados/presentes/futuros sensibles al tiempo y las diferencias entre los sustantivos en minúscula y las entidades nombradas en mayúscula, no se realizó ningún truncamiento. Dado que la eliminación dinámica de palabras vacías es una de las funcionalidades de nuestro método, no se eliminó ninguna palabra vacía. Eliminamos los caracteres no ingleses, sin embargo, después de eso, el número de características de palabras asciende a 423,433. Todos los experimentos se implementaron en Java y se llevaron a cabo en una PC Pentium 4 de 3.2 GHz con Windows 2003 Server y 1 GB de memoria. 7.2 Categorización de características Descargamos 34 stopwords bien conocidos utilizados por el motor de búsqueda de Google como nuestras características de entrenamiento iniciales, que incluyen a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en y www. Excluimos las últimas cinco palabras vacías ya que son poco comunes en noticias. Al analizar solo historias de noticias durante 259 días laborables, calculamos el límite superior del espectro de potencia para las palabras vacías en 11.18 y los rangos correspondientes de DFIDF van desde 0.1182 hasta 0.3691. Cualquier característica f que cumpla con Sf <= 11.18 y 0.1182 <= DFIDFf <= 0.3691 durante los días de la semana se considerará una palabra vacía. De esta manera, se encontraron y eliminaron 470 palabras vacías como se muestra en la Figura 9. Algunas palabras vacías detectadas son A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) y much (P = 22, S = 0.80, DFIDF = 0.1865). Después de la eliminación de estas palabras vacías, la distribución de las noticias entre semana y los fines de semana están más o menos equilibradas, y en los experimentos subsiguientes, haremos uso del corpus completo (entre semana y fines de semana). El valor del espectro de potencia límite superior de 11.18 para el entrenamiento de palabras vacías fue seleccionado como el límite entre el espectro de alta potencia y baja potencia. El límite entre alta y baja periodicidad se estableció en 365/2 = 183. Todos los 422,963 (423433 − 470) rasgos de palabras fueron categorizados en 4 conjuntos de rasgos: HH (69 rasgos), HL (1,087 rasgos), LH (83,471 rasgos) y LL (338,806 rasgos) como se muestra en la Figura 10. En la Figura 10, cada nivel de gris denota la densidad relativa de características en una región cuadrada, medida por log10(1 + Dk), donde Dk es el número de características dentro de la k-ésima región cuadrada. A partir de la figura, podemos hacer el 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figura 9: Distribución de SW (palabras vacías) en las regiones HH, HL, LH y LL. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figura 10: Distribución de características categorizadas en los cuatro cuadrantes (sombreado en escala logarítmica). siguientes observaciones: 1. La mayoría de las características tienen un valor bajo de S y son fácilmente distinguibles de aquellas características que tienen un valor mucho más alto de S, lo que nos permite detectar eventos importantes (a)periódicos de eventos triviales seleccionando características con un alto valor de S. 2. Las características en los cuadrantes HH y LH son aperiódicas, las cuales están bien separadas (gran brecha horizontal) de las características periódicas. Esto permite detectar de manera confiable eventos aperiódicos y eventos periódicos de forma independiente. 3. La frontera (vertical) entre el espectro de alta y baja potencia no es tan clara y el valor exacto dependerá de la aplicación específica. Al revisar la distribución de dispersión de las características de SW en HH, HL, LH y LL como se muestra en la Figura 9, encontramos que el 87.02% (409/470) de las stopwords detectadas se originaron en LL. La clasificación LL y las altas puntuaciones de DFIDF de las palabras vacías concuerdan con la noción generalmente aceptada de que las palabras vacías son igualmente frecuentes en todo momento. Por lo tanto, establecer el límite entre el espectro de alta y baja potencia utilizando el límite superior Sf de SW es una heurística razonable. 7.3 Detección de Eventos Aperiódicos Evaluaremos nuestras dos hipótesis, 1)los eventos aperiódicos importantes pueden ser definidos por un conjunto de características HH, y 2)los eventos aperiódicos menos reportados pueden ser definidos por un conjunto de características LH. Dado que no existen flujos de noticias de referencia para la detección de eventos (los conjuntos de datos de TDT no son flujos adecuados), evaluamos la calidad de los eventos detectados automáticamente comparándolos con eventos confirmados manualmente mediante la búsqueda en el corpus. Entre las 69 características de HH, detectamos 17 eventos aperiódicos importantes como se muestra en la Tabla 1 (e1 - e17). Ten en cuenta que toda la identificación tomó menos de 1 segundo, después de eliminar los eventos que solo contenían la característica del mes. De los 17 eventos, aparte de las superposiciones entre e3 y e4 (ambos describen el mismo evento de rehenes), e11 y e16 (ambos sobre informes de empresas), los 14 eventos identificados son extremadamente precisos y corresponden muy bien a los principales eventos del período. Por ejemplo, la derrota de Bob Dole, la elección de Tony Blair, el ataque con misiles a Iraq, etc. Recuerde que seleccionar las características para un evento debería minimizar el costo en la Ecuación 2 de tal manera que 1) el número de características abarque diferentes eventos, y 2) no se seleccionarán todas las características relevantes para un evento, por ejemplo, la característica Clinton es representativa para e12, pero dado que Clinton se relaciona con muchos otros eventos, su señal de dominio temporal es muy diferente de la de otras características representativas como Dole y Bob. El número de documentos de un evento detectado se estima aproximadamente por el número de documentos indexados que contienen las características representativas. Podemos ver que los 17 eventos aperiódicos importantes son eventos reportados popularmente. Después de 742 minutos de tiempo de computación, detectamos 23,525 eventos aperiódicos menos reportados de 83,471 características de LH. La Tabla 1 enumera los 5 principales eventos aperiódicos detectados (e18 - e22) con respecto al costo. Descubrimos que estos 5 eventos son en realidad eventos muy triviales con solo unos pocos informes de noticias, y suelen ser englobados por algunos temas más grandes. Por ejemplo, e22 es uno de los eventos de rescate en un tema de secuestro de avión. Una ventaja de nuestro Algoritmo UG para descubrir eventos aperiódicos poco reportados es que podemos detectar con precisión el verdadero período del evento. 7.4 Detección de Eventos Periódicos Entre las 1,087 características de HL, se detectaron 330 eventos periódicos importantes en un tiempo de cálculo de 10 minutos. La Tabla 1 enumera los 5 eventos periódicos detectados con respecto al costo (e23 - e27). Todos los eventos periódicos detectados son realmente válidos y corresponden a eventos periódicos de la vida real. El modelo GMM es capaz de detectar y estimar el período de ráfagas de manera precisa, aunque no puede distinguir la ligera diferencia entre cada lunes a viernes y todos los días de la semana, como se muestra en e23. También observamos que e26 es en realidad un subconjunto de e27 (partido de fútbol), lo cual es aceptable ya que los resultados de la liga de Sheffield se anuncian de forma independiente cada fin de semana. 8. CONCLUSIONES Este artículo adoptó una perspectiva completamente nueva para analizar las trayectorias de características como señales en el dominio del tiempo. Al considerar las frecuencias de los documentos en el dominio del tiempo y de la frecuencia, pudimos derivar muchas nuevas características sobre los flujos de noticias que antes eran desconocidas, por ejemplo, las diferentes distribuciones de palabras vacías durante los días de la semana y los fines de semana. Por primera vez en el área de TDT, aplicamos un enfoque sistemático para detectar automáticamente eventos importantes y menos reportados, periódicos y aperiódicos. La idea clave de nuestro trabajo radica en las observaciones de que los eventos periódicos tienen características representativas periódicas y los eventos (in)importantes tienen características representativas (in)activas, diferenciadas por sus espectros de potencia y períodos de tiempo. Para abordar el problema de detección de eventos reales, se utilizó un enfoque basado en densidad de mezcla simple y efectivo para identificar ráfagas de características y sus períodos asociados de ráfagas. También diseñamos un algoritmo codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos, el cual tuvo éxito en detectar eventos reales como se muestra en la evaluación en un flujo de noticias reales. Aunque no hemos realizado ninguna comparación de referencia con otro enfoque, simplemente porque no hay trabajos previos en el problema abordado. El trabajo futuro incluye evaluar la recuperación de eventos detectados en un flujo de noticias etiquetado, y comparar nuestro modelo con los métodos equivalentes más cercanos, que actualmente se limitan a los métodos de Kleinberg [12] (que solo pueden detectar ciertos tipos de eventos explosivos dependiendo de la configuración de parámetros), Fung et al. [9], y Swan y Allan [18]. Sin embargo, creemos que nuestro método simple y efectivo será útil para todos los practicantes de TDT, y será especialmente útil para el análisis exploratorio inicial de flujos de noticias. REFERENCIAS [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Alertas de noticias de Google, http://www.google.com/alerts. [3] Corpus de Reuters, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan. Detección y seguimiento de temas. Organización de la información basada en eventos. Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, y H. Jin. La detección de la primera historia en tdt es difícil. En CIKM, páginas 374-381, 2000. [6] J. Allan, C. Wade y A. Bolivar. Recuperación y detección de novedades a nivel de oración. En SIGIR, páginas 314-321, 2003. [7] T. Brants, F. Chen y A. Farahat. Un sistema para la detección de nuevos eventos. En SIGIR, páginas 330-337, 2003. [8] A. P. Dempster, N. M. Laird y D. B. Rubin. Máxima verosimilitud a partir de datos incompletos a través del algoritmo EM. Revista de la Real Sociedad Estadística, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu y H. Lu. Detección de eventos explosivos sin parámetros en flujos de texto. En VLDB, páginas 181-192, 2005. [10] Q. Él, K. Chang y E.-P. Lim. Un modelo para la detección anticipada de eventos. En ER, páginas 168-181, 2006. [11] Q. Él, K. Chang, E.-P. Lim y J. Zhang. Representación de características intermitentes para la agrupación de flujos de texto. En SDM, aceptado, 2007. [12] J. Kleinberg. Estructura explosiva y jerárquica en arroyos. En SIGKDD, páginas 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan y A. Tomkins. Sobre la evolución explosiva del blogosfera. En WWW, páginas 159-178, 2005. [14] G. Kumaran y J. Allan. Clasificación de texto y entidades nombradas para la detección de nuevos eventos. En SIGIR, páginas 297-304, 2004. [15] Q. Mei y C. Zhai. Descubriendo patrones temáticos evolutivos a partir de texto: una exploración de la minería de texto temporal. En SIGKDD, páginas 198-207, 2005. [16] W. D. Penny. Divergencias de Kullback-Leibler de densidades normales, gamma, dirichlet y wishart. Informe técnico, 2001. [17] N. Stokes y J. Carthy. Combinando clasificadores de documentos semánticos y sintácticos para mejorar la detección de la primera noticia. En SIGIR, páginas 424-425, 2001. [18] R. Swan y J. Allan. Generación automática de líneas de tiempo de resumen. En SIGIR, páginas 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena y D. Gunopulos. Identificando similitudes, periodicidades y ráfagas en las consultas de búsqueda en línea. En SIGMOD, páginas 131-142, 2004. [20] Y. Yang, T. Pierce y J. Carbonell. Un estudio de detección de eventos retrospectivos y en línea. En SIGIR, páginas 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell y C. Jin. Detección de novedades condicionada por el tema. En SIGKDD, páginas 688-693, 2002. Tabla 1: Todos los eventos aperiódicos importantes (e1 - e17), los 5 eventos aperiódicos menos reportados (e18 - e22) y los 5 eventos periódicos importantes (e23 - e27). Evento detectado y período de actividad intensa Doc # Verdadero evento e1 (Sali, Berisha, Albania, albanés, marzo) 02/02/199705/29/1997 1409 El presidente albanés Sali Berisha perdió en una elección temprana y renunció, 12/1996-07/1997. e2 (Seko, Mobutu, Sese, Kabila) 03/22/1997-06/09/1997 2273 El presidente de Zaire, Mobutu Sese, coordinó la rebelión nativa y fracasó el 16/05/1997. e3 (Marxista, peruano) 11/19/1996-03/05/1997 824 Los rebeldes de Perú (Movimiento Revolucionario Tupac Amaru) lideraron un asedio de rehenes en Lima a principios de 1997. e4 (Movimiento, Tupac, Amaru, Lima, rehén, rehenes) 11/16/1996-03/20/1997 824 Lo mismo que e3. e5 (Kinshasa, Kabila, Laurent, Congo) 03/26/199706/15/1997 1378 Zaire fue renombrado República Democrática del Congo el 16/05/1997. e6 (Jospin, Lionel, junio) 05/10/1997-07/09/1997 605 Tras las elecciones generales tempranas alrededor de 06/1997, Lionel Jospin fue nombrado Primer Ministro el 02/06/1997. e7 (Irak, misil) 08/31/1996-09/13/1996 1262 EE. UU. disparó un misil a Irak el 03/09/1996 y el 04/09/1996. e8 (kurdo, Bagdad, iraquí) 08/29/1996-09/09/1996 1132 Tropas iraquíes lucharon con facciones kurdas alrededor de 09/1996. e9 (mayo, Blair) 03/24/1997-07/04/1997 1049 Tony Blair se convirtió en el Primer Ministro del Reino Unido el 02/05/1997. e10 (slalom, esquí) 12/05/1996-03/21/1997 253 Juego de eslalon de esquí alpino en 01/1997-02/1997. e11 (Interino, meses) 09/24/1996-12/31/1996 3063 Tokio publicó los resultados interinos de la empresa para los últimos meses en 09/1996-12/1996. e12 (Dole, Bob) 09/09/1996-11/24/1996 1599 Bob Dole perdió las elecciones presidenciales de EE. UU. de 1996. e13 (julio, Sen) 06/25/1997-06/25/1997 344 El Primer Ministro de Camboya, Hun Sen, lanzó un sangriento golpe militar en 07/1997. e14 (Hebrón) 10/15/1996-02/14/1997 2098 Hebrón fue dividida en dos sectores a principios de 1997. e15 (abril, Pascua) 02/23/1997-05/04/1997 480 Festividades de Pascua alrededor de 04/1997 (para occidentales y ortodoxos). e16 (Diluido, Grupo) 04/27/1997-07/20/1997 1888 Tokio publicó todos los resultados del grupo 96/97 en 04/199707/1997. e17 (diciembre, Navidad) 11/17/1996-01/26/1997 1326 Festín de Navidad a finales de 12/1997. e18 (Kolaceva, invierno, Juntos, paseos, Zajedno, Slobodan, Belgrado, serbio, Serbia, Draskovic, municipal, Kragujevac) 1/25/1997 3 Estudiantes universitarios organizaron una vigilia en la calle Kolaceva contra el gobierno el 25/01/1997. e19 (Tutsi, Luvengi, Burundi, Uvira, combustible, Banyamulenge, burundés, Kivu, Kiliba, Runingo, Kagunga, Bwegera) 10/19/1996 6 Estallaron nuevos enfrentamientos alrededor de Uvira entre las fuerzas armadas de Zaire y los rebeldes Tutsi de Banyamulenge el 19/10/1996. e20 (Malantacchi, Corea, Guy, Rider, Sindicatos, trabajo, Confederación, embestido, Ginebra, paradas, Virgin, contratar, Myongdong, Metalúrgicos) 1/11/1997 2 Marcello Malantacchi, secretario general de la Federación Internacional de Metalúrgicos, y Guy Rider, quien dirige la oficina de Ginebra de la Confederación Internacional de Sindicatos Libres, atacaron la nueva ley laboral de Corea del Sur el 11/01/1997. e21 (DBS, Raﬄes) 8/17/1997 9 La lista de la unidad de DBS Land Raﬄes Holdings de Singapur planea el 17/08/1997. e22 (conservador, combustible, Galawa, Huddle, Leul, Beausse) 11/24/1996 3 Rescataron a una mujer y a su bebé durante un secuestro de un avión etíope que se quedó sin combustible y se estrelló en el mar cerca de la playa Le Galawa el 24/11/1996. e23 (PRECIO, LISTADO, MLN, VENCIMIENTO, CUPÓN, MOODY, MONTO, PRIMERO, ISS, TIPO, PAGO, PRESTAMISTA) Lunes a viernes/semana 7966 Anuncian el precio de los bonos todos los días de la semana. e24 (No auditado, Terminado, Meses, Ponderado, Provisión, Costo, Venta, Ingresos, Pérdida, Ingreso, excepto, Shrs, Revs) cada temporada 2264 Informes de ingresos netos-pérdidas publicados por empresas en cada temporada. e25 (calificación, Wall Street, Ian) Lunes a viernes/semana 21767 Informes de acciones de Wall Street todos los días de la semana. e26 (Sheffield, liga, goles de puntuación, delantero, juegos) cada viernes, sábado y domingo 574 Resultados de partidos de la liga de fútbol de Sheffield publicados los viernes, sábados y domingos 10 veces más que en los otros 4 días. e27 (fútbol, partidos, Resultados, temporada, juego, Copa, partido, victoria, vencer, jugado, jugar, división) cada viernes, sábado y domingo 2396 Juegos de fútbol celebrados los viernes, sábados y domingos 7 veces más que en los otros 4 días. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "spectral analysis": {
            "translated_key": "análisis espectral",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Analyzing Feature Trajectories for Event Detection Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg School of Computer Engineering Nanyang Technological University Block N4, Nanyang Avenue, Singapore 639798 ABSTRACT We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words.",
                "A set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner.",
                "The document frequency of each word across time is treated like a time series, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point.",
                "In this paper, we 1) first applied <br>spectral analysis</br> to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events.",
                "All of the above methods can be applied to time series data in general.",
                "We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events.",
                "Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Experimentation. 1.",
                "INTRODUCTION There are more than 4,000 online news sources in the world.",
                "Manually monitoring all of them for important events has become difficult or practically impossible.",
                "In fact, the topic detection and tracking (TDT) community has for many years been trying to come up with a practical solution to help people monitor news effectively.",
                "Unfortunately, the holy grail is still elusive, because the vast majority of TDT solutions proposed for event detection [20, 5, 17, 4, 21, 7, 14, 10] are either too simplistic (based on cosine similarity [5]) or impractical due to the need to tune a large number of parameters [9].",
                "The ineffectiveness of current TDT technologies can be easily illustrated by subscribing to any of the many online news alerts services such as the industryleading Google News Alerts [2], which generates more than 50% false alarms [10].",
                "As further proof, portals like Yahoo take a more pragmatic approach by requiring all machine generated news alerts to go through a human operator for confirmation before sending them out to subscribers.",
                "Instead of attacking the problem with variations of the same hammer (cosine similarity and TFIDF), a fundamental understanding of the characteristics of news stream data is necessary before any major breakthroughs can be made in TDT.",
                "Thus in this paper, we look at news stories and feature trends from the perspective of analyzing a time-series word signal.",
                "Previous work like [9] has attempted to reconstruct an event with its representative features.",
                "However, in many predictive event detection tasks (i.e., retrospective event detection), there is a vast set of potential features only for a fixed set of observations (i.e., the obvious bursts).",
                "Of these features, often only a small number are expected to be useful.",
                "In particular, we study the novel problem of analyzing feature trajectories for event detection, borrowing a well-known technique from signal processing: identifying distributional correlations among all features by <br>spectral analysis</br>.",
                "To evaluate our method, we subsequently propose an unsupervised event detection algorithm for news streams. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Easter April (a) aperiodic event 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Unaudited Ended (b) periodic event Figure 1: Feature correlation (DFIDF:time) between a) Easter and April b) Unaudited and Ended.",
                "As an illustrative example, consider the correlation between the words Easter and April from the Reuters Corpus1 .",
                "From the plot of their normalized DFIDF in Figure 1(a), we observe the heavy overlap between the two words circa 04/1997, which means they probably both belong to the same event during that time (Easter feast).",
                "In this example, the hidden event Easter feast is a typical important aperiodic event over 1-year data.",
                "Another example is given by Figure 1(b), where both the words Unaudited and Ended 1 Reuters Corpus is the default dataset for all examples. exhibit similar behaviour over periods of 3 months.",
                "These two words actually originated from the same periodic event, net income-loss reports, which are released quarterly by publicly listed companies.",
                "Other observations drawn from Figure 1 are: 1) the bursty period of April is much longer than Easter, which suggests that April may exist in other events during the same period; 2) Unaudited has a higher average DFIDF value than Ended, which indicates Unaudited to be more representative for the underlying event.",
                "These two examples are but the tip of the iceberg among all word trends and correlations hidden in a news stream like Reuters.",
                "If a large number of them can be uncovered, it could significantly aid TDT tasks.",
                "In particular, it indicates the significance of mining correlating features for detecting corresponding events.",
                "To summarize, we postulate that: 1) An event is described by its representative features.",
                "A periodic event has a list of periodic features and an aperiodic event has a list of aperiodic features; 2) Representative features from the same event share similar distributions over time and are highly correlated; 3) An important event has a set of active (largely reported) representative features, whereas an unimportant event has a set of inactive (less-reported) representative features; 4) A feature may be included by several events with overlaps in time frames.",
                "Based on these observations, we can either mine representative features given an event or detect an event from a list of highly correlated features.",
                "In this paper, we focus on the latter, i.e., how correlated features can be uncovered to form an event in an unsupervised manner. 1.1 Contributions This paper has three main contributions: • To the best of our knowledge, our approach is the first to categorize word features for heterogenous events.",
                "Specifically, every word feature is categorized into one of the following five feature types based on its power spectrum strength and periodicity: 1) HH (high power and high/long periodicity): important aperiodic events, 2) HL (high power and low periodicity): important periodic events, 3) LH (low power and high periodicity): unimportant aperiodic events, 4) LL (low power and low periodicity): non-events, and 5) SW (stopwords), a higher power and periodicity subset of LL comprising stopwords, which contains no information. • We propose a simple and effective mixture densitybased approach to model and detect feature bursts. • We come up with an unsupervised event detection algorithm to detect both aperiodic and periodic events.",
                "Our algorithm has been evaluated on a real news stream to show its effectiveness. 2.",
                "RELATED WORK This work is largely motivated by a broader family of problems collectively known as Topic Detection and Tracking (TDT) [20, 5, 17, 4, 21, 7, 14, 10].",
                "Moreover, most TDT research so far has been concerned with clustering/classifying documents into topic types, identifying novel sentences [6] for new events, etc., without much regard to analyzing the word trajectory with respect to time.",
                "Swan and Allan [18] first attempted using co-occuring terms to construct an event.",
                "However, they only considered named entities and noun phrase pairs, without considering their periodicities.",
                "On the contrary, our paper considers all of the above.",
                "Recently, there has been significant interest in modeling an event in text streams as a burst of activities by incorporating temporal information.",
                "Kleinbergs seminal work described how bursty features can be extracted from text streams using an infinite automaton model [12], which inspired a whole series of applications such as Kumars identification of bursty communities from Weblog graphs [13], Meis summarization of evolutionary themes in text streams [15], Hes clustering of text streams using bursty features [11], etc.",
                "Nevertheless, none of the existing work specifically identified features for events, except for Fung et al. [9], who clustered busty features to identify various bursty events.",
                "Our work differs from [9] in several ways: 1) we analyze every single feature, not only bursty features; 2) we classify features along two categorical dimensions (periodicity and power), yielding altogether five primary feature types; 3) we do not restrict each feature to exclusively belong to only one event.",
                "<br>spectral analysis</br> techniques have previously been used by Vlachos et al. [19] to identify periodicities and bursts from query logs.",
                "Their focus was on detecting multiple periodicities from the power spectrum graph, which were then used to index words for query-by-burst search.",
                "In this paper, we use <br>spectral analysis</br> to classify word features along two dimensions, namely periodicity and power spectrum, with the ultimate goal of identifying both periodic and aperiodic bursty events. 3.",
                "DATA REPRESENTATION Let T be the duration/period (in days) of a news stream, and F represents the complete word feature space in the classical static Vector Space Model (VSM). 3.1 Event Periodicity Classification Within T, there may exist certain events that occur only once, e.g., Tony Blair elected as Prime Minister of U.K., and other recurring events of various periodicities, e.g., weekly soccer matches.",
                "We thus categorize all events into two types: aperiodic and periodic, defined as follows.",
                "Definition 1. (Aperiodic Event) An event is aperiodic within T if it only happens once.",
                "Definition 2. (Periodic Event) If events of a certain event genre occur regularly with a fixed periodicity P ≤ T/2 , we say that this particular event genre is periodic, with each member event qualified as a periodic event.",
                "Note that the definition of aperiodic is relative, i.e., it is true only for a given T, and may be invalid for any other T > T. For example, the event Christmas feast is aperiodic for T ≤ 365 but periodic for T ≥ 730. 3.2 Representative Features Intuitively, an event can be described very concisely by a few discriminative and representative word features and vice-versa, e.g., hurricane, sweep, and strike could be representative features of a Hurricane genre event.",
                "Likewise, a set of strongly correlated features could be used to reconstruct an event description, assuming that strongly correlated features are representative.",
                "The representation vector of a word feature is defined as follows: Definition 3. (Feature Trajectory) The trajectory of a word feature f can be written as the sequence yf = [yf (1), yf (2), . . . , yf (T)], where each element yf (t) is a measure of feature f at time t, which could be defined using the normalized DFIDF score2 yf (t) = DFf (t) N(t) × log( N DFf ), where DFf (t) is the number of documents (local DF) containing feature f at day t, DFf is the total number of documents (global DF) containing feature f over T, N(t) is the number of documents for day t, and N is the total number of documents over T. 4.",
                "IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 <br>spectral analysis</br> for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. DFT can represent the original time series as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T.",
                "The original trajectory can be reconstructed with just the dominant frequencies, which can be determined from the power spectrum using the popular periodogram estimator.",
                "The periodogram is a sequence of the squared magnitude of the Fourier coefficients, Xk 2 , k = 1, 2, . . . , T/2 , which indicates the signal power at frequency k/T in the spectrum.",
                "From the power spectrum, the dominant period is chosen as the inverse of the frequency with the highest power spectrum, as follows.",
                "Definition 4. (Dominant Period) The dominant period (DP) of a given feature f is Pf = T/ arg max k Xk 2 .",
                "Accordingly, we have Definition 5. (Dominant Power Spectrum) The dominant power spectrum (DPS) of a given feature f is Sf = Xk 2 , with Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorizing Features The DPS of a feature trajectory is a strong indicator of its activeness at the specified frequency; the higher the DPS, the more likely for the feature to be bursty.",
                "Combining DPS with DP, we therefore categorize all features into four types: 2 We normalize yf (t) as yf (t) = yf (t)/ T i=1 yf (i) so that it could be interpreted as a probability. • HH: high Sf , aperiodic or long-term periodic (Pf > T/2 ); • HL: high Sf , short-term periodic (Pf ≤ T/2 ); • LH: low Sf , aperiodic or long-term periodic; • LL: low Sf , short-term periodic.",
                "The boundary between long-term and short-term periodic is set to T/2 .",
                "However, distinguishing between a high and low DPS is not straightforward, which will be tackled later.",
                "Properties of Different Feature Sets To better understand the properties of HH, HL, LH and LL, we select four features, Christmas, soccer, DBS and your as illustrative examples.",
                "Since the boundary between high and low power spectrum is unclear, these chosen examples have relative wide range of power spectrum values.",
                "Figure 2(a) shows the DFIDF trajectory for Christmas with a distinct burst around Christmas day.",
                "For the 1-year Reuters dataset, Christmas is classified as a typical aperiodic event with Pf = 365 and Sf = 135.68, as shown in Figure 2(b).",
                "Clearly, the value of Sf = 135.68 is reasonable for a well-known bursty event like Christmas. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Christmas(DFIDF:time) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Christmas(S:frequency) Figure 2: Feature Christmas with relative high Sf and long-term Pf .",
                "The DFIDF trajectory for soccer is shown in Figure 3(a), from which we can observe that there is a regular burst every 7 days, which is again verified by its computed value of Pf = 7, as shown in Figure 3(b).",
                "Using the domain knowledge that soccer games have more matches every Saturday, which makes it a typical and heavily reported periodic event, we thus consider the value of Sf = 155.13 to be high. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) soccer(DFIDF:time) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) soccer(S:frequency) Figure 3: Feature soccer with relative high Sf and short-term Pf .",
                "From the DFIDF trajectory for DBS in Figure 4(a), we can immediately deduce DBS to be an infrequent word with a trivial burst on 08/17/1997 corresponding to DBS Land Raﬄes Holdings plans.",
                "This is confirmed by the long period of Pf = 365 and low power of Sf = 0.3084 as shown in Figure 4(b).",
                "Moreover, since this aperiodic event is only reported in a few news stories over a very short time of few days, we therefore say that its low power value of Sf = 0.3084 is representative of unimportant events.",
                "The most confusing example is shown in Figure 5 for the word feature your, which looks very similar to the graph for soccer in Figure 3.",
                "At first glance, we may be tempted to group both your and soccer into the same category of HL or LL since both distributions look similar and have the same dominant period of approximately a week.",
                "However, further 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:time) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frequency) Figure 4: Feature DBS with relative low Sf and long-term Pf . analysis indicates that the periodicity of your is due to the differences in document counts for weekdays (average 2,919 per day) and weekends3 (average 479 per day).",
                "One would have expected the periodicity of a stopword like your to be a day.",
                "Moreover, despite our DFIDF normalization, the weekday/weekend imbalance still prevailed; stopwords occur 4 times more frequently on weekends than on weekdays.",
                "Thus, the DPS remains the only distinguishing factor between your (Sf = 9.42) and soccer (Sf = 155.13).",
                "However, it is very dangerous to simply conclude that a power value of S = 9.42 corresponds to a stopword feature. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) your(DFIDF:time) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) your(S:frequency) Figure 5: Feature your as an example confusing with feature soccer.",
                "Before introducing our solution to this problem, lets look at another LL example as shown in Figure 6 for beenb, which is actually a confirmed typo.",
                "We therefore classify beenb as a noisy feature that does not contribute to any event.",
                "Clearly, the trajectory of your is very different from beenb, which means that the former has to be considered separately. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figure 6: Feature beenb with relative low Sf and short-term Pf .",
                "Stop Words (SW) Feature Set Based on the above analysis, we realize that there must be another feature set between HL and LL that corresponds to the set of stopwords.",
                "Features from this set has moderate DPS and low but known dominant period.",
                "Since it is hard to distinguish this feature set from HL and LL only based on DPS, we introduce another factor called average DFIDF (DFIDF).",
                "As shown in Figure 5, features like your usually have a lower DPS than a HL feature like soccer, but have a much higher DFIDF than another LL noisy feature such as beenb.",
                "Since such properties are usually characteristics of stopwords, we group features like your into the newly defined stopword (SW) feature set.",
                "Since setting the DPS and DFIDF thresholds for identifying stopwords is more of an art than science, we proposed a heuristic HS algorithm, Algorithm 1.",
                "The basic idea is to only use news stories from weekdays to identify stopwords. 3 The weekends here also include public holidays falling on weekdays.",
                "The SW set is initially seeded with a small set of 29 popular stopwords utilized by Google search engine.",
                "Algorithm 1 Heuristic Stopwords detection (HS) Input: Seed SW set, weekday trajectories of all words 1: From the seed set SW, compute the maximum DPS as UDPS, maximum DFIDF as UDFIDF, and minimum of DFIDF as LDFIDF. 2: for fi ∈ F do 3: Compute DFT for fi. 4: if Sfi ≤ UDPS and DFIDFfi ∈ [LDFIDF, UDFIDF] then 5: fi → SW 6: F = F − fi 7: end if 8: end for Overview of Feature Categorization After the SW set is generated, all stopwords are removed from F. We then set the boundary between high and low DPS to be the upper bound of the SW sets DPS.",
                "An overview of all five feature sets is shown in Figure 7.",
                "Figure 7: The 5 feature sets for events. 5.",
                "IDENTIFYING BURSTS FOR FEATURES Since only features from HH, HL and LH are meaningful and could potentially be representative to some events, we pruned all other feature classified as LL or SW.",
                "In this section, we describe how bursts can be identified from the remaining features.",
                "Unlike Kleinbergs burst identification algorithm [12], we can identify both significant and trivial bursts without the need to set any parameters. 5.1 Detecting Aperiodic Features Bursts For each feature in HH and HL, we truncate its trajectory by keeping only the bursty period, which is modeled with a Gaussian distribution.",
                "For example, Figure 8 shows the word feature Iraq with a burst circa 09/06/1996 being modeled as a Gaussian.",
                "Its bursty period is defined by [μf − σf , μf + σf ] as shown in Figure 8(b). 5.2 Detecting Periodic Features Bursts Since we have computed the DP for a periodic feature f, we can easily model its periodic feature trajectory yf using 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) original DFIDF:time 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 burst= [μ-σ, μ+σ] (b) identifying burst Figure 8: Modeling Iraqs time series as a truncated Gaussian with μ = 09/06/1996 and σ = 6.26. a mixture of K = T/Pf Gaussians: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , where the parameter set θf = {αk, μk, σk}K k=1 comprises: • αk is the probability of assigning yf into the kth Gaussian. αk > 0, ∀k ∈ [1, K] and K k=1 αk = 1; • μk/σk is mean/standard deviation of the kth Gaussian.",
                "The well known Expectation Maximization (EM) [8] algorithm is used to compute the mixing proportions αk, as well as the individual Gaussian density parameters μk and σK .",
                "Each Gaussian represents one periodic event, and is modeled similarly as mentioned in Section 5.1. 6.",
                "EVENTS FROM FEATURES After identifying and modeling bursts for all features, the next task is to paint a picture of the event with a potential set of representative features. 6.1 Feature Correlation If two features fi and fj are representative of the same event, they must satisfy the following necessary conditions: 1. fi and fj are identically distributed: yfi ∼ yfj . 2. fi and fj have a high document overlap.",
                "Measuring Feature Distribution Similarity We measure the similarity between two features fi and fj using discrete KL-divergence defined as follows.",
                "Definition 6. (feature similarity) KL(fi, fj ) is given by max(KL(fi|fj ), KL(fj |fi)), where KL(fi|fj ) = T t=1 f(yfi (t)|θfi )log f(yfi (t)|θfi ) f(yfj (t)|θfj ) . (1) Since KL-divergence is not symmetric, we define the similarity between between fi and fj as the maximum of KL(fi|fj ) and KL(fj |fi).",
                "Further, the similarity between two aperiodic features can be computed using a closed form of the KL-divergence [16].",
                "The same discrete KL-divergence formula of Eq. 1 is employed to compute the similarity between two periodic features, Next, we define the overal similarity among a set of features R using the maximum inter-feature KL-Divergence value as follows.",
                "Definition 7. (sets similarity)KL(R) = max ∀fi,fj ∈R KL(fi, fj ).",
                "Document Overlap Let Mi be the set of all documents containing feature fi.",
                "Given two features fi and fj , the overlapping document set containing both features is Mi ∩ Mj .",
                "Intuitively, the higher the |Mi ∩ Mj |, the more likelty that fi and fj will be highly correlated.",
                "We define the degree of document overlap between two features fi and fj as follows.",
                "Definition 8. (Feature DF Overlap) d(fi, fj ) = |Mi∩Mj| min(|Mi|,|Mj|) .",
                "Accordingly, the DF Overlap among a set of features R is also defined.",
                "Definition 9. (Set DF Overlap) d(R) = min ∀fi,fj ∈R d(fi, fj). 6.2 Unsupervised Greedy Event Detection We use features from HH to detect important aperiodic events, features from LH to detect less-reported/unimportant aperiodic events, and features from HL to detect periodic events.",
                "All of them share the same algorithm.",
                "Given bursty feature fi ∈ HH, the goal is to find highly correlated features from HH.",
                "The set of features similar to fi can then collectively describe an event.",
                "Specifically, we need to find a subset Ri of HH that minimizes the following cost function: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) The underlying event e (associated with the burst of fi) can be represented by Ri as y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) The burst analysis for event e is exactly the same as the feature trajectory.",
                "The cost in Eq. 2 can be minimized using our unsupervised greedy UG event detection algorithm, which is described in Algorithm 2.",
                "The UG algorithm allows a feature Algorithm 2 Unsupervised Greedy event detection (UG).",
                "Input: HH, document index for each feature. 1: Sort and select features in descending DPS order: Sf1 ≥ Sf2 ≥ . . . ≥ Sf|HH| . 2: k = 0. 3: for fi ∈ HH do 4: k = k + 1. 5: Init: Ri ← fi, C(Ri) = 1/Sfi and HH = HH − fi. 6: while HH not empty do 7: m = arg min m C(Ri ∪ fm). 8: if C(Ri ∪ fm) < C(Ri) then 9: Ri ← fm and HH = HH − fm. 10: else 11: break while. 12: end if 13: end while 14: Output ek as Eq. 3. 15: end for to be contained in multiple events so that we can detect several events happening at the same time.",
                "Furthermore, trivial events only containing year/month features (i.e., an event only containing 1 feature Aug could be identified over a 1year news stream) could be removed, although such events will have inherent high cost and should already be ranked very low.",
                "Note that our UG algorithm only requires one data-dependant parameter, the boundary between high and low power spectrum, to be set once, and this parameter can be easily estimated using the HS algorithm (Algorithm 1). 7.",
                "EXPERIMENTS In this section, we study the performances of our feature categorizing method and event detection algorithm.",
                "We first introduce the dataset and experimental setup, then we subjectively evaluate the categorization of features for HH, HL, LH, LL and SW.",
                "Finally, we study the (a)periodic event detection problem with Algorithm 2. 7.1 Dataset and Experimental Setup The Reuters Corpus contains 806,791 English news stories from 08/20/1996 to 08/19/1997 at a day resolution.",
                "Version 2 of the open source Lucene software [1] was used to tokenize the news text content and generate the document-word vector.",
                "In order to preserve the time-sensitive past/present/future tenses of verbs and the differences between lower case nouns and upper case named entities, no stemming was done.",
                "Since dynamic stopword removal is one of the functionalities of our method, no stopword was removed.",
                "We did remove nonEnglish characters, however, after which the number of word features amounts to 423,433.",
                "All experiments were implemented in Java and conducted on a 3.2 GHz Pentium 4 PC running Windows 2003 Server with 1 GB of memory. 7.2 Categorizing Features We downloaded 34 well-known stopwords utilized by the Google search engine as our seed training features, which includes a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en and www.",
                "We excluded the last five stopwords as they are uncommon in news stories.",
                "By only analyzing news stories over 259 weekdays, we computed the upper bound of the power spectrum for stopwords at 11.18 and corresponding DFIDF ranges from 0.1182 to 0.3691.",
                "Any feature f satisfying Sf <= 11.18 and 0.1182 <= DFIDFf <= 0.3691 over weekdays will be considered a stopword.",
                "In this manner, 470 stopwords were found and removed as visualized in Figure 9.",
                "Some detected stopwords are A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) and much (P = 22, S = 0.80, DFIDF = 0.1865).",
                "After the removal of these stopwords, the distribution of weekday and weekend news are more or less matched, and in the ensuing experiments, we shall make use of the full corpus (weekdays and weekends).",
                "The upper bound power spectrum value of 11.18 for stopwords training was selected as the boundary between the high power and low power spectrum.",
                "The boundary between high and low periodicity was set to 365/2 = 183.",
                "All 422,963 (423433 − 470) word features were categorized into 4 feature sets: HH (69 features), HL (1,087 features), LH (83,471 features), and LL (338,806 features) as shown in Figure 10.",
                "In Figure 10, each gray level denotes the relative density of features in a square region, measured by log10(1 + Dk), where Dk is the number of features within the k-th square region.",
                "From the figure, we can make the 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figure 9: Distribution of SW (stopwords) in the HH, HL, LH, and LL regions. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figure 10: Distribution of categorized features over the four quadrants (shading in log scale). following observations: 1.",
                "Most features have low S and are easily distinguishable from those features having a much higher S, which allows us to detect important (a)periodic events from trivial events by selecting features with high S. 2.",
                "Features in the HH and LH quadrants are aperiodic, which are nicely separated (big horizontal gap) from the periodic features.",
                "This allows reliably detecting aperiodic events and periodic events independently. 3.",
                "The (vertical) boundary between high and low power spectrum is not as clearcut and the exact value will be application specific.",
                "By checking the scatter distribution of features from SW on HH, HL, LH, and LL as shown in Figure 9, we found that 87.02%(409/470) of the detected stopwords originated from LL.",
                "The LL classification and high DFIDF scores of stopwords agree with the generally accepted notion that stopwords are equally frequent over all time.",
                "Therefore, setting the boundary between high and low power spectrum using the upper bound Sf of SW is a reasonable heuristic. 7.3 Detecting Aperiodic Events We shall evaluate our two hypotheses, 1)important aperiodic events can be defined by a set of HH features, and 2)less reported aperiodic events can be defined by a set of LH features.",
                "Since no benchmark news streams exist for event detection (TDT datasets are not proper streams), we evaluate the quality of the automatically detected events by comparing them to manually-confirmed events by searching through the corpus.",
                "Among the 69 HH features, we detected 17 important aperiodic events as shown in Table 1 (e1 − e17).",
                "Note that the entire identification took less than 1 second, after removing events containing only the month feature.",
                "Among the 17 events, other than the overlaps between e3 and e4 (both describes the same hostage event), e11 and e16 (both about company reports), the 14 identified events are extremely accurate and correspond very well to the major events of the period.",
                "For example, the defeat of Bob Dole, election of Tony Blair, Missile attack on Iraq, etc.",
                "Recall that selecting the features for one event should minimize the cost in Eq. 2 such that 1) the number of features span different events, and 2) not all features relevant to an event will be selected, e.g., the feature Clinton is representative to e12 but since Clinton relates to many other events, its time domain signal is far different from those of other representative features like Dole and Bob.",
                "The number of documents of a detected event is roughly estimated by the number of indexed documents containing the representative features.",
                "We can see that all 17 important aperiodic events are popularly reported events.",
                "After 742 minutes of computation time, we detected 23, 525 less reported aperiodic events from 83,471 LH features.",
                "Table 1 lists the top 5 detected aperiodic events (e18 − e22) with respect to the cost.",
                "We found that these 5 events are actually very trivial events with only a few news reports, and are usually subsumed by some larger topics.",
                "For example, e22 is one of the rescue events in an airplane hijack topic.",
                "One advantage of our UG Algorithm for discovering less-reported aperiodic events is that we are able to precisely detect the true event period. 7.4 Detecting Periodic Events Among the 1,087 HL features, 330 important periodic events were detected within 10 minutes of computing time.",
                "Table 1 lists the top 5 detected periodic events with respect to the cost (e23 − e27).",
                "All of the detected periodic events are indeed valid, and correspond to real life periodic events.",
                "The GMM model is able to detect and estimate the bursty period nicely although it cannot distinguish the slight difference between every Monday-Friday and all weekdays as shown in e23.",
                "We also notice that e26 is actually a subset of e27 (soccer game), which is acceptable since the Sheffield league results are announced independently every weekend. 8.",
                "CONCLUSIONS This paper took a whole new perspective of analyzing feature trajectories as time domain signals.",
                "By considering the word document frequencies in both time and frequency domains, we were able to derive many new characteristics about news streams that were previously unknown, e.g., the different distributions of stopwords during weekdays and weekends.",
                "For the first time in the area of TDT, we applied a systematic approach to automatically detect important and less-reported, periodic and aperiodic events.",
                "The key idea of our work lies in the observations that (a)periodic events have (a)periodic representative features and (un)important events have (in)active representative features, differentiated by their power spectrums and time periods.",
                "To address the real event detection problem, a simple and effective mixture density-based approach was used to identify feature bursts and their associated bursty periods.",
                "We also designed an unsupervised greedy algorithm to detect both aperiodic and periodic events, which was successful in detecting real events as shown in the evaluation on a real news stream.",
                "Although we have not made any benchmark comparison against another approach, simply because there is no previous work in the addressed problem.",
                "Future work includes evaluating the recall of detected events for a labeled news stream, and comparing our model against the closest equivalent methods, which currently are limited to the methods of Kleinberg [12] (which can only detect certain type of bursty events depending on parameter settings), Fung et al. [9], and Swan and Allan [18].",
                "Nevertheless, we believe our simple and effective method will be useful for all TDT practitioners, and will be especially useful for the initial exploratory analysis of news streams. 9.",
                "REFERENCES [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Google news alerts, http://www.google.com/alerts. [3] Reuters corpus, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan.",
                "Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, and H. Jin.",
                "First story detection in tdt is hard.",
                "In CIKM, pages 374-381, 2000. [6] J. Allan, C. Wade, and A. Bolivar.",
                "Retrieval and novelty detection at the sentence level.",
                "In SIGIR, pages 314-321, 2003. [7] T. Brants, F. Chen, and A. Farahat.",
                "A system for new event detection.",
                "In SIGIR, pages 330-337, 2003. [8] A. P. Dempster, N. M. Laird, and D. B. Rubin.",
                "Maximum likelihood from incomplete data via the EM algorithm.",
                "Journal of the Royal Statistical Society, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu, and H. Lu.",
                "Parameter free bursty events detection in text streams.",
                "In VLDB, pages 181-192, 2005. [10] Q.",
                "He, K. Chang, and E.-P. Lim.",
                "A model for anticipatory event detection.",
                "In ER, pages 168-181, 2006. [11] Q.",
                "He, K. Chang, E.-P. Lim, and J. Zhang.",
                "Bursty feature reprensentation for clustering text streams.",
                "In SDM, accepted, 2007. [12] J. Kleinberg.",
                "Bursty and hierarchical structure in streams.",
                "In SIGKDD, pages 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins.",
                "On the bursty evolution of blogspace.",
                "In WWW, pages 159-178, 2005. [14] G. Kumaran and J. Allan.",
                "Text classification and named entities for new event detection.",
                "In SIGIR, pages 297-304, 2004. [15] Q. Mei and C. Zhai.",
                "Discovering evolutionary theme patterns from text: an exploration of temporal text mining.",
                "In SIGKDD, pages 198-207, 2005. [16] W. D. Penny.",
                "Kullback-liebler divergences of normal, gamma, dirichlet and wishart densities.",
                "Technical report, 2001. [17] N. Stokes and J. Carthy.",
                "Combining semantic and syntactic document classifiers to improve first story detection.",
                "In SIGIR, pages 424-425, 2001. [18] R. Swan and J. Allan.",
                "Automatic generation of overview timelines.",
                "In SIGIR, pages 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena, and D. Gunopulos.",
                "Identifying similarities, periodicities and bursts for online search queries.",
                "In SIGMOD, pages 131-142, 2004. [20] Y. Yang, T. Pierce, and J. Carbonell.",
                "A study of retrospective and on-line event detection.",
                "In SIGIR, pages 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topic-conditioned novelty detection.",
                "In SIGKDD, pages 688-693, 2002.",
                "Table 1: All important aperiodic events (e1 − e17), top 5 less-reported aperiodic events (e18 − e22) and top 5 important periodic events (e23 − e27).",
                "Detected Event and Bursty Period Doc # True Event e1(Sali,Berisha,Albania,Albanian,March) 02/02/199705/29/1997 1409 Albanians president Sali Berisha lost in an early election and resigned, 12/1996-07/1997. e2(Seko,Mobutu,Sese,Kabila) 03/22/1997-06/09/1997 2273 Zaires president Mobutu Sese coordinated the native rebellion and failed on 05/16/1997. e3(Marxist,Peruvian) 11/19/1996-03/05/1997 824 Peru rebels (Tupac Amaru revolutionary Movement) led a hostage siege in Lima in early 1997. e4(Movement,Tupac,Amaru,Lima,hostage,hostages) 11/16/1996-03/20/1997 824 The same as e3. e5(Kinshasa,Kabila,Laurent,Congo) 03/26/199706/15/1997 1378 Zaire was renamed the Democratic Republic of Congo on 05/16/1997. e6(Jospin,Lionel,June) 05/10/1997-07/09/1997 605 Following the early General Elections circa 06/1997, Lionel Jospin was appointed Prime Minister on 06/02/1997. e7(Iraq,missile) 08/31/1996-09/13/1996 1262 U.S. fired missile at Iraq on 09/03/1996 and 09/04/1996. e8(Kurdish,Baghdad,Iraqi) 08/29/1996-09/09/1996 1132 Iraqi troop fought with Kurdish faction circa 09/1996. e9(May,Blair) 03/24/1997-07/04/1997 1049 Tony Blair became the Primary Minister of the United Kingdom on 05/02/1997. e10(slalom,skiing) 12/05/1996-03/21/1997 253 Slalom Game of Alpine Skiing in 01/1997-02/1997. e11(Interim,months) 09/24/1996-12/31/1996 3063 Tokyo released company interim results for the past several months in 09/1996-12/1996. e12(Dole,Bob) 09/09/1996-11/24/1996 1599 Dole Bob lost the 1996 US presidential election. e13(July,Sen) 06/25/1997-06/25/1997 344 Cambodias Prime Minister Hun Sen launched a bloody military coup in 07/1997. e14(Hebron) 10/15/1996-02/14/1997 2098 Hebron was divided into two sectors in early 1997. e15(April,Easter) 02/23/1997-05/04/1997 480 Easter feasts circa 04/1997 (for western and Orthodox). e16(Diluted,Group) 04/27/1997-07/20/1997 1888 Tokyo released all 96/97 group results in 04/199707/1997. e17(December,Christmas) 11/17/1996-01/26/1997 1326 Christmas feast in late 12/1997. e18(Kolaceva,winter,Together,promenades,Zajedno, Slobodan,Belgrade,Serbian,Serbia,Draskovic,municipal, Kragujevac) 1/25/1997 3 University students organized a vigil on Kolaceva street against government on 1/25/1997. e19(Tutsi,Luvengi,Burundi,Uvira,fuel,Banyamulenge, Burundian,Kivu,Kiliba,Runingo,Kagunga,Bwegera) 10/19/1996 6 Fresh fighting erupted around Uvira between Zaire armed forces and Banyamulengs Tutsi rebels on 10/19/1996. e20(Malantacchi,Korea,Guy,Rider,Unions,labour, Trade,unions,Confederation,rammed,Geneva,stoppages, Virgin,hire,Myongdong,Metalworkers) 1/11/1997 2 Marcello Malantacchi secretary general of the International Metalworkers Federation and Guy Rider who heads the Geneva office of the International Confederation of Free Trade Unions attacked the new labour law of South Korea on 1/11/1997. e21(DBS,Raﬄes) 8/17/1997 9 The list of the unit of Singapore DBS Land Raﬄes Holdings plans on 8/17/1997. e22(preserver,fuel,Galawa,Huddle,Leul,Beausse) 11/24/1996 3 Rescued a woman and her baby during a hijacked Ethiopian plane that ran out of fuel and crashed into the sea near Le Galawa beach on 11/24/1996. e23(PRICE,LISTING,MLN,MATURITY,COUPON, MOODY,AMT,FIRST,ISS,TYPE,PAY,BORROWER) Monday-Friday/week 7966 Announce bond price on all weekdays. e24(Unaudited,Ended,Months,Weighted,Provision,Cost, Selling,Revenues,Loss,Income,except,Shrs,Revs) every season 2264 Net income-loss reports released by companies in every season. e25(rating,Wall,Street,Ian) Monday-Friday/week 21767 Stock reports from Wall Street on all weekdays. e26(Sheffield,league,scoring,goals,striker,games) every Friday, Saturday and Sunday 574 Match results of Sheffield soccer league were published on Friday, Saturday and Sunday 10 times than other 4 days. e27(soccer,matches,Results,season,game,Cup,match, victory,beat,played,play,division) every Friday, Saturday and Sunday 2396 Soccer games held on Friday, Saturday and Sunday 7 times than other 4 days."
            ],
            "original_annotated_samples": [
                "In this paper, we 1) first applied <br>spectral analysis</br> to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events.",
                "In particular, we study the novel problem of analyzing feature trajectories for event detection, borrowing a well-known technique from signal processing: identifying distributional correlations among all features by <br>spectral analysis</br>.",
                "<br>spectral analysis</br> techniques have previously been used by Vlachos et al. [19] to identify periodicities and bursts from query logs.",
                "In this paper, we use <br>spectral analysis</br> to classify word features along two dimensions, namely periodicity and power spectrum, with the ultimate goal of identifying both periodic and aperiodic bursty events. 3.",
                "IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 <br>spectral analysis</br> for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. DFT can represent the original time series as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T."
            ],
            "translated_annotated_samples": [
                "En este artículo, 1) primero aplicamos <br>análisis espectral</br> para categorizar características de diferentes tipos de eventos: importantes y poco reportados, periódicos y aperiódicos; 2) modelamos las características aperiódicas con densidad gaussiana y las características periódicas con densidades de mezcla gaussiana, y posteriormente detectamos cada ráfaga de características mediante el enfoque gaussiano truncado; 3) propusimos un algoritmo de detección de eventos codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos.",
                "En particular, estudiamos el novedoso problema de analizar trayectorias de características para la detección de eventos, utilizando una técnica conocida de procesamiento de señales: identificar correlaciones distribucionales entre todas las características mediante <br>análisis espectral</br>.",
                "Las técnicas de <br>análisis espectral</br> han sido utilizadas previamente por Vlachos et al. [19] para identificar periodicidades y ráfagas en los registros de consultas.",
                "En este artículo, utilizamos <br>análisis espectral</br> para clasificar las características de las palabras a lo largo de dos dimensiones, a saber, periodicidad y espectro de potencia, con el objetivo final de identificar eventos tanto periódicos como no periódicos y explosivos. 3.",
                "En esta sección, mostramos cómo se pueden extraer características representativas para eventos (poco) importantes o (a)periódicos. 4.1 Análisis Espectral para el Período Dominante Dada una característica f, descomponemos su trayectoria de características yf = [yf (1), yf (2), ..., yf (T)] en la secuencia de T números complejos [X1, . . . , XT ] a través de la transformada discreta de Fourier (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. La DFT puede representar la serie temporal original como una combinación lineal de sinusoides complejas, lo cual se ilustra mediante la transformada discreta de Fourier inversa (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, donde el coeficiente de Fourier Xk denota la amplitud del sinusoides con frecuencia k/T."
            ],
            "translated_text": "Analizando Trayectorias de Características para la Detección de Eventos Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg Escuela de Ingeniería Informática Universidad Tecnológica de Nanyang Bloque N4, Avenida Nanyang, Singapur 639798 RESUMEN Consideramos el problema de analizar trayectorias de palabras en los dominios del tiempo y la frecuencia, con el objetivo específico de identificar palabras importantes y menos reportadas, periódicas y aperiódicas. Un conjunto de palabras con tendencias idénticas puede agruparse para reconstruir un evento de manera completamente no supervisada. La frecuencia del documento de cada palabra a lo largo del tiempo se trata como una serie temporal, donde cada elemento es el puntaje de frecuencia del documento - frecuencia inversa del documento (DFIDF) en un punto temporal. En este artículo, 1) primero aplicamos <br>análisis espectral</br> para categorizar características de diferentes tipos de eventos: importantes y poco reportados, periódicos y aperiódicos; 2) modelamos las características aperiódicas con densidad gaussiana y las características periódicas con densidades de mezcla gaussiana, y posteriormente detectamos cada ráfaga de características mediante el enfoque gaussiano truncado; 3) propusimos un algoritmo de detección de eventos codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos. Todos los métodos anteriores se pueden aplicar a datos de series temporales en general. Evaluamos exhaustivamente nuestros métodos en el Corpus de Noticias de Reuters de 1 año [3] y demostramos que fueron capaces de descubrir eventos significativos aperiódicos y periódicos. Categorías y Descriptores de Asignaturas: H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales: Algoritmos, Experimentación. 1. INTRODUCCIÓN Hay más de 4,000 fuentes de noticias en línea en el mundo. Supervisar manualmente todos ellos en busca de eventos importantes se ha vuelto difícil o prácticamente imposible. De hecho, la comunidad de detección y seguimiento de temas (TDT) ha estado tratando durante muchos años de encontrar una solución práctica para ayudar a las personas a monitorear las noticias de manera efectiva. Desafortunadamente, el Santo Grial sigue siendo esquivo, ya que la gran mayoría de las soluciones de TDT propuestas para la detección de eventos [20, 5, 17, 4, 21, 7, 14, 10] son demasiado simplistas (basadas en la similitud del coseno [5]) o impracticables debido a la necesidad de ajustar un gran número de parámetros [9]. La ineficacia de las tecnologías actuales de TDT se puede ilustrar fácilmente suscribiéndose a cualquiera de los muchos servicios de alertas de noticias en línea, como el líder de la industria Google News Alerts, que genera más del 50% de falsas alarmas. Como prueba adicional, portales como Yahoo adoptan un enfoque más pragmático al requerir que todas las alertas de noticias generadas por máquinas pasen por un operador humano para su confirmación antes de enviarlas a los suscriptores. En lugar de abordar el problema con variaciones del mismo martillo (similitud coseno y TFIDF), es necesario contar con una comprensión fundamental de las características de los datos de flujo de noticias antes de que se puedan lograr avances importantes en TDT. Por lo tanto, en este artículo, examinamos noticias y tendencias de características desde la perspectiva de analizar una señal de palabras de series temporales. Trabajos anteriores como [9] han intentado reconstruir un evento con sus características representativas. Sin embargo, en muchas tareas de detección de eventos predictivos (es decir, detección de eventos retrospectivos), hay un vasto conjunto de características potenciales solo para un conjunto fijo de observaciones (es decir, los estallidos obvios). De estas características, a menudo solo se espera que un pequeño número sea útil. En particular, estudiamos el novedoso problema de analizar trayectorias de características para la detección de eventos, utilizando una técnica conocida de procesamiento de señales: identificar correlaciones distribucionales entre todas las características mediante <br>análisis espectral</br>. Para evaluar nuestro método, posteriormente proponemos un algoritmo de detección de eventos no supervisado para flujos de noticias. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Pascua Abril (a) evento aperiódico 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 No auditado Finalizado (b) evento periódico Figura 1: Correlación de características (DFIDF:tiempo) entre a) Pascua y Abril b) No auditado y Finalizado. Como ejemplo ilustrativo, considera la correlación entre las palabras Pascua y abril del Corpus de Reuters. A partir del gráfico de su DFIDF normalizado en la Figura 1(a), observamos la gran superposición entre las dos palabras alrededor de 04/1997, lo que significa que probablemente ambas pertenecen al mismo evento durante ese tiempo (festividad de Pascua). En este ejemplo, el evento oculto de la festividad de Pascua es un evento aperiódico típico e importante en datos de 1 año. Otro ejemplo se muestra en la Figura 1(b), donde las palabras \"No auditado\" y \"Finalizado 1\" del Corpus de Reuters son el conjunto de datos predeterminado para todos los ejemplos y presentan un comportamiento similar durante períodos de 3 meses. Estas dos palabras en realidad se originaron a partir del mismo evento periódico, informes de ganancias y pérdidas, que son publicados trimestralmente por empresas cotizadas en bolsa. Otras observaciones extraídas de la Figura 1 son: 1) el período de actividad intensa de abril es mucho más largo que el de Semana Santa, lo que sugiere que abril puede estar presente en otros eventos durante el mismo período; 2) No auditado tiene un valor promedio de DFIDF más alto que Finalizado, lo que indica que No auditado es más representativo para el evento subyacente. Estos dos ejemplos son solo la punta del iceberg entre todas las tendencias de palabras y correlaciones ocultas en un flujo de noticias como Reuters. Si se puede descubrir un gran número de ellos, podría ayudar significativamente en las tareas de TDT. En particular, indica la importancia de extraer características correlacionadas para detectar eventos correspondientes. Para resumir, postulamos que: 1) Un evento se describe por sus características representativas. Un evento periódico tiene una lista de características periódicas y un evento aperiódico tiene una lista de características aperiódicas; 2) Las características representativas del mismo evento comparten distribuciones similares en el tiempo y están altamente correlacionadas; 3) Un evento importante tiene un conjunto de características representativas activas (ampliamente reportadas), mientras que un evento no importante tiene un conjunto de características representativas inactivas (menos reportadas); 4) Una característica puede ser incluida por varios eventos con superposiciones en los marcos de tiempo. Basándonos en estas observaciones, podemos extraer características representativas dadas un evento o detectar un evento a partir de una lista de características altamente correlacionadas. En este artículo, nos enfocamos en este último aspecto, es decir, cómo se pueden descubrir características correlacionadas para formar un evento de manera no supervisada. 1.1 Contribuciones Este artículo tiene tres contribuciones principales: • Hasta donde sabemos, nuestro enfoque es el primero en categorizar características de palabras para eventos heterogéneos. Específicamente, cada característica de palabra se clasifica en uno de los siguientes cinco tipos de características basados en la fuerza de su espectro de potencia y periodicidad: 1) HH (alta potencia y alta/larga periodicidad): eventos aperiódicos importantes, 2) HL (alta potencia y baja periodicidad): eventos periódicos importantes, 3) LH (baja potencia y alta periodicidad): eventos aperiódicos no importantes, 4) LL (baja potencia y baja periodicidad): no eventos, y 5) SW (palabras vacías), un subconjunto de LL con mayor potencia y periodicidad que comprende palabras vacías, que no contienen información. • Proponemos un enfoque simple y efectivo basado en densidad de mezcla para modelar y detectar ráfagas de características. • Presentamos un algoritmo de detección de eventos no supervisado para detectar eventos tanto aperiódicos como periódicos. Nuestro algoritmo ha sido evaluado en un flujo de noticias reales para demostrar su efectividad. 2. TRABAJO RELACIONADO Este trabajo está motivado en gran medida por una familia más amplia de problemas conocidos colectivamente como Detección y Seguimiento de Temas (TDT) [20, 5, 17, 4, 21, 7, 14, 10]. Además, la mayoría de las investigaciones de TDT hasta ahora se han centrado en agrupar/clasificar documentos en tipos de temas, identificar oraciones novedosas para eventos nuevos, etc., sin prestar mucha atención al análisis de la trayectoria de las palabras con respecto al tiempo. Swan y Allan [18] intentaron por primera vez usar términos que co-ocurren para construir un evento. Sin embargo, solo consideraron entidades nombradas y pares de frases nominales, sin tener en cuenta sus periodicidades. Por el contrario, nuestro artículo considera todo lo anterior. Recientemente, ha habido un gran interés en modelar un evento en flujos de texto como un estallido de actividades al incorporar información temporal. El trabajo seminal de Kleinberg describió cómo se pueden extraer características explosivas de flujos de texto utilizando un modelo de autómata infinito [12], lo que inspiró toda una serie de aplicaciones como la identificación de comunidades explosivas de Kumar a partir de gráficos de blogs [13], la sumarización de temas evolutivos en flujos de texto de Meis [15], el agrupamiento de flujos de texto utilizando características explosivas de Hes [11], etc. Sin embargo, ninguno de los trabajos existentes identificó específicamente características para eventos, excepto Fung et al. [9], quienes agruparon características llamativas para identificar varios eventos llamativos. Nuestro trabajo difiere de [9] en varias formas: 1) analizamos cada característica individual, no solo las características explosivas; 2) clasificamos las características a lo largo de dos dimensiones categóricas (periodicidad y potencia), dando en total cinco tipos de características principales; 3) no restringimos que cada característica pertenezca exclusivamente a un solo evento. Las técnicas de <br>análisis espectral</br> han sido utilizadas previamente por Vlachos et al. [19] para identificar periodicidades y ráfagas en los registros de consultas. Su enfoque estaba en detectar múltiples periodicidades a partir del gráfico del espectro de potencia, las cuales luego se utilizaron para indexar palabras para la búsqueda por ráfagas. En este artículo, utilizamos <br>análisis espectral</br> para clasificar las características de las palabras a lo largo de dos dimensiones, a saber, periodicidad y espectro de potencia, con el objetivo final de identificar eventos tanto periódicos como no periódicos y explosivos. 3. REPRESENTACIÓN DE DATOS Sea T la duración/período (en días) de un flujo de noticias, y F representa el espacio de características de palabras completo en el Modelo de Espacio Vectorial (VSM) estático clásico. 3.1 Clasificación de Periodicidad de Eventos Dentro de T, pueden existir ciertos eventos que ocurren solo una vez, por ejemplo, la elección de Tony Blair como Primer Ministro del Reino Unido, y otros eventos recurrentes de diversas periodicidades, por ejemplo, partidos de fútbol semanales. Por lo tanto, categorizamos todos los eventos en dos tipos: aperiódicos y periódicos, definidos de la siguiente manera. Definición 1. (Evento aperiódico) Un evento es aperiódico dentro de T si solo ocurre una vez. Definición 2. (Evento periódico) Si los eventos de un cierto género de eventos ocurren regularmente con una periodicidad fija P ≤ T/2, decimos que este género particular de eventos es periódico, y cada evento miembro se califica como un evento periódico. Ten en cuenta que la definición de aperiódico es relativa, es decir, es verdadera solo para un T dado y puede ser inválida para cualquier otro T > T. Por ejemplo, el evento de la fiesta de Navidad es aperiódico para T ≤ 365 pero periódico para T ≥ 730. 3.2 Características Representativas Intuitivamente, un evento puede ser descrito de manera muy concisa por unas pocas características de palabras discriminativas y representativas y viceversa, por ejemplo, huracán, barrido y golpe podrían ser características representativas de un evento del género de huracanes. Asimismo, un conjunto de características fuertemente correlacionadas podría ser utilizado para reconstruir una descripción de un evento, asumiendo que las características fuertemente correlacionadas son representativas. El vector de representación de una característica de palabra se define de la siguiente manera: Definición 3. (Trayectoria de la Característica) La trayectoria de una característica de palabra f puede escribirse como la secuencia yf = [yf (1), yf (2), . . . , yf (T)], donde cada elemento yf (t) es una medida de la característica f en el tiempo t, que podría definirse utilizando la puntuación normalizada DFIDF yf (t) = DFf (t) N(t) × log( N DFf ), donde DFf (t) es el número de documentos (DF local) que contienen la característica f en el día t, DFf es el número total de documentos (DF global) que contienen la característica f en T, N(t) es el número de documentos para el día t, y N es el número total de documentos en T. 4. En esta sección, mostramos cómo se pueden extraer características representativas para eventos (poco) importantes o (a)periódicos. 4.1 Análisis Espectral para el Período Dominante Dada una característica f, descomponemos su trayectoria de características yf = [yf (1), yf (2), ..., yf (T)] en la secuencia de T números complejos [X1, . . . , XT ] a través de la transformada discreta de Fourier (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. La DFT puede representar la serie temporal original como una combinación lineal de sinusoides complejas, lo cual se ilustra mediante la transformada discreta de Fourier inversa (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, donde el coeficiente de Fourier Xk denota la amplitud del sinusoides con frecuencia k/T. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "topic detection": {
            "translated_key": "detección y seguimiento de temas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Analyzing Feature Trajectories for Event Detection Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg School of Computer Engineering Nanyang Technological University Block N4, Nanyang Avenue, Singapore 639798 ABSTRACT We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words.",
                "A set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner.",
                "The document frequency of each word across time is treated like a time series, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point.",
                "In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events.",
                "All of the above methods can be applied to time series data in general.",
                "We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events.",
                "Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Experimentation. 1.",
                "INTRODUCTION There are more than 4,000 online news sources in the world.",
                "Manually monitoring all of them for important events has become difficult or practically impossible.",
                "In fact, the <br>topic detection</br> and tracking (TDT) community has for many years been trying to come up with a practical solution to help people monitor news effectively.",
                "Unfortunately, the holy grail is still elusive, because the vast majority of TDT solutions proposed for event detection [20, 5, 17, 4, 21, 7, 14, 10] are either too simplistic (based on cosine similarity [5]) or impractical due to the need to tune a large number of parameters [9].",
                "The ineffectiveness of current TDT technologies can be easily illustrated by subscribing to any of the many online news alerts services such as the industryleading Google News Alerts [2], which generates more than 50% false alarms [10].",
                "As further proof, portals like Yahoo take a more pragmatic approach by requiring all machine generated news alerts to go through a human operator for confirmation before sending them out to subscribers.",
                "Instead of attacking the problem with variations of the same hammer (cosine similarity and TFIDF), a fundamental understanding of the characteristics of news stream data is necessary before any major breakthroughs can be made in TDT.",
                "Thus in this paper, we look at news stories and feature trends from the perspective of analyzing a time-series word signal.",
                "Previous work like [9] has attempted to reconstruct an event with its representative features.",
                "However, in many predictive event detection tasks (i.e., retrospective event detection), there is a vast set of potential features only for a fixed set of observations (i.e., the obvious bursts).",
                "Of these features, often only a small number are expected to be useful.",
                "In particular, we study the novel problem of analyzing feature trajectories for event detection, borrowing a well-known technique from signal processing: identifying distributional correlations among all features by spectral analysis.",
                "To evaluate our method, we subsequently propose an unsupervised event detection algorithm for news streams. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Easter April (a) aperiodic event 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Unaudited Ended (b) periodic event Figure 1: Feature correlation (DFIDF:time) between a) Easter and April b) Unaudited and Ended.",
                "As an illustrative example, consider the correlation between the words Easter and April from the Reuters Corpus1 .",
                "From the plot of their normalized DFIDF in Figure 1(a), we observe the heavy overlap between the two words circa 04/1997, which means they probably both belong to the same event during that time (Easter feast).",
                "In this example, the hidden event Easter feast is a typical important aperiodic event over 1-year data.",
                "Another example is given by Figure 1(b), where both the words Unaudited and Ended 1 Reuters Corpus is the default dataset for all examples. exhibit similar behaviour over periods of 3 months.",
                "These two words actually originated from the same periodic event, net income-loss reports, which are released quarterly by publicly listed companies.",
                "Other observations drawn from Figure 1 are: 1) the bursty period of April is much longer than Easter, which suggests that April may exist in other events during the same period; 2) Unaudited has a higher average DFIDF value than Ended, which indicates Unaudited to be more representative for the underlying event.",
                "These two examples are but the tip of the iceberg among all word trends and correlations hidden in a news stream like Reuters.",
                "If a large number of them can be uncovered, it could significantly aid TDT tasks.",
                "In particular, it indicates the significance of mining correlating features for detecting corresponding events.",
                "To summarize, we postulate that: 1) An event is described by its representative features.",
                "A periodic event has a list of periodic features and an aperiodic event has a list of aperiodic features; 2) Representative features from the same event share similar distributions over time and are highly correlated; 3) An important event has a set of active (largely reported) representative features, whereas an unimportant event has a set of inactive (less-reported) representative features; 4) A feature may be included by several events with overlaps in time frames.",
                "Based on these observations, we can either mine representative features given an event or detect an event from a list of highly correlated features.",
                "In this paper, we focus on the latter, i.e., how correlated features can be uncovered to form an event in an unsupervised manner. 1.1 Contributions This paper has three main contributions: • To the best of our knowledge, our approach is the first to categorize word features for heterogenous events.",
                "Specifically, every word feature is categorized into one of the following five feature types based on its power spectrum strength and periodicity: 1) HH (high power and high/long periodicity): important aperiodic events, 2) HL (high power and low periodicity): important periodic events, 3) LH (low power and high periodicity): unimportant aperiodic events, 4) LL (low power and low periodicity): non-events, and 5) SW (stopwords), a higher power and periodicity subset of LL comprising stopwords, which contains no information. • We propose a simple and effective mixture densitybased approach to model and detect feature bursts. • We come up with an unsupervised event detection algorithm to detect both aperiodic and periodic events.",
                "Our algorithm has been evaluated on a real news stream to show its effectiveness. 2.",
                "RELATED WORK This work is largely motivated by a broader family of problems collectively known as <br>topic detection</br> and Tracking (TDT) [20, 5, 17, 4, 21, 7, 14, 10].",
                "Moreover, most TDT research so far has been concerned with clustering/classifying documents into topic types, identifying novel sentences [6] for new events, etc., without much regard to analyzing the word trajectory with respect to time.",
                "Swan and Allan [18] first attempted using co-occuring terms to construct an event.",
                "However, they only considered named entities and noun phrase pairs, without considering their periodicities.",
                "On the contrary, our paper considers all of the above.",
                "Recently, there has been significant interest in modeling an event in text streams as a burst of activities by incorporating temporal information.",
                "Kleinbergs seminal work described how bursty features can be extracted from text streams using an infinite automaton model [12], which inspired a whole series of applications such as Kumars identification of bursty communities from Weblog graphs [13], Meis summarization of evolutionary themes in text streams [15], Hes clustering of text streams using bursty features [11], etc.",
                "Nevertheless, none of the existing work specifically identified features for events, except for Fung et al. [9], who clustered busty features to identify various bursty events.",
                "Our work differs from [9] in several ways: 1) we analyze every single feature, not only bursty features; 2) we classify features along two categorical dimensions (periodicity and power), yielding altogether five primary feature types; 3) we do not restrict each feature to exclusively belong to only one event.",
                "Spectral analysis techniques have previously been used by Vlachos et al. [19] to identify periodicities and bursts from query logs.",
                "Their focus was on detecting multiple periodicities from the power spectrum graph, which were then used to index words for query-by-burst search.",
                "In this paper, we use spectral analysis to classify word features along two dimensions, namely periodicity and power spectrum, with the ultimate goal of identifying both periodic and aperiodic bursty events. 3.",
                "DATA REPRESENTATION Let T be the duration/period (in days) of a news stream, and F represents the complete word feature space in the classical static Vector Space Model (VSM). 3.1 Event Periodicity Classification Within T, there may exist certain events that occur only once, e.g., Tony Blair elected as Prime Minister of U.K., and other recurring events of various periodicities, e.g., weekly soccer matches.",
                "We thus categorize all events into two types: aperiodic and periodic, defined as follows.",
                "Definition 1. (Aperiodic Event) An event is aperiodic within T if it only happens once.",
                "Definition 2. (Periodic Event) If events of a certain event genre occur regularly with a fixed periodicity P ≤ T/2 , we say that this particular event genre is periodic, with each member event qualified as a periodic event.",
                "Note that the definition of aperiodic is relative, i.e., it is true only for a given T, and may be invalid for any other T > T. For example, the event Christmas feast is aperiodic for T ≤ 365 but periodic for T ≥ 730. 3.2 Representative Features Intuitively, an event can be described very concisely by a few discriminative and representative word features and vice-versa, e.g., hurricane, sweep, and strike could be representative features of a Hurricane genre event.",
                "Likewise, a set of strongly correlated features could be used to reconstruct an event description, assuming that strongly correlated features are representative.",
                "The representation vector of a word feature is defined as follows: Definition 3. (Feature Trajectory) The trajectory of a word feature f can be written as the sequence yf = [yf (1), yf (2), . . . , yf (T)], where each element yf (t) is a measure of feature f at time t, which could be defined using the normalized DFIDF score2 yf (t) = DFf (t) N(t) × log( N DFf ), where DFf (t) is the number of documents (local DF) containing feature f at day t, DFf is the total number of documents (global DF) containing feature f over T, N(t) is the number of documents for day t, and N is the total number of documents over T. 4.",
                "IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 Spectral Analysis for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. DFT can represent the original time series as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T.",
                "The original trajectory can be reconstructed with just the dominant frequencies, which can be determined from the power spectrum using the popular periodogram estimator.",
                "The periodogram is a sequence of the squared magnitude of the Fourier coefficients, Xk 2 , k = 1, 2, . . . , T/2 , which indicates the signal power at frequency k/T in the spectrum.",
                "From the power spectrum, the dominant period is chosen as the inverse of the frequency with the highest power spectrum, as follows.",
                "Definition 4. (Dominant Period) The dominant period (DP) of a given feature f is Pf = T/ arg max k Xk 2 .",
                "Accordingly, we have Definition 5. (Dominant Power Spectrum) The dominant power spectrum (DPS) of a given feature f is Sf = Xk 2 , with Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorizing Features The DPS of a feature trajectory is a strong indicator of its activeness at the specified frequency; the higher the DPS, the more likely for the feature to be bursty.",
                "Combining DPS with DP, we therefore categorize all features into four types: 2 We normalize yf (t) as yf (t) = yf (t)/ T i=1 yf (i) so that it could be interpreted as a probability. • HH: high Sf , aperiodic or long-term periodic (Pf > T/2 ); • HL: high Sf , short-term periodic (Pf ≤ T/2 ); • LH: low Sf , aperiodic or long-term periodic; • LL: low Sf , short-term periodic.",
                "The boundary between long-term and short-term periodic is set to T/2 .",
                "However, distinguishing between a high and low DPS is not straightforward, which will be tackled later.",
                "Properties of Different Feature Sets To better understand the properties of HH, HL, LH and LL, we select four features, Christmas, soccer, DBS and your as illustrative examples.",
                "Since the boundary between high and low power spectrum is unclear, these chosen examples have relative wide range of power spectrum values.",
                "Figure 2(a) shows the DFIDF trajectory for Christmas with a distinct burst around Christmas day.",
                "For the 1-year Reuters dataset, Christmas is classified as a typical aperiodic event with Pf = 365 and Sf = 135.68, as shown in Figure 2(b).",
                "Clearly, the value of Sf = 135.68 is reasonable for a well-known bursty event like Christmas. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Christmas(DFIDF:time) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Christmas(S:frequency) Figure 2: Feature Christmas with relative high Sf and long-term Pf .",
                "The DFIDF trajectory for soccer is shown in Figure 3(a), from which we can observe that there is a regular burst every 7 days, which is again verified by its computed value of Pf = 7, as shown in Figure 3(b).",
                "Using the domain knowledge that soccer games have more matches every Saturday, which makes it a typical and heavily reported periodic event, we thus consider the value of Sf = 155.13 to be high. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) soccer(DFIDF:time) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) soccer(S:frequency) Figure 3: Feature soccer with relative high Sf and short-term Pf .",
                "From the DFIDF trajectory for DBS in Figure 4(a), we can immediately deduce DBS to be an infrequent word with a trivial burst on 08/17/1997 corresponding to DBS Land Raﬄes Holdings plans.",
                "This is confirmed by the long period of Pf = 365 and low power of Sf = 0.3084 as shown in Figure 4(b).",
                "Moreover, since this aperiodic event is only reported in a few news stories over a very short time of few days, we therefore say that its low power value of Sf = 0.3084 is representative of unimportant events.",
                "The most confusing example is shown in Figure 5 for the word feature your, which looks very similar to the graph for soccer in Figure 3.",
                "At first glance, we may be tempted to group both your and soccer into the same category of HL or LL since both distributions look similar and have the same dominant period of approximately a week.",
                "However, further 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:time) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frequency) Figure 4: Feature DBS with relative low Sf and long-term Pf . analysis indicates that the periodicity of your is due to the differences in document counts for weekdays (average 2,919 per day) and weekends3 (average 479 per day).",
                "One would have expected the periodicity of a stopword like your to be a day.",
                "Moreover, despite our DFIDF normalization, the weekday/weekend imbalance still prevailed; stopwords occur 4 times more frequently on weekends than on weekdays.",
                "Thus, the DPS remains the only distinguishing factor between your (Sf = 9.42) and soccer (Sf = 155.13).",
                "However, it is very dangerous to simply conclude that a power value of S = 9.42 corresponds to a stopword feature. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) your(DFIDF:time) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) your(S:frequency) Figure 5: Feature your as an example confusing with feature soccer.",
                "Before introducing our solution to this problem, lets look at another LL example as shown in Figure 6 for beenb, which is actually a confirmed typo.",
                "We therefore classify beenb as a noisy feature that does not contribute to any event.",
                "Clearly, the trajectory of your is very different from beenb, which means that the former has to be considered separately. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figure 6: Feature beenb with relative low Sf and short-term Pf .",
                "Stop Words (SW) Feature Set Based on the above analysis, we realize that there must be another feature set between HL and LL that corresponds to the set of stopwords.",
                "Features from this set has moderate DPS and low but known dominant period.",
                "Since it is hard to distinguish this feature set from HL and LL only based on DPS, we introduce another factor called average DFIDF (DFIDF).",
                "As shown in Figure 5, features like your usually have a lower DPS than a HL feature like soccer, but have a much higher DFIDF than another LL noisy feature such as beenb.",
                "Since such properties are usually characteristics of stopwords, we group features like your into the newly defined stopword (SW) feature set.",
                "Since setting the DPS and DFIDF thresholds for identifying stopwords is more of an art than science, we proposed a heuristic HS algorithm, Algorithm 1.",
                "The basic idea is to only use news stories from weekdays to identify stopwords. 3 The weekends here also include public holidays falling on weekdays.",
                "The SW set is initially seeded with a small set of 29 popular stopwords utilized by Google search engine.",
                "Algorithm 1 Heuristic Stopwords detection (HS) Input: Seed SW set, weekday trajectories of all words 1: From the seed set SW, compute the maximum DPS as UDPS, maximum DFIDF as UDFIDF, and minimum of DFIDF as LDFIDF. 2: for fi ∈ F do 3: Compute DFT for fi. 4: if Sfi ≤ UDPS and DFIDFfi ∈ [LDFIDF, UDFIDF] then 5: fi → SW 6: F = F − fi 7: end if 8: end for Overview of Feature Categorization After the SW set is generated, all stopwords are removed from F. We then set the boundary between high and low DPS to be the upper bound of the SW sets DPS.",
                "An overview of all five feature sets is shown in Figure 7.",
                "Figure 7: The 5 feature sets for events. 5.",
                "IDENTIFYING BURSTS FOR FEATURES Since only features from HH, HL and LH are meaningful and could potentially be representative to some events, we pruned all other feature classified as LL or SW.",
                "In this section, we describe how bursts can be identified from the remaining features.",
                "Unlike Kleinbergs burst identification algorithm [12], we can identify both significant and trivial bursts without the need to set any parameters. 5.1 Detecting Aperiodic Features Bursts For each feature in HH and HL, we truncate its trajectory by keeping only the bursty period, which is modeled with a Gaussian distribution.",
                "For example, Figure 8 shows the word feature Iraq with a burst circa 09/06/1996 being modeled as a Gaussian.",
                "Its bursty period is defined by [μf − σf , μf + σf ] as shown in Figure 8(b). 5.2 Detecting Periodic Features Bursts Since we have computed the DP for a periodic feature f, we can easily model its periodic feature trajectory yf using 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) original DFIDF:time 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 burst= [μ-σ, μ+σ] (b) identifying burst Figure 8: Modeling Iraqs time series as a truncated Gaussian with μ = 09/06/1996 and σ = 6.26. a mixture of K = T/Pf Gaussians: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , where the parameter set θf = {αk, μk, σk}K k=1 comprises: • αk is the probability of assigning yf into the kth Gaussian. αk > 0, ∀k ∈ [1, K] and K k=1 αk = 1; • μk/σk is mean/standard deviation of the kth Gaussian.",
                "The well known Expectation Maximization (EM) [8] algorithm is used to compute the mixing proportions αk, as well as the individual Gaussian density parameters μk and σK .",
                "Each Gaussian represents one periodic event, and is modeled similarly as mentioned in Section 5.1. 6.",
                "EVENTS FROM FEATURES After identifying and modeling bursts for all features, the next task is to paint a picture of the event with a potential set of representative features. 6.1 Feature Correlation If two features fi and fj are representative of the same event, they must satisfy the following necessary conditions: 1. fi and fj are identically distributed: yfi ∼ yfj . 2. fi and fj have a high document overlap.",
                "Measuring Feature Distribution Similarity We measure the similarity between two features fi and fj using discrete KL-divergence defined as follows.",
                "Definition 6. (feature similarity) KL(fi, fj ) is given by max(KL(fi|fj ), KL(fj |fi)), where KL(fi|fj ) = T t=1 f(yfi (t)|θfi )log f(yfi (t)|θfi ) f(yfj (t)|θfj ) . (1) Since KL-divergence is not symmetric, we define the similarity between between fi and fj as the maximum of KL(fi|fj ) and KL(fj |fi).",
                "Further, the similarity between two aperiodic features can be computed using a closed form of the KL-divergence [16].",
                "The same discrete KL-divergence formula of Eq. 1 is employed to compute the similarity between two periodic features, Next, we define the overal similarity among a set of features R using the maximum inter-feature KL-Divergence value as follows.",
                "Definition 7. (sets similarity)KL(R) = max ∀fi,fj ∈R KL(fi, fj ).",
                "Document Overlap Let Mi be the set of all documents containing feature fi.",
                "Given two features fi and fj , the overlapping document set containing both features is Mi ∩ Mj .",
                "Intuitively, the higher the |Mi ∩ Mj |, the more likelty that fi and fj will be highly correlated.",
                "We define the degree of document overlap between two features fi and fj as follows.",
                "Definition 8. (Feature DF Overlap) d(fi, fj ) = |Mi∩Mj| min(|Mi|,|Mj|) .",
                "Accordingly, the DF Overlap among a set of features R is also defined.",
                "Definition 9. (Set DF Overlap) d(R) = min ∀fi,fj ∈R d(fi, fj). 6.2 Unsupervised Greedy Event Detection We use features from HH to detect important aperiodic events, features from LH to detect less-reported/unimportant aperiodic events, and features from HL to detect periodic events.",
                "All of them share the same algorithm.",
                "Given bursty feature fi ∈ HH, the goal is to find highly correlated features from HH.",
                "The set of features similar to fi can then collectively describe an event.",
                "Specifically, we need to find a subset Ri of HH that minimizes the following cost function: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) The underlying event e (associated with the burst of fi) can be represented by Ri as y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) The burst analysis for event e is exactly the same as the feature trajectory.",
                "The cost in Eq. 2 can be minimized using our unsupervised greedy UG event detection algorithm, which is described in Algorithm 2.",
                "The UG algorithm allows a feature Algorithm 2 Unsupervised Greedy event detection (UG).",
                "Input: HH, document index for each feature. 1: Sort and select features in descending DPS order: Sf1 ≥ Sf2 ≥ . . . ≥ Sf|HH| . 2: k = 0. 3: for fi ∈ HH do 4: k = k + 1. 5: Init: Ri ← fi, C(Ri) = 1/Sfi and HH = HH − fi. 6: while HH not empty do 7: m = arg min m C(Ri ∪ fm). 8: if C(Ri ∪ fm) < C(Ri) then 9: Ri ← fm and HH = HH − fm. 10: else 11: break while. 12: end if 13: end while 14: Output ek as Eq. 3. 15: end for to be contained in multiple events so that we can detect several events happening at the same time.",
                "Furthermore, trivial events only containing year/month features (i.e., an event only containing 1 feature Aug could be identified over a 1year news stream) could be removed, although such events will have inherent high cost and should already be ranked very low.",
                "Note that our UG algorithm only requires one data-dependant parameter, the boundary between high and low power spectrum, to be set once, and this parameter can be easily estimated using the HS algorithm (Algorithm 1). 7.",
                "EXPERIMENTS In this section, we study the performances of our feature categorizing method and event detection algorithm.",
                "We first introduce the dataset and experimental setup, then we subjectively evaluate the categorization of features for HH, HL, LH, LL and SW.",
                "Finally, we study the (a)periodic event detection problem with Algorithm 2. 7.1 Dataset and Experimental Setup The Reuters Corpus contains 806,791 English news stories from 08/20/1996 to 08/19/1997 at a day resolution.",
                "Version 2 of the open source Lucene software [1] was used to tokenize the news text content and generate the document-word vector.",
                "In order to preserve the time-sensitive past/present/future tenses of verbs and the differences between lower case nouns and upper case named entities, no stemming was done.",
                "Since dynamic stopword removal is one of the functionalities of our method, no stopword was removed.",
                "We did remove nonEnglish characters, however, after which the number of word features amounts to 423,433.",
                "All experiments were implemented in Java and conducted on a 3.2 GHz Pentium 4 PC running Windows 2003 Server with 1 GB of memory. 7.2 Categorizing Features We downloaded 34 well-known stopwords utilized by the Google search engine as our seed training features, which includes a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en and www.",
                "We excluded the last five stopwords as they are uncommon in news stories.",
                "By only analyzing news stories over 259 weekdays, we computed the upper bound of the power spectrum for stopwords at 11.18 and corresponding DFIDF ranges from 0.1182 to 0.3691.",
                "Any feature f satisfying Sf <= 11.18 and 0.1182 <= DFIDFf <= 0.3691 over weekdays will be considered a stopword.",
                "In this manner, 470 stopwords were found and removed as visualized in Figure 9.",
                "Some detected stopwords are A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) and much (P = 22, S = 0.80, DFIDF = 0.1865).",
                "After the removal of these stopwords, the distribution of weekday and weekend news are more or less matched, and in the ensuing experiments, we shall make use of the full corpus (weekdays and weekends).",
                "The upper bound power spectrum value of 11.18 for stopwords training was selected as the boundary between the high power and low power spectrum.",
                "The boundary between high and low periodicity was set to 365/2 = 183.",
                "All 422,963 (423433 − 470) word features were categorized into 4 feature sets: HH (69 features), HL (1,087 features), LH (83,471 features), and LL (338,806 features) as shown in Figure 10.",
                "In Figure 10, each gray level denotes the relative density of features in a square region, measured by log10(1 + Dk), where Dk is the number of features within the k-th square region.",
                "From the figure, we can make the 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figure 9: Distribution of SW (stopwords) in the HH, HL, LH, and LL regions. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figure 10: Distribution of categorized features over the four quadrants (shading in log scale). following observations: 1.",
                "Most features have low S and are easily distinguishable from those features having a much higher S, which allows us to detect important (a)periodic events from trivial events by selecting features with high S. 2.",
                "Features in the HH and LH quadrants are aperiodic, which are nicely separated (big horizontal gap) from the periodic features.",
                "This allows reliably detecting aperiodic events and periodic events independently. 3.",
                "The (vertical) boundary between high and low power spectrum is not as clearcut and the exact value will be application specific.",
                "By checking the scatter distribution of features from SW on HH, HL, LH, and LL as shown in Figure 9, we found that 87.02%(409/470) of the detected stopwords originated from LL.",
                "The LL classification and high DFIDF scores of stopwords agree with the generally accepted notion that stopwords are equally frequent over all time.",
                "Therefore, setting the boundary between high and low power spectrum using the upper bound Sf of SW is a reasonable heuristic. 7.3 Detecting Aperiodic Events We shall evaluate our two hypotheses, 1)important aperiodic events can be defined by a set of HH features, and 2)less reported aperiodic events can be defined by a set of LH features.",
                "Since no benchmark news streams exist for event detection (TDT datasets are not proper streams), we evaluate the quality of the automatically detected events by comparing them to manually-confirmed events by searching through the corpus.",
                "Among the 69 HH features, we detected 17 important aperiodic events as shown in Table 1 (e1 − e17).",
                "Note that the entire identification took less than 1 second, after removing events containing only the month feature.",
                "Among the 17 events, other than the overlaps between e3 and e4 (both describes the same hostage event), e11 and e16 (both about company reports), the 14 identified events are extremely accurate and correspond very well to the major events of the period.",
                "For example, the defeat of Bob Dole, election of Tony Blair, Missile attack on Iraq, etc.",
                "Recall that selecting the features for one event should minimize the cost in Eq. 2 such that 1) the number of features span different events, and 2) not all features relevant to an event will be selected, e.g., the feature Clinton is representative to e12 but since Clinton relates to many other events, its time domain signal is far different from those of other representative features like Dole and Bob.",
                "The number of documents of a detected event is roughly estimated by the number of indexed documents containing the representative features.",
                "We can see that all 17 important aperiodic events are popularly reported events.",
                "After 742 minutes of computation time, we detected 23, 525 less reported aperiodic events from 83,471 LH features.",
                "Table 1 lists the top 5 detected aperiodic events (e18 − e22) with respect to the cost.",
                "We found that these 5 events are actually very trivial events with only a few news reports, and are usually subsumed by some larger topics.",
                "For example, e22 is one of the rescue events in an airplane hijack topic.",
                "One advantage of our UG Algorithm for discovering less-reported aperiodic events is that we are able to precisely detect the true event period. 7.4 Detecting Periodic Events Among the 1,087 HL features, 330 important periodic events were detected within 10 minutes of computing time.",
                "Table 1 lists the top 5 detected periodic events with respect to the cost (e23 − e27).",
                "All of the detected periodic events are indeed valid, and correspond to real life periodic events.",
                "The GMM model is able to detect and estimate the bursty period nicely although it cannot distinguish the slight difference between every Monday-Friday and all weekdays as shown in e23.",
                "We also notice that e26 is actually a subset of e27 (soccer game), which is acceptable since the Sheffield league results are announced independently every weekend. 8.",
                "CONCLUSIONS This paper took a whole new perspective of analyzing feature trajectories as time domain signals.",
                "By considering the word document frequencies in both time and frequency domains, we were able to derive many new characteristics about news streams that were previously unknown, e.g., the different distributions of stopwords during weekdays and weekends.",
                "For the first time in the area of TDT, we applied a systematic approach to automatically detect important and less-reported, periodic and aperiodic events.",
                "The key idea of our work lies in the observations that (a)periodic events have (a)periodic representative features and (un)important events have (in)active representative features, differentiated by their power spectrums and time periods.",
                "To address the real event detection problem, a simple and effective mixture density-based approach was used to identify feature bursts and their associated bursty periods.",
                "We also designed an unsupervised greedy algorithm to detect both aperiodic and periodic events, which was successful in detecting real events as shown in the evaluation on a real news stream.",
                "Although we have not made any benchmark comparison against another approach, simply because there is no previous work in the addressed problem.",
                "Future work includes evaluating the recall of detected events for a labeled news stream, and comparing our model against the closest equivalent methods, which currently are limited to the methods of Kleinberg [12] (which can only detect certain type of bursty events depending on parameter settings), Fung et al. [9], and Swan and Allan [18].",
                "Nevertheless, we believe our simple and effective method will be useful for all TDT practitioners, and will be especially useful for the initial exploratory analysis of news streams. 9.",
                "REFERENCES [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Google news alerts, http://www.google.com/alerts. [3] Reuters corpus, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan.",
                "<br>topic detection</br> and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, and H. Jin.",
                "First story detection in tdt is hard.",
                "In CIKM, pages 374-381, 2000. [6] J. Allan, C. Wade, and A. Bolivar.",
                "Retrieval and novelty detection at the sentence level.",
                "In SIGIR, pages 314-321, 2003. [7] T. Brants, F. Chen, and A. Farahat.",
                "A system for new event detection.",
                "In SIGIR, pages 330-337, 2003. [8] A. P. Dempster, N. M. Laird, and D. B. Rubin.",
                "Maximum likelihood from incomplete data via the EM algorithm.",
                "Journal of the Royal Statistical Society, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu, and H. Lu.",
                "Parameter free bursty events detection in text streams.",
                "In VLDB, pages 181-192, 2005. [10] Q.",
                "He, K. Chang, and E.-P. Lim.",
                "A model for anticipatory event detection.",
                "In ER, pages 168-181, 2006. [11] Q.",
                "He, K. Chang, E.-P. Lim, and J. Zhang.",
                "Bursty feature reprensentation for clustering text streams.",
                "In SDM, accepted, 2007. [12] J. Kleinberg.",
                "Bursty and hierarchical structure in streams.",
                "In SIGKDD, pages 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins.",
                "On the bursty evolution of blogspace.",
                "In WWW, pages 159-178, 2005. [14] G. Kumaran and J. Allan.",
                "Text classification and named entities for new event detection.",
                "In SIGIR, pages 297-304, 2004. [15] Q. Mei and C. Zhai.",
                "Discovering evolutionary theme patterns from text: an exploration of temporal text mining.",
                "In SIGKDD, pages 198-207, 2005. [16] W. D. Penny.",
                "Kullback-liebler divergences of normal, gamma, dirichlet and wishart densities.",
                "Technical report, 2001. [17] N. Stokes and J. Carthy.",
                "Combining semantic and syntactic document classifiers to improve first story detection.",
                "In SIGIR, pages 424-425, 2001. [18] R. Swan and J. Allan.",
                "Automatic generation of overview timelines.",
                "In SIGIR, pages 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena, and D. Gunopulos.",
                "Identifying similarities, periodicities and bursts for online search queries.",
                "In SIGMOD, pages 131-142, 2004. [20] Y. Yang, T. Pierce, and J. Carbonell.",
                "A study of retrospective and on-line event detection.",
                "In SIGIR, pages 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topic-conditioned novelty detection.",
                "In SIGKDD, pages 688-693, 2002.",
                "Table 1: All important aperiodic events (e1 − e17), top 5 less-reported aperiodic events (e18 − e22) and top 5 important periodic events (e23 − e27).",
                "Detected Event and Bursty Period Doc # True Event e1(Sali,Berisha,Albania,Albanian,March) 02/02/199705/29/1997 1409 Albanians president Sali Berisha lost in an early election and resigned, 12/1996-07/1997. e2(Seko,Mobutu,Sese,Kabila) 03/22/1997-06/09/1997 2273 Zaires president Mobutu Sese coordinated the native rebellion and failed on 05/16/1997. e3(Marxist,Peruvian) 11/19/1996-03/05/1997 824 Peru rebels (Tupac Amaru revolutionary Movement) led a hostage siege in Lima in early 1997. e4(Movement,Tupac,Amaru,Lima,hostage,hostages) 11/16/1996-03/20/1997 824 The same as e3. e5(Kinshasa,Kabila,Laurent,Congo) 03/26/199706/15/1997 1378 Zaire was renamed the Democratic Republic of Congo on 05/16/1997. e6(Jospin,Lionel,June) 05/10/1997-07/09/1997 605 Following the early General Elections circa 06/1997, Lionel Jospin was appointed Prime Minister on 06/02/1997. e7(Iraq,missile) 08/31/1996-09/13/1996 1262 U.S. fired missile at Iraq on 09/03/1996 and 09/04/1996. e8(Kurdish,Baghdad,Iraqi) 08/29/1996-09/09/1996 1132 Iraqi troop fought with Kurdish faction circa 09/1996. e9(May,Blair) 03/24/1997-07/04/1997 1049 Tony Blair became the Primary Minister of the United Kingdom on 05/02/1997. e10(slalom,skiing) 12/05/1996-03/21/1997 253 Slalom Game of Alpine Skiing in 01/1997-02/1997. e11(Interim,months) 09/24/1996-12/31/1996 3063 Tokyo released company interim results for the past several months in 09/1996-12/1996. e12(Dole,Bob) 09/09/1996-11/24/1996 1599 Dole Bob lost the 1996 US presidential election. e13(July,Sen) 06/25/1997-06/25/1997 344 Cambodias Prime Minister Hun Sen launched a bloody military coup in 07/1997. e14(Hebron) 10/15/1996-02/14/1997 2098 Hebron was divided into two sectors in early 1997. e15(April,Easter) 02/23/1997-05/04/1997 480 Easter feasts circa 04/1997 (for western and Orthodox). e16(Diluted,Group) 04/27/1997-07/20/1997 1888 Tokyo released all 96/97 group results in 04/199707/1997. e17(December,Christmas) 11/17/1996-01/26/1997 1326 Christmas feast in late 12/1997. e18(Kolaceva,winter,Together,promenades,Zajedno, Slobodan,Belgrade,Serbian,Serbia,Draskovic,municipal, Kragujevac) 1/25/1997 3 University students organized a vigil on Kolaceva street against government on 1/25/1997. e19(Tutsi,Luvengi,Burundi,Uvira,fuel,Banyamulenge, Burundian,Kivu,Kiliba,Runingo,Kagunga,Bwegera) 10/19/1996 6 Fresh fighting erupted around Uvira between Zaire armed forces and Banyamulengs Tutsi rebels on 10/19/1996. e20(Malantacchi,Korea,Guy,Rider,Unions,labour, Trade,unions,Confederation,rammed,Geneva,stoppages, Virgin,hire,Myongdong,Metalworkers) 1/11/1997 2 Marcello Malantacchi secretary general of the International Metalworkers Federation and Guy Rider who heads the Geneva office of the International Confederation of Free Trade Unions attacked the new labour law of South Korea on 1/11/1997. e21(DBS,Raﬄes) 8/17/1997 9 The list of the unit of Singapore DBS Land Raﬄes Holdings plans on 8/17/1997. e22(preserver,fuel,Galawa,Huddle,Leul,Beausse) 11/24/1996 3 Rescued a woman and her baby during a hijacked Ethiopian plane that ran out of fuel and crashed into the sea near Le Galawa beach on 11/24/1996. e23(PRICE,LISTING,MLN,MATURITY,COUPON, MOODY,AMT,FIRST,ISS,TYPE,PAY,BORROWER) Monday-Friday/week 7966 Announce bond price on all weekdays. e24(Unaudited,Ended,Months,Weighted,Provision,Cost, Selling,Revenues,Loss,Income,except,Shrs,Revs) every season 2264 Net income-loss reports released by companies in every season. e25(rating,Wall,Street,Ian) Monday-Friday/week 21767 Stock reports from Wall Street on all weekdays. e26(Sheffield,league,scoring,goals,striker,games) every Friday, Saturday and Sunday 574 Match results of Sheffield soccer league were published on Friday, Saturday and Sunday 10 times than other 4 days. e27(soccer,matches,Results,season,game,Cup,match, victory,beat,played,play,division) every Friday, Saturday and Sunday 2396 Soccer games held on Friday, Saturday and Sunday 7 times than other 4 days."
            ],
            "original_annotated_samples": [
                "In fact, the <br>topic detection</br> and tracking (TDT) community has for many years been trying to come up with a practical solution to help people monitor news effectively.",
                "RELATED WORK This work is largely motivated by a broader family of problems collectively known as <br>topic detection</br> and Tracking (TDT) [20, 5, 17, 4, 21, 7, 14, 10].",
                "<br>topic detection</br> and Tracking."
            ],
            "translated_annotated_samples": [
                "De hecho, la comunidad de <br>detección y seguimiento de temas</br> (TDT) ha estado tratando durante muchos años de encontrar una solución práctica para ayudar a las personas a monitorear las noticias de manera efectiva.",
                "TRABAJO RELACIONADO Este trabajo está motivado en gran medida por una familia más amplia de problemas conocidos colectivamente como <br>Detección y Seguimiento de Temas</br> (TDT) [20, 5, 17, 4, 21, 7, 14, 10].",
                "Detección y seguimiento de temas."
            ],
            "translated_text": "Analizando Trayectorias de Características para la Detección de Eventos Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg Escuela de Ingeniería Informática Universidad Tecnológica de Nanyang Bloque N4, Avenida Nanyang, Singapur 639798 RESUMEN Consideramos el problema de analizar trayectorias de palabras en los dominios del tiempo y la frecuencia, con el objetivo específico de identificar palabras importantes y menos reportadas, periódicas y aperiódicas. Un conjunto de palabras con tendencias idénticas puede agruparse para reconstruir un evento de manera completamente no supervisada. La frecuencia del documento de cada palabra a lo largo del tiempo se trata como una serie temporal, donde cada elemento es el puntaje de frecuencia del documento - frecuencia inversa del documento (DFIDF) en un punto temporal. En este artículo, 1) primero aplicamos análisis espectral para categorizar características de diferentes tipos de eventos: importantes y poco reportados, periódicos y aperiódicos; 2) modelamos las características aperiódicas con densidad gaussiana y las características periódicas con densidades de mezcla gaussiana, y posteriormente detectamos cada ráfaga de características mediante el enfoque gaussiano truncado; 3) propusimos un algoritmo de detección de eventos codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos. Todos los métodos anteriores se pueden aplicar a datos de series temporales en general. Evaluamos exhaustivamente nuestros métodos en el Corpus de Noticias de Reuters de 1 año [3] y demostramos que fueron capaces de descubrir eventos significativos aperiódicos y periódicos. Categorías y Descriptores de Asignaturas: H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales: Algoritmos, Experimentación. 1. INTRODUCCIÓN Hay más de 4,000 fuentes de noticias en línea en el mundo. Supervisar manualmente todos ellos en busca de eventos importantes se ha vuelto difícil o prácticamente imposible. De hecho, la comunidad de <br>detección y seguimiento de temas</br> (TDT) ha estado tratando durante muchos años de encontrar una solución práctica para ayudar a las personas a monitorear las noticias de manera efectiva. Desafortunadamente, el Santo Grial sigue siendo esquivo, ya que la gran mayoría de las soluciones de TDT propuestas para la detección de eventos [20, 5, 17, 4, 21, 7, 14, 10] son demasiado simplistas (basadas en la similitud del coseno [5]) o impracticables debido a la necesidad de ajustar un gran número de parámetros [9]. La ineficacia de las tecnologías actuales de TDT se puede ilustrar fácilmente suscribiéndose a cualquiera de los muchos servicios de alertas de noticias en línea, como el líder de la industria Google News Alerts, que genera más del 50% de falsas alarmas. Como prueba adicional, portales como Yahoo adoptan un enfoque más pragmático al requerir que todas las alertas de noticias generadas por máquinas pasen por un operador humano para su confirmación antes de enviarlas a los suscriptores. En lugar de abordar el problema con variaciones del mismo martillo (similitud coseno y TFIDF), es necesario contar con una comprensión fundamental de las características de los datos de flujo de noticias antes de que se puedan lograr avances importantes en TDT. Por lo tanto, en este artículo, examinamos noticias y tendencias de características desde la perspectiva de analizar una señal de palabras de series temporales. Trabajos anteriores como [9] han intentado reconstruir un evento con sus características representativas. Sin embargo, en muchas tareas de detección de eventos predictivos (es decir, detección de eventos retrospectivos), hay un vasto conjunto de características potenciales solo para un conjunto fijo de observaciones (es decir, los estallidos obvios). De estas características, a menudo solo se espera que un pequeño número sea útil. En particular, estudiamos el novedoso problema de analizar trayectorias de características para la detección de eventos, utilizando una técnica conocida de procesamiento de señales: identificar correlaciones distribucionales entre todas las características mediante análisis espectral. Para evaluar nuestro método, posteriormente proponemos un algoritmo de detección de eventos no supervisado para flujos de noticias. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Pascua Abril (a) evento aperiódico 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 No auditado Finalizado (b) evento periódico Figura 1: Correlación de características (DFIDF:tiempo) entre a) Pascua y Abril b) No auditado y Finalizado. Como ejemplo ilustrativo, considera la correlación entre las palabras Pascua y abril del Corpus de Reuters. A partir del gráfico de su DFIDF normalizado en la Figura 1(a), observamos la gran superposición entre las dos palabras alrededor de 04/1997, lo que significa que probablemente ambas pertenecen al mismo evento durante ese tiempo (festividad de Pascua). En este ejemplo, el evento oculto de la festividad de Pascua es un evento aperiódico típico e importante en datos de 1 año. Otro ejemplo se muestra en la Figura 1(b), donde las palabras \"No auditado\" y \"Finalizado 1\" del Corpus de Reuters son el conjunto de datos predeterminado para todos los ejemplos y presentan un comportamiento similar durante períodos de 3 meses. Estas dos palabras en realidad se originaron a partir del mismo evento periódico, informes de ganancias y pérdidas, que son publicados trimestralmente por empresas cotizadas en bolsa. Otras observaciones extraídas de la Figura 1 son: 1) el período de actividad intensa de abril es mucho más largo que el de Semana Santa, lo que sugiere que abril puede estar presente en otros eventos durante el mismo período; 2) No auditado tiene un valor promedio de DFIDF más alto que Finalizado, lo que indica que No auditado es más representativo para el evento subyacente. Estos dos ejemplos son solo la punta del iceberg entre todas las tendencias de palabras y correlaciones ocultas en un flujo de noticias como Reuters. Si se puede descubrir un gran número de ellos, podría ayudar significativamente en las tareas de TDT. En particular, indica la importancia de extraer características correlacionadas para detectar eventos correspondientes. Para resumir, postulamos que: 1) Un evento se describe por sus características representativas. Un evento periódico tiene una lista de características periódicas y un evento aperiódico tiene una lista de características aperiódicas; 2) Las características representativas del mismo evento comparten distribuciones similares en el tiempo y están altamente correlacionadas; 3) Un evento importante tiene un conjunto de características representativas activas (ampliamente reportadas), mientras que un evento no importante tiene un conjunto de características representativas inactivas (menos reportadas); 4) Una característica puede ser incluida por varios eventos con superposiciones en los marcos de tiempo. Basándonos en estas observaciones, podemos extraer características representativas dadas un evento o detectar un evento a partir de una lista de características altamente correlacionadas. En este artículo, nos enfocamos en este último aspecto, es decir, cómo se pueden descubrir características correlacionadas para formar un evento de manera no supervisada. 1.1 Contribuciones Este artículo tiene tres contribuciones principales: • Hasta donde sabemos, nuestro enfoque es el primero en categorizar características de palabras para eventos heterogéneos. Específicamente, cada característica de palabra se clasifica en uno de los siguientes cinco tipos de características basados en la fuerza de su espectro de potencia y periodicidad: 1) HH (alta potencia y alta/larga periodicidad): eventos aperiódicos importantes, 2) HL (alta potencia y baja periodicidad): eventos periódicos importantes, 3) LH (baja potencia y alta periodicidad): eventos aperiódicos no importantes, 4) LL (baja potencia y baja periodicidad): no eventos, y 5) SW (palabras vacías), un subconjunto de LL con mayor potencia y periodicidad que comprende palabras vacías, que no contienen información. • Proponemos un enfoque simple y efectivo basado en densidad de mezcla para modelar y detectar ráfagas de características. • Presentamos un algoritmo de detección de eventos no supervisado para detectar eventos tanto aperiódicos como periódicos. Nuestro algoritmo ha sido evaluado en un flujo de noticias reales para demostrar su efectividad. 2. TRABAJO RELACIONADO Este trabajo está motivado en gran medida por una familia más amplia de problemas conocidos colectivamente como <br>Detección y Seguimiento de Temas</br> (TDT) [20, 5, 17, 4, 21, 7, 14, 10]. Además, la mayoría de las investigaciones de TDT hasta ahora se han centrado en agrupar/clasificar documentos en tipos de temas, identificar oraciones novedosas para eventos nuevos, etc., sin prestar mucha atención al análisis de la trayectoria de las palabras con respecto al tiempo. Swan y Allan [18] intentaron por primera vez usar términos que co-ocurren para construir un evento. Sin embargo, solo consideraron entidades nombradas y pares de frases nominales, sin tener en cuenta sus periodicidades. Por el contrario, nuestro artículo considera todo lo anterior. Recientemente, ha habido un gran interés en modelar un evento en flujos de texto como un estallido de actividades al incorporar información temporal. El trabajo seminal de Kleinberg describió cómo se pueden extraer características explosivas de flujos de texto utilizando un modelo de autómata infinito [12], lo que inspiró toda una serie de aplicaciones como la identificación de comunidades explosivas de Kumar a partir de gráficos de blogs [13], la sumarización de temas evolutivos en flujos de texto de Meis [15], el agrupamiento de flujos de texto utilizando características explosivas de Hes [11], etc. Sin embargo, ninguno de los trabajos existentes identificó específicamente características para eventos, excepto Fung et al. [9], quienes agruparon características llamativas para identificar varios eventos llamativos. Nuestro trabajo difiere de [9] en varias formas: 1) analizamos cada característica individual, no solo las características explosivas; 2) clasificamos las características a lo largo de dos dimensiones categóricas (periodicidad y potencia), dando en total cinco tipos de características principales; 3) no restringimos que cada característica pertenezca exclusivamente a un solo evento. Las técnicas de análisis espectral han sido utilizadas previamente por Vlachos et al. [19] para identificar periodicidades y ráfagas en los registros de consultas. Su enfoque estaba en detectar múltiples periodicidades a partir del gráfico del espectro de potencia, las cuales luego se utilizaron para indexar palabras para la búsqueda por ráfagas. En este artículo, utilizamos análisis espectral para clasificar las características de las palabras a lo largo de dos dimensiones, a saber, periodicidad y espectro de potencia, con el objetivo final de identificar eventos tanto periódicos como no periódicos y explosivos. 3. REPRESENTACIÓN DE DATOS Sea T la duración/período (en días) de un flujo de noticias, y F representa el espacio de características de palabras completo en el Modelo de Espacio Vectorial (VSM) estático clásico. 3.1 Clasificación de Periodicidad de Eventos Dentro de T, pueden existir ciertos eventos que ocurren solo una vez, por ejemplo, la elección de Tony Blair como Primer Ministro del Reino Unido, y otros eventos recurrentes de diversas periodicidades, por ejemplo, partidos de fútbol semanales. Por lo tanto, categorizamos todos los eventos en dos tipos: aperiódicos y periódicos, definidos de la siguiente manera. Definición 1. (Evento aperiódico) Un evento es aperiódico dentro de T si solo ocurre una vez. Definición 2. (Evento periódico) Si los eventos de un cierto género de eventos ocurren regularmente con una periodicidad fija P ≤ T/2, decimos que este género particular de eventos es periódico, y cada evento miembro se califica como un evento periódico. Ten en cuenta que la definición de aperiódico es relativa, es decir, es verdadera solo para un T dado y puede ser inválida para cualquier otro T > T. Por ejemplo, el evento de la fiesta de Navidad es aperiódico para T ≤ 365 pero periódico para T ≥ 730. 3.2 Características Representativas Intuitivamente, un evento puede ser descrito de manera muy concisa por unas pocas características de palabras discriminativas y representativas y viceversa, por ejemplo, huracán, barrido y golpe podrían ser características representativas de un evento del género de huracanes. Asimismo, un conjunto de características fuertemente correlacionadas podría ser utilizado para reconstruir una descripción de un evento, asumiendo que las características fuertemente correlacionadas son representativas. El vector de representación de una característica de palabra se define de la siguiente manera: Definición 3. (Trayectoria de la Característica) La trayectoria de una característica de palabra f puede escribirse como la secuencia yf = [yf (1), yf (2), . . . , yf (T)], donde cada elemento yf (t) es una medida de la característica f en el tiempo t, que podría definirse utilizando la puntuación normalizada DFIDF yf (t) = DFf (t) N(t) × log( N DFf ), donde DFf (t) es el número de documentos (DF local) que contienen la característica f en el día t, DFf es el número total de documentos (DF global) que contienen la característica f en T, N(t) es el número de documentos para el día t, y N es el número total de documentos en T. 4. En esta sección, mostramos cómo se pueden extraer características representativas para eventos (poco) importantes o (a)periódicos. 4.1 Análisis Espectral para el Período Dominante Dada una característica f, descomponemos su trayectoria de características yf = [yf (1), yf (2), ..., yf (T)] en la secuencia de T números complejos [X1, . . . , XT ] a través de la transformada discreta de Fourier (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. La DFT puede representar la serie temporal original como una combinación lineal de sinusoides complejas, lo cual se ilustra mediante la transformada discreta de Fourier inversa (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, donde el coeficiente de Fourier Xk denota la amplitud del sinusoides con frecuencia k/T. La trayectoria original puede ser reconstruida con solo las frecuencias dominantes, las cuales pueden ser determinadas a partir del espectro de potencia utilizando el popular estimador periodograma. El periodograma es una secuencia de la magnitud al cuadrado de los coeficientes de Fourier, Xk^2, k = 1, 2, . . . , T/2, que indica la potencia de la señal en la frecuencia k/T en el espectro. A partir del espectro de potencia, se elige el período dominante como el inverso de la frecuencia con el espectro de potencia más alto, de la siguiente manera. Definición 4. (Período Dominante) El período dominante (DP) de una característica dada f es Pf = T/ arg max k Xk 2. Por lo tanto, tenemos la Definición 5. (Espectro de Potencia Dominante) El espectro de potencia dominante (DPS) de una característica dada f es Sf = Xk 2 , con Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorización de Características El DPS de una trayectoria de características es un indicador fuerte de su actividad en la frecuencia especificada; cuanto mayor sea el DPS, es más probable que la característica sea explosiva. Al combinar DPS con DP, categorizamos todas las características en cuatro tipos: 2 Normalizamos yf (t) como yf (t) = yf (t)/ T i=1 yf (i) para que pueda interpretarse como una probabilidad. • HH: alta Sf, aperiódico o periódico a largo plazo (Pf > T/2); • HL: alta Sf, periódico a corto plazo (Pf ≤ T/2); • LH: baja Sf, aperiódico o periódico a largo plazo; • LL: baja Sf, periódico a corto plazo. La frontera entre los periodos a largo plazo y a corto plazo se establece en T/2. Sin embargo, distinguir entre un DPS alto y bajo no es sencillo, lo cual se abordará más adelante. Propiedades de diferentes conjuntos de características Para comprender mejor las propiedades de HH, HL, LH y LL, seleccionamos cuatro características, Navidad, fútbol, DBS y tu como ejemplos ilustrativos. Dado que la frontera entre el espectro de alta y baja potencia no está clara, estos ejemplos seleccionados tienen un rango relativo amplio de valores de espectro de potencia. La figura 2(a) muestra la trayectoria de DFIDF para la Navidad con un pico distintivo alrededor del día de Navidad. Para el conjunto de datos de Reuters de 1 año, la Navidad se clasifica como un evento aperiódico típico con Pf = 365 y Sf = 135.68, como se muestra en la Figura 2(b). Claramente, el valor de Sf = 135.68 es razonable para un evento conocido por ser intermitente como la Navidad. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Navidad(DFIDF:tiempo) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Navidad(S:frecuencia) Figura 2: Característica Navidad con un Sf relativamente alto y un Pf a largo plazo. La trayectoria de DFIDF para el fútbol se muestra en la Figura 3(a), de la cual podemos observar que hay un estallido regular cada 7 días, lo cual es nuevamente verificado por su valor calculado de Pf = 7, como se muestra en la Figura 3(b). Usando el conocimiento del dominio de que los partidos de fútbol tienen más encuentros cada sábado, lo que lo convierte en un evento periódico típico y ampliamente reportado, consideramos que el valor de Sf = 155.13 es alto. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) fútbol (DFIDF:tiempo) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) fútbol (S:frecuencia) Figura 3: Característica fútbol con un Sf relativamente alto y un Pf a corto plazo. A partir de la trayectoria de DFIDF para DBS en la Figura 4(a), podemos deducir de inmediato que DBS es una palabra poco frecuente con un aumento trivial el 17/08/1997 correspondiente a los planes de DBS Land Raﬄes Holdings. Esto se confirma por el largo período de Pf = 365 y la baja potencia de Sf = 0.3084 como se muestra en la Figura 4(b). Además, dado que este evento aperiódico solo se informa en algunas noticias durante un corto período de unos pocos días, por lo tanto, decimos que su bajo valor de potencia de Sf = 0.3084 es representativo de eventos poco importantes. El ejemplo más confuso se muestra en la Figura 5 para la palabra \"your\", que se ve muy similar al gráfico para fútbol en la Figura 3. A primera vista, podríamos sentirnos tentados a agrupar tanto tu como el fútbol en la misma categoría de HL o LL, ya que ambas distribuciones se ven similares y tienen el mismo período dominante de aproximadamente una semana. Sin embargo, más adelante 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:tiempo) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frecuencia) Figura 4: Característica DBS con Sf relativamente bajo y Pf a largo plazo. El análisis indica que la periodicidad de su es debido a las diferencias en el recuento de documentos para los días de la semana (promedio de 2,919 por día) y los fines de semana (promedio de 479 por día). Uno habría esperado que la periodicidad de una palabra vacía como \"tu\" fuera de un día. Además, a pesar de nuestra normalización de DFIDF, el desequilibrio entre los días de la semana y los fines de semana aún prevalecía; las palabras vacías ocurren 4 veces más frecuentemente los fines de semana que los días de semana. Por lo tanto, el DPS sigue siendo el único factor distintivo entre tu (Sf = 9.42) y el fútbol (Sf = 155.13). Sin embargo, es muy peligroso concluir simplemente que un valor de potencia de S = 9.42 corresponde a una característica de palabra vacía. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) tu(DFIDF:tiempo) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) tu(S:frecuencia) Figura 5: Característica tu como un ejemplo confundido con la característica fútbol. Antes de presentar nuestra solución a este problema, veamos otro ejemplo de LL como se muestra en la Figura 6 para beenb, que en realidad es un error tipográfico confirmado. Por lo tanto, clasificamos beenb como una característica ruidosa que no contribuye a ningún evento. Claramente, la trayectoria de tu es muy diferente de beenb, lo que significa que el primero debe considerarse por separado. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figura 6: Característica beenb con Sf relativamente bajo y Pf a corto plazo. Conjunto de características de palabras vacías (SW) Basándonos en el análisis anterior, nos damos cuenta de que debe haber otro conjunto de características entre HL y LL que corresponda al conjunto de palabras vacías. Las características de este conjunto tienen un DPS moderado y un período dominante bajo pero conocido. Dado que es difícil distinguir este conjunto de características de HL y LL solo basándose en DPS, introducimos otro factor llamado promedio de DFIDF (DFIDF). Como se muestra en la Figura 5, características como la tuya suelen tener un DPS más bajo que una característica HL como el fútbol, pero tienen un DFIDF mucho más alto que otra característica ruidosa LL como \"beenb\". Dado que tales propiedades suelen ser características de las palabras vacías, agrupamos características como \"tu\" en el conjunto de características de palabras vacías (SW) recién definido. Dado que establecer los umbrales de DPS y DFIDF para identificar las palabras vacías es más un arte que una ciencia, propusimos un algoritmo heurístico HS, Algoritmo 1. La idea básica es utilizar solo noticias de días laborables para identificar palabras vacías. Los fines de semana aquí también incluyen días festivos que caen en días laborables. El conjunto SW se inicialmente alimenta con un pequeño conjunto de 29 stopwords populares utilizadas por el motor de búsqueda de Google. Algoritmo 1 Detección heurística de palabras vacías (HS) Entrada: Conjunto de palabras vacías semilla, trayectorias semanales de todas las palabras 1: A partir del conjunto semilla SW, calcular el DPS máximo como UDPS, el DFIDF máximo como UDFIDF y el mínimo de DFIDF como LDFIDF. 2: para fi ∈ F hacer 3: Calcular DFT para fi. 4: si Sfi ≤ UDPS y DFIDFfi ∈ [LDFIDF, UDFIDF] entonces 5: fi → SW 6: F = F - fi 7: fin si 8: fin para Resumen de la Categorización de Características Después de generar el conjunto SW, se eliminan todas las palabras vacías de F. Luego, establecemos el límite entre DPS alto y bajo como el límite superior de los DPS de los conjuntos SW. Una visión general de los cinco conjuntos de características se muestra en la Figura 7. Figura 7: Los 5 conjuntos de características para eventos. 5. IDENTIFICACIÓN DE RÁFAGAS PARA CARACTERÍSTICAS Dado que solo las características de HH, HL y LH son significativas y podrían ser representativas de algunos eventos, eliminamos todas las demás características clasificadas como LL o SW. En esta sección, describimos cómo se pueden identificar los estallidos a partir de las características restantes. A diferencia del algoritmo de identificación de ráfagas de Kleinberg [12], podemos identificar tanto ráfagas significativas como triviales sin necesidad de establecer ningún parámetro. 5.1 Detección de ráfagas de características aperiódicas Para cada característica en HH y HL, truncamos su trayectoria manteniendo solo el período de ráfagas, el cual está modelado con una distribución gaussiana. Por ejemplo, la Figura 8 muestra la característica de la palabra Iraq con una explosión alrededor del 09/06/1996 modelada como una Gaussiana. Su período de ráfagas está definido por [μf − σf , μf + σf ] como se muestra en la Figura 8(b). 5.2 Detección de características periódicas de ráfagas Dado que hemos calculado el DP para una característica periódica f, podemos modelar fácilmente su trayectoria de características periódicas yf usando 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) DFIDF original: tiempo 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 ráfaga= [μ-σ, μ+σ] (b) identificación de ráfaga Figura 8: Modelando la serie temporal de Iraq como una Gaussiana truncada con μ = 09/06/1996 y σ = 6.26. una mezcla de K = T/Pf Gaussianas: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , donde el conjunto de parámetros θf = {αk, μk, σk}K k=1 comprende: • αk es la probabilidad de asignar yf a la k-ésima Gaussiana. αk > 0, ∀k ∈ [1, K] y K k=1 αk = 1; • μk/σk es la media/desviación estándar de la k-ésima Gaussiana. El conocido algoritmo Expectation Maximization (EM) [8] se utiliza para calcular las proporciones de mezcla αk, así como los parámetros individuales de densidad gaussiana μk y σK. Cada Gaussiana representa un evento periódico, y se modela de manera similar como se menciona en la Sección 5.1. 6. EVENTOS A PARTIR DE CARACTERÍSTICAS Después de identificar y modelar ráfagas para todas las características, la siguiente tarea es pintar un cuadro del evento con un posible conjunto de características representativas. 6.1 Correlación de Características Si dos características fi y fj son representativas del mismo evento, deben cumplir las siguientes condiciones necesarias: 1. fi y fj están distribuidas de manera idéntica: yfi ∼ yfj. 2. fi y fj tienen una alta superposición de documentos. Medición de la similitud de la distribución de características. Medimos la similitud entre dos características fi y fj utilizando la divergencia KL discreta definida de la siguiente manera. Definición 6. (similitud de características) KL(fi, fj) se da por max(KL(fi|fj), KL(fj|fi)), donde KL(fi|fj) = T t=1 f(yfi(t)|θfi)log f(yfi(t)|θfi) f(yfj(t)|θfj). (1) Dado que la divergencia KL no es simétrica, definimos la similitud entre fi y fj como el máximo entre KL(fi|fj) y KL(fj|fi). Además, la similitud entre dos características aperiódicas puede calcularse utilizando una forma cerrada de la divergencia de Kullback-Leibler [16]. La misma fórmula discreta de divergencia KL de la Ecuación 1 se emplea para calcular la similitud entre dos características periódicas. A continuación, definimos la similitud general entre un conjunto de características R utilizando el valor máximo de divergencia KL entre características como sigue. Definición 7. (similitud de conjuntos) KL(R) = max ∀fi, fj ∈R KL(fi, fj). Superposición de documentos: Sea Mi el conjunto de todos los documentos que contienen la característica fi. Dadas dos características fi y fj, el conjunto de documentos superpuestos que contienen ambas características es Mi ∩ Mj. De manera intuitiva, cuanto mayor sea |Mi ∩ Mj|, es más probable que fi y fj estén altamente correlacionados. Definimos el grado de superposición de documentos entre dos características fi y fj de la siguiente manera. Definición 8. (Superposición de características DF) d(fi, fj) = |Mi∩Mj| min(|Mi|, |Mj|). En consecuencia, la superposición de DF entre un conjunto de características R también está definida. Definición 9. (Superposición de Conjuntos DF) d(R) = min ∀fi, fj ∈R d(fi, fj). 6.2 Detección de Eventos Codiciosa No Supervisada Utilizamos características de HH para detectar eventos aperiódicos importantes, características de LH para detectar eventos aperiódicos menos reportados/poco importantes, y características de HL para detectar eventos periódicos. Todos comparten el mismo algoritmo. Dado el rasgo explosivo fi ∈ HH, el objetivo es encontrar rasgos altamente correlacionados de HH. El conjunto de características similares a fi puede describir colectivamente un evento. Específicamente, necesitamos encontrar un subconjunto Ri de HH que minimice la siguiente función de costo: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) El evento subyacente e (asociado con la explosión de fi) puede ser representado por Ri como y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) El análisis de la explosión para el evento e es exactamente el mismo que la trayectoria de características. El costo en la Ecuación 2 se puede minimizar utilizando nuestro algoritmo de detección de eventos UG codicioso no supervisado, que se describe en el Algoritmo 2. El algoritmo UG permite una característica Algoritmo 2 Detección de eventos codiciosos no supervisados (UG). Salida: ek como Ec. 3. Además, los eventos triviales que solo contienen características de año/mes (es decir, un evento que solo contiene una característica de agosto podría ser identificado en un flujo de noticias de 1 año) podrían ser eliminados, aunque dichos eventos tendrán un costo inherente alto y deberían estar clasificados muy bajos. Tenga en cuenta que nuestro algoritmo UG solo requiere un parámetro dependiente de los datos, el límite entre el espectro de alta y baja potencia, que debe establecerse una vez, y este parámetro puede estimarse fácilmente utilizando el algoritmo HS (Algoritmo 1). 7. EXPERIMENTOS En esta sección, estudiamos el rendimiento de nuestro método de categorización de características y algoritmo de detección de eventos. Primero presentamos el conjunto de datos y la configuración experimental, luego evaluamos subjetivamente la categorización de características para HH, HL, LH, LL y SW. Finalmente, estudiamos el problema de detección de eventos (a)periódicos con el Algoritmo 2. 7.1. Conjunto de datos y configuración experimental El Corpus de Reuters contiene 806,791 noticias en inglés desde el 20/08/1996 hasta el 19/08/1997 con una resolución diaria. La versión 2 del software de código abierto Lucene [1] se utilizó para tokenizar el contenido de texto de noticias y generar el vector documento-palabra. Con el fin de preservar los tiempos verbales pasados/presentes/futuros sensibles al tiempo y las diferencias entre los sustantivos en minúscula y las entidades nombradas en mayúscula, no se realizó ningún truncamiento. Dado que la eliminación dinámica de palabras vacías es una de las funcionalidades de nuestro método, no se eliminó ninguna palabra vacía. Eliminamos los caracteres no ingleses, sin embargo, después de eso, el número de características de palabras asciende a 423,433. Todos los experimentos se implementaron en Java y se llevaron a cabo en una PC Pentium 4 de 3.2 GHz con Windows 2003 Server y 1 GB de memoria. 7.2 Categorización de características Descargamos 34 stopwords bien conocidos utilizados por el motor de búsqueda de Google como nuestras características de entrenamiento iniciales, que incluyen a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en y www. Excluimos las últimas cinco palabras vacías ya que son poco comunes en noticias. Al analizar solo historias de noticias durante 259 días laborables, calculamos el límite superior del espectro de potencia para las palabras vacías en 11.18 y los rangos correspondientes de DFIDF van desde 0.1182 hasta 0.3691. Cualquier característica f que cumpla con Sf <= 11.18 y 0.1182 <= DFIDFf <= 0.3691 durante los días de la semana se considerará una palabra vacía. De esta manera, se encontraron y eliminaron 470 palabras vacías como se muestra en la Figura 9. Algunas palabras vacías detectadas son A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) y much (P = 22, S = 0.80, DFIDF = 0.1865). Después de la eliminación de estas palabras vacías, la distribución de las noticias entre semana y los fines de semana están más o menos equilibradas, y en los experimentos subsiguientes, haremos uso del corpus completo (entre semana y fines de semana). El valor del espectro de potencia límite superior de 11.18 para el entrenamiento de palabras vacías fue seleccionado como el límite entre el espectro de alta potencia y baja potencia. El límite entre alta y baja periodicidad se estableció en 365/2 = 183. Todos los 422,963 (423433 − 470) rasgos de palabras fueron categorizados en 4 conjuntos de rasgos: HH (69 rasgos), HL (1,087 rasgos), LH (83,471 rasgos) y LL (338,806 rasgos) como se muestra en la Figura 10. En la Figura 10, cada nivel de gris denota la densidad relativa de características en una región cuadrada, medida por log10(1 + Dk), donde Dk es el número de características dentro de la k-ésima región cuadrada. A partir de la figura, podemos hacer el 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figura 9: Distribución de SW (palabras vacías) en las regiones HH, HL, LH y LL. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figura 10: Distribución de características categorizadas en los cuatro cuadrantes (sombreado en escala logarítmica). siguientes observaciones: 1. La mayoría de las características tienen un valor bajo de S y son fácilmente distinguibles de aquellas características que tienen un valor mucho más alto de S, lo que nos permite detectar eventos importantes (a)periódicos de eventos triviales seleccionando características con un alto valor de S. 2. Las características en los cuadrantes HH y LH son aperiódicas, las cuales están bien separadas (gran brecha horizontal) de las características periódicas. Esto permite detectar de manera confiable eventos aperiódicos y eventos periódicos de forma independiente. 3. La frontera (vertical) entre el espectro de alta y baja potencia no es tan clara y el valor exacto dependerá de la aplicación específica. Al revisar la distribución de dispersión de las características de SW en HH, HL, LH y LL como se muestra en la Figura 9, encontramos que el 87.02% (409/470) de las stopwords detectadas se originaron en LL. La clasificación LL y las altas puntuaciones de DFIDF de las palabras vacías concuerdan con la noción generalmente aceptada de que las palabras vacías son igualmente frecuentes en todo momento. Por lo tanto, establecer el límite entre el espectro de alta y baja potencia utilizando el límite superior Sf de SW es una heurística razonable. 7.3 Detección de Eventos Aperiódicos Evaluaremos nuestras dos hipótesis, 1)los eventos aperiódicos importantes pueden ser definidos por un conjunto de características HH, y 2)los eventos aperiódicos menos reportados pueden ser definidos por un conjunto de características LH. Dado que no existen flujos de noticias de referencia para la detección de eventos (los conjuntos de datos de TDT no son flujos adecuados), evaluamos la calidad de los eventos detectados automáticamente comparándolos con eventos confirmados manualmente mediante la búsqueda en el corpus. Entre las 69 características de HH, detectamos 17 eventos aperiódicos importantes como se muestra en la Tabla 1 (e1 - e17). Ten en cuenta que toda la identificación tomó menos de 1 segundo, después de eliminar los eventos que solo contenían la característica del mes. De los 17 eventos, aparte de las superposiciones entre e3 y e4 (ambos describen el mismo evento de rehenes), e11 y e16 (ambos sobre informes de empresas), los 14 eventos identificados son extremadamente precisos y corresponden muy bien a los principales eventos del período. Por ejemplo, la derrota de Bob Dole, la elección de Tony Blair, el ataque con misiles a Iraq, etc. Recuerde que seleccionar las características para un evento debería minimizar el costo en la Ecuación 2 de tal manera que 1) el número de características abarque diferentes eventos, y 2) no se seleccionarán todas las características relevantes para un evento, por ejemplo, la característica Clinton es representativa para e12, pero dado que Clinton se relaciona con muchos otros eventos, su señal de dominio temporal es muy diferente de la de otras características representativas como Dole y Bob. El número de documentos de un evento detectado se estima aproximadamente por el número de documentos indexados que contienen las características representativas. Podemos ver que los 17 eventos aperiódicos importantes son eventos reportados popularmente. Después de 742 minutos de tiempo de computación, detectamos 23,525 eventos aperiódicos menos reportados de 83,471 características de LH. La Tabla 1 enumera los 5 principales eventos aperiódicos detectados (e18 - e22) con respecto al costo. Descubrimos que estos 5 eventos son en realidad eventos muy triviales con solo unos pocos informes de noticias, y suelen ser englobados por algunos temas más grandes. Por ejemplo, e22 es uno de los eventos de rescate en un tema de secuestro de avión. Una ventaja de nuestro Algoritmo UG para descubrir eventos aperiódicos poco reportados es que podemos detectar con precisión el verdadero período del evento. 7.4 Detección de Eventos Periódicos Entre las 1,087 características de HL, se detectaron 330 eventos periódicos importantes en un tiempo de cálculo de 10 minutos. La Tabla 1 enumera los 5 eventos periódicos detectados con respecto al costo (e23 - e27). Todos los eventos periódicos detectados son realmente válidos y corresponden a eventos periódicos de la vida real. El modelo GMM es capaz de detectar y estimar el período de ráfagas de manera precisa, aunque no puede distinguir la ligera diferencia entre cada lunes a viernes y todos los días de la semana, como se muestra en e23. También observamos que e26 es en realidad un subconjunto de e27 (partido de fútbol), lo cual es aceptable ya que los resultados de la liga de Sheffield se anuncian de forma independiente cada fin de semana. 8. CONCLUSIONES Este artículo adoptó una perspectiva completamente nueva para analizar las trayectorias de características como señales en el dominio del tiempo. Al considerar las frecuencias de los documentos en el dominio del tiempo y de la frecuencia, pudimos derivar muchas nuevas características sobre los flujos de noticias que antes eran desconocidas, por ejemplo, las diferentes distribuciones de palabras vacías durante los días de la semana y los fines de semana. Por primera vez en el área de TDT, aplicamos un enfoque sistemático para detectar automáticamente eventos importantes y menos reportados, periódicos y aperiódicos. La idea clave de nuestro trabajo radica en las observaciones de que los eventos periódicos tienen características representativas periódicas y los eventos (in)importantes tienen características representativas (in)activas, diferenciadas por sus espectros de potencia y períodos de tiempo. Para abordar el problema de detección de eventos reales, se utilizó un enfoque basado en densidad de mezcla simple y efectivo para identificar ráfagas de características y sus períodos asociados de ráfagas. También diseñamos un algoritmo codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos, el cual tuvo éxito en detectar eventos reales como se muestra en la evaluación en un flujo de noticias reales. Aunque no hemos realizado ninguna comparación de referencia con otro enfoque, simplemente porque no hay trabajos previos en el problema abordado. El trabajo futuro incluye evaluar la recuperación de eventos detectados en un flujo de noticias etiquetado, y comparar nuestro modelo con los métodos equivalentes más cercanos, que actualmente se limitan a los métodos de Kleinberg [12] (que solo pueden detectar ciertos tipos de eventos explosivos dependiendo de la configuración de parámetros), Fung et al. [9], y Swan y Allan [18]. Sin embargo, creemos que nuestro método simple y efectivo será útil para todos los practicantes de TDT, y será especialmente útil para el análisis exploratorio inicial de flujos de noticias. REFERENCIAS [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Alertas de noticias de Google, http://www.google.com/alerts. [3] Corpus de Reuters, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan. Detección y seguimiento de temas. Organización de la información basada en eventos. Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, y H. Jin. La detección de la primera historia en tdt es difícil. En CIKM, páginas 374-381, 2000. [6] J. Allan, C. Wade y A. Bolivar. Recuperación y detección de novedades a nivel de oración. En SIGIR, páginas 314-321, 2003. [7] T. Brants, F. Chen y A. Farahat. Un sistema para la detección de nuevos eventos. En SIGIR, páginas 330-337, 2003. [8] A. P. Dempster, N. M. Laird y D. B. Rubin. Máxima verosimilitud a partir de datos incompletos a través del algoritmo EM. Revista de la Real Sociedad Estadística, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu y H. Lu. Detección de eventos explosivos sin parámetros en flujos de texto. En VLDB, páginas 181-192, 2005. [10] Q. Él, K. Chang y E.-P. Lim. Un modelo para la detección anticipada de eventos. En ER, páginas 168-181, 2006. [11] Q. Él, K. Chang, E.-P. Lim y J. Zhang. Representación de características intermitentes para la agrupación de flujos de texto. En SDM, aceptado, 2007. [12] J. Kleinberg. Estructura explosiva y jerárquica en arroyos. En SIGKDD, páginas 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan y A. Tomkins. Sobre la evolución explosiva del blogosfera. En WWW, páginas 159-178, 2005. [14] G. Kumaran y J. Allan. Clasificación de texto y entidades nombradas para la detección de nuevos eventos. En SIGIR, páginas 297-304, 2004. [15] Q. Mei y C. Zhai. Descubriendo patrones temáticos evolutivos a partir de texto: una exploración de la minería de texto temporal. En SIGKDD, páginas 198-207, 2005. [16] W. D. Penny. Divergencias de Kullback-Leibler de densidades normales, gamma, dirichlet y wishart. Informe técnico, 2001. [17] N. Stokes y J. Carthy. Combinando clasificadores de documentos semánticos y sintácticos para mejorar la detección de la primera noticia. En SIGIR, páginas 424-425, 2001. [18] R. Swan y J. Allan. Generación automática de líneas de tiempo de resumen. En SIGIR, páginas 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena y D. Gunopulos. Identificando similitudes, periodicidades y ráfagas en las consultas de búsqueda en línea. En SIGMOD, páginas 131-142, 2004. [20] Y. Yang, T. Pierce y J. Carbonell. Un estudio de detección de eventos retrospectivos y en línea. En SIGIR, páginas 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell y C. Jin. Detección de novedades condicionada por el tema. En SIGKDD, páginas 688-693, 2002. Tabla 1: Todos los eventos aperiódicos importantes (e1 - e17), los 5 eventos aperiódicos menos reportados (e18 - e22) y los 5 eventos periódicos importantes (e23 - e27). Evento detectado y período de actividad intensa Doc # Verdadero evento e1 (Sali, Berisha, Albania, albanés, marzo) 02/02/199705/29/1997 1409 El presidente albanés Sali Berisha perdió en una elección temprana y renunció, 12/1996-07/1997. e2 (Seko, Mobutu, Sese, Kabila) 03/22/1997-06/09/1997 2273 El presidente de Zaire, Mobutu Sese, coordinó la rebelión nativa y fracasó el 16/05/1997. e3 (Marxista, peruano) 11/19/1996-03/05/1997 824 Los rebeldes de Perú (Movimiento Revolucionario Tupac Amaru) lideraron un asedio de rehenes en Lima a principios de 1997. e4 (Movimiento, Tupac, Amaru, Lima, rehén, rehenes) 11/16/1996-03/20/1997 824 Lo mismo que e3. e5 (Kinshasa, Kabila, Laurent, Congo) 03/26/199706/15/1997 1378 Zaire fue renombrado República Democrática del Congo el 16/05/1997. e6 (Jospin, Lionel, junio) 05/10/1997-07/09/1997 605 Tras las elecciones generales tempranas alrededor de 06/1997, Lionel Jospin fue nombrado Primer Ministro el 02/06/1997. e7 (Irak, misil) 08/31/1996-09/13/1996 1262 EE. UU. disparó un misil a Irak el 03/09/1996 y el 04/09/1996. e8 (kurdo, Bagdad, iraquí) 08/29/1996-09/09/1996 1132 Tropas iraquíes lucharon con facciones kurdas alrededor de 09/1996. e9 (mayo, Blair) 03/24/1997-07/04/1997 1049 Tony Blair se convirtió en el Primer Ministro del Reino Unido el 02/05/1997. e10 (slalom, esquí) 12/05/1996-03/21/1997 253 Juego de eslalon de esquí alpino en 01/1997-02/1997. e11 (Interino, meses) 09/24/1996-12/31/1996 3063 Tokio publicó los resultados interinos de la empresa para los últimos meses en 09/1996-12/1996. e12 (Dole, Bob) 09/09/1996-11/24/1996 1599 Bob Dole perdió las elecciones presidenciales de EE. UU. de 1996. e13 (julio, Sen) 06/25/1997-06/25/1997 344 El Primer Ministro de Camboya, Hun Sen, lanzó un sangriento golpe militar en 07/1997. e14 (Hebrón) 10/15/1996-02/14/1997 2098 Hebrón fue dividida en dos sectores a principios de 1997. e15 (abril, Pascua) 02/23/1997-05/04/1997 480 Festividades de Pascua alrededor de 04/1997 (para occidentales y ortodoxos). e16 (Diluido, Grupo) 04/27/1997-07/20/1997 1888 Tokio publicó todos los resultados del grupo 96/97 en 04/199707/1997. e17 (diciembre, Navidad) 11/17/1996-01/26/1997 1326 Festín de Navidad a finales de 12/1997. e18 (Kolaceva, invierno, Juntos, paseos, Zajedno, Slobodan, Belgrado, serbio, Serbia, Draskovic, municipal, Kragujevac) 1/25/1997 3 Estudiantes universitarios organizaron una vigilia en la calle Kolaceva contra el gobierno el 25/01/1997. e19 (Tutsi, Luvengi, Burundi, Uvira, combustible, Banyamulenge, burundés, Kivu, Kiliba, Runingo, Kagunga, Bwegera) 10/19/1996 6 Estallaron nuevos enfrentamientos alrededor de Uvira entre las fuerzas armadas de Zaire y los rebeldes Tutsi de Banyamulenge el 19/10/1996. e20 (Malantacchi, Corea, Guy, Rider, Sindicatos, trabajo, Confederación, embestido, Ginebra, paradas, Virgin, contratar, Myongdong, Metalúrgicos) 1/11/1997 2 Marcello Malantacchi, secretario general de la Federación Internacional de Metalúrgicos, y Guy Rider, quien dirige la oficina de Ginebra de la Confederación Internacional de Sindicatos Libres, atacaron la nueva ley laboral de Corea del Sur el 11/01/1997. e21 (DBS, Raﬄes) 8/17/1997 9 La lista de la unidad de DBS Land Raﬄes Holdings de Singapur planea el 17/08/1997. e22 (conservador, combustible, Galawa, Huddle, Leul, Beausse) 11/24/1996 3 Rescataron a una mujer y a su bebé durante un secuestro de un avión etíope que se quedó sin combustible y se estrelló en el mar cerca de la playa Le Galawa el 24/11/1996. e23 (PRECIO, LISTADO, MLN, VENCIMIENTO, CUPÓN, MOODY, MONTO, PRIMERO, ISS, TIPO, PAGO, PRESTAMISTA) Lunes a viernes/semana 7966 Anuncian el precio de los bonos todos los días de la semana. e24 (No auditado, Terminado, Meses, Ponderado, Provisión, Costo, Venta, Ingresos, Pérdida, Ingreso, excepto, Shrs, Revs) cada temporada 2264 Informes de ingresos netos-pérdidas publicados por empresas en cada temporada. e25 (calificación, Wall Street, Ian) Lunes a viernes/semana 21767 Informes de acciones de Wall Street todos los días de la semana. e26 (Sheffield, liga, goles de puntuación, delantero, juegos) cada viernes, sábado y domingo 574 Resultados de partidos de la liga de fútbol de Sheffield publicados los viernes, sábados y domingos 10 veces más que en los otros 4 días. e27 (fútbol, partidos, Resultados, temporada, juego, Copa, partido, victoria, vencer, jugado, jugar, división) cada viernes, sábado y domingo 2396 Juegos de fútbol celebrados los viernes, sábados y domingos 7 veces más que en los otros 4 días. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "topic tracking": {
            "translated_key": "Seguimiento de temas",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Analyzing Feature Trajectories for Event Detection Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg School of Computer Engineering Nanyang Technological University Block N4, Nanyang Avenue, Singapore 639798 ABSTRACT We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words.",
                "A set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner.",
                "The document frequency of each word across time is treated like a time series, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point.",
                "In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events.",
                "All of the above methods can be applied to time series data in general.",
                "We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events.",
                "Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Experimentation. 1.",
                "INTRODUCTION There are more than 4,000 online news sources in the world.",
                "Manually monitoring all of them for important events has become difficult or practically impossible.",
                "In fact, the topic detection and tracking (TDT) community has for many years been trying to come up with a practical solution to help people monitor news effectively.",
                "Unfortunately, the holy grail is still elusive, because the vast majority of TDT solutions proposed for event detection [20, 5, 17, 4, 21, 7, 14, 10] are either too simplistic (based on cosine similarity [5]) or impractical due to the need to tune a large number of parameters [9].",
                "The ineffectiveness of current TDT technologies can be easily illustrated by subscribing to any of the many online news alerts services such as the industryleading Google News Alerts [2], which generates more than 50% false alarms [10].",
                "As further proof, portals like Yahoo take a more pragmatic approach by requiring all machine generated news alerts to go through a human operator for confirmation before sending them out to subscribers.",
                "Instead of attacking the problem with variations of the same hammer (cosine similarity and TFIDF), a fundamental understanding of the characteristics of news stream data is necessary before any major breakthroughs can be made in TDT.",
                "Thus in this paper, we look at news stories and feature trends from the perspective of analyzing a time-series word signal.",
                "Previous work like [9] has attempted to reconstruct an event with its representative features.",
                "However, in many predictive event detection tasks (i.e., retrospective event detection), there is a vast set of potential features only for a fixed set of observations (i.e., the obvious bursts).",
                "Of these features, often only a small number are expected to be useful.",
                "In particular, we study the novel problem of analyzing feature trajectories for event detection, borrowing a well-known technique from signal processing: identifying distributional correlations among all features by spectral analysis.",
                "To evaluate our method, we subsequently propose an unsupervised event detection algorithm for news streams. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Easter April (a) aperiodic event 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Unaudited Ended (b) periodic event Figure 1: Feature correlation (DFIDF:time) between a) Easter and April b) Unaudited and Ended.",
                "As an illustrative example, consider the correlation between the words Easter and April from the Reuters Corpus1 .",
                "From the plot of their normalized DFIDF in Figure 1(a), we observe the heavy overlap between the two words circa 04/1997, which means they probably both belong to the same event during that time (Easter feast).",
                "In this example, the hidden event Easter feast is a typical important aperiodic event over 1-year data.",
                "Another example is given by Figure 1(b), where both the words Unaudited and Ended 1 Reuters Corpus is the default dataset for all examples. exhibit similar behaviour over periods of 3 months.",
                "These two words actually originated from the same periodic event, net income-loss reports, which are released quarterly by publicly listed companies.",
                "Other observations drawn from Figure 1 are: 1) the bursty period of April is much longer than Easter, which suggests that April may exist in other events during the same period; 2) Unaudited has a higher average DFIDF value than Ended, which indicates Unaudited to be more representative for the underlying event.",
                "These two examples are but the tip of the iceberg among all word trends and correlations hidden in a news stream like Reuters.",
                "If a large number of them can be uncovered, it could significantly aid TDT tasks.",
                "In particular, it indicates the significance of mining correlating features for detecting corresponding events.",
                "To summarize, we postulate that: 1) An event is described by its representative features.",
                "A periodic event has a list of periodic features and an aperiodic event has a list of aperiodic features; 2) Representative features from the same event share similar distributions over time and are highly correlated; 3) An important event has a set of active (largely reported) representative features, whereas an unimportant event has a set of inactive (less-reported) representative features; 4) A feature may be included by several events with overlaps in time frames.",
                "Based on these observations, we can either mine representative features given an event or detect an event from a list of highly correlated features.",
                "In this paper, we focus on the latter, i.e., how correlated features can be uncovered to form an event in an unsupervised manner. 1.1 Contributions This paper has three main contributions: • To the best of our knowledge, our approach is the first to categorize word features for heterogenous events.",
                "Specifically, every word feature is categorized into one of the following five feature types based on its power spectrum strength and periodicity: 1) HH (high power and high/long periodicity): important aperiodic events, 2) HL (high power and low periodicity): important periodic events, 3) LH (low power and high periodicity): unimportant aperiodic events, 4) LL (low power and low periodicity): non-events, and 5) SW (stopwords), a higher power and periodicity subset of LL comprising stopwords, which contains no information. • We propose a simple and effective mixture densitybased approach to model and detect feature bursts. • We come up with an unsupervised event detection algorithm to detect both aperiodic and periodic events.",
                "Our algorithm has been evaluated on a real news stream to show its effectiveness. 2.",
                "RELATED WORK This work is largely motivated by a broader family of problems collectively known as Topic Detection and Tracking (TDT) [20, 5, 17, 4, 21, 7, 14, 10].",
                "Moreover, most TDT research so far has been concerned with clustering/classifying documents into topic types, identifying novel sentences [6] for new events, etc., without much regard to analyzing the word trajectory with respect to time.",
                "Swan and Allan [18] first attempted using co-occuring terms to construct an event.",
                "However, they only considered named entities and noun phrase pairs, without considering their periodicities.",
                "On the contrary, our paper considers all of the above.",
                "Recently, there has been significant interest in modeling an event in text streams as a burst of activities by incorporating temporal information.",
                "Kleinbergs seminal work described how bursty features can be extracted from text streams using an infinite automaton model [12], which inspired a whole series of applications such as Kumars identification of bursty communities from Weblog graphs [13], Meis summarization of evolutionary themes in text streams [15], Hes clustering of text streams using bursty features [11], etc.",
                "Nevertheless, none of the existing work specifically identified features for events, except for Fung et al. [9], who clustered busty features to identify various bursty events.",
                "Our work differs from [9] in several ways: 1) we analyze every single feature, not only bursty features; 2) we classify features along two categorical dimensions (periodicity and power), yielding altogether five primary feature types; 3) we do not restrict each feature to exclusively belong to only one event.",
                "Spectral analysis techniques have previously been used by Vlachos et al. [19] to identify periodicities and bursts from query logs.",
                "Their focus was on detecting multiple periodicities from the power spectrum graph, which were then used to index words for query-by-burst search.",
                "In this paper, we use spectral analysis to classify word features along two dimensions, namely periodicity and power spectrum, with the ultimate goal of identifying both periodic and aperiodic bursty events. 3.",
                "DATA REPRESENTATION Let T be the duration/period (in days) of a news stream, and F represents the complete word feature space in the classical static Vector Space Model (VSM). 3.1 Event Periodicity Classification Within T, there may exist certain events that occur only once, e.g., Tony Blair elected as Prime Minister of U.K., and other recurring events of various periodicities, e.g., weekly soccer matches.",
                "We thus categorize all events into two types: aperiodic and periodic, defined as follows.",
                "Definition 1. (Aperiodic Event) An event is aperiodic within T if it only happens once.",
                "Definition 2. (Periodic Event) If events of a certain event genre occur regularly with a fixed periodicity P ≤ T/2 , we say that this particular event genre is periodic, with each member event qualified as a periodic event.",
                "Note that the definition of aperiodic is relative, i.e., it is true only for a given T, and may be invalid for any other T > T. For example, the event Christmas feast is aperiodic for T ≤ 365 but periodic for T ≥ 730. 3.2 Representative Features Intuitively, an event can be described very concisely by a few discriminative and representative word features and vice-versa, e.g., hurricane, sweep, and strike could be representative features of a Hurricane genre event.",
                "Likewise, a set of strongly correlated features could be used to reconstruct an event description, assuming that strongly correlated features are representative.",
                "The representation vector of a word feature is defined as follows: Definition 3. (Feature Trajectory) The trajectory of a word feature f can be written as the sequence yf = [yf (1), yf (2), . . . , yf (T)], where each element yf (t) is a measure of feature f at time t, which could be defined using the normalized DFIDF score2 yf (t) = DFf (t) N(t) × log( N DFf ), where DFf (t) is the number of documents (local DF) containing feature f at day t, DFf is the total number of documents (global DF) containing feature f over T, N(t) is the number of documents for day t, and N is the total number of documents over T. 4.",
                "IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 Spectral Analysis for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. DFT can represent the original time series as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T.",
                "The original trajectory can be reconstructed with just the dominant frequencies, which can be determined from the power spectrum using the popular periodogram estimator.",
                "The periodogram is a sequence of the squared magnitude of the Fourier coefficients, Xk 2 , k = 1, 2, . . . , T/2 , which indicates the signal power at frequency k/T in the spectrum.",
                "From the power spectrum, the dominant period is chosen as the inverse of the frequency with the highest power spectrum, as follows.",
                "Definition 4. (Dominant Period) The dominant period (DP) of a given feature f is Pf = T/ arg max k Xk 2 .",
                "Accordingly, we have Definition 5. (Dominant Power Spectrum) The dominant power spectrum (DPS) of a given feature f is Sf = Xk 2 , with Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorizing Features The DPS of a feature trajectory is a strong indicator of its activeness at the specified frequency; the higher the DPS, the more likely for the feature to be bursty.",
                "Combining DPS with DP, we therefore categorize all features into four types: 2 We normalize yf (t) as yf (t) = yf (t)/ T i=1 yf (i) so that it could be interpreted as a probability. • HH: high Sf , aperiodic or long-term periodic (Pf > T/2 ); • HL: high Sf , short-term periodic (Pf ≤ T/2 ); • LH: low Sf , aperiodic or long-term periodic; • LL: low Sf , short-term periodic.",
                "The boundary between long-term and short-term periodic is set to T/2 .",
                "However, distinguishing between a high and low DPS is not straightforward, which will be tackled later.",
                "Properties of Different Feature Sets To better understand the properties of HH, HL, LH and LL, we select four features, Christmas, soccer, DBS and your as illustrative examples.",
                "Since the boundary between high and low power spectrum is unclear, these chosen examples have relative wide range of power spectrum values.",
                "Figure 2(a) shows the DFIDF trajectory for Christmas with a distinct burst around Christmas day.",
                "For the 1-year Reuters dataset, Christmas is classified as a typical aperiodic event with Pf = 365 and Sf = 135.68, as shown in Figure 2(b).",
                "Clearly, the value of Sf = 135.68 is reasonable for a well-known bursty event like Christmas. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Christmas(DFIDF:time) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Christmas(S:frequency) Figure 2: Feature Christmas with relative high Sf and long-term Pf .",
                "The DFIDF trajectory for soccer is shown in Figure 3(a), from which we can observe that there is a regular burst every 7 days, which is again verified by its computed value of Pf = 7, as shown in Figure 3(b).",
                "Using the domain knowledge that soccer games have more matches every Saturday, which makes it a typical and heavily reported periodic event, we thus consider the value of Sf = 155.13 to be high. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) soccer(DFIDF:time) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) soccer(S:frequency) Figure 3: Feature soccer with relative high Sf and short-term Pf .",
                "From the DFIDF trajectory for DBS in Figure 4(a), we can immediately deduce DBS to be an infrequent word with a trivial burst on 08/17/1997 corresponding to DBS Land Raﬄes Holdings plans.",
                "This is confirmed by the long period of Pf = 365 and low power of Sf = 0.3084 as shown in Figure 4(b).",
                "Moreover, since this aperiodic event is only reported in a few news stories over a very short time of few days, we therefore say that its low power value of Sf = 0.3084 is representative of unimportant events.",
                "The most confusing example is shown in Figure 5 for the word feature your, which looks very similar to the graph for soccer in Figure 3.",
                "At first glance, we may be tempted to group both your and soccer into the same category of HL or LL since both distributions look similar and have the same dominant period of approximately a week.",
                "However, further 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:time) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frequency) Figure 4: Feature DBS with relative low Sf and long-term Pf . analysis indicates that the periodicity of your is due to the differences in document counts for weekdays (average 2,919 per day) and weekends3 (average 479 per day).",
                "One would have expected the periodicity of a stopword like your to be a day.",
                "Moreover, despite our DFIDF normalization, the weekday/weekend imbalance still prevailed; stopwords occur 4 times more frequently on weekends than on weekdays.",
                "Thus, the DPS remains the only distinguishing factor between your (Sf = 9.42) and soccer (Sf = 155.13).",
                "However, it is very dangerous to simply conclude that a power value of S = 9.42 corresponds to a stopword feature. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) your(DFIDF:time) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) your(S:frequency) Figure 5: Feature your as an example confusing with feature soccer.",
                "Before introducing our solution to this problem, lets look at another LL example as shown in Figure 6 for beenb, which is actually a confirmed typo.",
                "We therefore classify beenb as a noisy feature that does not contribute to any event.",
                "Clearly, the trajectory of your is very different from beenb, which means that the former has to be considered separately. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figure 6: Feature beenb with relative low Sf and short-term Pf .",
                "Stop Words (SW) Feature Set Based on the above analysis, we realize that there must be another feature set between HL and LL that corresponds to the set of stopwords.",
                "Features from this set has moderate DPS and low but known dominant period.",
                "Since it is hard to distinguish this feature set from HL and LL only based on DPS, we introduce another factor called average DFIDF (DFIDF).",
                "As shown in Figure 5, features like your usually have a lower DPS than a HL feature like soccer, but have a much higher DFIDF than another LL noisy feature such as beenb.",
                "Since such properties are usually characteristics of stopwords, we group features like your into the newly defined stopword (SW) feature set.",
                "Since setting the DPS and DFIDF thresholds for identifying stopwords is more of an art than science, we proposed a heuristic HS algorithm, Algorithm 1.",
                "The basic idea is to only use news stories from weekdays to identify stopwords. 3 The weekends here also include public holidays falling on weekdays.",
                "The SW set is initially seeded with a small set of 29 popular stopwords utilized by Google search engine.",
                "Algorithm 1 Heuristic Stopwords detection (HS) Input: Seed SW set, weekday trajectories of all words 1: From the seed set SW, compute the maximum DPS as UDPS, maximum DFIDF as UDFIDF, and minimum of DFIDF as LDFIDF. 2: for fi ∈ F do 3: Compute DFT for fi. 4: if Sfi ≤ UDPS and DFIDFfi ∈ [LDFIDF, UDFIDF] then 5: fi → SW 6: F = F − fi 7: end if 8: end for Overview of Feature Categorization After the SW set is generated, all stopwords are removed from F. We then set the boundary between high and low DPS to be the upper bound of the SW sets DPS.",
                "An overview of all five feature sets is shown in Figure 7.",
                "Figure 7: The 5 feature sets for events. 5.",
                "IDENTIFYING BURSTS FOR FEATURES Since only features from HH, HL and LH are meaningful and could potentially be representative to some events, we pruned all other feature classified as LL or SW.",
                "In this section, we describe how bursts can be identified from the remaining features.",
                "Unlike Kleinbergs burst identification algorithm [12], we can identify both significant and trivial bursts without the need to set any parameters. 5.1 Detecting Aperiodic Features Bursts For each feature in HH and HL, we truncate its trajectory by keeping only the bursty period, which is modeled with a Gaussian distribution.",
                "For example, Figure 8 shows the word feature Iraq with a burst circa 09/06/1996 being modeled as a Gaussian.",
                "Its bursty period is defined by [μf − σf , μf + σf ] as shown in Figure 8(b). 5.2 Detecting Periodic Features Bursts Since we have computed the DP for a periodic feature f, we can easily model its periodic feature trajectory yf using 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) original DFIDF:time 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 burst= [μ-σ, μ+σ] (b) identifying burst Figure 8: Modeling Iraqs time series as a truncated Gaussian with μ = 09/06/1996 and σ = 6.26. a mixture of K = T/Pf Gaussians: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , where the parameter set θf = {αk, μk, σk}K k=1 comprises: • αk is the probability of assigning yf into the kth Gaussian. αk > 0, ∀k ∈ [1, K] and K k=1 αk = 1; • μk/σk is mean/standard deviation of the kth Gaussian.",
                "The well known Expectation Maximization (EM) [8] algorithm is used to compute the mixing proportions αk, as well as the individual Gaussian density parameters μk and σK .",
                "Each Gaussian represents one periodic event, and is modeled similarly as mentioned in Section 5.1. 6.",
                "EVENTS FROM FEATURES After identifying and modeling bursts for all features, the next task is to paint a picture of the event with a potential set of representative features. 6.1 Feature Correlation If two features fi and fj are representative of the same event, they must satisfy the following necessary conditions: 1. fi and fj are identically distributed: yfi ∼ yfj . 2. fi and fj have a high document overlap.",
                "Measuring Feature Distribution Similarity We measure the similarity between two features fi and fj using discrete KL-divergence defined as follows.",
                "Definition 6. (feature similarity) KL(fi, fj ) is given by max(KL(fi|fj ), KL(fj |fi)), where KL(fi|fj ) = T t=1 f(yfi (t)|θfi )log f(yfi (t)|θfi ) f(yfj (t)|θfj ) . (1) Since KL-divergence is not symmetric, we define the similarity between between fi and fj as the maximum of KL(fi|fj ) and KL(fj |fi).",
                "Further, the similarity between two aperiodic features can be computed using a closed form of the KL-divergence [16].",
                "The same discrete KL-divergence formula of Eq. 1 is employed to compute the similarity between two periodic features, Next, we define the overal similarity among a set of features R using the maximum inter-feature KL-Divergence value as follows.",
                "Definition 7. (sets similarity)KL(R) = max ∀fi,fj ∈R KL(fi, fj ).",
                "Document Overlap Let Mi be the set of all documents containing feature fi.",
                "Given two features fi and fj , the overlapping document set containing both features is Mi ∩ Mj .",
                "Intuitively, the higher the |Mi ∩ Mj |, the more likelty that fi and fj will be highly correlated.",
                "We define the degree of document overlap between two features fi and fj as follows.",
                "Definition 8. (Feature DF Overlap) d(fi, fj ) = |Mi∩Mj| min(|Mi|,|Mj|) .",
                "Accordingly, the DF Overlap among a set of features R is also defined.",
                "Definition 9. (Set DF Overlap) d(R) = min ∀fi,fj ∈R d(fi, fj). 6.2 Unsupervised Greedy Event Detection We use features from HH to detect important aperiodic events, features from LH to detect less-reported/unimportant aperiodic events, and features from HL to detect periodic events.",
                "All of them share the same algorithm.",
                "Given bursty feature fi ∈ HH, the goal is to find highly correlated features from HH.",
                "The set of features similar to fi can then collectively describe an event.",
                "Specifically, we need to find a subset Ri of HH that minimizes the following cost function: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) The underlying event e (associated with the burst of fi) can be represented by Ri as y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) The burst analysis for event e is exactly the same as the feature trajectory.",
                "The cost in Eq. 2 can be minimized using our unsupervised greedy UG event detection algorithm, which is described in Algorithm 2.",
                "The UG algorithm allows a feature Algorithm 2 Unsupervised Greedy event detection (UG).",
                "Input: HH, document index for each feature. 1: Sort and select features in descending DPS order: Sf1 ≥ Sf2 ≥ . . . ≥ Sf|HH| . 2: k = 0. 3: for fi ∈ HH do 4: k = k + 1. 5: Init: Ri ← fi, C(Ri) = 1/Sfi and HH = HH − fi. 6: while HH not empty do 7: m = arg min m C(Ri ∪ fm). 8: if C(Ri ∪ fm) < C(Ri) then 9: Ri ← fm and HH = HH − fm. 10: else 11: break while. 12: end if 13: end while 14: Output ek as Eq. 3. 15: end for to be contained in multiple events so that we can detect several events happening at the same time.",
                "Furthermore, trivial events only containing year/month features (i.e., an event only containing 1 feature Aug could be identified over a 1year news stream) could be removed, although such events will have inherent high cost and should already be ranked very low.",
                "Note that our UG algorithm only requires one data-dependant parameter, the boundary between high and low power spectrum, to be set once, and this parameter can be easily estimated using the HS algorithm (Algorithm 1). 7.",
                "EXPERIMENTS In this section, we study the performances of our feature categorizing method and event detection algorithm.",
                "We first introduce the dataset and experimental setup, then we subjectively evaluate the categorization of features for HH, HL, LH, LL and SW.",
                "Finally, we study the (a)periodic event detection problem with Algorithm 2. 7.1 Dataset and Experimental Setup The Reuters Corpus contains 806,791 English news stories from 08/20/1996 to 08/19/1997 at a day resolution.",
                "Version 2 of the open source Lucene software [1] was used to tokenize the news text content and generate the document-word vector.",
                "In order to preserve the time-sensitive past/present/future tenses of verbs and the differences between lower case nouns and upper case named entities, no stemming was done.",
                "Since dynamic stopword removal is one of the functionalities of our method, no stopword was removed.",
                "We did remove nonEnglish characters, however, after which the number of word features amounts to 423,433.",
                "All experiments were implemented in Java and conducted on a 3.2 GHz Pentium 4 PC running Windows 2003 Server with 1 GB of memory. 7.2 Categorizing Features We downloaded 34 well-known stopwords utilized by the Google search engine as our seed training features, which includes a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en and www.",
                "We excluded the last five stopwords as they are uncommon in news stories.",
                "By only analyzing news stories over 259 weekdays, we computed the upper bound of the power spectrum for stopwords at 11.18 and corresponding DFIDF ranges from 0.1182 to 0.3691.",
                "Any feature f satisfying Sf <= 11.18 and 0.1182 <= DFIDFf <= 0.3691 over weekdays will be considered a stopword.",
                "In this manner, 470 stopwords were found and removed as visualized in Figure 9.",
                "Some detected stopwords are A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) and much (P = 22, S = 0.80, DFIDF = 0.1865).",
                "After the removal of these stopwords, the distribution of weekday and weekend news are more or less matched, and in the ensuing experiments, we shall make use of the full corpus (weekdays and weekends).",
                "The upper bound power spectrum value of 11.18 for stopwords training was selected as the boundary between the high power and low power spectrum.",
                "The boundary between high and low periodicity was set to 365/2 = 183.",
                "All 422,963 (423433 − 470) word features were categorized into 4 feature sets: HH (69 features), HL (1,087 features), LH (83,471 features), and LL (338,806 features) as shown in Figure 10.",
                "In Figure 10, each gray level denotes the relative density of features in a square region, measured by log10(1 + Dk), where Dk is the number of features within the k-th square region.",
                "From the figure, we can make the 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figure 9: Distribution of SW (stopwords) in the HH, HL, LH, and LL regions. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figure 10: Distribution of categorized features over the four quadrants (shading in log scale). following observations: 1.",
                "Most features have low S and are easily distinguishable from those features having a much higher S, which allows us to detect important (a)periodic events from trivial events by selecting features with high S. 2.",
                "Features in the HH and LH quadrants are aperiodic, which are nicely separated (big horizontal gap) from the periodic features.",
                "This allows reliably detecting aperiodic events and periodic events independently. 3.",
                "The (vertical) boundary between high and low power spectrum is not as clearcut and the exact value will be application specific.",
                "By checking the scatter distribution of features from SW on HH, HL, LH, and LL as shown in Figure 9, we found that 87.02%(409/470) of the detected stopwords originated from LL.",
                "The LL classification and high DFIDF scores of stopwords agree with the generally accepted notion that stopwords are equally frequent over all time.",
                "Therefore, setting the boundary between high and low power spectrum using the upper bound Sf of SW is a reasonable heuristic. 7.3 Detecting Aperiodic Events We shall evaluate our two hypotheses, 1)important aperiodic events can be defined by a set of HH features, and 2)less reported aperiodic events can be defined by a set of LH features.",
                "Since no benchmark news streams exist for event detection (TDT datasets are not proper streams), we evaluate the quality of the automatically detected events by comparing them to manually-confirmed events by searching through the corpus.",
                "Among the 69 HH features, we detected 17 important aperiodic events as shown in Table 1 (e1 − e17).",
                "Note that the entire identification took less than 1 second, after removing events containing only the month feature.",
                "Among the 17 events, other than the overlaps between e3 and e4 (both describes the same hostage event), e11 and e16 (both about company reports), the 14 identified events are extremely accurate and correspond very well to the major events of the period.",
                "For example, the defeat of Bob Dole, election of Tony Blair, Missile attack on Iraq, etc.",
                "Recall that selecting the features for one event should minimize the cost in Eq. 2 such that 1) the number of features span different events, and 2) not all features relevant to an event will be selected, e.g., the feature Clinton is representative to e12 but since Clinton relates to many other events, its time domain signal is far different from those of other representative features like Dole and Bob.",
                "The number of documents of a detected event is roughly estimated by the number of indexed documents containing the representative features.",
                "We can see that all 17 important aperiodic events are popularly reported events.",
                "After 742 minutes of computation time, we detected 23, 525 less reported aperiodic events from 83,471 LH features.",
                "Table 1 lists the top 5 detected aperiodic events (e18 − e22) with respect to the cost.",
                "We found that these 5 events are actually very trivial events with only a few news reports, and are usually subsumed by some larger topics.",
                "For example, e22 is one of the rescue events in an airplane hijack topic.",
                "One advantage of our UG Algorithm for discovering less-reported aperiodic events is that we are able to precisely detect the true event period. 7.4 Detecting Periodic Events Among the 1,087 HL features, 330 important periodic events were detected within 10 minutes of computing time.",
                "Table 1 lists the top 5 detected periodic events with respect to the cost (e23 − e27).",
                "All of the detected periodic events are indeed valid, and correspond to real life periodic events.",
                "The GMM model is able to detect and estimate the bursty period nicely although it cannot distinguish the slight difference between every Monday-Friday and all weekdays as shown in e23.",
                "We also notice that e26 is actually a subset of e27 (soccer game), which is acceptable since the Sheffield league results are announced independently every weekend. 8.",
                "CONCLUSIONS This paper took a whole new perspective of analyzing feature trajectories as time domain signals.",
                "By considering the word document frequencies in both time and frequency domains, we were able to derive many new characteristics about news streams that were previously unknown, e.g., the different distributions of stopwords during weekdays and weekends.",
                "For the first time in the area of TDT, we applied a systematic approach to automatically detect important and less-reported, periodic and aperiodic events.",
                "The key idea of our work lies in the observations that (a)periodic events have (a)periodic representative features and (un)important events have (in)active representative features, differentiated by their power spectrums and time periods.",
                "To address the real event detection problem, a simple and effective mixture density-based approach was used to identify feature bursts and their associated bursty periods.",
                "We also designed an unsupervised greedy algorithm to detect both aperiodic and periodic events, which was successful in detecting real events as shown in the evaluation on a real news stream.",
                "Although we have not made any benchmark comparison against another approach, simply because there is no previous work in the addressed problem.",
                "Future work includes evaluating the recall of detected events for a labeled news stream, and comparing our model against the closest equivalent methods, which currently are limited to the methods of Kleinberg [12] (which can only detect certain type of bursty events depending on parameter settings), Fung et al. [9], and Swan and Allan [18].",
                "Nevertheless, we believe our simple and effective method will be useful for all TDT practitioners, and will be especially useful for the initial exploratory analysis of news streams. 9.",
                "REFERENCES [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Google news alerts, http://www.google.com/alerts. [3] Reuters corpus, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan.",
                "Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, and H. Jin.",
                "First story detection in tdt is hard.",
                "In CIKM, pages 374-381, 2000. [6] J. Allan, C. Wade, and A. Bolivar.",
                "Retrieval and novelty detection at the sentence level.",
                "In SIGIR, pages 314-321, 2003. [7] T. Brants, F. Chen, and A. Farahat.",
                "A system for new event detection.",
                "In SIGIR, pages 330-337, 2003. [8] A. P. Dempster, N. M. Laird, and D. B. Rubin.",
                "Maximum likelihood from incomplete data via the EM algorithm.",
                "Journal of the Royal Statistical Society, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu, and H. Lu.",
                "Parameter free bursty events detection in text streams.",
                "In VLDB, pages 181-192, 2005. [10] Q.",
                "He, K. Chang, and E.-P. Lim.",
                "A model for anticipatory event detection.",
                "In ER, pages 168-181, 2006. [11] Q.",
                "He, K. Chang, E.-P. Lim, and J. Zhang.",
                "Bursty feature reprensentation for clustering text streams.",
                "In SDM, accepted, 2007. [12] J. Kleinberg.",
                "Bursty and hierarchical structure in streams.",
                "In SIGKDD, pages 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins.",
                "On the bursty evolution of blogspace.",
                "In WWW, pages 159-178, 2005. [14] G. Kumaran and J. Allan.",
                "Text classification and named entities for new event detection.",
                "In SIGIR, pages 297-304, 2004. [15] Q. Mei and C. Zhai.",
                "Discovering evolutionary theme patterns from text: an exploration of temporal text mining.",
                "In SIGKDD, pages 198-207, 2005. [16] W. D. Penny.",
                "Kullback-liebler divergences of normal, gamma, dirichlet and wishart densities.",
                "Technical report, 2001. [17] N. Stokes and J. Carthy.",
                "Combining semantic and syntactic document classifiers to improve first story detection.",
                "In SIGIR, pages 424-425, 2001. [18] R. Swan and J. Allan.",
                "Automatic generation of overview timelines.",
                "In SIGIR, pages 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena, and D. Gunopulos.",
                "Identifying similarities, periodicities and bursts for online search queries.",
                "In SIGMOD, pages 131-142, 2004. [20] Y. Yang, T. Pierce, and J. Carbonell.",
                "A study of retrospective and on-line event detection.",
                "In SIGIR, pages 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topic-conditioned novelty detection.",
                "In SIGKDD, pages 688-693, 2002.",
                "Table 1: All important aperiodic events (e1 − e17), top 5 less-reported aperiodic events (e18 − e22) and top 5 important periodic events (e23 − e27).",
                "Detected Event and Bursty Period Doc # True Event e1(Sali,Berisha,Albania,Albanian,March) 02/02/199705/29/1997 1409 Albanians president Sali Berisha lost in an early election and resigned, 12/1996-07/1997. e2(Seko,Mobutu,Sese,Kabila) 03/22/1997-06/09/1997 2273 Zaires president Mobutu Sese coordinated the native rebellion and failed on 05/16/1997. e3(Marxist,Peruvian) 11/19/1996-03/05/1997 824 Peru rebels (Tupac Amaru revolutionary Movement) led a hostage siege in Lima in early 1997. e4(Movement,Tupac,Amaru,Lima,hostage,hostages) 11/16/1996-03/20/1997 824 The same as e3. e5(Kinshasa,Kabila,Laurent,Congo) 03/26/199706/15/1997 1378 Zaire was renamed the Democratic Republic of Congo on 05/16/1997. e6(Jospin,Lionel,June) 05/10/1997-07/09/1997 605 Following the early General Elections circa 06/1997, Lionel Jospin was appointed Prime Minister on 06/02/1997. e7(Iraq,missile) 08/31/1996-09/13/1996 1262 U.S. fired missile at Iraq on 09/03/1996 and 09/04/1996. e8(Kurdish,Baghdad,Iraqi) 08/29/1996-09/09/1996 1132 Iraqi troop fought with Kurdish faction circa 09/1996. e9(May,Blair) 03/24/1997-07/04/1997 1049 Tony Blair became the Primary Minister of the United Kingdom on 05/02/1997. e10(slalom,skiing) 12/05/1996-03/21/1997 253 Slalom Game of Alpine Skiing in 01/1997-02/1997. e11(Interim,months) 09/24/1996-12/31/1996 3063 Tokyo released company interim results for the past several months in 09/1996-12/1996. e12(Dole,Bob) 09/09/1996-11/24/1996 1599 Dole Bob lost the 1996 US presidential election. e13(July,Sen) 06/25/1997-06/25/1997 344 Cambodias Prime Minister Hun Sen launched a bloody military coup in 07/1997. e14(Hebron) 10/15/1996-02/14/1997 2098 Hebron was divided into two sectors in early 1997. e15(April,Easter) 02/23/1997-05/04/1997 480 Easter feasts circa 04/1997 (for western and Orthodox). e16(Diluted,Group) 04/27/1997-07/20/1997 1888 Tokyo released all 96/97 group results in 04/199707/1997. e17(December,Christmas) 11/17/1996-01/26/1997 1326 Christmas feast in late 12/1997. e18(Kolaceva,winter,Together,promenades,Zajedno, Slobodan,Belgrade,Serbian,Serbia,Draskovic,municipal, Kragujevac) 1/25/1997 3 University students organized a vigil on Kolaceva street against government on 1/25/1997. e19(Tutsi,Luvengi,Burundi,Uvira,fuel,Banyamulenge, Burundian,Kivu,Kiliba,Runingo,Kagunga,Bwegera) 10/19/1996 6 Fresh fighting erupted around Uvira between Zaire armed forces and Banyamulengs Tutsi rebels on 10/19/1996. e20(Malantacchi,Korea,Guy,Rider,Unions,labour, Trade,unions,Confederation,rammed,Geneva,stoppages, Virgin,hire,Myongdong,Metalworkers) 1/11/1997 2 Marcello Malantacchi secretary general of the International Metalworkers Federation and Guy Rider who heads the Geneva office of the International Confederation of Free Trade Unions attacked the new labour law of South Korea on 1/11/1997. e21(DBS,Raﬄes) 8/17/1997 9 The list of the unit of Singapore DBS Land Raﬄes Holdings plans on 8/17/1997. e22(preserver,fuel,Galawa,Huddle,Leul,Beausse) 11/24/1996 3 Rescued a woman and her baby during a hijacked Ethiopian plane that ran out of fuel and crashed into the sea near Le Galawa beach on 11/24/1996. e23(PRICE,LISTING,MLN,MATURITY,COUPON, MOODY,AMT,FIRST,ISS,TYPE,PAY,BORROWER) Monday-Friday/week 7966 Announce bond price on all weekdays. e24(Unaudited,Ended,Months,Weighted,Provision,Cost, Selling,Revenues,Loss,Income,except,Shrs,Revs) every season 2264 Net income-loss reports released by companies in every season. e25(rating,Wall,Street,Ian) Monday-Friday/week 21767 Stock reports from Wall Street on all weekdays. e26(Sheffield,league,scoring,goals,striker,games) every Friday, Saturday and Sunday 574 Match results of Sheffield soccer league were published on Friday, Saturday and Sunday 10 times than other 4 days. e27(soccer,matches,Results,season,game,Cup,match, victory,beat,played,play,division) every Friday, Saturday and Sunday 2396 Soccer games held on Friday, Saturday and Sunday 7 times than other 4 days."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "text stream": {
            "translated_key": "flujos de texto",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Analyzing Feature Trajectories for Event Detection Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg School of Computer Engineering Nanyang Technological University Block N4, Nanyang Avenue, Singapore 639798 ABSTRACT We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words.",
                "A set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner.",
                "The document frequency of each word across time is treated like a time series, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point.",
                "In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events.",
                "All of the above methods can be applied to time series data in general.",
                "We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events.",
                "Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Experimentation. 1.",
                "INTRODUCTION There are more than 4,000 online news sources in the world.",
                "Manually monitoring all of them for important events has become difficult or practically impossible.",
                "In fact, the topic detection and tracking (TDT) community has for many years been trying to come up with a practical solution to help people monitor news effectively.",
                "Unfortunately, the holy grail is still elusive, because the vast majority of TDT solutions proposed for event detection [20, 5, 17, 4, 21, 7, 14, 10] are either too simplistic (based on cosine similarity [5]) or impractical due to the need to tune a large number of parameters [9].",
                "The ineffectiveness of current TDT technologies can be easily illustrated by subscribing to any of the many online news alerts services such as the industryleading Google News Alerts [2], which generates more than 50% false alarms [10].",
                "As further proof, portals like Yahoo take a more pragmatic approach by requiring all machine generated news alerts to go through a human operator for confirmation before sending them out to subscribers.",
                "Instead of attacking the problem with variations of the same hammer (cosine similarity and TFIDF), a fundamental understanding of the characteristics of news stream data is necessary before any major breakthroughs can be made in TDT.",
                "Thus in this paper, we look at news stories and feature trends from the perspective of analyzing a time-series word signal.",
                "Previous work like [9] has attempted to reconstruct an event with its representative features.",
                "However, in many predictive event detection tasks (i.e., retrospective event detection), there is a vast set of potential features only for a fixed set of observations (i.e., the obvious bursts).",
                "Of these features, often only a small number are expected to be useful.",
                "In particular, we study the novel problem of analyzing feature trajectories for event detection, borrowing a well-known technique from signal processing: identifying distributional correlations among all features by spectral analysis.",
                "To evaluate our method, we subsequently propose an unsupervised event detection algorithm for news streams. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Easter April (a) aperiodic event 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Unaudited Ended (b) periodic event Figure 1: Feature correlation (DFIDF:time) between a) Easter and April b) Unaudited and Ended.",
                "As an illustrative example, consider the correlation between the words Easter and April from the Reuters Corpus1 .",
                "From the plot of their normalized DFIDF in Figure 1(a), we observe the heavy overlap between the two words circa 04/1997, which means they probably both belong to the same event during that time (Easter feast).",
                "In this example, the hidden event Easter feast is a typical important aperiodic event over 1-year data.",
                "Another example is given by Figure 1(b), where both the words Unaudited and Ended 1 Reuters Corpus is the default dataset for all examples. exhibit similar behaviour over periods of 3 months.",
                "These two words actually originated from the same periodic event, net income-loss reports, which are released quarterly by publicly listed companies.",
                "Other observations drawn from Figure 1 are: 1) the bursty period of April is much longer than Easter, which suggests that April may exist in other events during the same period; 2) Unaudited has a higher average DFIDF value than Ended, which indicates Unaudited to be more representative for the underlying event.",
                "These two examples are but the tip of the iceberg among all word trends and correlations hidden in a news stream like Reuters.",
                "If a large number of them can be uncovered, it could significantly aid TDT tasks.",
                "In particular, it indicates the significance of mining correlating features for detecting corresponding events.",
                "To summarize, we postulate that: 1) An event is described by its representative features.",
                "A periodic event has a list of periodic features and an aperiodic event has a list of aperiodic features; 2) Representative features from the same event share similar distributions over time and are highly correlated; 3) An important event has a set of active (largely reported) representative features, whereas an unimportant event has a set of inactive (less-reported) representative features; 4) A feature may be included by several events with overlaps in time frames.",
                "Based on these observations, we can either mine representative features given an event or detect an event from a list of highly correlated features.",
                "In this paper, we focus on the latter, i.e., how correlated features can be uncovered to form an event in an unsupervised manner. 1.1 Contributions This paper has three main contributions: • To the best of our knowledge, our approach is the first to categorize word features for heterogenous events.",
                "Specifically, every word feature is categorized into one of the following five feature types based on its power spectrum strength and periodicity: 1) HH (high power and high/long periodicity): important aperiodic events, 2) HL (high power and low periodicity): important periodic events, 3) LH (low power and high periodicity): unimportant aperiodic events, 4) LL (low power and low periodicity): non-events, and 5) SW (stopwords), a higher power and periodicity subset of LL comprising stopwords, which contains no information. • We propose a simple and effective mixture densitybased approach to model and detect feature bursts. • We come up with an unsupervised event detection algorithm to detect both aperiodic and periodic events.",
                "Our algorithm has been evaluated on a real news stream to show its effectiveness. 2.",
                "RELATED WORK This work is largely motivated by a broader family of problems collectively known as Topic Detection and Tracking (TDT) [20, 5, 17, 4, 21, 7, 14, 10].",
                "Moreover, most TDT research so far has been concerned with clustering/classifying documents into topic types, identifying novel sentences [6] for new events, etc., without much regard to analyzing the word trajectory with respect to time.",
                "Swan and Allan [18] first attempted using co-occuring terms to construct an event.",
                "However, they only considered named entities and noun phrase pairs, without considering their periodicities.",
                "On the contrary, our paper considers all of the above.",
                "Recently, there has been significant interest in modeling an event in <br>text stream</br>s as a burst of activities by incorporating temporal information.",
                "Kleinbergs seminal work described how bursty features can be extracted from <br>text stream</br>s using an infinite automaton model [12], which inspired a whole series of applications such as Kumars identification of bursty communities from Weblog graphs [13], Meis summarization of evolutionary themes in <br>text stream</br>s [15], Hes clustering of text streams using bursty features [11], etc.",
                "Nevertheless, none of the existing work specifically identified features for events, except for Fung et al. [9], who clustered busty features to identify various bursty events.",
                "Our work differs from [9] in several ways: 1) we analyze every single feature, not only bursty features; 2) we classify features along two categorical dimensions (periodicity and power), yielding altogether five primary feature types; 3) we do not restrict each feature to exclusively belong to only one event.",
                "Spectral analysis techniques have previously been used by Vlachos et al. [19] to identify periodicities and bursts from query logs.",
                "Their focus was on detecting multiple periodicities from the power spectrum graph, which were then used to index words for query-by-burst search.",
                "In this paper, we use spectral analysis to classify word features along two dimensions, namely periodicity and power spectrum, with the ultimate goal of identifying both periodic and aperiodic bursty events. 3.",
                "DATA REPRESENTATION Let T be the duration/period (in days) of a news stream, and F represents the complete word feature space in the classical static Vector Space Model (VSM). 3.1 Event Periodicity Classification Within T, there may exist certain events that occur only once, e.g., Tony Blair elected as Prime Minister of U.K., and other recurring events of various periodicities, e.g., weekly soccer matches.",
                "We thus categorize all events into two types: aperiodic and periodic, defined as follows.",
                "Definition 1. (Aperiodic Event) An event is aperiodic within T if it only happens once.",
                "Definition 2. (Periodic Event) If events of a certain event genre occur regularly with a fixed periodicity P ≤ T/2 , we say that this particular event genre is periodic, with each member event qualified as a periodic event.",
                "Note that the definition of aperiodic is relative, i.e., it is true only for a given T, and may be invalid for any other T > T. For example, the event Christmas feast is aperiodic for T ≤ 365 but periodic for T ≥ 730. 3.2 Representative Features Intuitively, an event can be described very concisely by a few discriminative and representative word features and vice-versa, e.g., hurricane, sweep, and strike could be representative features of a Hurricane genre event.",
                "Likewise, a set of strongly correlated features could be used to reconstruct an event description, assuming that strongly correlated features are representative.",
                "The representation vector of a word feature is defined as follows: Definition 3. (Feature Trajectory) The trajectory of a word feature f can be written as the sequence yf = [yf (1), yf (2), . . . , yf (T)], where each element yf (t) is a measure of feature f at time t, which could be defined using the normalized DFIDF score2 yf (t) = DFf (t) N(t) × log( N DFf ), where DFf (t) is the number of documents (local DF) containing feature f at day t, DFf is the total number of documents (global DF) containing feature f over T, N(t) is the number of documents for day t, and N is the total number of documents over T. 4.",
                "IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 Spectral Analysis for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. DFT can represent the original time series as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T.",
                "The original trajectory can be reconstructed with just the dominant frequencies, which can be determined from the power spectrum using the popular periodogram estimator.",
                "The periodogram is a sequence of the squared magnitude of the Fourier coefficients, Xk 2 , k = 1, 2, . . . , T/2 , which indicates the signal power at frequency k/T in the spectrum.",
                "From the power spectrum, the dominant period is chosen as the inverse of the frequency with the highest power spectrum, as follows.",
                "Definition 4. (Dominant Period) The dominant period (DP) of a given feature f is Pf = T/ arg max k Xk 2 .",
                "Accordingly, we have Definition 5. (Dominant Power Spectrum) The dominant power spectrum (DPS) of a given feature f is Sf = Xk 2 , with Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorizing Features The DPS of a feature trajectory is a strong indicator of its activeness at the specified frequency; the higher the DPS, the more likely for the feature to be bursty.",
                "Combining DPS with DP, we therefore categorize all features into four types: 2 We normalize yf (t) as yf (t) = yf (t)/ T i=1 yf (i) so that it could be interpreted as a probability. • HH: high Sf , aperiodic or long-term periodic (Pf > T/2 ); • HL: high Sf , short-term periodic (Pf ≤ T/2 ); • LH: low Sf , aperiodic or long-term periodic; • LL: low Sf , short-term periodic.",
                "The boundary between long-term and short-term periodic is set to T/2 .",
                "However, distinguishing between a high and low DPS is not straightforward, which will be tackled later.",
                "Properties of Different Feature Sets To better understand the properties of HH, HL, LH and LL, we select four features, Christmas, soccer, DBS and your as illustrative examples.",
                "Since the boundary between high and low power spectrum is unclear, these chosen examples have relative wide range of power spectrum values.",
                "Figure 2(a) shows the DFIDF trajectory for Christmas with a distinct burst around Christmas day.",
                "For the 1-year Reuters dataset, Christmas is classified as a typical aperiodic event with Pf = 365 and Sf = 135.68, as shown in Figure 2(b).",
                "Clearly, the value of Sf = 135.68 is reasonable for a well-known bursty event like Christmas. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Christmas(DFIDF:time) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Christmas(S:frequency) Figure 2: Feature Christmas with relative high Sf and long-term Pf .",
                "The DFIDF trajectory for soccer is shown in Figure 3(a), from which we can observe that there is a regular burst every 7 days, which is again verified by its computed value of Pf = 7, as shown in Figure 3(b).",
                "Using the domain knowledge that soccer games have more matches every Saturday, which makes it a typical and heavily reported periodic event, we thus consider the value of Sf = 155.13 to be high. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) soccer(DFIDF:time) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) soccer(S:frequency) Figure 3: Feature soccer with relative high Sf and short-term Pf .",
                "From the DFIDF trajectory for DBS in Figure 4(a), we can immediately deduce DBS to be an infrequent word with a trivial burst on 08/17/1997 corresponding to DBS Land Raﬄes Holdings plans.",
                "This is confirmed by the long period of Pf = 365 and low power of Sf = 0.3084 as shown in Figure 4(b).",
                "Moreover, since this aperiodic event is only reported in a few news stories over a very short time of few days, we therefore say that its low power value of Sf = 0.3084 is representative of unimportant events.",
                "The most confusing example is shown in Figure 5 for the word feature your, which looks very similar to the graph for soccer in Figure 3.",
                "At first glance, we may be tempted to group both your and soccer into the same category of HL or LL since both distributions look similar and have the same dominant period of approximately a week.",
                "However, further 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:time) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frequency) Figure 4: Feature DBS with relative low Sf and long-term Pf . analysis indicates that the periodicity of your is due to the differences in document counts for weekdays (average 2,919 per day) and weekends3 (average 479 per day).",
                "One would have expected the periodicity of a stopword like your to be a day.",
                "Moreover, despite our DFIDF normalization, the weekday/weekend imbalance still prevailed; stopwords occur 4 times more frequently on weekends than on weekdays.",
                "Thus, the DPS remains the only distinguishing factor between your (Sf = 9.42) and soccer (Sf = 155.13).",
                "However, it is very dangerous to simply conclude that a power value of S = 9.42 corresponds to a stopword feature. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) your(DFIDF:time) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) your(S:frequency) Figure 5: Feature your as an example confusing with feature soccer.",
                "Before introducing our solution to this problem, lets look at another LL example as shown in Figure 6 for beenb, which is actually a confirmed typo.",
                "We therefore classify beenb as a noisy feature that does not contribute to any event.",
                "Clearly, the trajectory of your is very different from beenb, which means that the former has to be considered separately. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figure 6: Feature beenb with relative low Sf and short-term Pf .",
                "Stop Words (SW) Feature Set Based on the above analysis, we realize that there must be another feature set between HL and LL that corresponds to the set of stopwords.",
                "Features from this set has moderate DPS and low but known dominant period.",
                "Since it is hard to distinguish this feature set from HL and LL only based on DPS, we introduce another factor called average DFIDF (DFIDF).",
                "As shown in Figure 5, features like your usually have a lower DPS than a HL feature like soccer, but have a much higher DFIDF than another LL noisy feature such as beenb.",
                "Since such properties are usually characteristics of stopwords, we group features like your into the newly defined stopword (SW) feature set.",
                "Since setting the DPS and DFIDF thresholds for identifying stopwords is more of an art than science, we proposed a heuristic HS algorithm, Algorithm 1.",
                "The basic idea is to only use news stories from weekdays to identify stopwords. 3 The weekends here also include public holidays falling on weekdays.",
                "The SW set is initially seeded with a small set of 29 popular stopwords utilized by Google search engine.",
                "Algorithm 1 Heuristic Stopwords detection (HS) Input: Seed SW set, weekday trajectories of all words 1: From the seed set SW, compute the maximum DPS as UDPS, maximum DFIDF as UDFIDF, and minimum of DFIDF as LDFIDF. 2: for fi ∈ F do 3: Compute DFT for fi. 4: if Sfi ≤ UDPS and DFIDFfi ∈ [LDFIDF, UDFIDF] then 5: fi → SW 6: F = F − fi 7: end if 8: end for Overview of Feature Categorization After the SW set is generated, all stopwords are removed from F. We then set the boundary between high and low DPS to be the upper bound of the SW sets DPS.",
                "An overview of all five feature sets is shown in Figure 7.",
                "Figure 7: The 5 feature sets for events. 5.",
                "IDENTIFYING BURSTS FOR FEATURES Since only features from HH, HL and LH are meaningful and could potentially be representative to some events, we pruned all other feature classified as LL or SW.",
                "In this section, we describe how bursts can be identified from the remaining features.",
                "Unlike Kleinbergs burst identification algorithm [12], we can identify both significant and trivial bursts without the need to set any parameters. 5.1 Detecting Aperiodic Features Bursts For each feature in HH and HL, we truncate its trajectory by keeping only the bursty period, which is modeled with a Gaussian distribution.",
                "For example, Figure 8 shows the word feature Iraq with a burst circa 09/06/1996 being modeled as a Gaussian.",
                "Its bursty period is defined by [μf − σf , μf + σf ] as shown in Figure 8(b). 5.2 Detecting Periodic Features Bursts Since we have computed the DP for a periodic feature f, we can easily model its periodic feature trajectory yf using 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) original DFIDF:time 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 burst= [μ-σ, μ+σ] (b) identifying burst Figure 8: Modeling Iraqs time series as a truncated Gaussian with μ = 09/06/1996 and σ = 6.26. a mixture of K = T/Pf Gaussians: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , where the parameter set θf = {αk, μk, σk}K k=1 comprises: • αk is the probability of assigning yf into the kth Gaussian. αk > 0, ∀k ∈ [1, K] and K k=1 αk = 1; • μk/σk is mean/standard deviation of the kth Gaussian.",
                "The well known Expectation Maximization (EM) [8] algorithm is used to compute the mixing proportions αk, as well as the individual Gaussian density parameters μk and σK .",
                "Each Gaussian represents one periodic event, and is modeled similarly as mentioned in Section 5.1. 6.",
                "EVENTS FROM FEATURES After identifying and modeling bursts for all features, the next task is to paint a picture of the event with a potential set of representative features. 6.1 Feature Correlation If two features fi and fj are representative of the same event, they must satisfy the following necessary conditions: 1. fi and fj are identically distributed: yfi ∼ yfj . 2. fi and fj have a high document overlap.",
                "Measuring Feature Distribution Similarity We measure the similarity between two features fi and fj using discrete KL-divergence defined as follows.",
                "Definition 6. (feature similarity) KL(fi, fj ) is given by max(KL(fi|fj ), KL(fj |fi)), where KL(fi|fj ) = T t=1 f(yfi (t)|θfi )log f(yfi (t)|θfi ) f(yfj (t)|θfj ) . (1) Since KL-divergence is not symmetric, we define the similarity between between fi and fj as the maximum of KL(fi|fj ) and KL(fj |fi).",
                "Further, the similarity between two aperiodic features can be computed using a closed form of the KL-divergence [16].",
                "The same discrete KL-divergence formula of Eq. 1 is employed to compute the similarity between two periodic features, Next, we define the overal similarity among a set of features R using the maximum inter-feature KL-Divergence value as follows.",
                "Definition 7. (sets similarity)KL(R) = max ∀fi,fj ∈R KL(fi, fj ).",
                "Document Overlap Let Mi be the set of all documents containing feature fi.",
                "Given two features fi and fj , the overlapping document set containing both features is Mi ∩ Mj .",
                "Intuitively, the higher the |Mi ∩ Mj |, the more likelty that fi and fj will be highly correlated.",
                "We define the degree of document overlap between two features fi and fj as follows.",
                "Definition 8. (Feature DF Overlap) d(fi, fj ) = |Mi∩Mj| min(|Mi|,|Mj|) .",
                "Accordingly, the DF Overlap among a set of features R is also defined.",
                "Definition 9. (Set DF Overlap) d(R) = min ∀fi,fj ∈R d(fi, fj). 6.2 Unsupervised Greedy Event Detection We use features from HH to detect important aperiodic events, features from LH to detect less-reported/unimportant aperiodic events, and features from HL to detect periodic events.",
                "All of them share the same algorithm.",
                "Given bursty feature fi ∈ HH, the goal is to find highly correlated features from HH.",
                "The set of features similar to fi can then collectively describe an event.",
                "Specifically, we need to find a subset Ri of HH that minimizes the following cost function: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) The underlying event e (associated with the burst of fi) can be represented by Ri as y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) The burst analysis for event e is exactly the same as the feature trajectory.",
                "The cost in Eq. 2 can be minimized using our unsupervised greedy UG event detection algorithm, which is described in Algorithm 2.",
                "The UG algorithm allows a feature Algorithm 2 Unsupervised Greedy event detection (UG).",
                "Input: HH, document index for each feature. 1: Sort and select features in descending DPS order: Sf1 ≥ Sf2 ≥ . . . ≥ Sf|HH| . 2: k = 0. 3: for fi ∈ HH do 4: k = k + 1. 5: Init: Ri ← fi, C(Ri) = 1/Sfi and HH = HH − fi. 6: while HH not empty do 7: m = arg min m C(Ri ∪ fm). 8: if C(Ri ∪ fm) < C(Ri) then 9: Ri ← fm and HH = HH − fm. 10: else 11: break while. 12: end if 13: end while 14: Output ek as Eq. 3. 15: end for to be contained in multiple events so that we can detect several events happening at the same time.",
                "Furthermore, trivial events only containing year/month features (i.e., an event only containing 1 feature Aug could be identified over a 1year news stream) could be removed, although such events will have inherent high cost and should already be ranked very low.",
                "Note that our UG algorithm only requires one data-dependant parameter, the boundary between high and low power spectrum, to be set once, and this parameter can be easily estimated using the HS algorithm (Algorithm 1). 7.",
                "EXPERIMENTS In this section, we study the performances of our feature categorizing method and event detection algorithm.",
                "We first introduce the dataset and experimental setup, then we subjectively evaluate the categorization of features for HH, HL, LH, LL and SW.",
                "Finally, we study the (a)periodic event detection problem with Algorithm 2. 7.1 Dataset and Experimental Setup The Reuters Corpus contains 806,791 English news stories from 08/20/1996 to 08/19/1997 at a day resolution.",
                "Version 2 of the open source Lucene software [1] was used to tokenize the news text content and generate the document-word vector.",
                "In order to preserve the time-sensitive past/present/future tenses of verbs and the differences between lower case nouns and upper case named entities, no stemming was done.",
                "Since dynamic stopword removal is one of the functionalities of our method, no stopword was removed.",
                "We did remove nonEnglish characters, however, after which the number of word features amounts to 423,433.",
                "All experiments were implemented in Java and conducted on a 3.2 GHz Pentium 4 PC running Windows 2003 Server with 1 GB of memory. 7.2 Categorizing Features We downloaded 34 well-known stopwords utilized by the Google search engine as our seed training features, which includes a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en and www.",
                "We excluded the last five stopwords as they are uncommon in news stories.",
                "By only analyzing news stories over 259 weekdays, we computed the upper bound of the power spectrum for stopwords at 11.18 and corresponding DFIDF ranges from 0.1182 to 0.3691.",
                "Any feature f satisfying Sf <= 11.18 and 0.1182 <= DFIDFf <= 0.3691 over weekdays will be considered a stopword.",
                "In this manner, 470 stopwords were found and removed as visualized in Figure 9.",
                "Some detected stopwords are A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) and much (P = 22, S = 0.80, DFIDF = 0.1865).",
                "After the removal of these stopwords, the distribution of weekday and weekend news are more or less matched, and in the ensuing experiments, we shall make use of the full corpus (weekdays and weekends).",
                "The upper bound power spectrum value of 11.18 for stopwords training was selected as the boundary between the high power and low power spectrum.",
                "The boundary between high and low periodicity was set to 365/2 = 183.",
                "All 422,963 (423433 − 470) word features were categorized into 4 feature sets: HH (69 features), HL (1,087 features), LH (83,471 features), and LL (338,806 features) as shown in Figure 10.",
                "In Figure 10, each gray level denotes the relative density of features in a square region, measured by log10(1 + Dk), where Dk is the number of features within the k-th square region.",
                "From the figure, we can make the 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figure 9: Distribution of SW (stopwords) in the HH, HL, LH, and LL regions. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figure 10: Distribution of categorized features over the four quadrants (shading in log scale). following observations: 1.",
                "Most features have low S and are easily distinguishable from those features having a much higher S, which allows us to detect important (a)periodic events from trivial events by selecting features with high S. 2.",
                "Features in the HH and LH quadrants are aperiodic, which are nicely separated (big horizontal gap) from the periodic features.",
                "This allows reliably detecting aperiodic events and periodic events independently. 3.",
                "The (vertical) boundary between high and low power spectrum is not as clearcut and the exact value will be application specific.",
                "By checking the scatter distribution of features from SW on HH, HL, LH, and LL as shown in Figure 9, we found that 87.02%(409/470) of the detected stopwords originated from LL.",
                "The LL classification and high DFIDF scores of stopwords agree with the generally accepted notion that stopwords are equally frequent over all time.",
                "Therefore, setting the boundary between high and low power spectrum using the upper bound Sf of SW is a reasonable heuristic. 7.3 Detecting Aperiodic Events We shall evaluate our two hypotheses, 1)important aperiodic events can be defined by a set of HH features, and 2)less reported aperiodic events can be defined by a set of LH features.",
                "Since no benchmark news streams exist for event detection (TDT datasets are not proper streams), we evaluate the quality of the automatically detected events by comparing them to manually-confirmed events by searching through the corpus.",
                "Among the 69 HH features, we detected 17 important aperiodic events as shown in Table 1 (e1 − e17).",
                "Note that the entire identification took less than 1 second, after removing events containing only the month feature.",
                "Among the 17 events, other than the overlaps between e3 and e4 (both describes the same hostage event), e11 and e16 (both about company reports), the 14 identified events are extremely accurate and correspond very well to the major events of the period.",
                "For example, the defeat of Bob Dole, election of Tony Blair, Missile attack on Iraq, etc.",
                "Recall that selecting the features for one event should minimize the cost in Eq. 2 such that 1) the number of features span different events, and 2) not all features relevant to an event will be selected, e.g., the feature Clinton is representative to e12 but since Clinton relates to many other events, its time domain signal is far different from those of other representative features like Dole and Bob.",
                "The number of documents of a detected event is roughly estimated by the number of indexed documents containing the representative features.",
                "We can see that all 17 important aperiodic events are popularly reported events.",
                "After 742 minutes of computation time, we detected 23, 525 less reported aperiodic events from 83,471 LH features.",
                "Table 1 lists the top 5 detected aperiodic events (e18 − e22) with respect to the cost.",
                "We found that these 5 events are actually very trivial events with only a few news reports, and are usually subsumed by some larger topics.",
                "For example, e22 is one of the rescue events in an airplane hijack topic.",
                "One advantage of our UG Algorithm for discovering less-reported aperiodic events is that we are able to precisely detect the true event period. 7.4 Detecting Periodic Events Among the 1,087 HL features, 330 important periodic events were detected within 10 minutes of computing time.",
                "Table 1 lists the top 5 detected periodic events with respect to the cost (e23 − e27).",
                "All of the detected periodic events are indeed valid, and correspond to real life periodic events.",
                "The GMM model is able to detect and estimate the bursty period nicely although it cannot distinguish the slight difference between every Monday-Friday and all weekdays as shown in e23.",
                "We also notice that e26 is actually a subset of e27 (soccer game), which is acceptable since the Sheffield league results are announced independently every weekend. 8.",
                "CONCLUSIONS This paper took a whole new perspective of analyzing feature trajectories as time domain signals.",
                "By considering the word document frequencies in both time and frequency domains, we were able to derive many new characteristics about news streams that were previously unknown, e.g., the different distributions of stopwords during weekdays and weekends.",
                "For the first time in the area of TDT, we applied a systematic approach to automatically detect important and less-reported, periodic and aperiodic events.",
                "The key idea of our work lies in the observations that (a)periodic events have (a)periodic representative features and (un)important events have (in)active representative features, differentiated by their power spectrums and time periods.",
                "To address the real event detection problem, a simple and effective mixture density-based approach was used to identify feature bursts and their associated bursty periods.",
                "We also designed an unsupervised greedy algorithm to detect both aperiodic and periodic events, which was successful in detecting real events as shown in the evaluation on a real news stream.",
                "Although we have not made any benchmark comparison against another approach, simply because there is no previous work in the addressed problem.",
                "Future work includes evaluating the recall of detected events for a labeled news stream, and comparing our model against the closest equivalent methods, which currently are limited to the methods of Kleinberg [12] (which can only detect certain type of bursty events depending on parameter settings), Fung et al. [9], and Swan and Allan [18].",
                "Nevertheless, we believe our simple and effective method will be useful for all TDT practitioners, and will be especially useful for the initial exploratory analysis of news streams. 9.",
                "REFERENCES [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Google news alerts, http://www.google.com/alerts. [3] Reuters corpus, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan.",
                "Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, and H. Jin.",
                "First story detection in tdt is hard.",
                "In CIKM, pages 374-381, 2000. [6] J. Allan, C. Wade, and A. Bolivar.",
                "Retrieval and novelty detection at the sentence level.",
                "In SIGIR, pages 314-321, 2003. [7] T. Brants, F. Chen, and A. Farahat.",
                "A system for new event detection.",
                "In SIGIR, pages 330-337, 2003. [8] A. P. Dempster, N. M. Laird, and D. B. Rubin.",
                "Maximum likelihood from incomplete data via the EM algorithm.",
                "Journal of the Royal Statistical Society, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu, and H. Lu.",
                "Parameter free bursty events detection in <br>text stream</br>s.",
                "In VLDB, pages 181-192, 2005. [10] Q.",
                "He, K. Chang, and E.-P. Lim.",
                "A model for anticipatory event detection.",
                "In ER, pages 168-181, 2006. [11] Q.",
                "He, K. Chang, E.-P. Lim, and J. Zhang.",
                "Bursty feature reprensentation for clustering <br>text stream</br>s.",
                "In SDM, accepted, 2007. [12] J. Kleinberg.",
                "Bursty and hierarchical structure in streams.",
                "In SIGKDD, pages 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins.",
                "On the bursty evolution of blogspace.",
                "In WWW, pages 159-178, 2005. [14] G. Kumaran and J. Allan.",
                "Text classification and named entities for new event detection.",
                "In SIGIR, pages 297-304, 2004. [15] Q. Mei and C. Zhai.",
                "Discovering evolutionary theme patterns from text: an exploration of temporal text mining.",
                "In SIGKDD, pages 198-207, 2005. [16] W. D. Penny.",
                "Kullback-liebler divergences of normal, gamma, dirichlet and wishart densities.",
                "Technical report, 2001. [17] N. Stokes and J. Carthy.",
                "Combining semantic and syntactic document classifiers to improve first story detection.",
                "In SIGIR, pages 424-425, 2001. [18] R. Swan and J. Allan.",
                "Automatic generation of overview timelines.",
                "In SIGIR, pages 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena, and D. Gunopulos.",
                "Identifying similarities, periodicities and bursts for online search queries.",
                "In SIGMOD, pages 131-142, 2004. [20] Y. Yang, T. Pierce, and J. Carbonell.",
                "A study of retrospective and on-line event detection.",
                "In SIGIR, pages 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topic-conditioned novelty detection.",
                "In SIGKDD, pages 688-693, 2002.",
                "Table 1: All important aperiodic events (e1 − e17), top 5 less-reported aperiodic events (e18 − e22) and top 5 important periodic events (e23 − e27).",
                "Detected Event and Bursty Period Doc # True Event e1(Sali,Berisha,Albania,Albanian,March) 02/02/199705/29/1997 1409 Albanians president Sali Berisha lost in an early election and resigned, 12/1996-07/1997. e2(Seko,Mobutu,Sese,Kabila) 03/22/1997-06/09/1997 2273 Zaires president Mobutu Sese coordinated the native rebellion and failed on 05/16/1997. e3(Marxist,Peruvian) 11/19/1996-03/05/1997 824 Peru rebels (Tupac Amaru revolutionary Movement) led a hostage siege in Lima in early 1997. e4(Movement,Tupac,Amaru,Lima,hostage,hostages) 11/16/1996-03/20/1997 824 The same as e3. e5(Kinshasa,Kabila,Laurent,Congo) 03/26/199706/15/1997 1378 Zaire was renamed the Democratic Republic of Congo on 05/16/1997. e6(Jospin,Lionel,June) 05/10/1997-07/09/1997 605 Following the early General Elections circa 06/1997, Lionel Jospin was appointed Prime Minister on 06/02/1997. e7(Iraq,missile) 08/31/1996-09/13/1996 1262 U.S. fired missile at Iraq on 09/03/1996 and 09/04/1996. e8(Kurdish,Baghdad,Iraqi) 08/29/1996-09/09/1996 1132 Iraqi troop fought with Kurdish faction circa 09/1996. e9(May,Blair) 03/24/1997-07/04/1997 1049 Tony Blair became the Primary Minister of the United Kingdom on 05/02/1997. e10(slalom,skiing) 12/05/1996-03/21/1997 253 Slalom Game of Alpine Skiing in 01/1997-02/1997. e11(Interim,months) 09/24/1996-12/31/1996 3063 Tokyo released company interim results for the past several months in 09/1996-12/1996. e12(Dole,Bob) 09/09/1996-11/24/1996 1599 Dole Bob lost the 1996 US presidential election. e13(July,Sen) 06/25/1997-06/25/1997 344 Cambodias Prime Minister Hun Sen launched a bloody military coup in 07/1997. e14(Hebron) 10/15/1996-02/14/1997 2098 Hebron was divided into two sectors in early 1997. e15(April,Easter) 02/23/1997-05/04/1997 480 Easter feasts circa 04/1997 (for western and Orthodox). e16(Diluted,Group) 04/27/1997-07/20/1997 1888 Tokyo released all 96/97 group results in 04/199707/1997. e17(December,Christmas) 11/17/1996-01/26/1997 1326 Christmas feast in late 12/1997. e18(Kolaceva,winter,Together,promenades,Zajedno, Slobodan,Belgrade,Serbian,Serbia,Draskovic,municipal, Kragujevac) 1/25/1997 3 University students organized a vigil on Kolaceva street against government on 1/25/1997. e19(Tutsi,Luvengi,Burundi,Uvira,fuel,Banyamulenge, Burundian,Kivu,Kiliba,Runingo,Kagunga,Bwegera) 10/19/1996 6 Fresh fighting erupted around Uvira between Zaire armed forces and Banyamulengs Tutsi rebels on 10/19/1996. e20(Malantacchi,Korea,Guy,Rider,Unions,labour, Trade,unions,Confederation,rammed,Geneva,stoppages, Virgin,hire,Myongdong,Metalworkers) 1/11/1997 2 Marcello Malantacchi secretary general of the International Metalworkers Federation and Guy Rider who heads the Geneva office of the International Confederation of Free Trade Unions attacked the new labour law of South Korea on 1/11/1997. e21(DBS,Raﬄes) 8/17/1997 9 The list of the unit of Singapore DBS Land Raﬄes Holdings plans on 8/17/1997. e22(preserver,fuel,Galawa,Huddle,Leul,Beausse) 11/24/1996 3 Rescued a woman and her baby during a hijacked Ethiopian plane that ran out of fuel and crashed into the sea near Le Galawa beach on 11/24/1996. e23(PRICE,LISTING,MLN,MATURITY,COUPON, MOODY,AMT,FIRST,ISS,TYPE,PAY,BORROWER) Monday-Friday/week 7966 Announce bond price on all weekdays. e24(Unaudited,Ended,Months,Weighted,Provision,Cost, Selling,Revenues,Loss,Income,except,Shrs,Revs) every season 2264 Net income-loss reports released by companies in every season. e25(rating,Wall,Street,Ian) Monday-Friday/week 21767 Stock reports from Wall Street on all weekdays. e26(Sheffield,league,scoring,goals,striker,games) every Friday, Saturday and Sunday 574 Match results of Sheffield soccer league were published on Friday, Saturday and Sunday 10 times than other 4 days. e27(soccer,matches,Results,season,game,Cup,match, victory,beat,played,play,division) every Friday, Saturday and Sunday 2396 Soccer games held on Friday, Saturday and Sunday 7 times than other 4 days."
            ],
            "original_annotated_samples": [
                "Recently, there has been significant interest in modeling an event in <br>text stream</br>s as a burst of activities by incorporating temporal information.",
                "Kleinbergs seminal work described how bursty features can be extracted from <br>text stream</br>s using an infinite automaton model [12], which inspired a whole series of applications such as Kumars identification of bursty communities from Weblog graphs [13], Meis summarization of evolutionary themes in <br>text stream</br>s [15], Hes clustering of text streams using bursty features [11], etc.",
                "Parameter free bursty events detection in <br>text stream</br>s.",
                "Bursty feature reprensentation for clustering <br>text stream</br>s."
            ],
            "translated_annotated_samples": [
                "Recientemente, ha habido un gran interés en modelar un evento en <br>flujos de texto</br> como un estallido de actividades al incorporar información temporal.",
                "El trabajo seminal de Kleinberg describió cómo se pueden extraer características explosivas de <br>flujos de texto</br> utilizando un modelo de autómata infinito [12], lo que inspiró toda una serie de aplicaciones como la identificación de comunidades explosivas de Kumar a partir de gráficos de blogs [13], la sumarización de temas evolutivos en <br>flujos de texto</br> de Meis [15], el agrupamiento de flujos de texto utilizando características explosivas de Hes [11], etc.",
                "Detección de eventos explosivos sin parámetros en <br>flujos de texto</br>.",
                "Representación de características intermitentes para la agrupación de <br>flujos de texto</br>."
            ],
            "translated_text": "Analizando Trayectorias de Características para la Detección de Eventos Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg Escuela de Ingeniería Informática Universidad Tecnológica de Nanyang Bloque N4, Avenida Nanyang, Singapur 639798 RESUMEN Consideramos el problema de analizar trayectorias de palabras en los dominios del tiempo y la frecuencia, con el objetivo específico de identificar palabras importantes y menos reportadas, periódicas y aperiódicas. Un conjunto de palabras con tendencias idénticas puede agruparse para reconstruir un evento de manera completamente no supervisada. La frecuencia del documento de cada palabra a lo largo del tiempo se trata como una serie temporal, donde cada elemento es el puntaje de frecuencia del documento - frecuencia inversa del documento (DFIDF) en un punto temporal. En este artículo, 1) primero aplicamos análisis espectral para categorizar características de diferentes tipos de eventos: importantes y poco reportados, periódicos y aperiódicos; 2) modelamos las características aperiódicas con densidad gaussiana y las características periódicas con densidades de mezcla gaussiana, y posteriormente detectamos cada ráfaga de características mediante el enfoque gaussiano truncado; 3) propusimos un algoritmo de detección de eventos codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos. Todos los métodos anteriores se pueden aplicar a datos de series temporales en general. Evaluamos exhaustivamente nuestros métodos en el Corpus de Noticias de Reuters de 1 año [3] y demostramos que fueron capaces de descubrir eventos significativos aperiódicos y periódicos. Categorías y Descriptores de Asignaturas: H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales: Algoritmos, Experimentación. 1. INTRODUCCIÓN Hay más de 4,000 fuentes de noticias en línea en el mundo. Supervisar manualmente todos ellos en busca de eventos importantes se ha vuelto difícil o prácticamente imposible. De hecho, la comunidad de detección y seguimiento de temas (TDT) ha estado tratando durante muchos años de encontrar una solución práctica para ayudar a las personas a monitorear las noticias de manera efectiva. Desafortunadamente, el Santo Grial sigue siendo esquivo, ya que la gran mayoría de las soluciones de TDT propuestas para la detección de eventos [20, 5, 17, 4, 21, 7, 14, 10] son demasiado simplistas (basadas en la similitud del coseno [5]) o impracticables debido a la necesidad de ajustar un gran número de parámetros [9]. La ineficacia de las tecnologías actuales de TDT se puede ilustrar fácilmente suscribiéndose a cualquiera de los muchos servicios de alertas de noticias en línea, como el líder de la industria Google News Alerts, que genera más del 50% de falsas alarmas. Como prueba adicional, portales como Yahoo adoptan un enfoque más pragmático al requerir que todas las alertas de noticias generadas por máquinas pasen por un operador humano para su confirmación antes de enviarlas a los suscriptores. En lugar de abordar el problema con variaciones del mismo martillo (similitud coseno y TFIDF), es necesario contar con una comprensión fundamental de las características de los datos de flujo de noticias antes de que se puedan lograr avances importantes en TDT. Por lo tanto, en este artículo, examinamos noticias y tendencias de características desde la perspectiva de analizar una señal de palabras de series temporales. Trabajos anteriores como [9] han intentado reconstruir un evento con sus características representativas. Sin embargo, en muchas tareas de detección de eventos predictivos (es decir, detección de eventos retrospectivos), hay un vasto conjunto de características potenciales solo para un conjunto fijo de observaciones (es decir, los estallidos obvios). De estas características, a menudo solo se espera que un pequeño número sea útil. En particular, estudiamos el novedoso problema de analizar trayectorias de características para la detección de eventos, utilizando una técnica conocida de procesamiento de señales: identificar correlaciones distribucionales entre todas las características mediante análisis espectral. Para evaluar nuestro método, posteriormente proponemos un algoritmo de detección de eventos no supervisado para flujos de noticias. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Pascua Abril (a) evento aperiódico 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 No auditado Finalizado (b) evento periódico Figura 1: Correlación de características (DFIDF:tiempo) entre a) Pascua y Abril b) No auditado y Finalizado. Como ejemplo ilustrativo, considera la correlación entre las palabras Pascua y abril del Corpus de Reuters. A partir del gráfico de su DFIDF normalizado en la Figura 1(a), observamos la gran superposición entre las dos palabras alrededor de 04/1997, lo que significa que probablemente ambas pertenecen al mismo evento durante ese tiempo (festividad de Pascua). En este ejemplo, el evento oculto de la festividad de Pascua es un evento aperiódico típico e importante en datos de 1 año. Otro ejemplo se muestra en la Figura 1(b), donde las palabras \"No auditado\" y \"Finalizado 1\" del Corpus de Reuters son el conjunto de datos predeterminado para todos los ejemplos y presentan un comportamiento similar durante períodos de 3 meses. Estas dos palabras en realidad se originaron a partir del mismo evento periódico, informes de ganancias y pérdidas, que son publicados trimestralmente por empresas cotizadas en bolsa. Otras observaciones extraídas de la Figura 1 son: 1) el período de actividad intensa de abril es mucho más largo que el de Semana Santa, lo que sugiere que abril puede estar presente en otros eventos durante el mismo período; 2) No auditado tiene un valor promedio de DFIDF más alto que Finalizado, lo que indica que No auditado es más representativo para el evento subyacente. Estos dos ejemplos son solo la punta del iceberg entre todas las tendencias de palabras y correlaciones ocultas en un flujo de noticias como Reuters. Si se puede descubrir un gran número de ellos, podría ayudar significativamente en las tareas de TDT. En particular, indica la importancia de extraer características correlacionadas para detectar eventos correspondientes. Para resumir, postulamos que: 1) Un evento se describe por sus características representativas. Un evento periódico tiene una lista de características periódicas y un evento aperiódico tiene una lista de características aperiódicas; 2) Las características representativas del mismo evento comparten distribuciones similares en el tiempo y están altamente correlacionadas; 3) Un evento importante tiene un conjunto de características representativas activas (ampliamente reportadas), mientras que un evento no importante tiene un conjunto de características representativas inactivas (menos reportadas); 4) Una característica puede ser incluida por varios eventos con superposiciones en los marcos de tiempo. Basándonos en estas observaciones, podemos extraer características representativas dadas un evento o detectar un evento a partir de una lista de características altamente correlacionadas. En este artículo, nos enfocamos en este último aspecto, es decir, cómo se pueden descubrir características correlacionadas para formar un evento de manera no supervisada. 1.1 Contribuciones Este artículo tiene tres contribuciones principales: • Hasta donde sabemos, nuestro enfoque es el primero en categorizar características de palabras para eventos heterogéneos. Específicamente, cada característica de palabra se clasifica en uno de los siguientes cinco tipos de características basados en la fuerza de su espectro de potencia y periodicidad: 1) HH (alta potencia y alta/larga periodicidad): eventos aperiódicos importantes, 2) HL (alta potencia y baja periodicidad): eventos periódicos importantes, 3) LH (baja potencia y alta periodicidad): eventos aperiódicos no importantes, 4) LL (baja potencia y baja periodicidad): no eventos, y 5) SW (palabras vacías), un subconjunto de LL con mayor potencia y periodicidad que comprende palabras vacías, que no contienen información. • Proponemos un enfoque simple y efectivo basado en densidad de mezcla para modelar y detectar ráfagas de características. • Presentamos un algoritmo de detección de eventos no supervisado para detectar eventos tanto aperiódicos como periódicos. Nuestro algoritmo ha sido evaluado en un flujo de noticias reales para demostrar su efectividad. 2. TRABAJO RELACIONADO Este trabajo está motivado en gran medida por una familia más amplia de problemas conocidos colectivamente como Detección y Seguimiento de Temas (TDT) [20, 5, 17, 4, 21, 7, 14, 10]. Además, la mayoría de las investigaciones de TDT hasta ahora se han centrado en agrupar/clasificar documentos en tipos de temas, identificar oraciones novedosas para eventos nuevos, etc., sin prestar mucha atención al análisis de la trayectoria de las palabras con respecto al tiempo. Swan y Allan [18] intentaron por primera vez usar términos que co-ocurren para construir un evento. Sin embargo, solo consideraron entidades nombradas y pares de frases nominales, sin tener en cuenta sus periodicidades. Por el contrario, nuestro artículo considera todo lo anterior. Recientemente, ha habido un gran interés en modelar un evento en <br>flujos de texto</br> como un estallido de actividades al incorporar información temporal. El trabajo seminal de Kleinberg describió cómo se pueden extraer características explosivas de <br>flujos de texto</br> utilizando un modelo de autómata infinito [12], lo que inspiró toda una serie de aplicaciones como la identificación de comunidades explosivas de Kumar a partir de gráficos de blogs [13], la sumarización de temas evolutivos en <br>flujos de texto</br> de Meis [15], el agrupamiento de flujos de texto utilizando características explosivas de Hes [11], etc. Sin embargo, ninguno de los trabajos existentes identificó específicamente características para eventos, excepto Fung et al. [9], quienes agruparon características llamativas para identificar varios eventos llamativos. Nuestro trabajo difiere de [9] en varias formas: 1) analizamos cada característica individual, no solo las características explosivas; 2) clasificamos las características a lo largo de dos dimensiones categóricas (periodicidad y potencia), dando en total cinco tipos de características principales; 3) no restringimos que cada característica pertenezca exclusivamente a un solo evento. Las técnicas de análisis espectral han sido utilizadas previamente por Vlachos et al. [19] para identificar periodicidades y ráfagas en los registros de consultas. Su enfoque estaba en detectar múltiples periodicidades a partir del gráfico del espectro de potencia, las cuales luego se utilizaron para indexar palabras para la búsqueda por ráfagas. En este artículo, utilizamos análisis espectral para clasificar las características de las palabras a lo largo de dos dimensiones, a saber, periodicidad y espectro de potencia, con el objetivo final de identificar eventos tanto periódicos como no periódicos y explosivos. 3. REPRESENTACIÓN DE DATOS Sea T la duración/período (en días) de un flujo de noticias, y F representa el espacio de características de palabras completo en el Modelo de Espacio Vectorial (VSM) estático clásico. 3.1 Clasificación de Periodicidad de Eventos Dentro de T, pueden existir ciertos eventos que ocurren solo una vez, por ejemplo, la elección de Tony Blair como Primer Ministro del Reino Unido, y otros eventos recurrentes de diversas periodicidades, por ejemplo, partidos de fútbol semanales. Por lo tanto, categorizamos todos los eventos en dos tipos: aperiódicos y periódicos, definidos de la siguiente manera. Definición 1. (Evento aperiódico) Un evento es aperiódico dentro de T si solo ocurre una vez. Definición 2. (Evento periódico) Si los eventos de un cierto género de eventos ocurren regularmente con una periodicidad fija P ≤ T/2, decimos que este género particular de eventos es periódico, y cada evento miembro se califica como un evento periódico. Ten en cuenta que la definición de aperiódico es relativa, es decir, es verdadera solo para un T dado y puede ser inválida para cualquier otro T > T. Por ejemplo, el evento de la fiesta de Navidad es aperiódico para T ≤ 365 pero periódico para T ≥ 730. 3.2 Características Representativas Intuitivamente, un evento puede ser descrito de manera muy concisa por unas pocas características de palabras discriminativas y representativas y viceversa, por ejemplo, huracán, barrido y golpe podrían ser características representativas de un evento del género de huracanes. Asimismo, un conjunto de características fuertemente correlacionadas podría ser utilizado para reconstruir una descripción de un evento, asumiendo que las características fuertemente correlacionadas son representativas. El vector de representación de una característica de palabra se define de la siguiente manera: Definición 3. (Trayectoria de la Característica) La trayectoria de una característica de palabra f puede escribirse como la secuencia yf = [yf (1), yf (2), . . . , yf (T)], donde cada elemento yf (t) es una medida de la característica f en el tiempo t, que podría definirse utilizando la puntuación normalizada DFIDF yf (t) = DFf (t) N(t) × log( N DFf ), donde DFf (t) es el número de documentos (DF local) que contienen la característica f en el día t, DFf es el número total de documentos (DF global) que contienen la característica f en T, N(t) es el número de documentos para el día t, y N es el número total de documentos en T. 4. En esta sección, mostramos cómo se pueden extraer características representativas para eventos (poco) importantes o (a)periódicos. 4.1 Análisis Espectral para el Período Dominante Dada una característica f, descomponemos su trayectoria de características yf = [yf (1), yf (2), ..., yf (T)] en la secuencia de T números complejos [X1, . . . , XT ] a través de la transformada discreta de Fourier (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. La DFT puede representar la serie temporal original como una combinación lineal de sinusoides complejas, lo cual se ilustra mediante la transformada discreta de Fourier inversa (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, donde el coeficiente de Fourier Xk denota la amplitud del sinusoides con frecuencia k/T. La trayectoria original puede ser reconstruida con solo las frecuencias dominantes, las cuales pueden ser determinadas a partir del espectro de potencia utilizando el popular estimador periodograma. El periodograma es una secuencia de la magnitud al cuadrado de los coeficientes de Fourier, Xk^2, k = 1, 2, . . . , T/2, que indica la potencia de la señal en la frecuencia k/T en el espectro. A partir del espectro de potencia, se elige el período dominante como el inverso de la frecuencia con el espectro de potencia más alto, de la siguiente manera. Definición 4. (Período Dominante) El período dominante (DP) de una característica dada f es Pf = T/ arg max k Xk 2. Por lo tanto, tenemos la Definición 5. (Espectro de Potencia Dominante) El espectro de potencia dominante (DPS) de una característica dada f es Sf = Xk 2 , con Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorización de Características El DPS de una trayectoria de características es un indicador fuerte de su actividad en la frecuencia especificada; cuanto mayor sea el DPS, es más probable que la característica sea explosiva. Al combinar DPS con DP, categorizamos todas las características en cuatro tipos: 2 Normalizamos yf (t) como yf (t) = yf (t)/ T i=1 yf (i) para que pueda interpretarse como una probabilidad. • HH: alta Sf, aperiódico o periódico a largo plazo (Pf > T/2); • HL: alta Sf, periódico a corto plazo (Pf ≤ T/2); • LH: baja Sf, aperiódico o periódico a largo plazo; • LL: baja Sf, periódico a corto plazo. La frontera entre los periodos a largo plazo y a corto plazo se establece en T/2. Sin embargo, distinguir entre un DPS alto y bajo no es sencillo, lo cual se abordará más adelante. Propiedades de diferentes conjuntos de características Para comprender mejor las propiedades de HH, HL, LH y LL, seleccionamos cuatro características, Navidad, fútbol, DBS y tu como ejemplos ilustrativos. Dado que la frontera entre el espectro de alta y baja potencia no está clara, estos ejemplos seleccionados tienen un rango relativo amplio de valores de espectro de potencia. La figura 2(a) muestra la trayectoria de DFIDF para la Navidad con un pico distintivo alrededor del día de Navidad. Para el conjunto de datos de Reuters de 1 año, la Navidad se clasifica como un evento aperiódico típico con Pf = 365 y Sf = 135.68, como se muestra en la Figura 2(b). Claramente, el valor de Sf = 135.68 es razonable para un evento conocido por ser intermitente como la Navidad. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Navidad(DFIDF:tiempo) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Navidad(S:frecuencia) Figura 2: Característica Navidad con un Sf relativamente alto y un Pf a largo plazo. La trayectoria de DFIDF para el fútbol se muestra en la Figura 3(a), de la cual podemos observar que hay un estallido regular cada 7 días, lo cual es nuevamente verificado por su valor calculado de Pf = 7, como se muestra en la Figura 3(b). Usando el conocimiento del dominio de que los partidos de fútbol tienen más encuentros cada sábado, lo que lo convierte en un evento periódico típico y ampliamente reportado, consideramos que el valor de Sf = 155.13 es alto. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) fútbol (DFIDF:tiempo) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) fútbol (S:frecuencia) Figura 3: Característica fútbol con un Sf relativamente alto y un Pf a corto plazo. A partir de la trayectoria de DFIDF para DBS en la Figura 4(a), podemos deducir de inmediato que DBS es una palabra poco frecuente con un aumento trivial el 17/08/1997 correspondiente a los planes de DBS Land Raﬄes Holdings. Esto se confirma por el largo período de Pf = 365 y la baja potencia de Sf = 0.3084 como se muestra en la Figura 4(b). Además, dado que este evento aperiódico solo se informa en algunas noticias durante un corto período de unos pocos días, por lo tanto, decimos que su bajo valor de potencia de Sf = 0.3084 es representativo de eventos poco importantes. El ejemplo más confuso se muestra en la Figura 5 para la palabra \"your\", que se ve muy similar al gráfico para fútbol en la Figura 3. A primera vista, podríamos sentirnos tentados a agrupar tanto tu como el fútbol en la misma categoría de HL o LL, ya que ambas distribuciones se ven similares y tienen el mismo período dominante de aproximadamente una semana. Sin embargo, más adelante 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:tiempo) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frecuencia) Figura 4: Característica DBS con Sf relativamente bajo y Pf a largo plazo. El análisis indica que la periodicidad de su es debido a las diferencias en el recuento de documentos para los días de la semana (promedio de 2,919 por día) y los fines de semana (promedio de 479 por día). Uno habría esperado que la periodicidad de una palabra vacía como \"tu\" fuera de un día. Además, a pesar de nuestra normalización de DFIDF, el desequilibrio entre los días de la semana y los fines de semana aún prevalecía; las palabras vacías ocurren 4 veces más frecuentemente los fines de semana que los días de semana. Por lo tanto, el DPS sigue siendo el único factor distintivo entre tu (Sf = 9.42) y el fútbol (Sf = 155.13). Sin embargo, es muy peligroso concluir simplemente que un valor de potencia de S = 9.42 corresponde a una característica de palabra vacía. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) tu(DFIDF:tiempo) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) tu(S:frecuencia) Figura 5: Característica tu como un ejemplo confundido con la característica fútbol. Antes de presentar nuestra solución a este problema, veamos otro ejemplo de LL como se muestra en la Figura 6 para beenb, que en realidad es un error tipográfico confirmado. Por lo tanto, clasificamos beenb como una característica ruidosa que no contribuye a ningún evento. Claramente, la trayectoria de tu es muy diferente de beenb, lo que significa que el primero debe considerarse por separado. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figura 6: Característica beenb con Sf relativamente bajo y Pf a corto plazo. Conjunto de características de palabras vacías (SW) Basándonos en el análisis anterior, nos damos cuenta de que debe haber otro conjunto de características entre HL y LL que corresponda al conjunto de palabras vacías. Las características de este conjunto tienen un DPS moderado y un período dominante bajo pero conocido. Dado que es difícil distinguir este conjunto de características de HL y LL solo basándose en DPS, introducimos otro factor llamado promedio de DFIDF (DFIDF). Como se muestra en la Figura 5, características como la tuya suelen tener un DPS más bajo que una característica HL como el fútbol, pero tienen un DFIDF mucho más alto que otra característica ruidosa LL como \"beenb\". Dado que tales propiedades suelen ser características de las palabras vacías, agrupamos características como \"tu\" en el conjunto de características de palabras vacías (SW) recién definido. Dado que establecer los umbrales de DPS y DFIDF para identificar las palabras vacías es más un arte que una ciencia, propusimos un algoritmo heurístico HS, Algoritmo 1. La idea básica es utilizar solo noticias de días laborables para identificar palabras vacías. Los fines de semana aquí también incluyen días festivos que caen en días laborables. El conjunto SW se inicialmente alimenta con un pequeño conjunto de 29 stopwords populares utilizadas por el motor de búsqueda de Google. Algoritmo 1 Detección heurística de palabras vacías (HS) Entrada: Conjunto de palabras vacías semilla, trayectorias semanales de todas las palabras 1: A partir del conjunto semilla SW, calcular el DPS máximo como UDPS, el DFIDF máximo como UDFIDF y el mínimo de DFIDF como LDFIDF. 2: para fi ∈ F hacer 3: Calcular DFT para fi. 4: si Sfi ≤ UDPS y DFIDFfi ∈ [LDFIDF, UDFIDF] entonces 5: fi → SW 6: F = F - fi 7: fin si 8: fin para Resumen de la Categorización de Características Después de generar el conjunto SW, se eliminan todas las palabras vacías de F. Luego, establecemos el límite entre DPS alto y bajo como el límite superior de los DPS de los conjuntos SW. Una visión general de los cinco conjuntos de características se muestra en la Figura 7. Figura 7: Los 5 conjuntos de características para eventos. 5. IDENTIFICACIÓN DE RÁFAGAS PARA CARACTERÍSTICAS Dado que solo las características de HH, HL y LH son significativas y podrían ser representativas de algunos eventos, eliminamos todas las demás características clasificadas como LL o SW. En esta sección, describimos cómo se pueden identificar los estallidos a partir de las características restantes. A diferencia del algoritmo de identificación de ráfagas de Kleinberg [12], podemos identificar tanto ráfagas significativas como triviales sin necesidad de establecer ningún parámetro. 5.1 Detección de ráfagas de características aperiódicas Para cada característica en HH y HL, truncamos su trayectoria manteniendo solo el período de ráfagas, el cual está modelado con una distribución gaussiana. Por ejemplo, la Figura 8 muestra la característica de la palabra Iraq con una explosión alrededor del 09/06/1996 modelada como una Gaussiana. Su período de ráfagas está definido por [μf − σf , μf + σf ] como se muestra en la Figura 8(b). 5.2 Detección de características periódicas de ráfagas Dado que hemos calculado el DP para una característica periódica f, podemos modelar fácilmente su trayectoria de características periódicas yf usando 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) DFIDF original: tiempo 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 ráfaga= [μ-σ, μ+σ] (b) identificación de ráfaga Figura 8: Modelando la serie temporal de Iraq como una Gaussiana truncada con μ = 09/06/1996 y σ = 6.26. una mezcla de K = T/Pf Gaussianas: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , donde el conjunto de parámetros θf = {αk, μk, σk}K k=1 comprende: • αk es la probabilidad de asignar yf a la k-ésima Gaussiana. αk > 0, ∀k ∈ [1, K] y K k=1 αk = 1; • μk/σk es la media/desviación estándar de la k-ésima Gaussiana. El conocido algoritmo Expectation Maximization (EM) [8] se utiliza para calcular las proporciones de mezcla αk, así como los parámetros individuales de densidad gaussiana μk y σK. Cada Gaussiana representa un evento periódico, y se modela de manera similar como se menciona en la Sección 5.1. 6. EVENTOS A PARTIR DE CARACTERÍSTICAS Después de identificar y modelar ráfagas para todas las características, la siguiente tarea es pintar un cuadro del evento con un posible conjunto de características representativas. 6.1 Correlación de Características Si dos características fi y fj son representativas del mismo evento, deben cumplir las siguientes condiciones necesarias: 1. fi y fj están distribuidas de manera idéntica: yfi ∼ yfj. 2. fi y fj tienen una alta superposición de documentos. Medición de la similitud de la distribución de características. Medimos la similitud entre dos características fi y fj utilizando la divergencia KL discreta definida de la siguiente manera. Definición 6. (similitud de características) KL(fi, fj) se da por max(KL(fi|fj), KL(fj|fi)), donde KL(fi|fj) = T t=1 f(yfi(t)|θfi)log f(yfi(t)|θfi) f(yfj(t)|θfj). (1) Dado que la divergencia KL no es simétrica, definimos la similitud entre fi y fj como el máximo entre KL(fi|fj) y KL(fj|fi). Además, la similitud entre dos características aperiódicas puede calcularse utilizando una forma cerrada de la divergencia de Kullback-Leibler [16]. La misma fórmula discreta de divergencia KL de la Ecuación 1 se emplea para calcular la similitud entre dos características periódicas. A continuación, definimos la similitud general entre un conjunto de características R utilizando el valor máximo de divergencia KL entre características como sigue. Definición 7. (similitud de conjuntos) KL(R) = max ∀fi, fj ∈R KL(fi, fj). Superposición de documentos: Sea Mi el conjunto de todos los documentos que contienen la característica fi. Dadas dos características fi y fj, el conjunto de documentos superpuestos que contienen ambas características es Mi ∩ Mj. De manera intuitiva, cuanto mayor sea |Mi ∩ Mj|, es más probable que fi y fj estén altamente correlacionados. Definimos el grado de superposición de documentos entre dos características fi y fj de la siguiente manera. Definición 8. (Superposición de características DF) d(fi, fj) = |Mi∩Mj| min(|Mi|, |Mj|). En consecuencia, la superposición de DF entre un conjunto de características R también está definida. Definición 9. (Superposición de Conjuntos DF) d(R) = min ∀fi, fj ∈R d(fi, fj). 6.2 Detección de Eventos Codiciosa No Supervisada Utilizamos características de HH para detectar eventos aperiódicos importantes, características de LH para detectar eventos aperiódicos menos reportados/poco importantes, y características de HL para detectar eventos periódicos. Todos comparten el mismo algoritmo. Dado el rasgo explosivo fi ∈ HH, el objetivo es encontrar rasgos altamente correlacionados de HH. El conjunto de características similares a fi puede describir colectivamente un evento. Específicamente, necesitamos encontrar un subconjunto Ri de HH que minimice la siguiente función de costo: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) El evento subyacente e (asociado con la explosión de fi) puede ser representado por Ri como y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) El análisis de la explosión para el evento e es exactamente el mismo que la trayectoria de características. El costo en la Ecuación 2 se puede minimizar utilizando nuestro algoritmo de detección de eventos UG codicioso no supervisado, que se describe en el Algoritmo 2. El algoritmo UG permite una característica Algoritmo 2 Detección de eventos codiciosos no supervisados (UG). Salida: ek como Ec. 3. Además, los eventos triviales que solo contienen características de año/mes (es decir, un evento que solo contiene una característica de agosto podría ser identificado en un flujo de noticias de 1 año) podrían ser eliminados, aunque dichos eventos tendrán un costo inherente alto y deberían estar clasificados muy bajos. Tenga en cuenta que nuestro algoritmo UG solo requiere un parámetro dependiente de los datos, el límite entre el espectro de alta y baja potencia, que debe establecerse una vez, y este parámetro puede estimarse fácilmente utilizando el algoritmo HS (Algoritmo 1). 7. EXPERIMENTOS En esta sección, estudiamos el rendimiento de nuestro método de categorización de características y algoritmo de detección de eventos. Primero presentamos el conjunto de datos y la configuración experimental, luego evaluamos subjetivamente la categorización de características para HH, HL, LH, LL y SW. Finalmente, estudiamos el problema de detección de eventos (a)periódicos con el Algoritmo 2. 7.1. Conjunto de datos y configuración experimental El Corpus de Reuters contiene 806,791 noticias en inglés desde el 20/08/1996 hasta el 19/08/1997 con una resolución diaria. La versión 2 del software de código abierto Lucene [1] se utilizó para tokenizar el contenido de texto de noticias y generar el vector documento-palabra. Con el fin de preservar los tiempos verbales pasados/presentes/futuros sensibles al tiempo y las diferencias entre los sustantivos en minúscula y las entidades nombradas en mayúscula, no se realizó ningún truncamiento. Dado que la eliminación dinámica de palabras vacías es una de las funcionalidades de nuestro método, no se eliminó ninguna palabra vacía. Eliminamos los caracteres no ingleses, sin embargo, después de eso, el número de características de palabras asciende a 423,433. Todos los experimentos se implementaron en Java y se llevaron a cabo en una PC Pentium 4 de 3.2 GHz con Windows 2003 Server y 1 GB de memoria. 7.2 Categorización de características Descargamos 34 stopwords bien conocidos utilizados por el motor de búsqueda de Google como nuestras características de entrenamiento iniciales, que incluyen a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en y www. Excluimos las últimas cinco palabras vacías ya que son poco comunes en noticias. Al analizar solo historias de noticias durante 259 días laborables, calculamos el límite superior del espectro de potencia para las palabras vacías en 11.18 y los rangos correspondientes de DFIDF van desde 0.1182 hasta 0.3691. Cualquier característica f que cumpla con Sf <= 11.18 y 0.1182 <= DFIDFf <= 0.3691 durante los días de la semana se considerará una palabra vacía. De esta manera, se encontraron y eliminaron 470 palabras vacías como se muestra en la Figura 9. Algunas palabras vacías detectadas son A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) y much (P = 22, S = 0.80, DFIDF = 0.1865). Después de la eliminación de estas palabras vacías, la distribución de las noticias entre semana y los fines de semana están más o menos equilibradas, y en los experimentos subsiguientes, haremos uso del corpus completo (entre semana y fines de semana). El valor del espectro de potencia límite superior de 11.18 para el entrenamiento de palabras vacías fue seleccionado como el límite entre el espectro de alta potencia y baja potencia. El límite entre alta y baja periodicidad se estableció en 365/2 = 183. Todos los 422,963 (423433 − 470) rasgos de palabras fueron categorizados en 4 conjuntos de rasgos: HH (69 rasgos), HL (1,087 rasgos), LH (83,471 rasgos) y LL (338,806 rasgos) como se muestra en la Figura 10. En la Figura 10, cada nivel de gris denota la densidad relativa de características en una región cuadrada, medida por log10(1 + Dk), donde Dk es el número de características dentro de la k-ésima región cuadrada. A partir de la figura, podemos hacer el 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figura 9: Distribución de SW (palabras vacías) en las regiones HH, HL, LH y LL. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figura 10: Distribución de características categorizadas en los cuatro cuadrantes (sombreado en escala logarítmica). siguientes observaciones: 1. La mayoría de las características tienen un valor bajo de S y son fácilmente distinguibles de aquellas características que tienen un valor mucho más alto de S, lo que nos permite detectar eventos importantes (a)periódicos de eventos triviales seleccionando características con un alto valor de S. 2. Las características en los cuadrantes HH y LH son aperiódicas, las cuales están bien separadas (gran brecha horizontal) de las características periódicas. Esto permite detectar de manera confiable eventos aperiódicos y eventos periódicos de forma independiente. 3. La frontera (vertical) entre el espectro de alta y baja potencia no es tan clara y el valor exacto dependerá de la aplicación específica. Al revisar la distribución de dispersión de las características de SW en HH, HL, LH y LL como se muestra en la Figura 9, encontramos que el 87.02% (409/470) de las stopwords detectadas se originaron en LL. La clasificación LL y las altas puntuaciones de DFIDF de las palabras vacías concuerdan con la noción generalmente aceptada de que las palabras vacías son igualmente frecuentes en todo momento. Por lo tanto, establecer el límite entre el espectro de alta y baja potencia utilizando el límite superior Sf de SW es una heurística razonable. 7.3 Detección de Eventos Aperiódicos Evaluaremos nuestras dos hipótesis, 1)los eventos aperiódicos importantes pueden ser definidos por un conjunto de características HH, y 2)los eventos aperiódicos menos reportados pueden ser definidos por un conjunto de características LH. Dado que no existen flujos de noticias de referencia para la detección de eventos (los conjuntos de datos de TDT no son flujos adecuados), evaluamos la calidad de los eventos detectados automáticamente comparándolos con eventos confirmados manualmente mediante la búsqueda en el corpus. Entre las 69 características de HH, detectamos 17 eventos aperiódicos importantes como se muestra en la Tabla 1 (e1 - e17). Ten en cuenta que toda la identificación tomó menos de 1 segundo, después de eliminar los eventos que solo contenían la característica del mes. De los 17 eventos, aparte de las superposiciones entre e3 y e4 (ambos describen el mismo evento de rehenes), e11 y e16 (ambos sobre informes de empresas), los 14 eventos identificados son extremadamente precisos y corresponden muy bien a los principales eventos del período. Por ejemplo, la derrota de Bob Dole, la elección de Tony Blair, el ataque con misiles a Iraq, etc. Recuerde que seleccionar las características para un evento debería minimizar el costo en la Ecuación 2 de tal manera que 1) el número de características abarque diferentes eventos, y 2) no se seleccionarán todas las características relevantes para un evento, por ejemplo, la característica Clinton es representativa para e12, pero dado que Clinton se relaciona con muchos otros eventos, su señal de dominio temporal es muy diferente de la de otras características representativas como Dole y Bob. El número de documentos de un evento detectado se estima aproximadamente por el número de documentos indexados que contienen las características representativas. Podemos ver que los 17 eventos aperiódicos importantes son eventos reportados popularmente. Después de 742 minutos de tiempo de computación, detectamos 23,525 eventos aperiódicos menos reportados de 83,471 características de LH. La Tabla 1 enumera los 5 principales eventos aperiódicos detectados (e18 - e22) con respecto al costo. Descubrimos que estos 5 eventos son en realidad eventos muy triviales con solo unos pocos informes de noticias, y suelen ser englobados por algunos temas más grandes. Por ejemplo, e22 es uno de los eventos de rescate en un tema de secuestro de avión. Una ventaja de nuestro Algoritmo UG para descubrir eventos aperiódicos poco reportados es que podemos detectar con precisión el verdadero período del evento. 7.4 Detección de Eventos Periódicos Entre las 1,087 características de HL, se detectaron 330 eventos periódicos importantes en un tiempo de cálculo de 10 minutos. La Tabla 1 enumera los 5 eventos periódicos detectados con respecto al costo (e23 - e27). Todos los eventos periódicos detectados son realmente válidos y corresponden a eventos periódicos de la vida real. El modelo GMM es capaz de detectar y estimar el período de ráfagas de manera precisa, aunque no puede distinguir la ligera diferencia entre cada lunes a viernes y todos los días de la semana, como se muestra en e23. También observamos que e26 es en realidad un subconjunto de e27 (partido de fútbol), lo cual es aceptable ya que los resultados de la liga de Sheffield se anuncian de forma independiente cada fin de semana. 8. CONCLUSIONES Este artículo adoptó una perspectiva completamente nueva para analizar las trayectorias de características como señales en el dominio del tiempo. Al considerar las frecuencias de los documentos en el dominio del tiempo y de la frecuencia, pudimos derivar muchas nuevas características sobre los flujos de noticias que antes eran desconocidas, por ejemplo, las diferentes distribuciones de palabras vacías durante los días de la semana y los fines de semana. Por primera vez en el área de TDT, aplicamos un enfoque sistemático para detectar automáticamente eventos importantes y menos reportados, periódicos y aperiódicos. La idea clave de nuestro trabajo radica en las observaciones de que los eventos periódicos tienen características representativas periódicas y los eventos (in)importantes tienen características representativas (in)activas, diferenciadas por sus espectros de potencia y períodos de tiempo. Para abordar el problema de detección de eventos reales, se utilizó un enfoque basado en densidad de mezcla simple y efectivo para identificar ráfagas de características y sus períodos asociados de ráfagas. También diseñamos un algoritmo codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos, el cual tuvo éxito en detectar eventos reales como se muestra en la evaluación en un flujo de noticias reales. Aunque no hemos realizado ninguna comparación de referencia con otro enfoque, simplemente porque no hay trabajos previos en el problema abordado. El trabajo futuro incluye evaluar la recuperación de eventos detectados en un flujo de noticias etiquetado, y comparar nuestro modelo con los métodos equivalentes más cercanos, que actualmente se limitan a los métodos de Kleinberg [12] (que solo pueden detectar ciertos tipos de eventos explosivos dependiendo de la configuración de parámetros), Fung et al. [9], y Swan y Allan [18]. Sin embargo, creemos que nuestro método simple y efectivo será útil para todos los practicantes de TDT, y será especialmente útil para el análisis exploratorio inicial de flujos de noticias. REFERENCIAS [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Alertas de noticias de Google, http://www.google.com/alerts. [3] Corpus de Reuters, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan. Detección y seguimiento de temas. Organización de la información basada en eventos. Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, y H. Jin. La detección de la primera historia en tdt es difícil. En CIKM, páginas 374-381, 2000. [6] J. Allan, C. Wade y A. Bolivar. Recuperación y detección de novedades a nivel de oración. En SIGIR, páginas 314-321, 2003. [7] T. Brants, F. Chen y A. Farahat. Un sistema para la detección de nuevos eventos. En SIGIR, páginas 330-337, 2003. [8] A. P. Dempster, N. M. Laird y D. B. Rubin. Máxima verosimilitud a partir de datos incompletos a través del algoritmo EM. Revista de la Real Sociedad Estadística, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu y H. Lu. Detección de eventos explosivos sin parámetros en <br>flujos de texto</br>. En VLDB, páginas 181-192, 2005. [10] Q. Él, K. Chang y E.-P. Lim. Un modelo para la detección anticipada de eventos. En ER, páginas 168-181, 2006. [11] Q. Él, K. Chang, E.-P. Lim y J. Zhang. Representación de características intermitentes para la agrupación de <br>flujos de texto</br>. En SDM, aceptado, 2007. [12] J. Kleinberg. Estructura explosiva y jerárquica en arroyos. En SIGKDD, páginas 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan y A. Tomkins. Sobre la evolución explosiva del blogosfera. En WWW, páginas 159-178, 2005. [14] G. Kumaran y J. Allan. Clasificación de texto y entidades nombradas para la detección de nuevos eventos. En SIGIR, páginas 297-304, 2004. [15] Q. Mei y C. Zhai. Descubriendo patrones temáticos evolutivos a partir de texto: una exploración de la minería de texto temporal. En SIGKDD, páginas 198-207, 2005. [16] W. D. Penny. Divergencias de Kullback-Leibler de densidades normales, gamma, dirichlet y wishart. Informe técnico, 2001. [17] N. Stokes y J. Carthy. Combinando clasificadores de documentos semánticos y sintácticos para mejorar la detección de la primera noticia. En SIGIR, páginas 424-425, 2001. [18] R. Swan y J. Allan. Generación automática de líneas de tiempo de resumen. En SIGIR, páginas 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena y D. Gunopulos. Identificando similitudes, periodicidades y ráfagas en las consultas de búsqueda en línea. En SIGMOD, páginas 131-142, 2004. [20] Y. Yang, T. Pierce y J. Carbonell. Un estudio de detección de eventos retrospectivos y en línea. En SIGIR, páginas 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell y C. Jin. Detección de novedades condicionada por el tema. En SIGKDD, páginas 688-693, 2002. Tabla 1: Todos los eventos aperiódicos importantes (e1 - e17), los 5 eventos aperiódicos menos reportados (e18 - e22) y los 5 eventos periódicos importantes (e23 - e27). Evento detectado y período de actividad intensa Doc # Verdadero evento e1 (Sali, Berisha, Albania, albanés, marzo) 02/02/199705/29/1997 1409 El presidente albanés Sali Berisha perdió en una elección temprana y renunció, 12/1996-07/1997. e2 (Seko, Mobutu, Sese, Kabila) 03/22/1997-06/09/1997 2273 El presidente de Zaire, Mobutu Sese, coordinó la rebelión nativa y fracasó el 16/05/1997. e3 (Marxista, peruano) 11/19/1996-03/05/1997 824 Los rebeldes de Perú (Movimiento Revolucionario Tupac Amaru) lideraron un asedio de rehenes en Lima a principios de 1997. e4 (Movimiento, Tupac, Amaru, Lima, rehén, rehenes) 11/16/1996-03/20/1997 824 Lo mismo que e3. e5 (Kinshasa, Kabila, Laurent, Congo) 03/26/199706/15/1997 1378 Zaire fue renombrado República Democrática del Congo el 16/05/1997. e6 (Jospin, Lionel, junio) 05/10/1997-07/09/1997 605 Tras las elecciones generales tempranas alrededor de 06/1997, Lionel Jospin fue nombrado Primer Ministro el 02/06/1997. e7 (Irak, misil) 08/31/1996-09/13/1996 1262 EE. UU. disparó un misil a Irak el 03/09/1996 y el 04/09/1996. e8 (kurdo, Bagdad, iraquí) 08/29/1996-09/09/1996 1132 Tropas iraquíes lucharon con facciones kurdas alrededor de 09/1996. e9 (mayo, Blair) 03/24/1997-07/04/1997 1049 Tony Blair se convirtió en el Primer Ministro del Reino Unido el 02/05/1997. e10 (slalom, esquí) 12/05/1996-03/21/1997 253 Juego de eslalon de esquí alpino en 01/1997-02/1997. e11 (Interino, meses) 09/24/1996-12/31/1996 3063 Tokio publicó los resultados interinos de la empresa para los últimos meses en 09/1996-12/1996. e12 (Dole, Bob) 09/09/1996-11/24/1996 1599 Bob Dole perdió las elecciones presidenciales de EE. UU. de 1996. e13 (julio, Sen) 06/25/1997-06/25/1997 344 El Primer Ministro de Camboya, Hun Sen, lanzó un sangriento golpe militar en 07/1997. e14 (Hebrón) 10/15/1996-02/14/1997 2098 Hebrón fue dividida en dos sectores a principios de 1997. e15 (abril, Pascua) 02/23/1997-05/04/1997 480 Festividades de Pascua alrededor de 04/1997 (para occidentales y ortodoxos). e16 (Diluido, Grupo) 04/27/1997-07/20/1997 1888 Tokio publicó todos los resultados del grupo 96/97 en 04/199707/1997. e17 (diciembre, Navidad) 11/17/1996-01/26/1997 1326 Festín de Navidad a finales de 12/1997. e18 (Kolaceva, invierno, Juntos, paseos, Zajedno, Slobodan, Belgrado, serbio, Serbia, Draskovic, municipal, Kragujevac) 1/25/1997 3 Estudiantes universitarios organizaron una vigilia en la calle Kolaceva contra el gobierno el 25/01/1997. e19 (Tutsi, Luvengi, Burundi, Uvira, combustible, Banyamulenge, burundés, Kivu, Kiliba, Runingo, Kagunga, Bwegera) 10/19/1996 6 Estallaron nuevos enfrentamientos alrededor de Uvira entre las fuerzas armadas de Zaire y los rebeldes Tutsi de Banyamulenge el 19/10/1996. e20 (Malantacchi, Corea, Guy, Rider, Sindicatos, trabajo, Confederación, embestido, Ginebra, paradas, Virgin, contratar, Myongdong, Metalúrgicos) 1/11/1997 2 Marcello Malantacchi, secretario general de la Federación Internacional de Metalúrgicos, y Guy Rider, quien dirige la oficina de Ginebra de la Confederación Internacional de Sindicatos Libres, atacaron la nueva ley laboral de Corea del Sur el 11/01/1997. e21 (DBS, Raﬄes) 8/17/1997 9 La lista de la unidad de DBS Land Raﬄes Holdings de Singapur planea el 17/08/1997. e22 (conservador, combustible, Galawa, Huddle, Leul, Beausse) 11/24/1996 3 Rescataron a una mujer y a su bebé durante un secuestro de un avión etíope que se quedó sin combustible y se estrelló en el mar cerca de la playa Le Galawa el 24/11/1996. e23 (PRECIO, LISTADO, MLN, VENCIMIENTO, CUPÓN, MOODY, MONTO, PRIMERO, ISS, TIPO, PAGO, PRESTAMISTA) Lunes a viernes/semana 7966 Anuncian el precio de los bonos todos los días de la semana. e24 (No auditado, Terminado, Meses, Ponderado, Provisión, Costo, Venta, Ingresos, Pérdida, Ingreso, excepto, Shrs, Revs) cada temporada 2264 Informes de ingresos netos-pérdidas publicados por empresas en cada temporada. e25 (calificación, Wall Street, Ian) Lunes a viernes/semana 21767 Informes de acciones de Wall Street todos los días de la semana. e26 (Sheffield, liga, goles de puntuación, delantero, juegos) cada viernes, sábado y domingo 574 Resultados de partidos de la liga de fútbol de Sheffield publicados los viernes, sábados y domingos 10 veces más que en los otros 4 días. e27 (fútbol, partidos, Resultados, temporada, juego, Copa, partido, victoria, vencer, jugado, jugar, división) cada viernes, sábado y domingo 2396 Juegos de fútbol celebrados los viernes, sábados y domingos 7 veces más que en los otros 4 días. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "news stream": {
            "translated_key": "flujo de noticias",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Analyzing Feature Trajectories for Event Detection Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg School of Computer Engineering Nanyang Technological University Block N4, Nanyang Avenue, Singapore 639798 ABSTRACT We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words.",
                "A set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner.",
                "The document frequency of each word across time is treated like a time series, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point.",
                "In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events.",
                "All of the above methods can be applied to time series data in general.",
                "We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events.",
                "Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Experimentation. 1.",
                "INTRODUCTION There are more than 4,000 online news sources in the world.",
                "Manually monitoring all of them for important events has become difficult or practically impossible.",
                "In fact, the topic detection and tracking (TDT) community has for many years been trying to come up with a practical solution to help people monitor news effectively.",
                "Unfortunately, the holy grail is still elusive, because the vast majority of TDT solutions proposed for event detection [20, 5, 17, 4, 21, 7, 14, 10] are either too simplistic (based on cosine similarity [5]) or impractical due to the need to tune a large number of parameters [9].",
                "The ineffectiveness of current TDT technologies can be easily illustrated by subscribing to any of the many online news alerts services such as the industryleading Google News Alerts [2], which generates more than 50% false alarms [10].",
                "As further proof, portals like Yahoo take a more pragmatic approach by requiring all machine generated news alerts to go through a human operator for confirmation before sending them out to subscribers.",
                "Instead of attacking the problem with variations of the same hammer (cosine similarity and TFIDF), a fundamental understanding of the characteristics of <br>news stream</br> data is necessary before any major breakthroughs can be made in TDT.",
                "Thus in this paper, we look at news stories and feature trends from the perspective of analyzing a time-series word signal.",
                "Previous work like [9] has attempted to reconstruct an event with its representative features.",
                "However, in many predictive event detection tasks (i.e., retrospective event detection), there is a vast set of potential features only for a fixed set of observations (i.e., the obvious bursts).",
                "Of these features, often only a small number are expected to be useful.",
                "In particular, we study the novel problem of analyzing feature trajectories for event detection, borrowing a well-known technique from signal processing: identifying distributional correlations among all features by spectral analysis.",
                "To evaluate our method, we subsequently propose an unsupervised event detection algorithm for news streams. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Easter April (a) aperiodic event 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Unaudited Ended (b) periodic event Figure 1: Feature correlation (DFIDF:time) between a) Easter and April b) Unaudited and Ended.",
                "As an illustrative example, consider the correlation between the words Easter and April from the Reuters Corpus1 .",
                "From the plot of their normalized DFIDF in Figure 1(a), we observe the heavy overlap between the two words circa 04/1997, which means they probably both belong to the same event during that time (Easter feast).",
                "In this example, the hidden event Easter feast is a typical important aperiodic event over 1-year data.",
                "Another example is given by Figure 1(b), where both the words Unaudited and Ended 1 Reuters Corpus is the default dataset for all examples. exhibit similar behaviour over periods of 3 months.",
                "These two words actually originated from the same periodic event, net income-loss reports, which are released quarterly by publicly listed companies.",
                "Other observations drawn from Figure 1 are: 1) the bursty period of April is much longer than Easter, which suggests that April may exist in other events during the same period; 2) Unaudited has a higher average DFIDF value than Ended, which indicates Unaudited to be more representative for the underlying event.",
                "These two examples are but the tip of the iceberg among all word trends and correlations hidden in a <br>news stream</br> like Reuters.",
                "If a large number of them can be uncovered, it could significantly aid TDT tasks.",
                "In particular, it indicates the significance of mining correlating features for detecting corresponding events.",
                "To summarize, we postulate that: 1) An event is described by its representative features.",
                "A periodic event has a list of periodic features and an aperiodic event has a list of aperiodic features; 2) Representative features from the same event share similar distributions over time and are highly correlated; 3) An important event has a set of active (largely reported) representative features, whereas an unimportant event has a set of inactive (less-reported) representative features; 4) A feature may be included by several events with overlaps in time frames.",
                "Based on these observations, we can either mine representative features given an event or detect an event from a list of highly correlated features.",
                "In this paper, we focus on the latter, i.e., how correlated features can be uncovered to form an event in an unsupervised manner. 1.1 Contributions This paper has three main contributions: • To the best of our knowledge, our approach is the first to categorize word features for heterogenous events.",
                "Specifically, every word feature is categorized into one of the following five feature types based on its power spectrum strength and periodicity: 1) HH (high power and high/long periodicity): important aperiodic events, 2) HL (high power and low periodicity): important periodic events, 3) LH (low power and high periodicity): unimportant aperiodic events, 4) LL (low power and low periodicity): non-events, and 5) SW (stopwords), a higher power and periodicity subset of LL comprising stopwords, which contains no information. • We propose a simple and effective mixture densitybased approach to model and detect feature bursts. • We come up with an unsupervised event detection algorithm to detect both aperiodic and periodic events.",
                "Our algorithm has been evaluated on a real <br>news stream</br> to show its effectiveness. 2.",
                "RELATED WORK This work is largely motivated by a broader family of problems collectively known as Topic Detection and Tracking (TDT) [20, 5, 17, 4, 21, 7, 14, 10].",
                "Moreover, most TDT research so far has been concerned with clustering/classifying documents into topic types, identifying novel sentences [6] for new events, etc., without much regard to analyzing the word trajectory with respect to time.",
                "Swan and Allan [18] first attempted using co-occuring terms to construct an event.",
                "However, they only considered named entities and noun phrase pairs, without considering their periodicities.",
                "On the contrary, our paper considers all of the above.",
                "Recently, there has been significant interest in modeling an event in text streams as a burst of activities by incorporating temporal information.",
                "Kleinbergs seminal work described how bursty features can be extracted from text streams using an infinite automaton model [12], which inspired a whole series of applications such as Kumars identification of bursty communities from Weblog graphs [13], Meis summarization of evolutionary themes in text streams [15], Hes clustering of text streams using bursty features [11], etc.",
                "Nevertheless, none of the existing work specifically identified features for events, except for Fung et al. [9], who clustered busty features to identify various bursty events.",
                "Our work differs from [9] in several ways: 1) we analyze every single feature, not only bursty features; 2) we classify features along two categorical dimensions (periodicity and power), yielding altogether five primary feature types; 3) we do not restrict each feature to exclusively belong to only one event.",
                "Spectral analysis techniques have previously been used by Vlachos et al. [19] to identify periodicities and bursts from query logs.",
                "Their focus was on detecting multiple periodicities from the power spectrum graph, which were then used to index words for query-by-burst search.",
                "In this paper, we use spectral analysis to classify word features along two dimensions, namely periodicity and power spectrum, with the ultimate goal of identifying both periodic and aperiodic bursty events. 3.",
                "DATA REPRESENTATION Let T be the duration/period (in days) of a <br>news stream</br>, and F represents the complete word feature space in the classical static Vector Space Model (VSM). 3.1 Event Periodicity Classification Within T, there may exist certain events that occur only once, e.g., Tony Blair elected as Prime Minister of U.K., and other recurring events of various periodicities, e.g., weekly soccer matches.",
                "We thus categorize all events into two types: aperiodic and periodic, defined as follows.",
                "Definition 1. (Aperiodic Event) An event is aperiodic within T if it only happens once.",
                "Definition 2. (Periodic Event) If events of a certain event genre occur regularly with a fixed periodicity P ≤ T/2 , we say that this particular event genre is periodic, with each member event qualified as a periodic event.",
                "Note that the definition of aperiodic is relative, i.e., it is true only for a given T, and may be invalid for any other T > T. For example, the event Christmas feast is aperiodic for T ≤ 365 but periodic for T ≥ 730. 3.2 Representative Features Intuitively, an event can be described very concisely by a few discriminative and representative word features and vice-versa, e.g., hurricane, sweep, and strike could be representative features of a Hurricane genre event.",
                "Likewise, a set of strongly correlated features could be used to reconstruct an event description, assuming that strongly correlated features are representative.",
                "The representation vector of a word feature is defined as follows: Definition 3. (Feature Trajectory) The trajectory of a word feature f can be written as the sequence yf = [yf (1), yf (2), . . . , yf (T)], where each element yf (t) is a measure of feature f at time t, which could be defined using the normalized DFIDF score2 yf (t) = DFf (t) N(t) × log( N DFf ), where DFf (t) is the number of documents (local DF) containing feature f at day t, DFf is the total number of documents (global DF) containing feature f over T, N(t) is the number of documents for day t, and N is the total number of documents over T. 4.",
                "IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 Spectral Analysis for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. DFT can represent the original time series as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T.",
                "The original trajectory can be reconstructed with just the dominant frequencies, which can be determined from the power spectrum using the popular periodogram estimator.",
                "The periodogram is a sequence of the squared magnitude of the Fourier coefficients, Xk 2 , k = 1, 2, . . . , T/2 , which indicates the signal power at frequency k/T in the spectrum.",
                "From the power spectrum, the dominant period is chosen as the inverse of the frequency with the highest power spectrum, as follows.",
                "Definition 4. (Dominant Period) The dominant period (DP) of a given feature f is Pf = T/ arg max k Xk 2 .",
                "Accordingly, we have Definition 5. (Dominant Power Spectrum) The dominant power spectrum (DPS) of a given feature f is Sf = Xk 2 , with Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorizing Features The DPS of a feature trajectory is a strong indicator of its activeness at the specified frequency; the higher the DPS, the more likely for the feature to be bursty.",
                "Combining DPS with DP, we therefore categorize all features into four types: 2 We normalize yf (t) as yf (t) = yf (t)/ T i=1 yf (i) so that it could be interpreted as a probability. • HH: high Sf , aperiodic or long-term periodic (Pf > T/2 ); • HL: high Sf , short-term periodic (Pf ≤ T/2 ); • LH: low Sf , aperiodic or long-term periodic; • LL: low Sf , short-term periodic.",
                "The boundary between long-term and short-term periodic is set to T/2 .",
                "However, distinguishing between a high and low DPS is not straightforward, which will be tackled later.",
                "Properties of Different Feature Sets To better understand the properties of HH, HL, LH and LL, we select four features, Christmas, soccer, DBS and your as illustrative examples.",
                "Since the boundary between high and low power spectrum is unclear, these chosen examples have relative wide range of power spectrum values.",
                "Figure 2(a) shows the DFIDF trajectory for Christmas with a distinct burst around Christmas day.",
                "For the 1-year Reuters dataset, Christmas is classified as a typical aperiodic event with Pf = 365 and Sf = 135.68, as shown in Figure 2(b).",
                "Clearly, the value of Sf = 135.68 is reasonable for a well-known bursty event like Christmas. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Christmas(DFIDF:time) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Christmas(S:frequency) Figure 2: Feature Christmas with relative high Sf and long-term Pf .",
                "The DFIDF trajectory for soccer is shown in Figure 3(a), from which we can observe that there is a regular burst every 7 days, which is again verified by its computed value of Pf = 7, as shown in Figure 3(b).",
                "Using the domain knowledge that soccer games have more matches every Saturday, which makes it a typical and heavily reported periodic event, we thus consider the value of Sf = 155.13 to be high. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) soccer(DFIDF:time) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) soccer(S:frequency) Figure 3: Feature soccer with relative high Sf and short-term Pf .",
                "From the DFIDF trajectory for DBS in Figure 4(a), we can immediately deduce DBS to be an infrequent word with a trivial burst on 08/17/1997 corresponding to DBS Land Raﬄes Holdings plans.",
                "This is confirmed by the long period of Pf = 365 and low power of Sf = 0.3084 as shown in Figure 4(b).",
                "Moreover, since this aperiodic event is only reported in a few news stories over a very short time of few days, we therefore say that its low power value of Sf = 0.3084 is representative of unimportant events.",
                "The most confusing example is shown in Figure 5 for the word feature your, which looks very similar to the graph for soccer in Figure 3.",
                "At first glance, we may be tempted to group both your and soccer into the same category of HL or LL since both distributions look similar and have the same dominant period of approximately a week.",
                "However, further 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:time) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frequency) Figure 4: Feature DBS with relative low Sf and long-term Pf . analysis indicates that the periodicity of your is due to the differences in document counts for weekdays (average 2,919 per day) and weekends3 (average 479 per day).",
                "One would have expected the periodicity of a stopword like your to be a day.",
                "Moreover, despite our DFIDF normalization, the weekday/weekend imbalance still prevailed; stopwords occur 4 times more frequently on weekends than on weekdays.",
                "Thus, the DPS remains the only distinguishing factor between your (Sf = 9.42) and soccer (Sf = 155.13).",
                "However, it is very dangerous to simply conclude that a power value of S = 9.42 corresponds to a stopword feature. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) your(DFIDF:time) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) your(S:frequency) Figure 5: Feature your as an example confusing with feature soccer.",
                "Before introducing our solution to this problem, lets look at another LL example as shown in Figure 6 for beenb, which is actually a confirmed typo.",
                "We therefore classify beenb as a noisy feature that does not contribute to any event.",
                "Clearly, the trajectory of your is very different from beenb, which means that the former has to be considered separately. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figure 6: Feature beenb with relative low Sf and short-term Pf .",
                "Stop Words (SW) Feature Set Based on the above analysis, we realize that there must be another feature set between HL and LL that corresponds to the set of stopwords.",
                "Features from this set has moderate DPS and low but known dominant period.",
                "Since it is hard to distinguish this feature set from HL and LL only based on DPS, we introduce another factor called average DFIDF (DFIDF).",
                "As shown in Figure 5, features like your usually have a lower DPS than a HL feature like soccer, but have a much higher DFIDF than another LL noisy feature such as beenb.",
                "Since such properties are usually characteristics of stopwords, we group features like your into the newly defined stopword (SW) feature set.",
                "Since setting the DPS and DFIDF thresholds for identifying stopwords is more of an art than science, we proposed a heuristic HS algorithm, Algorithm 1.",
                "The basic idea is to only use news stories from weekdays to identify stopwords. 3 The weekends here also include public holidays falling on weekdays.",
                "The SW set is initially seeded with a small set of 29 popular stopwords utilized by Google search engine.",
                "Algorithm 1 Heuristic Stopwords detection (HS) Input: Seed SW set, weekday trajectories of all words 1: From the seed set SW, compute the maximum DPS as UDPS, maximum DFIDF as UDFIDF, and minimum of DFIDF as LDFIDF. 2: for fi ∈ F do 3: Compute DFT for fi. 4: if Sfi ≤ UDPS and DFIDFfi ∈ [LDFIDF, UDFIDF] then 5: fi → SW 6: F = F − fi 7: end if 8: end for Overview of Feature Categorization After the SW set is generated, all stopwords are removed from F. We then set the boundary between high and low DPS to be the upper bound of the SW sets DPS.",
                "An overview of all five feature sets is shown in Figure 7.",
                "Figure 7: The 5 feature sets for events. 5.",
                "IDENTIFYING BURSTS FOR FEATURES Since only features from HH, HL and LH are meaningful and could potentially be representative to some events, we pruned all other feature classified as LL or SW.",
                "In this section, we describe how bursts can be identified from the remaining features.",
                "Unlike Kleinbergs burst identification algorithm [12], we can identify both significant and trivial bursts without the need to set any parameters. 5.1 Detecting Aperiodic Features Bursts For each feature in HH and HL, we truncate its trajectory by keeping only the bursty period, which is modeled with a Gaussian distribution.",
                "For example, Figure 8 shows the word feature Iraq with a burst circa 09/06/1996 being modeled as a Gaussian.",
                "Its bursty period is defined by [μf − σf , μf + σf ] as shown in Figure 8(b). 5.2 Detecting Periodic Features Bursts Since we have computed the DP for a periodic feature f, we can easily model its periodic feature trajectory yf using 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) original DFIDF:time 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 burst= [μ-σ, μ+σ] (b) identifying burst Figure 8: Modeling Iraqs time series as a truncated Gaussian with μ = 09/06/1996 and σ = 6.26. a mixture of K = T/Pf Gaussians: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , where the parameter set θf = {αk, μk, σk}K k=1 comprises: • αk is the probability of assigning yf into the kth Gaussian. αk > 0, ∀k ∈ [1, K] and K k=1 αk = 1; • μk/σk is mean/standard deviation of the kth Gaussian.",
                "The well known Expectation Maximization (EM) [8] algorithm is used to compute the mixing proportions αk, as well as the individual Gaussian density parameters μk and σK .",
                "Each Gaussian represents one periodic event, and is modeled similarly as mentioned in Section 5.1. 6.",
                "EVENTS FROM FEATURES After identifying and modeling bursts for all features, the next task is to paint a picture of the event with a potential set of representative features. 6.1 Feature Correlation If two features fi and fj are representative of the same event, they must satisfy the following necessary conditions: 1. fi and fj are identically distributed: yfi ∼ yfj . 2. fi and fj have a high document overlap.",
                "Measuring Feature Distribution Similarity We measure the similarity between two features fi and fj using discrete KL-divergence defined as follows.",
                "Definition 6. (feature similarity) KL(fi, fj ) is given by max(KL(fi|fj ), KL(fj |fi)), where KL(fi|fj ) = T t=1 f(yfi (t)|θfi )log f(yfi (t)|θfi ) f(yfj (t)|θfj ) . (1) Since KL-divergence is not symmetric, we define the similarity between between fi and fj as the maximum of KL(fi|fj ) and KL(fj |fi).",
                "Further, the similarity between two aperiodic features can be computed using a closed form of the KL-divergence [16].",
                "The same discrete KL-divergence formula of Eq. 1 is employed to compute the similarity between two periodic features, Next, we define the overal similarity among a set of features R using the maximum inter-feature KL-Divergence value as follows.",
                "Definition 7. (sets similarity)KL(R) = max ∀fi,fj ∈R KL(fi, fj ).",
                "Document Overlap Let Mi be the set of all documents containing feature fi.",
                "Given two features fi and fj , the overlapping document set containing both features is Mi ∩ Mj .",
                "Intuitively, the higher the |Mi ∩ Mj |, the more likelty that fi and fj will be highly correlated.",
                "We define the degree of document overlap between two features fi and fj as follows.",
                "Definition 8. (Feature DF Overlap) d(fi, fj ) = |Mi∩Mj| min(|Mi|,|Mj|) .",
                "Accordingly, the DF Overlap among a set of features R is also defined.",
                "Definition 9. (Set DF Overlap) d(R) = min ∀fi,fj ∈R d(fi, fj). 6.2 Unsupervised Greedy Event Detection We use features from HH to detect important aperiodic events, features from LH to detect less-reported/unimportant aperiodic events, and features from HL to detect periodic events.",
                "All of them share the same algorithm.",
                "Given bursty feature fi ∈ HH, the goal is to find highly correlated features from HH.",
                "The set of features similar to fi can then collectively describe an event.",
                "Specifically, we need to find a subset Ri of HH that minimizes the following cost function: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) The underlying event e (associated with the burst of fi) can be represented by Ri as y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) The burst analysis for event e is exactly the same as the feature trajectory.",
                "The cost in Eq. 2 can be minimized using our unsupervised greedy UG event detection algorithm, which is described in Algorithm 2.",
                "The UG algorithm allows a feature Algorithm 2 Unsupervised Greedy event detection (UG).",
                "Input: HH, document index for each feature. 1: Sort and select features in descending DPS order: Sf1 ≥ Sf2 ≥ . . . ≥ Sf|HH| . 2: k = 0. 3: for fi ∈ HH do 4: k = k + 1. 5: Init: Ri ← fi, C(Ri) = 1/Sfi and HH = HH − fi. 6: while HH not empty do 7: m = arg min m C(Ri ∪ fm). 8: if C(Ri ∪ fm) < C(Ri) then 9: Ri ← fm and HH = HH − fm. 10: else 11: break while. 12: end if 13: end while 14: Output ek as Eq. 3. 15: end for to be contained in multiple events so that we can detect several events happening at the same time.",
                "Furthermore, trivial events only containing year/month features (i.e., an event only containing 1 feature Aug could be identified over a 1year <br>news stream</br>) could be removed, although such events will have inherent high cost and should already be ranked very low.",
                "Note that our UG algorithm only requires one data-dependant parameter, the boundary between high and low power spectrum, to be set once, and this parameter can be easily estimated using the HS algorithm (Algorithm 1). 7.",
                "EXPERIMENTS In this section, we study the performances of our feature categorizing method and event detection algorithm.",
                "We first introduce the dataset and experimental setup, then we subjectively evaluate the categorization of features for HH, HL, LH, LL and SW.",
                "Finally, we study the (a)periodic event detection problem with Algorithm 2. 7.1 Dataset and Experimental Setup The Reuters Corpus contains 806,791 English news stories from 08/20/1996 to 08/19/1997 at a day resolution.",
                "Version 2 of the open source Lucene software [1] was used to tokenize the news text content and generate the document-word vector.",
                "In order to preserve the time-sensitive past/present/future tenses of verbs and the differences between lower case nouns and upper case named entities, no stemming was done.",
                "Since dynamic stopword removal is one of the functionalities of our method, no stopword was removed.",
                "We did remove nonEnglish characters, however, after which the number of word features amounts to 423,433.",
                "All experiments were implemented in Java and conducted on a 3.2 GHz Pentium 4 PC running Windows 2003 Server with 1 GB of memory. 7.2 Categorizing Features We downloaded 34 well-known stopwords utilized by the Google search engine as our seed training features, which includes a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en and www.",
                "We excluded the last five stopwords as they are uncommon in news stories.",
                "By only analyzing news stories over 259 weekdays, we computed the upper bound of the power spectrum for stopwords at 11.18 and corresponding DFIDF ranges from 0.1182 to 0.3691.",
                "Any feature f satisfying Sf <= 11.18 and 0.1182 <= DFIDFf <= 0.3691 over weekdays will be considered a stopword.",
                "In this manner, 470 stopwords were found and removed as visualized in Figure 9.",
                "Some detected stopwords are A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) and much (P = 22, S = 0.80, DFIDF = 0.1865).",
                "After the removal of these stopwords, the distribution of weekday and weekend news are more or less matched, and in the ensuing experiments, we shall make use of the full corpus (weekdays and weekends).",
                "The upper bound power spectrum value of 11.18 for stopwords training was selected as the boundary between the high power and low power spectrum.",
                "The boundary between high and low periodicity was set to 365/2 = 183.",
                "All 422,963 (423433 − 470) word features were categorized into 4 feature sets: HH (69 features), HL (1,087 features), LH (83,471 features), and LL (338,806 features) as shown in Figure 10.",
                "In Figure 10, each gray level denotes the relative density of features in a square region, measured by log10(1 + Dk), where Dk is the number of features within the k-th square region.",
                "From the figure, we can make the 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figure 9: Distribution of SW (stopwords) in the HH, HL, LH, and LL regions. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figure 10: Distribution of categorized features over the four quadrants (shading in log scale). following observations: 1.",
                "Most features have low S and are easily distinguishable from those features having a much higher S, which allows us to detect important (a)periodic events from trivial events by selecting features with high S. 2.",
                "Features in the HH and LH quadrants are aperiodic, which are nicely separated (big horizontal gap) from the periodic features.",
                "This allows reliably detecting aperiodic events and periodic events independently. 3.",
                "The (vertical) boundary between high and low power spectrum is not as clearcut and the exact value will be application specific.",
                "By checking the scatter distribution of features from SW on HH, HL, LH, and LL as shown in Figure 9, we found that 87.02%(409/470) of the detected stopwords originated from LL.",
                "The LL classification and high DFIDF scores of stopwords agree with the generally accepted notion that stopwords are equally frequent over all time.",
                "Therefore, setting the boundary between high and low power spectrum using the upper bound Sf of SW is a reasonable heuristic. 7.3 Detecting Aperiodic Events We shall evaluate our two hypotheses, 1)important aperiodic events can be defined by a set of HH features, and 2)less reported aperiodic events can be defined by a set of LH features.",
                "Since no benchmark news streams exist for event detection (TDT datasets are not proper streams), we evaluate the quality of the automatically detected events by comparing them to manually-confirmed events by searching through the corpus.",
                "Among the 69 HH features, we detected 17 important aperiodic events as shown in Table 1 (e1 − e17).",
                "Note that the entire identification took less than 1 second, after removing events containing only the month feature.",
                "Among the 17 events, other than the overlaps between e3 and e4 (both describes the same hostage event), e11 and e16 (both about company reports), the 14 identified events are extremely accurate and correspond very well to the major events of the period.",
                "For example, the defeat of Bob Dole, election of Tony Blair, Missile attack on Iraq, etc.",
                "Recall that selecting the features for one event should minimize the cost in Eq. 2 such that 1) the number of features span different events, and 2) not all features relevant to an event will be selected, e.g., the feature Clinton is representative to e12 but since Clinton relates to many other events, its time domain signal is far different from those of other representative features like Dole and Bob.",
                "The number of documents of a detected event is roughly estimated by the number of indexed documents containing the representative features.",
                "We can see that all 17 important aperiodic events are popularly reported events.",
                "After 742 minutes of computation time, we detected 23, 525 less reported aperiodic events from 83,471 LH features.",
                "Table 1 lists the top 5 detected aperiodic events (e18 − e22) with respect to the cost.",
                "We found that these 5 events are actually very trivial events with only a few news reports, and are usually subsumed by some larger topics.",
                "For example, e22 is one of the rescue events in an airplane hijack topic.",
                "One advantage of our UG Algorithm for discovering less-reported aperiodic events is that we are able to precisely detect the true event period. 7.4 Detecting Periodic Events Among the 1,087 HL features, 330 important periodic events were detected within 10 minutes of computing time.",
                "Table 1 lists the top 5 detected periodic events with respect to the cost (e23 − e27).",
                "All of the detected periodic events are indeed valid, and correspond to real life periodic events.",
                "The GMM model is able to detect and estimate the bursty period nicely although it cannot distinguish the slight difference between every Monday-Friday and all weekdays as shown in e23.",
                "We also notice that e26 is actually a subset of e27 (soccer game), which is acceptable since the Sheffield league results are announced independently every weekend. 8.",
                "CONCLUSIONS This paper took a whole new perspective of analyzing feature trajectories as time domain signals.",
                "By considering the word document frequencies in both time and frequency domains, we were able to derive many new characteristics about news streams that were previously unknown, e.g., the different distributions of stopwords during weekdays and weekends.",
                "For the first time in the area of TDT, we applied a systematic approach to automatically detect important and less-reported, periodic and aperiodic events.",
                "The key idea of our work lies in the observations that (a)periodic events have (a)periodic representative features and (un)important events have (in)active representative features, differentiated by their power spectrums and time periods.",
                "To address the real event detection problem, a simple and effective mixture density-based approach was used to identify feature bursts and their associated bursty periods.",
                "We also designed an unsupervised greedy algorithm to detect both aperiodic and periodic events, which was successful in detecting real events as shown in the evaluation on a real <br>news stream</br>.",
                "Although we have not made any benchmark comparison against another approach, simply because there is no previous work in the addressed problem.",
                "Future work includes evaluating the recall of detected events for a labeled <br>news stream</br>, and comparing our model against the closest equivalent methods, which currently are limited to the methods of Kleinberg [12] (which can only detect certain type of bursty events depending on parameter settings), Fung et al. [9], and Swan and Allan [18].",
                "Nevertheless, we believe our simple and effective method will be useful for all TDT practitioners, and will be especially useful for the initial exploratory analysis of news streams. 9.",
                "REFERENCES [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Google news alerts, http://www.google.com/alerts. [3] Reuters corpus, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan.",
                "Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, and H. Jin.",
                "First story detection in tdt is hard.",
                "In CIKM, pages 374-381, 2000. [6] J. Allan, C. Wade, and A. Bolivar.",
                "Retrieval and novelty detection at the sentence level.",
                "In SIGIR, pages 314-321, 2003. [7] T. Brants, F. Chen, and A. Farahat.",
                "A system for new event detection.",
                "In SIGIR, pages 330-337, 2003. [8] A. P. Dempster, N. M. Laird, and D. B. Rubin.",
                "Maximum likelihood from incomplete data via the EM algorithm.",
                "Journal of the Royal Statistical Society, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu, and H. Lu.",
                "Parameter free bursty events detection in text streams.",
                "In VLDB, pages 181-192, 2005. [10] Q.",
                "He, K. Chang, and E.-P. Lim.",
                "A model for anticipatory event detection.",
                "In ER, pages 168-181, 2006. [11] Q.",
                "He, K. Chang, E.-P. Lim, and J. Zhang.",
                "Bursty feature reprensentation for clustering text streams.",
                "In SDM, accepted, 2007. [12] J. Kleinberg.",
                "Bursty and hierarchical structure in streams.",
                "In SIGKDD, pages 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins.",
                "On the bursty evolution of blogspace.",
                "In WWW, pages 159-178, 2005. [14] G. Kumaran and J. Allan.",
                "Text classification and named entities for new event detection.",
                "In SIGIR, pages 297-304, 2004. [15] Q. Mei and C. Zhai.",
                "Discovering evolutionary theme patterns from text: an exploration of temporal text mining.",
                "In SIGKDD, pages 198-207, 2005. [16] W. D. Penny.",
                "Kullback-liebler divergences of normal, gamma, dirichlet and wishart densities.",
                "Technical report, 2001. [17] N. Stokes and J. Carthy.",
                "Combining semantic and syntactic document classifiers to improve first story detection.",
                "In SIGIR, pages 424-425, 2001. [18] R. Swan and J. Allan.",
                "Automatic generation of overview timelines.",
                "In SIGIR, pages 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena, and D. Gunopulos.",
                "Identifying similarities, periodicities and bursts for online search queries.",
                "In SIGMOD, pages 131-142, 2004. [20] Y. Yang, T. Pierce, and J. Carbonell.",
                "A study of retrospective and on-line event detection.",
                "In SIGIR, pages 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topic-conditioned novelty detection.",
                "In SIGKDD, pages 688-693, 2002.",
                "Table 1: All important aperiodic events (e1 − e17), top 5 less-reported aperiodic events (e18 − e22) and top 5 important periodic events (e23 − e27).",
                "Detected Event and Bursty Period Doc # True Event e1(Sali,Berisha,Albania,Albanian,March) 02/02/199705/29/1997 1409 Albanians president Sali Berisha lost in an early election and resigned, 12/1996-07/1997. e2(Seko,Mobutu,Sese,Kabila) 03/22/1997-06/09/1997 2273 Zaires president Mobutu Sese coordinated the native rebellion and failed on 05/16/1997. e3(Marxist,Peruvian) 11/19/1996-03/05/1997 824 Peru rebels (Tupac Amaru revolutionary Movement) led a hostage siege in Lima in early 1997. e4(Movement,Tupac,Amaru,Lima,hostage,hostages) 11/16/1996-03/20/1997 824 The same as e3. e5(Kinshasa,Kabila,Laurent,Congo) 03/26/199706/15/1997 1378 Zaire was renamed the Democratic Republic of Congo on 05/16/1997. e6(Jospin,Lionel,June) 05/10/1997-07/09/1997 605 Following the early General Elections circa 06/1997, Lionel Jospin was appointed Prime Minister on 06/02/1997. e7(Iraq,missile) 08/31/1996-09/13/1996 1262 U.S. fired missile at Iraq on 09/03/1996 and 09/04/1996. e8(Kurdish,Baghdad,Iraqi) 08/29/1996-09/09/1996 1132 Iraqi troop fought with Kurdish faction circa 09/1996. e9(May,Blair) 03/24/1997-07/04/1997 1049 Tony Blair became the Primary Minister of the United Kingdom on 05/02/1997. e10(slalom,skiing) 12/05/1996-03/21/1997 253 Slalom Game of Alpine Skiing in 01/1997-02/1997. e11(Interim,months) 09/24/1996-12/31/1996 3063 Tokyo released company interim results for the past several months in 09/1996-12/1996. e12(Dole,Bob) 09/09/1996-11/24/1996 1599 Dole Bob lost the 1996 US presidential election. e13(July,Sen) 06/25/1997-06/25/1997 344 Cambodias Prime Minister Hun Sen launched a bloody military coup in 07/1997. e14(Hebron) 10/15/1996-02/14/1997 2098 Hebron was divided into two sectors in early 1997. e15(April,Easter) 02/23/1997-05/04/1997 480 Easter feasts circa 04/1997 (for western and Orthodox). e16(Diluted,Group) 04/27/1997-07/20/1997 1888 Tokyo released all 96/97 group results in 04/199707/1997. e17(December,Christmas) 11/17/1996-01/26/1997 1326 Christmas feast in late 12/1997. e18(Kolaceva,winter,Together,promenades,Zajedno, Slobodan,Belgrade,Serbian,Serbia,Draskovic,municipal, Kragujevac) 1/25/1997 3 University students organized a vigil on Kolaceva street against government on 1/25/1997. e19(Tutsi,Luvengi,Burundi,Uvira,fuel,Banyamulenge, Burundian,Kivu,Kiliba,Runingo,Kagunga,Bwegera) 10/19/1996 6 Fresh fighting erupted around Uvira between Zaire armed forces and Banyamulengs Tutsi rebels on 10/19/1996. e20(Malantacchi,Korea,Guy,Rider,Unions,labour, Trade,unions,Confederation,rammed,Geneva,stoppages, Virgin,hire,Myongdong,Metalworkers) 1/11/1997 2 Marcello Malantacchi secretary general of the International Metalworkers Federation and Guy Rider who heads the Geneva office of the International Confederation of Free Trade Unions attacked the new labour law of South Korea on 1/11/1997. e21(DBS,Raﬄes) 8/17/1997 9 The list of the unit of Singapore DBS Land Raﬄes Holdings plans on 8/17/1997. e22(preserver,fuel,Galawa,Huddle,Leul,Beausse) 11/24/1996 3 Rescued a woman and her baby during a hijacked Ethiopian plane that ran out of fuel and crashed into the sea near Le Galawa beach on 11/24/1996. e23(PRICE,LISTING,MLN,MATURITY,COUPON, MOODY,AMT,FIRST,ISS,TYPE,PAY,BORROWER) Monday-Friday/week 7966 Announce bond price on all weekdays. e24(Unaudited,Ended,Months,Weighted,Provision,Cost, Selling,Revenues,Loss,Income,except,Shrs,Revs) every season 2264 Net income-loss reports released by companies in every season. e25(rating,Wall,Street,Ian) Monday-Friday/week 21767 Stock reports from Wall Street on all weekdays. e26(Sheffield,league,scoring,goals,striker,games) every Friday, Saturday and Sunday 574 Match results of Sheffield soccer league were published on Friday, Saturday and Sunday 10 times than other 4 days. e27(soccer,matches,Results,season,game,Cup,match, victory,beat,played,play,division) every Friday, Saturday and Sunday 2396 Soccer games held on Friday, Saturday and Sunday 7 times than other 4 days."
            ],
            "original_annotated_samples": [
                "Instead of attacking the problem with variations of the same hammer (cosine similarity and TFIDF), a fundamental understanding of the characteristics of <br>news stream</br> data is necessary before any major breakthroughs can be made in TDT.",
                "These two examples are but the tip of the iceberg among all word trends and correlations hidden in a <br>news stream</br> like Reuters.",
                "Our algorithm has been evaluated on a real <br>news stream</br> to show its effectiveness. 2.",
                "DATA REPRESENTATION Let T be the duration/period (in days) of a <br>news stream</br>, and F represents the complete word feature space in the classical static Vector Space Model (VSM). 3.1 Event Periodicity Classification Within T, there may exist certain events that occur only once, e.g., Tony Blair elected as Prime Minister of U.K., and other recurring events of various periodicities, e.g., weekly soccer matches.",
                "Furthermore, trivial events only containing year/month features (i.e., an event only containing 1 feature Aug could be identified over a 1year <br>news stream</br>) could be removed, although such events will have inherent high cost and should already be ranked very low."
            ],
            "translated_annotated_samples": [
                "En lugar de abordar el problema con variaciones del mismo martillo (similitud coseno y TFIDF), es necesario contar con una comprensión fundamental de las características de los <br>datos de flujo de noticias</br> antes de que se puedan lograr avances importantes en TDT.",
                "Estos dos ejemplos son solo la punta del iceberg entre todas las tendencias de palabras y correlaciones ocultas en un <br>flujo de noticias</br> como Reuters.",
                "Nuestro algoritmo ha sido evaluado en un <br>flujo de noticias</br> reales para demostrar su efectividad. 2.",
                "REPRESENTACIÓN DE DATOS Sea T la duración/período (en días) de un <br>flujo de noticias</br>, y F representa el espacio de características de palabras completo en el Modelo de Espacio Vectorial (VSM) estático clásico. 3.1 Clasificación de Periodicidad de Eventos Dentro de T, pueden existir ciertos eventos que ocurren solo una vez, por ejemplo, la elección de Tony Blair como Primer Ministro del Reino Unido, y otros eventos recurrentes de diversas periodicidades, por ejemplo, partidos de fútbol semanales.",
                "Además, los eventos triviales que solo contienen características de año/mes (es decir, un evento que solo contiene una característica de agosto podría ser identificado en un <br>flujo de noticias</br> de 1 año) podrían ser eliminados, aunque dichos eventos tendrán un costo inherente alto y deberían estar clasificados muy bajos."
            ],
            "translated_text": "Analizando Trayectorias de Características para la Detección de Eventos Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg Escuela de Ingeniería Informática Universidad Tecnológica de Nanyang Bloque N4, Avenida Nanyang, Singapur 639798 RESUMEN Consideramos el problema de analizar trayectorias de palabras en los dominios del tiempo y la frecuencia, con el objetivo específico de identificar palabras importantes y menos reportadas, periódicas y aperiódicas. Un conjunto de palabras con tendencias idénticas puede agruparse para reconstruir un evento de manera completamente no supervisada. La frecuencia del documento de cada palabra a lo largo del tiempo se trata como una serie temporal, donde cada elemento es el puntaje de frecuencia del documento - frecuencia inversa del documento (DFIDF) en un punto temporal. En este artículo, 1) primero aplicamos análisis espectral para categorizar características de diferentes tipos de eventos: importantes y poco reportados, periódicos y aperiódicos; 2) modelamos las características aperiódicas con densidad gaussiana y las características periódicas con densidades de mezcla gaussiana, y posteriormente detectamos cada ráfaga de características mediante el enfoque gaussiano truncado; 3) propusimos un algoritmo de detección de eventos codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos. Todos los métodos anteriores se pueden aplicar a datos de series temporales en general. Evaluamos exhaustivamente nuestros métodos en el Corpus de Noticias de Reuters de 1 año [3] y demostramos que fueron capaces de descubrir eventos significativos aperiódicos y periódicos. Categorías y Descriptores de Asignaturas: H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales: Algoritmos, Experimentación. 1. INTRODUCCIÓN Hay más de 4,000 fuentes de noticias en línea en el mundo. Supervisar manualmente todos ellos en busca de eventos importantes se ha vuelto difícil o prácticamente imposible. De hecho, la comunidad de detección y seguimiento de temas (TDT) ha estado tratando durante muchos años de encontrar una solución práctica para ayudar a las personas a monitorear las noticias de manera efectiva. Desafortunadamente, el Santo Grial sigue siendo esquivo, ya que la gran mayoría de las soluciones de TDT propuestas para la detección de eventos [20, 5, 17, 4, 21, 7, 14, 10] son demasiado simplistas (basadas en la similitud del coseno [5]) o impracticables debido a la necesidad de ajustar un gran número de parámetros [9]. La ineficacia de las tecnologías actuales de TDT se puede ilustrar fácilmente suscribiéndose a cualquiera de los muchos servicios de alertas de noticias en línea, como el líder de la industria Google News Alerts, que genera más del 50% de falsas alarmas. Como prueba adicional, portales como Yahoo adoptan un enfoque más pragmático al requerir que todas las alertas de noticias generadas por máquinas pasen por un operador humano para su confirmación antes de enviarlas a los suscriptores. En lugar de abordar el problema con variaciones del mismo martillo (similitud coseno y TFIDF), es necesario contar con una comprensión fundamental de las características de los <br>datos de flujo de noticias</br> antes de que se puedan lograr avances importantes en TDT. Por lo tanto, en este artículo, examinamos noticias y tendencias de características desde la perspectiva de analizar una señal de palabras de series temporales. Trabajos anteriores como [9] han intentado reconstruir un evento con sus características representativas. Sin embargo, en muchas tareas de detección de eventos predictivos (es decir, detección de eventos retrospectivos), hay un vasto conjunto de características potenciales solo para un conjunto fijo de observaciones (es decir, los estallidos obvios). De estas características, a menudo solo se espera que un pequeño número sea útil. En particular, estudiamos el novedoso problema de analizar trayectorias de características para la detección de eventos, utilizando una técnica conocida de procesamiento de señales: identificar correlaciones distribucionales entre todas las características mediante análisis espectral. Para evaluar nuestro método, posteriormente proponemos un algoritmo de detección de eventos no supervisado para flujos de noticias. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Pascua Abril (a) evento aperiódico 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 No auditado Finalizado (b) evento periódico Figura 1: Correlación de características (DFIDF:tiempo) entre a) Pascua y Abril b) No auditado y Finalizado. Como ejemplo ilustrativo, considera la correlación entre las palabras Pascua y abril del Corpus de Reuters. A partir del gráfico de su DFIDF normalizado en la Figura 1(a), observamos la gran superposición entre las dos palabras alrededor de 04/1997, lo que significa que probablemente ambas pertenecen al mismo evento durante ese tiempo (festividad de Pascua). En este ejemplo, el evento oculto de la festividad de Pascua es un evento aperiódico típico e importante en datos de 1 año. Otro ejemplo se muestra en la Figura 1(b), donde las palabras \"No auditado\" y \"Finalizado 1\" del Corpus de Reuters son el conjunto de datos predeterminado para todos los ejemplos y presentan un comportamiento similar durante períodos de 3 meses. Estas dos palabras en realidad se originaron a partir del mismo evento periódico, informes de ganancias y pérdidas, que son publicados trimestralmente por empresas cotizadas en bolsa. Otras observaciones extraídas de la Figura 1 son: 1) el período de actividad intensa de abril es mucho más largo que el de Semana Santa, lo que sugiere que abril puede estar presente en otros eventos durante el mismo período; 2) No auditado tiene un valor promedio de DFIDF más alto que Finalizado, lo que indica que No auditado es más representativo para el evento subyacente. Estos dos ejemplos son solo la punta del iceberg entre todas las tendencias de palabras y correlaciones ocultas en un <br>flujo de noticias</br> como Reuters. Si se puede descubrir un gran número de ellos, podría ayudar significativamente en las tareas de TDT. En particular, indica la importancia de extraer características correlacionadas para detectar eventos correspondientes. Para resumir, postulamos que: 1) Un evento se describe por sus características representativas. Un evento periódico tiene una lista de características periódicas y un evento aperiódico tiene una lista de características aperiódicas; 2) Las características representativas del mismo evento comparten distribuciones similares en el tiempo y están altamente correlacionadas; 3) Un evento importante tiene un conjunto de características representativas activas (ampliamente reportadas), mientras que un evento no importante tiene un conjunto de características representativas inactivas (menos reportadas); 4) Una característica puede ser incluida por varios eventos con superposiciones en los marcos de tiempo. Basándonos en estas observaciones, podemos extraer características representativas dadas un evento o detectar un evento a partir de una lista de características altamente correlacionadas. En este artículo, nos enfocamos en este último aspecto, es decir, cómo se pueden descubrir características correlacionadas para formar un evento de manera no supervisada. 1.1 Contribuciones Este artículo tiene tres contribuciones principales: • Hasta donde sabemos, nuestro enfoque es el primero en categorizar características de palabras para eventos heterogéneos. Específicamente, cada característica de palabra se clasifica en uno de los siguientes cinco tipos de características basados en la fuerza de su espectro de potencia y periodicidad: 1) HH (alta potencia y alta/larga periodicidad): eventos aperiódicos importantes, 2) HL (alta potencia y baja periodicidad): eventos periódicos importantes, 3) LH (baja potencia y alta periodicidad): eventos aperiódicos no importantes, 4) LL (baja potencia y baja periodicidad): no eventos, y 5) SW (palabras vacías), un subconjunto de LL con mayor potencia y periodicidad que comprende palabras vacías, que no contienen información. • Proponemos un enfoque simple y efectivo basado en densidad de mezcla para modelar y detectar ráfagas de características. • Presentamos un algoritmo de detección de eventos no supervisado para detectar eventos tanto aperiódicos como periódicos. Nuestro algoritmo ha sido evaluado en un <br>flujo de noticias</br> reales para demostrar su efectividad. 2. TRABAJO RELACIONADO Este trabajo está motivado en gran medida por una familia más amplia de problemas conocidos colectivamente como Detección y Seguimiento de Temas (TDT) [20, 5, 17, 4, 21, 7, 14, 10]. Además, la mayoría de las investigaciones de TDT hasta ahora se han centrado en agrupar/clasificar documentos en tipos de temas, identificar oraciones novedosas para eventos nuevos, etc., sin prestar mucha atención al análisis de la trayectoria de las palabras con respecto al tiempo. Swan y Allan [18] intentaron por primera vez usar términos que co-ocurren para construir un evento. Sin embargo, solo consideraron entidades nombradas y pares de frases nominales, sin tener en cuenta sus periodicidades. Por el contrario, nuestro artículo considera todo lo anterior. Recientemente, ha habido un gran interés en modelar un evento en flujos de texto como un estallido de actividades al incorporar información temporal. El trabajo seminal de Kleinberg describió cómo se pueden extraer características explosivas de flujos de texto utilizando un modelo de autómata infinito [12], lo que inspiró toda una serie de aplicaciones como la identificación de comunidades explosivas de Kumar a partir de gráficos de blogs [13], la sumarización de temas evolutivos en flujos de texto de Meis [15], el agrupamiento de flujos de texto utilizando características explosivas de Hes [11], etc. Sin embargo, ninguno de los trabajos existentes identificó específicamente características para eventos, excepto Fung et al. [9], quienes agruparon características llamativas para identificar varios eventos llamativos. Nuestro trabajo difiere de [9] en varias formas: 1) analizamos cada característica individual, no solo las características explosivas; 2) clasificamos las características a lo largo de dos dimensiones categóricas (periodicidad y potencia), dando en total cinco tipos de características principales; 3) no restringimos que cada característica pertenezca exclusivamente a un solo evento. Las técnicas de análisis espectral han sido utilizadas previamente por Vlachos et al. [19] para identificar periodicidades y ráfagas en los registros de consultas. Su enfoque estaba en detectar múltiples periodicidades a partir del gráfico del espectro de potencia, las cuales luego se utilizaron para indexar palabras para la búsqueda por ráfagas. En este artículo, utilizamos análisis espectral para clasificar las características de las palabras a lo largo de dos dimensiones, a saber, periodicidad y espectro de potencia, con el objetivo final de identificar eventos tanto periódicos como no periódicos y explosivos. 3. REPRESENTACIÓN DE DATOS Sea T la duración/período (en días) de un <br>flujo de noticias</br>, y F representa el espacio de características de palabras completo en el Modelo de Espacio Vectorial (VSM) estático clásico. 3.1 Clasificación de Periodicidad de Eventos Dentro de T, pueden existir ciertos eventos que ocurren solo una vez, por ejemplo, la elección de Tony Blair como Primer Ministro del Reino Unido, y otros eventos recurrentes de diversas periodicidades, por ejemplo, partidos de fútbol semanales. Por lo tanto, categorizamos todos los eventos en dos tipos: aperiódicos y periódicos, definidos de la siguiente manera. Definición 1. (Evento aperiódico) Un evento es aperiódico dentro de T si solo ocurre una vez. Definición 2. (Evento periódico) Si los eventos de un cierto género de eventos ocurren regularmente con una periodicidad fija P ≤ T/2, decimos que este género particular de eventos es periódico, y cada evento miembro se califica como un evento periódico. Ten en cuenta que la definición de aperiódico es relativa, es decir, es verdadera solo para un T dado y puede ser inválida para cualquier otro T > T. Por ejemplo, el evento de la fiesta de Navidad es aperiódico para T ≤ 365 pero periódico para T ≥ 730. 3.2 Características Representativas Intuitivamente, un evento puede ser descrito de manera muy concisa por unas pocas características de palabras discriminativas y representativas y viceversa, por ejemplo, huracán, barrido y golpe podrían ser características representativas de un evento del género de huracanes. Asimismo, un conjunto de características fuertemente correlacionadas podría ser utilizado para reconstruir una descripción de un evento, asumiendo que las características fuertemente correlacionadas son representativas. El vector de representación de una característica de palabra se define de la siguiente manera: Definición 3. (Trayectoria de la Característica) La trayectoria de una característica de palabra f puede escribirse como la secuencia yf = [yf (1), yf (2), . . . , yf (T)], donde cada elemento yf (t) es una medida de la característica f en el tiempo t, que podría definirse utilizando la puntuación normalizada DFIDF yf (t) = DFf (t) N(t) × log( N DFf ), donde DFf (t) es el número de documentos (DF local) que contienen la característica f en el día t, DFf es el número total de documentos (DF global) que contienen la característica f en T, N(t) es el número de documentos para el día t, y N es el número total de documentos en T. 4. En esta sección, mostramos cómo se pueden extraer características representativas para eventos (poco) importantes o (a)periódicos. 4.1 Análisis Espectral para el Período Dominante Dada una característica f, descomponemos su trayectoria de características yf = [yf (1), yf (2), ..., yf (T)] en la secuencia de T números complejos [X1, . . . , XT ] a través de la transformada discreta de Fourier (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. La DFT puede representar la serie temporal original como una combinación lineal de sinusoides complejas, lo cual se ilustra mediante la transformada discreta de Fourier inversa (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, donde el coeficiente de Fourier Xk denota la amplitud del sinusoides con frecuencia k/T. La trayectoria original puede ser reconstruida con solo las frecuencias dominantes, las cuales pueden ser determinadas a partir del espectro de potencia utilizando el popular estimador periodograma. El periodograma es una secuencia de la magnitud al cuadrado de los coeficientes de Fourier, Xk^2, k = 1, 2, . . . , T/2, que indica la potencia de la señal en la frecuencia k/T en el espectro. A partir del espectro de potencia, se elige el período dominante como el inverso de la frecuencia con el espectro de potencia más alto, de la siguiente manera. Definición 4. (Período Dominante) El período dominante (DP) de una característica dada f es Pf = T/ arg max k Xk 2. Por lo tanto, tenemos la Definición 5. (Espectro de Potencia Dominante) El espectro de potencia dominante (DPS) de una característica dada f es Sf = Xk 2 , con Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorización de Características El DPS de una trayectoria de características es un indicador fuerte de su actividad en la frecuencia especificada; cuanto mayor sea el DPS, es más probable que la característica sea explosiva. Al combinar DPS con DP, categorizamos todas las características en cuatro tipos: 2 Normalizamos yf (t) como yf (t) = yf (t)/ T i=1 yf (i) para que pueda interpretarse como una probabilidad. • HH: alta Sf, aperiódico o periódico a largo plazo (Pf > T/2); • HL: alta Sf, periódico a corto plazo (Pf ≤ T/2); • LH: baja Sf, aperiódico o periódico a largo plazo; • LL: baja Sf, periódico a corto plazo. La frontera entre los periodos a largo plazo y a corto plazo se establece en T/2. Sin embargo, distinguir entre un DPS alto y bajo no es sencillo, lo cual se abordará más adelante. Propiedades de diferentes conjuntos de características Para comprender mejor las propiedades de HH, HL, LH y LL, seleccionamos cuatro características, Navidad, fútbol, DBS y tu como ejemplos ilustrativos. Dado que la frontera entre el espectro de alta y baja potencia no está clara, estos ejemplos seleccionados tienen un rango relativo amplio de valores de espectro de potencia. La figura 2(a) muestra la trayectoria de DFIDF para la Navidad con un pico distintivo alrededor del día de Navidad. Para el conjunto de datos de Reuters de 1 año, la Navidad se clasifica como un evento aperiódico típico con Pf = 365 y Sf = 135.68, como se muestra en la Figura 2(b). Claramente, el valor de Sf = 135.68 es razonable para un evento conocido por ser intermitente como la Navidad. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Navidad(DFIDF:tiempo) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Navidad(S:frecuencia) Figura 2: Característica Navidad con un Sf relativamente alto y un Pf a largo plazo. La trayectoria de DFIDF para el fútbol se muestra en la Figura 3(a), de la cual podemos observar que hay un estallido regular cada 7 días, lo cual es nuevamente verificado por su valor calculado de Pf = 7, como se muestra en la Figura 3(b). Usando el conocimiento del dominio de que los partidos de fútbol tienen más encuentros cada sábado, lo que lo convierte en un evento periódico típico y ampliamente reportado, consideramos que el valor de Sf = 155.13 es alto. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) fútbol (DFIDF:tiempo) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) fútbol (S:frecuencia) Figura 3: Característica fútbol con un Sf relativamente alto y un Pf a corto plazo. A partir de la trayectoria de DFIDF para DBS en la Figura 4(a), podemos deducir de inmediato que DBS es una palabra poco frecuente con un aumento trivial el 17/08/1997 correspondiente a los planes de DBS Land Raﬄes Holdings. Esto se confirma por el largo período de Pf = 365 y la baja potencia de Sf = 0.3084 como se muestra en la Figura 4(b). Además, dado que este evento aperiódico solo se informa en algunas noticias durante un corto período de unos pocos días, por lo tanto, decimos que su bajo valor de potencia de Sf = 0.3084 es representativo de eventos poco importantes. El ejemplo más confuso se muestra en la Figura 5 para la palabra \"your\", que se ve muy similar al gráfico para fútbol en la Figura 3. A primera vista, podríamos sentirnos tentados a agrupar tanto tu como el fútbol en la misma categoría de HL o LL, ya que ambas distribuciones se ven similares y tienen el mismo período dominante de aproximadamente una semana. Sin embargo, más adelante 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:tiempo) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frecuencia) Figura 4: Característica DBS con Sf relativamente bajo y Pf a largo plazo. El análisis indica que la periodicidad de su es debido a las diferencias en el recuento de documentos para los días de la semana (promedio de 2,919 por día) y los fines de semana (promedio de 479 por día). Uno habría esperado que la periodicidad de una palabra vacía como \"tu\" fuera de un día. Además, a pesar de nuestra normalización de DFIDF, el desequilibrio entre los días de la semana y los fines de semana aún prevalecía; las palabras vacías ocurren 4 veces más frecuentemente los fines de semana que los días de semana. Por lo tanto, el DPS sigue siendo el único factor distintivo entre tu (Sf = 9.42) y el fútbol (Sf = 155.13). Sin embargo, es muy peligroso concluir simplemente que un valor de potencia de S = 9.42 corresponde a una característica de palabra vacía. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) tu(DFIDF:tiempo) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) tu(S:frecuencia) Figura 5: Característica tu como un ejemplo confundido con la característica fútbol. Antes de presentar nuestra solución a este problema, veamos otro ejemplo de LL como se muestra en la Figura 6 para beenb, que en realidad es un error tipográfico confirmado. Por lo tanto, clasificamos beenb como una característica ruidosa que no contribuye a ningún evento. Claramente, la trayectoria de tu es muy diferente de beenb, lo que significa que el primero debe considerarse por separado. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figura 6: Característica beenb con Sf relativamente bajo y Pf a corto plazo. Conjunto de características de palabras vacías (SW) Basándonos en el análisis anterior, nos damos cuenta de que debe haber otro conjunto de características entre HL y LL que corresponda al conjunto de palabras vacías. Las características de este conjunto tienen un DPS moderado y un período dominante bajo pero conocido. Dado que es difícil distinguir este conjunto de características de HL y LL solo basándose en DPS, introducimos otro factor llamado promedio de DFIDF (DFIDF). Como se muestra en la Figura 5, características como la tuya suelen tener un DPS más bajo que una característica HL como el fútbol, pero tienen un DFIDF mucho más alto que otra característica ruidosa LL como \"beenb\". Dado que tales propiedades suelen ser características de las palabras vacías, agrupamos características como \"tu\" en el conjunto de características de palabras vacías (SW) recién definido. Dado que establecer los umbrales de DPS y DFIDF para identificar las palabras vacías es más un arte que una ciencia, propusimos un algoritmo heurístico HS, Algoritmo 1. La idea básica es utilizar solo noticias de días laborables para identificar palabras vacías. Los fines de semana aquí también incluyen días festivos que caen en días laborables. El conjunto SW se inicialmente alimenta con un pequeño conjunto de 29 stopwords populares utilizadas por el motor de búsqueda de Google. Algoritmo 1 Detección heurística de palabras vacías (HS) Entrada: Conjunto de palabras vacías semilla, trayectorias semanales de todas las palabras 1: A partir del conjunto semilla SW, calcular el DPS máximo como UDPS, el DFIDF máximo como UDFIDF y el mínimo de DFIDF como LDFIDF. 2: para fi ∈ F hacer 3: Calcular DFT para fi. 4: si Sfi ≤ UDPS y DFIDFfi ∈ [LDFIDF, UDFIDF] entonces 5: fi → SW 6: F = F - fi 7: fin si 8: fin para Resumen de la Categorización de Características Después de generar el conjunto SW, se eliminan todas las palabras vacías de F. Luego, establecemos el límite entre DPS alto y bajo como el límite superior de los DPS de los conjuntos SW. Una visión general de los cinco conjuntos de características se muestra en la Figura 7. Figura 7: Los 5 conjuntos de características para eventos. 5. IDENTIFICACIÓN DE RÁFAGAS PARA CARACTERÍSTICAS Dado que solo las características de HH, HL y LH son significativas y podrían ser representativas de algunos eventos, eliminamos todas las demás características clasificadas como LL o SW. En esta sección, describimos cómo se pueden identificar los estallidos a partir de las características restantes. A diferencia del algoritmo de identificación de ráfagas de Kleinberg [12], podemos identificar tanto ráfagas significativas como triviales sin necesidad de establecer ningún parámetro. 5.1 Detección de ráfagas de características aperiódicas Para cada característica en HH y HL, truncamos su trayectoria manteniendo solo el período de ráfagas, el cual está modelado con una distribución gaussiana. Por ejemplo, la Figura 8 muestra la característica de la palabra Iraq con una explosión alrededor del 09/06/1996 modelada como una Gaussiana. Su período de ráfagas está definido por [μf − σf , μf + σf ] como se muestra en la Figura 8(b). 5.2 Detección de características periódicas de ráfagas Dado que hemos calculado el DP para una característica periódica f, podemos modelar fácilmente su trayectoria de características periódicas yf usando 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) DFIDF original: tiempo 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 ráfaga= [μ-σ, μ+σ] (b) identificación de ráfaga Figura 8: Modelando la serie temporal de Iraq como una Gaussiana truncada con μ = 09/06/1996 y σ = 6.26. una mezcla de K = T/Pf Gaussianas: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , donde el conjunto de parámetros θf = {αk, μk, σk}K k=1 comprende: • αk es la probabilidad de asignar yf a la k-ésima Gaussiana. αk > 0, ∀k ∈ [1, K] y K k=1 αk = 1; • μk/σk es la media/desviación estándar de la k-ésima Gaussiana. El conocido algoritmo Expectation Maximization (EM) [8] se utiliza para calcular las proporciones de mezcla αk, así como los parámetros individuales de densidad gaussiana μk y σK. Cada Gaussiana representa un evento periódico, y se modela de manera similar como se menciona en la Sección 5.1. 6. EVENTOS A PARTIR DE CARACTERÍSTICAS Después de identificar y modelar ráfagas para todas las características, la siguiente tarea es pintar un cuadro del evento con un posible conjunto de características representativas. 6.1 Correlación de Características Si dos características fi y fj son representativas del mismo evento, deben cumplir las siguientes condiciones necesarias: 1. fi y fj están distribuidas de manera idéntica: yfi ∼ yfj. 2. fi y fj tienen una alta superposición de documentos. Medición de la similitud de la distribución de características. Medimos la similitud entre dos características fi y fj utilizando la divergencia KL discreta definida de la siguiente manera. Definición 6. (similitud de características) KL(fi, fj) se da por max(KL(fi|fj), KL(fj|fi)), donde KL(fi|fj) = T t=1 f(yfi(t)|θfi)log f(yfi(t)|θfi) f(yfj(t)|θfj). (1) Dado que la divergencia KL no es simétrica, definimos la similitud entre fi y fj como el máximo entre KL(fi|fj) y KL(fj|fi). Además, la similitud entre dos características aperiódicas puede calcularse utilizando una forma cerrada de la divergencia de Kullback-Leibler [16]. La misma fórmula discreta de divergencia KL de la Ecuación 1 se emplea para calcular la similitud entre dos características periódicas. A continuación, definimos la similitud general entre un conjunto de características R utilizando el valor máximo de divergencia KL entre características como sigue. Definición 7. (similitud de conjuntos) KL(R) = max ∀fi, fj ∈R KL(fi, fj). Superposición de documentos: Sea Mi el conjunto de todos los documentos que contienen la característica fi. Dadas dos características fi y fj, el conjunto de documentos superpuestos que contienen ambas características es Mi ∩ Mj. De manera intuitiva, cuanto mayor sea |Mi ∩ Mj|, es más probable que fi y fj estén altamente correlacionados. Definimos el grado de superposición de documentos entre dos características fi y fj de la siguiente manera. Definición 8. (Superposición de características DF) d(fi, fj) = |Mi∩Mj| min(|Mi|, |Mj|). En consecuencia, la superposición de DF entre un conjunto de características R también está definida. Definición 9. (Superposición de Conjuntos DF) d(R) = min ∀fi, fj ∈R d(fi, fj). 6.2 Detección de Eventos Codiciosa No Supervisada Utilizamos características de HH para detectar eventos aperiódicos importantes, características de LH para detectar eventos aperiódicos menos reportados/poco importantes, y características de HL para detectar eventos periódicos. Todos comparten el mismo algoritmo. Dado el rasgo explosivo fi ∈ HH, el objetivo es encontrar rasgos altamente correlacionados de HH. El conjunto de características similares a fi puede describir colectivamente un evento. Específicamente, necesitamos encontrar un subconjunto Ri de HH que minimice la siguiente función de costo: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) El evento subyacente e (asociado con la explosión de fi) puede ser representado por Ri como y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) El análisis de la explosión para el evento e es exactamente el mismo que la trayectoria de características. El costo en la Ecuación 2 se puede minimizar utilizando nuestro algoritmo de detección de eventos UG codicioso no supervisado, que se describe en el Algoritmo 2. El algoritmo UG permite una característica Algoritmo 2 Detección de eventos codiciosos no supervisados (UG). Salida: ek como Ec. 3. Además, los eventos triviales que solo contienen características de año/mes (es decir, un evento que solo contiene una característica de agosto podría ser identificado en un <br>flujo de noticias</br> de 1 año) podrían ser eliminados, aunque dichos eventos tendrán un costo inherente alto y deberían estar clasificados muy bajos. ",
            "candidates": [],
            "error": [
                [
                    "datos de flujo de noticias",
                    "flujo de noticias",
                    "flujo de noticias",
                    "flujo de noticias",
                    "flujo de noticias"
                ]
            ]
        },
        "time series": {
            "translated_key": "serie temporal",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Analyzing Feature Trajectories for Event Detection Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg School of Computer Engineering Nanyang Technological University Block N4, Nanyang Avenue, Singapore 639798 ABSTRACT We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words.",
                "A set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner.",
                "The document frequency of each word across time is treated like a <br>time series</br>, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point.",
                "In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events.",
                "All of the above methods can be applied to <br>time series</br> data in general.",
                "We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events.",
                "Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Experimentation. 1.",
                "INTRODUCTION There are more than 4,000 online news sources in the world.",
                "Manually monitoring all of them for important events has become difficult or practically impossible.",
                "In fact, the topic detection and tracking (TDT) community has for many years been trying to come up with a practical solution to help people monitor news effectively.",
                "Unfortunately, the holy grail is still elusive, because the vast majority of TDT solutions proposed for event detection [20, 5, 17, 4, 21, 7, 14, 10] are either too simplistic (based on cosine similarity [5]) or impractical due to the need to tune a large number of parameters [9].",
                "The ineffectiveness of current TDT technologies can be easily illustrated by subscribing to any of the many online news alerts services such as the industryleading Google News Alerts [2], which generates more than 50% false alarms [10].",
                "As further proof, portals like Yahoo take a more pragmatic approach by requiring all machine generated news alerts to go through a human operator for confirmation before sending them out to subscribers.",
                "Instead of attacking the problem with variations of the same hammer (cosine similarity and TFIDF), a fundamental understanding of the characteristics of news stream data is necessary before any major breakthroughs can be made in TDT.",
                "Thus in this paper, we look at news stories and feature trends from the perspective of analyzing a time-series word signal.",
                "Previous work like [9] has attempted to reconstruct an event with its representative features.",
                "However, in many predictive event detection tasks (i.e., retrospective event detection), there is a vast set of potential features only for a fixed set of observations (i.e., the obvious bursts).",
                "Of these features, often only a small number are expected to be useful.",
                "In particular, we study the novel problem of analyzing feature trajectories for event detection, borrowing a well-known technique from signal processing: identifying distributional correlations among all features by spectral analysis.",
                "To evaluate our method, we subsequently propose an unsupervised event detection algorithm for news streams. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Easter April (a) aperiodic event 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Unaudited Ended (b) periodic event Figure 1: Feature correlation (DFIDF:time) between a) Easter and April b) Unaudited and Ended.",
                "As an illustrative example, consider the correlation between the words Easter and April from the Reuters Corpus1 .",
                "From the plot of their normalized DFIDF in Figure 1(a), we observe the heavy overlap between the two words circa 04/1997, which means they probably both belong to the same event during that time (Easter feast).",
                "In this example, the hidden event Easter feast is a typical important aperiodic event over 1-year data.",
                "Another example is given by Figure 1(b), where both the words Unaudited and Ended 1 Reuters Corpus is the default dataset for all examples. exhibit similar behaviour over periods of 3 months.",
                "These two words actually originated from the same periodic event, net income-loss reports, which are released quarterly by publicly listed companies.",
                "Other observations drawn from Figure 1 are: 1) the bursty period of April is much longer than Easter, which suggests that April may exist in other events during the same period; 2) Unaudited has a higher average DFIDF value than Ended, which indicates Unaudited to be more representative for the underlying event.",
                "These two examples are but the tip of the iceberg among all word trends and correlations hidden in a news stream like Reuters.",
                "If a large number of them can be uncovered, it could significantly aid TDT tasks.",
                "In particular, it indicates the significance of mining correlating features for detecting corresponding events.",
                "To summarize, we postulate that: 1) An event is described by its representative features.",
                "A periodic event has a list of periodic features and an aperiodic event has a list of aperiodic features; 2) Representative features from the same event share similar distributions over time and are highly correlated; 3) An important event has a set of active (largely reported) representative features, whereas an unimportant event has a set of inactive (less-reported) representative features; 4) A feature may be included by several events with overlaps in time frames.",
                "Based on these observations, we can either mine representative features given an event or detect an event from a list of highly correlated features.",
                "In this paper, we focus on the latter, i.e., how correlated features can be uncovered to form an event in an unsupervised manner. 1.1 Contributions This paper has three main contributions: • To the best of our knowledge, our approach is the first to categorize word features for heterogenous events.",
                "Specifically, every word feature is categorized into one of the following five feature types based on its power spectrum strength and periodicity: 1) HH (high power and high/long periodicity): important aperiodic events, 2) HL (high power and low periodicity): important periodic events, 3) LH (low power and high periodicity): unimportant aperiodic events, 4) LL (low power and low periodicity): non-events, and 5) SW (stopwords), a higher power and periodicity subset of LL comprising stopwords, which contains no information. • We propose a simple and effective mixture densitybased approach to model and detect feature bursts. • We come up with an unsupervised event detection algorithm to detect both aperiodic and periodic events.",
                "Our algorithm has been evaluated on a real news stream to show its effectiveness. 2.",
                "RELATED WORK This work is largely motivated by a broader family of problems collectively known as Topic Detection and Tracking (TDT) [20, 5, 17, 4, 21, 7, 14, 10].",
                "Moreover, most TDT research so far has been concerned with clustering/classifying documents into topic types, identifying novel sentences [6] for new events, etc., without much regard to analyzing the word trajectory with respect to time.",
                "Swan and Allan [18] first attempted using co-occuring terms to construct an event.",
                "However, they only considered named entities and noun phrase pairs, without considering their periodicities.",
                "On the contrary, our paper considers all of the above.",
                "Recently, there has been significant interest in modeling an event in text streams as a burst of activities by incorporating temporal information.",
                "Kleinbergs seminal work described how bursty features can be extracted from text streams using an infinite automaton model [12], which inspired a whole series of applications such as Kumars identification of bursty communities from Weblog graphs [13], Meis summarization of evolutionary themes in text streams [15], Hes clustering of text streams using bursty features [11], etc.",
                "Nevertheless, none of the existing work specifically identified features for events, except for Fung et al. [9], who clustered busty features to identify various bursty events.",
                "Our work differs from [9] in several ways: 1) we analyze every single feature, not only bursty features; 2) we classify features along two categorical dimensions (periodicity and power), yielding altogether five primary feature types; 3) we do not restrict each feature to exclusively belong to only one event.",
                "Spectral analysis techniques have previously been used by Vlachos et al. [19] to identify periodicities and bursts from query logs.",
                "Their focus was on detecting multiple periodicities from the power spectrum graph, which were then used to index words for query-by-burst search.",
                "In this paper, we use spectral analysis to classify word features along two dimensions, namely periodicity and power spectrum, with the ultimate goal of identifying both periodic and aperiodic bursty events. 3.",
                "DATA REPRESENTATION Let T be the duration/period (in days) of a news stream, and F represents the complete word feature space in the classical static Vector Space Model (VSM). 3.1 Event Periodicity Classification Within T, there may exist certain events that occur only once, e.g., Tony Blair elected as Prime Minister of U.K., and other recurring events of various periodicities, e.g., weekly soccer matches.",
                "We thus categorize all events into two types: aperiodic and periodic, defined as follows.",
                "Definition 1. (Aperiodic Event) An event is aperiodic within T if it only happens once.",
                "Definition 2. (Periodic Event) If events of a certain event genre occur regularly with a fixed periodicity P ≤ T/2 , we say that this particular event genre is periodic, with each member event qualified as a periodic event.",
                "Note that the definition of aperiodic is relative, i.e., it is true only for a given T, and may be invalid for any other T > T. For example, the event Christmas feast is aperiodic for T ≤ 365 but periodic for T ≥ 730. 3.2 Representative Features Intuitively, an event can be described very concisely by a few discriminative and representative word features and vice-versa, e.g., hurricane, sweep, and strike could be representative features of a Hurricane genre event.",
                "Likewise, a set of strongly correlated features could be used to reconstruct an event description, assuming that strongly correlated features are representative.",
                "The representation vector of a word feature is defined as follows: Definition 3. (Feature Trajectory) The trajectory of a word feature f can be written as the sequence yf = [yf (1), yf (2), . . . , yf (T)], where each element yf (t) is a measure of feature f at time t, which could be defined using the normalized DFIDF score2 yf (t) = DFf (t) N(t) × log( N DFf ), where DFf (t) is the number of documents (local DF) containing feature f at day t, DFf is the total number of documents (global DF) containing feature f over T, N(t) is the number of documents for day t, and N is the total number of documents over T. 4.",
                "IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 Spectral Analysis for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. DFT can represent the original <br>time series</br> as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T.",
                "The original trajectory can be reconstructed with just the dominant frequencies, which can be determined from the power spectrum using the popular periodogram estimator.",
                "The periodogram is a sequence of the squared magnitude of the Fourier coefficients, Xk 2 , k = 1, 2, . . . , T/2 , which indicates the signal power at frequency k/T in the spectrum.",
                "From the power spectrum, the dominant period is chosen as the inverse of the frequency with the highest power spectrum, as follows.",
                "Definition 4. (Dominant Period) The dominant period (DP) of a given feature f is Pf = T/ arg max k Xk 2 .",
                "Accordingly, we have Definition 5. (Dominant Power Spectrum) The dominant power spectrum (DPS) of a given feature f is Sf = Xk 2 , with Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorizing Features The DPS of a feature trajectory is a strong indicator of its activeness at the specified frequency; the higher the DPS, the more likely for the feature to be bursty.",
                "Combining DPS with DP, we therefore categorize all features into four types: 2 We normalize yf (t) as yf (t) = yf (t)/ T i=1 yf (i) so that it could be interpreted as a probability. • HH: high Sf , aperiodic or long-term periodic (Pf > T/2 ); • HL: high Sf , short-term periodic (Pf ≤ T/2 ); • LH: low Sf , aperiodic or long-term periodic; • LL: low Sf , short-term periodic.",
                "The boundary between long-term and short-term periodic is set to T/2 .",
                "However, distinguishing between a high and low DPS is not straightforward, which will be tackled later.",
                "Properties of Different Feature Sets To better understand the properties of HH, HL, LH and LL, we select four features, Christmas, soccer, DBS and your as illustrative examples.",
                "Since the boundary between high and low power spectrum is unclear, these chosen examples have relative wide range of power spectrum values.",
                "Figure 2(a) shows the DFIDF trajectory for Christmas with a distinct burst around Christmas day.",
                "For the 1-year Reuters dataset, Christmas is classified as a typical aperiodic event with Pf = 365 and Sf = 135.68, as shown in Figure 2(b).",
                "Clearly, the value of Sf = 135.68 is reasonable for a well-known bursty event like Christmas. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Christmas(DFIDF:time) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Christmas(S:frequency) Figure 2: Feature Christmas with relative high Sf and long-term Pf .",
                "The DFIDF trajectory for soccer is shown in Figure 3(a), from which we can observe that there is a regular burst every 7 days, which is again verified by its computed value of Pf = 7, as shown in Figure 3(b).",
                "Using the domain knowledge that soccer games have more matches every Saturday, which makes it a typical and heavily reported periodic event, we thus consider the value of Sf = 155.13 to be high. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) soccer(DFIDF:time) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) soccer(S:frequency) Figure 3: Feature soccer with relative high Sf and short-term Pf .",
                "From the DFIDF trajectory for DBS in Figure 4(a), we can immediately deduce DBS to be an infrequent word with a trivial burst on 08/17/1997 corresponding to DBS Land Raﬄes Holdings plans.",
                "This is confirmed by the long period of Pf = 365 and low power of Sf = 0.3084 as shown in Figure 4(b).",
                "Moreover, since this aperiodic event is only reported in a few news stories over a very short time of few days, we therefore say that its low power value of Sf = 0.3084 is representative of unimportant events.",
                "The most confusing example is shown in Figure 5 for the word feature your, which looks very similar to the graph for soccer in Figure 3.",
                "At first glance, we may be tempted to group both your and soccer into the same category of HL or LL since both distributions look similar and have the same dominant period of approximately a week.",
                "However, further 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:time) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frequency) Figure 4: Feature DBS with relative low Sf and long-term Pf . analysis indicates that the periodicity of your is due to the differences in document counts for weekdays (average 2,919 per day) and weekends3 (average 479 per day).",
                "One would have expected the periodicity of a stopword like your to be a day.",
                "Moreover, despite our DFIDF normalization, the weekday/weekend imbalance still prevailed; stopwords occur 4 times more frequently on weekends than on weekdays.",
                "Thus, the DPS remains the only distinguishing factor between your (Sf = 9.42) and soccer (Sf = 155.13).",
                "However, it is very dangerous to simply conclude that a power value of S = 9.42 corresponds to a stopword feature. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) your(DFIDF:time) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) your(S:frequency) Figure 5: Feature your as an example confusing with feature soccer.",
                "Before introducing our solution to this problem, lets look at another LL example as shown in Figure 6 for beenb, which is actually a confirmed typo.",
                "We therefore classify beenb as a noisy feature that does not contribute to any event.",
                "Clearly, the trajectory of your is very different from beenb, which means that the former has to be considered separately. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figure 6: Feature beenb with relative low Sf and short-term Pf .",
                "Stop Words (SW) Feature Set Based on the above analysis, we realize that there must be another feature set between HL and LL that corresponds to the set of stopwords.",
                "Features from this set has moderate DPS and low but known dominant period.",
                "Since it is hard to distinguish this feature set from HL and LL only based on DPS, we introduce another factor called average DFIDF (DFIDF).",
                "As shown in Figure 5, features like your usually have a lower DPS than a HL feature like soccer, but have a much higher DFIDF than another LL noisy feature such as beenb.",
                "Since such properties are usually characteristics of stopwords, we group features like your into the newly defined stopword (SW) feature set.",
                "Since setting the DPS and DFIDF thresholds for identifying stopwords is more of an art than science, we proposed a heuristic HS algorithm, Algorithm 1.",
                "The basic idea is to only use news stories from weekdays to identify stopwords. 3 The weekends here also include public holidays falling on weekdays.",
                "The SW set is initially seeded with a small set of 29 popular stopwords utilized by Google search engine.",
                "Algorithm 1 Heuristic Stopwords detection (HS) Input: Seed SW set, weekday trajectories of all words 1: From the seed set SW, compute the maximum DPS as UDPS, maximum DFIDF as UDFIDF, and minimum of DFIDF as LDFIDF. 2: for fi ∈ F do 3: Compute DFT for fi. 4: if Sfi ≤ UDPS and DFIDFfi ∈ [LDFIDF, UDFIDF] then 5: fi → SW 6: F = F − fi 7: end if 8: end for Overview of Feature Categorization After the SW set is generated, all stopwords are removed from F. We then set the boundary between high and low DPS to be the upper bound of the SW sets DPS.",
                "An overview of all five feature sets is shown in Figure 7.",
                "Figure 7: The 5 feature sets for events. 5.",
                "IDENTIFYING BURSTS FOR FEATURES Since only features from HH, HL and LH are meaningful and could potentially be representative to some events, we pruned all other feature classified as LL or SW.",
                "In this section, we describe how bursts can be identified from the remaining features.",
                "Unlike Kleinbergs burst identification algorithm [12], we can identify both significant and trivial bursts without the need to set any parameters. 5.1 Detecting Aperiodic Features Bursts For each feature in HH and HL, we truncate its trajectory by keeping only the bursty period, which is modeled with a Gaussian distribution.",
                "For example, Figure 8 shows the word feature Iraq with a burst circa 09/06/1996 being modeled as a Gaussian.",
                "Its bursty period is defined by [μf − σf , μf + σf ] as shown in Figure 8(b). 5.2 Detecting Periodic Features Bursts Since we have computed the DP for a periodic feature f, we can easily model its periodic feature trajectory yf using 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) original DFIDF:time 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 burst= [μ-σ, μ+σ] (b) identifying burst Figure 8: Modeling Iraqs <br>time series</br> as a truncated Gaussian with μ = 09/06/1996 and σ = 6.26. a mixture of K = T/Pf Gaussians: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , where the parameter set θf = {αk, μk, σk}K k=1 comprises: • αk is the probability of assigning yf into the kth Gaussian. αk > 0, ∀k ∈ [1, K] and K k=1 αk = 1; • μk/σk is mean/standard deviation of the kth Gaussian.",
                "The well known Expectation Maximization (EM) [8] algorithm is used to compute the mixing proportions αk, as well as the individual Gaussian density parameters μk and σK .",
                "Each Gaussian represents one periodic event, and is modeled similarly as mentioned in Section 5.1. 6.",
                "EVENTS FROM FEATURES After identifying and modeling bursts for all features, the next task is to paint a picture of the event with a potential set of representative features. 6.1 Feature Correlation If two features fi and fj are representative of the same event, they must satisfy the following necessary conditions: 1. fi and fj are identically distributed: yfi ∼ yfj . 2. fi and fj have a high document overlap.",
                "Measuring Feature Distribution Similarity We measure the similarity between two features fi and fj using discrete KL-divergence defined as follows.",
                "Definition 6. (feature similarity) KL(fi, fj ) is given by max(KL(fi|fj ), KL(fj |fi)), where KL(fi|fj ) = T t=1 f(yfi (t)|θfi )log f(yfi (t)|θfi ) f(yfj (t)|θfj ) . (1) Since KL-divergence is not symmetric, we define the similarity between between fi and fj as the maximum of KL(fi|fj ) and KL(fj |fi).",
                "Further, the similarity between two aperiodic features can be computed using a closed form of the KL-divergence [16].",
                "The same discrete KL-divergence formula of Eq. 1 is employed to compute the similarity between two periodic features, Next, we define the overal similarity among a set of features R using the maximum inter-feature KL-Divergence value as follows.",
                "Definition 7. (sets similarity)KL(R) = max ∀fi,fj ∈R KL(fi, fj ).",
                "Document Overlap Let Mi be the set of all documents containing feature fi.",
                "Given two features fi and fj , the overlapping document set containing both features is Mi ∩ Mj .",
                "Intuitively, the higher the |Mi ∩ Mj |, the more likelty that fi and fj will be highly correlated.",
                "We define the degree of document overlap between two features fi and fj as follows.",
                "Definition 8. (Feature DF Overlap) d(fi, fj ) = |Mi∩Mj| min(|Mi|,|Mj|) .",
                "Accordingly, the DF Overlap among a set of features R is also defined.",
                "Definition 9. (Set DF Overlap) d(R) = min ∀fi,fj ∈R d(fi, fj). 6.2 Unsupervised Greedy Event Detection We use features from HH to detect important aperiodic events, features from LH to detect less-reported/unimportant aperiodic events, and features from HL to detect periodic events.",
                "All of them share the same algorithm.",
                "Given bursty feature fi ∈ HH, the goal is to find highly correlated features from HH.",
                "The set of features similar to fi can then collectively describe an event.",
                "Specifically, we need to find a subset Ri of HH that minimizes the following cost function: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) The underlying event e (associated with the burst of fi) can be represented by Ri as y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) The burst analysis for event e is exactly the same as the feature trajectory.",
                "The cost in Eq. 2 can be minimized using our unsupervised greedy UG event detection algorithm, which is described in Algorithm 2.",
                "The UG algorithm allows a feature Algorithm 2 Unsupervised Greedy event detection (UG).",
                "Input: HH, document index for each feature. 1: Sort and select features in descending DPS order: Sf1 ≥ Sf2 ≥ . . . ≥ Sf|HH| . 2: k = 0. 3: for fi ∈ HH do 4: k = k + 1. 5: Init: Ri ← fi, C(Ri) = 1/Sfi and HH = HH − fi. 6: while HH not empty do 7: m = arg min m C(Ri ∪ fm). 8: if C(Ri ∪ fm) < C(Ri) then 9: Ri ← fm and HH = HH − fm. 10: else 11: break while. 12: end if 13: end while 14: Output ek as Eq. 3. 15: end for to be contained in multiple events so that we can detect several events happening at the same time.",
                "Furthermore, trivial events only containing year/month features (i.e., an event only containing 1 feature Aug could be identified over a 1year news stream) could be removed, although such events will have inherent high cost and should already be ranked very low.",
                "Note that our UG algorithm only requires one data-dependant parameter, the boundary between high and low power spectrum, to be set once, and this parameter can be easily estimated using the HS algorithm (Algorithm 1). 7.",
                "EXPERIMENTS In this section, we study the performances of our feature categorizing method and event detection algorithm.",
                "We first introduce the dataset and experimental setup, then we subjectively evaluate the categorization of features for HH, HL, LH, LL and SW.",
                "Finally, we study the (a)periodic event detection problem with Algorithm 2. 7.1 Dataset and Experimental Setup The Reuters Corpus contains 806,791 English news stories from 08/20/1996 to 08/19/1997 at a day resolution.",
                "Version 2 of the open source Lucene software [1] was used to tokenize the news text content and generate the document-word vector.",
                "In order to preserve the time-sensitive past/present/future tenses of verbs and the differences between lower case nouns and upper case named entities, no stemming was done.",
                "Since dynamic stopword removal is one of the functionalities of our method, no stopword was removed.",
                "We did remove nonEnglish characters, however, after which the number of word features amounts to 423,433.",
                "All experiments were implemented in Java and conducted on a 3.2 GHz Pentium 4 PC running Windows 2003 Server with 1 GB of memory. 7.2 Categorizing Features We downloaded 34 well-known stopwords utilized by the Google search engine as our seed training features, which includes a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en and www.",
                "We excluded the last five stopwords as they are uncommon in news stories.",
                "By only analyzing news stories over 259 weekdays, we computed the upper bound of the power spectrum for stopwords at 11.18 and corresponding DFIDF ranges from 0.1182 to 0.3691.",
                "Any feature f satisfying Sf <= 11.18 and 0.1182 <= DFIDFf <= 0.3691 over weekdays will be considered a stopword.",
                "In this manner, 470 stopwords were found and removed as visualized in Figure 9.",
                "Some detected stopwords are A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) and much (P = 22, S = 0.80, DFIDF = 0.1865).",
                "After the removal of these stopwords, the distribution of weekday and weekend news are more or less matched, and in the ensuing experiments, we shall make use of the full corpus (weekdays and weekends).",
                "The upper bound power spectrum value of 11.18 for stopwords training was selected as the boundary between the high power and low power spectrum.",
                "The boundary between high and low periodicity was set to 365/2 = 183.",
                "All 422,963 (423433 − 470) word features were categorized into 4 feature sets: HH (69 features), HL (1,087 features), LH (83,471 features), and LL (338,806 features) as shown in Figure 10.",
                "In Figure 10, each gray level denotes the relative density of features in a square region, measured by log10(1 + Dk), where Dk is the number of features within the k-th square region.",
                "From the figure, we can make the 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figure 9: Distribution of SW (stopwords) in the HH, HL, LH, and LL regions. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figure 10: Distribution of categorized features over the four quadrants (shading in log scale). following observations: 1.",
                "Most features have low S and are easily distinguishable from those features having a much higher S, which allows us to detect important (a)periodic events from trivial events by selecting features with high S. 2.",
                "Features in the HH and LH quadrants are aperiodic, which are nicely separated (big horizontal gap) from the periodic features.",
                "This allows reliably detecting aperiodic events and periodic events independently. 3.",
                "The (vertical) boundary between high and low power spectrum is not as clearcut and the exact value will be application specific.",
                "By checking the scatter distribution of features from SW on HH, HL, LH, and LL as shown in Figure 9, we found that 87.02%(409/470) of the detected stopwords originated from LL.",
                "The LL classification and high DFIDF scores of stopwords agree with the generally accepted notion that stopwords are equally frequent over all time.",
                "Therefore, setting the boundary between high and low power spectrum using the upper bound Sf of SW is a reasonable heuristic. 7.3 Detecting Aperiodic Events We shall evaluate our two hypotheses, 1)important aperiodic events can be defined by a set of HH features, and 2)less reported aperiodic events can be defined by a set of LH features.",
                "Since no benchmark news streams exist for event detection (TDT datasets are not proper streams), we evaluate the quality of the automatically detected events by comparing them to manually-confirmed events by searching through the corpus.",
                "Among the 69 HH features, we detected 17 important aperiodic events as shown in Table 1 (e1 − e17).",
                "Note that the entire identification took less than 1 second, after removing events containing only the month feature.",
                "Among the 17 events, other than the overlaps between e3 and e4 (both describes the same hostage event), e11 and e16 (both about company reports), the 14 identified events are extremely accurate and correspond very well to the major events of the period.",
                "For example, the defeat of Bob Dole, election of Tony Blair, Missile attack on Iraq, etc.",
                "Recall that selecting the features for one event should minimize the cost in Eq. 2 such that 1) the number of features span different events, and 2) not all features relevant to an event will be selected, e.g., the feature Clinton is representative to e12 but since Clinton relates to many other events, its time domain signal is far different from those of other representative features like Dole and Bob.",
                "The number of documents of a detected event is roughly estimated by the number of indexed documents containing the representative features.",
                "We can see that all 17 important aperiodic events are popularly reported events.",
                "After 742 minutes of computation time, we detected 23, 525 less reported aperiodic events from 83,471 LH features.",
                "Table 1 lists the top 5 detected aperiodic events (e18 − e22) with respect to the cost.",
                "We found that these 5 events are actually very trivial events with only a few news reports, and are usually subsumed by some larger topics.",
                "For example, e22 is one of the rescue events in an airplane hijack topic.",
                "One advantage of our UG Algorithm for discovering less-reported aperiodic events is that we are able to precisely detect the true event period. 7.4 Detecting Periodic Events Among the 1,087 HL features, 330 important periodic events were detected within 10 minutes of computing time.",
                "Table 1 lists the top 5 detected periodic events with respect to the cost (e23 − e27).",
                "All of the detected periodic events are indeed valid, and correspond to real life periodic events.",
                "The GMM model is able to detect and estimate the bursty period nicely although it cannot distinguish the slight difference between every Monday-Friday and all weekdays as shown in e23.",
                "We also notice that e26 is actually a subset of e27 (soccer game), which is acceptable since the Sheffield league results are announced independently every weekend. 8.",
                "CONCLUSIONS This paper took a whole new perspective of analyzing feature trajectories as time domain signals.",
                "By considering the word document frequencies in both time and frequency domains, we were able to derive many new characteristics about news streams that were previously unknown, e.g., the different distributions of stopwords during weekdays and weekends.",
                "For the first time in the area of TDT, we applied a systematic approach to automatically detect important and less-reported, periodic and aperiodic events.",
                "The key idea of our work lies in the observations that (a)periodic events have (a)periodic representative features and (un)important events have (in)active representative features, differentiated by their power spectrums and time periods.",
                "To address the real event detection problem, a simple and effective mixture density-based approach was used to identify feature bursts and their associated bursty periods.",
                "We also designed an unsupervised greedy algorithm to detect both aperiodic and periodic events, which was successful in detecting real events as shown in the evaluation on a real news stream.",
                "Although we have not made any benchmark comparison against another approach, simply because there is no previous work in the addressed problem.",
                "Future work includes evaluating the recall of detected events for a labeled news stream, and comparing our model against the closest equivalent methods, which currently are limited to the methods of Kleinberg [12] (which can only detect certain type of bursty events depending on parameter settings), Fung et al. [9], and Swan and Allan [18].",
                "Nevertheless, we believe our simple and effective method will be useful for all TDT practitioners, and will be especially useful for the initial exploratory analysis of news streams. 9.",
                "REFERENCES [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Google news alerts, http://www.google.com/alerts. [3] Reuters corpus, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan.",
                "Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, and H. Jin.",
                "First story detection in tdt is hard.",
                "In CIKM, pages 374-381, 2000. [6] J. Allan, C. Wade, and A. Bolivar.",
                "Retrieval and novelty detection at the sentence level.",
                "In SIGIR, pages 314-321, 2003. [7] T. Brants, F. Chen, and A. Farahat.",
                "A system for new event detection.",
                "In SIGIR, pages 330-337, 2003. [8] A. P. Dempster, N. M. Laird, and D. B. Rubin.",
                "Maximum likelihood from incomplete data via the EM algorithm.",
                "Journal of the Royal Statistical Society, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu, and H. Lu.",
                "Parameter free bursty events detection in text streams.",
                "In VLDB, pages 181-192, 2005. [10] Q.",
                "He, K. Chang, and E.-P. Lim.",
                "A model for anticipatory event detection.",
                "In ER, pages 168-181, 2006. [11] Q.",
                "He, K. Chang, E.-P. Lim, and J. Zhang.",
                "Bursty feature reprensentation for clustering text streams.",
                "In SDM, accepted, 2007. [12] J. Kleinberg.",
                "Bursty and hierarchical structure in streams.",
                "In SIGKDD, pages 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins.",
                "On the bursty evolution of blogspace.",
                "In WWW, pages 159-178, 2005. [14] G. Kumaran and J. Allan.",
                "Text classification and named entities for new event detection.",
                "In SIGIR, pages 297-304, 2004. [15] Q. Mei and C. Zhai.",
                "Discovering evolutionary theme patterns from text: an exploration of temporal text mining.",
                "In SIGKDD, pages 198-207, 2005. [16] W. D. Penny.",
                "Kullback-liebler divergences of normal, gamma, dirichlet and wishart densities.",
                "Technical report, 2001. [17] N. Stokes and J. Carthy.",
                "Combining semantic and syntactic document classifiers to improve first story detection.",
                "In SIGIR, pages 424-425, 2001. [18] R. Swan and J. Allan.",
                "Automatic generation of overview timelines.",
                "In SIGIR, pages 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena, and D. Gunopulos.",
                "Identifying similarities, periodicities and bursts for online search queries.",
                "In SIGMOD, pages 131-142, 2004. [20] Y. Yang, T. Pierce, and J. Carbonell.",
                "A study of retrospective and on-line event detection.",
                "In SIGIR, pages 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topic-conditioned novelty detection.",
                "In SIGKDD, pages 688-693, 2002.",
                "Table 1: All important aperiodic events (e1 − e17), top 5 less-reported aperiodic events (e18 − e22) and top 5 important periodic events (e23 − e27).",
                "Detected Event and Bursty Period Doc # True Event e1(Sali,Berisha,Albania,Albanian,March) 02/02/199705/29/1997 1409 Albanians president Sali Berisha lost in an early election and resigned, 12/1996-07/1997. e2(Seko,Mobutu,Sese,Kabila) 03/22/1997-06/09/1997 2273 Zaires president Mobutu Sese coordinated the native rebellion and failed on 05/16/1997. e3(Marxist,Peruvian) 11/19/1996-03/05/1997 824 Peru rebels (Tupac Amaru revolutionary Movement) led a hostage siege in Lima in early 1997. e4(Movement,Tupac,Amaru,Lima,hostage,hostages) 11/16/1996-03/20/1997 824 The same as e3. e5(Kinshasa,Kabila,Laurent,Congo) 03/26/199706/15/1997 1378 Zaire was renamed the Democratic Republic of Congo on 05/16/1997. e6(Jospin,Lionel,June) 05/10/1997-07/09/1997 605 Following the early General Elections circa 06/1997, Lionel Jospin was appointed Prime Minister on 06/02/1997. e7(Iraq,missile) 08/31/1996-09/13/1996 1262 U.S. fired missile at Iraq on 09/03/1996 and 09/04/1996. e8(Kurdish,Baghdad,Iraqi) 08/29/1996-09/09/1996 1132 Iraqi troop fought with Kurdish faction circa 09/1996. e9(May,Blair) 03/24/1997-07/04/1997 1049 Tony Blair became the Primary Minister of the United Kingdom on 05/02/1997. e10(slalom,skiing) 12/05/1996-03/21/1997 253 Slalom Game of Alpine Skiing in 01/1997-02/1997. e11(Interim,months) 09/24/1996-12/31/1996 3063 Tokyo released company interim results for the past several months in 09/1996-12/1996. e12(Dole,Bob) 09/09/1996-11/24/1996 1599 Dole Bob lost the 1996 US presidential election. e13(July,Sen) 06/25/1997-06/25/1997 344 Cambodias Prime Minister Hun Sen launched a bloody military coup in 07/1997. e14(Hebron) 10/15/1996-02/14/1997 2098 Hebron was divided into two sectors in early 1997. e15(April,Easter) 02/23/1997-05/04/1997 480 Easter feasts circa 04/1997 (for western and Orthodox). e16(Diluted,Group) 04/27/1997-07/20/1997 1888 Tokyo released all 96/97 group results in 04/199707/1997. e17(December,Christmas) 11/17/1996-01/26/1997 1326 Christmas feast in late 12/1997. e18(Kolaceva,winter,Together,promenades,Zajedno, Slobodan,Belgrade,Serbian,Serbia,Draskovic,municipal, Kragujevac) 1/25/1997 3 University students organized a vigil on Kolaceva street against government on 1/25/1997. e19(Tutsi,Luvengi,Burundi,Uvira,fuel,Banyamulenge, Burundian,Kivu,Kiliba,Runingo,Kagunga,Bwegera) 10/19/1996 6 Fresh fighting erupted around Uvira between Zaire armed forces and Banyamulengs Tutsi rebels on 10/19/1996. e20(Malantacchi,Korea,Guy,Rider,Unions,labour, Trade,unions,Confederation,rammed,Geneva,stoppages, Virgin,hire,Myongdong,Metalworkers) 1/11/1997 2 Marcello Malantacchi secretary general of the International Metalworkers Federation and Guy Rider who heads the Geneva office of the International Confederation of Free Trade Unions attacked the new labour law of South Korea on 1/11/1997. e21(DBS,Raﬄes) 8/17/1997 9 The list of the unit of Singapore DBS Land Raﬄes Holdings plans on 8/17/1997. e22(preserver,fuel,Galawa,Huddle,Leul,Beausse) 11/24/1996 3 Rescued a woman and her baby during a hijacked Ethiopian plane that ran out of fuel and crashed into the sea near Le Galawa beach on 11/24/1996. e23(PRICE,LISTING,MLN,MATURITY,COUPON, MOODY,AMT,FIRST,ISS,TYPE,PAY,BORROWER) Monday-Friday/week 7966 Announce bond price on all weekdays. e24(Unaudited,Ended,Months,Weighted,Provision,Cost, Selling,Revenues,Loss,Income,except,Shrs,Revs) every season 2264 Net income-loss reports released by companies in every season. e25(rating,Wall,Street,Ian) Monday-Friday/week 21767 Stock reports from Wall Street on all weekdays. e26(Sheffield,league,scoring,goals,striker,games) every Friday, Saturday and Sunday 574 Match results of Sheffield soccer league were published on Friday, Saturday and Sunday 10 times than other 4 days. e27(soccer,matches,Results,season,game,Cup,match, victory,beat,played,play,division) every Friday, Saturday and Sunday 2396 Soccer games held on Friday, Saturday and Sunday 7 times than other 4 days."
            ],
            "original_annotated_samples": [
                "The document frequency of each word across time is treated like a <br>time series</br>, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point.",
                "All of the above methods can be applied to <br>time series</br> data in general.",
                "IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 Spectral Analysis for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. DFT can represent the original <br>time series</br> as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T.",
                "Its bursty period is defined by [μf − σf , μf + σf ] as shown in Figure 8(b). 5.2 Detecting Periodic Features Bursts Since we have computed the DP for a periodic feature f, we can easily model its periodic feature trajectory yf using 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) original DFIDF:time 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 burst= [μ-σ, μ+σ] (b) identifying burst Figure 8: Modeling Iraqs <br>time series</br> as a truncated Gaussian with μ = 09/06/1996 and σ = 6.26. a mixture of K = T/Pf Gaussians: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , where the parameter set θf = {αk, μk, σk}K k=1 comprises: • αk is the probability of assigning yf into the kth Gaussian. αk > 0, ∀k ∈ [1, K] and K k=1 αk = 1; • μk/σk is mean/standard deviation of the kth Gaussian."
            ],
            "translated_annotated_samples": [
                "La frecuencia del documento de cada palabra a lo largo del tiempo se trata como una <br>serie temporal</br>, donde cada elemento es el puntaje de frecuencia del documento - frecuencia inversa del documento (DFIDF) en un punto temporal.",
                "Todos los métodos anteriores se pueden aplicar a datos de <br>series temporales</br> en general.",
                "En esta sección, mostramos cómo se pueden extraer características representativas para eventos (poco) importantes o (a)periódicos. 4.1 Análisis Espectral para el Período Dominante Dada una característica f, descomponemos su trayectoria de características yf = [yf (1), yf (2), ..., yf (T)] en la secuencia de T números complejos [X1, . . . , XT ] a través de la transformada discreta de Fourier (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. La DFT puede representar la <br>serie temporal</br> original como una combinación lineal de sinusoides complejas, lo cual se ilustra mediante la transformada discreta de Fourier inversa (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, donde el coeficiente de Fourier Xk denota la amplitud del sinusoides con frecuencia k/T.",
                "Su período de ráfagas está definido por [μf − σf , μf + σf ] como se muestra en la Figura 8(b). 5.2 Detección de características periódicas de ráfagas Dado que hemos calculado el DP para una característica periódica f, podemos modelar fácilmente su trayectoria de características periódicas yf usando 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) DFIDF original: tiempo 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 ráfaga= [μ-σ, μ+σ] (b) identificación de ráfaga Figura 8: Modelando la <br>serie temporal</br> de Iraq como una Gaussiana truncada con μ = 09/06/1996 y σ = 6.26. una mezcla de K = T/Pf Gaussianas: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , donde el conjunto de parámetros θf = {αk, μk, σk}K k=1 comprende: • αk es la probabilidad de asignar yf a la k-ésima Gaussiana. αk > 0, ∀k ∈ [1, K] y K k=1 αk = 1; • μk/σk es la media/desviación estándar de la k-ésima Gaussiana."
            ],
            "translated_text": "Analizando Trayectorias de Características para la Detección de Eventos Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg Escuela de Ingeniería Informática Universidad Tecnológica de Nanyang Bloque N4, Avenida Nanyang, Singapur 639798 RESUMEN Consideramos el problema de analizar trayectorias de palabras en los dominios del tiempo y la frecuencia, con el objetivo específico de identificar palabras importantes y menos reportadas, periódicas y aperiódicas. Un conjunto de palabras con tendencias idénticas puede agruparse para reconstruir un evento de manera completamente no supervisada. La frecuencia del documento de cada palabra a lo largo del tiempo se trata como una <br>serie temporal</br>, donde cada elemento es el puntaje de frecuencia del documento - frecuencia inversa del documento (DFIDF) en un punto temporal. En este artículo, 1) primero aplicamos análisis espectral para categorizar características de diferentes tipos de eventos: importantes y poco reportados, periódicos y aperiódicos; 2) modelamos las características aperiódicas con densidad gaussiana y las características periódicas con densidades de mezcla gaussiana, y posteriormente detectamos cada ráfaga de características mediante el enfoque gaussiano truncado; 3) propusimos un algoritmo de detección de eventos codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos. Todos los métodos anteriores se pueden aplicar a datos de <br>series temporales</br> en general. Evaluamos exhaustivamente nuestros métodos en el Corpus de Noticias de Reuters de 1 año [3] y demostramos que fueron capaces de descubrir eventos significativos aperiódicos y periódicos. Categorías y Descriptores de Asignaturas: H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales: Algoritmos, Experimentación. 1. INTRODUCCIÓN Hay más de 4,000 fuentes de noticias en línea en el mundo. Supervisar manualmente todos ellos en busca de eventos importantes se ha vuelto difícil o prácticamente imposible. De hecho, la comunidad de detección y seguimiento de temas (TDT) ha estado tratando durante muchos años de encontrar una solución práctica para ayudar a las personas a monitorear las noticias de manera efectiva. Desafortunadamente, el Santo Grial sigue siendo esquivo, ya que la gran mayoría de las soluciones de TDT propuestas para la detección de eventos [20, 5, 17, 4, 21, 7, 14, 10] son demasiado simplistas (basadas en la similitud del coseno [5]) o impracticables debido a la necesidad de ajustar un gran número de parámetros [9]. La ineficacia de las tecnologías actuales de TDT se puede ilustrar fácilmente suscribiéndose a cualquiera de los muchos servicios de alertas de noticias en línea, como el líder de la industria Google News Alerts, que genera más del 50% de falsas alarmas. Como prueba adicional, portales como Yahoo adoptan un enfoque más pragmático al requerir que todas las alertas de noticias generadas por máquinas pasen por un operador humano para su confirmación antes de enviarlas a los suscriptores. En lugar de abordar el problema con variaciones del mismo martillo (similitud coseno y TFIDF), es necesario contar con una comprensión fundamental de las características de los datos de flujo de noticias antes de que se puedan lograr avances importantes en TDT. Por lo tanto, en este artículo, examinamos noticias y tendencias de características desde la perspectiva de analizar una señal de palabras de series temporales. Trabajos anteriores como [9] han intentado reconstruir un evento con sus características representativas. Sin embargo, en muchas tareas de detección de eventos predictivos (es decir, detección de eventos retrospectivos), hay un vasto conjunto de características potenciales solo para un conjunto fijo de observaciones (es decir, los estallidos obvios). De estas características, a menudo solo se espera que un pequeño número sea útil. En particular, estudiamos el novedoso problema de analizar trayectorias de características para la detección de eventos, utilizando una técnica conocida de procesamiento de señales: identificar correlaciones distribucionales entre todas las características mediante análisis espectral. Para evaluar nuestro método, posteriormente proponemos un algoritmo de detección de eventos no supervisado para flujos de noticias. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Pascua Abril (a) evento aperiódico 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 No auditado Finalizado (b) evento periódico Figura 1: Correlación de características (DFIDF:tiempo) entre a) Pascua y Abril b) No auditado y Finalizado. Como ejemplo ilustrativo, considera la correlación entre las palabras Pascua y abril del Corpus de Reuters. A partir del gráfico de su DFIDF normalizado en la Figura 1(a), observamos la gran superposición entre las dos palabras alrededor de 04/1997, lo que significa que probablemente ambas pertenecen al mismo evento durante ese tiempo (festividad de Pascua). En este ejemplo, el evento oculto de la festividad de Pascua es un evento aperiódico típico e importante en datos de 1 año. Otro ejemplo se muestra en la Figura 1(b), donde las palabras \"No auditado\" y \"Finalizado 1\" del Corpus de Reuters son el conjunto de datos predeterminado para todos los ejemplos y presentan un comportamiento similar durante períodos de 3 meses. Estas dos palabras en realidad se originaron a partir del mismo evento periódico, informes de ganancias y pérdidas, que son publicados trimestralmente por empresas cotizadas en bolsa. Otras observaciones extraídas de la Figura 1 son: 1) el período de actividad intensa de abril es mucho más largo que el de Semana Santa, lo que sugiere que abril puede estar presente en otros eventos durante el mismo período; 2) No auditado tiene un valor promedio de DFIDF más alto que Finalizado, lo que indica que No auditado es más representativo para el evento subyacente. Estos dos ejemplos son solo la punta del iceberg entre todas las tendencias de palabras y correlaciones ocultas en un flujo de noticias como Reuters. Si se puede descubrir un gran número de ellos, podría ayudar significativamente en las tareas de TDT. En particular, indica la importancia de extraer características correlacionadas para detectar eventos correspondientes. Para resumir, postulamos que: 1) Un evento se describe por sus características representativas. Un evento periódico tiene una lista de características periódicas y un evento aperiódico tiene una lista de características aperiódicas; 2) Las características representativas del mismo evento comparten distribuciones similares en el tiempo y están altamente correlacionadas; 3) Un evento importante tiene un conjunto de características representativas activas (ampliamente reportadas), mientras que un evento no importante tiene un conjunto de características representativas inactivas (menos reportadas); 4) Una característica puede ser incluida por varios eventos con superposiciones en los marcos de tiempo. Basándonos en estas observaciones, podemos extraer características representativas dadas un evento o detectar un evento a partir de una lista de características altamente correlacionadas. En este artículo, nos enfocamos en este último aspecto, es decir, cómo se pueden descubrir características correlacionadas para formar un evento de manera no supervisada. 1.1 Contribuciones Este artículo tiene tres contribuciones principales: • Hasta donde sabemos, nuestro enfoque es el primero en categorizar características de palabras para eventos heterogéneos. Específicamente, cada característica de palabra se clasifica en uno de los siguientes cinco tipos de características basados en la fuerza de su espectro de potencia y periodicidad: 1) HH (alta potencia y alta/larga periodicidad): eventos aperiódicos importantes, 2) HL (alta potencia y baja periodicidad): eventos periódicos importantes, 3) LH (baja potencia y alta periodicidad): eventos aperiódicos no importantes, 4) LL (baja potencia y baja periodicidad): no eventos, y 5) SW (palabras vacías), un subconjunto de LL con mayor potencia y periodicidad que comprende palabras vacías, que no contienen información. • Proponemos un enfoque simple y efectivo basado en densidad de mezcla para modelar y detectar ráfagas de características. • Presentamos un algoritmo de detección de eventos no supervisado para detectar eventos tanto aperiódicos como periódicos. Nuestro algoritmo ha sido evaluado en un flujo de noticias reales para demostrar su efectividad. 2. TRABAJO RELACIONADO Este trabajo está motivado en gran medida por una familia más amplia de problemas conocidos colectivamente como Detección y Seguimiento de Temas (TDT) [20, 5, 17, 4, 21, 7, 14, 10]. Además, la mayoría de las investigaciones de TDT hasta ahora se han centrado en agrupar/clasificar documentos en tipos de temas, identificar oraciones novedosas para eventos nuevos, etc., sin prestar mucha atención al análisis de la trayectoria de las palabras con respecto al tiempo. Swan y Allan [18] intentaron por primera vez usar términos que co-ocurren para construir un evento. Sin embargo, solo consideraron entidades nombradas y pares de frases nominales, sin tener en cuenta sus periodicidades. Por el contrario, nuestro artículo considera todo lo anterior. Recientemente, ha habido un gran interés en modelar un evento en flujos de texto como un estallido de actividades al incorporar información temporal. El trabajo seminal de Kleinberg describió cómo se pueden extraer características explosivas de flujos de texto utilizando un modelo de autómata infinito [12], lo que inspiró toda una serie de aplicaciones como la identificación de comunidades explosivas de Kumar a partir de gráficos de blogs [13], la sumarización de temas evolutivos en flujos de texto de Meis [15], el agrupamiento de flujos de texto utilizando características explosivas de Hes [11], etc. Sin embargo, ninguno de los trabajos existentes identificó específicamente características para eventos, excepto Fung et al. [9], quienes agruparon características llamativas para identificar varios eventos llamativos. Nuestro trabajo difiere de [9] en varias formas: 1) analizamos cada característica individual, no solo las características explosivas; 2) clasificamos las características a lo largo de dos dimensiones categóricas (periodicidad y potencia), dando en total cinco tipos de características principales; 3) no restringimos que cada característica pertenezca exclusivamente a un solo evento. Las técnicas de análisis espectral han sido utilizadas previamente por Vlachos et al. [19] para identificar periodicidades y ráfagas en los registros de consultas. Su enfoque estaba en detectar múltiples periodicidades a partir del gráfico del espectro de potencia, las cuales luego se utilizaron para indexar palabras para la búsqueda por ráfagas. En este artículo, utilizamos análisis espectral para clasificar las características de las palabras a lo largo de dos dimensiones, a saber, periodicidad y espectro de potencia, con el objetivo final de identificar eventos tanto periódicos como no periódicos y explosivos. 3. REPRESENTACIÓN DE DATOS Sea T la duración/período (en días) de un flujo de noticias, y F representa el espacio de características de palabras completo en el Modelo de Espacio Vectorial (VSM) estático clásico. 3.1 Clasificación de Periodicidad de Eventos Dentro de T, pueden existir ciertos eventos que ocurren solo una vez, por ejemplo, la elección de Tony Blair como Primer Ministro del Reino Unido, y otros eventos recurrentes de diversas periodicidades, por ejemplo, partidos de fútbol semanales. Por lo tanto, categorizamos todos los eventos en dos tipos: aperiódicos y periódicos, definidos de la siguiente manera. Definición 1. (Evento aperiódico) Un evento es aperiódico dentro de T si solo ocurre una vez. Definición 2. (Evento periódico) Si los eventos de un cierto género de eventos ocurren regularmente con una periodicidad fija P ≤ T/2, decimos que este género particular de eventos es periódico, y cada evento miembro se califica como un evento periódico. Ten en cuenta que la definición de aperiódico es relativa, es decir, es verdadera solo para un T dado y puede ser inválida para cualquier otro T > T. Por ejemplo, el evento de la fiesta de Navidad es aperiódico para T ≤ 365 pero periódico para T ≥ 730. 3.2 Características Representativas Intuitivamente, un evento puede ser descrito de manera muy concisa por unas pocas características de palabras discriminativas y representativas y viceversa, por ejemplo, huracán, barrido y golpe podrían ser características representativas de un evento del género de huracanes. Asimismo, un conjunto de características fuertemente correlacionadas podría ser utilizado para reconstruir una descripción de un evento, asumiendo que las características fuertemente correlacionadas son representativas. El vector de representación de una característica de palabra se define de la siguiente manera: Definición 3. (Trayectoria de la Característica) La trayectoria de una característica de palabra f puede escribirse como la secuencia yf = [yf (1), yf (2), . . . , yf (T)], donde cada elemento yf (t) es una medida de la característica f en el tiempo t, que podría definirse utilizando la puntuación normalizada DFIDF yf (t) = DFf (t) N(t) × log( N DFf ), donde DFf (t) es el número de documentos (DF local) que contienen la característica f en el día t, DFf es el número total de documentos (DF global) que contienen la característica f en T, N(t) es el número de documentos para el día t, y N es el número total de documentos en T. 4. En esta sección, mostramos cómo se pueden extraer características representativas para eventos (poco) importantes o (a)periódicos. 4.1 Análisis Espectral para el Período Dominante Dada una característica f, descomponemos su trayectoria de características yf = [yf (1), yf (2), ..., yf (T)] en la secuencia de T números complejos [X1, . . . , XT ] a través de la transformada discreta de Fourier (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. La DFT puede representar la <br>serie temporal</br> original como una combinación lineal de sinusoides complejas, lo cual se ilustra mediante la transformada discreta de Fourier inversa (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, donde el coeficiente de Fourier Xk denota la amplitud del sinusoides con frecuencia k/T. La trayectoria original puede ser reconstruida con solo las frecuencias dominantes, las cuales pueden ser determinadas a partir del espectro de potencia utilizando el popular estimador periodograma. El periodograma es una secuencia de la magnitud al cuadrado de los coeficientes de Fourier, Xk^2, k = 1, 2, . . . , T/2, que indica la potencia de la señal en la frecuencia k/T en el espectro. A partir del espectro de potencia, se elige el período dominante como el inverso de la frecuencia con el espectro de potencia más alto, de la siguiente manera. Definición 4. (Período Dominante) El período dominante (DP) de una característica dada f es Pf = T/ arg max k Xk 2. Por lo tanto, tenemos la Definición 5. (Espectro de Potencia Dominante) El espectro de potencia dominante (DPS) de una característica dada f es Sf = Xk 2 , con Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorización de Características El DPS de una trayectoria de características es un indicador fuerte de su actividad en la frecuencia especificada; cuanto mayor sea el DPS, es más probable que la característica sea explosiva. Al combinar DPS con DP, categorizamos todas las características en cuatro tipos: 2 Normalizamos yf (t) como yf (t) = yf (t)/ T i=1 yf (i) para que pueda interpretarse como una probabilidad. • HH: alta Sf, aperiódico o periódico a largo plazo (Pf > T/2); • HL: alta Sf, periódico a corto plazo (Pf ≤ T/2); • LH: baja Sf, aperiódico o periódico a largo plazo; • LL: baja Sf, periódico a corto plazo. La frontera entre los periodos a largo plazo y a corto plazo se establece en T/2. Sin embargo, distinguir entre un DPS alto y bajo no es sencillo, lo cual se abordará más adelante. Propiedades de diferentes conjuntos de características Para comprender mejor las propiedades de HH, HL, LH y LL, seleccionamos cuatro características, Navidad, fútbol, DBS y tu como ejemplos ilustrativos. Dado que la frontera entre el espectro de alta y baja potencia no está clara, estos ejemplos seleccionados tienen un rango relativo amplio de valores de espectro de potencia. La figura 2(a) muestra la trayectoria de DFIDF para la Navidad con un pico distintivo alrededor del día de Navidad. Para el conjunto de datos de Reuters de 1 año, la Navidad se clasifica como un evento aperiódico típico con Pf = 365 y Sf = 135.68, como se muestra en la Figura 2(b). Claramente, el valor de Sf = 135.68 es razonable para un evento conocido por ser intermitente como la Navidad. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Navidad(DFIDF:tiempo) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Navidad(S:frecuencia) Figura 2: Característica Navidad con un Sf relativamente alto y un Pf a largo plazo. La trayectoria de DFIDF para el fútbol se muestra en la Figura 3(a), de la cual podemos observar que hay un estallido regular cada 7 días, lo cual es nuevamente verificado por su valor calculado de Pf = 7, como se muestra en la Figura 3(b). Usando el conocimiento del dominio de que los partidos de fútbol tienen más encuentros cada sábado, lo que lo convierte en un evento periódico típico y ampliamente reportado, consideramos que el valor de Sf = 155.13 es alto. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) fútbol (DFIDF:tiempo) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) fútbol (S:frecuencia) Figura 3: Característica fútbol con un Sf relativamente alto y un Pf a corto plazo. A partir de la trayectoria de DFIDF para DBS en la Figura 4(a), podemos deducir de inmediato que DBS es una palabra poco frecuente con un aumento trivial el 17/08/1997 correspondiente a los planes de DBS Land Raﬄes Holdings. Esto se confirma por el largo período de Pf = 365 y la baja potencia de Sf = 0.3084 como se muestra en la Figura 4(b). Además, dado que este evento aperiódico solo se informa en algunas noticias durante un corto período de unos pocos días, por lo tanto, decimos que su bajo valor de potencia de Sf = 0.3084 es representativo de eventos poco importantes. El ejemplo más confuso se muestra en la Figura 5 para la palabra \"your\", que se ve muy similar al gráfico para fútbol en la Figura 3. A primera vista, podríamos sentirnos tentados a agrupar tanto tu como el fútbol en la misma categoría de HL o LL, ya que ambas distribuciones se ven similares y tienen el mismo período dominante de aproximadamente una semana. Sin embargo, más adelante 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:tiempo) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frecuencia) Figura 4: Característica DBS con Sf relativamente bajo y Pf a largo plazo. El análisis indica que la periodicidad de su es debido a las diferencias en el recuento de documentos para los días de la semana (promedio de 2,919 por día) y los fines de semana (promedio de 479 por día). Uno habría esperado que la periodicidad de una palabra vacía como \"tu\" fuera de un día. Además, a pesar de nuestra normalización de DFIDF, el desequilibrio entre los días de la semana y los fines de semana aún prevalecía; las palabras vacías ocurren 4 veces más frecuentemente los fines de semana que los días de semana. Por lo tanto, el DPS sigue siendo el único factor distintivo entre tu (Sf = 9.42) y el fútbol (Sf = 155.13). Sin embargo, es muy peligroso concluir simplemente que un valor de potencia de S = 9.42 corresponde a una característica de palabra vacía. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) tu(DFIDF:tiempo) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) tu(S:frecuencia) Figura 5: Característica tu como un ejemplo confundido con la característica fútbol. Antes de presentar nuestra solución a este problema, veamos otro ejemplo de LL como se muestra en la Figura 6 para beenb, que en realidad es un error tipográfico confirmado. Por lo tanto, clasificamos beenb como una característica ruidosa que no contribuye a ningún evento. Claramente, la trayectoria de tu es muy diferente de beenb, lo que significa que el primero debe considerarse por separado. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figura 6: Característica beenb con Sf relativamente bajo y Pf a corto plazo. Conjunto de características de palabras vacías (SW) Basándonos en el análisis anterior, nos damos cuenta de que debe haber otro conjunto de características entre HL y LL que corresponda al conjunto de palabras vacías. Las características de este conjunto tienen un DPS moderado y un período dominante bajo pero conocido. Dado que es difícil distinguir este conjunto de características de HL y LL solo basándose en DPS, introducimos otro factor llamado promedio de DFIDF (DFIDF). Como se muestra en la Figura 5, características como la tuya suelen tener un DPS más bajo que una característica HL como el fútbol, pero tienen un DFIDF mucho más alto que otra característica ruidosa LL como \"beenb\". Dado que tales propiedades suelen ser características de las palabras vacías, agrupamos características como \"tu\" en el conjunto de características de palabras vacías (SW) recién definido. Dado que establecer los umbrales de DPS y DFIDF para identificar las palabras vacías es más un arte que una ciencia, propusimos un algoritmo heurístico HS, Algoritmo 1. La idea básica es utilizar solo noticias de días laborables para identificar palabras vacías. Los fines de semana aquí también incluyen días festivos que caen en días laborables. El conjunto SW se inicialmente alimenta con un pequeño conjunto de 29 stopwords populares utilizadas por el motor de búsqueda de Google. Algoritmo 1 Detección heurística de palabras vacías (HS) Entrada: Conjunto de palabras vacías semilla, trayectorias semanales de todas las palabras 1: A partir del conjunto semilla SW, calcular el DPS máximo como UDPS, el DFIDF máximo como UDFIDF y el mínimo de DFIDF como LDFIDF. 2: para fi ∈ F hacer 3: Calcular DFT para fi. 4: si Sfi ≤ UDPS y DFIDFfi ∈ [LDFIDF, UDFIDF] entonces 5: fi → SW 6: F = F - fi 7: fin si 8: fin para Resumen de la Categorización de Características Después de generar el conjunto SW, se eliminan todas las palabras vacías de F. Luego, establecemos el límite entre DPS alto y bajo como el límite superior de los DPS de los conjuntos SW. Una visión general de los cinco conjuntos de características se muestra en la Figura 7. Figura 7: Los 5 conjuntos de características para eventos. 5. IDENTIFICACIÓN DE RÁFAGAS PARA CARACTERÍSTICAS Dado que solo las características de HH, HL y LH son significativas y podrían ser representativas de algunos eventos, eliminamos todas las demás características clasificadas como LL o SW. En esta sección, describimos cómo se pueden identificar los estallidos a partir de las características restantes. A diferencia del algoritmo de identificación de ráfagas de Kleinberg [12], podemos identificar tanto ráfagas significativas como triviales sin necesidad de establecer ningún parámetro. 5.1 Detección de ráfagas de características aperiódicas Para cada característica en HH y HL, truncamos su trayectoria manteniendo solo el período de ráfagas, el cual está modelado con una distribución gaussiana. Por ejemplo, la Figura 8 muestra la característica de la palabra Iraq con una explosión alrededor del 09/06/1996 modelada como una Gaussiana. Su período de ráfagas está definido por [μf − σf , μf + σf ] como se muestra en la Figura 8(b). 5.2 Detección de características periódicas de ráfagas Dado que hemos calculado el DP para una característica periódica f, podemos modelar fácilmente su trayectoria de características periódicas yf usando 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) DFIDF original: tiempo 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 ráfaga= [μ-σ, μ+σ] (b) identificación de ráfaga Figura 8: Modelando la <br>serie temporal</br> de Iraq como una Gaussiana truncada con μ = 09/06/1996 y σ = 6.26. una mezcla de K = T/Pf Gaussianas: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , donde el conjunto de parámetros θf = {αk, μk, σk}K k=1 comprende: • αk es la probabilidad de asignar yf a la k-ésima Gaussiana. αk > 0, ∀k ∈ [1, K] y K k=1 αk = 1; • μk/σk es la media/desviación estándar de la k-ésima Gaussiana. El conocido algoritmo Expectation Maximization (EM) [8] se utiliza para calcular las proporciones de mezcla αk, así como los parámetros individuales de densidad gaussiana μk y σK. Cada Gaussiana representa un evento periódico, y se modela de manera similar como se menciona en la Sección 5.1. 6. EVENTOS A PARTIR DE CARACTERÍSTICAS Después de identificar y modelar ráfagas para todas las características, la siguiente tarea es pintar un cuadro del evento con un posible conjunto de características representativas. 6.1 Correlación de Características Si dos características fi y fj son representativas del mismo evento, deben cumplir las siguientes condiciones necesarias: 1. fi y fj están distribuidas de manera idéntica: yfi ∼ yfj. 2. fi y fj tienen una alta superposición de documentos. Medición de la similitud de la distribución de características. Medimos la similitud entre dos características fi y fj utilizando la divergencia KL discreta definida de la siguiente manera. Definición 6. (similitud de características) KL(fi, fj) se da por max(KL(fi|fj), KL(fj|fi)), donde KL(fi|fj) = T t=1 f(yfi(t)|θfi)log f(yfi(t)|θfi) f(yfj(t)|θfj). (1) Dado que la divergencia KL no es simétrica, definimos la similitud entre fi y fj como el máximo entre KL(fi|fj) y KL(fj|fi). Además, la similitud entre dos características aperiódicas puede calcularse utilizando una forma cerrada de la divergencia de Kullback-Leibler [16]. La misma fórmula discreta de divergencia KL de la Ecuación 1 se emplea para calcular la similitud entre dos características periódicas. A continuación, definimos la similitud general entre un conjunto de características R utilizando el valor máximo de divergencia KL entre características como sigue. Definición 7. (similitud de conjuntos) KL(R) = max ∀fi, fj ∈R KL(fi, fj). Superposición de documentos: Sea Mi el conjunto de todos los documentos que contienen la característica fi. Dadas dos características fi y fj, el conjunto de documentos superpuestos que contienen ambas características es Mi ∩ Mj. De manera intuitiva, cuanto mayor sea |Mi ∩ Mj|, es más probable que fi y fj estén altamente correlacionados. Definimos el grado de superposición de documentos entre dos características fi y fj de la siguiente manera. Definición 8. (Superposición de características DF) d(fi, fj) = |Mi∩Mj| min(|Mi|, |Mj|). En consecuencia, la superposición de DF entre un conjunto de características R también está definida. Definición 9. (Superposición de Conjuntos DF) d(R) = min ∀fi, fj ∈R d(fi, fj). 6.2 Detección de Eventos Codiciosa No Supervisada Utilizamos características de HH para detectar eventos aperiódicos importantes, características de LH para detectar eventos aperiódicos menos reportados/poco importantes, y características de HL para detectar eventos periódicos. Todos comparten el mismo algoritmo. Dado el rasgo explosivo fi ∈ HH, el objetivo es encontrar rasgos altamente correlacionados de HH. El conjunto de características similares a fi puede describir colectivamente un evento. Específicamente, necesitamos encontrar un subconjunto Ri de HH que minimice la siguiente función de costo: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) El evento subyacente e (asociado con la explosión de fi) puede ser representado por Ri como y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) El análisis de la explosión para el evento e es exactamente el mismo que la trayectoria de características. El costo en la Ecuación 2 se puede minimizar utilizando nuestro algoritmo de detección de eventos UG codicioso no supervisado, que se describe en el Algoritmo 2. El algoritmo UG permite una característica Algoritmo 2 Detección de eventos codiciosos no supervisados (UG). Salida: ek como Ec. 3. Además, los eventos triviales que solo contienen características de año/mes (es decir, un evento que solo contiene una característica de agosto podría ser identificado en un flujo de noticias de 1 año) podrían ser eliminados, aunque dichos eventos tendrán un costo inherente alto y deberían estar clasificados muy bajos. Tenga en cuenta que nuestro algoritmo UG solo requiere un parámetro dependiente de los datos, el límite entre el espectro de alta y baja potencia, que debe establecerse una vez, y este parámetro puede estimarse fácilmente utilizando el algoritmo HS (Algoritmo 1). 7. EXPERIMENTOS En esta sección, estudiamos el rendimiento de nuestro método de categorización de características y algoritmo de detección de eventos. Primero presentamos el conjunto de datos y la configuración experimental, luego evaluamos subjetivamente la categorización de características para HH, HL, LH, LL y SW. Finalmente, estudiamos el problema de detección de eventos (a)periódicos con el Algoritmo 2. 7.1. Conjunto de datos y configuración experimental El Corpus de Reuters contiene 806,791 noticias en inglés desde el 20/08/1996 hasta el 19/08/1997 con una resolución diaria. La versión 2 del software de código abierto Lucene [1] se utilizó para tokenizar el contenido de texto de noticias y generar el vector documento-palabra. Con el fin de preservar los tiempos verbales pasados/presentes/futuros sensibles al tiempo y las diferencias entre los sustantivos en minúscula y las entidades nombradas en mayúscula, no se realizó ningún truncamiento. Dado que la eliminación dinámica de palabras vacías es una de las funcionalidades de nuestro método, no se eliminó ninguna palabra vacía. Eliminamos los caracteres no ingleses, sin embargo, después de eso, el número de características de palabras asciende a 423,433. Todos los experimentos se implementaron en Java y se llevaron a cabo en una PC Pentium 4 de 3.2 GHz con Windows 2003 Server y 1 GB de memoria. 7.2 Categorización de características Descargamos 34 stopwords bien conocidos utilizados por el motor de búsqueda de Google como nuestras características de entrenamiento iniciales, que incluyen a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en y www. Excluimos las últimas cinco palabras vacías ya que son poco comunes en noticias. Al analizar solo historias de noticias durante 259 días laborables, calculamos el límite superior del espectro de potencia para las palabras vacías en 11.18 y los rangos correspondientes de DFIDF van desde 0.1182 hasta 0.3691. Cualquier característica f que cumpla con Sf <= 11.18 y 0.1182 <= DFIDFf <= 0.3691 durante los días de la semana se considerará una palabra vacía. De esta manera, se encontraron y eliminaron 470 palabras vacías como se muestra en la Figura 9. Algunas palabras vacías detectadas son A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) y much (P = 22, S = 0.80, DFIDF = 0.1865). Después de la eliminación de estas palabras vacías, la distribución de las noticias entre semana y los fines de semana están más o menos equilibradas, y en los experimentos subsiguientes, haremos uso del corpus completo (entre semana y fines de semana). El valor del espectro de potencia límite superior de 11.18 para el entrenamiento de palabras vacías fue seleccionado como el límite entre el espectro de alta potencia y baja potencia. El límite entre alta y baja periodicidad se estableció en 365/2 = 183. Todos los 422,963 (423433 − 470) rasgos de palabras fueron categorizados en 4 conjuntos de rasgos: HH (69 rasgos), HL (1,087 rasgos), LH (83,471 rasgos) y LL (338,806 rasgos) como se muestra en la Figura 10. En la Figura 10, cada nivel de gris denota la densidad relativa de características en una región cuadrada, medida por log10(1 + Dk), donde Dk es el número de características dentro de la k-ésima región cuadrada. A partir de la figura, podemos hacer el 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figura 9: Distribución de SW (palabras vacías) en las regiones HH, HL, LH y LL. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figura 10: Distribución de características categorizadas en los cuatro cuadrantes (sombreado en escala logarítmica). siguientes observaciones: 1. La mayoría de las características tienen un valor bajo de S y son fácilmente distinguibles de aquellas características que tienen un valor mucho más alto de S, lo que nos permite detectar eventos importantes (a)periódicos de eventos triviales seleccionando características con un alto valor de S. 2. Las características en los cuadrantes HH y LH son aperiódicas, las cuales están bien separadas (gran brecha horizontal) de las características periódicas. Esto permite detectar de manera confiable eventos aperiódicos y eventos periódicos de forma independiente. 3. La frontera (vertical) entre el espectro de alta y baja potencia no es tan clara y el valor exacto dependerá de la aplicación específica. Al revisar la distribución de dispersión de las características de SW en HH, HL, LH y LL como se muestra en la Figura 9, encontramos que el 87.02% (409/470) de las stopwords detectadas se originaron en LL. La clasificación LL y las altas puntuaciones de DFIDF de las palabras vacías concuerdan con la noción generalmente aceptada de que las palabras vacías son igualmente frecuentes en todo momento. Por lo tanto, establecer el límite entre el espectro de alta y baja potencia utilizando el límite superior Sf de SW es una heurística razonable. 7.3 Detección de Eventos Aperiódicos Evaluaremos nuestras dos hipótesis, 1)los eventos aperiódicos importantes pueden ser definidos por un conjunto de características HH, y 2)los eventos aperiódicos menos reportados pueden ser definidos por un conjunto de características LH. Dado que no existen flujos de noticias de referencia para la detección de eventos (los conjuntos de datos de TDT no son flujos adecuados), evaluamos la calidad de los eventos detectados automáticamente comparándolos con eventos confirmados manualmente mediante la búsqueda en el corpus. Entre las 69 características de HH, detectamos 17 eventos aperiódicos importantes como se muestra en la Tabla 1 (e1 - e17). Ten en cuenta que toda la identificación tomó menos de 1 segundo, después de eliminar los eventos que solo contenían la característica del mes. De los 17 eventos, aparte de las superposiciones entre e3 y e4 (ambos describen el mismo evento de rehenes), e11 y e16 (ambos sobre informes de empresas), los 14 eventos identificados son extremadamente precisos y corresponden muy bien a los principales eventos del período. Por ejemplo, la derrota de Bob Dole, la elección de Tony Blair, el ataque con misiles a Iraq, etc. Recuerde que seleccionar las características para un evento debería minimizar el costo en la Ecuación 2 de tal manera que 1) el número de características abarque diferentes eventos, y 2) no se seleccionarán todas las características relevantes para un evento, por ejemplo, la característica Clinton es representativa para e12, pero dado que Clinton se relaciona con muchos otros eventos, su señal de dominio temporal es muy diferente de la de otras características representativas como Dole y Bob. El número de documentos de un evento detectado se estima aproximadamente por el número de documentos indexados que contienen las características representativas. Podemos ver que los 17 eventos aperiódicos importantes son eventos reportados popularmente. Después de 742 minutos de tiempo de computación, detectamos 23,525 eventos aperiódicos menos reportados de 83,471 características de LH. La Tabla 1 enumera los 5 principales eventos aperiódicos detectados (e18 - e22) con respecto al costo. Descubrimos que estos 5 eventos son en realidad eventos muy triviales con solo unos pocos informes de noticias, y suelen ser englobados por algunos temas más grandes. Por ejemplo, e22 es uno de los eventos de rescate en un tema de secuestro de avión. Una ventaja de nuestro Algoritmo UG para descubrir eventos aperiódicos poco reportados es que podemos detectar con precisión el verdadero período del evento. 7.4 Detección de Eventos Periódicos Entre las 1,087 características de HL, se detectaron 330 eventos periódicos importantes en un tiempo de cálculo de 10 minutos. La Tabla 1 enumera los 5 eventos periódicos detectados con respecto al costo (e23 - e27). Todos los eventos periódicos detectados son realmente válidos y corresponden a eventos periódicos de la vida real. El modelo GMM es capaz de detectar y estimar el período de ráfagas de manera precisa, aunque no puede distinguir la ligera diferencia entre cada lunes a viernes y todos los días de la semana, como se muestra en e23. También observamos que e26 es en realidad un subconjunto de e27 (partido de fútbol), lo cual es aceptable ya que los resultados de la liga de Sheffield se anuncian de forma independiente cada fin de semana. 8. CONCLUSIONES Este artículo adoptó una perspectiva completamente nueva para analizar las trayectorias de características como señales en el dominio del tiempo. Al considerar las frecuencias de los documentos en el dominio del tiempo y de la frecuencia, pudimos derivar muchas nuevas características sobre los flujos de noticias que antes eran desconocidas, por ejemplo, las diferentes distribuciones de palabras vacías durante los días de la semana y los fines de semana. Por primera vez en el área de TDT, aplicamos un enfoque sistemático para detectar automáticamente eventos importantes y menos reportados, periódicos y aperiódicos. La idea clave de nuestro trabajo radica en las observaciones de que los eventos periódicos tienen características representativas periódicas y los eventos (in)importantes tienen características representativas (in)activas, diferenciadas por sus espectros de potencia y períodos de tiempo. Para abordar el problema de detección de eventos reales, se utilizó un enfoque basado en densidad de mezcla simple y efectivo para identificar ráfagas de características y sus períodos asociados de ráfagas. También diseñamos un algoritmo codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos, el cual tuvo éxito en detectar eventos reales como se muestra en la evaluación en un flujo de noticias reales. Aunque no hemos realizado ninguna comparación de referencia con otro enfoque, simplemente porque no hay trabajos previos en el problema abordado. El trabajo futuro incluye evaluar la recuperación de eventos detectados en un flujo de noticias etiquetado, y comparar nuestro modelo con los métodos equivalentes más cercanos, que actualmente se limitan a los métodos de Kleinberg [12] (que solo pueden detectar ciertos tipos de eventos explosivos dependiendo de la configuración de parámetros), Fung et al. [9], y Swan y Allan [18]. Sin embargo, creemos que nuestro método simple y efectivo será útil para todos los practicantes de TDT, y será especialmente útil para el análisis exploratorio inicial de flujos de noticias. REFERENCIAS [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Alertas de noticias de Google, http://www.google.com/alerts. [3] Corpus de Reuters, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan. Detección y seguimiento de temas. Organización de la información basada en eventos. Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, y H. Jin. La detección de la primera historia en tdt es difícil. En CIKM, páginas 374-381, 2000. [6] J. Allan, C. Wade y A. Bolivar. Recuperación y detección de novedades a nivel de oración. En SIGIR, páginas 314-321, 2003. [7] T. Brants, F. Chen y A. Farahat. Un sistema para la detección de nuevos eventos. En SIGIR, páginas 330-337, 2003. [8] A. P. Dempster, N. M. Laird y D. B. Rubin. Máxima verosimilitud a partir de datos incompletos a través del algoritmo EM. Revista de la Real Sociedad Estadística, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu y H. Lu. Detección de eventos explosivos sin parámetros en flujos de texto. En VLDB, páginas 181-192, 2005. [10] Q. Él, K. Chang y E.-P. Lim. Un modelo para la detección anticipada de eventos. En ER, páginas 168-181, 2006. [11] Q. Él, K. Chang, E.-P. Lim y J. Zhang. Representación de características intermitentes para la agrupación de flujos de texto. En SDM, aceptado, 2007. [12] J. Kleinberg. Estructura explosiva y jerárquica en arroyos. En SIGKDD, páginas 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan y A. Tomkins. Sobre la evolución explosiva del blogosfera. En WWW, páginas 159-178, 2005. [14] G. Kumaran y J. Allan. Clasificación de texto y entidades nombradas para la detección de nuevos eventos. En SIGIR, páginas 297-304, 2004. [15] Q. Mei y C. Zhai. Descubriendo patrones temáticos evolutivos a partir de texto: una exploración de la minería de texto temporal. En SIGKDD, páginas 198-207, 2005. [16] W. D. Penny. Divergencias de Kullback-Leibler de densidades normales, gamma, dirichlet y wishart. Informe técnico, 2001. [17] N. Stokes y J. Carthy. Combinando clasificadores de documentos semánticos y sintácticos para mejorar la detección de la primera noticia. En SIGIR, páginas 424-425, 2001. [18] R. Swan y J. Allan. Generación automática de líneas de tiempo de resumen. En SIGIR, páginas 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena y D. Gunopulos. Identificando similitudes, periodicidades y ráfagas en las consultas de búsqueda en línea. En SIGMOD, páginas 131-142, 2004. [20] Y. Yang, T. Pierce y J. Carbonell. Un estudio de detección de eventos retrospectivos y en línea. En SIGIR, páginas 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell y C. Jin. Detección de novedades condicionada por el tema. En SIGKDD, páginas 688-693, 2002. Tabla 1: Todos los eventos aperiódicos importantes (e1 - e17), los 5 eventos aperiódicos menos reportados (e18 - e22) y los 5 eventos periódicos importantes (e23 - e27). Evento detectado y período de actividad intensa Doc # Verdadero evento e1 (Sali, Berisha, Albania, albanés, marzo) 02/02/199705/29/1997 1409 El presidente albanés Sali Berisha perdió en una elección temprana y renunció, 12/1996-07/1997. e2 (Seko, Mobutu, Sese, Kabila) 03/22/1997-06/09/1997 2273 El presidente de Zaire, Mobutu Sese, coordinó la rebelión nativa y fracasó el 16/05/1997. e3 (Marxista, peruano) 11/19/1996-03/05/1997 824 Los rebeldes de Perú (Movimiento Revolucionario Tupac Amaru) lideraron un asedio de rehenes en Lima a principios de 1997. e4 (Movimiento, Tupac, Amaru, Lima, rehén, rehenes) 11/16/1996-03/20/1997 824 Lo mismo que e3. e5 (Kinshasa, Kabila, Laurent, Congo) 03/26/199706/15/1997 1378 Zaire fue renombrado República Democrática del Congo el 16/05/1997. e6 (Jospin, Lionel, junio) 05/10/1997-07/09/1997 605 Tras las elecciones generales tempranas alrededor de 06/1997, Lionel Jospin fue nombrado Primer Ministro el 02/06/1997. e7 (Irak, misil) 08/31/1996-09/13/1996 1262 EE. UU. disparó un misil a Irak el 03/09/1996 y el 04/09/1996. e8 (kurdo, Bagdad, iraquí) 08/29/1996-09/09/1996 1132 Tropas iraquíes lucharon con facciones kurdas alrededor de 09/1996. e9 (mayo, Blair) 03/24/1997-07/04/1997 1049 Tony Blair se convirtió en el Primer Ministro del Reino Unido el 02/05/1997. e10 (slalom, esquí) 12/05/1996-03/21/1997 253 Juego de eslalon de esquí alpino en 01/1997-02/1997. e11 (Interino, meses) 09/24/1996-12/31/1996 3063 Tokio publicó los resultados interinos de la empresa para los últimos meses en 09/1996-12/1996. e12 (Dole, Bob) 09/09/1996-11/24/1996 1599 Bob Dole perdió las elecciones presidenciales de EE. UU. de 1996. e13 (julio, Sen) 06/25/1997-06/25/1997 344 El Primer Ministro de Camboya, Hun Sen, lanzó un sangriento golpe militar en 07/1997. e14 (Hebrón) 10/15/1996-02/14/1997 2098 Hebrón fue dividida en dos sectores a principios de 1997. e15 (abril, Pascua) 02/23/1997-05/04/1997 480 Festividades de Pascua alrededor de 04/1997 (para occidentales y ortodoxos). e16 (Diluido, Grupo) 04/27/1997-07/20/1997 1888 Tokio publicó todos los resultados del grupo 96/97 en 04/199707/1997. e17 (diciembre, Navidad) 11/17/1996-01/26/1997 1326 Festín de Navidad a finales de 12/1997. e18 (Kolaceva, invierno, Juntos, paseos, Zajedno, Slobodan, Belgrado, serbio, Serbia, Draskovic, municipal, Kragujevac) 1/25/1997 3 Estudiantes universitarios organizaron una vigilia en la calle Kolaceva contra el gobierno el 25/01/1997. e19 (Tutsi, Luvengi, Burundi, Uvira, combustible, Banyamulenge, burundés, Kivu, Kiliba, Runingo, Kagunga, Bwegera) 10/19/1996 6 Estallaron nuevos enfrentamientos alrededor de Uvira entre las fuerzas armadas de Zaire y los rebeldes Tutsi de Banyamulenge el 19/10/1996. e20 (Malantacchi, Corea, Guy, Rider, Sindicatos, trabajo, Confederación, embestido, Ginebra, paradas, Virgin, contratar, Myongdong, Metalúrgicos) 1/11/1997 2 Marcello Malantacchi, secretario general de la Federación Internacional de Metalúrgicos, y Guy Rider, quien dirige la oficina de Ginebra de la Confederación Internacional de Sindicatos Libres, atacaron la nueva ley laboral de Corea del Sur el 11/01/1997. e21 (DBS, Raﬄes) 8/17/1997 9 La lista de la unidad de DBS Land Raﬄes Holdings de Singapur planea el 17/08/1997. e22 (conservador, combustible, Galawa, Huddle, Leul, Beausse) 11/24/1996 3 Rescataron a una mujer y a su bebé durante un secuestro de un avión etíope que se quedó sin combustible y se estrelló en el mar cerca de la playa Le Galawa el 24/11/1996. e23 (PRECIO, LISTADO, MLN, VENCIMIENTO, CUPÓN, MOODY, MONTO, PRIMERO, ISS, TIPO, PAGO, PRESTAMISTA) Lunes a viernes/semana 7966 Anuncian el precio de los bonos todos los días de la semana. e24 (No auditado, Terminado, Meses, Ponderado, Provisión, Costo, Venta, Ingresos, Pérdida, Ingreso, excepto, Shrs, Revs) cada temporada 2264 Informes de ingresos netos-pérdidas publicados por empresas en cada temporada. e25 (calificación, Wall Street, Ian) Lunes a viernes/semana 21767 Informes de acciones de Wall Street todos los días de la semana. e26 (Sheffield, liga, goles de puntuación, delantero, juegos) cada viernes, sábado y domingo 574 Resultados de partidos de la liga de fútbol de Sheffield publicados los viernes, sábados y domingos 10 veces más que en los otros 4 días. e27 (fútbol, partidos, Resultados, temporada, juego, Copa, partido, victoria, vencer, jugado, jugar, división) cada viernes, sábado y domingo 2396 Juegos de fútbol celebrados los viernes, sábados y domingos 7 veces más que en los otros 4 días. ",
            "candidates": [],
            "error": [
                [
                    "serie temporal",
                    "series temporales",
                    "serie temporal",
                    "serie temporal"
                ]
            ]
        },
        "feature categorization": {
            "translated_key": "categorización de las características",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Analyzing Feature Trajectories for Event Detection Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg School of Computer Engineering Nanyang Technological University Block N4, Nanyang Avenue, Singapore 639798 ABSTRACT We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words.",
                "A set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner.",
                "The document frequency of each word across time is treated like a time series, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point.",
                "In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events.",
                "All of the above methods can be applied to time series data in general.",
                "We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events.",
                "Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Experimentation. 1.",
                "INTRODUCTION There are more than 4,000 online news sources in the world.",
                "Manually monitoring all of them for important events has become difficult or practically impossible.",
                "In fact, the topic detection and tracking (TDT) community has for many years been trying to come up with a practical solution to help people monitor news effectively.",
                "Unfortunately, the holy grail is still elusive, because the vast majority of TDT solutions proposed for event detection [20, 5, 17, 4, 21, 7, 14, 10] are either too simplistic (based on cosine similarity [5]) or impractical due to the need to tune a large number of parameters [9].",
                "The ineffectiveness of current TDT technologies can be easily illustrated by subscribing to any of the many online news alerts services such as the industryleading Google News Alerts [2], which generates more than 50% false alarms [10].",
                "As further proof, portals like Yahoo take a more pragmatic approach by requiring all machine generated news alerts to go through a human operator for confirmation before sending them out to subscribers.",
                "Instead of attacking the problem with variations of the same hammer (cosine similarity and TFIDF), a fundamental understanding of the characteristics of news stream data is necessary before any major breakthroughs can be made in TDT.",
                "Thus in this paper, we look at news stories and feature trends from the perspective of analyzing a time-series word signal.",
                "Previous work like [9] has attempted to reconstruct an event with its representative features.",
                "However, in many predictive event detection tasks (i.e., retrospective event detection), there is a vast set of potential features only for a fixed set of observations (i.e., the obvious bursts).",
                "Of these features, often only a small number are expected to be useful.",
                "In particular, we study the novel problem of analyzing feature trajectories for event detection, borrowing a well-known technique from signal processing: identifying distributional correlations among all features by spectral analysis.",
                "To evaluate our method, we subsequently propose an unsupervised event detection algorithm for news streams. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Easter April (a) aperiodic event 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Unaudited Ended (b) periodic event Figure 1: Feature correlation (DFIDF:time) between a) Easter and April b) Unaudited and Ended.",
                "As an illustrative example, consider the correlation between the words Easter and April from the Reuters Corpus1 .",
                "From the plot of their normalized DFIDF in Figure 1(a), we observe the heavy overlap between the two words circa 04/1997, which means they probably both belong to the same event during that time (Easter feast).",
                "In this example, the hidden event Easter feast is a typical important aperiodic event over 1-year data.",
                "Another example is given by Figure 1(b), where both the words Unaudited and Ended 1 Reuters Corpus is the default dataset for all examples. exhibit similar behaviour over periods of 3 months.",
                "These two words actually originated from the same periodic event, net income-loss reports, which are released quarterly by publicly listed companies.",
                "Other observations drawn from Figure 1 are: 1) the bursty period of April is much longer than Easter, which suggests that April may exist in other events during the same period; 2) Unaudited has a higher average DFIDF value than Ended, which indicates Unaudited to be more representative for the underlying event.",
                "These two examples are but the tip of the iceberg among all word trends and correlations hidden in a news stream like Reuters.",
                "If a large number of them can be uncovered, it could significantly aid TDT tasks.",
                "In particular, it indicates the significance of mining correlating features for detecting corresponding events.",
                "To summarize, we postulate that: 1) An event is described by its representative features.",
                "A periodic event has a list of periodic features and an aperiodic event has a list of aperiodic features; 2) Representative features from the same event share similar distributions over time and are highly correlated; 3) An important event has a set of active (largely reported) representative features, whereas an unimportant event has a set of inactive (less-reported) representative features; 4) A feature may be included by several events with overlaps in time frames.",
                "Based on these observations, we can either mine representative features given an event or detect an event from a list of highly correlated features.",
                "In this paper, we focus on the latter, i.e., how correlated features can be uncovered to form an event in an unsupervised manner. 1.1 Contributions This paper has three main contributions: • To the best of our knowledge, our approach is the first to categorize word features for heterogenous events.",
                "Specifically, every word feature is categorized into one of the following five feature types based on its power spectrum strength and periodicity: 1) HH (high power and high/long periodicity): important aperiodic events, 2) HL (high power and low periodicity): important periodic events, 3) LH (low power and high periodicity): unimportant aperiodic events, 4) LL (low power and low periodicity): non-events, and 5) SW (stopwords), a higher power and periodicity subset of LL comprising stopwords, which contains no information. • We propose a simple and effective mixture densitybased approach to model and detect feature bursts. • We come up with an unsupervised event detection algorithm to detect both aperiodic and periodic events.",
                "Our algorithm has been evaluated on a real news stream to show its effectiveness. 2.",
                "RELATED WORK This work is largely motivated by a broader family of problems collectively known as Topic Detection and Tracking (TDT) [20, 5, 17, 4, 21, 7, 14, 10].",
                "Moreover, most TDT research so far has been concerned with clustering/classifying documents into topic types, identifying novel sentences [6] for new events, etc., without much regard to analyzing the word trajectory with respect to time.",
                "Swan and Allan [18] first attempted using co-occuring terms to construct an event.",
                "However, they only considered named entities and noun phrase pairs, without considering their periodicities.",
                "On the contrary, our paper considers all of the above.",
                "Recently, there has been significant interest in modeling an event in text streams as a burst of activities by incorporating temporal information.",
                "Kleinbergs seminal work described how bursty features can be extracted from text streams using an infinite automaton model [12], which inspired a whole series of applications such as Kumars identification of bursty communities from Weblog graphs [13], Meis summarization of evolutionary themes in text streams [15], Hes clustering of text streams using bursty features [11], etc.",
                "Nevertheless, none of the existing work specifically identified features for events, except for Fung et al. [9], who clustered busty features to identify various bursty events.",
                "Our work differs from [9] in several ways: 1) we analyze every single feature, not only bursty features; 2) we classify features along two categorical dimensions (periodicity and power), yielding altogether five primary feature types; 3) we do not restrict each feature to exclusively belong to only one event.",
                "Spectral analysis techniques have previously been used by Vlachos et al. [19] to identify periodicities and bursts from query logs.",
                "Their focus was on detecting multiple periodicities from the power spectrum graph, which were then used to index words for query-by-burst search.",
                "In this paper, we use spectral analysis to classify word features along two dimensions, namely periodicity and power spectrum, with the ultimate goal of identifying both periodic and aperiodic bursty events. 3.",
                "DATA REPRESENTATION Let T be the duration/period (in days) of a news stream, and F represents the complete word feature space in the classical static Vector Space Model (VSM). 3.1 Event Periodicity Classification Within T, there may exist certain events that occur only once, e.g., Tony Blair elected as Prime Minister of U.K., and other recurring events of various periodicities, e.g., weekly soccer matches.",
                "We thus categorize all events into two types: aperiodic and periodic, defined as follows.",
                "Definition 1. (Aperiodic Event) An event is aperiodic within T if it only happens once.",
                "Definition 2. (Periodic Event) If events of a certain event genre occur regularly with a fixed periodicity P ≤ T/2 , we say that this particular event genre is periodic, with each member event qualified as a periodic event.",
                "Note that the definition of aperiodic is relative, i.e., it is true only for a given T, and may be invalid for any other T > T. For example, the event Christmas feast is aperiodic for T ≤ 365 but periodic for T ≥ 730. 3.2 Representative Features Intuitively, an event can be described very concisely by a few discriminative and representative word features and vice-versa, e.g., hurricane, sweep, and strike could be representative features of a Hurricane genre event.",
                "Likewise, a set of strongly correlated features could be used to reconstruct an event description, assuming that strongly correlated features are representative.",
                "The representation vector of a word feature is defined as follows: Definition 3. (Feature Trajectory) The trajectory of a word feature f can be written as the sequence yf = [yf (1), yf (2), . . . , yf (T)], where each element yf (t) is a measure of feature f at time t, which could be defined using the normalized DFIDF score2 yf (t) = DFf (t) N(t) × log( N DFf ), where DFf (t) is the number of documents (local DF) containing feature f at day t, DFf is the total number of documents (global DF) containing feature f over T, N(t) is the number of documents for day t, and N is the total number of documents over T. 4.",
                "IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 Spectral Analysis for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. DFT can represent the original time series as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T.",
                "The original trajectory can be reconstructed with just the dominant frequencies, which can be determined from the power spectrum using the popular periodogram estimator.",
                "The periodogram is a sequence of the squared magnitude of the Fourier coefficients, Xk 2 , k = 1, 2, . . . , T/2 , which indicates the signal power at frequency k/T in the spectrum.",
                "From the power spectrum, the dominant period is chosen as the inverse of the frequency with the highest power spectrum, as follows.",
                "Definition 4. (Dominant Period) The dominant period (DP) of a given feature f is Pf = T/ arg max k Xk 2 .",
                "Accordingly, we have Definition 5. (Dominant Power Spectrum) The dominant power spectrum (DPS) of a given feature f is Sf = Xk 2 , with Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorizing Features The DPS of a feature trajectory is a strong indicator of its activeness at the specified frequency; the higher the DPS, the more likely for the feature to be bursty.",
                "Combining DPS with DP, we therefore categorize all features into four types: 2 We normalize yf (t) as yf (t) = yf (t)/ T i=1 yf (i) so that it could be interpreted as a probability. • HH: high Sf , aperiodic or long-term periodic (Pf > T/2 ); • HL: high Sf , short-term periodic (Pf ≤ T/2 ); • LH: low Sf , aperiodic or long-term periodic; • LL: low Sf , short-term periodic.",
                "The boundary between long-term and short-term periodic is set to T/2 .",
                "However, distinguishing between a high and low DPS is not straightforward, which will be tackled later.",
                "Properties of Different Feature Sets To better understand the properties of HH, HL, LH and LL, we select four features, Christmas, soccer, DBS and your as illustrative examples.",
                "Since the boundary between high and low power spectrum is unclear, these chosen examples have relative wide range of power spectrum values.",
                "Figure 2(a) shows the DFIDF trajectory for Christmas with a distinct burst around Christmas day.",
                "For the 1-year Reuters dataset, Christmas is classified as a typical aperiodic event with Pf = 365 and Sf = 135.68, as shown in Figure 2(b).",
                "Clearly, the value of Sf = 135.68 is reasonable for a well-known bursty event like Christmas. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Christmas(DFIDF:time) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Christmas(S:frequency) Figure 2: Feature Christmas with relative high Sf and long-term Pf .",
                "The DFIDF trajectory for soccer is shown in Figure 3(a), from which we can observe that there is a regular burst every 7 days, which is again verified by its computed value of Pf = 7, as shown in Figure 3(b).",
                "Using the domain knowledge that soccer games have more matches every Saturday, which makes it a typical and heavily reported periodic event, we thus consider the value of Sf = 155.13 to be high. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) soccer(DFIDF:time) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) soccer(S:frequency) Figure 3: Feature soccer with relative high Sf and short-term Pf .",
                "From the DFIDF trajectory for DBS in Figure 4(a), we can immediately deduce DBS to be an infrequent word with a trivial burst on 08/17/1997 corresponding to DBS Land Raﬄes Holdings plans.",
                "This is confirmed by the long period of Pf = 365 and low power of Sf = 0.3084 as shown in Figure 4(b).",
                "Moreover, since this aperiodic event is only reported in a few news stories over a very short time of few days, we therefore say that its low power value of Sf = 0.3084 is representative of unimportant events.",
                "The most confusing example is shown in Figure 5 for the word feature your, which looks very similar to the graph for soccer in Figure 3.",
                "At first glance, we may be tempted to group both your and soccer into the same category of HL or LL since both distributions look similar and have the same dominant period of approximately a week.",
                "However, further 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:time) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frequency) Figure 4: Feature DBS with relative low Sf and long-term Pf . analysis indicates that the periodicity of your is due to the differences in document counts for weekdays (average 2,919 per day) and weekends3 (average 479 per day).",
                "One would have expected the periodicity of a stopword like your to be a day.",
                "Moreover, despite our DFIDF normalization, the weekday/weekend imbalance still prevailed; stopwords occur 4 times more frequently on weekends than on weekdays.",
                "Thus, the DPS remains the only distinguishing factor between your (Sf = 9.42) and soccer (Sf = 155.13).",
                "However, it is very dangerous to simply conclude that a power value of S = 9.42 corresponds to a stopword feature. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) your(DFIDF:time) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) your(S:frequency) Figure 5: Feature your as an example confusing with feature soccer.",
                "Before introducing our solution to this problem, lets look at another LL example as shown in Figure 6 for beenb, which is actually a confirmed typo.",
                "We therefore classify beenb as a noisy feature that does not contribute to any event.",
                "Clearly, the trajectory of your is very different from beenb, which means that the former has to be considered separately. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figure 6: Feature beenb with relative low Sf and short-term Pf .",
                "Stop Words (SW) Feature Set Based on the above analysis, we realize that there must be another feature set between HL and LL that corresponds to the set of stopwords.",
                "Features from this set has moderate DPS and low but known dominant period.",
                "Since it is hard to distinguish this feature set from HL and LL only based on DPS, we introduce another factor called average DFIDF (DFIDF).",
                "As shown in Figure 5, features like your usually have a lower DPS than a HL feature like soccer, but have a much higher DFIDF than another LL noisy feature such as beenb.",
                "Since such properties are usually characteristics of stopwords, we group features like your into the newly defined stopword (SW) feature set.",
                "Since setting the DPS and DFIDF thresholds for identifying stopwords is more of an art than science, we proposed a heuristic HS algorithm, Algorithm 1.",
                "The basic idea is to only use news stories from weekdays to identify stopwords. 3 The weekends here also include public holidays falling on weekdays.",
                "The SW set is initially seeded with a small set of 29 popular stopwords utilized by Google search engine.",
                "Algorithm 1 Heuristic Stopwords detection (HS) Input: Seed SW set, weekday trajectories of all words 1: From the seed set SW, compute the maximum DPS as UDPS, maximum DFIDF as UDFIDF, and minimum of DFIDF as LDFIDF. 2: for fi ∈ F do 3: Compute DFT for fi. 4: if Sfi ≤ UDPS and DFIDFfi ∈ [LDFIDF, UDFIDF] then 5: fi → SW 6: F = F − fi 7: end if 8: end for Overview of <br>feature categorization</br> After the SW set is generated, all stopwords are removed from F. We then set the boundary between high and low DPS to be the upper bound of the SW sets DPS.",
                "An overview of all five feature sets is shown in Figure 7.",
                "Figure 7: The 5 feature sets for events. 5.",
                "IDENTIFYING BURSTS FOR FEATURES Since only features from HH, HL and LH are meaningful and could potentially be representative to some events, we pruned all other feature classified as LL or SW.",
                "In this section, we describe how bursts can be identified from the remaining features.",
                "Unlike Kleinbergs burst identification algorithm [12], we can identify both significant and trivial bursts without the need to set any parameters. 5.1 Detecting Aperiodic Features Bursts For each feature in HH and HL, we truncate its trajectory by keeping only the bursty period, which is modeled with a Gaussian distribution.",
                "For example, Figure 8 shows the word feature Iraq with a burst circa 09/06/1996 being modeled as a Gaussian.",
                "Its bursty period is defined by [μf − σf , μf + σf ] as shown in Figure 8(b). 5.2 Detecting Periodic Features Bursts Since we have computed the DP for a periodic feature f, we can easily model its periodic feature trajectory yf using 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) original DFIDF:time 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 burst= [μ-σ, μ+σ] (b) identifying burst Figure 8: Modeling Iraqs time series as a truncated Gaussian with μ = 09/06/1996 and σ = 6.26. a mixture of K = T/Pf Gaussians: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , where the parameter set θf = {αk, μk, σk}K k=1 comprises: • αk is the probability of assigning yf into the kth Gaussian. αk > 0, ∀k ∈ [1, K] and K k=1 αk = 1; • μk/σk is mean/standard deviation of the kth Gaussian.",
                "The well known Expectation Maximization (EM) [8] algorithm is used to compute the mixing proportions αk, as well as the individual Gaussian density parameters μk and σK .",
                "Each Gaussian represents one periodic event, and is modeled similarly as mentioned in Section 5.1. 6.",
                "EVENTS FROM FEATURES After identifying and modeling bursts for all features, the next task is to paint a picture of the event with a potential set of representative features. 6.1 Feature Correlation If two features fi and fj are representative of the same event, they must satisfy the following necessary conditions: 1. fi and fj are identically distributed: yfi ∼ yfj . 2. fi and fj have a high document overlap.",
                "Measuring Feature Distribution Similarity We measure the similarity between two features fi and fj using discrete KL-divergence defined as follows.",
                "Definition 6. (feature similarity) KL(fi, fj ) is given by max(KL(fi|fj ), KL(fj |fi)), where KL(fi|fj ) = T t=1 f(yfi (t)|θfi )log f(yfi (t)|θfi ) f(yfj (t)|θfj ) . (1) Since KL-divergence is not symmetric, we define the similarity between between fi and fj as the maximum of KL(fi|fj ) and KL(fj |fi).",
                "Further, the similarity between two aperiodic features can be computed using a closed form of the KL-divergence [16].",
                "The same discrete KL-divergence formula of Eq. 1 is employed to compute the similarity between two periodic features, Next, we define the overal similarity among a set of features R using the maximum inter-feature KL-Divergence value as follows.",
                "Definition 7. (sets similarity)KL(R) = max ∀fi,fj ∈R KL(fi, fj ).",
                "Document Overlap Let Mi be the set of all documents containing feature fi.",
                "Given two features fi and fj , the overlapping document set containing both features is Mi ∩ Mj .",
                "Intuitively, the higher the |Mi ∩ Mj |, the more likelty that fi and fj will be highly correlated.",
                "We define the degree of document overlap between two features fi and fj as follows.",
                "Definition 8. (Feature DF Overlap) d(fi, fj ) = |Mi∩Mj| min(|Mi|,|Mj|) .",
                "Accordingly, the DF Overlap among a set of features R is also defined.",
                "Definition 9. (Set DF Overlap) d(R) = min ∀fi,fj ∈R d(fi, fj). 6.2 Unsupervised Greedy Event Detection We use features from HH to detect important aperiodic events, features from LH to detect less-reported/unimportant aperiodic events, and features from HL to detect periodic events.",
                "All of them share the same algorithm.",
                "Given bursty feature fi ∈ HH, the goal is to find highly correlated features from HH.",
                "The set of features similar to fi can then collectively describe an event.",
                "Specifically, we need to find a subset Ri of HH that minimizes the following cost function: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) The underlying event e (associated with the burst of fi) can be represented by Ri as y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) The burst analysis for event e is exactly the same as the feature trajectory.",
                "The cost in Eq. 2 can be minimized using our unsupervised greedy UG event detection algorithm, which is described in Algorithm 2.",
                "The UG algorithm allows a feature Algorithm 2 Unsupervised Greedy event detection (UG).",
                "Input: HH, document index for each feature. 1: Sort and select features in descending DPS order: Sf1 ≥ Sf2 ≥ . . . ≥ Sf|HH| . 2: k = 0. 3: for fi ∈ HH do 4: k = k + 1. 5: Init: Ri ← fi, C(Ri) = 1/Sfi and HH = HH − fi. 6: while HH not empty do 7: m = arg min m C(Ri ∪ fm). 8: if C(Ri ∪ fm) < C(Ri) then 9: Ri ← fm and HH = HH − fm. 10: else 11: break while. 12: end if 13: end while 14: Output ek as Eq. 3. 15: end for to be contained in multiple events so that we can detect several events happening at the same time.",
                "Furthermore, trivial events only containing year/month features (i.e., an event only containing 1 feature Aug could be identified over a 1year news stream) could be removed, although such events will have inherent high cost and should already be ranked very low.",
                "Note that our UG algorithm only requires one data-dependant parameter, the boundary between high and low power spectrum, to be set once, and this parameter can be easily estimated using the HS algorithm (Algorithm 1). 7.",
                "EXPERIMENTS In this section, we study the performances of our feature categorizing method and event detection algorithm.",
                "We first introduce the dataset and experimental setup, then we subjectively evaluate the categorization of features for HH, HL, LH, LL and SW.",
                "Finally, we study the (a)periodic event detection problem with Algorithm 2. 7.1 Dataset and Experimental Setup The Reuters Corpus contains 806,791 English news stories from 08/20/1996 to 08/19/1997 at a day resolution.",
                "Version 2 of the open source Lucene software [1] was used to tokenize the news text content and generate the document-word vector.",
                "In order to preserve the time-sensitive past/present/future tenses of verbs and the differences between lower case nouns and upper case named entities, no stemming was done.",
                "Since dynamic stopword removal is one of the functionalities of our method, no stopword was removed.",
                "We did remove nonEnglish characters, however, after which the number of word features amounts to 423,433.",
                "All experiments were implemented in Java and conducted on a 3.2 GHz Pentium 4 PC running Windows 2003 Server with 1 GB of memory. 7.2 Categorizing Features We downloaded 34 well-known stopwords utilized by the Google search engine as our seed training features, which includes a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en and www.",
                "We excluded the last five stopwords as they are uncommon in news stories.",
                "By only analyzing news stories over 259 weekdays, we computed the upper bound of the power spectrum for stopwords at 11.18 and corresponding DFIDF ranges from 0.1182 to 0.3691.",
                "Any feature f satisfying Sf <= 11.18 and 0.1182 <= DFIDFf <= 0.3691 over weekdays will be considered a stopword.",
                "In this manner, 470 stopwords were found and removed as visualized in Figure 9.",
                "Some detected stopwords are A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) and much (P = 22, S = 0.80, DFIDF = 0.1865).",
                "After the removal of these stopwords, the distribution of weekday and weekend news are more or less matched, and in the ensuing experiments, we shall make use of the full corpus (weekdays and weekends).",
                "The upper bound power spectrum value of 11.18 for stopwords training was selected as the boundary between the high power and low power spectrum.",
                "The boundary between high and low periodicity was set to 365/2 = 183.",
                "All 422,963 (423433 − 470) word features were categorized into 4 feature sets: HH (69 features), HL (1,087 features), LH (83,471 features), and LL (338,806 features) as shown in Figure 10.",
                "In Figure 10, each gray level denotes the relative density of features in a square region, measured by log10(1 + Dk), where Dk is the number of features within the k-th square region.",
                "From the figure, we can make the 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figure 9: Distribution of SW (stopwords) in the HH, HL, LH, and LL regions. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figure 10: Distribution of categorized features over the four quadrants (shading in log scale). following observations: 1.",
                "Most features have low S and are easily distinguishable from those features having a much higher S, which allows us to detect important (a)periodic events from trivial events by selecting features with high S. 2.",
                "Features in the HH and LH quadrants are aperiodic, which are nicely separated (big horizontal gap) from the periodic features.",
                "This allows reliably detecting aperiodic events and periodic events independently. 3.",
                "The (vertical) boundary between high and low power spectrum is not as clearcut and the exact value will be application specific.",
                "By checking the scatter distribution of features from SW on HH, HL, LH, and LL as shown in Figure 9, we found that 87.02%(409/470) of the detected stopwords originated from LL.",
                "The LL classification and high DFIDF scores of stopwords agree with the generally accepted notion that stopwords are equally frequent over all time.",
                "Therefore, setting the boundary between high and low power spectrum using the upper bound Sf of SW is a reasonable heuristic. 7.3 Detecting Aperiodic Events We shall evaluate our two hypotheses, 1)important aperiodic events can be defined by a set of HH features, and 2)less reported aperiodic events can be defined by a set of LH features.",
                "Since no benchmark news streams exist for event detection (TDT datasets are not proper streams), we evaluate the quality of the automatically detected events by comparing them to manually-confirmed events by searching through the corpus.",
                "Among the 69 HH features, we detected 17 important aperiodic events as shown in Table 1 (e1 − e17).",
                "Note that the entire identification took less than 1 second, after removing events containing only the month feature.",
                "Among the 17 events, other than the overlaps between e3 and e4 (both describes the same hostage event), e11 and e16 (both about company reports), the 14 identified events are extremely accurate and correspond very well to the major events of the period.",
                "For example, the defeat of Bob Dole, election of Tony Blair, Missile attack on Iraq, etc.",
                "Recall that selecting the features for one event should minimize the cost in Eq. 2 such that 1) the number of features span different events, and 2) not all features relevant to an event will be selected, e.g., the feature Clinton is representative to e12 but since Clinton relates to many other events, its time domain signal is far different from those of other representative features like Dole and Bob.",
                "The number of documents of a detected event is roughly estimated by the number of indexed documents containing the representative features.",
                "We can see that all 17 important aperiodic events are popularly reported events.",
                "After 742 minutes of computation time, we detected 23, 525 less reported aperiodic events from 83,471 LH features.",
                "Table 1 lists the top 5 detected aperiodic events (e18 − e22) with respect to the cost.",
                "We found that these 5 events are actually very trivial events with only a few news reports, and are usually subsumed by some larger topics.",
                "For example, e22 is one of the rescue events in an airplane hijack topic.",
                "One advantage of our UG Algorithm for discovering less-reported aperiodic events is that we are able to precisely detect the true event period. 7.4 Detecting Periodic Events Among the 1,087 HL features, 330 important periodic events were detected within 10 minutes of computing time.",
                "Table 1 lists the top 5 detected periodic events with respect to the cost (e23 − e27).",
                "All of the detected periodic events are indeed valid, and correspond to real life periodic events.",
                "The GMM model is able to detect and estimate the bursty period nicely although it cannot distinguish the slight difference between every Monday-Friday and all weekdays as shown in e23.",
                "We also notice that e26 is actually a subset of e27 (soccer game), which is acceptable since the Sheffield league results are announced independently every weekend. 8.",
                "CONCLUSIONS This paper took a whole new perspective of analyzing feature trajectories as time domain signals.",
                "By considering the word document frequencies in both time and frequency domains, we were able to derive many new characteristics about news streams that were previously unknown, e.g., the different distributions of stopwords during weekdays and weekends.",
                "For the first time in the area of TDT, we applied a systematic approach to automatically detect important and less-reported, periodic and aperiodic events.",
                "The key idea of our work lies in the observations that (a)periodic events have (a)periodic representative features and (un)important events have (in)active representative features, differentiated by their power spectrums and time periods.",
                "To address the real event detection problem, a simple and effective mixture density-based approach was used to identify feature bursts and their associated bursty periods.",
                "We also designed an unsupervised greedy algorithm to detect both aperiodic and periodic events, which was successful in detecting real events as shown in the evaluation on a real news stream.",
                "Although we have not made any benchmark comparison against another approach, simply because there is no previous work in the addressed problem.",
                "Future work includes evaluating the recall of detected events for a labeled news stream, and comparing our model against the closest equivalent methods, which currently are limited to the methods of Kleinberg [12] (which can only detect certain type of bursty events depending on parameter settings), Fung et al. [9], and Swan and Allan [18].",
                "Nevertheless, we believe our simple and effective method will be useful for all TDT practitioners, and will be especially useful for the initial exploratory analysis of news streams. 9.",
                "REFERENCES [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Google news alerts, http://www.google.com/alerts. [3] Reuters corpus, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan.",
                "Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, and H. Jin.",
                "First story detection in tdt is hard.",
                "In CIKM, pages 374-381, 2000. [6] J. Allan, C. Wade, and A. Bolivar.",
                "Retrieval and novelty detection at the sentence level.",
                "In SIGIR, pages 314-321, 2003. [7] T. Brants, F. Chen, and A. Farahat.",
                "A system for new event detection.",
                "In SIGIR, pages 330-337, 2003. [8] A. P. Dempster, N. M. Laird, and D. B. Rubin.",
                "Maximum likelihood from incomplete data via the EM algorithm.",
                "Journal of the Royal Statistical Society, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu, and H. Lu.",
                "Parameter free bursty events detection in text streams.",
                "In VLDB, pages 181-192, 2005. [10] Q.",
                "He, K. Chang, and E.-P. Lim.",
                "A model for anticipatory event detection.",
                "In ER, pages 168-181, 2006. [11] Q.",
                "He, K. Chang, E.-P. Lim, and J. Zhang.",
                "Bursty feature reprensentation for clustering text streams.",
                "In SDM, accepted, 2007. [12] J. Kleinberg.",
                "Bursty and hierarchical structure in streams.",
                "In SIGKDD, pages 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins.",
                "On the bursty evolution of blogspace.",
                "In WWW, pages 159-178, 2005. [14] G. Kumaran and J. Allan.",
                "Text classification and named entities for new event detection.",
                "In SIGIR, pages 297-304, 2004. [15] Q. Mei and C. Zhai.",
                "Discovering evolutionary theme patterns from text: an exploration of temporal text mining.",
                "In SIGKDD, pages 198-207, 2005. [16] W. D. Penny.",
                "Kullback-liebler divergences of normal, gamma, dirichlet and wishart densities.",
                "Technical report, 2001. [17] N. Stokes and J. Carthy.",
                "Combining semantic and syntactic document classifiers to improve first story detection.",
                "In SIGIR, pages 424-425, 2001. [18] R. Swan and J. Allan.",
                "Automatic generation of overview timelines.",
                "In SIGIR, pages 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena, and D. Gunopulos.",
                "Identifying similarities, periodicities and bursts for online search queries.",
                "In SIGMOD, pages 131-142, 2004. [20] Y. Yang, T. Pierce, and J. Carbonell.",
                "A study of retrospective and on-line event detection.",
                "In SIGIR, pages 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topic-conditioned novelty detection.",
                "In SIGKDD, pages 688-693, 2002.",
                "Table 1: All important aperiodic events (e1 − e17), top 5 less-reported aperiodic events (e18 − e22) and top 5 important periodic events (e23 − e27).",
                "Detected Event and Bursty Period Doc # True Event e1(Sali,Berisha,Albania,Albanian,March) 02/02/199705/29/1997 1409 Albanians president Sali Berisha lost in an early election and resigned, 12/1996-07/1997. e2(Seko,Mobutu,Sese,Kabila) 03/22/1997-06/09/1997 2273 Zaires president Mobutu Sese coordinated the native rebellion and failed on 05/16/1997. e3(Marxist,Peruvian) 11/19/1996-03/05/1997 824 Peru rebels (Tupac Amaru revolutionary Movement) led a hostage siege in Lima in early 1997. e4(Movement,Tupac,Amaru,Lima,hostage,hostages) 11/16/1996-03/20/1997 824 The same as e3. e5(Kinshasa,Kabila,Laurent,Congo) 03/26/199706/15/1997 1378 Zaire was renamed the Democratic Republic of Congo on 05/16/1997. e6(Jospin,Lionel,June) 05/10/1997-07/09/1997 605 Following the early General Elections circa 06/1997, Lionel Jospin was appointed Prime Minister on 06/02/1997. e7(Iraq,missile) 08/31/1996-09/13/1996 1262 U.S. fired missile at Iraq on 09/03/1996 and 09/04/1996. e8(Kurdish,Baghdad,Iraqi) 08/29/1996-09/09/1996 1132 Iraqi troop fought with Kurdish faction circa 09/1996. e9(May,Blair) 03/24/1997-07/04/1997 1049 Tony Blair became the Primary Minister of the United Kingdom on 05/02/1997. e10(slalom,skiing) 12/05/1996-03/21/1997 253 Slalom Game of Alpine Skiing in 01/1997-02/1997. e11(Interim,months) 09/24/1996-12/31/1996 3063 Tokyo released company interim results for the past several months in 09/1996-12/1996. e12(Dole,Bob) 09/09/1996-11/24/1996 1599 Dole Bob lost the 1996 US presidential election. e13(July,Sen) 06/25/1997-06/25/1997 344 Cambodias Prime Minister Hun Sen launched a bloody military coup in 07/1997. e14(Hebron) 10/15/1996-02/14/1997 2098 Hebron was divided into two sectors in early 1997. e15(April,Easter) 02/23/1997-05/04/1997 480 Easter feasts circa 04/1997 (for western and Orthodox). e16(Diluted,Group) 04/27/1997-07/20/1997 1888 Tokyo released all 96/97 group results in 04/199707/1997. e17(December,Christmas) 11/17/1996-01/26/1997 1326 Christmas feast in late 12/1997. e18(Kolaceva,winter,Together,promenades,Zajedno, Slobodan,Belgrade,Serbian,Serbia,Draskovic,municipal, Kragujevac) 1/25/1997 3 University students organized a vigil on Kolaceva street against government on 1/25/1997. e19(Tutsi,Luvengi,Burundi,Uvira,fuel,Banyamulenge, Burundian,Kivu,Kiliba,Runingo,Kagunga,Bwegera) 10/19/1996 6 Fresh fighting erupted around Uvira between Zaire armed forces and Banyamulengs Tutsi rebels on 10/19/1996. e20(Malantacchi,Korea,Guy,Rider,Unions,labour, Trade,unions,Confederation,rammed,Geneva,stoppages, Virgin,hire,Myongdong,Metalworkers) 1/11/1997 2 Marcello Malantacchi secretary general of the International Metalworkers Federation and Guy Rider who heads the Geneva office of the International Confederation of Free Trade Unions attacked the new labour law of South Korea on 1/11/1997. e21(DBS,Raﬄes) 8/17/1997 9 The list of the unit of Singapore DBS Land Raﬄes Holdings plans on 8/17/1997. e22(preserver,fuel,Galawa,Huddle,Leul,Beausse) 11/24/1996 3 Rescued a woman and her baby during a hijacked Ethiopian plane that ran out of fuel and crashed into the sea near Le Galawa beach on 11/24/1996. e23(PRICE,LISTING,MLN,MATURITY,COUPON, MOODY,AMT,FIRST,ISS,TYPE,PAY,BORROWER) Monday-Friday/week 7966 Announce bond price on all weekdays. e24(Unaudited,Ended,Months,Weighted,Provision,Cost, Selling,Revenues,Loss,Income,except,Shrs,Revs) every season 2264 Net income-loss reports released by companies in every season. e25(rating,Wall,Street,Ian) Monday-Friday/week 21767 Stock reports from Wall Street on all weekdays. e26(Sheffield,league,scoring,goals,striker,games) every Friday, Saturday and Sunday 574 Match results of Sheffield soccer league were published on Friday, Saturday and Sunday 10 times than other 4 days. e27(soccer,matches,Results,season,game,Cup,match, victory,beat,played,play,division) every Friday, Saturday and Sunday 2396 Soccer games held on Friday, Saturday and Sunday 7 times than other 4 days."
            ],
            "original_annotated_samples": [
                "Algorithm 1 Heuristic Stopwords detection (HS) Input: Seed SW set, weekday trajectories of all words 1: From the seed set SW, compute the maximum DPS as UDPS, maximum DFIDF as UDFIDF, and minimum of DFIDF as LDFIDF. 2: for fi ∈ F do 3: Compute DFT for fi. 4: if Sfi ≤ UDPS and DFIDFfi ∈ [LDFIDF, UDFIDF] then 5: fi → SW 6: F = F − fi 7: end if 8: end for Overview of <br>feature categorization</br> After the SW set is generated, all stopwords are removed from F. We then set the boundary between high and low DPS to be the upper bound of the SW sets DPS."
            ],
            "translated_annotated_samples": [
                "Algoritmo 1 Detección heurística de palabras vacías (HS) Entrada: Conjunto de palabras vacías semilla, trayectorias semanales de todas las palabras 1: A partir del conjunto semilla SW, calcular el DPS máximo como UDPS, el DFIDF máximo como UDFIDF y el mínimo de DFIDF como LDFIDF. 2: para fi ∈ F hacer 3: Calcular DFT para fi. 4: si Sfi ≤ UDPS y DFIDFfi ∈ [LDFIDF, UDFIDF] entonces 5: fi → SW 6: F = F - fi 7: fin si 8: fin para Resumen de la Categorización de Características Después de generar el conjunto SW, se eliminan todas las palabras vacías de F. Luego, establecemos el límite entre DPS alto y bajo como el límite superior de los DPS de los conjuntos SW."
            ],
            "translated_text": "Analizando Trayectorias de Características para la Detección de Eventos Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg Escuela de Ingeniería Informática Universidad Tecnológica de Nanyang Bloque N4, Avenida Nanyang, Singapur 639798 RESUMEN Consideramos el problema de analizar trayectorias de palabras en los dominios del tiempo y la frecuencia, con el objetivo específico de identificar palabras importantes y menos reportadas, periódicas y aperiódicas. Un conjunto de palabras con tendencias idénticas puede agruparse para reconstruir un evento de manera completamente no supervisada. La frecuencia del documento de cada palabra a lo largo del tiempo se trata como una serie temporal, donde cada elemento es el puntaje de frecuencia del documento - frecuencia inversa del documento (DFIDF) en un punto temporal. En este artículo, 1) primero aplicamos análisis espectral para categorizar características de diferentes tipos de eventos: importantes y poco reportados, periódicos y aperiódicos; 2) modelamos las características aperiódicas con densidad gaussiana y las características periódicas con densidades de mezcla gaussiana, y posteriormente detectamos cada ráfaga de características mediante el enfoque gaussiano truncado; 3) propusimos un algoritmo de detección de eventos codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos. Todos los métodos anteriores se pueden aplicar a datos de series temporales en general. Evaluamos exhaustivamente nuestros métodos en el Corpus de Noticias de Reuters de 1 año [3] y demostramos que fueron capaces de descubrir eventos significativos aperiódicos y periódicos. Categorías y Descriptores de Asignaturas: H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales: Algoritmos, Experimentación. 1. INTRODUCCIÓN Hay más de 4,000 fuentes de noticias en línea en el mundo. Supervisar manualmente todos ellos en busca de eventos importantes se ha vuelto difícil o prácticamente imposible. De hecho, la comunidad de detección y seguimiento de temas (TDT) ha estado tratando durante muchos años de encontrar una solución práctica para ayudar a las personas a monitorear las noticias de manera efectiva. Desafortunadamente, el Santo Grial sigue siendo esquivo, ya que la gran mayoría de las soluciones de TDT propuestas para la detección de eventos [20, 5, 17, 4, 21, 7, 14, 10] son demasiado simplistas (basadas en la similitud del coseno [5]) o impracticables debido a la necesidad de ajustar un gran número de parámetros [9]. La ineficacia de las tecnologías actuales de TDT se puede ilustrar fácilmente suscribiéndose a cualquiera de los muchos servicios de alertas de noticias en línea, como el líder de la industria Google News Alerts, que genera más del 50% de falsas alarmas. Como prueba adicional, portales como Yahoo adoptan un enfoque más pragmático al requerir que todas las alertas de noticias generadas por máquinas pasen por un operador humano para su confirmación antes de enviarlas a los suscriptores. En lugar de abordar el problema con variaciones del mismo martillo (similitud coseno y TFIDF), es necesario contar con una comprensión fundamental de las características de los datos de flujo de noticias antes de que se puedan lograr avances importantes en TDT. Por lo tanto, en este artículo, examinamos noticias y tendencias de características desde la perspectiva de analizar una señal de palabras de series temporales. Trabajos anteriores como [9] han intentado reconstruir un evento con sus características representativas. Sin embargo, en muchas tareas de detección de eventos predictivos (es decir, detección de eventos retrospectivos), hay un vasto conjunto de características potenciales solo para un conjunto fijo de observaciones (es decir, los estallidos obvios). De estas características, a menudo solo se espera que un pequeño número sea útil. En particular, estudiamos el novedoso problema de analizar trayectorias de características para la detección de eventos, utilizando una técnica conocida de procesamiento de señales: identificar correlaciones distribucionales entre todas las características mediante análisis espectral. Para evaluar nuestro método, posteriormente proponemos un algoritmo de detección de eventos no supervisado para flujos de noticias. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Pascua Abril (a) evento aperiódico 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 No auditado Finalizado (b) evento periódico Figura 1: Correlación de características (DFIDF:tiempo) entre a) Pascua y Abril b) No auditado y Finalizado. Como ejemplo ilustrativo, considera la correlación entre las palabras Pascua y abril del Corpus de Reuters. A partir del gráfico de su DFIDF normalizado en la Figura 1(a), observamos la gran superposición entre las dos palabras alrededor de 04/1997, lo que significa que probablemente ambas pertenecen al mismo evento durante ese tiempo (festividad de Pascua). En este ejemplo, el evento oculto de la festividad de Pascua es un evento aperiódico típico e importante en datos de 1 año. Otro ejemplo se muestra en la Figura 1(b), donde las palabras \"No auditado\" y \"Finalizado 1\" del Corpus de Reuters son el conjunto de datos predeterminado para todos los ejemplos y presentan un comportamiento similar durante períodos de 3 meses. Estas dos palabras en realidad se originaron a partir del mismo evento periódico, informes de ganancias y pérdidas, que son publicados trimestralmente por empresas cotizadas en bolsa. Otras observaciones extraídas de la Figura 1 son: 1) el período de actividad intensa de abril es mucho más largo que el de Semana Santa, lo que sugiere que abril puede estar presente en otros eventos durante el mismo período; 2) No auditado tiene un valor promedio de DFIDF más alto que Finalizado, lo que indica que No auditado es más representativo para el evento subyacente. Estos dos ejemplos son solo la punta del iceberg entre todas las tendencias de palabras y correlaciones ocultas en un flujo de noticias como Reuters. Si se puede descubrir un gran número de ellos, podría ayudar significativamente en las tareas de TDT. En particular, indica la importancia de extraer características correlacionadas para detectar eventos correspondientes. Para resumir, postulamos que: 1) Un evento se describe por sus características representativas. Un evento periódico tiene una lista de características periódicas y un evento aperiódico tiene una lista de características aperiódicas; 2) Las características representativas del mismo evento comparten distribuciones similares en el tiempo y están altamente correlacionadas; 3) Un evento importante tiene un conjunto de características representativas activas (ampliamente reportadas), mientras que un evento no importante tiene un conjunto de características representativas inactivas (menos reportadas); 4) Una característica puede ser incluida por varios eventos con superposiciones en los marcos de tiempo. Basándonos en estas observaciones, podemos extraer características representativas dadas un evento o detectar un evento a partir de una lista de características altamente correlacionadas. En este artículo, nos enfocamos en este último aspecto, es decir, cómo se pueden descubrir características correlacionadas para formar un evento de manera no supervisada. 1.1 Contribuciones Este artículo tiene tres contribuciones principales: • Hasta donde sabemos, nuestro enfoque es el primero en categorizar características de palabras para eventos heterogéneos. Específicamente, cada característica de palabra se clasifica en uno de los siguientes cinco tipos de características basados en la fuerza de su espectro de potencia y periodicidad: 1) HH (alta potencia y alta/larga periodicidad): eventos aperiódicos importantes, 2) HL (alta potencia y baja periodicidad): eventos periódicos importantes, 3) LH (baja potencia y alta periodicidad): eventos aperiódicos no importantes, 4) LL (baja potencia y baja periodicidad): no eventos, y 5) SW (palabras vacías), un subconjunto de LL con mayor potencia y periodicidad que comprende palabras vacías, que no contienen información. • Proponemos un enfoque simple y efectivo basado en densidad de mezcla para modelar y detectar ráfagas de características. • Presentamos un algoritmo de detección de eventos no supervisado para detectar eventos tanto aperiódicos como periódicos. Nuestro algoritmo ha sido evaluado en un flujo de noticias reales para demostrar su efectividad. 2. TRABAJO RELACIONADO Este trabajo está motivado en gran medida por una familia más amplia de problemas conocidos colectivamente como Detección y Seguimiento de Temas (TDT) [20, 5, 17, 4, 21, 7, 14, 10]. Además, la mayoría de las investigaciones de TDT hasta ahora se han centrado en agrupar/clasificar documentos en tipos de temas, identificar oraciones novedosas para eventos nuevos, etc., sin prestar mucha atención al análisis de la trayectoria de las palabras con respecto al tiempo. Swan y Allan [18] intentaron por primera vez usar términos que co-ocurren para construir un evento. Sin embargo, solo consideraron entidades nombradas y pares de frases nominales, sin tener en cuenta sus periodicidades. Por el contrario, nuestro artículo considera todo lo anterior. Recientemente, ha habido un gran interés en modelar un evento en flujos de texto como un estallido de actividades al incorporar información temporal. El trabajo seminal de Kleinberg describió cómo se pueden extraer características explosivas de flujos de texto utilizando un modelo de autómata infinito [12], lo que inspiró toda una serie de aplicaciones como la identificación de comunidades explosivas de Kumar a partir de gráficos de blogs [13], la sumarización de temas evolutivos en flujos de texto de Meis [15], el agrupamiento de flujos de texto utilizando características explosivas de Hes [11], etc. Sin embargo, ninguno de los trabajos existentes identificó específicamente características para eventos, excepto Fung et al. [9], quienes agruparon características llamativas para identificar varios eventos llamativos. Nuestro trabajo difiere de [9] en varias formas: 1) analizamos cada característica individual, no solo las características explosivas; 2) clasificamos las características a lo largo de dos dimensiones categóricas (periodicidad y potencia), dando en total cinco tipos de características principales; 3) no restringimos que cada característica pertenezca exclusivamente a un solo evento. Las técnicas de análisis espectral han sido utilizadas previamente por Vlachos et al. [19] para identificar periodicidades y ráfagas en los registros de consultas. Su enfoque estaba en detectar múltiples periodicidades a partir del gráfico del espectro de potencia, las cuales luego se utilizaron para indexar palabras para la búsqueda por ráfagas. En este artículo, utilizamos análisis espectral para clasificar las características de las palabras a lo largo de dos dimensiones, a saber, periodicidad y espectro de potencia, con el objetivo final de identificar eventos tanto periódicos como no periódicos y explosivos. 3. REPRESENTACIÓN DE DATOS Sea T la duración/período (en días) de un flujo de noticias, y F representa el espacio de características de palabras completo en el Modelo de Espacio Vectorial (VSM) estático clásico. 3.1 Clasificación de Periodicidad de Eventos Dentro de T, pueden existir ciertos eventos que ocurren solo una vez, por ejemplo, la elección de Tony Blair como Primer Ministro del Reino Unido, y otros eventos recurrentes de diversas periodicidades, por ejemplo, partidos de fútbol semanales. Por lo tanto, categorizamos todos los eventos en dos tipos: aperiódicos y periódicos, definidos de la siguiente manera. Definición 1. (Evento aperiódico) Un evento es aperiódico dentro de T si solo ocurre una vez. Definición 2. (Evento periódico) Si los eventos de un cierto género de eventos ocurren regularmente con una periodicidad fija P ≤ T/2, decimos que este género particular de eventos es periódico, y cada evento miembro se califica como un evento periódico. Ten en cuenta que la definición de aperiódico es relativa, es decir, es verdadera solo para un T dado y puede ser inválida para cualquier otro T > T. Por ejemplo, el evento de la fiesta de Navidad es aperiódico para T ≤ 365 pero periódico para T ≥ 730. 3.2 Características Representativas Intuitivamente, un evento puede ser descrito de manera muy concisa por unas pocas características de palabras discriminativas y representativas y viceversa, por ejemplo, huracán, barrido y golpe podrían ser características representativas de un evento del género de huracanes. Asimismo, un conjunto de características fuertemente correlacionadas podría ser utilizado para reconstruir una descripción de un evento, asumiendo que las características fuertemente correlacionadas son representativas. El vector de representación de una característica de palabra se define de la siguiente manera: Definición 3. (Trayectoria de la Característica) La trayectoria de una característica de palabra f puede escribirse como la secuencia yf = [yf (1), yf (2), . . . , yf (T)], donde cada elemento yf (t) es una medida de la característica f en el tiempo t, que podría definirse utilizando la puntuación normalizada DFIDF yf (t) = DFf (t) N(t) × log( N DFf ), donde DFf (t) es el número de documentos (DF local) que contienen la característica f en el día t, DFf es el número total de documentos (DF global) que contienen la característica f en T, N(t) es el número de documentos para el día t, y N es el número total de documentos en T. 4. En esta sección, mostramos cómo se pueden extraer características representativas para eventos (poco) importantes o (a)periódicos. 4.1 Análisis Espectral para el Período Dominante Dada una característica f, descomponemos su trayectoria de características yf = [yf (1), yf (2), ..., yf (T)] en la secuencia de T números complejos [X1, . . . , XT ] a través de la transformada discreta de Fourier (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. La DFT puede representar la serie temporal original como una combinación lineal de sinusoides complejas, lo cual se ilustra mediante la transformada discreta de Fourier inversa (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, donde el coeficiente de Fourier Xk denota la amplitud del sinusoides con frecuencia k/T. La trayectoria original puede ser reconstruida con solo las frecuencias dominantes, las cuales pueden ser determinadas a partir del espectro de potencia utilizando el popular estimador periodograma. El periodograma es una secuencia de la magnitud al cuadrado de los coeficientes de Fourier, Xk^2, k = 1, 2, . . . , T/2, que indica la potencia de la señal en la frecuencia k/T en el espectro. A partir del espectro de potencia, se elige el período dominante como el inverso de la frecuencia con el espectro de potencia más alto, de la siguiente manera. Definición 4. (Período Dominante) El período dominante (DP) de una característica dada f es Pf = T/ arg max k Xk 2. Por lo tanto, tenemos la Definición 5. (Espectro de Potencia Dominante) El espectro de potencia dominante (DPS) de una característica dada f es Sf = Xk 2 , con Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorización de Características El DPS de una trayectoria de características es un indicador fuerte de su actividad en la frecuencia especificada; cuanto mayor sea el DPS, es más probable que la característica sea explosiva. Al combinar DPS con DP, categorizamos todas las características en cuatro tipos: 2 Normalizamos yf (t) como yf (t) = yf (t)/ T i=1 yf (i) para que pueda interpretarse como una probabilidad. • HH: alta Sf, aperiódico o periódico a largo plazo (Pf > T/2); • HL: alta Sf, periódico a corto plazo (Pf ≤ T/2); • LH: baja Sf, aperiódico o periódico a largo plazo; • LL: baja Sf, periódico a corto plazo. La frontera entre los periodos a largo plazo y a corto plazo se establece en T/2. Sin embargo, distinguir entre un DPS alto y bajo no es sencillo, lo cual se abordará más adelante. Propiedades de diferentes conjuntos de características Para comprender mejor las propiedades de HH, HL, LH y LL, seleccionamos cuatro características, Navidad, fútbol, DBS y tu como ejemplos ilustrativos. Dado que la frontera entre el espectro de alta y baja potencia no está clara, estos ejemplos seleccionados tienen un rango relativo amplio de valores de espectro de potencia. La figura 2(a) muestra la trayectoria de DFIDF para la Navidad con un pico distintivo alrededor del día de Navidad. Para el conjunto de datos de Reuters de 1 año, la Navidad se clasifica como un evento aperiódico típico con Pf = 365 y Sf = 135.68, como se muestra en la Figura 2(b). Claramente, el valor de Sf = 135.68 es razonable para un evento conocido por ser intermitente como la Navidad. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Navidad(DFIDF:tiempo) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Navidad(S:frecuencia) Figura 2: Característica Navidad con un Sf relativamente alto y un Pf a largo plazo. La trayectoria de DFIDF para el fútbol se muestra en la Figura 3(a), de la cual podemos observar que hay un estallido regular cada 7 días, lo cual es nuevamente verificado por su valor calculado de Pf = 7, como se muestra en la Figura 3(b). Usando el conocimiento del dominio de que los partidos de fútbol tienen más encuentros cada sábado, lo que lo convierte en un evento periódico típico y ampliamente reportado, consideramos que el valor de Sf = 155.13 es alto. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) fútbol (DFIDF:tiempo) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) fútbol (S:frecuencia) Figura 3: Característica fútbol con un Sf relativamente alto y un Pf a corto plazo. A partir de la trayectoria de DFIDF para DBS en la Figura 4(a), podemos deducir de inmediato que DBS es una palabra poco frecuente con un aumento trivial el 17/08/1997 correspondiente a los planes de DBS Land Raﬄes Holdings. Esto se confirma por el largo período de Pf = 365 y la baja potencia de Sf = 0.3084 como se muestra en la Figura 4(b). Además, dado que este evento aperiódico solo se informa en algunas noticias durante un corto período de unos pocos días, por lo tanto, decimos que su bajo valor de potencia de Sf = 0.3084 es representativo de eventos poco importantes. El ejemplo más confuso se muestra en la Figura 5 para la palabra \"your\", que se ve muy similar al gráfico para fútbol en la Figura 3. A primera vista, podríamos sentirnos tentados a agrupar tanto tu como el fútbol en la misma categoría de HL o LL, ya que ambas distribuciones se ven similares y tienen el mismo período dominante de aproximadamente una semana. Sin embargo, más adelante 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:tiempo) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frecuencia) Figura 4: Característica DBS con Sf relativamente bajo y Pf a largo plazo. El análisis indica que la periodicidad de su es debido a las diferencias en el recuento de documentos para los días de la semana (promedio de 2,919 por día) y los fines de semana (promedio de 479 por día). Uno habría esperado que la periodicidad de una palabra vacía como \"tu\" fuera de un día. Además, a pesar de nuestra normalización de DFIDF, el desequilibrio entre los días de la semana y los fines de semana aún prevalecía; las palabras vacías ocurren 4 veces más frecuentemente los fines de semana que los días de semana. Por lo tanto, el DPS sigue siendo el único factor distintivo entre tu (Sf = 9.42) y el fútbol (Sf = 155.13). Sin embargo, es muy peligroso concluir simplemente que un valor de potencia de S = 9.42 corresponde a una característica de palabra vacía. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) tu(DFIDF:tiempo) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) tu(S:frecuencia) Figura 5: Característica tu como un ejemplo confundido con la característica fútbol. Antes de presentar nuestra solución a este problema, veamos otro ejemplo de LL como se muestra en la Figura 6 para beenb, que en realidad es un error tipográfico confirmado. Por lo tanto, clasificamos beenb como una característica ruidosa que no contribuye a ningún evento. Claramente, la trayectoria de tu es muy diferente de beenb, lo que significa que el primero debe considerarse por separado. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figura 6: Característica beenb con Sf relativamente bajo y Pf a corto plazo. Conjunto de características de palabras vacías (SW) Basándonos en el análisis anterior, nos damos cuenta de que debe haber otro conjunto de características entre HL y LL que corresponda al conjunto de palabras vacías. Las características de este conjunto tienen un DPS moderado y un período dominante bajo pero conocido. Dado que es difícil distinguir este conjunto de características de HL y LL solo basándose en DPS, introducimos otro factor llamado promedio de DFIDF (DFIDF). Como se muestra en la Figura 5, características como la tuya suelen tener un DPS más bajo que una característica HL como el fútbol, pero tienen un DFIDF mucho más alto que otra característica ruidosa LL como \"beenb\". Dado que tales propiedades suelen ser características de las palabras vacías, agrupamos características como \"tu\" en el conjunto de características de palabras vacías (SW) recién definido. Dado que establecer los umbrales de DPS y DFIDF para identificar las palabras vacías es más un arte que una ciencia, propusimos un algoritmo heurístico HS, Algoritmo 1. La idea básica es utilizar solo noticias de días laborables para identificar palabras vacías. Los fines de semana aquí también incluyen días festivos que caen en días laborables. El conjunto SW se inicialmente alimenta con un pequeño conjunto de 29 stopwords populares utilizadas por el motor de búsqueda de Google. Algoritmo 1 Detección heurística de palabras vacías (HS) Entrada: Conjunto de palabras vacías semilla, trayectorias semanales de todas las palabras 1: A partir del conjunto semilla SW, calcular el DPS máximo como UDPS, el DFIDF máximo como UDFIDF y el mínimo de DFIDF como LDFIDF. 2: para fi ∈ F hacer 3: Calcular DFT para fi. 4: si Sfi ≤ UDPS y DFIDFfi ∈ [LDFIDF, UDFIDF] entonces 5: fi → SW 6: F = F - fi 7: fin si 8: fin para Resumen de la Categorización de Características Después de generar el conjunto SW, se eliminan todas las palabras vacías de F. Luego, establecemos el límite entre DPS alto y bajo como el límite superior de los DPS de los conjuntos SW. Una visión general de los cinco conjuntos de características se muestra en la Figura 7. Figura 7: Los 5 conjuntos de características para eventos. 5. IDENTIFICACIÓN DE RÁFAGAS PARA CARACTERÍSTICAS Dado que solo las características de HH, HL y LH son significativas y podrían ser representativas de algunos eventos, eliminamos todas las demás características clasificadas como LL o SW. En esta sección, describimos cómo se pueden identificar los estallidos a partir de las características restantes. A diferencia del algoritmo de identificación de ráfagas de Kleinberg [12], podemos identificar tanto ráfagas significativas como triviales sin necesidad de establecer ningún parámetro. 5.1 Detección de ráfagas de características aperiódicas Para cada característica en HH y HL, truncamos su trayectoria manteniendo solo el período de ráfagas, el cual está modelado con una distribución gaussiana. Por ejemplo, la Figura 8 muestra la característica de la palabra Iraq con una explosión alrededor del 09/06/1996 modelada como una Gaussiana. Su período de ráfagas está definido por [μf − σf , μf + σf ] como se muestra en la Figura 8(b). 5.2 Detección de características periódicas de ráfagas Dado que hemos calculado el DP para una característica periódica f, podemos modelar fácilmente su trayectoria de características periódicas yf usando 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) DFIDF original: tiempo 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 ráfaga= [μ-σ, μ+σ] (b) identificación de ráfaga Figura 8: Modelando la serie temporal de Iraq como una Gaussiana truncada con μ = 09/06/1996 y σ = 6.26. una mezcla de K = T/Pf Gaussianas: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , donde el conjunto de parámetros θf = {αk, μk, σk}K k=1 comprende: • αk es la probabilidad de asignar yf a la k-ésima Gaussiana. αk > 0, ∀k ∈ [1, K] y K k=1 αk = 1; • μk/σk es la media/desviación estándar de la k-ésima Gaussiana. El conocido algoritmo Expectation Maximization (EM) [8] se utiliza para calcular las proporciones de mezcla αk, así como los parámetros individuales de densidad gaussiana μk y σK. Cada Gaussiana representa un evento periódico, y se modela de manera similar como se menciona en la Sección 5.1. 6. EVENTOS A PARTIR DE CARACTERÍSTICAS Después de identificar y modelar ráfagas para todas las características, la siguiente tarea es pintar un cuadro del evento con un posible conjunto de características representativas. 6.1 Correlación de Características Si dos características fi y fj son representativas del mismo evento, deben cumplir las siguientes condiciones necesarias: 1. fi y fj están distribuidas de manera idéntica: yfi ∼ yfj. 2. fi y fj tienen una alta superposición de documentos. Medición de la similitud de la distribución de características. Medimos la similitud entre dos características fi y fj utilizando la divergencia KL discreta definida de la siguiente manera. Definición 6. (similitud de características) KL(fi, fj) se da por max(KL(fi|fj), KL(fj|fi)), donde KL(fi|fj) = T t=1 f(yfi(t)|θfi)log f(yfi(t)|θfi) f(yfj(t)|θfj). (1) Dado que la divergencia KL no es simétrica, definimos la similitud entre fi y fj como el máximo entre KL(fi|fj) y KL(fj|fi). Además, la similitud entre dos características aperiódicas puede calcularse utilizando una forma cerrada de la divergencia de Kullback-Leibler [16]. La misma fórmula discreta de divergencia KL de la Ecuación 1 se emplea para calcular la similitud entre dos características periódicas. A continuación, definimos la similitud general entre un conjunto de características R utilizando el valor máximo de divergencia KL entre características como sigue. Definición 7. (similitud de conjuntos) KL(R) = max ∀fi, fj ∈R KL(fi, fj). Superposición de documentos: Sea Mi el conjunto de todos los documentos que contienen la característica fi. Dadas dos características fi y fj, el conjunto de documentos superpuestos que contienen ambas características es Mi ∩ Mj. De manera intuitiva, cuanto mayor sea |Mi ∩ Mj|, es más probable que fi y fj estén altamente correlacionados. Definimos el grado de superposición de documentos entre dos características fi y fj de la siguiente manera. Definición 8. (Superposición de características DF) d(fi, fj) = |Mi∩Mj| min(|Mi|, |Mj|). En consecuencia, la superposición de DF entre un conjunto de características R también está definida. Definición 9. (Superposición de Conjuntos DF) d(R) = min ∀fi, fj ∈R d(fi, fj). 6.2 Detección de Eventos Codiciosa No Supervisada Utilizamos características de HH para detectar eventos aperiódicos importantes, características de LH para detectar eventos aperiódicos menos reportados/poco importantes, y características de HL para detectar eventos periódicos. Todos comparten el mismo algoritmo. Dado el rasgo explosivo fi ∈ HH, el objetivo es encontrar rasgos altamente correlacionados de HH. El conjunto de características similares a fi puede describir colectivamente un evento. Específicamente, necesitamos encontrar un subconjunto Ri de HH que minimice la siguiente función de costo: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) El evento subyacente e (asociado con la explosión de fi) puede ser representado por Ri como y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) El análisis de la explosión para el evento e es exactamente el mismo que la trayectoria de características. El costo en la Ecuación 2 se puede minimizar utilizando nuestro algoritmo de detección de eventos UG codicioso no supervisado, que se describe en el Algoritmo 2. El algoritmo UG permite una característica Algoritmo 2 Detección de eventos codiciosos no supervisados (UG). Salida: ek como Ec. 3. Además, los eventos triviales que solo contienen características de año/mes (es decir, un evento que solo contiene una característica de agosto podría ser identificado en un flujo de noticias de 1 año) podrían ser eliminados, aunque dichos eventos tendrán un costo inherente alto y deberían estar clasificados muy bajos. Tenga en cuenta que nuestro algoritmo UG solo requiere un parámetro dependiente de los datos, el límite entre el espectro de alta y baja potencia, que debe establecerse una vez, y este parámetro puede estimarse fácilmente utilizando el algoritmo HS (Algoritmo 1). 7. EXPERIMENTOS En esta sección, estudiamos el rendimiento de nuestro método de categorización de características y algoritmo de detección de eventos. Primero presentamos el conjunto de datos y la configuración experimental, luego evaluamos subjetivamente la categorización de características para HH, HL, LH, LL y SW. Finalmente, estudiamos el problema de detección de eventos (a)periódicos con el Algoritmo 2. 7.1. Conjunto de datos y configuración experimental El Corpus de Reuters contiene 806,791 noticias en inglés desde el 20/08/1996 hasta el 19/08/1997 con una resolución diaria. La versión 2 del software de código abierto Lucene [1] se utilizó para tokenizar el contenido de texto de noticias y generar el vector documento-palabra. Con el fin de preservar los tiempos verbales pasados/presentes/futuros sensibles al tiempo y las diferencias entre los sustantivos en minúscula y las entidades nombradas en mayúscula, no se realizó ningún truncamiento. Dado que la eliminación dinámica de palabras vacías es una de las funcionalidades de nuestro método, no se eliminó ninguna palabra vacía. Eliminamos los caracteres no ingleses, sin embargo, después de eso, el número de características de palabras asciende a 423,433. Todos los experimentos se implementaron en Java y se llevaron a cabo en una PC Pentium 4 de 3.2 GHz con Windows 2003 Server y 1 GB de memoria. 7.2 Categorización de características Descargamos 34 stopwords bien conocidos utilizados por el motor de búsqueda de Google como nuestras características de entrenamiento iniciales, que incluyen a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en y www. Excluimos las últimas cinco palabras vacías ya que son poco comunes en noticias. Al analizar solo historias de noticias durante 259 días laborables, calculamos el límite superior del espectro de potencia para las palabras vacías en 11.18 y los rangos correspondientes de DFIDF van desde 0.1182 hasta 0.3691. Cualquier característica f que cumpla con Sf <= 11.18 y 0.1182 <= DFIDFf <= 0.3691 durante los días de la semana se considerará una palabra vacía. De esta manera, se encontraron y eliminaron 470 palabras vacías como se muestra en la Figura 9. Algunas palabras vacías detectadas son A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) y much (P = 22, S = 0.80, DFIDF = 0.1865). Después de la eliminación de estas palabras vacías, la distribución de las noticias entre semana y los fines de semana están más o menos equilibradas, y en los experimentos subsiguientes, haremos uso del corpus completo (entre semana y fines de semana). El valor del espectro de potencia límite superior de 11.18 para el entrenamiento de palabras vacías fue seleccionado como el límite entre el espectro de alta potencia y baja potencia. El límite entre alta y baja periodicidad se estableció en 365/2 = 183. Todos los 422,963 (423433 − 470) rasgos de palabras fueron categorizados en 4 conjuntos de rasgos: HH (69 rasgos), HL (1,087 rasgos), LH (83,471 rasgos) y LL (338,806 rasgos) como se muestra en la Figura 10. En la Figura 10, cada nivel de gris denota la densidad relativa de características en una región cuadrada, medida por log10(1 + Dk), donde Dk es el número de características dentro de la k-ésima región cuadrada. A partir de la figura, podemos hacer el 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figura 9: Distribución de SW (palabras vacías) en las regiones HH, HL, LH y LL. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figura 10: Distribución de características categorizadas en los cuatro cuadrantes (sombreado en escala logarítmica). siguientes observaciones: 1. La mayoría de las características tienen un valor bajo de S y son fácilmente distinguibles de aquellas características que tienen un valor mucho más alto de S, lo que nos permite detectar eventos importantes (a)periódicos de eventos triviales seleccionando características con un alto valor de S. 2. Las características en los cuadrantes HH y LH son aperiódicas, las cuales están bien separadas (gran brecha horizontal) de las características periódicas. Esto permite detectar de manera confiable eventos aperiódicos y eventos periódicos de forma independiente. 3. La frontera (vertical) entre el espectro de alta y baja potencia no es tan clara y el valor exacto dependerá de la aplicación específica. Al revisar la distribución de dispersión de las características de SW en HH, HL, LH y LL como se muestra en la Figura 9, encontramos que el 87.02% (409/470) de las stopwords detectadas se originaron en LL. La clasificación LL y las altas puntuaciones de DFIDF de las palabras vacías concuerdan con la noción generalmente aceptada de que las palabras vacías son igualmente frecuentes en todo momento. Por lo tanto, establecer el límite entre el espectro de alta y baja potencia utilizando el límite superior Sf de SW es una heurística razonable. 7.3 Detección de Eventos Aperiódicos Evaluaremos nuestras dos hipótesis, 1)los eventos aperiódicos importantes pueden ser definidos por un conjunto de características HH, y 2)los eventos aperiódicos menos reportados pueden ser definidos por un conjunto de características LH. Dado que no existen flujos de noticias de referencia para la detección de eventos (los conjuntos de datos de TDT no son flujos adecuados), evaluamos la calidad de los eventos detectados automáticamente comparándolos con eventos confirmados manualmente mediante la búsqueda en el corpus. Entre las 69 características de HH, detectamos 17 eventos aperiódicos importantes como se muestra en la Tabla 1 (e1 - e17). Ten en cuenta que toda la identificación tomó menos de 1 segundo, después de eliminar los eventos que solo contenían la característica del mes. De los 17 eventos, aparte de las superposiciones entre e3 y e4 (ambos describen el mismo evento de rehenes), e11 y e16 (ambos sobre informes de empresas), los 14 eventos identificados son extremadamente precisos y corresponden muy bien a los principales eventos del período. Por ejemplo, la derrota de Bob Dole, la elección de Tony Blair, el ataque con misiles a Iraq, etc. Recuerde que seleccionar las características para un evento debería minimizar el costo en la Ecuación 2 de tal manera que 1) el número de características abarque diferentes eventos, y 2) no se seleccionarán todas las características relevantes para un evento, por ejemplo, la característica Clinton es representativa para e12, pero dado que Clinton se relaciona con muchos otros eventos, su señal de dominio temporal es muy diferente de la de otras características representativas como Dole y Bob. El número de documentos de un evento detectado se estima aproximadamente por el número de documentos indexados que contienen las características representativas. Podemos ver que los 17 eventos aperiódicos importantes son eventos reportados popularmente. Después de 742 minutos de tiempo de computación, detectamos 23,525 eventos aperiódicos menos reportados de 83,471 características de LH. La Tabla 1 enumera los 5 principales eventos aperiódicos detectados (e18 - e22) con respecto al costo. Descubrimos que estos 5 eventos son en realidad eventos muy triviales con solo unos pocos informes de noticias, y suelen ser englobados por algunos temas más grandes. Por ejemplo, e22 es uno de los eventos de rescate en un tema de secuestro de avión. Una ventaja de nuestro Algoritmo UG para descubrir eventos aperiódicos poco reportados es que podemos detectar con precisión el verdadero período del evento. 7.4 Detección de Eventos Periódicos Entre las 1,087 características de HL, se detectaron 330 eventos periódicos importantes en un tiempo de cálculo de 10 minutos. La Tabla 1 enumera los 5 eventos periódicos detectados con respecto al costo (e23 - e27). Todos los eventos periódicos detectados son realmente válidos y corresponden a eventos periódicos de la vida real. El modelo GMM es capaz de detectar y estimar el período de ráfagas de manera precisa, aunque no puede distinguir la ligera diferencia entre cada lunes a viernes y todos los días de la semana, como se muestra en e23. También observamos que e26 es en realidad un subconjunto de e27 (partido de fútbol), lo cual es aceptable ya que los resultados de la liga de Sheffield se anuncian de forma independiente cada fin de semana. 8. CONCLUSIONES Este artículo adoptó una perspectiva completamente nueva para analizar las trayectorias de características como señales en el dominio del tiempo. Al considerar las frecuencias de los documentos en el dominio del tiempo y de la frecuencia, pudimos derivar muchas nuevas características sobre los flujos de noticias que antes eran desconocidas, por ejemplo, las diferentes distribuciones de palabras vacías durante los días de la semana y los fines de semana. Por primera vez en el área de TDT, aplicamos un enfoque sistemático para detectar automáticamente eventos importantes y menos reportados, periódicos y aperiódicos. La idea clave de nuestro trabajo radica en las observaciones de que los eventos periódicos tienen características representativas periódicas y los eventos (in)importantes tienen características representativas (in)activas, diferenciadas por sus espectros de potencia y períodos de tiempo. Para abordar el problema de detección de eventos reales, se utilizó un enfoque basado en densidad de mezcla simple y efectivo para identificar ráfagas de características y sus períodos asociados de ráfagas. También diseñamos un algoritmo codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos, el cual tuvo éxito en detectar eventos reales como se muestra en la evaluación en un flujo de noticias reales. Aunque no hemos realizado ninguna comparación de referencia con otro enfoque, simplemente porque no hay trabajos previos en el problema abordado. El trabajo futuro incluye evaluar la recuperación de eventos detectados en un flujo de noticias etiquetado, y comparar nuestro modelo con los métodos equivalentes más cercanos, que actualmente se limitan a los métodos de Kleinberg [12] (que solo pueden detectar ciertos tipos de eventos explosivos dependiendo de la configuración de parámetros), Fung et al. [9], y Swan y Allan [18]. Sin embargo, creemos que nuestro método simple y efectivo será útil para todos los practicantes de TDT, y será especialmente útil para el análisis exploratorio inicial de flujos de noticias. REFERENCIAS [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Alertas de noticias de Google, http://www.google.com/alerts. [3] Corpus de Reuters, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan. Detección y seguimiento de temas. Organización de la información basada en eventos. Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, y H. Jin. La detección de la primera historia en tdt es difícil. En CIKM, páginas 374-381, 2000. [6] J. Allan, C. Wade y A. Bolivar. Recuperación y detección de novedades a nivel de oración. En SIGIR, páginas 314-321, 2003. [7] T. Brants, F. Chen y A. Farahat. Un sistema para la detección de nuevos eventos. En SIGIR, páginas 330-337, 2003. [8] A. P. Dempster, N. M. Laird y D. B. Rubin. Máxima verosimilitud a partir de datos incompletos a través del algoritmo EM. Revista de la Real Sociedad Estadística, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu y H. Lu. Detección de eventos explosivos sin parámetros en flujos de texto. En VLDB, páginas 181-192, 2005. [10] Q. Él, K. Chang y E.-P. Lim. Un modelo para la detección anticipada de eventos. En ER, páginas 168-181, 2006. [11] Q. Él, K. Chang, E.-P. Lim y J. Zhang. Representación de características intermitentes para la agrupación de flujos de texto. En SDM, aceptado, 2007. [12] J. Kleinberg. Estructura explosiva y jerárquica en arroyos. En SIGKDD, páginas 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan y A. Tomkins. Sobre la evolución explosiva del blogosfera. En WWW, páginas 159-178, 2005. [14] G. Kumaran y J. Allan. Clasificación de texto y entidades nombradas para la detección de nuevos eventos. En SIGIR, páginas 297-304, 2004. [15] Q. Mei y C. Zhai. Descubriendo patrones temáticos evolutivos a partir de texto: una exploración de la minería de texto temporal. En SIGKDD, páginas 198-207, 2005. [16] W. D. Penny. Divergencias de Kullback-Leibler de densidades normales, gamma, dirichlet y wishart. Informe técnico, 2001. [17] N. Stokes y J. Carthy. Combinando clasificadores de documentos semánticos y sintácticos para mejorar la detección de la primera noticia. En SIGIR, páginas 424-425, 2001. [18] R. Swan y J. Allan. Generación automática de líneas de tiempo de resumen. En SIGIR, páginas 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena y D. Gunopulos. Identificando similitudes, periodicidades y ráfagas en las consultas de búsqueda en línea. En SIGMOD, páginas 131-142, 2004. [20] Y. Yang, T. Pierce y J. Carbonell. Un estudio de detección de eventos retrospectivos y en línea. En SIGIR, páginas 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell y C. Jin. Detección de novedades condicionada por el tema. En SIGKDD, páginas 688-693, 2002. Tabla 1: Todos los eventos aperiódicos importantes (e1 - e17), los 5 eventos aperiódicos menos reportados (e18 - e22) y los 5 eventos periódicos importantes (e23 - e27). Evento detectado y período de actividad intensa Doc # Verdadero evento e1 (Sali, Berisha, Albania, albanés, marzo) 02/02/199705/29/1997 1409 El presidente albanés Sali Berisha perdió en una elección temprana y renunció, 12/1996-07/1997. e2 (Seko, Mobutu, Sese, Kabila) 03/22/1997-06/09/1997 2273 El presidente de Zaire, Mobutu Sese, coordinó la rebelión nativa y fracasó el 16/05/1997. e3 (Marxista, peruano) 11/19/1996-03/05/1997 824 Los rebeldes de Perú (Movimiento Revolucionario Tupac Amaru) lideraron un asedio de rehenes en Lima a principios de 1997. e4 (Movimiento, Tupac, Amaru, Lima, rehén, rehenes) 11/16/1996-03/20/1997 824 Lo mismo que e3. e5 (Kinshasa, Kabila, Laurent, Congo) 03/26/199706/15/1997 1378 Zaire fue renombrado República Democrática del Congo el 16/05/1997. e6 (Jospin, Lionel, junio) 05/10/1997-07/09/1997 605 Tras las elecciones generales tempranas alrededor de 06/1997, Lionel Jospin fue nombrado Primer Ministro el 02/06/1997. e7 (Irak, misil) 08/31/1996-09/13/1996 1262 EE. UU. disparó un misil a Irak el 03/09/1996 y el 04/09/1996. e8 (kurdo, Bagdad, iraquí) 08/29/1996-09/09/1996 1132 Tropas iraquíes lucharon con facciones kurdas alrededor de 09/1996. e9 (mayo, Blair) 03/24/1997-07/04/1997 1049 Tony Blair se convirtió en el Primer Ministro del Reino Unido el 02/05/1997. e10 (slalom, esquí) 12/05/1996-03/21/1997 253 Juego de eslalon de esquí alpino en 01/1997-02/1997. e11 (Interino, meses) 09/24/1996-12/31/1996 3063 Tokio publicó los resultados interinos de la empresa para los últimos meses en 09/1996-12/1996. e12 (Dole, Bob) 09/09/1996-11/24/1996 1599 Bob Dole perdió las elecciones presidenciales de EE. UU. de 1996. e13 (julio, Sen) 06/25/1997-06/25/1997 344 El Primer Ministro de Camboya, Hun Sen, lanzó un sangriento golpe militar en 07/1997. e14 (Hebrón) 10/15/1996-02/14/1997 2098 Hebrón fue dividida en dos sectores a principios de 1997. e15 (abril, Pascua) 02/23/1997-05/04/1997 480 Festividades de Pascua alrededor de 04/1997 (para occidentales y ortodoxos). e16 (Diluido, Grupo) 04/27/1997-07/20/1997 1888 Tokio publicó todos los resultados del grupo 96/97 en 04/199707/1997. e17 (diciembre, Navidad) 11/17/1996-01/26/1997 1326 Festín de Navidad a finales de 12/1997. e18 (Kolaceva, invierno, Juntos, paseos, Zajedno, Slobodan, Belgrado, serbio, Serbia, Draskovic, municipal, Kragujevac) 1/25/1997 3 Estudiantes universitarios organizaron una vigilia en la calle Kolaceva contra el gobierno el 25/01/1997. e19 (Tutsi, Luvengi, Burundi, Uvira, combustible, Banyamulenge, burundés, Kivu, Kiliba, Runingo, Kagunga, Bwegera) 10/19/1996 6 Estallaron nuevos enfrentamientos alrededor de Uvira entre las fuerzas armadas de Zaire y los rebeldes Tutsi de Banyamulenge el 19/10/1996. e20 (Malantacchi, Corea, Guy, Rider, Sindicatos, trabajo, Confederación, embestido, Ginebra, paradas, Virgin, contratar, Myongdong, Metalúrgicos) 1/11/1997 2 Marcello Malantacchi, secretario general de la Federación Internacional de Metalúrgicos, y Guy Rider, quien dirige la oficina de Ginebra de la Confederación Internacional de Sindicatos Libres, atacaron la nueva ley laboral de Corea del Sur el 11/01/1997. e21 (DBS, Raﬄes) 8/17/1997 9 La lista de la unidad de DBS Land Raﬄes Holdings de Singapur planea el 17/08/1997. e22 (conservador, combustible, Galawa, Huddle, Leul, Beausse) 11/24/1996 3 Rescataron a una mujer y a su bebé durante un secuestro de un avión etíope que se quedó sin combustible y se estrelló en el mar cerca de la playa Le Galawa el 24/11/1996. e23 (PRECIO, LISTADO, MLN, VENCIMIENTO, CUPÓN, MOODY, MONTO, PRIMERO, ISS, TIPO, PAGO, PRESTAMISTA) Lunes a viernes/semana 7966 Anuncian el precio de los bonos todos los días de la semana. e24 (No auditado, Terminado, Meses, Ponderado, Provisión, Costo, Venta, Ingresos, Pérdida, Ingreso, excepto, Shrs, Revs) cada temporada 2264 Informes de ingresos netos-pérdidas publicados por empresas en cada temporada. e25 (calificación, Wall Street, Ian) Lunes a viernes/semana 21767 Informes de acciones de Wall Street todos los días de la semana. e26 (Sheffield, liga, goles de puntuación, delantero, juegos) cada viernes, sábado y domingo 574 Resultados de partidos de la liga de fútbol de Sheffield publicados los viernes, sábados y domingos 10 veces más que en los otros 4 días. e27 (fútbol, partidos, Resultados, temporada, juego, Copa, partido, victoria, vencer, jugado, jugar, división) cada viernes, sábado y domingo 2396 Juegos de fútbol celebrados los viernes, sábados y domingos 7 veces más que en los otros 4 días. ",
            "candidates": [],
            "error": [
                []
            ]
        },
        "dft": {
            "translated_key": "DFT",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Analyzing Feature Trajectories for Event Detection Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg School of Computer Engineering Nanyang Technological University Block N4, Nanyang Avenue, Singapore 639798 ABSTRACT We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words.",
                "A set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner.",
                "The document frequency of each word across time is treated like a time series, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point.",
                "In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events.",
                "All of the above methods can be applied to time series data in general.",
                "We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events.",
                "Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Experimentation. 1.",
                "INTRODUCTION There are more than 4,000 online news sources in the world.",
                "Manually monitoring all of them for important events has become difficult or practically impossible.",
                "In fact, the topic detection and tracking (TDT) community has for many years been trying to come up with a practical solution to help people monitor news effectively.",
                "Unfortunately, the holy grail is still elusive, because the vast majority of TDT solutions proposed for event detection [20, 5, 17, 4, 21, 7, 14, 10] are either too simplistic (based on cosine similarity [5]) or impractical due to the need to tune a large number of parameters [9].",
                "The ineffectiveness of current TDT technologies can be easily illustrated by subscribing to any of the many online news alerts services such as the industryleading Google News Alerts [2], which generates more than 50% false alarms [10].",
                "As further proof, portals like Yahoo take a more pragmatic approach by requiring all machine generated news alerts to go through a human operator for confirmation before sending them out to subscribers.",
                "Instead of attacking the problem with variations of the same hammer (cosine similarity and TFIDF), a fundamental understanding of the characteristics of news stream data is necessary before any major breakthroughs can be made in TDT.",
                "Thus in this paper, we look at news stories and feature trends from the perspective of analyzing a time-series word signal.",
                "Previous work like [9] has attempted to reconstruct an event with its representative features.",
                "However, in many predictive event detection tasks (i.e., retrospective event detection), there is a vast set of potential features only for a fixed set of observations (i.e., the obvious bursts).",
                "Of these features, often only a small number are expected to be useful.",
                "In particular, we study the novel problem of analyzing feature trajectories for event detection, borrowing a well-known technique from signal processing: identifying distributional correlations among all features by spectral analysis.",
                "To evaluate our method, we subsequently propose an unsupervised event detection algorithm for news streams. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Easter April (a) aperiodic event 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Unaudited Ended (b) periodic event Figure 1: Feature correlation (DFIDF:time) between a) Easter and April b) Unaudited and Ended.",
                "As an illustrative example, consider the correlation between the words Easter and April from the Reuters Corpus1 .",
                "From the plot of their normalized DFIDF in Figure 1(a), we observe the heavy overlap between the two words circa 04/1997, which means they probably both belong to the same event during that time (Easter feast).",
                "In this example, the hidden event Easter feast is a typical important aperiodic event over 1-year data.",
                "Another example is given by Figure 1(b), where both the words Unaudited and Ended 1 Reuters Corpus is the default dataset for all examples. exhibit similar behaviour over periods of 3 months.",
                "These two words actually originated from the same periodic event, net income-loss reports, which are released quarterly by publicly listed companies.",
                "Other observations drawn from Figure 1 are: 1) the bursty period of April is much longer than Easter, which suggests that April may exist in other events during the same period; 2) Unaudited has a higher average DFIDF value than Ended, which indicates Unaudited to be more representative for the underlying event.",
                "These two examples are but the tip of the iceberg among all word trends and correlations hidden in a news stream like Reuters.",
                "If a large number of them can be uncovered, it could significantly aid TDT tasks.",
                "In particular, it indicates the significance of mining correlating features for detecting corresponding events.",
                "To summarize, we postulate that: 1) An event is described by its representative features.",
                "A periodic event has a list of periodic features and an aperiodic event has a list of aperiodic features; 2) Representative features from the same event share similar distributions over time and are highly correlated; 3) An important event has a set of active (largely reported) representative features, whereas an unimportant event has a set of inactive (less-reported) representative features; 4) A feature may be included by several events with overlaps in time frames.",
                "Based on these observations, we can either mine representative features given an event or detect an event from a list of highly correlated features.",
                "In this paper, we focus on the latter, i.e., how correlated features can be uncovered to form an event in an unsupervised manner. 1.1 Contributions This paper has three main contributions: • To the best of our knowledge, our approach is the first to categorize word features for heterogenous events.",
                "Specifically, every word feature is categorized into one of the following five feature types based on its power spectrum strength and periodicity: 1) HH (high power and high/long periodicity): important aperiodic events, 2) HL (high power and low periodicity): important periodic events, 3) LH (low power and high periodicity): unimportant aperiodic events, 4) LL (low power and low periodicity): non-events, and 5) SW (stopwords), a higher power and periodicity subset of LL comprising stopwords, which contains no information. • We propose a simple and effective mixture densitybased approach to model and detect feature bursts. • We come up with an unsupervised event detection algorithm to detect both aperiodic and periodic events.",
                "Our algorithm has been evaluated on a real news stream to show its effectiveness. 2.",
                "RELATED WORK This work is largely motivated by a broader family of problems collectively known as Topic Detection and Tracking (TDT) [20, 5, 17, 4, 21, 7, 14, 10].",
                "Moreover, most TDT research so far has been concerned with clustering/classifying documents into topic types, identifying novel sentences [6] for new events, etc., without much regard to analyzing the word trajectory with respect to time.",
                "Swan and Allan [18] first attempted using co-occuring terms to construct an event.",
                "However, they only considered named entities and noun phrase pairs, without considering their periodicities.",
                "On the contrary, our paper considers all of the above.",
                "Recently, there has been significant interest in modeling an event in text streams as a burst of activities by incorporating temporal information.",
                "Kleinbergs seminal work described how bursty features can be extracted from text streams using an infinite automaton model [12], which inspired a whole series of applications such as Kumars identification of bursty communities from Weblog graphs [13], Meis summarization of evolutionary themes in text streams [15], Hes clustering of text streams using bursty features [11], etc.",
                "Nevertheless, none of the existing work specifically identified features for events, except for Fung et al. [9], who clustered busty features to identify various bursty events.",
                "Our work differs from [9] in several ways: 1) we analyze every single feature, not only bursty features; 2) we classify features along two categorical dimensions (periodicity and power), yielding altogether five primary feature types; 3) we do not restrict each feature to exclusively belong to only one event.",
                "Spectral analysis techniques have previously been used by Vlachos et al. [19] to identify periodicities and bursts from query logs.",
                "Their focus was on detecting multiple periodicities from the power spectrum graph, which were then used to index words for query-by-burst search.",
                "In this paper, we use spectral analysis to classify word features along two dimensions, namely periodicity and power spectrum, with the ultimate goal of identifying both periodic and aperiodic bursty events. 3.",
                "DATA REPRESENTATION Let T be the duration/period (in days) of a news stream, and F represents the complete word feature space in the classical static Vector Space Model (VSM). 3.1 Event Periodicity Classification Within T, there may exist certain events that occur only once, e.g., Tony Blair elected as Prime Minister of U.K., and other recurring events of various periodicities, e.g., weekly soccer matches.",
                "We thus categorize all events into two types: aperiodic and periodic, defined as follows.",
                "Definition 1. (Aperiodic Event) An event is aperiodic within T if it only happens once.",
                "Definition 2. (Periodic Event) If events of a certain event genre occur regularly with a fixed periodicity P ≤ T/2 , we say that this particular event genre is periodic, with each member event qualified as a periodic event.",
                "Note that the definition of aperiodic is relative, i.e., it is true only for a given T, and may be invalid for any other T > T. For example, the event Christmas feast is aperiodic for T ≤ 365 but periodic for T ≥ 730. 3.2 Representative Features Intuitively, an event can be described very concisely by a few discriminative and representative word features and vice-versa, e.g., hurricane, sweep, and strike could be representative features of a Hurricane genre event.",
                "Likewise, a set of strongly correlated features could be used to reconstruct an event description, assuming that strongly correlated features are representative.",
                "The representation vector of a word feature is defined as follows: Definition 3. (Feature Trajectory) The trajectory of a word feature f can be written as the sequence yf = [yf (1), yf (2), . . . , yf (T)], where each element yf (t) is a measure of feature f at time t, which could be defined using the normalized DFIDF score2 yf (t) = DFf (t) N(t) × log( N DFf ), where DFf (t) is the number of documents (local DF) containing feature f at day t, DFf is the total number of documents (global DF) containing feature f over T, N(t) is the number of documents for day t, and N is the total number of documents over T. 4.",
                "IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 Spectral Analysis for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (<br>dft</br>): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. <br>dft</br> can represent the original time series as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T.",
                "The original trajectory can be reconstructed with just the dominant frequencies, which can be determined from the power spectrum using the popular periodogram estimator.",
                "The periodogram is a sequence of the squared magnitude of the Fourier coefficients, Xk 2 , k = 1, 2, . . . , T/2 , which indicates the signal power at frequency k/T in the spectrum.",
                "From the power spectrum, the dominant period is chosen as the inverse of the frequency with the highest power spectrum, as follows.",
                "Definition 4. (Dominant Period) The dominant period (DP) of a given feature f is Pf = T/ arg max k Xk 2 .",
                "Accordingly, we have Definition 5. (Dominant Power Spectrum) The dominant power spectrum (DPS) of a given feature f is Sf = Xk 2 , with Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorizing Features The DPS of a feature trajectory is a strong indicator of its activeness at the specified frequency; the higher the DPS, the more likely for the feature to be bursty.",
                "Combining DPS with DP, we therefore categorize all features into four types: 2 We normalize yf (t) as yf (t) = yf (t)/ T i=1 yf (i) so that it could be interpreted as a probability. • HH: high Sf , aperiodic or long-term periodic (Pf > T/2 ); • HL: high Sf , short-term periodic (Pf ≤ T/2 ); • LH: low Sf , aperiodic or long-term periodic; • LL: low Sf , short-term periodic.",
                "The boundary between long-term and short-term periodic is set to T/2 .",
                "However, distinguishing between a high and low DPS is not straightforward, which will be tackled later.",
                "Properties of Different Feature Sets To better understand the properties of HH, HL, LH and LL, we select four features, Christmas, soccer, DBS and your as illustrative examples.",
                "Since the boundary between high and low power spectrum is unclear, these chosen examples have relative wide range of power spectrum values.",
                "Figure 2(a) shows the DFIDF trajectory for Christmas with a distinct burst around Christmas day.",
                "For the 1-year Reuters dataset, Christmas is classified as a typical aperiodic event with Pf = 365 and Sf = 135.68, as shown in Figure 2(b).",
                "Clearly, the value of Sf = 135.68 is reasonable for a well-known bursty event like Christmas. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Christmas(DFIDF:time) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Christmas(S:frequency) Figure 2: Feature Christmas with relative high Sf and long-term Pf .",
                "The DFIDF trajectory for soccer is shown in Figure 3(a), from which we can observe that there is a regular burst every 7 days, which is again verified by its computed value of Pf = 7, as shown in Figure 3(b).",
                "Using the domain knowledge that soccer games have more matches every Saturday, which makes it a typical and heavily reported periodic event, we thus consider the value of Sf = 155.13 to be high. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) soccer(DFIDF:time) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) soccer(S:frequency) Figure 3: Feature soccer with relative high Sf and short-term Pf .",
                "From the DFIDF trajectory for DBS in Figure 4(a), we can immediately deduce DBS to be an infrequent word with a trivial burst on 08/17/1997 corresponding to DBS Land Raﬄes Holdings plans.",
                "This is confirmed by the long period of Pf = 365 and low power of Sf = 0.3084 as shown in Figure 4(b).",
                "Moreover, since this aperiodic event is only reported in a few news stories over a very short time of few days, we therefore say that its low power value of Sf = 0.3084 is representative of unimportant events.",
                "The most confusing example is shown in Figure 5 for the word feature your, which looks very similar to the graph for soccer in Figure 3.",
                "At first glance, we may be tempted to group both your and soccer into the same category of HL or LL since both distributions look similar and have the same dominant period of approximately a week.",
                "However, further 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:time) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frequency) Figure 4: Feature DBS with relative low Sf and long-term Pf . analysis indicates that the periodicity of your is due to the differences in document counts for weekdays (average 2,919 per day) and weekends3 (average 479 per day).",
                "One would have expected the periodicity of a stopword like your to be a day.",
                "Moreover, despite our DFIDF normalization, the weekday/weekend imbalance still prevailed; stopwords occur 4 times more frequently on weekends than on weekdays.",
                "Thus, the DPS remains the only distinguishing factor between your (Sf = 9.42) and soccer (Sf = 155.13).",
                "However, it is very dangerous to simply conclude that a power value of S = 9.42 corresponds to a stopword feature. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) your(DFIDF:time) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) your(S:frequency) Figure 5: Feature your as an example confusing with feature soccer.",
                "Before introducing our solution to this problem, lets look at another LL example as shown in Figure 6 for beenb, which is actually a confirmed typo.",
                "We therefore classify beenb as a noisy feature that does not contribute to any event.",
                "Clearly, the trajectory of your is very different from beenb, which means that the former has to be considered separately. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figure 6: Feature beenb with relative low Sf and short-term Pf .",
                "Stop Words (SW) Feature Set Based on the above analysis, we realize that there must be another feature set between HL and LL that corresponds to the set of stopwords.",
                "Features from this set has moderate DPS and low but known dominant period.",
                "Since it is hard to distinguish this feature set from HL and LL only based on DPS, we introduce another factor called average DFIDF (DFIDF).",
                "As shown in Figure 5, features like your usually have a lower DPS than a HL feature like soccer, but have a much higher DFIDF than another LL noisy feature such as beenb.",
                "Since such properties are usually characteristics of stopwords, we group features like your into the newly defined stopword (SW) feature set.",
                "Since setting the DPS and DFIDF thresholds for identifying stopwords is more of an art than science, we proposed a heuristic HS algorithm, Algorithm 1.",
                "The basic idea is to only use news stories from weekdays to identify stopwords. 3 The weekends here also include public holidays falling on weekdays.",
                "The SW set is initially seeded with a small set of 29 popular stopwords utilized by Google search engine.",
                "Algorithm 1 Heuristic Stopwords detection (HS) Input: Seed SW set, weekday trajectories of all words 1: From the seed set SW, compute the maximum DPS as UDPS, maximum DFIDF as UDFIDF, and minimum of DFIDF as LDFIDF. 2: for fi ∈ F do 3: Compute <br>dft</br> for fi. 4: if Sfi ≤ UDPS and DFIDFfi ∈ [LDFIDF, UDFIDF] then 5: fi → SW 6: F = F − fi 7: end if 8: end for Overview of Feature Categorization After the SW set is generated, all stopwords are removed from F. We then set the boundary between high and low DPS to be the upper bound of the SW sets DPS.",
                "An overview of all five feature sets is shown in Figure 7.",
                "Figure 7: The 5 feature sets for events. 5.",
                "IDENTIFYING BURSTS FOR FEATURES Since only features from HH, HL and LH are meaningful and could potentially be representative to some events, we pruned all other feature classified as LL or SW.",
                "In this section, we describe how bursts can be identified from the remaining features.",
                "Unlike Kleinbergs burst identification algorithm [12], we can identify both significant and trivial bursts without the need to set any parameters. 5.1 Detecting Aperiodic Features Bursts For each feature in HH and HL, we truncate its trajectory by keeping only the bursty period, which is modeled with a Gaussian distribution.",
                "For example, Figure 8 shows the word feature Iraq with a burst circa 09/06/1996 being modeled as a Gaussian.",
                "Its bursty period is defined by [μf − σf , μf + σf ] as shown in Figure 8(b). 5.2 Detecting Periodic Features Bursts Since we have computed the DP for a periodic feature f, we can easily model its periodic feature trajectory yf using 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) original DFIDF:time 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 burst= [μ-σ, μ+σ] (b) identifying burst Figure 8: Modeling Iraqs time series as a truncated Gaussian with μ = 09/06/1996 and σ = 6.26. a mixture of K = T/Pf Gaussians: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , where the parameter set θf = {αk, μk, σk}K k=1 comprises: • αk is the probability of assigning yf into the kth Gaussian. αk > 0, ∀k ∈ [1, K] and K k=1 αk = 1; • μk/σk is mean/standard deviation of the kth Gaussian.",
                "The well known Expectation Maximization (EM) [8] algorithm is used to compute the mixing proportions αk, as well as the individual Gaussian density parameters μk and σK .",
                "Each Gaussian represents one periodic event, and is modeled similarly as mentioned in Section 5.1. 6.",
                "EVENTS FROM FEATURES After identifying and modeling bursts for all features, the next task is to paint a picture of the event with a potential set of representative features. 6.1 Feature Correlation If two features fi and fj are representative of the same event, they must satisfy the following necessary conditions: 1. fi and fj are identically distributed: yfi ∼ yfj . 2. fi and fj have a high document overlap.",
                "Measuring Feature Distribution Similarity We measure the similarity between two features fi and fj using discrete KL-divergence defined as follows.",
                "Definition 6. (feature similarity) KL(fi, fj ) is given by max(KL(fi|fj ), KL(fj |fi)), where KL(fi|fj ) = T t=1 f(yfi (t)|θfi )log f(yfi (t)|θfi ) f(yfj (t)|θfj ) . (1) Since KL-divergence is not symmetric, we define the similarity between between fi and fj as the maximum of KL(fi|fj ) and KL(fj |fi).",
                "Further, the similarity between two aperiodic features can be computed using a closed form of the KL-divergence [16].",
                "The same discrete KL-divergence formula of Eq. 1 is employed to compute the similarity between two periodic features, Next, we define the overal similarity among a set of features R using the maximum inter-feature KL-Divergence value as follows.",
                "Definition 7. (sets similarity)KL(R) = max ∀fi,fj ∈R KL(fi, fj ).",
                "Document Overlap Let Mi be the set of all documents containing feature fi.",
                "Given two features fi and fj , the overlapping document set containing both features is Mi ∩ Mj .",
                "Intuitively, the higher the |Mi ∩ Mj |, the more likelty that fi and fj will be highly correlated.",
                "We define the degree of document overlap between two features fi and fj as follows.",
                "Definition 8. (Feature DF Overlap) d(fi, fj ) = |Mi∩Mj| min(|Mi|,|Mj|) .",
                "Accordingly, the DF Overlap among a set of features R is also defined.",
                "Definition 9. (Set DF Overlap) d(R) = min ∀fi,fj ∈R d(fi, fj). 6.2 Unsupervised Greedy Event Detection We use features from HH to detect important aperiodic events, features from LH to detect less-reported/unimportant aperiodic events, and features from HL to detect periodic events.",
                "All of them share the same algorithm.",
                "Given bursty feature fi ∈ HH, the goal is to find highly correlated features from HH.",
                "The set of features similar to fi can then collectively describe an event.",
                "Specifically, we need to find a subset Ri of HH that minimizes the following cost function: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) The underlying event e (associated with the burst of fi) can be represented by Ri as y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) The burst analysis for event e is exactly the same as the feature trajectory.",
                "The cost in Eq. 2 can be minimized using our unsupervised greedy UG event detection algorithm, which is described in Algorithm 2.",
                "The UG algorithm allows a feature Algorithm 2 Unsupervised Greedy event detection (UG).",
                "Input: HH, document index for each feature. 1: Sort and select features in descending DPS order: Sf1 ≥ Sf2 ≥ . . . ≥ Sf|HH| . 2: k = 0. 3: for fi ∈ HH do 4: k = k + 1. 5: Init: Ri ← fi, C(Ri) = 1/Sfi and HH = HH − fi. 6: while HH not empty do 7: m = arg min m C(Ri ∪ fm). 8: if C(Ri ∪ fm) < C(Ri) then 9: Ri ← fm and HH = HH − fm. 10: else 11: break while. 12: end if 13: end while 14: Output ek as Eq. 3. 15: end for to be contained in multiple events so that we can detect several events happening at the same time.",
                "Furthermore, trivial events only containing year/month features (i.e., an event only containing 1 feature Aug could be identified over a 1year news stream) could be removed, although such events will have inherent high cost and should already be ranked very low.",
                "Note that our UG algorithm only requires one data-dependant parameter, the boundary between high and low power spectrum, to be set once, and this parameter can be easily estimated using the HS algorithm (Algorithm 1). 7.",
                "EXPERIMENTS In this section, we study the performances of our feature categorizing method and event detection algorithm.",
                "We first introduce the dataset and experimental setup, then we subjectively evaluate the categorization of features for HH, HL, LH, LL and SW.",
                "Finally, we study the (a)periodic event detection problem with Algorithm 2. 7.1 Dataset and Experimental Setup The Reuters Corpus contains 806,791 English news stories from 08/20/1996 to 08/19/1997 at a day resolution.",
                "Version 2 of the open source Lucene software [1] was used to tokenize the news text content and generate the document-word vector.",
                "In order to preserve the time-sensitive past/present/future tenses of verbs and the differences between lower case nouns and upper case named entities, no stemming was done.",
                "Since dynamic stopword removal is one of the functionalities of our method, no stopword was removed.",
                "We did remove nonEnglish characters, however, after which the number of word features amounts to 423,433.",
                "All experiments were implemented in Java and conducted on a 3.2 GHz Pentium 4 PC running Windows 2003 Server with 1 GB of memory. 7.2 Categorizing Features We downloaded 34 well-known stopwords utilized by the Google search engine as our seed training features, which includes a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en and www.",
                "We excluded the last five stopwords as they are uncommon in news stories.",
                "By only analyzing news stories over 259 weekdays, we computed the upper bound of the power spectrum for stopwords at 11.18 and corresponding DFIDF ranges from 0.1182 to 0.3691.",
                "Any feature f satisfying Sf <= 11.18 and 0.1182 <= DFIDFf <= 0.3691 over weekdays will be considered a stopword.",
                "In this manner, 470 stopwords were found and removed as visualized in Figure 9.",
                "Some detected stopwords are A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) and much (P = 22, S = 0.80, DFIDF = 0.1865).",
                "After the removal of these stopwords, the distribution of weekday and weekend news are more or less matched, and in the ensuing experiments, we shall make use of the full corpus (weekdays and weekends).",
                "The upper bound power spectrum value of 11.18 for stopwords training was selected as the boundary between the high power and low power spectrum.",
                "The boundary between high and low periodicity was set to 365/2 = 183.",
                "All 422,963 (423433 − 470) word features were categorized into 4 feature sets: HH (69 features), HL (1,087 features), LH (83,471 features), and LL (338,806 features) as shown in Figure 10.",
                "In Figure 10, each gray level denotes the relative density of features in a square region, measured by log10(1 + Dk), where Dk is the number of features within the k-th square region.",
                "From the figure, we can make the 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figure 9: Distribution of SW (stopwords) in the HH, HL, LH, and LL regions. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figure 10: Distribution of categorized features over the four quadrants (shading in log scale). following observations: 1.",
                "Most features have low S and are easily distinguishable from those features having a much higher S, which allows us to detect important (a)periodic events from trivial events by selecting features with high S. 2.",
                "Features in the HH and LH quadrants are aperiodic, which are nicely separated (big horizontal gap) from the periodic features.",
                "This allows reliably detecting aperiodic events and periodic events independently. 3.",
                "The (vertical) boundary between high and low power spectrum is not as clearcut and the exact value will be application specific.",
                "By checking the scatter distribution of features from SW on HH, HL, LH, and LL as shown in Figure 9, we found that 87.02%(409/470) of the detected stopwords originated from LL.",
                "The LL classification and high DFIDF scores of stopwords agree with the generally accepted notion that stopwords are equally frequent over all time.",
                "Therefore, setting the boundary between high and low power spectrum using the upper bound Sf of SW is a reasonable heuristic. 7.3 Detecting Aperiodic Events We shall evaluate our two hypotheses, 1)important aperiodic events can be defined by a set of HH features, and 2)less reported aperiodic events can be defined by a set of LH features.",
                "Since no benchmark news streams exist for event detection (TDT datasets are not proper streams), we evaluate the quality of the automatically detected events by comparing them to manually-confirmed events by searching through the corpus.",
                "Among the 69 HH features, we detected 17 important aperiodic events as shown in Table 1 (e1 − e17).",
                "Note that the entire identification took less than 1 second, after removing events containing only the month feature.",
                "Among the 17 events, other than the overlaps between e3 and e4 (both describes the same hostage event), e11 and e16 (both about company reports), the 14 identified events are extremely accurate and correspond very well to the major events of the period.",
                "For example, the defeat of Bob Dole, election of Tony Blair, Missile attack on Iraq, etc.",
                "Recall that selecting the features for one event should minimize the cost in Eq. 2 such that 1) the number of features span different events, and 2) not all features relevant to an event will be selected, e.g., the feature Clinton is representative to e12 but since Clinton relates to many other events, its time domain signal is far different from those of other representative features like Dole and Bob.",
                "The number of documents of a detected event is roughly estimated by the number of indexed documents containing the representative features.",
                "We can see that all 17 important aperiodic events are popularly reported events.",
                "After 742 minutes of computation time, we detected 23, 525 less reported aperiodic events from 83,471 LH features.",
                "Table 1 lists the top 5 detected aperiodic events (e18 − e22) with respect to the cost.",
                "We found that these 5 events are actually very trivial events with only a few news reports, and are usually subsumed by some larger topics.",
                "For example, e22 is one of the rescue events in an airplane hijack topic.",
                "One advantage of our UG Algorithm for discovering less-reported aperiodic events is that we are able to precisely detect the true event period. 7.4 Detecting Periodic Events Among the 1,087 HL features, 330 important periodic events were detected within 10 minutes of computing time.",
                "Table 1 lists the top 5 detected periodic events with respect to the cost (e23 − e27).",
                "All of the detected periodic events are indeed valid, and correspond to real life periodic events.",
                "The GMM model is able to detect and estimate the bursty period nicely although it cannot distinguish the slight difference between every Monday-Friday and all weekdays as shown in e23.",
                "We also notice that e26 is actually a subset of e27 (soccer game), which is acceptable since the Sheffield league results are announced independently every weekend. 8.",
                "CONCLUSIONS This paper took a whole new perspective of analyzing feature trajectories as time domain signals.",
                "By considering the word document frequencies in both time and frequency domains, we were able to derive many new characteristics about news streams that were previously unknown, e.g., the different distributions of stopwords during weekdays and weekends.",
                "For the first time in the area of TDT, we applied a systematic approach to automatically detect important and less-reported, periodic and aperiodic events.",
                "The key idea of our work lies in the observations that (a)periodic events have (a)periodic representative features and (un)important events have (in)active representative features, differentiated by their power spectrums and time periods.",
                "To address the real event detection problem, a simple and effective mixture density-based approach was used to identify feature bursts and their associated bursty periods.",
                "We also designed an unsupervised greedy algorithm to detect both aperiodic and periodic events, which was successful in detecting real events as shown in the evaluation on a real news stream.",
                "Although we have not made any benchmark comparison against another approach, simply because there is no previous work in the addressed problem.",
                "Future work includes evaluating the recall of detected events for a labeled news stream, and comparing our model against the closest equivalent methods, which currently are limited to the methods of Kleinberg [12] (which can only detect certain type of bursty events depending on parameter settings), Fung et al. [9], and Swan and Allan [18].",
                "Nevertheless, we believe our simple and effective method will be useful for all TDT practitioners, and will be especially useful for the initial exploratory analysis of news streams. 9.",
                "REFERENCES [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Google news alerts, http://www.google.com/alerts. [3] Reuters corpus, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan.",
                "Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, and H. Jin.",
                "First story detection in tdt is hard.",
                "In CIKM, pages 374-381, 2000. [6] J. Allan, C. Wade, and A. Bolivar.",
                "Retrieval and novelty detection at the sentence level.",
                "In SIGIR, pages 314-321, 2003. [7] T. Brants, F. Chen, and A. Farahat.",
                "A system for new event detection.",
                "In SIGIR, pages 330-337, 2003. [8] A. P. Dempster, N. M. Laird, and D. B. Rubin.",
                "Maximum likelihood from incomplete data via the EM algorithm.",
                "Journal of the Royal Statistical Society, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu, and H. Lu.",
                "Parameter free bursty events detection in text streams.",
                "In VLDB, pages 181-192, 2005. [10] Q.",
                "He, K. Chang, and E.-P. Lim.",
                "A model for anticipatory event detection.",
                "In ER, pages 168-181, 2006. [11] Q.",
                "He, K. Chang, E.-P. Lim, and J. Zhang.",
                "Bursty feature reprensentation for clustering text streams.",
                "In SDM, accepted, 2007. [12] J. Kleinberg.",
                "Bursty and hierarchical structure in streams.",
                "In SIGKDD, pages 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins.",
                "On the bursty evolution of blogspace.",
                "In WWW, pages 159-178, 2005. [14] G. Kumaran and J. Allan.",
                "Text classification and named entities for new event detection.",
                "In SIGIR, pages 297-304, 2004. [15] Q. Mei and C. Zhai.",
                "Discovering evolutionary theme patterns from text: an exploration of temporal text mining.",
                "In SIGKDD, pages 198-207, 2005. [16] W. D. Penny.",
                "Kullback-liebler divergences of normal, gamma, dirichlet and wishart densities.",
                "Technical report, 2001. [17] N. Stokes and J. Carthy.",
                "Combining semantic and syntactic document classifiers to improve first story detection.",
                "In SIGIR, pages 424-425, 2001. [18] R. Swan and J. Allan.",
                "Automatic generation of overview timelines.",
                "In SIGIR, pages 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena, and D. Gunopulos.",
                "Identifying similarities, periodicities and bursts for online search queries.",
                "In SIGMOD, pages 131-142, 2004. [20] Y. Yang, T. Pierce, and J. Carbonell.",
                "A study of retrospective and on-line event detection.",
                "In SIGIR, pages 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topic-conditioned novelty detection.",
                "In SIGKDD, pages 688-693, 2002.",
                "Table 1: All important aperiodic events (e1 − e17), top 5 less-reported aperiodic events (e18 − e22) and top 5 important periodic events (e23 − e27).",
                "Detected Event and Bursty Period Doc # True Event e1(Sali,Berisha,Albania,Albanian,March) 02/02/199705/29/1997 1409 Albanians president Sali Berisha lost in an early election and resigned, 12/1996-07/1997. e2(Seko,Mobutu,Sese,Kabila) 03/22/1997-06/09/1997 2273 Zaires president Mobutu Sese coordinated the native rebellion and failed on 05/16/1997. e3(Marxist,Peruvian) 11/19/1996-03/05/1997 824 Peru rebels (Tupac Amaru revolutionary Movement) led a hostage siege in Lima in early 1997. e4(Movement,Tupac,Amaru,Lima,hostage,hostages) 11/16/1996-03/20/1997 824 The same as e3. e5(Kinshasa,Kabila,Laurent,Congo) 03/26/199706/15/1997 1378 Zaire was renamed the Democratic Republic of Congo on 05/16/1997. e6(Jospin,Lionel,June) 05/10/1997-07/09/1997 605 Following the early General Elections circa 06/1997, Lionel Jospin was appointed Prime Minister on 06/02/1997. e7(Iraq,missile) 08/31/1996-09/13/1996 1262 U.S. fired missile at Iraq on 09/03/1996 and 09/04/1996. e8(Kurdish,Baghdad,Iraqi) 08/29/1996-09/09/1996 1132 Iraqi troop fought with Kurdish faction circa 09/1996. e9(May,Blair) 03/24/1997-07/04/1997 1049 Tony Blair became the Primary Minister of the United Kingdom on 05/02/1997. e10(slalom,skiing) 12/05/1996-03/21/1997 253 Slalom Game of Alpine Skiing in 01/1997-02/1997. e11(Interim,months) 09/24/1996-12/31/1996 3063 Tokyo released company interim results for the past several months in 09/1996-12/1996. e12(Dole,Bob) 09/09/1996-11/24/1996 1599 Dole Bob lost the 1996 US presidential election. e13(July,Sen) 06/25/1997-06/25/1997 344 Cambodias Prime Minister Hun Sen launched a bloody military coup in 07/1997. e14(Hebron) 10/15/1996-02/14/1997 2098 Hebron was divided into two sectors in early 1997. e15(April,Easter) 02/23/1997-05/04/1997 480 Easter feasts circa 04/1997 (for western and Orthodox). e16(Diluted,Group) 04/27/1997-07/20/1997 1888 Tokyo released all 96/97 group results in 04/199707/1997. e17(December,Christmas) 11/17/1996-01/26/1997 1326 Christmas feast in late 12/1997. e18(Kolaceva,winter,Together,promenades,Zajedno, Slobodan,Belgrade,Serbian,Serbia,Draskovic,municipal, Kragujevac) 1/25/1997 3 University students organized a vigil on Kolaceva street against government on 1/25/1997. e19(Tutsi,Luvengi,Burundi,Uvira,fuel,Banyamulenge, Burundian,Kivu,Kiliba,Runingo,Kagunga,Bwegera) 10/19/1996 6 Fresh fighting erupted around Uvira between Zaire armed forces and Banyamulengs Tutsi rebels on 10/19/1996. e20(Malantacchi,Korea,Guy,Rider,Unions,labour, Trade,unions,Confederation,rammed,Geneva,stoppages, Virgin,hire,Myongdong,Metalworkers) 1/11/1997 2 Marcello Malantacchi secretary general of the International Metalworkers Federation and Guy Rider who heads the Geneva office of the International Confederation of Free Trade Unions attacked the new labour law of South Korea on 1/11/1997. e21(DBS,Raﬄes) 8/17/1997 9 The list of the unit of Singapore DBS Land Raﬄes Holdings plans on 8/17/1997. e22(preserver,fuel,Galawa,Huddle,Leul,Beausse) 11/24/1996 3 Rescued a woman and her baby during a hijacked Ethiopian plane that ran out of fuel and crashed into the sea near Le Galawa beach on 11/24/1996. e23(PRICE,LISTING,MLN,MATURITY,COUPON, MOODY,AMT,FIRST,ISS,TYPE,PAY,BORROWER) Monday-Friday/week 7966 Announce bond price on all weekdays. e24(Unaudited,Ended,Months,Weighted,Provision,Cost, Selling,Revenues,Loss,Income,except,Shrs,Revs) every season 2264 Net income-loss reports released by companies in every season. e25(rating,Wall,Street,Ian) Monday-Friday/week 21767 Stock reports from Wall Street on all weekdays. e26(Sheffield,league,scoring,goals,striker,games) every Friday, Saturday and Sunday 574 Match results of Sheffield soccer league were published on Friday, Saturday and Sunday 10 times than other 4 days. e27(soccer,matches,Results,season,game,Cup,match, victory,beat,played,play,division) every Friday, Saturday and Sunday 2396 Soccer games held on Friday, Saturday and Sunday 7 times than other 4 days."
            ],
            "original_annotated_samples": [
                "IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 Spectral Analysis for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (<br>dft</br>): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. <br>dft</br> can represent the original time series as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T.",
                "Algorithm 1 Heuristic Stopwords detection (HS) Input: Seed SW set, weekday trajectories of all words 1: From the seed set SW, compute the maximum DPS as UDPS, maximum DFIDF as UDFIDF, and minimum of DFIDF as LDFIDF. 2: for fi ∈ F do 3: Compute <br>dft</br> for fi. 4: if Sfi ≤ UDPS and DFIDFfi ∈ [LDFIDF, UDFIDF] then 5: fi → SW 6: F = F − fi 7: end if 8: end for Overview of Feature Categorization After the SW set is generated, all stopwords are removed from F. We then set the boundary between high and low DPS to be the upper bound of the SW sets DPS."
            ],
            "translated_annotated_samples": [
                "En esta sección, mostramos cómo se pueden extraer características representativas para eventos (poco) importantes o (a)periódicos. 4.1 Análisis Espectral para el Período Dominante Dada una característica f, descomponemos su trayectoria de características yf = [yf (1), yf (2), ..., yf (T)] en la secuencia de T números complejos [X1, . . . , XT ] a través de la transformada discreta de Fourier (<br>DFT</br>): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. La <br>DFT</br> puede representar la serie temporal original como una combinación lineal de sinusoides complejas, lo cual se ilustra mediante la transformada discreta de Fourier inversa (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, donde el coeficiente de Fourier Xk denota la amplitud del sinusoides con frecuencia k/T.",
                "Algoritmo 1 Detección heurística de palabras vacías (HS) Entrada: Conjunto de palabras vacías semilla, trayectorias semanales de todas las palabras 1: A partir del conjunto semilla SW, calcular el DPS máximo como UDPS, el DFIDF máximo como UDFIDF y el mínimo de DFIDF como LDFIDF. 2: para fi ∈ F hacer 3: Calcular DFT para fi. 4: si Sfi ≤ UDPS y DFIDFfi ∈ [LDFIDF, UDFIDF] entonces 5: fi → SW 6: F = F - fi 7: fin si 8: fin para Resumen de la Categorización de Características Después de generar el conjunto SW, se eliminan todas las palabras vacías de F. Luego, establecemos el límite entre DPS alto y bajo como el límite superior de los DPS de los conjuntos SW."
            ],
            "translated_text": "Analizando Trayectorias de Características para la Detección de Eventos Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg Escuela de Ingeniería Informática Universidad Tecnológica de Nanyang Bloque N4, Avenida Nanyang, Singapur 639798 RESUMEN Consideramos el problema de analizar trayectorias de palabras en los dominios del tiempo y la frecuencia, con el objetivo específico de identificar palabras importantes y menos reportadas, periódicas y aperiódicas. Un conjunto de palabras con tendencias idénticas puede agruparse para reconstruir un evento de manera completamente no supervisada. La frecuencia del documento de cada palabra a lo largo del tiempo se trata como una serie temporal, donde cada elemento es el puntaje de frecuencia del documento - frecuencia inversa del documento (DFIDF) en un punto temporal. En este artículo, 1) primero aplicamos análisis espectral para categorizar características de diferentes tipos de eventos: importantes y poco reportados, periódicos y aperiódicos; 2) modelamos las características aperiódicas con densidad gaussiana y las características periódicas con densidades de mezcla gaussiana, y posteriormente detectamos cada ráfaga de características mediante el enfoque gaussiano truncado; 3) propusimos un algoritmo de detección de eventos codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos. Todos los métodos anteriores se pueden aplicar a datos de series temporales en general. Evaluamos exhaustivamente nuestros métodos en el Corpus de Noticias de Reuters de 1 año [3] y demostramos que fueron capaces de descubrir eventos significativos aperiódicos y periódicos. Categorías y Descriptores de Asignaturas: H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales: Algoritmos, Experimentación. 1. INTRODUCCIÓN Hay más de 4,000 fuentes de noticias en línea en el mundo. Supervisar manualmente todos ellos en busca de eventos importantes se ha vuelto difícil o prácticamente imposible. De hecho, la comunidad de detección y seguimiento de temas (TDT) ha estado tratando durante muchos años de encontrar una solución práctica para ayudar a las personas a monitorear las noticias de manera efectiva. Desafortunadamente, el Santo Grial sigue siendo esquivo, ya que la gran mayoría de las soluciones de TDT propuestas para la detección de eventos [20, 5, 17, 4, 21, 7, 14, 10] son demasiado simplistas (basadas en la similitud del coseno [5]) o impracticables debido a la necesidad de ajustar un gran número de parámetros [9]. La ineficacia de las tecnologías actuales de TDT se puede ilustrar fácilmente suscribiéndose a cualquiera de los muchos servicios de alertas de noticias en línea, como el líder de la industria Google News Alerts, que genera más del 50% de falsas alarmas. Como prueba adicional, portales como Yahoo adoptan un enfoque más pragmático al requerir que todas las alertas de noticias generadas por máquinas pasen por un operador humano para su confirmación antes de enviarlas a los suscriptores. En lugar de abordar el problema con variaciones del mismo martillo (similitud coseno y TFIDF), es necesario contar con una comprensión fundamental de las características de los datos de flujo de noticias antes de que se puedan lograr avances importantes en TDT. Por lo tanto, en este artículo, examinamos noticias y tendencias de características desde la perspectiva de analizar una señal de palabras de series temporales. Trabajos anteriores como [9] han intentado reconstruir un evento con sus características representativas. Sin embargo, en muchas tareas de detección de eventos predictivos (es decir, detección de eventos retrospectivos), hay un vasto conjunto de características potenciales solo para un conjunto fijo de observaciones (es decir, los estallidos obvios). De estas características, a menudo solo se espera que un pequeño número sea útil. En particular, estudiamos el novedoso problema de analizar trayectorias de características para la detección de eventos, utilizando una técnica conocida de procesamiento de señales: identificar correlaciones distribucionales entre todas las características mediante análisis espectral. Para evaluar nuestro método, posteriormente proponemos un algoritmo de detección de eventos no supervisado para flujos de noticias. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Pascua Abril (a) evento aperiódico 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 No auditado Finalizado (b) evento periódico Figura 1: Correlación de características (DFIDF:tiempo) entre a) Pascua y Abril b) No auditado y Finalizado. Como ejemplo ilustrativo, considera la correlación entre las palabras Pascua y abril del Corpus de Reuters. A partir del gráfico de su DFIDF normalizado en la Figura 1(a), observamos la gran superposición entre las dos palabras alrededor de 04/1997, lo que significa que probablemente ambas pertenecen al mismo evento durante ese tiempo (festividad de Pascua). En este ejemplo, el evento oculto de la festividad de Pascua es un evento aperiódico típico e importante en datos de 1 año. Otro ejemplo se muestra en la Figura 1(b), donde las palabras \"No auditado\" y \"Finalizado 1\" del Corpus de Reuters son el conjunto de datos predeterminado para todos los ejemplos y presentan un comportamiento similar durante períodos de 3 meses. Estas dos palabras en realidad se originaron a partir del mismo evento periódico, informes de ganancias y pérdidas, que son publicados trimestralmente por empresas cotizadas en bolsa. Otras observaciones extraídas de la Figura 1 son: 1) el período de actividad intensa de abril es mucho más largo que el de Semana Santa, lo que sugiere que abril puede estar presente en otros eventos durante el mismo período; 2) No auditado tiene un valor promedio de DFIDF más alto que Finalizado, lo que indica que No auditado es más representativo para el evento subyacente. Estos dos ejemplos son solo la punta del iceberg entre todas las tendencias de palabras y correlaciones ocultas en un flujo de noticias como Reuters. Si se puede descubrir un gran número de ellos, podría ayudar significativamente en las tareas de TDT. En particular, indica la importancia de extraer características correlacionadas para detectar eventos correspondientes. Para resumir, postulamos que: 1) Un evento se describe por sus características representativas. Un evento periódico tiene una lista de características periódicas y un evento aperiódico tiene una lista de características aperiódicas; 2) Las características representativas del mismo evento comparten distribuciones similares en el tiempo y están altamente correlacionadas; 3) Un evento importante tiene un conjunto de características representativas activas (ampliamente reportadas), mientras que un evento no importante tiene un conjunto de características representativas inactivas (menos reportadas); 4) Una característica puede ser incluida por varios eventos con superposiciones en los marcos de tiempo. Basándonos en estas observaciones, podemos extraer características representativas dadas un evento o detectar un evento a partir de una lista de características altamente correlacionadas. En este artículo, nos enfocamos en este último aspecto, es decir, cómo se pueden descubrir características correlacionadas para formar un evento de manera no supervisada. 1.1 Contribuciones Este artículo tiene tres contribuciones principales: • Hasta donde sabemos, nuestro enfoque es el primero en categorizar características de palabras para eventos heterogéneos. Específicamente, cada característica de palabra se clasifica en uno de los siguientes cinco tipos de características basados en la fuerza de su espectro de potencia y periodicidad: 1) HH (alta potencia y alta/larga periodicidad): eventos aperiódicos importantes, 2) HL (alta potencia y baja periodicidad): eventos periódicos importantes, 3) LH (baja potencia y alta periodicidad): eventos aperiódicos no importantes, 4) LL (baja potencia y baja periodicidad): no eventos, y 5) SW (palabras vacías), un subconjunto de LL con mayor potencia y periodicidad que comprende palabras vacías, que no contienen información. • Proponemos un enfoque simple y efectivo basado en densidad de mezcla para modelar y detectar ráfagas de características. • Presentamos un algoritmo de detección de eventos no supervisado para detectar eventos tanto aperiódicos como periódicos. Nuestro algoritmo ha sido evaluado en un flujo de noticias reales para demostrar su efectividad. 2. TRABAJO RELACIONADO Este trabajo está motivado en gran medida por una familia más amplia de problemas conocidos colectivamente como Detección y Seguimiento de Temas (TDT) [20, 5, 17, 4, 21, 7, 14, 10]. Además, la mayoría de las investigaciones de TDT hasta ahora se han centrado en agrupar/clasificar documentos en tipos de temas, identificar oraciones novedosas para eventos nuevos, etc., sin prestar mucha atención al análisis de la trayectoria de las palabras con respecto al tiempo. Swan y Allan [18] intentaron por primera vez usar términos que co-ocurren para construir un evento. Sin embargo, solo consideraron entidades nombradas y pares de frases nominales, sin tener en cuenta sus periodicidades. Por el contrario, nuestro artículo considera todo lo anterior. Recientemente, ha habido un gran interés en modelar un evento en flujos de texto como un estallido de actividades al incorporar información temporal. El trabajo seminal de Kleinberg describió cómo se pueden extraer características explosivas de flujos de texto utilizando un modelo de autómata infinito [12], lo que inspiró toda una serie de aplicaciones como la identificación de comunidades explosivas de Kumar a partir de gráficos de blogs [13], la sumarización de temas evolutivos en flujos de texto de Meis [15], el agrupamiento de flujos de texto utilizando características explosivas de Hes [11], etc. Sin embargo, ninguno de los trabajos existentes identificó específicamente características para eventos, excepto Fung et al. [9], quienes agruparon características llamativas para identificar varios eventos llamativos. Nuestro trabajo difiere de [9] en varias formas: 1) analizamos cada característica individual, no solo las características explosivas; 2) clasificamos las características a lo largo de dos dimensiones categóricas (periodicidad y potencia), dando en total cinco tipos de características principales; 3) no restringimos que cada característica pertenezca exclusivamente a un solo evento. Las técnicas de análisis espectral han sido utilizadas previamente por Vlachos et al. [19] para identificar periodicidades y ráfagas en los registros de consultas. Su enfoque estaba en detectar múltiples periodicidades a partir del gráfico del espectro de potencia, las cuales luego se utilizaron para indexar palabras para la búsqueda por ráfagas. En este artículo, utilizamos análisis espectral para clasificar las características de las palabras a lo largo de dos dimensiones, a saber, periodicidad y espectro de potencia, con el objetivo final de identificar eventos tanto periódicos como no periódicos y explosivos. 3. REPRESENTACIÓN DE DATOS Sea T la duración/período (en días) de un flujo de noticias, y F representa el espacio de características de palabras completo en el Modelo de Espacio Vectorial (VSM) estático clásico. 3.1 Clasificación de Periodicidad de Eventos Dentro de T, pueden existir ciertos eventos que ocurren solo una vez, por ejemplo, la elección de Tony Blair como Primer Ministro del Reino Unido, y otros eventos recurrentes de diversas periodicidades, por ejemplo, partidos de fútbol semanales. Por lo tanto, categorizamos todos los eventos en dos tipos: aperiódicos y periódicos, definidos de la siguiente manera. Definición 1. (Evento aperiódico) Un evento es aperiódico dentro de T si solo ocurre una vez. Definición 2. (Evento periódico) Si los eventos de un cierto género de eventos ocurren regularmente con una periodicidad fija P ≤ T/2, decimos que este género particular de eventos es periódico, y cada evento miembro se califica como un evento periódico. Ten en cuenta que la definición de aperiódico es relativa, es decir, es verdadera solo para un T dado y puede ser inválida para cualquier otro T > T. Por ejemplo, el evento de la fiesta de Navidad es aperiódico para T ≤ 365 pero periódico para T ≥ 730. 3.2 Características Representativas Intuitivamente, un evento puede ser descrito de manera muy concisa por unas pocas características de palabras discriminativas y representativas y viceversa, por ejemplo, huracán, barrido y golpe podrían ser características representativas de un evento del género de huracanes. Asimismo, un conjunto de características fuertemente correlacionadas podría ser utilizado para reconstruir una descripción de un evento, asumiendo que las características fuertemente correlacionadas son representativas. El vector de representación de una característica de palabra se define de la siguiente manera: Definición 3. (Trayectoria de la Característica) La trayectoria de una característica de palabra f puede escribirse como la secuencia yf = [yf (1), yf (2), . . . , yf (T)], donde cada elemento yf (t) es una medida de la característica f en el tiempo t, que podría definirse utilizando la puntuación normalizada DFIDF yf (t) = DFf (t) N(t) × log( N DFf ), donde DFf (t) es el número de documentos (DF local) que contienen la característica f en el día t, DFf es el número total de documentos (DF global) que contienen la característica f en T, N(t) es el número de documentos para el día t, y N es el número total de documentos en T. 4. En esta sección, mostramos cómo se pueden extraer características representativas para eventos (poco) importantes o (a)periódicos. 4.1 Análisis Espectral para el Período Dominante Dada una característica f, descomponemos su trayectoria de características yf = [yf (1), yf (2), ..., yf (T)] en la secuencia de T números complejos [X1, . . . , XT ] a través de la transformada discreta de Fourier (<br>DFT</br>): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. La <br>DFT</br> puede representar la serie temporal original como una combinación lineal de sinusoides complejas, lo cual se ilustra mediante la transformada discreta de Fourier inversa (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, donde el coeficiente de Fourier Xk denota la amplitud del sinusoides con frecuencia k/T. La trayectoria original puede ser reconstruida con solo las frecuencias dominantes, las cuales pueden ser determinadas a partir del espectro de potencia utilizando el popular estimador periodograma. El periodograma es una secuencia de la magnitud al cuadrado de los coeficientes de Fourier, Xk^2, k = 1, 2, . . . , T/2, que indica la potencia de la señal en la frecuencia k/T en el espectro. A partir del espectro de potencia, se elige el período dominante como el inverso de la frecuencia con el espectro de potencia más alto, de la siguiente manera. Definición 4. (Período Dominante) El período dominante (DP) de una característica dada f es Pf = T/ arg max k Xk 2. Por lo tanto, tenemos la Definición 5. (Espectro de Potencia Dominante) El espectro de potencia dominante (DPS) de una característica dada f es Sf = Xk 2 , con Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorización de Características El DPS de una trayectoria de características es un indicador fuerte de su actividad en la frecuencia especificada; cuanto mayor sea el DPS, es más probable que la característica sea explosiva. Al combinar DPS con DP, categorizamos todas las características en cuatro tipos: 2 Normalizamos yf (t) como yf (t) = yf (t)/ T i=1 yf (i) para que pueda interpretarse como una probabilidad. • HH: alta Sf, aperiódico o periódico a largo plazo (Pf > T/2); • HL: alta Sf, periódico a corto plazo (Pf ≤ T/2); • LH: baja Sf, aperiódico o periódico a largo plazo; • LL: baja Sf, periódico a corto plazo. La frontera entre los periodos a largo plazo y a corto plazo se establece en T/2. Sin embargo, distinguir entre un DPS alto y bajo no es sencillo, lo cual se abordará más adelante. Propiedades de diferentes conjuntos de características Para comprender mejor las propiedades de HH, HL, LH y LL, seleccionamos cuatro características, Navidad, fútbol, DBS y tu como ejemplos ilustrativos. Dado que la frontera entre el espectro de alta y baja potencia no está clara, estos ejemplos seleccionados tienen un rango relativo amplio de valores de espectro de potencia. La figura 2(a) muestra la trayectoria de DFIDF para la Navidad con un pico distintivo alrededor del día de Navidad. Para el conjunto de datos de Reuters de 1 año, la Navidad se clasifica como un evento aperiódico típico con Pf = 365 y Sf = 135.68, como se muestra en la Figura 2(b). Claramente, el valor de Sf = 135.68 es razonable para un evento conocido por ser intermitente como la Navidad. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Navidad(DFIDF:tiempo) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Navidad(S:frecuencia) Figura 2: Característica Navidad con un Sf relativamente alto y un Pf a largo plazo. La trayectoria de DFIDF para el fútbol se muestra en la Figura 3(a), de la cual podemos observar que hay un estallido regular cada 7 días, lo cual es nuevamente verificado por su valor calculado de Pf = 7, como se muestra en la Figura 3(b). Usando el conocimiento del dominio de que los partidos de fútbol tienen más encuentros cada sábado, lo que lo convierte en un evento periódico típico y ampliamente reportado, consideramos que el valor de Sf = 155.13 es alto. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) fútbol (DFIDF:tiempo) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) fútbol (S:frecuencia) Figura 3: Característica fútbol con un Sf relativamente alto y un Pf a corto plazo. A partir de la trayectoria de DFIDF para DBS en la Figura 4(a), podemos deducir de inmediato que DBS es una palabra poco frecuente con un aumento trivial el 17/08/1997 correspondiente a los planes de DBS Land Raﬄes Holdings. Esto se confirma por el largo período de Pf = 365 y la baja potencia de Sf = 0.3084 como se muestra en la Figura 4(b). Además, dado que este evento aperiódico solo se informa en algunas noticias durante un corto período de unos pocos días, por lo tanto, decimos que su bajo valor de potencia de Sf = 0.3084 es representativo de eventos poco importantes. El ejemplo más confuso se muestra en la Figura 5 para la palabra \"your\", que se ve muy similar al gráfico para fútbol en la Figura 3. A primera vista, podríamos sentirnos tentados a agrupar tanto tu como el fútbol en la misma categoría de HL o LL, ya que ambas distribuciones se ven similares y tienen el mismo período dominante de aproximadamente una semana. Sin embargo, más adelante 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:tiempo) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frecuencia) Figura 4: Característica DBS con Sf relativamente bajo y Pf a largo plazo. El análisis indica que la periodicidad de su es debido a las diferencias en el recuento de documentos para los días de la semana (promedio de 2,919 por día) y los fines de semana (promedio de 479 por día). Uno habría esperado que la periodicidad de una palabra vacía como \"tu\" fuera de un día. Además, a pesar de nuestra normalización de DFIDF, el desequilibrio entre los días de la semana y los fines de semana aún prevalecía; las palabras vacías ocurren 4 veces más frecuentemente los fines de semana que los días de semana. Por lo tanto, el DPS sigue siendo el único factor distintivo entre tu (Sf = 9.42) y el fútbol (Sf = 155.13). Sin embargo, es muy peligroso concluir simplemente que un valor de potencia de S = 9.42 corresponde a una característica de palabra vacía. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) tu(DFIDF:tiempo) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) tu(S:frecuencia) Figura 5: Característica tu como un ejemplo confundido con la característica fútbol. Antes de presentar nuestra solución a este problema, veamos otro ejemplo de LL como se muestra en la Figura 6 para beenb, que en realidad es un error tipográfico confirmado. Por lo tanto, clasificamos beenb como una característica ruidosa que no contribuye a ningún evento. Claramente, la trayectoria de tu es muy diferente de beenb, lo que significa que el primero debe considerarse por separado. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figura 6: Característica beenb con Sf relativamente bajo y Pf a corto plazo. Conjunto de características de palabras vacías (SW) Basándonos en el análisis anterior, nos damos cuenta de que debe haber otro conjunto de características entre HL y LL que corresponda al conjunto de palabras vacías. Las características de este conjunto tienen un DPS moderado y un período dominante bajo pero conocido. Dado que es difícil distinguir este conjunto de características de HL y LL solo basándose en DPS, introducimos otro factor llamado promedio de DFIDF (DFIDF). Como se muestra en la Figura 5, características como la tuya suelen tener un DPS más bajo que una característica HL como el fútbol, pero tienen un DFIDF mucho más alto que otra característica ruidosa LL como \"beenb\". Dado que tales propiedades suelen ser características de las palabras vacías, agrupamos características como \"tu\" en el conjunto de características de palabras vacías (SW) recién definido. Dado que establecer los umbrales de DPS y DFIDF para identificar las palabras vacías es más un arte que una ciencia, propusimos un algoritmo heurístico HS, Algoritmo 1. La idea básica es utilizar solo noticias de días laborables para identificar palabras vacías. Los fines de semana aquí también incluyen días festivos que caen en días laborables. El conjunto SW se inicialmente alimenta con un pequeño conjunto de 29 stopwords populares utilizadas por el motor de búsqueda de Google. Algoritmo 1 Detección heurística de palabras vacías (HS) Entrada: Conjunto de palabras vacías semilla, trayectorias semanales de todas las palabras 1: A partir del conjunto semilla SW, calcular el DPS máximo como UDPS, el DFIDF máximo como UDFIDF y el mínimo de DFIDF como LDFIDF. 2: para fi ∈ F hacer 3: Calcular DFT para fi. 4: si Sfi ≤ UDPS y DFIDFfi ∈ [LDFIDF, UDFIDF] entonces 5: fi → SW 6: F = F - fi 7: fin si 8: fin para Resumen de la Categorización de Características Después de generar el conjunto SW, se eliminan todas las palabras vacías de F. Luego, establecemos el límite entre DPS alto y bajo como el límite superior de los DPS de los conjuntos SW. Una visión general de los cinco conjuntos de características se muestra en la Figura 7. Figura 7: Los 5 conjuntos de características para eventos. 5. IDENTIFICACIÓN DE RÁFAGAS PARA CARACTERÍSTICAS Dado que solo las características de HH, HL y LH son significativas y podrían ser representativas de algunos eventos, eliminamos todas las demás características clasificadas como LL o SW. En esta sección, describimos cómo se pueden identificar los estallidos a partir de las características restantes. A diferencia del algoritmo de identificación de ráfagas de Kleinberg [12], podemos identificar tanto ráfagas significativas como triviales sin necesidad de establecer ningún parámetro. 5.1 Detección de ráfagas de características aperiódicas Para cada característica en HH y HL, truncamos su trayectoria manteniendo solo el período de ráfagas, el cual está modelado con una distribución gaussiana. Por ejemplo, la Figura 8 muestra la característica de la palabra Iraq con una explosión alrededor del 09/06/1996 modelada como una Gaussiana. Su período de ráfagas está definido por [μf − σf , μf + σf ] como se muestra en la Figura 8(b). 5.2 Detección de características periódicas de ráfagas Dado que hemos calculado el DP para una característica periódica f, podemos modelar fácilmente su trayectoria de características periódicas yf usando 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) DFIDF original: tiempo 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 ráfaga= [μ-σ, μ+σ] (b) identificación de ráfaga Figura 8: Modelando la serie temporal de Iraq como una Gaussiana truncada con μ = 09/06/1996 y σ = 6.26. una mezcla de K = T/Pf Gaussianas: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , donde el conjunto de parámetros θf = {αk, μk, σk}K k=1 comprende: • αk es la probabilidad de asignar yf a la k-ésima Gaussiana. αk > 0, ∀k ∈ [1, K] y K k=1 αk = 1; • μk/σk es la media/desviación estándar de la k-ésima Gaussiana. El conocido algoritmo Expectation Maximization (EM) [8] se utiliza para calcular las proporciones de mezcla αk, así como los parámetros individuales de densidad gaussiana μk y σK. Cada Gaussiana representa un evento periódico, y se modela de manera similar como se menciona en la Sección 5.1. 6. EVENTOS A PARTIR DE CARACTERÍSTICAS Después de identificar y modelar ráfagas para todas las características, la siguiente tarea es pintar un cuadro del evento con un posible conjunto de características representativas. 6.1 Correlación de Características Si dos características fi y fj son representativas del mismo evento, deben cumplir las siguientes condiciones necesarias: 1. fi y fj están distribuidas de manera idéntica: yfi ∼ yfj. 2. fi y fj tienen una alta superposición de documentos. Medición de la similitud de la distribución de características. Medimos la similitud entre dos características fi y fj utilizando la divergencia KL discreta definida de la siguiente manera. Definición 6. (similitud de características) KL(fi, fj) se da por max(KL(fi|fj), KL(fj|fi)), donde KL(fi|fj) = T t=1 f(yfi(t)|θfi)log f(yfi(t)|θfi) f(yfj(t)|θfj). (1) Dado que la divergencia KL no es simétrica, definimos la similitud entre fi y fj como el máximo entre KL(fi|fj) y KL(fj|fi). Además, la similitud entre dos características aperiódicas puede calcularse utilizando una forma cerrada de la divergencia de Kullback-Leibler [16]. La misma fórmula discreta de divergencia KL de la Ecuación 1 se emplea para calcular la similitud entre dos características periódicas. A continuación, definimos la similitud general entre un conjunto de características R utilizando el valor máximo de divergencia KL entre características como sigue. Definición 7. (similitud de conjuntos) KL(R) = max ∀fi, fj ∈R KL(fi, fj). Superposición de documentos: Sea Mi el conjunto de todos los documentos que contienen la característica fi. Dadas dos características fi y fj, el conjunto de documentos superpuestos que contienen ambas características es Mi ∩ Mj. De manera intuitiva, cuanto mayor sea |Mi ∩ Mj|, es más probable que fi y fj estén altamente correlacionados. Definimos el grado de superposición de documentos entre dos características fi y fj de la siguiente manera. Definición 8. (Superposición de características DF) d(fi, fj) = |Mi∩Mj| min(|Mi|, |Mj|). En consecuencia, la superposición de DF entre un conjunto de características R también está definida. Definición 9. (Superposición de Conjuntos DF) d(R) = min ∀fi, fj ∈R d(fi, fj). 6.2 Detección de Eventos Codiciosa No Supervisada Utilizamos características de HH para detectar eventos aperiódicos importantes, características de LH para detectar eventos aperiódicos menos reportados/poco importantes, y características de HL para detectar eventos periódicos. Todos comparten el mismo algoritmo. Dado el rasgo explosivo fi ∈ HH, el objetivo es encontrar rasgos altamente correlacionados de HH. El conjunto de características similares a fi puede describir colectivamente un evento. Específicamente, necesitamos encontrar un subconjunto Ri de HH que minimice la siguiente función de costo: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) El evento subyacente e (asociado con la explosión de fi) puede ser representado por Ri como y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) El análisis de la explosión para el evento e es exactamente el mismo que la trayectoria de características. El costo en la Ecuación 2 se puede minimizar utilizando nuestro algoritmo de detección de eventos UG codicioso no supervisado, que se describe en el Algoritmo 2. El algoritmo UG permite una característica Algoritmo 2 Detección de eventos codiciosos no supervisados (UG). Salida: ek como Ec. 3. Además, los eventos triviales que solo contienen características de año/mes (es decir, un evento que solo contiene una característica de agosto podría ser identificado en un flujo de noticias de 1 año) podrían ser eliminados, aunque dichos eventos tendrán un costo inherente alto y deberían estar clasificados muy bajos. Tenga en cuenta que nuestro algoritmo UG solo requiere un parámetro dependiente de los datos, el límite entre el espectro de alta y baja potencia, que debe establecerse una vez, y este parámetro puede estimarse fácilmente utilizando el algoritmo HS (Algoritmo 1). 7. EXPERIMENTOS En esta sección, estudiamos el rendimiento de nuestro método de categorización de características y algoritmo de detección de eventos. Primero presentamos el conjunto de datos y la configuración experimental, luego evaluamos subjetivamente la categorización de características para HH, HL, LH, LL y SW. Finalmente, estudiamos el problema de detección de eventos (a)periódicos con el Algoritmo 2. 7.1. Conjunto de datos y configuración experimental El Corpus de Reuters contiene 806,791 noticias en inglés desde el 20/08/1996 hasta el 19/08/1997 con una resolución diaria. La versión 2 del software de código abierto Lucene [1] se utilizó para tokenizar el contenido de texto de noticias y generar el vector documento-palabra. Con el fin de preservar los tiempos verbales pasados/presentes/futuros sensibles al tiempo y las diferencias entre los sustantivos en minúscula y las entidades nombradas en mayúscula, no se realizó ningún truncamiento. Dado que la eliminación dinámica de palabras vacías es una de las funcionalidades de nuestro método, no se eliminó ninguna palabra vacía. Eliminamos los caracteres no ingleses, sin embargo, después de eso, el número de características de palabras asciende a 423,433. Todos los experimentos se implementaron en Java y se llevaron a cabo en una PC Pentium 4 de 3.2 GHz con Windows 2003 Server y 1 GB de memoria. 7.2 Categorización de características Descargamos 34 stopwords bien conocidos utilizados por el motor de búsqueda de Google como nuestras características de entrenamiento iniciales, que incluyen a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en y www. Excluimos las últimas cinco palabras vacías ya que son poco comunes en noticias. Al analizar solo historias de noticias durante 259 días laborables, calculamos el límite superior del espectro de potencia para las palabras vacías en 11.18 y los rangos correspondientes de DFIDF van desde 0.1182 hasta 0.3691. Cualquier característica f que cumpla con Sf <= 11.18 y 0.1182 <= DFIDFf <= 0.3691 durante los días de la semana se considerará una palabra vacía. De esta manera, se encontraron y eliminaron 470 palabras vacías como se muestra en la Figura 9. Algunas palabras vacías detectadas son A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) y much (P = 22, S = 0.80, DFIDF = 0.1865). Después de la eliminación de estas palabras vacías, la distribución de las noticias entre semana y los fines de semana están más o menos equilibradas, y en los experimentos subsiguientes, haremos uso del corpus completo (entre semana y fines de semana). El valor del espectro de potencia límite superior de 11.18 para el entrenamiento de palabras vacías fue seleccionado como el límite entre el espectro de alta potencia y baja potencia. El límite entre alta y baja periodicidad se estableció en 365/2 = 183. Todos los 422,963 (423433 − 470) rasgos de palabras fueron categorizados en 4 conjuntos de rasgos: HH (69 rasgos), HL (1,087 rasgos), LH (83,471 rasgos) y LL (338,806 rasgos) como se muestra en la Figura 10. En la Figura 10, cada nivel de gris denota la densidad relativa de características en una región cuadrada, medida por log10(1 + Dk), donde Dk es el número de características dentro de la k-ésima región cuadrada. A partir de la figura, podemos hacer el 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figura 9: Distribución de SW (palabras vacías) en las regiones HH, HL, LH y LL. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figura 10: Distribución de características categorizadas en los cuatro cuadrantes (sombreado en escala logarítmica). siguientes observaciones: 1. La mayoría de las características tienen un valor bajo de S y son fácilmente distinguibles de aquellas características que tienen un valor mucho más alto de S, lo que nos permite detectar eventos importantes (a)periódicos de eventos triviales seleccionando características con un alto valor de S. 2. Las características en los cuadrantes HH y LH son aperiódicas, las cuales están bien separadas (gran brecha horizontal) de las características periódicas. Esto permite detectar de manera confiable eventos aperiódicos y eventos periódicos de forma independiente. 3. La frontera (vertical) entre el espectro de alta y baja potencia no es tan clara y el valor exacto dependerá de la aplicación específica. Al revisar la distribución de dispersión de las características de SW en HH, HL, LH y LL como se muestra en la Figura 9, encontramos que el 87.02% (409/470) de las stopwords detectadas se originaron en LL. La clasificación LL y las altas puntuaciones de DFIDF de las palabras vacías concuerdan con la noción generalmente aceptada de que las palabras vacías son igualmente frecuentes en todo momento. Por lo tanto, establecer el límite entre el espectro de alta y baja potencia utilizando el límite superior Sf de SW es una heurística razonable. 7.3 Detección de Eventos Aperiódicos Evaluaremos nuestras dos hipótesis, 1)los eventos aperiódicos importantes pueden ser definidos por un conjunto de características HH, y 2)los eventos aperiódicos menos reportados pueden ser definidos por un conjunto de características LH. Dado que no existen flujos de noticias de referencia para la detección de eventos (los conjuntos de datos de TDT no son flujos adecuados), evaluamos la calidad de los eventos detectados automáticamente comparándolos con eventos confirmados manualmente mediante la búsqueda en el corpus. Entre las 69 características de HH, detectamos 17 eventos aperiódicos importantes como se muestra en la Tabla 1 (e1 - e17). Ten en cuenta que toda la identificación tomó menos de 1 segundo, después de eliminar los eventos que solo contenían la característica del mes. De los 17 eventos, aparte de las superposiciones entre e3 y e4 (ambos describen el mismo evento de rehenes), e11 y e16 (ambos sobre informes de empresas), los 14 eventos identificados son extremadamente precisos y corresponden muy bien a los principales eventos del período. Por ejemplo, la derrota de Bob Dole, la elección de Tony Blair, el ataque con misiles a Iraq, etc. Recuerde que seleccionar las características para un evento debería minimizar el costo en la Ecuación 2 de tal manera que 1) el número de características abarque diferentes eventos, y 2) no se seleccionarán todas las características relevantes para un evento, por ejemplo, la característica Clinton es representativa para e12, pero dado que Clinton se relaciona con muchos otros eventos, su señal de dominio temporal es muy diferente de la de otras características representativas como Dole y Bob. El número de documentos de un evento detectado se estima aproximadamente por el número de documentos indexados que contienen las características representativas. Podemos ver que los 17 eventos aperiódicos importantes son eventos reportados popularmente. Después de 742 minutos de tiempo de computación, detectamos 23,525 eventos aperiódicos menos reportados de 83,471 características de LH. La Tabla 1 enumera los 5 principales eventos aperiódicos detectados (e18 - e22) con respecto al costo. Descubrimos que estos 5 eventos son en realidad eventos muy triviales con solo unos pocos informes de noticias, y suelen ser englobados por algunos temas más grandes. Por ejemplo, e22 es uno de los eventos de rescate en un tema de secuestro de avión. Una ventaja de nuestro Algoritmo UG para descubrir eventos aperiódicos poco reportados es que podemos detectar con precisión el verdadero período del evento. 7.4 Detección de Eventos Periódicos Entre las 1,087 características de HL, se detectaron 330 eventos periódicos importantes en un tiempo de cálculo de 10 minutos. La Tabla 1 enumera los 5 eventos periódicos detectados con respecto al costo (e23 - e27). Todos los eventos periódicos detectados son realmente válidos y corresponden a eventos periódicos de la vida real. El modelo GMM es capaz de detectar y estimar el período de ráfagas de manera precisa, aunque no puede distinguir la ligera diferencia entre cada lunes a viernes y todos los días de la semana, como se muestra en e23. También observamos que e26 es en realidad un subconjunto de e27 (partido de fútbol), lo cual es aceptable ya que los resultados de la liga de Sheffield se anuncian de forma independiente cada fin de semana. 8. CONCLUSIONES Este artículo adoptó una perspectiva completamente nueva para analizar las trayectorias de características como señales en el dominio del tiempo. Al considerar las frecuencias de los documentos en el dominio del tiempo y de la frecuencia, pudimos derivar muchas nuevas características sobre los flujos de noticias que antes eran desconocidas, por ejemplo, las diferentes distribuciones de palabras vacías durante los días de la semana y los fines de semana. Por primera vez en el área de TDT, aplicamos un enfoque sistemático para detectar automáticamente eventos importantes y menos reportados, periódicos y aperiódicos. La idea clave de nuestro trabajo radica en las observaciones de que los eventos periódicos tienen características representativas periódicas y los eventos (in)importantes tienen características representativas (in)activas, diferenciadas por sus espectros de potencia y períodos de tiempo. Para abordar el problema de detección de eventos reales, se utilizó un enfoque basado en densidad de mezcla simple y efectivo para identificar ráfagas de características y sus períodos asociados de ráfagas. También diseñamos un algoritmo codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos, el cual tuvo éxito en detectar eventos reales como se muestra en la evaluación en un flujo de noticias reales. Aunque no hemos realizado ninguna comparación de referencia con otro enfoque, simplemente porque no hay trabajos previos en el problema abordado. El trabajo futuro incluye evaluar la recuperación de eventos detectados en un flujo de noticias etiquetado, y comparar nuestro modelo con los métodos equivalentes más cercanos, que actualmente se limitan a los métodos de Kleinberg [12] (que solo pueden detectar ciertos tipos de eventos explosivos dependiendo de la configuración de parámetros), Fung et al. [9], y Swan y Allan [18]. Sin embargo, creemos que nuestro método simple y efectivo será útil para todos los practicantes de TDT, y será especialmente útil para el análisis exploratorio inicial de flujos de noticias. REFERENCIAS [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Alertas de noticias de Google, http://www.google.com/alerts. [3] Corpus de Reuters, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan. Detección y seguimiento de temas. Organización de la información basada en eventos. Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, y H. Jin. La detección de la primera historia en tdt es difícil. En CIKM, páginas 374-381, 2000. [6] J. Allan, C. Wade y A. Bolivar. Recuperación y detección de novedades a nivel de oración. En SIGIR, páginas 314-321, 2003. [7] T. Brants, F. Chen y A. Farahat. Un sistema para la detección de nuevos eventos. En SIGIR, páginas 330-337, 2003. [8] A. P. Dempster, N. M. Laird y D. B. Rubin. Máxima verosimilitud a partir de datos incompletos a través del algoritmo EM. Revista de la Real Sociedad Estadística, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu y H. Lu. Detección de eventos explosivos sin parámetros en flujos de texto. En VLDB, páginas 181-192, 2005. [10] Q. Él, K. Chang y E.-P. Lim. Un modelo para la detección anticipada de eventos. En ER, páginas 168-181, 2006. [11] Q. Él, K. Chang, E.-P. Lim y J. Zhang. Representación de características intermitentes para la agrupación de flujos de texto. En SDM, aceptado, 2007. [12] J. Kleinberg. Estructura explosiva y jerárquica en arroyos. En SIGKDD, páginas 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan y A. Tomkins. Sobre la evolución explosiva del blogosfera. En WWW, páginas 159-178, 2005. [14] G. Kumaran y J. Allan. Clasificación de texto y entidades nombradas para la detección de nuevos eventos. En SIGIR, páginas 297-304, 2004. [15] Q. Mei y C. Zhai. Descubriendo patrones temáticos evolutivos a partir de texto: una exploración de la minería de texto temporal. En SIGKDD, páginas 198-207, 2005. [16] W. D. Penny. Divergencias de Kullback-Leibler de densidades normales, gamma, dirichlet y wishart. Informe técnico, 2001. [17] N. Stokes y J. Carthy. Combinando clasificadores de documentos semánticos y sintácticos para mejorar la detección de la primera noticia. En SIGIR, páginas 424-425, 2001. [18] R. Swan y J. Allan. Generación automática de líneas de tiempo de resumen. En SIGIR, páginas 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena y D. Gunopulos. Identificando similitudes, periodicidades y ráfagas en las consultas de búsqueda en línea. En SIGMOD, páginas 131-142, 2004. [20] Y. Yang, T. Pierce y J. Carbonell. Un estudio de detección de eventos retrospectivos y en línea. En SIGIR, páginas 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell y C. Jin. Detección de novedades condicionada por el tema. En SIGKDD, páginas 688-693, 2002. Tabla 1: Todos los eventos aperiódicos importantes (e1 - e17), los 5 eventos aperiódicos menos reportados (e18 - e22) y los 5 eventos periódicos importantes (e23 - e27). Evento detectado y período de actividad intensa Doc # Verdadero evento e1 (Sali, Berisha, Albania, albanés, marzo) 02/02/199705/29/1997 1409 El presidente albanés Sali Berisha perdió en una elección temprana y renunció, 12/1996-07/1997. e2 (Seko, Mobutu, Sese, Kabila) 03/22/1997-06/09/1997 2273 El presidente de Zaire, Mobutu Sese, coordinó la rebelión nativa y fracasó el 16/05/1997. e3 (Marxista, peruano) 11/19/1996-03/05/1997 824 Los rebeldes de Perú (Movimiento Revolucionario Tupac Amaru) lideraron un asedio de rehenes en Lima a principios de 1997. e4 (Movimiento, Tupac, Amaru, Lima, rehén, rehenes) 11/16/1996-03/20/1997 824 Lo mismo que e3. e5 (Kinshasa, Kabila, Laurent, Congo) 03/26/199706/15/1997 1378 Zaire fue renombrado República Democrática del Congo el 16/05/1997. e6 (Jospin, Lionel, junio) 05/10/1997-07/09/1997 605 Tras las elecciones generales tempranas alrededor de 06/1997, Lionel Jospin fue nombrado Primer Ministro el 02/06/1997. e7 (Irak, misil) 08/31/1996-09/13/1996 1262 EE. UU. disparó un misil a Irak el 03/09/1996 y el 04/09/1996. e8 (kurdo, Bagdad, iraquí) 08/29/1996-09/09/1996 1132 Tropas iraquíes lucharon con facciones kurdas alrededor de 09/1996. e9 (mayo, Blair) 03/24/1997-07/04/1997 1049 Tony Blair se convirtió en el Primer Ministro del Reino Unido el 02/05/1997. e10 (slalom, esquí) 12/05/1996-03/21/1997 253 Juego de eslalon de esquí alpino en 01/1997-02/1997. e11 (Interino, meses) 09/24/1996-12/31/1996 3063 Tokio publicó los resultados interinos de la empresa para los últimos meses en 09/1996-12/1996. e12 (Dole, Bob) 09/09/1996-11/24/1996 1599 Bob Dole perdió las elecciones presidenciales de EE. UU. de 1996. e13 (julio, Sen) 06/25/1997-06/25/1997 344 El Primer Ministro de Camboya, Hun Sen, lanzó un sangriento golpe militar en 07/1997. e14 (Hebrón) 10/15/1996-02/14/1997 2098 Hebrón fue dividida en dos sectores a principios de 1997. e15 (abril, Pascua) 02/23/1997-05/04/1997 480 Festividades de Pascua alrededor de 04/1997 (para occidentales y ortodoxos). e16 (Diluido, Grupo) 04/27/1997-07/20/1997 1888 Tokio publicó todos los resultados del grupo 96/97 en 04/199707/1997. e17 (diciembre, Navidad) 11/17/1996-01/26/1997 1326 Festín de Navidad a finales de 12/1997. e18 (Kolaceva, invierno, Juntos, paseos, Zajedno, Slobodan, Belgrado, serbio, Serbia, Draskovic, municipal, Kragujevac) 1/25/1997 3 Estudiantes universitarios organizaron una vigilia en la calle Kolaceva contra el gobierno el 25/01/1997. e19 (Tutsi, Luvengi, Burundi, Uvira, combustible, Banyamulenge, burundés, Kivu, Kiliba, Runingo, Kagunga, Bwegera) 10/19/1996 6 Estallaron nuevos enfrentamientos alrededor de Uvira entre las fuerzas armadas de Zaire y los rebeldes Tutsi de Banyamulenge el 19/10/1996. e20 (Malantacchi, Corea, Guy, Rider, Sindicatos, trabajo, Confederación, embestido, Ginebra, paradas, Virgin, contratar, Myongdong, Metalúrgicos) 1/11/1997 2 Marcello Malantacchi, secretario general de la Federación Internacional de Metalúrgicos, y Guy Rider, quien dirige la oficina de Ginebra de la Confederación Internacional de Sindicatos Libres, atacaron la nueva ley laboral de Corea del Sur el 11/01/1997. e21 (DBS, Raﬄes) 8/17/1997 9 La lista de la unidad de DBS Land Raﬄes Holdings de Singapur planea el 17/08/1997. e22 (conservador, combustible, Galawa, Huddle, Leul, Beausse) 11/24/1996 3 Rescataron a una mujer y a su bebé durante un secuestro de un avión etíope que se quedó sin combustible y se estrelló en el mar cerca de la playa Le Galawa el 24/11/1996. e23 (PRECIO, LISTADO, MLN, VENCIMIENTO, CUPÓN, MOODY, MONTO, PRIMERO, ISS, TIPO, PAGO, PRESTAMISTA) Lunes a viernes/semana 7966 Anuncian el precio de los bonos todos los días de la semana. e24 (No auditado, Terminado, Meses, Ponderado, Provisión, Costo, Venta, Ingresos, Pérdida, Ingreso, excepto, Shrs, Revs) cada temporada 2264 Informes de ingresos netos-pérdidas publicados por empresas en cada temporada. e25 (calificación, Wall Street, Ian) Lunes a viernes/semana 21767 Informes de acciones de Wall Street todos los días de la semana. e26 (Sheffield, liga, goles de puntuación, delantero, juegos) cada viernes, sábado y domingo 574 Resultados de partidos de la liga de fútbol de Sheffield publicados los viernes, sábados y domingos 10 veces más que en los otros 4 días. e27 (fútbol, partidos, Resultados, temporada, juego, Copa, partido, victoria, vencer, jugado, jugar, división) cada viernes, sábado y domingo 2396 Juegos de fútbol celebrados los viernes, sábados y domingos 7 veces más que en los otros 4 días. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "gaussian": {
            "translated_key": "gaussiana",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Analyzing Feature Trajectories for Event Detection Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg School of Computer Engineering Nanyang Technological University Block N4, Nanyang Avenue, Singapore 639798 ABSTRACT We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words.",
                "A set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner.",
                "The document frequency of each word across time is treated like a time series, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point.",
                "In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with <br>gaussian</br> density and periodic features with <br>gaussian</br> mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events.",
                "All of the above methods can be applied to time series data in general.",
                "We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events.",
                "Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Experimentation. 1.",
                "INTRODUCTION There are more than 4,000 online news sources in the world.",
                "Manually monitoring all of them for important events has become difficult or practically impossible.",
                "In fact, the topic detection and tracking (TDT) community has for many years been trying to come up with a practical solution to help people monitor news effectively.",
                "Unfortunately, the holy grail is still elusive, because the vast majority of TDT solutions proposed for event detection [20, 5, 17, 4, 21, 7, 14, 10] are either too simplistic (based on cosine similarity [5]) or impractical due to the need to tune a large number of parameters [9].",
                "The ineffectiveness of current TDT technologies can be easily illustrated by subscribing to any of the many online news alerts services such as the industryleading Google News Alerts [2], which generates more than 50% false alarms [10].",
                "As further proof, portals like Yahoo take a more pragmatic approach by requiring all machine generated news alerts to go through a human operator for confirmation before sending them out to subscribers.",
                "Instead of attacking the problem with variations of the same hammer (cosine similarity and TFIDF), a fundamental understanding of the characteristics of news stream data is necessary before any major breakthroughs can be made in TDT.",
                "Thus in this paper, we look at news stories and feature trends from the perspective of analyzing a time-series word signal.",
                "Previous work like [9] has attempted to reconstruct an event with its representative features.",
                "However, in many predictive event detection tasks (i.e., retrospective event detection), there is a vast set of potential features only for a fixed set of observations (i.e., the obvious bursts).",
                "Of these features, often only a small number are expected to be useful.",
                "In particular, we study the novel problem of analyzing feature trajectories for event detection, borrowing a well-known technique from signal processing: identifying distributional correlations among all features by spectral analysis.",
                "To evaluate our method, we subsequently propose an unsupervised event detection algorithm for news streams. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Easter April (a) aperiodic event 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Unaudited Ended (b) periodic event Figure 1: Feature correlation (DFIDF:time) between a) Easter and April b) Unaudited and Ended.",
                "As an illustrative example, consider the correlation between the words Easter and April from the Reuters Corpus1 .",
                "From the plot of their normalized DFIDF in Figure 1(a), we observe the heavy overlap between the two words circa 04/1997, which means they probably both belong to the same event during that time (Easter feast).",
                "In this example, the hidden event Easter feast is a typical important aperiodic event over 1-year data.",
                "Another example is given by Figure 1(b), where both the words Unaudited and Ended 1 Reuters Corpus is the default dataset for all examples. exhibit similar behaviour over periods of 3 months.",
                "These two words actually originated from the same periodic event, net income-loss reports, which are released quarterly by publicly listed companies.",
                "Other observations drawn from Figure 1 are: 1) the bursty period of April is much longer than Easter, which suggests that April may exist in other events during the same period; 2) Unaudited has a higher average DFIDF value than Ended, which indicates Unaudited to be more representative for the underlying event.",
                "These two examples are but the tip of the iceberg among all word trends and correlations hidden in a news stream like Reuters.",
                "If a large number of them can be uncovered, it could significantly aid TDT tasks.",
                "In particular, it indicates the significance of mining correlating features for detecting corresponding events.",
                "To summarize, we postulate that: 1) An event is described by its representative features.",
                "A periodic event has a list of periodic features and an aperiodic event has a list of aperiodic features; 2) Representative features from the same event share similar distributions over time and are highly correlated; 3) An important event has a set of active (largely reported) representative features, whereas an unimportant event has a set of inactive (less-reported) representative features; 4) A feature may be included by several events with overlaps in time frames.",
                "Based on these observations, we can either mine representative features given an event or detect an event from a list of highly correlated features.",
                "In this paper, we focus on the latter, i.e., how correlated features can be uncovered to form an event in an unsupervised manner. 1.1 Contributions This paper has three main contributions: • To the best of our knowledge, our approach is the first to categorize word features for heterogenous events.",
                "Specifically, every word feature is categorized into one of the following five feature types based on its power spectrum strength and periodicity: 1) HH (high power and high/long periodicity): important aperiodic events, 2) HL (high power and low periodicity): important periodic events, 3) LH (low power and high periodicity): unimportant aperiodic events, 4) LL (low power and low periodicity): non-events, and 5) SW (stopwords), a higher power and periodicity subset of LL comprising stopwords, which contains no information. • We propose a simple and effective mixture densitybased approach to model and detect feature bursts. • We come up with an unsupervised event detection algorithm to detect both aperiodic and periodic events.",
                "Our algorithm has been evaluated on a real news stream to show its effectiveness. 2.",
                "RELATED WORK This work is largely motivated by a broader family of problems collectively known as Topic Detection and Tracking (TDT) [20, 5, 17, 4, 21, 7, 14, 10].",
                "Moreover, most TDT research so far has been concerned with clustering/classifying documents into topic types, identifying novel sentences [6] for new events, etc., without much regard to analyzing the word trajectory with respect to time.",
                "Swan and Allan [18] first attempted using co-occuring terms to construct an event.",
                "However, they only considered named entities and noun phrase pairs, without considering their periodicities.",
                "On the contrary, our paper considers all of the above.",
                "Recently, there has been significant interest in modeling an event in text streams as a burst of activities by incorporating temporal information.",
                "Kleinbergs seminal work described how bursty features can be extracted from text streams using an infinite automaton model [12], which inspired a whole series of applications such as Kumars identification of bursty communities from Weblog graphs [13], Meis summarization of evolutionary themes in text streams [15], Hes clustering of text streams using bursty features [11], etc.",
                "Nevertheless, none of the existing work specifically identified features for events, except for Fung et al. [9], who clustered busty features to identify various bursty events.",
                "Our work differs from [9] in several ways: 1) we analyze every single feature, not only bursty features; 2) we classify features along two categorical dimensions (periodicity and power), yielding altogether five primary feature types; 3) we do not restrict each feature to exclusively belong to only one event.",
                "Spectral analysis techniques have previously been used by Vlachos et al. [19] to identify periodicities and bursts from query logs.",
                "Their focus was on detecting multiple periodicities from the power spectrum graph, which were then used to index words for query-by-burst search.",
                "In this paper, we use spectral analysis to classify word features along two dimensions, namely periodicity and power spectrum, with the ultimate goal of identifying both periodic and aperiodic bursty events. 3.",
                "DATA REPRESENTATION Let T be the duration/period (in days) of a news stream, and F represents the complete word feature space in the classical static Vector Space Model (VSM). 3.1 Event Periodicity Classification Within T, there may exist certain events that occur only once, e.g., Tony Blair elected as Prime Minister of U.K., and other recurring events of various periodicities, e.g., weekly soccer matches.",
                "We thus categorize all events into two types: aperiodic and periodic, defined as follows.",
                "Definition 1. (Aperiodic Event) An event is aperiodic within T if it only happens once.",
                "Definition 2. (Periodic Event) If events of a certain event genre occur regularly with a fixed periodicity P ≤ T/2 , we say that this particular event genre is periodic, with each member event qualified as a periodic event.",
                "Note that the definition of aperiodic is relative, i.e., it is true only for a given T, and may be invalid for any other T > T. For example, the event Christmas feast is aperiodic for T ≤ 365 but periodic for T ≥ 730. 3.2 Representative Features Intuitively, an event can be described very concisely by a few discriminative and representative word features and vice-versa, e.g., hurricane, sweep, and strike could be representative features of a Hurricane genre event.",
                "Likewise, a set of strongly correlated features could be used to reconstruct an event description, assuming that strongly correlated features are representative.",
                "The representation vector of a word feature is defined as follows: Definition 3. (Feature Trajectory) The trajectory of a word feature f can be written as the sequence yf = [yf (1), yf (2), . . . , yf (T)], where each element yf (t) is a measure of feature f at time t, which could be defined using the normalized DFIDF score2 yf (t) = DFf (t) N(t) × log( N DFf ), where DFf (t) is the number of documents (local DF) containing feature f at day t, DFf is the total number of documents (global DF) containing feature f over T, N(t) is the number of documents for day t, and N is the total number of documents over T. 4.",
                "IDENTIFYING FEATURES FOR EVENTS In this section, we show how representative features can be extracted for (un)important or (a)periodic events. 4.1 Spectral Analysis for Dominant Period Given a feature f, we decompose its feature trajectory yf = [yf (1), yf (2), ..., yf (T)] into the sequence of T complex numbers [X1, . . . , XT ] via the discrete Fourier transform (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. DFT can represent the original time series as a linear combination of complex sinusoids, which is illustrated by the inverse discrete Fourier transform (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, where the Fourier coefficient Xk denotes the amplitude of the sinusoid with frequency k/T.",
                "The original trajectory can be reconstructed with just the dominant frequencies, which can be determined from the power spectrum using the popular periodogram estimator.",
                "The periodogram is a sequence of the squared magnitude of the Fourier coefficients, Xk 2 , k = 1, 2, . . . , T/2 , which indicates the signal power at frequency k/T in the spectrum.",
                "From the power spectrum, the dominant period is chosen as the inverse of the frequency with the highest power spectrum, as follows.",
                "Definition 4. (Dominant Period) The dominant period (DP) of a given feature f is Pf = T/ arg max k Xk 2 .",
                "Accordingly, we have Definition 5. (Dominant Power Spectrum) The dominant power spectrum (DPS) of a given feature f is Sf = Xk 2 , with Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorizing Features The DPS of a feature trajectory is a strong indicator of its activeness at the specified frequency; the higher the DPS, the more likely for the feature to be bursty.",
                "Combining DPS with DP, we therefore categorize all features into four types: 2 We normalize yf (t) as yf (t) = yf (t)/ T i=1 yf (i) so that it could be interpreted as a probability. • HH: high Sf , aperiodic or long-term periodic (Pf > T/2 ); • HL: high Sf , short-term periodic (Pf ≤ T/2 ); • LH: low Sf , aperiodic or long-term periodic; • LL: low Sf , short-term periodic.",
                "The boundary between long-term and short-term periodic is set to T/2 .",
                "However, distinguishing between a high and low DPS is not straightforward, which will be tackled later.",
                "Properties of Different Feature Sets To better understand the properties of HH, HL, LH and LL, we select four features, Christmas, soccer, DBS and your as illustrative examples.",
                "Since the boundary between high and low power spectrum is unclear, these chosen examples have relative wide range of power spectrum values.",
                "Figure 2(a) shows the DFIDF trajectory for Christmas with a distinct burst around Christmas day.",
                "For the 1-year Reuters dataset, Christmas is classified as a typical aperiodic event with Pf = 365 and Sf = 135.68, as shown in Figure 2(b).",
                "Clearly, the value of Sf = 135.68 is reasonable for a well-known bursty event like Christmas. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Christmas(DFIDF:time) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Christmas(S:frequency) Figure 2: Feature Christmas with relative high Sf and long-term Pf .",
                "The DFIDF trajectory for soccer is shown in Figure 3(a), from which we can observe that there is a regular burst every 7 days, which is again verified by its computed value of Pf = 7, as shown in Figure 3(b).",
                "Using the domain knowledge that soccer games have more matches every Saturday, which makes it a typical and heavily reported periodic event, we thus consider the value of Sf = 155.13 to be high. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) soccer(DFIDF:time) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) soccer(S:frequency) Figure 3: Feature soccer with relative high Sf and short-term Pf .",
                "From the DFIDF trajectory for DBS in Figure 4(a), we can immediately deduce DBS to be an infrequent word with a trivial burst on 08/17/1997 corresponding to DBS Land Raﬄes Holdings plans.",
                "This is confirmed by the long period of Pf = 365 and low power of Sf = 0.3084 as shown in Figure 4(b).",
                "Moreover, since this aperiodic event is only reported in a few news stories over a very short time of few days, we therefore say that its low power value of Sf = 0.3084 is representative of unimportant events.",
                "The most confusing example is shown in Figure 5 for the word feature your, which looks very similar to the graph for soccer in Figure 3.",
                "At first glance, we may be tempted to group both your and soccer into the same category of HL or LL since both distributions look similar and have the same dominant period of approximately a week.",
                "However, further 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:time) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frequency) Figure 4: Feature DBS with relative low Sf and long-term Pf . analysis indicates that the periodicity of your is due to the differences in document counts for weekdays (average 2,919 per day) and weekends3 (average 479 per day).",
                "One would have expected the periodicity of a stopword like your to be a day.",
                "Moreover, despite our DFIDF normalization, the weekday/weekend imbalance still prevailed; stopwords occur 4 times more frequently on weekends than on weekdays.",
                "Thus, the DPS remains the only distinguishing factor between your (Sf = 9.42) and soccer (Sf = 155.13).",
                "However, it is very dangerous to simply conclude that a power value of S = 9.42 corresponds to a stopword feature. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) your(DFIDF:time) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) your(S:frequency) Figure 5: Feature your as an example confusing with feature soccer.",
                "Before introducing our solution to this problem, lets look at another LL example as shown in Figure 6 for beenb, which is actually a confirmed typo.",
                "We therefore classify beenb as a noisy feature that does not contribute to any event.",
                "Clearly, the trajectory of your is very different from beenb, which means that the former has to be considered separately. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figure 6: Feature beenb with relative low Sf and short-term Pf .",
                "Stop Words (SW) Feature Set Based on the above analysis, we realize that there must be another feature set between HL and LL that corresponds to the set of stopwords.",
                "Features from this set has moderate DPS and low but known dominant period.",
                "Since it is hard to distinguish this feature set from HL and LL only based on DPS, we introduce another factor called average DFIDF (DFIDF).",
                "As shown in Figure 5, features like your usually have a lower DPS than a HL feature like soccer, but have a much higher DFIDF than another LL noisy feature such as beenb.",
                "Since such properties are usually characteristics of stopwords, we group features like your into the newly defined stopword (SW) feature set.",
                "Since setting the DPS and DFIDF thresholds for identifying stopwords is more of an art than science, we proposed a heuristic HS algorithm, Algorithm 1.",
                "The basic idea is to only use news stories from weekdays to identify stopwords. 3 The weekends here also include public holidays falling on weekdays.",
                "The SW set is initially seeded with a small set of 29 popular stopwords utilized by Google search engine.",
                "Algorithm 1 Heuristic Stopwords detection (HS) Input: Seed SW set, weekday trajectories of all words 1: From the seed set SW, compute the maximum DPS as UDPS, maximum DFIDF as UDFIDF, and minimum of DFIDF as LDFIDF. 2: for fi ∈ F do 3: Compute DFT for fi. 4: if Sfi ≤ UDPS and DFIDFfi ∈ [LDFIDF, UDFIDF] then 5: fi → SW 6: F = F − fi 7: end if 8: end for Overview of Feature Categorization After the SW set is generated, all stopwords are removed from F. We then set the boundary between high and low DPS to be the upper bound of the SW sets DPS.",
                "An overview of all five feature sets is shown in Figure 7.",
                "Figure 7: The 5 feature sets for events. 5.",
                "IDENTIFYING BURSTS FOR FEATURES Since only features from HH, HL and LH are meaningful and could potentially be representative to some events, we pruned all other feature classified as LL or SW.",
                "In this section, we describe how bursts can be identified from the remaining features.",
                "Unlike Kleinbergs burst identification algorithm [12], we can identify both significant and trivial bursts without the need to set any parameters. 5.1 Detecting Aperiodic Features Bursts For each feature in HH and HL, we truncate its trajectory by keeping only the bursty period, which is modeled with a <br>gaussian</br> distribution.",
                "For example, Figure 8 shows the word feature Iraq with a burst circa 09/06/1996 being modeled as a <br>gaussian</br>.",
                "Its bursty period is defined by [μf − σf , μf + σf ] as shown in Figure 8(b). 5.2 Detecting Periodic Features Bursts Since we have computed the DP for a periodic feature f, we can easily model its periodic feature trajectory yf using 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) original DFIDF:time 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 burst= [μ-σ, μ+σ] (b) identifying burst Figure 8: Modeling Iraqs time series as a truncated <br>gaussian</br> with μ = 09/06/1996 and σ = 6.26. a mixture of K = T/Pf Gaussians: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , where the parameter set θf = {αk, μk, σk}K k=1 comprises: • αk is the probability of assigning yf into the kth <br>gaussian</br>. αk > 0, ∀k ∈ [1, K] and K k=1 αk = 1; • μk/σk is mean/standard deviation of the kth Gaussian.",
                "The well known Expectation Maximization (EM) [8] algorithm is used to compute the mixing proportions αk, as well as the individual <br>gaussian</br> density parameters μk and σK .",
                "Each <br>gaussian</br> represents one periodic event, and is modeled similarly as mentioned in Section 5.1. 6.",
                "EVENTS FROM FEATURES After identifying and modeling bursts for all features, the next task is to paint a picture of the event with a potential set of representative features. 6.1 Feature Correlation If two features fi and fj are representative of the same event, they must satisfy the following necessary conditions: 1. fi and fj are identically distributed: yfi ∼ yfj . 2. fi and fj have a high document overlap.",
                "Measuring Feature Distribution Similarity We measure the similarity between two features fi and fj using discrete KL-divergence defined as follows.",
                "Definition 6. (feature similarity) KL(fi, fj ) is given by max(KL(fi|fj ), KL(fj |fi)), where KL(fi|fj ) = T t=1 f(yfi (t)|θfi )log f(yfi (t)|θfi ) f(yfj (t)|θfj ) . (1) Since KL-divergence is not symmetric, we define the similarity between between fi and fj as the maximum of KL(fi|fj ) and KL(fj |fi).",
                "Further, the similarity between two aperiodic features can be computed using a closed form of the KL-divergence [16].",
                "The same discrete KL-divergence formula of Eq. 1 is employed to compute the similarity between two periodic features, Next, we define the overal similarity among a set of features R using the maximum inter-feature KL-Divergence value as follows.",
                "Definition 7. (sets similarity)KL(R) = max ∀fi,fj ∈R KL(fi, fj ).",
                "Document Overlap Let Mi be the set of all documents containing feature fi.",
                "Given two features fi and fj , the overlapping document set containing both features is Mi ∩ Mj .",
                "Intuitively, the higher the |Mi ∩ Mj |, the more likelty that fi and fj will be highly correlated.",
                "We define the degree of document overlap between two features fi and fj as follows.",
                "Definition 8. (Feature DF Overlap) d(fi, fj ) = |Mi∩Mj| min(|Mi|,|Mj|) .",
                "Accordingly, the DF Overlap among a set of features R is also defined.",
                "Definition 9. (Set DF Overlap) d(R) = min ∀fi,fj ∈R d(fi, fj). 6.2 Unsupervised Greedy Event Detection We use features from HH to detect important aperiodic events, features from LH to detect less-reported/unimportant aperiodic events, and features from HL to detect periodic events.",
                "All of them share the same algorithm.",
                "Given bursty feature fi ∈ HH, the goal is to find highly correlated features from HH.",
                "The set of features similar to fi can then collectively describe an event.",
                "Specifically, we need to find a subset Ri of HH that minimizes the following cost function: C(Ri) = KL(Ri) d(Ri) fj ∈Ri Sfj , Ri ⊂ HH. (2) The underlying event e (associated with the burst of fi) can be represented by Ri as y(e) = fj ∈Ri Sfj fu∈Ri Sfu yfj . (3) The burst analysis for event e is exactly the same as the feature trajectory.",
                "The cost in Eq. 2 can be minimized using our unsupervised greedy UG event detection algorithm, which is described in Algorithm 2.",
                "The UG algorithm allows a feature Algorithm 2 Unsupervised Greedy event detection (UG).",
                "Input: HH, document index for each feature. 1: Sort and select features in descending DPS order: Sf1 ≥ Sf2 ≥ . . . ≥ Sf|HH| . 2: k = 0. 3: for fi ∈ HH do 4: k = k + 1. 5: Init: Ri ← fi, C(Ri) = 1/Sfi and HH = HH − fi. 6: while HH not empty do 7: m = arg min m C(Ri ∪ fm). 8: if C(Ri ∪ fm) < C(Ri) then 9: Ri ← fm and HH = HH − fm. 10: else 11: break while. 12: end if 13: end while 14: Output ek as Eq. 3. 15: end for to be contained in multiple events so that we can detect several events happening at the same time.",
                "Furthermore, trivial events only containing year/month features (i.e., an event only containing 1 feature Aug could be identified over a 1year news stream) could be removed, although such events will have inherent high cost and should already be ranked very low.",
                "Note that our UG algorithm only requires one data-dependant parameter, the boundary between high and low power spectrum, to be set once, and this parameter can be easily estimated using the HS algorithm (Algorithm 1). 7.",
                "EXPERIMENTS In this section, we study the performances of our feature categorizing method and event detection algorithm.",
                "We first introduce the dataset and experimental setup, then we subjectively evaluate the categorization of features for HH, HL, LH, LL and SW.",
                "Finally, we study the (a)periodic event detection problem with Algorithm 2. 7.1 Dataset and Experimental Setup The Reuters Corpus contains 806,791 English news stories from 08/20/1996 to 08/19/1997 at a day resolution.",
                "Version 2 of the open source Lucene software [1] was used to tokenize the news text content and generate the document-word vector.",
                "In order to preserve the time-sensitive past/present/future tenses of verbs and the differences between lower case nouns and upper case named entities, no stemming was done.",
                "Since dynamic stopword removal is one of the functionalities of our method, no stopword was removed.",
                "We did remove nonEnglish characters, however, after which the number of word features amounts to 423,433.",
                "All experiments were implemented in Java and conducted on a 3.2 GHz Pentium 4 PC running Windows 2003 Server with 1 GB of memory. 7.2 Categorizing Features We downloaded 34 well-known stopwords utilized by the Google search engine as our seed training features, which includes a, about, an, are, as, at, be, by, de, for, from, how, in, is, it, of, on, or, that, the, this, to, was, what, when, where, who, will, with, la, com, und, en and www.",
                "We excluded the last five stopwords as they are uncommon in news stories.",
                "By only analyzing news stories over 259 weekdays, we computed the upper bound of the power spectrum for stopwords at 11.18 and corresponding DFIDF ranges from 0.1182 to 0.3691.",
                "Any feature f satisfying Sf <= 11.18 and 0.1182 <= DFIDFf <= 0.3691 over weekdays will be considered a stopword.",
                "In this manner, 470 stopwords were found and removed as visualized in Figure 9.",
                "Some detected stopwords are A (P = 65, S = 3.36, DFIDF = 0.3103), At (P = 259, S = 1.86, DFIDF = 0.1551), GMT (P = 130, S = 6.16, DFIDF = 0.1628) and much (P = 22, S = 0.80, DFIDF = 0.1865).",
                "After the removal of these stopwords, the distribution of weekday and weekend news are more or less matched, and in the ensuing experiments, we shall make use of the full corpus (weekdays and weekends).",
                "The upper bound power spectrum value of 11.18 for stopwords training was selected as the boundary between the high power and low power spectrum.",
                "The boundary between high and low periodicity was set to 365/2 = 183.",
                "All 422,963 (423433 − 470) word features were categorized into 4 feature sets: HH (69 features), HL (1,087 features), LH (83,471 features), and LL (338,806 features) as shown in Figure 10.",
                "In Figure 10, each gray level denotes the relative density of features in a square region, measured by log10(1 + Dk), where Dk is the number of features within the k-th square region.",
                "From the figure, we can make the 0 2 4 6 8 11.18 12879.82 1 65 100 130 259 S(f) P(f) LH HH LL HL Figure 9: Distribution of SW (stopwords) in the HH, HL, LH, and LL regions. 0 5 11.18 50 100 200 300 400 500 1000 12879.82 1 2 4 6 8 20 50 100 183 364 365 S(f) P(f) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 LH HH LL HL Figure 10: Distribution of categorized features over the four quadrants (shading in log scale). following observations: 1.",
                "Most features have low S and are easily distinguishable from those features having a much higher S, which allows us to detect important (a)periodic events from trivial events by selecting features with high S. 2.",
                "Features in the HH and LH quadrants are aperiodic, which are nicely separated (big horizontal gap) from the periodic features.",
                "This allows reliably detecting aperiodic events and periodic events independently. 3.",
                "The (vertical) boundary between high and low power spectrum is not as clearcut and the exact value will be application specific.",
                "By checking the scatter distribution of features from SW on HH, HL, LH, and LL as shown in Figure 9, we found that 87.02%(409/470) of the detected stopwords originated from LL.",
                "The LL classification and high DFIDF scores of stopwords agree with the generally accepted notion that stopwords are equally frequent over all time.",
                "Therefore, setting the boundary between high and low power spectrum using the upper bound Sf of SW is a reasonable heuristic. 7.3 Detecting Aperiodic Events We shall evaluate our two hypotheses, 1)important aperiodic events can be defined by a set of HH features, and 2)less reported aperiodic events can be defined by a set of LH features.",
                "Since no benchmark news streams exist for event detection (TDT datasets are not proper streams), we evaluate the quality of the automatically detected events by comparing them to manually-confirmed events by searching through the corpus.",
                "Among the 69 HH features, we detected 17 important aperiodic events as shown in Table 1 (e1 − e17).",
                "Note that the entire identification took less than 1 second, after removing events containing only the month feature.",
                "Among the 17 events, other than the overlaps between e3 and e4 (both describes the same hostage event), e11 and e16 (both about company reports), the 14 identified events are extremely accurate and correspond very well to the major events of the period.",
                "For example, the defeat of Bob Dole, election of Tony Blair, Missile attack on Iraq, etc.",
                "Recall that selecting the features for one event should minimize the cost in Eq. 2 such that 1) the number of features span different events, and 2) not all features relevant to an event will be selected, e.g., the feature Clinton is representative to e12 but since Clinton relates to many other events, its time domain signal is far different from those of other representative features like Dole and Bob.",
                "The number of documents of a detected event is roughly estimated by the number of indexed documents containing the representative features.",
                "We can see that all 17 important aperiodic events are popularly reported events.",
                "After 742 minutes of computation time, we detected 23, 525 less reported aperiodic events from 83,471 LH features.",
                "Table 1 lists the top 5 detected aperiodic events (e18 − e22) with respect to the cost.",
                "We found that these 5 events are actually very trivial events with only a few news reports, and are usually subsumed by some larger topics.",
                "For example, e22 is one of the rescue events in an airplane hijack topic.",
                "One advantage of our UG Algorithm for discovering less-reported aperiodic events is that we are able to precisely detect the true event period. 7.4 Detecting Periodic Events Among the 1,087 HL features, 330 important periodic events were detected within 10 minutes of computing time.",
                "Table 1 lists the top 5 detected periodic events with respect to the cost (e23 − e27).",
                "All of the detected periodic events are indeed valid, and correspond to real life periodic events.",
                "The GMM model is able to detect and estimate the bursty period nicely although it cannot distinguish the slight difference between every Monday-Friday and all weekdays as shown in e23.",
                "We also notice that e26 is actually a subset of e27 (soccer game), which is acceptable since the Sheffield league results are announced independently every weekend. 8.",
                "CONCLUSIONS This paper took a whole new perspective of analyzing feature trajectories as time domain signals.",
                "By considering the word document frequencies in both time and frequency domains, we were able to derive many new characteristics about news streams that were previously unknown, e.g., the different distributions of stopwords during weekdays and weekends.",
                "For the first time in the area of TDT, we applied a systematic approach to automatically detect important and less-reported, periodic and aperiodic events.",
                "The key idea of our work lies in the observations that (a)periodic events have (a)periodic representative features and (un)important events have (in)active representative features, differentiated by their power spectrums and time periods.",
                "To address the real event detection problem, a simple and effective mixture density-based approach was used to identify feature bursts and their associated bursty periods.",
                "We also designed an unsupervised greedy algorithm to detect both aperiodic and periodic events, which was successful in detecting real events as shown in the evaluation on a real news stream.",
                "Although we have not made any benchmark comparison against another approach, simply because there is no previous work in the addressed problem.",
                "Future work includes evaluating the recall of detected events for a labeled news stream, and comparing our model against the closest equivalent methods, which currently are limited to the methods of Kleinberg [12] (which can only detect certain type of bursty events depending on parameter settings), Fung et al. [9], and Swan and Allan [18].",
                "Nevertheless, we believe our simple and effective method will be useful for all TDT practitioners, and will be especially useful for the initial exploratory analysis of news streams. 9.",
                "REFERENCES [1] Apache lucene-core 2.0.0, http://lucene.apache.org. [2] Google news alerts, http://www.google.com/alerts. [3] Reuters corpus, http://www.reuters.com/researchandstandards/corpus/. [4] J. Allan.",
                "Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. [5] J. Allan, V. Lavrenko, and H. Jin.",
                "First story detection in tdt is hard.",
                "In CIKM, pages 374-381, 2000. [6] J. Allan, C. Wade, and A. Bolivar.",
                "Retrieval and novelty detection at the sentence level.",
                "In SIGIR, pages 314-321, 2003. [7] T. Brants, F. Chen, and A. Farahat.",
                "A system for new event detection.",
                "In SIGIR, pages 330-337, 2003. [8] A. P. Dempster, N. M. Laird, and D. B. Rubin.",
                "Maximum likelihood from incomplete data via the EM algorithm.",
                "Journal of the Royal Statistical Society, 39(1):1-38, 1977. [9] G. P. C. Fung, J. X. Yu, P. S. Yu, and H. Lu.",
                "Parameter free bursty events detection in text streams.",
                "In VLDB, pages 181-192, 2005. [10] Q.",
                "He, K. Chang, and E.-P. Lim.",
                "A model for anticipatory event detection.",
                "In ER, pages 168-181, 2006. [11] Q.",
                "He, K. Chang, E.-P. Lim, and J. Zhang.",
                "Bursty feature reprensentation for clustering text streams.",
                "In SDM, accepted, 2007. [12] J. Kleinberg.",
                "Bursty and hierarchical structure in streams.",
                "In SIGKDD, pages 91-101, 2002. [13] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins.",
                "On the bursty evolution of blogspace.",
                "In WWW, pages 159-178, 2005. [14] G. Kumaran and J. Allan.",
                "Text classification and named entities for new event detection.",
                "In SIGIR, pages 297-304, 2004. [15] Q. Mei and C. Zhai.",
                "Discovering evolutionary theme patterns from text: an exploration of temporal text mining.",
                "In SIGKDD, pages 198-207, 2005. [16] W. D. Penny.",
                "Kullback-liebler divergences of normal, gamma, dirichlet and wishart densities.",
                "Technical report, 2001. [17] N. Stokes and J. Carthy.",
                "Combining semantic and syntactic document classifiers to improve first story detection.",
                "In SIGIR, pages 424-425, 2001. [18] R. Swan and J. Allan.",
                "Automatic generation of overview timelines.",
                "In SIGIR, pages 49-56, 2000. [19] M. Vlachos, C. Meek, Z. Vagena, and D. Gunopulos.",
                "Identifying similarities, periodicities and bursts for online search queries.",
                "In SIGMOD, pages 131-142, 2004. [20] Y. Yang, T. Pierce, and J. Carbonell.",
                "A study of retrospective and on-line event detection.",
                "In SIGIR, pages 28-36, 1998. [21] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topic-conditioned novelty detection.",
                "In SIGKDD, pages 688-693, 2002.",
                "Table 1: All important aperiodic events (e1 − e17), top 5 less-reported aperiodic events (e18 − e22) and top 5 important periodic events (e23 − e27).",
                "Detected Event and Bursty Period Doc # True Event e1(Sali,Berisha,Albania,Albanian,March) 02/02/199705/29/1997 1409 Albanians president Sali Berisha lost in an early election and resigned, 12/1996-07/1997. e2(Seko,Mobutu,Sese,Kabila) 03/22/1997-06/09/1997 2273 Zaires president Mobutu Sese coordinated the native rebellion and failed on 05/16/1997. e3(Marxist,Peruvian) 11/19/1996-03/05/1997 824 Peru rebels (Tupac Amaru revolutionary Movement) led a hostage siege in Lima in early 1997. e4(Movement,Tupac,Amaru,Lima,hostage,hostages) 11/16/1996-03/20/1997 824 The same as e3. e5(Kinshasa,Kabila,Laurent,Congo) 03/26/199706/15/1997 1378 Zaire was renamed the Democratic Republic of Congo on 05/16/1997. e6(Jospin,Lionel,June) 05/10/1997-07/09/1997 605 Following the early General Elections circa 06/1997, Lionel Jospin was appointed Prime Minister on 06/02/1997. e7(Iraq,missile) 08/31/1996-09/13/1996 1262 U.S. fired missile at Iraq on 09/03/1996 and 09/04/1996. e8(Kurdish,Baghdad,Iraqi) 08/29/1996-09/09/1996 1132 Iraqi troop fought with Kurdish faction circa 09/1996. e9(May,Blair) 03/24/1997-07/04/1997 1049 Tony Blair became the Primary Minister of the United Kingdom on 05/02/1997. e10(slalom,skiing) 12/05/1996-03/21/1997 253 Slalom Game of Alpine Skiing in 01/1997-02/1997. e11(Interim,months) 09/24/1996-12/31/1996 3063 Tokyo released company interim results for the past several months in 09/1996-12/1996. e12(Dole,Bob) 09/09/1996-11/24/1996 1599 Dole Bob lost the 1996 US presidential election. e13(July,Sen) 06/25/1997-06/25/1997 344 Cambodias Prime Minister Hun Sen launched a bloody military coup in 07/1997. e14(Hebron) 10/15/1996-02/14/1997 2098 Hebron was divided into two sectors in early 1997. e15(April,Easter) 02/23/1997-05/04/1997 480 Easter feasts circa 04/1997 (for western and Orthodox). e16(Diluted,Group) 04/27/1997-07/20/1997 1888 Tokyo released all 96/97 group results in 04/199707/1997. e17(December,Christmas) 11/17/1996-01/26/1997 1326 Christmas feast in late 12/1997. e18(Kolaceva,winter,Together,promenades,Zajedno, Slobodan,Belgrade,Serbian,Serbia,Draskovic,municipal, Kragujevac) 1/25/1997 3 University students organized a vigil on Kolaceva street against government on 1/25/1997. e19(Tutsi,Luvengi,Burundi,Uvira,fuel,Banyamulenge, Burundian,Kivu,Kiliba,Runingo,Kagunga,Bwegera) 10/19/1996 6 Fresh fighting erupted around Uvira between Zaire armed forces and Banyamulengs Tutsi rebels on 10/19/1996. e20(Malantacchi,Korea,Guy,Rider,Unions,labour, Trade,unions,Confederation,rammed,Geneva,stoppages, Virgin,hire,Myongdong,Metalworkers) 1/11/1997 2 Marcello Malantacchi secretary general of the International Metalworkers Federation and Guy Rider who heads the Geneva office of the International Confederation of Free Trade Unions attacked the new labour law of South Korea on 1/11/1997. e21(DBS,Raﬄes) 8/17/1997 9 The list of the unit of Singapore DBS Land Raﬄes Holdings plans on 8/17/1997. e22(preserver,fuel,Galawa,Huddle,Leul,Beausse) 11/24/1996 3 Rescued a woman and her baby during a hijacked Ethiopian plane that ran out of fuel and crashed into the sea near Le Galawa beach on 11/24/1996. e23(PRICE,LISTING,MLN,MATURITY,COUPON, MOODY,AMT,FIRST,ISS,TYPE,PAY,BORROWER) Monday-Friday/week 7966 Announce bond price on all weekdays. e24(Unaudited,Ended,Months,Weighted,Provision,Cost, Selling,Revenues,Loss,Income,except,Shrs,Revs) every season 2264 Net income-loss reports released by companies in every season. e25(rating,Wall,Street,Ian) Monday-Friday/week 21767 Stock reports from Wall Street on all weekdays. e26(Sheffield,league,scoring,goals,striker,games) every Friday, Saturday and Sunday 574 Match results of Sheffield soccer league were published on Friday, Saturday and Sunday 10 times than other 4 days. e27(soccer,matches,Results,season,game,Cup,match, victory,beat,played,play,division) every Friday, Saturday and Sunday 2396 Soccer games held on Friday, Saturday and Sunday 7 times than other 4 days."
            ],
            "original_annotated_samples": [
                "In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with <br>gaussian</br> density and periodic features with <br>gaussian</br> mixture densities, and subsequently detected each features burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events.",
                "Unlike Kleinbergs burst identification algorithm [12], we can identify both significant and trivial bursts without the need to set any parameters. 5.1 Detecting Aperiodic Features Bursts For each feature in HH and HL, we truncate its trajectory by keeping only the bursty period, which is modeled with a <br>gaussian</br> distribution.",
                "For example, Figure 8 shows the word feature Iraq with a burst circa 09/06/1996 being modeled as a <br>gaussian</br>.",
                "Its bursty period is defined by [μf − σf , μf + σf ] as shown in Figure 8(b). 5.2 Detecting Periodic Features Bursts Since we have computed the DP for a periodic feature f, we can easily model its periodic feature trajectory yf using 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) original DFIDF:time 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 burst= [μ-σ, μ+σ] (b) identifying burst Figure 8: Modeling Iraqs time series as a truncated <br>gaussian</br> with μ = 09/06/1996 and σ = 6.26. a mixture of K = T/Pf Gaussians: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , where the parameter set θf = {αk, μk, σk}K k=1 comprises: • αk is the probability of assigning yf into the kth <br>gaussian</br>. αk > 0, ∀k ∈ [1, K] and K k=1 αk = 1; • μk/σk is mean/standard deviation of the kth Gaussian.",
                "The well known Expectation Maximization (EM) [8] algorithm is used to compute the mixing proportions αk, as well as the individual <br>gaussian</br> density parameters μk and σK ."
            ],
            "translated_annotated_samples": [
                "En este artículo, 1) primero aplicamos análisis espectral para categorizar características de diferentes tipos de eventos: importantes y poco reportados, periódicos y aperiódicos; 2) modelamos las características aperiódicas con densidad <br>gaussiana</br> y las características periódicas con densidades de mezcla <br>gaussiana</br>, y posteriormente detectamos cada ráfaga de características mediante el enfoque gaussiano truncado; 3) propusimos un algoritmo de detección de eventos codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos.",
                "A diferencia del algoritmo de identificación de ráfagas de Kleinberg [12], podemos identificar tanto ráfagas significativas como triviales sin necesidad de establecer ningún parámetro. 5.1 Detección de ráfagas de características aperiódicas Para cada característica en HH y HL, truncamos su trayectoria manteniendo solo el período de ráfagas, el cual está modelado con una distribución <br>gaussiana</br>.",
                "Por ejemplo, la Figura 8 muestra la característica de la palabra Iraq con una explosión alrededor del 09/06/1996 modelada como una Gaussiana.",
                "Su período de ráfagas está definido por [μf − σf , μf + σf ] como se muestra en la Figura 8(b). 5.2 Detección de características periódicas de ráfagas Dado que hemos calculado el DP para una característica periódica f, podemos modelar fácilmente su trayectoria de características periódicas yf usando 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) DFIDF original: tiempo 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 ráfaga= [μ-σ, μ+σ] (b) identificación de ráfaga Figura 8: Modelando la serie temporal de Iraq como una Gaussiana truncada con μ = 09/06/1996 y σ = 6.26. una mezcla de K = T/Pf Gaussianas: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , donde el conjunto de parámetros θf = {αk, μk, σk}K k=1 comprende: • αk es la probabilidad de asignar yf a la k-ésima Gaussiana. αk > 0, ∀k ∈ [1, K] y K k=1 αk = 1; • μk/σk es la media/desviación estándar de la k-ésima Gaussiana.",
                "El conocido algoritmo Expectation Maximization (EM) [8] se utiliza para calcular las proporciones de mezcla αk, así como los parámetros individuales de densidad <br>gaussiana</br> μk y σK."
            ],
            "translated_text": "Analizando Trayectorias de Características para la Detección de Eventos Qi He qihe@pmail.ntu.edu.sg Kuiyu Chang ASKYChang@ntu.edu.sg Ee-Peng Lim ASEPLim@ntu.edu.sg Escuela de Ingeniería Informática Universidad Tecnológica de Nanyang Bloque N4, Avenida Nanyang, Singapur 639798 RESUMEN Consideramos el problema de analizar trayectorias de palabras en los dominios del tiempo y la frecuencia, con el objetivo específico de identificar palabras importantes y menos reportadas, periódicas y aperiódicas. Un conjunto de palabras con tendencias idénticas puede agruparse para reconstruir un evento de manera completamente no supervisada. La frecuencia del documento de cada palabra a lo largo del tiempo se trata como una serie temporal, donde cada elemento es el puntaje de frecuencia del documento - frecuencia inversa del documento (DFIDF) en un punto temporal. En este artículo, 1) primero aplicamos análisis espectral para categorizar características de diferentes tipos de eventos: importantes y poco reportados, periódicos y aperiódicos; 2) modelamos las características aperiódicas con densidad <br>gaussiana</br> y las características periódicas con densidades de mezcla <br>gaussiana</br>, y posteriormente detectamos cada ráfaga de características mediante el enfoque gaussiano truncado; 3) propusimos un algoritmo de detección de eventos codicioso no supervisado para detectar tanto eventos aperiódicos como periódicos. Todos los métodos anteriores se pueden aplicar a datos de series temporales en general. Evaluamos exhaustivamente nuestros métodos en el Corpus de Noticias de Reuters de 1 año [3] y demostramos que fueron capaces de descubrir eventos significativos aperiódicos y periódicos. Categorías y Descriptores de Asignaturas: H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales: Algoritmos, Experimentación. 1. INTRODUCCIÓN Hay más de 4,000 fuentes de noticias en línea en el mundo. Supervisar manualmente todos ellos en busca de eventos importantes se ha vuelto difícil o prácticamente imposible. De hecho, la comunidad de detección y seguimiento de temas (TDT) ha estado tratando durante muchos años de encontrar una solución práctica para ayudar a las personas a monitorear las noticias de manera efectiva. Desafortunadamente, el Santo Grial sigue siendo esquivo, ya que la gran mayoría de las soluciones de TDT propuestas para la detección de eventos [20, 5, 17, 4, 21, 7, 14, 10] son demasiado simplistas (basadas en la similitud del coseno [5]) o impracticables debido a la necesidad de ajustar un gran número de parámetros [9]. La ineficacia de las tecnologías actuales de TDT se puede ilustrar fácilmente suscribiéndose a cualquiera de los muchos servicios de alertas de noticias en línea, como el líder de la industria Google News Alerts, que genera más del 50% de falsas alarmas. Como prueba adicional, portales como Yahoo adoptan un enfoque más pragmático al requerir que todas las alertas de noticias generadas por máquinas pasen por un operador humano para su confirmación antes de enviarlas a los suscriptores. En lugar de abordar el problema con variaciones del mismo martillo (similitud coseno y TFIDF), es necesario contar con una comprensión fundamental de las características de los datos de flujo de noticias antes de que se puedan lograr avances importantes en TDT. Por lo tanto, en este artículo, examinamos noticias y tendencias de características desde la perspectiva de analizar una señal de palabras de series temporales. Trabajos anteriores como [9] han intentado reconstruir un evento con sus características representativas. Sin embargo, en muchas tareas de detección de eventos predictivos (es decir, detección de eventos retrospectivos), hay un vasto conjunto de características potenciales solo para un conjunto fijo de observaciones (es decir, los estallidos obvios). De estas características, a menudo solo se espera que un pequeño número sea útil. En particular, estudiamos el novedoso problema de analizar trayectorias de características para la detección de eventos, utilizando una técnica conocida de procesamiento de señales: identificar correlaciones distribucionales entre todas las características mediante análisis espectral. Para evaluar nuestro método, posteriormente proponemos un algoritmo de detección de eventos no supervisado para flujos de noticias. 0 0.2 0.4 0.6 0.8 8/20/1996 12/8/1996 3/28/1997 7/16/1997 Pascua Abril (a) evento aperiódico 0 0.1 0.2 0.3 0.4 8/20/1996 12/8/1996 3/28/1997 7/16/1997 No auditado Finalizado (b) evento periódico Figura 1: Correlación de características (DFIDF:tiempo) entre a) Pascua y Abril b) No auditado y Finalizado. Como ejemplo ilustrativo, considera la correlación entre las palabras Pascua y abril del Corpus de Reuters. A partir del gráfico de su DFIDF normalizado en la Figura 1(a), observamos la gran superposición entre las dos palabras alrededor de 04/1997, lo que significa que probablemente ambas pertenecen al mismo evento durante ese tiempo (festividad de Pascua). En este ejemplo, el evento oculto de la festividad de Pascua es un evento aperiódico típico e importante en datos de 1 año. Otro ejemplo se muestra en la Figura 1(b), donde las palabras \"No auditado\" y \"Finalizado 1\" del Corpus de Reuters son el conjunto de datos predeterminado para todos los ejemplos y presentan un comportamiento similar durante períodos de 3 meses. Estas dos palabras en realidad se originaron a partir del mismo evento periódico, informes de ganancias y pérdidas, que son publicados trimestralmente por empresas cotizadas en bolsa. Otras observaciones extraídas de la Figura 1 son: 1) el período de actividad intensa de abril es mucho más largo que el de Semana Santa, lo que sugiere que abril puede estar presente en otros eventos durante el mismo período; 2) No auditado tiene un valor promedio de DFIDF más alto que Finalizado, lo que indica que No auditado es más representativo para el evento subyacente. Estos dos ejemplos son solo la punta del iceberg entre todas las tendencias de palabras y correlaciones ocultas en un flujo de noticias como Reuters. Si se puede descubrir un gran número de ellos, podría ayudar significativamente en las tareas de TDT. En particular, indica la importancia de extraer características correlacionadas para detectar eventos correspondientes. Para resumir, postulamos que: 1) Un evento se describe por sus características representativas. Un evento periódico tiene una lista de características periódicas y un evento aperiódico tiene una lista de características aperiódicas; 2) Las características representativas del mismo evento comparten distribuciones similares en el tiempo y están altamente correlacionadas; 3) Un evento importante tiene un conjunto de características representativas activas (ampliamente reportadas), mientras que un evento no importante tiene un conjunto de características representativas inactivas (menos reportadas); 4) Una característica puede ser incluida por varios eventos con superposiciones en los marcos de tiempo. Basándonos en estas observaciones, podemos extraer características representativas dadas un evento o detectar un evento a partir de una lista de características altamente correlacionadas. En este artículo, nos enfocamos en este último aspecto, es decir, cómo se pueden descubrir características correlacionadas para formar un evento de manera no supervisada. 1.1 Contribuciones Este artículo tiene tres contribuciones principales: • Hasta donde sabemos, nuestro enfoque es el primero en categorizar características de palabras para eventos heterogéneos. Específicamente, cada característica de palabra se clasifica en uno de los siguientes cinco tipos de características basados en la fuerza de su espectro de potencia y periodicidad: 1) HH (alta potencia y alta/larga periodicidad): eventos aperiódicos importantes, 2) HL (alta potencia y baja periodicidad): eventos periódicos importantes, 3) LH (baja potencia y alta periodicidad): eventos aperiódicos no importantes, 4) LL (baja potencia y baja periodicidad): no eventos, y 5) SW (palabras vacías), un subconjunto de LL con mayor potencia y periodicidad que comprende palabras vacías, que no contienen información. • Proponemos un enfoque simple y efectivo basado en densidad de mezcla para modelar y detectar ráfagas de características. • Presentamos un algoritmo de detección de eventos no supervisado para detectar eventos tanto aperiódicos como periódicos. Nuestro algoritmo ha sido evaluado en un flujo de noticias reales para demostrar su efectividad. 2. TRABAJO RELACIONADO Este trabajo está motivado en gran medida por una familia más amplia de problemas conocidos colectivamente como Detección y Seguimiento de Temas (TDT) [20, 5, 17, 4, 21, 7, 14, 10]. Además, la mayoría de las investigaciones de TDT hasta ahora se han centrado en agrupar/clasificar documentos en tipos de temas, identificar oraciones novedosas para eventos nuevos, etc., sin prestar mucha atención al análisis de la trayectoria de las palabras con respecto al tiempo. Swan y Allan [18] intentaron por primera vez usar términos que co-ocurren para construir un evento. Sin embargo, solo consideraron entidades nombradas y pares de frases nominales, sin tener en cuenta sus periodicidades. Por el contrario, nuestro artículo considera todo lo anterior. Recientemente, ha habido un gran interés en modelar un evento en flujos de texto como un estallido de actividades al incorporar información temporal. El trabajo seminal de Kleinberg describió cómo se pueden extraer características explosivas de flujos de texto utilizando un modelo de autómata infinito [12], lo que inspiró toda una serie de aplicaciones como la identificación de comunidades explosivas de Kumar a partir de gráficos de blogs [13], la sumarización de temas evolutivos en flujos de texto de Meis [15], el agrupamiento de flujos de texto utilizando características explosivas de Hes [11], etc. Sin embargo, ninguno de los trabajos existentes identificó específicamente características para eventos, excepto Fung et al. [9], quienes agruparon características llamativas para identificar varios eventos llamativos. Nuestro trabajo difiere de [9] en varias formas: 1) analizamos cada característica individual, no solo las características explosivas; 2) clasificamos las características a lo largo de dos dimensiones categóricas (periodicidad y potencia), dando en total cinco tipos de características principales; 3) no restringimos que cada característica pertenezca exclusivamente a un solo evento. Las técnicas de análisis espectral han sido utilizadas previamente por Vlachos et al. [19] para identificar periodicidades y ráfagas en los registros de consultas. Su enfoque estaba en detectar múltiples periodicidades a partir del gráfico del espectro de potencia, las cuales luego se utilizaron para indexar palabras para la búsqueda por ráfagas. En este artículo, utilizamos análisis espectral para clasificar las características de las palabras a lo largo de dos dimensiones, a saber, periodicidad y espectro de potencia, con el objetivo final de identificar eventos tanto periódicos como no periódicos y explosivos. 3. REPRESENTACIÓN DE DATOS Sea T la duración/período (en días) de un flujo de noticias, y F representa el espacio de características de palabras completo en el Modelo de Espacio Vectorial (VSM) estático clásico. 3.1 Clasificación de Periodicidad de Eventos Dentro de T, pueden existir ciertos eventos que ocurren solo una vez, por ejemplo, la elección de Tony Blair como Primer Ministro del Reino Unido, y otros eventos recurrentes de diversas periodicidades, por ejemplo, partidos de fútbol semanales. Por lo tanto, categorizamos todos los eventos en dos tipos: aperiódicos y periódicos, definidos de la siguiente manera. Definición 1. (Evento aperiódico) Un evento es aperiódico dentro de T si solo ocurre una vez. Definición 2. (Evento periódico) Si los eventos de un cierto género de eventos ocurren regularmente con una periodicidad fija P ≤ T/2, decimos que este género particular de eventos es periódico, y cada evento miembro se califica como un evento periódico. Ten en cuenta que la definición de aperiódico es relativa, es decir, es verdadera solo para un T dado y puede ser inválida para cualquier otro T > T. Por ejemplo, el evento de la fiesta de Navidad es aperiódico para T ≤ 365 pero periódico para T ≥ 730. 3.2 Características Representativas Intuitivamente, un evento puede ser descrito de manera muy concisa por unas pocas características de palabras discriminativas y representativas y viceversa, por ejemplo, huracán, barrido y golpe podrían ser características representativas de un evento del género de huracanes. Asimismo, un conjunto de características fuertemente correlacionadas podría ser utilizado para reconstruir una descripción de un evento, asumiendo que las características fuertemente correlacionadas son representativas. El vector de representación de una característica de palabra se define de la siguiente manera: Definición 3. (Trayectoria de la Característica) La trayectoria de una característica de palabra f puede escribirse como la secuencia yf = [yf (1), yf (2), . . . , yf (T)], donde cada elemento yf (t) es una medida de la característica f en el tiempo t, que podría definirse utilizando la puntuación normalizada DFIDF yf (t) = DFf (t) N(t) × log( N DFf ), donde DFf (t) es el número de documentos (DF local) que contienen la característica f en el día t, DFf es el número total de documentos (DF global) que contienen la característica f en T, N(t) es el número de documentos para el día t, y N es el número total de documentos en T. 4. En esta sección, mostramos cómo se pueden extraer características representativas para eventos (poco) importantes o (a)periódicos. 4.1 Análisis Espectral para el Período Dominante Dada una característica f, descomponemos su trayectoria de características yf = [yf (1), yf (2), ..., yf (T)] en la secuencia de T números complejos [X1, . . . , XT ] a través de la transformada discreta de Fourier (DFT): Xk = T t=1 yf (t)e− 2πi T (k−1)t , k = 1, 2, . . . , T. La DFT puede representar la serie temporal original como una combinación lineal de sinusoides complejas, lo cual se ilustra mediante la transformada discreta de Fourier inversa (IDFT): yf (t) = 1 T T k=1 Xke 2πi T (k−1)t , t = 1, 2, . . . , T, donde el coeficiente de Fourier Xk denota la amplitud del sinusoides con frecuencia k/T. La trayectoria original puede ser reconstruida con solo las frecuencias dominantes, las cuales pueden ser determinadas a partir del espectro de potencia utilizando el popular estimador periodograma. El periodograma es una secuencia de la magnitud al cuadrado de los coeficientes de Fourier, Xk^2, k = 1, 2, . . . , T/2, que indica la potencia de la señal en la frecuencia k/T en el espectro. A partir del espectro de potencia, se elige el período dominante como el inverso de la frecuencia con el espectro de potencia más alto, de la siguiente manera. Definición 4. (Período Dominante) El período dominante (DP) de una característica dada f es Pf = T/ arg max k Xk 2. Por lo tanto, tenemos la Definición 5. (Espectro de Potencia Dominante) El espectro de potencia dominante (DPS) de una característica dada f es Sf = Xk 2 , con Xk 2 ≥ Xj 2 , ∀j = k. 4.2 Categorización de Características El DPS de una trayectoria de características es un indicador fuerte de su actividad en la frecuencia especificada; cuanto mayor sea el DPS, es más probable que la característica sea explosiva. Al combinar DPS con DP, categorizamos todas las características en cuatro tipos: 2 Normalizamos yf (t) como yf (t) = yf (t)/ T i=1 yf (i) para que pueda interpretarse como una probabilidad. • HH: alta Sf, aperiódico o periódico a largo plazo (Pf > T/2); • HL: alta Sf, periódico a corto plazo (Pf ≤ T/2); • LH: baja Sf, aperiódico o periódico a largo plazo; • LL: baja Sf, periódico a corto plazo. La frontera entre los periodos a largo plazo y a corto plazo se establece en T/2. Sin embargo, distinguir entre un DPS alto y bajo no es sencillo, lo cual se abordará más adelante. Propiedades de diferentes conjuntos de características Para comprender mejor las propiedades de HH, HL, LH y LL, seleccionamos cuatro características, Navidad, fútbol, DBS y tu como ejemplos ilustrativos. Dado que la frontera entre el espectro de alta y baja potencia no está clara, estos ejemplos seleccionados tienen un rango relativo amplio de valores de espectro de potencia. La figura 2(a) muestra la trayectoria de DFIDF para la Navidad con un pico distintivo alrededor del día de Navidad. Para el conjunto de datos de Reuters de 1 año, la Navidad se clasifica como un evento aperiódico típico con Pf = 365 y Sf = 135.68, como se muestra en la Figura 2(b). Claramente, el valor de Sf = 135.68 es razonable para un evento conocido por ser intermitente como la Navidad. 0 0.5 1 1.5 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) Navidad(DFIDF:tiempo) 0 50 100 150 0.00 0.13 0.25 0.37 0.50 P=365 S=135.68 (b) Navidad(S:frecuencia) Figura 2: Característica Navidad con un Sf relativamente alto y un Pf a largo plazo. La trayectoria de DFIDF para el fútbol se muestra en la Figura 3(a), de la cual podemos observar que hay un estallido regular cada 7 días, lo cual es nuevamente verificado por su valor calculado de Pf = 7, como se muestra en la Figura 3(b). Usando el conocimiento del dominio de que los partidos de fútbol tienen más encuentros cada sábado, lo que lo convierte en un evento periódico típico y ampliamente reportado, consideramos que el valor de Sf = 155.13 es alto. 0 0.2 0.4 0.6 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) fútbol (DFIDF:tiempo) 0 50 100 150 200 0.00 0.13 0.25 0.37 0.50 P=7 S=155.13 (b) fútbol (S:frecuencia) Figura 3: Característica fútbol con un Sf relativamente alto y un Pf a corto plazo. A partir de la trayectoria de DFIDF para DBS en la Figura 4(a), podemos deducir de inmediato que DBS es una palabra poco frecuente con un aumento trivial el 17/08/1997 correspondiente a los planes de DBS Land Raﬄes Holdings. Esto se confirma por el largo período de Pf = 365 y la baja potencia de Sf = 0.3084 como se muestra en la Figura 4(b). Además, dado que este evento aperiódico solo se informa en algunas noticias durante un corto período de unos pocos días, por lo tanto, decimos que su bajo valor de potencia de Sf = 0.3084 es representativo de eventos poco importantes. El ejemplo más confuso se muestra en la Figura 5 para la palabra \"your\", que se ve muy similar al gráfico para fútbol en la Figura 3. A primera vista, podríamos sentirnos tentados a agrupar tanto tu como el fútbol en la misma categoría de HL o LL, ya que ambas distribuciones se ven similares y tienen el mismo período dominante de aproximadamente una semana. Sin embargo, más adelante 0 0.05 0.1 0.15 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) DBS(DFIDF:tiempo) 0 0.1 0.2 0.3 0.4 0.00 0.13 0.25 0.37 0.50 P=365 S=0.3084 (b) DBS(S:frecuencia) Figura 4: Característica DBS con Sf relativamente bajo y Pf a largo plazo. El análisis indica que la periodicidad de su es debido a las diferencias en el recuento de documentos para los días de la semana (promedio de 2,919 por día) y los fines de semana (promedio de 479 por día). Uno habría esperado que la periodicidad de una palabra vacía como \"tu\" fuera de un día. Además, a pesar de nuestra normalización de DFIDF, el desequilibrio entre los días de la semana y los fines de semana aún prevalecía; las palabras vacías ocurren 4 veces más frecuentemente los fines de semana que los días de semana. Por lo tanto, el DPS sigue siendo el único factor distintivo entre tu (Sf = 9.42) y el fútbol (Sf = 155.13). Sin embargo, es muy peligroso concluir simplemente que un valor de potencia de S = 9.42 corresponde a una característica de palabra vacía. 0 0.05 0.1 0.15 0.2 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) tu(DFIDF:tiempo) 0 5 10 0.00 0.13 0.25 0.37 0.50 P=7 S=9.42 (b) tu(S:frecuencia) Figura 5: Característica tu como un ejemplo confundido con la característica fútbol. Antes de presentar nuestra solución a este problema, veamos otro ejemplo de LL como se muestra en la Figura 6 para beenb, que en realidad es un error tipográfico confirmado. Por lo tanto, clasificamos beenb como una característica ruidosa que no contribuye a ningún evento. Claramente, la trayectoria de tu es muy diferente de beenb, lo que significa que el primero debe considerarse por separado. 0 0.001 0.002 0.003 0.004 8/20/1996 12/8/1996 3/28/1997 7/16/1997 (a) beenb(DFIDF:time) 1.20E-05 1.20E-05 1.20E-05 1.20E-05 1.20E-05 0.003 0.126 0.249 0.373 0.496 P=8 S=1.20E-05 (b) beenb(S:frequency) Figura 6: Característica beenb con Sf relativamente bajo y Pf a corto plazo. Conjunto de características de palabras vacías (SW) Basándonos en el análisis anterior, nos damos cuenta de que debe haber otro conjunto de características entre HL y LL que corresponda al conjunto de palabras vacías. Las características de este conjunto tienen un DPS moderado y un período dominante bajo pero conocido. Dado que es difícil distinguir este conjunto de características de HL y LL solo basándose en DPS, introducimos otro factor llamado promedio de DFIDF (DFIDF). Como se muestra en la Figura 5, características como la tuya suelen tener un DPS más bajo que una característica HL como el fútbol, pero tienen un DFIDF mucho más alto que otra característica ruidosa LL como \"beenb\". Dado que tales propiedades suelen ser características de las palabras vacías, agrupamos características como \"tu\" en el conjunto de características de palabras vacías (SW) recién definido. Dado que establecer los umbrales de DPS y DFIDF para identificar las palabras vacías es más un arte que una ciencia, propusimos un algoritmo heurístico HS, Algoritmo 1. La idea básica es utilizar solo noticias de días laborables para identificar palabras vacías. Los fines de semana aquí también incluyen días festivos que caen en días laborables. El conjunto SW se inicialmente alimenta con un pequeño conjunto de 29 stopwords populares utilizadas por el motor de búsqueda de Google. Algoritmo 1 Detección heurística de palabras vacías (HS) Entrada: Conjunto de palabras vacías semilla, trayectorias semanales de todas las palabras 1: A partir del conjunto semilla SW, calcular el DPS máximo como UDPS, el DFIDF máximo como UDFIDF y el mínimo de DFIDF como LDFIDF. 2: para fi ∈ F hacer 3: Calcular DFT para fi. 4: si Sfi ≤ UDPS y DFIDFfi ∈ [LDFIDF, UDFIDF] entonces 5: fi → SW 6: F = F - fi 7: fin si 8: fin para Resumen de la Categorización de Características Después de generar el conjunto SW, se eliminan todas las palabras vacías de F. Luego, establecemos el límite entre DPS alto y bajo como el límite superior de los DPS de los conjuntos SW. Una visión general de los cinco conjuntos de características se muestra en la Figura 7. Figura 7: Los 5 conjuntos de características para eventos. 5. IDENTIFICACIÓN DE RÁFAGAS PARA CARACTERÍSTICAS Dado que solo las características de HH, HL y LH son significativas y podrían ser representativas de algunos eventos, eliminamos todas las demás características clasificadas como LL o SW. En esta sección, describimos cómo se pueden identificar los estallidos a partir de las características restantes. A diferencia del algoritmo de identificación de ráfagas de Kleinberg [12], podemos identificar tanto ráfagas significativas como triviales sin necesidad de establecer ningún parámetro. 5.1 Detección de ráfagas de características aperiódicas Para cada característica en HH y HL, truncamos su trayectoria manteniendo solo el período de ráfagas, el cual está modelado con una distribución <br>gaussiana</br>. Por ejemplo, la Figura 8 muestra la característica de la palabra Iraq con una explosión alrededor del 09/06/1996 modelada como una Gaussiana. Su período de ráfagas está definido por [μf − σf , μf + σf ] como se muestra en la Figura 8(b). 5.2 Detección de características periódicas de ráfagas Dado que hemos calculado el DP para una característica periódica f, podemos modelar fácilmente su trayectoria de características periódicas yf usando 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 (a) DFIDF original: tiempo 0 0.2 0.4 0.6 0.8 8/20/96 12/8/96 3/28/97 7/16/97 ráfaga= [μ-σ, μ+σ] (b) identificación de ráfaga Figura 8: Modelando la serie temporal de Iraq como una Gaussiana truncada con μ = 09/06/1996 y σ = 6.26. una mezcla de K = T/Pf Gaussianas: f(yf = yf (t)|θf ) = K k=1 αk 1 2πσ2 k e − 1 2σ2 k (yf (t)−µk)2 , donde el conjunto de parámetros θf = {αk, μk, σk}K k=1 comprende: • αk es la probabilidad de asignar yf a la k-ésima Gaussiana. αk > 0, ∀k ∈ [1, K] y K k=1 αk = 1; • μk/σk es la media/desviación estándar de la k-ésima Gaussiana. El conocido algoritmo Expectation Maximization (EM) [8] se utiliza para calcular las proporciones de mezcla αk, así como los parámetros individuales de densidad <br>gaussiana</br> μk y σK. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        }
    }
}