{
    "id": "J-70",
    "original_text": "Self-interested Automated Mechanism Design and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents. The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves. Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen. In a recently proposed approach-called automated mechanism design-a mechanism is computed for the preference aggregation setting at hand. This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time. Unlike the earlier work on automated mechanism design that studied a benevolent designer, in this paper we study automated mechanism design problems where the designer is self-interested. In this case, the center cares only about which outcome is chosen and what payments are made to it. The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism. In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen. We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy. Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) combinatorial auction design problem, where the bidders have best-only preferences. We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy. Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1. INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents. Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc. The preference aggregator generally does not know the agents preferences a priori. Rather, the agents report their preferences to the coordinator. Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully. Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen. Manipulability is a pervasive problem across preference aggregation mechanisms. A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.) What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective. This is the classic setting of mechanism design in game theory. In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself. This is the mechanism design setting most relevant to electronic commerce. In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear. It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences. The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments. The most common such constraint is that of individual rationality (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism. For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences. Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it. Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off. On the other hand, the designer will not necessarily choose a social welfare maximizing outcome. For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected. Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0. Classical mechanism design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective. The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]). However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare. If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization. In practice, the designer may also be interested in the outcome per se. For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical. For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed. Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments. In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand. This approach addresses all of the downsides listed above. We formulate the mechanism design problem as an optimization problem. The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types. The output is a nonmanipulable mechanism that is optimal with respect to some objective. This approach is called automated mechanism design. The automated mechanism design approach has four advantages over the classical approach of designing general mechanisms. First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare). Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences. When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally. Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types). Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information. For example, imagine a company automatically creating its procurement mechanism based on statistical knowledge about its suppliers, rather than using a classical descending procurement auction. Fourth, the burden of design is shifted from humans to a machine. However, automated mechanism design requires the mechanism design optimization problem to be solved anew for each setting. Hence its computational complexity becomes a key issue. Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6]. In this paper we study the computational complexity of automated mechanism design in the case of a self-interested designer. This is an important setting for automated mechanism design due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested. We also show that this problem is closely related to a particular optimal (revenue-maximizing) combinatorial auction design problem. 133 The rest of this paper is organized as follows. In Section 2, we justify the focus on nonmanipulable mechanisms. In Section 3, we define the problem we study. In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it. In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen. In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case. Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2. JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of automated mechanism design, we should justify our focus on nonmanipulable mechanisms. After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any nonmanipulable mechanism. This does, however, turn out to be the case: given any mechanism, we can construct a nonmanipulable mechanism whose performance is identical, as follows. We build an interface layer between the agents and the original mechanism. The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer. The resulting outcome is the outcome of the new mechanism. Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism. This argument is known in the mechanism design literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22]. However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.) Given this, we can focus on truthful mechanisms in the rest of the paper. 3. DEFINITIONS We now formalize the automated mechanism design setting. Definition 1. In an automated mechanism design setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize. There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent). In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness. However, in this paper, we focus on the case of a self-interested designer. A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer. Definition 2. A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i. In the case where g = 0 everywhere, the designer is said to be payment maximizing. In the case where payments are not possible, g constitutes the objective function by itself. We now define the kinds of mechanisms under study. By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them. Definition 3. We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing. The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator. The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 Individual rationality (IR) constraints The first type of constraint is the following. The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism. Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.) This type of constraint is called an IR (individual rationality) constraint. There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism. Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type). We will not study this concept in this paper. Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others. Ex post IR means that the agent would always participate even if it knew everybodys type. We will define the latter two notions of IR formally. First, we need to formalize the concept of the fallback outcome. We assume that each agents fallback utility is zero for each one of its types. This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16]. Definition 4. In any automated mechanism design setting with an IR constraint, there is a fallback outcome o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.) We can now to define the notions of individual rationality. Definition 5. Individual rationality (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0. A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments. A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0. The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle). For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium. Definition 6. Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known. Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ). In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )]. The terms involving payments can be left out in the case where payments are not possible. Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report. If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium. Definition 7. Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth. Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )]. In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )]. The terms involving payments can be left out in the case where payments are not possible. 135 3.3 Automated mechanism design We can now define the computational problem we study. Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an automated mechanism design setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective. An interesting special case is the setting where there is only one agent. In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents. Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here. Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here. This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4. PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents. We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts. To demonstrate NPhardness, we reduce from the MINSAT problem. Definition 9 (MINSAT). We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|). We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied. MINSAT was recently shown to be NP-complete [14]. We can now present our result. Theorem 1. Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types. Proof. It is easy to show that the problem is in NP. To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent payment-maximizing deterministic AMD instance. Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables. Let the probability distribution over these types be uniform. Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }. Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}. Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance. We show the instances are equivalent. First, suppose there is a solution to the MINSAT instance. Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ). Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|. For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the MINSAT solution, and π(θc) = |Θ| if c is satisfied. It is straightforward to check that the IR constraint is satisfied. We now check that the agent has no incentive to misreport. If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport. If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport. The final case to check is where the agents type is some θc where c is an unsatisfied clause. In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance. Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent. Clearly the agent is better off reporting truthfully, for a total utility of 0. This establishes that the agent never has an incentive to misreport. Finally, we show that the goal is reached. If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance. Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π. First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}. Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type. Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance. It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v. We claim this assignment is a solution to the MINSAT instance. By the IR constraint, the maximum payment we can extract from any type θv is |Θ|. Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.) Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1. It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses. Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance. Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible. However, it does not yet imply hardness for the special case where payments are not possible. We will prove hardness in this case in the next section. 5. SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible. We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts. Theorem 2. Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types. Proof. It is easy to show that the problem is in NP. To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent self-interested deterministic AMD without payments instance. Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables. Let the probability distribution over these types be uniform. Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }. Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}. Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1. Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance. We show the instances are equivalent. First, suppose there is a solution to the MINSAT instance. Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ). Then, for every v ∈ V , let o(θv) = of(v). For every c ∈ C that is satisfied in the MINSAT solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ . It is straightforward to check that the IR constraint is satisfied. We now check that the agent has no incentive to misreport. If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport. If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport. The final case to check is where the agents type is some θc where c is an unsatisfied clause. In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance. Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely. This establishes that the agent never has an incentive to misreport. Finally, we show that the goal is reached. If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance. Now suppose there is a solution to the AMD instance, given by an outcome function o. First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}. The only other outcome that the mechanism is allowed to choose under the IR constraint is o0. This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance. It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v. We claim this assignment is a solution to the MINSAT instance. By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|. For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).) Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes. It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses. Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance. Both of our hardness results relied on the constraint that the mechanism should be deterministic. In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6. RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of self-interested AMD tractable through linear programming, for any constant number of agents. Theorem 3. Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated. Proof. Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}. The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.) First, we show the IR constraints. For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0. For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0. Now, we show the solution concept constraints. For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ). Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )). All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )). As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents. Thus the problem is solvable in polynomial time. 7. IMPLICATIONS FOR AN OPTIMAL COMBINATORIAL AUCTION DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated mechanism design for a self-interested designer on designing optimal combinatorial auctions. Consider a combinatorial auction with a set S of items for sale. For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi. The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.) The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18]. However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25]. The problem is open even if there are only two items for sale. (The twoitem case with a very special form of complementarity and no substitutability has been solved recently [1].) Suppose we have free disposal-items can be thrown away at no cost. Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.) Definition 10. Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s). We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item. The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type. We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the payment maximizing AMD problem! Theorem 4. Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types. Proof. The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming. To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal combinatorial auction design problem instance with a single bidder with best-only preferences. For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance). Let the expected revenue target value be the same in both instances. We show the instances are equivalent. First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function. Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.) Let the payment functions be the same in both instances. Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution. Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same. It follows that there exists a solution to the optimal auction design instance. Now suppose there exists a solution to the optimal auction design instance. By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item. Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type. If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type. Let the payment functions be the same. Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution. Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same. It follows that there exists a solution to the AMD instance. Fortunately, we can also carry through the easiness result for randomized mechanisms to this combinatorial auction setting-giving us one of the few known polynomial-time algorithms for an optimal combinatorial auction design problem. Theorem 5. Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.) Proof. By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item. There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations. Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8. RELATED RESEARCH ON COMPLEXITY IN MECHANISM DESIGN There has been considerable recent interest in mechanism design in computer science. Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism. The closest piece of earlier work studied the complexity of automated mechanism design by a benevolent designer [5, 6]. Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21]. This is related to mechanism design, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments). Also, there is no explicit reporting of preferences. 9. CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents. The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves. Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen. In a recently emerging approach-called automated mechanism design-a mechanism is computed for the specific preference aggregation setting at hand. This has several advantages, 139 but the downside is that the mechanism design optimization problem needs to be solved anew each time. Unlike earlier work on automated mechanism design that studied a benevolent designer, in this paper we studied automated mechanism design problems where the designer is self-interesteda setting much more relevant for electronic commerce. In this setting, the center cares only about which outcome is chosen and what payments are made to it. The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism. In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen. These hardness results imply hardness in all more general automated mechanism design settings with a self-interested designer. The hardness results apply whether the individual rationality (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation. We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy. Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) combinatorial auction design problem, where the bidders have best-only preferences. We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy. Future research includes studying automated mechanism design with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments). We also want to study the complexity of automated mechanism design in settings where the outcome and type spaces have special structure so they can be represented more concisely. Finally, we plan to assemble a data set of real-world mechanism design problems-both historical and current-and apply automated mechanism design to those problems. 10. REFERENCES [1] M. Armstrong. Optimal multi-object auctions. Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow. The property rights doctrine and demand revelation under incomplete information. In M. Boskin, editor, Economics and human welfare. New York Academic Press, 1979. [3] C. Avery and T. Hendershott. Bundling and optimal auctions of multiple products. Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke. Multipart pricing of public goods. Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm. Complexity of mechanism design. In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm. Automated mechanism design: Complexity results stemming from the single-agent setting. In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm. Computational criticisms of the revelation principle. In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004. Short paper. Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet. Incentives and incomplete information. Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker. Sharing the cost of muliticast transmissions. Journal of Computer and System Sciences, 63:21-41, 2001. Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard. Manipulation of voting schemes. Econometrica, 41:587-602, 1973. [11] T. Groves. Incentives in teams. Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri. Vickrey prices and shortest paths: What is an edge worth? In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan. A polynomial algorithm in linear programming. Soviet Math. Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani. The minimum satisfiability problem. SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham. Truth revelation in rapid, approximately efficient combinatorial auctions. Journal of the ACM, 49(5):577-602, 2002. Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green. Microeconomic Theory. Oxford University Press, 1995. [17] E. S. Maskin and J. Riley. Optimal multi-unit auctions. In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335. Clarendon Press, Oxford, 1989. [18] R. Myerson. Optimal auction design. Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen. Computationally feasible VCG mechanisms. In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen. Algorithmic mechanism design. Games and Economic Behavior, 35:166-196, 2001. Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden. Designing networks for selfish users is hard. In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm. Issues in computational Vickrey auctions. International Journal of Electronic Commerce, 4(3):107-129, 2000. Special Issue on 140 Applying Intelligent Agents for Electronic Commerce. A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite. Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions. Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey. Counterspeculation, auctions, and competitive sealed tenders. Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra. Research problems in combinatorial auctions. Mimeo, version Oct. 29, 2001. 141",
    "original_translation": "Diseño de mecanismos automatizados de interés propio e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les resulte más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente propuesto, llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración de agregación de preferencias actual. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre el diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo. En este caso, al centro solo le importa qué resultado se elige y qué pagos se le hacen. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este contexto, demostramos que el diseño de mecanismos deterministas óptimos es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Luego mostramos cómo permitir la aleatorización en el mecanismo hace que los problemas en este entorno sean computacionalmente fáciles. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (maximizadora de ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar una subasta determinista óptima es NP-completo, pero diseñar una subasta aleatoria óptima es fácil. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Teoría 1. En entornos multiagentes, a menudo se debe elegir un resultado en función de las preferencias informadas por un grupo de agentes. Tales resultados podrían ser presidentes potenciales, planes conjuntos, asignaciones de bienes o recursos, etc. El agregador de preferencias generalmente no conoce las preferencias de los agentes de antemano. Más bien, los agentes informan sus preferencias al coordinador. Desafortunadamente, un agente puede tener un incentivo para informar incorrectamente sus preferencias con el fin de engañar al mecanismo y lograr que seleccione un resultado que sea más deseable para el agente que el resultado que se seleccionaría si el agente revelara sus preferencias de manera honesta. Tal manipulación es indeseable porque los mecanismos de agregación de preferencias están diseñados para agrupar las preferencias de una manera socialmente deseable, y si los agentes revelan sus preferencias de manera insincera, se podría elegir un resultado socialmente indeseable. La manipulabilidad es un problema generalizado en los mecanismos de agregación de preferencias. Un resultado negativo seminal, el teorema de Gibbard-Satterthwaite, muestra que bajo cualquier esquema de agregación de preferencias no dictatorial, si hay al menos 3 posibles resultados, existen preferencias bajo las cuales un agente está mejor reportando falsamente [10, 23]. (Un esquema de agregación de preferencias se llama dictatorial si uno de los agentes dicta el resultado sin importar las preferencias que reporten los otros agentes). Lo que le gustaría hacer al agregador es diseñar un mecanismo de agregación de preferencias para que 1) los agentes interesados reporten sus preferencias de manera veraz, y 2) el mecanismo elija un resultado que sea deseable desde la perspectiva de algún objetivo. Esta es la configuración clásica del diseño de mecanismos en la teoría de juegos. En este documento, estudiamos el caso en el que el diseñador actúa por interés propio, es decir, al diseñador no le importa directamente cómo se relaciona el resultado con las preferencias de los agentes, sino que está más preocupado por su propia agenda sobre cuál resultado debería ser elegido y en maximizar los pagos para sí mismo. Este es el entorno de diseño de mecanismos más relevante para el comercio electrónico. En el caso en que el diseñador del mecanismo esté interesado en maximizar alguna noción de bienestar social, la importancia de recopilar las preferencias de los agentes es clara. Quizás sea menos obvio por qué deberían ser recopilados cuando el diseñador está interesado en sí mismo y, por lo tanto, su objetivo no está directamente relacionado con las preferencias de los agentes. La razón de esto es que a menudo las preferencias de los agentes imponen límites en cómo el diseñador elige el resultado y los pagos. La restricción más común de este tipo es la de racionalidad individual (RI), lo que significa que el mecanismo no puede dejar a ningún agente en una situación peor a la que hubiera estado si no hubiera participado en el mecanismo. Por ejemplo, en el contexto del diseño óptimo de subastas, el diseñador (subastador) solo se preocupa por cuántos ingresos se recaudan, y no en sí mismo por cuán bien la asignación del bien (o bienes) corresponde a las preferencias de los agentes. Sin embargo, el diseñador no puede obligar a un agente a pagar más de lo que valora el paquete de bienes asignado a él. Por lo tanto, incluso un diseñador interesado en sí mismo elegirá un resultado que beneficie razonablemente a los agentes. Por otro lado, el diseñador no necesariamente elegirá un resultado que maximice el bienestar social. Por ejemplo, si el diseñador siempre elige un resultado que maximiza el bienestar social con respecto a las preferencias informadas, y obliga a cada agente a pagar la diferencia entre la utilidad que tiene ahora y la utilidad que habría tenido si no hubiera participado en el mecanismo, es fácil ver que los agentes pueden tener un incentivo para informar incorrectamente sus preferencias, lo que puede llevar realmente a recaudar menos ingresos. De hecho, uno de los resultados contraintuitivos de la teoría del diseño de subastas óptimas es que a veces el bien se asigna a nadie incluso cuando el subastador tiene un precio de reserva de 0. El diseño de mecanismos clásicos proporciona algunos mecanismos generales, que, bajo ciertas suposiciones, satisfacen alguna noción de no manipulabilidad y maximizan algún objetivo. La ventaja de estos mecanismos es que no dependen de información (incluso probabilística) sobre las preferencias de los agentes (por ejemplo, el mecanismo de Vickrey-Clarke-Groves (VCG) [24, 4, 11]), o pueden aplicarse fácilmente a cualquier distribución de probabilidad sobre las preferencias (por ejemplo, el mecanismo dAGVA [8, 2], la subasta de Myerson [18], y la subasta multiunidad de Maskin-Riley [17]). Sin embargo, los mecanismos generales también tienen importantes desventajas: • Los mecanismos generales más famosos y ampliamente aplicables, VCG y dAGVA, solo maximizan el bienestar social. Si el diseñador está interesado en sí mismo, como es el caso en muchos entornos de comercio electrónico, estos mecanismos no maximizan el objetivo del diseñador. • Los mecanismos generales que se centran en un diseñador interesado en sí mismo solo son aplicables en entornos muy restringidos, como la subasta de maximización de ingresos esperados de Myerson para vender un solo artículo, y la subasta de maximización de ingresos esperados de Maskin y Riley para vender múltiples unidades idénticas de un artículo. • Incluso en los entornos restringidos en los que se aplican estos mecanismos, solo permiten la maximización de pagos. En la práctica, el diseñador también puede estar interesado en el resultado en sí mismo. Por ejemplo, a un subastador le puede importar qué postor recibe el artículo. • A menudo se asume que los pagos laterales pueden ser utilizados para adaptar los incentivos de los agentes, pero esto no siempre es práctico. Por ejemplo, en los mercados electrónicos basados en trueque, como Recipco, firstbarter.com, BarterOne e Intagio, no se permiten los pagos laterales. Además, entre los agentes de software, podría ser más deseable construir mecanismos que no dependan de la capacidad de realizar pagos, ya que muchos agentes de software no cuentan con la infraestructura para hacer pagos. Por el contrario, seguimos un enfoque reciente donde el mecanismo se diseña automáticamente para el problema específico en cuestión. Este enfoque aborda todos los inconvenientes mencionados anteriormente. Formulamos el problema de diseño de mecanismos como un problema de optimización. La entrada se caracteriza por el número de agentes, los posibles tipos de agentes (preferencias) y las distribuciones previas de los agregadores sobre los tipos de agentes. La salida es un mecanismo no manipulable que es óptimo con respecto a algún objetivo. Este enfoque se llama diseño de mecanismos automatizado. El enfoque de diseño de mecanismos automatizado tiene cuatro ventajas sobre el enfoque clásico de diseñar mecanismos generales. Primero, se puede utilizar incluso en entornos que no cumplen con las suposiciones de los mecanismos clásicos (como la disponibilidad de pagos laterales o que el objetivo sea el bienestar social). Segundo, puede permitir a uno eludir resultados de imposibilidad (como el teorema de Gibbard-Satterthwaite) que establecen que no existe un mecanismo que sea deseable para todas las preferencias. Cuando el mecanismo está diseñado para la configuración actual, no importa que no funcione de manera más general. Tercero, puede generar mecanismos mejores (en términos de garantías de no manipulabilidad más sólidas y/o mejores resultados) que los mecanismos clásicos porque el mecanismo aprovecha las particularidades del entorno (la información probabilística que el diseñador tiene sobre los tipos de agentes). Dada la gran cantidad de información que las partes tienen entre sí hoy en día, es probable que este enfoque conduzca a ahorros enormes en comparación con los mecanismos clásicos, que en su mayoría ignoran esa información. Por ejemplo, imagina una empresa creando automáticamente su mecanismo de adquisiciones basado en el conocimiento estadístico sobre sus proveedores, en lugar de utilizar una subasta de adquisiciones descendente clásica. Cuarto, la carga del diseño se traslada de los humanos a una máquina. Sin embargo, el diseño automatizado de mecanismos requiere que el problema de optimización del diseño del mecanismo se resuelva de nuevo para cada configuración. Por lo tanto, su complejidad computacional se convierte en un tema clave. Investigaciones previas han estudiado esta pregunta para diseñadores benevolentes que desean maximizar, por ejemplo, el bienestar social [5, 6]. En este artículo estudiamos la complejidad computacional del diseño automatizado de mecanismos en el caso de un diseñador con interés propio. Esta es una configuración importante para el diseño de mecanismos automatizados debido a la escasez de mecanismos generales en esta área, y al hecho de que en la mayoría de las configuraciones de comercio electrónico el diseñador actúa en su propio interés. También demostramos que este problema está estrechamente relacionado con un problema de diseño de subasta combinatoria óptima (maximización de ingresos) particular. El resto de este documento está organizado de la siguiente manera. En la Sección 2, justificamos el enfoque en mecanismos no manipulables. En la Sección 3, definimos el problema que estudiamos. En la Sección 4, demostramos que diseñar un mecanismo determinista óptimo es NP-completo incluso cuando al diseñador solo le importan los pagos que recibe. En la Sección 5, demostramos que diseñar un mecanismo determinista óptimo también es NP-completo cuando los pagos no son posibles y el diseñador solo está interesado en el resultado elegido. En la Sección 6, demostramos que un mecanismo óptimo aleatorizado puede ser diseñado en tiempo polinómico incluso en el caso general. Finalmente, en la Sección 7, demostramos que para diseñar subastas combinatorias óptimas bajo preferencias de mejor opción solamente, nuestros resultados sobre AMD implican que este problema es NP-completo para subastas determinísticas, pero sencillo para subastas aleatorias. 2. JUSTIFICANDO EL ENFOQUE EN MECANISMOS NO MANIPULABLES Antes de definir el problema computacional del diseño automatizado de mecanismos, debemos justificar nuestro enfoque en mecanismos no manipulables. Después de todo, no es inmediatamente obvio que no haya mecanismos manipulables que, incluso cuando los agentes informan estratégicamente sus tipos y, por lo tanto, a veces de manera no veraz, aún logren mejores resultados (según el objetivo que usemos) que cualquier mecanismo no manipulable. Sin embargo, resulta ser el caso que, dado cualquier mecanismo, podemos construir un mecanismo no manipulable cuyo rendimiento es idéntico, de la siguiente manera. Construimos una capa de interfaz entre los agentes y el mecanismo original. Los agentes informan sus preferencias (o tipos) a la capa de interfaz; posteriormente, la capa de interfaz introduce en el mecanismo original los tipos que los agentes habrían informado estratégicamente al mecanismo original, si sus tipos fueran los declarados a la capa de interfaz. El resultado resultante es el resultado del nuevo mecanismo. Dado que la capa de interfaz actúa estratégicamente en nombre de cada agente, nunca hay un incentivo para informar falsamente a la capa de interfaz; por lo tanto, los tipos informados por la capa de interfaz son los tipos estratégicos que se habrían informado sin la capa de interfaz, por lo que los resultados son exactamente como habrían sido con el mecanismo original. Este argumento es conocido en la literatura de diseño de mecanismos como el principio de revelación [16]. (Existen dificultades computacionales al aplicar el principio de revelación en espacios de resultados y tipos combinatorios grandes [7, 22]). Sin embargo, dado que aquí nos enfocamos en espacios de resultados y tipos representados de forma plana, esto no es una preocupación aquí. Dado esto, podemos centrarnos en mecanismos veraces en el resto del documento. 3. DEFINICIONES Ahora formalizamos el entorno del diseño automatizado de mecanismos. Definición 1. En un entorno de diseño de mecanismos automatizados, se nos proporciona: • un conjunto finito de resultados O; • un conjunto finito de N agentes; • para cada agente i, 1. un conjunto finito de tipos Θi, 2. una distribución de probabilidad γi sobre Θi (en el caso de tipos correlacionados, hay una única distribución conjunta γ sobre Θ1 × . . . × ΘN), y 3. una función de utilidad ui: Θi × O → R; 1 • Una función objetivo cuya expectativa el diseñador desea maximizar. Existen muchas posibles funciones objetivo que el diseñador podría tener, por ejemplo, el bienestar social (donde el diseñador busca maximizar la suma de las utilidades de los agentes), o la utilidad mínima de cualquier agente (donde el diseñador busca maximizar la peor utilidad experimentada por cualquier agente). En ambos casos, el diseñador es benevolente, ya que, de alguna manera, el diseñador está buscando la felicidad colectiva de los agentes. Sin embargo, en este documento nos enfocamos en el caso de un diseñador interesado en sí mismo. Un diseñador egoísta solo se preocupa por el resultado elegido (es decir, al diseñador no le importa cómo se relaciona el resultado con las preferencias de los agentes, sino que tiene una preferencia fija sobre los resultados) y sobre los pagos netos realizados por los agentes, que fluyen hacia el diseñador. Definición 2. Un diseñador interesado tiene una función objetivo dada por g(o) + Σ i=1 πi, donde g : O → R indica las preferencias del diseñador sobre los resultados, y πi es el pago realizado por el agente i. En el caso en que g = 0 en todas partes, se dice que el diseñador está maximizando el pago. En el caso en que los pagos no sean posibles, g constituye la función objetivo por sí sola. Ahora definimos los tipos de mecanismos en estudio. Por el principio de revelación, podemos restringir la atención a mecanismos de revelación directa y veraz, donde los agentes informan directamente sus tipos y nunca tienen incentivos para informarlos de manera incorrecta. Definición 3. Consideramos los siguientes tipos de mecanismos: • Un mecanismo determinista sin pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O. • Un mecanismo aleatorio sin pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), donde P(O) es el conjunto de distribuciones de probabilidad sobre O. • Un mecanismo determinista con pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O y, para cada agente i, una función de selección de pagos πi: Θ1 × Θ2 × . . . × ΘN → R, donde πi(θ1, . . . , θN ) da el pago realizado por el agente i cuando los tipos reportados son θ1, . . . , θN. Aunque esto sigue la notación estándar de la teoría de juegos [16], el hecho de que el agente tenga tanto una función de utilidad como un tipo puede resultar confuso. Los tipos codifican las diversas preferencias posibles que el agente pueda tener, y el tipo de los agentes no es conocido por el agregador. La función de utilidad es un conocimiento común, pero debido a que el tipo de agente es un parámetro en la función de utilidad de los agentes, el agregador no puede saber cuál es la utilidad de los agentes sin conocer el tipo de agente. Un mecanismo aleatorio con pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), y para cada agente i, una función de selección de pago πi: Θ1 × Θ2 × . . . × ΘN → R. Hay dos tipos de restricciones para el diseñador al construir el mecanismo. 3.1 Restricciones de racionalidad individual (IR) El primer tipo de restricción es el siguiente. La utilidad de cada agente debe ser al menos tan grande como la utilidad de respaldo de los agentes, es decir, la utilidad que el agente recibiría si no participara en el mecanismo. De lo contrario, ese agente no participaría en el mecanismo, y la participación de ningún agente puede perjudicar el objetivo de los diseñadores del mecanismo, ya que en el peor de los casos, el mecanismo puede ignorar a un agente fingiendo que el agente no está presente. (Además, si no se aplicara tal restricción, el diseñador simplemente podría hacer que los agentes paguen una cantidad infinita). Este tipo de restricción se llama restricción de IR (racionalidad individual). Existen tres posibles restricciones de IR diferentes: ex ante, ex interim y ex post, dependiendo de lo que el agente sabe sobre su propio tipo y los tipos de los demás al decidir si participar en el mecanismo. Ex ante IR significa que el agente participaría si no supiera absolutamente nada (ni siquiera su propio tipo). No estudiaremos este concepto en este documento. Ex interim IR significa que el agente siempre participaría si conociera solo su propio tipo, pero no el de los demás. Ex post IR significa que el agente siempre participaría incluso si conociera el tipo de todos. Definiremos formalmente las dos últimas nociones de IR. Primero, necesitamos formalizar el concepto del resultado de respaldo. Suponemos que la utilidad de respaldo de cada agente es cero para cada uno de sus tipos. Esto se hace sin pérdida de generalidad porque podemos agregar un término constante a la función de utilidad de un agente (para un tipo dado), sin afectar el comportamiento de toma de decisiones de ese agente maximizador de utilidad esperada [16]. Definición 4. En cualquier entorno de diseño de mecanismos automatizados con una restricción de IR, existe un resultado de contingencia o0 ∈ O donde, para cualquier agente i y cualquier tipo θi ∈ Θi, tenemos ui(θi, o0) = 0. (Además, en el caso de un diseñador egoísta, g(o0) = 0). Ahora podemos definir las nociones de racionalidad individual. Definición 5. La racionalidad individual (RI) se define como: • Un mecanismo determinista es ex interim RI si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0. Un mecanismo aleatorio es ex interim IR si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • Un mecanismo determinista es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 No aleatorizamos sobre los pagos porque mientras los agentes y el diseñador sean neutrales al riesgo con respecto a los pagos, es decir, su utilidad es lineal en los pagos, no hay razón para aleatorizar sobre los pagos. Un mecanismo aleatorio es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 3.2 Restricciones de compatibilidad de incentivos (IC) El segundo tipo de restricción establece que los agentes nunca deben tener un incentivo para informar incorrectamente su tipo (como se justificó anteriormente mediante el principio de revelación). Para este tipo de restricción, las dos variantes más comunes (o conceptos de solución) son la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash. Definición 6. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en estrategias dominantes si decir la verdad siempre es óptimo incluso cuando los tipos reportados por los otros agentes ya son conocidos. Formalmente, para cualquier agente i, cualquier vector de tipos (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ). En el caso de mecanismos aleatorios tenemos Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. Por lo tanto, en la implementación de estrategias dominantes, decir la verdad es óptimo independientemente de lo que informen los otros agentes. Si es óptimo solo dado que los otros agentes son veraces, y dado que uno no conoce los tipos de los otros agentes, tenemos implementación en equilibrio de Bayes-Nash. Definición 7. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en equilibrio de Bayes-Nash si decir la verdad siempre es óptimo para un agente cuando ese agente aún no sabe nada sobre los tipos de los otros agentes, y los otros agentes están diciendo la verdad. Formalmente, para cualquier agente i, cualquier tipo θi ∈ Θi, y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )]. En el caso de mecanismos aleatorios tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 135 3.3 Diseño de mecanismos automatizados Ahora podemos definir el problema computacional que estudiamos. Definición 8. (DISEÑO DE MECANISMOS AUTOMATIZADOS (AMD)) Se nos da: • un entorno de diseño de mecanismos automatizados, • una noción de IR (ex interim, ex post, o ninguna), • un concepto de solución (estrategias dominantes o Bayes-Nash), • si los pagos son posibles, • si la aleatorización es posible, • (en la variante de decisión del problema) un valor objetivo G. Se nos pregunta si existe un mecanismo del tipo especificado (en términos de pagos y aleatorización) que satisfaga tanto la noción de IR como el concepto de solución, y proporcione un valor esperado de al menos G para el objetivo. Un caso especial interesante es aquel en el que solo hay un agente. En este caso, el agente informante siempre sabe todo lo que hay que saber sobre los otros tipos de agentes, porque no hay otros agentes. Dado que el IR ex post y el IR ex interim solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de IR coinciden aquí. Además, dado que la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de solución coinciden aquí. Esta observación resultará ser una herramienta útil para demostrar resultados de dificultad: si demostramos dificultad computacional en el escenario de un solo agente, esto implica inmediatamente dificultad para ambos conceptos de IR, para ambos conceptos de solución, para cualquier número de agentes. 4. En esta sección demostramos que es NP-completo diseñar un mecanismo determinístico que maximice la suma esperada de los pagos recolectados de los agentes. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Para demostrar la NP-dureza, reducimos desde el problema MINSAT. Definición 9 (MINSAT). Se nos da una fórmula φ en forma normal conjuntiva, representada por un conjunto de variables booleanas V y un conjunto de cláusulas C, y un entero K (K < |C|). Se nos pregunta si existe una asignación a las variables en V tal que se satisfacen a lo sumo K cláusulas en φ. MINSAT fue recientemente demostrado como NP-completo [14]. Ahora podemos presentar nuestro resultado. Teorema 1. El problema determinista de maximización de pagos de AMD es NP-completo, incluso para un solo agente, incluso con una distribución uniforme de tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista de maximización de pagos de un solo agente. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V } ∪ {−v : v ∈ V }. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Sea l ∈ c denota que el literal l ocurre en la cláusula c. Entonces, la función de utilidad de los agentes está dada por u(θc, ol) = |Θ| + 1 para todo l ∈ L con l ∈ c; u(θc, ol) = 0 para todo l ∈ L con l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc) = 0 para todo c ∈ C con c = c; u(θv, ol) = |Θ| para todo l ∈ L con v(l) = v; u(θv, ol) = 0 para todo l ∈ L con v(l) = v; u(θv, oc) = 0 para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ|, donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v) y π(θv) = |Θ|. Para cada c ∈ C, sea o(θc) = oc; sea π(θc) = |Θ| + 1 si c no está satisfecha en la solución MINSAT, y π(θc) = |Θ| si c está satisfecha. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es θv, entonces cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivo para informar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Porque además, ningún tipo que no sea θc conduce al resultado oc, informar cualquier otro tipo dará como resultado una utilidad de 0, mientras que aún se requiere un pago de al menos |Θ| por parte del agente. Claramente, el agente está mejor reportando honestamente, para una utilidad total de 0. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), el pago esperado de este mecanismo es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o y una función de pago π. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. Entonces, la utilidad que el agente obtiene del resultado dado para este tipo es 0, y por lo tanto, según la IR, no se puede extraer ningún pago del agente para este tipo. Dado que, nuevamente por IR, el pago máximo que se puede extraer para cualquier otro tipo es |Θ| + 1, se sigue que el pago esperado máximo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo cual contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o−v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por la restricción de IR, el pago máximo que podemos extraer de cualquier tipo θv es |Θ|. Dado que no puede haber incentivos para que el agente informe falsamente, para cualquier cláusula c satisfecha por la asignación dada, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ|. (Pues si extrajéramos más de este tipo, la utilidad del agente en este caso sería menor que 1; y si v es la variable que satisface c en la asignación, de modo que o(θv) = ol donde l ocurre en c, entonces al agente le convendría más informar θv en lugar del informe veraz θc, para obtener un resultado que valga |Θ|+1 para él mientras tiene que pagar como máximo |Θ|.) Finalmente, para cualquier cláusula insatisfecha c, según la restricción de IR, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ| + 1. Se deduce que el pago esperado de nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia de MINSAT. Dado que AMD, que maximiza el pago, es solo un caso especial de AMD para un diseñador egoísta en el que el diseñador no tiene preferencias sobre el resultado elegido, esto implica inmediatamente dificultades para el caso general de AMD para un diseñador egoísta en el que los pagos son posibles. Sin embargo, esto aún no implica dureza para el caso especial donde los pagos no son posibles. Demostraremos la dificultad en este caso en la próxima sección. 5. En esta sección demostramos que es NP-completo diseñar un mecanismo determinista que maximice la expectativa del objetivo del diseñador cuando no son posibles los pagos. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Teorema 2. Sin pagos, el diseño determinista de AMD para un diseñador egoísta es NP-completo, incluso para un solo agente, incluso con una distribución uniforme sobre los tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista auto-interesada de un solo agente sin pagos. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L} ∪ {o∗}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V} ∪ {−v : v ∈ V}. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Deje que l ∈ c denote que el literal l ocurre en la cláusula c. Luego, deje que la función de utilidad de los agentes esté dada por u(θc, ol) = 2 para todo l ∈ L con l ∈ c; u(θc, ol) = −1 para todo l ∈ L con l /∈ c; u(θc, oc) = 2; u(θc, oc) = −1 para todo c ∈ C con c = c; u(θc, o∗) = 1; u(θv, ol) = 1 para todo l ∈ L con v(l) = v; u(θv, ol) = −1 para todo l ∈ L con v(l) = v; u(θv, oc) = −1 para todo c ∈ C; u(θv, o∗) = −1. Que la función objetivo de los diseñadores esté dada por g(o∗ ) = |Θ|+1; g(ol) = |Θ| para todo l ∈ L; g(oc) = |Θ| para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ| , donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v). Para cada c ∈ C que se cumpla en la solución MINSAT, sea o(θc) = oc; para cada c ∈ C no satisfecho, sea o(θc) = o∗. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es algún θv, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para reportar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Debido a que tampoco ningún tipo conduce al resultado oc, no hay ningún resultado que el mecanismo seleccione que le daría al agente una utilidad mayor a 1 para el tipo θc, y por lo tanto el agente no tiene incentivo para informar falsamente. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), entonces el valor esperado de la función objetivo de los diseñadores es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. El único otro resultado que el mecanismo puede elegir bajo la restricción de IR es o0. Esto tiene un valor objetivo de 0, y dado que el valor más alto que la función objetivo alcanza es |Θ| + 1, se sigue que el valor esperado máximo de la función objetivo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo que contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o-v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por lo anterior, para cualquier tipo θv, el valor de la función objetivo en este mecanismo será |Θ|. Para cualquier cláusula c satisfecha por la asignación dada, el valor de la función objetivo en el caso en que el agente informe el tipo θc será como máximo |Θ|. (Esto se debe a que no podemos elegir el resultado o∗ para dicho tipo, ya que en este caso el agente tendría un incentivo para informar θv en su lugar, donde v es la variable que satisface c en la asignación (de modo que o(θv) = ol donde l ocurre en c).) Finalmente, para cualquier cláusula insatisfecha c, el valor máximo que la función objetivo puede alcanzar en el caso en que el agente informa el tipo θc es |Θ| + 1, simplemente porque este es el valor más grande que la función alcanza en cualquier momento. Se deduce que el valor esperado de la función objetivo para nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas 137 satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia MINSAT. Ambos de nuestros resultados de dureza se basaron en la restricción de que el mecanismo debería ser determinista. En la siguiente sección, mostramos que la dificultad del diseño desaparece cuando permitimos la aleatorización en el mecanismo. 6. La aleatorización de AMD para un diseñador interesado en sí mismo es fácil. Ahora mostramos cómo permitir la aleatorización sobre los resultados hace que el problema de AMD auto-interesado sea manejable a través de la programación lineal, para cualquier número constante de agentes. Teorema 3. El AMD aleatorio con interés propio con un número constante de agentes es resoluble en tiempo polinómico mediante programación lineal, tanto con pagos como sin pagos, tanto para IR ex post como ex interim, y tanto para la implementación en estrategias dominantes como para la implementación en equilibrio de Bayes-Nash, incluso si los tipos están correlacionados. Prueba. Dado que los programas lineales pueden resolverse en tiempo polinómico [13], todo lo que necesitamos demostrar es que el número de variables y ecuaciones en nuestro programa es polinomial para cualquier número constante de agentes, es decir, exponencial solo en N. En todo momento, para determinar el tamaño del programa lineal, consideremos T = maxi{|Θi|}. Las variables de nuestro programa lineal serán las probabilidades (p(θ1, θ2, . . . , θN ))(o) (como máximo TN |O| variables) y los pagos πi(θ1, θ2, . . . , θN ) (como máximo NTN variables). (Mostramos el programa lineal para el caso en que los pagos son posibles; el caso sin pagos se obtiene fácilmente de esto simplemente omitiendo todas las variables de pago en el programa, o agregando restricciones adicionales que obliguen a los pagos a ser 0). Primero, mostramos las restricciones de IR. Para el IR ex post, agregamos las siguientes restricciones (como máximo NTN) al LP: • Para cada i ∈ {1, 2, . . . , N}, y para cada (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , agregamos ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0. Para el ex interino IR, agregamos las siguientes restricciones (como máximo NT) al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada θi ∈ Θi, agregamos θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0. Ahora, mostramos las restricciones del concepto de solución. Para la implementación en estrategias dominantes, agregamos las siguientes (a lo sumo NTN+1) restricciones al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ). Finalmente, para la implementación en el equilibrio de Bayes-Nash, agregamos las siguientes (a lo sumo NT2) restricciones al LP: • Para cada i ∈ {1, 2, ..., N}, para cada θi ∈ Θi, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )). Todo lo que queda por hacer es dar la expresión que el diseñador busca maximizar, que es: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )). Como indicamos, el número de variables y restricciones es exponencial solo en N, por lo tanto, el programa lineal tiene un tamaño polinómico para un número constante de agentes. Por lo tanto, el problema es resoluble en tiempo polinómico. IMPLICACIONES PARA UN PROBLEMA DE DISEÑO DE SUBASTA COMBINATORIA ÓPTIMA En esta sección, demostraremos algunas consecuencias interesantes del problema de diseño de mecanismos automatizados para un diseñador interesado en sí mismo en el diseño de subastas combinatorias óptimas. Considera una subasta combinatoria con un conjunto S de artículos en venta. Para cualquier conjunto B ⊆ S, dejemos que ui(θi, B) sea la utilidad del postor i al recibir el conjunto B cuando el tipo del postor es θi. El problema de diseño de subasta óptima consiste en especificar las reglas de la subasta de manera que se maximice los ingresos esperados para el subastador. (Por el principio de revelación, sin pérdida de generalidad, podemos asumir que la subasta es veraz). El problema de diseño de subasta óptima se resuelve para el caso de un solo artículo mediante la famosa subasta de Myerson [18]. Sin embargo, el diseño de subastas óptimas en subastas combinatorias es un problema de investigación abierto reconocido [3, 25]. El problema está abierto incluso si solo hay dos artículos en venta. (El caso de dos artículos con una forma muy especial de complementariedad y sin sustituibilidad ha sido resuelto recientemente [1].) Supongamos que tenemos disposición libre: los artículos pueden ser desechados sin costo alguno. Además, supongamos que las preferencias de los postores tienen la siguiente estructura: cuando un postor recibe un conjunto de artículos, la utilidad del postor por ese conjunto está determinada únicamente por el mejor artículo en el conjunto. (Enfatizamos que qué artículo es el mejor puede depender del tipo de postor). Definición 10. Se dice que el postor i tiene preferencias solo por lo mejor sobre paquetes de artículos si existe una función vi: Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s). Hacemos la siguiente observación útil en este contexto: no tiene sentido otorgarle a un postor más de un artículo. La razón es que si el postor está informando honestamente, quitarle todos los artículos menos el de mayor valor no perjudicará al postor; y, mediante la disposición gratuita, hacerlo solo reducirá el incentivo para que este postor informe falsamente este tipo, cuando en realidad tiene otro tipo. Ahora demostramos que el problema de diseñar una subasta óptima determinista es NP-completo, mediante una reducción del problema AMD de maximización de pagos. Teorema 4. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de artículos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), diseñar la subasta determinística óptima es NP-completo, incluso para un único postor con una distribución uniforme sobre los tipos. Prueba. El problema está en NP porque podemos generar de manera no determinista una regla de asignación, y luego establecer los pagos utilizando programación lineal. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de AMD determinista que maximiza el pago, con un único agente y una distribución uniforme de tipos, al siguiente problema de diseño de subasta combinatoria óptima con una única postor con preferencias de solo los mejores. Para cada resultado o ∈ O en la instancia de AMD (excepto el resultado o0), que haya un artículo so ∈ S. Que el espacio de tipos sea el mismo, y que v(θi, so) = ui(θi, o) (donde u está especificado en la instancia de AMD). Que el valor objetivo de ingresos esperados sea el mismo en ambas instancias. Mostramos que las instancias son equivalentes. Primero supongamos que existe una solución para la instancia de AMD, dada por una función de resultado y una función de pago. Entonces, si la solución de AMD elige el resultado o para un tipo, en la solución de subasta óptima, asignamos {so} al postor para este tipo. (A menos que o = o0, en cuyo caso asignamos {} al postor). Que las funciones de pago sean las mismas en ambas instancias. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo verdadero) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución óptima de la subasta. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el subastador/diseñador son los mismos. Se deduce que existe una solución para la instancia de diseño de subasta óptima. Ahora supongamos que existe una solución para la instancia de diseño de subasta óptima. Por la observación de que como máximo se puede tener un artículo, podemos asumir sin pérdida de generalidad que la solución nunca asigna más de un artículo. Entonces, si la solución de subasta óptima asigna el artículo al postor para un tipo, en la solución de AMD, permita que el mecanismo elija el resultado o para ese tipo. Si la solución de subasta óptima no asigna nada al postor para un tipo, en la solución AMD, permita que el mecanismo elija el resultado o0 para ese tipo. Que las funciones de pago sean las mismas. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo real) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución AMD. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el diseñador/subastador son los mismos. Se deduce que existe una solución para la instancia de AMD. Afortunadamente, también podemos extender el resultado de facilidad para mecanismos aleatorios a este escenario de subasta combinatoria, lo que nos proporciona uno de los pocos algoritmos de tiempo polinómico conocidos para un problema de diseño óptimo de subasta combinatoria. Teorema 5. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de elementos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), si el número de postores es una constante k, entonces la subasta aleatoria óptima puede ser diseñada en tiempo polinómico. (Para cualquier restricción de IC e IR.) Prueba. Por la observación de que a lo sumo un artículo, podemos sin pérdida de generalidad restringirnos a asignaciones donde cada postor recibe como máximo un artículo. Hay menos de (|S| + 1)k asignaciones de ese tipo, es decir, un número polinómico de asignaciones. Dado que podemos enumerar explícitamente los resultados, simplemente podemos resolver esto como una instancia de AMD que maximiza el pago, con programación lineal. 8. Investigaciones relacionadas sobre la complejidad en el diseño de mecanismos. Ha habido un considerable interés reciente en el diseño de mecanismos en la informática. Parte de ello se ha centrado en cuestiones de complejidad computacional, pero la mayor parte de ese trabajo ha buscado diseñar mecanismos que sean fáciles de ejecutar (por ejemplo, [20, 15, 19, 9, 12]), en lugar de estudiar la complejidad de diseñar el mecanismo. La pieza más cercana de trabajo anterior estudió la complejidad del diseño automatizado de mecanismos por un diseñador benevolente [5, 6]. Roughgarden ha estudiado la complejidad de diseñar una buena topología de red para agentes que eligen egoístamente los enlaces que utilizan [21]. Esto está relacionado con el diseño de mecanismos, pero difiere significativamente en que el diseñador solo tiene un control restringido sobre las reglas del juego porque no hay ninguna parte que pueda imponer el resultado (o pagos laterales). Además, no hay un informe explícito de preferencias. 9. CONCLUSIONES E INVESTIGACIONES FUTURAS A menudo, un resultado debe ser elegido en función de las preferencias informadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les sea más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente emergente llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración específica de agregación de preferencias en cuestión. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo, un entorno mucho más relevante para el comercio electrónico. En este contexto, al centro solo le importa qué resultado se elige y qué pagos se le realizan. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este escenario, demostramos que diseñar un mecanismo determinista óptimo es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Estos resultados de dureza implican dificultad en todos los entornos de diseño de mecanismos automatizados más generales con un diseñador egoísta. Los resultados de dureza se aplican ya sea que las restricciones de racionalidad individual (participación) se apliquen ex interim o ex post, y ya sea que el concepto de solución sea la implementación de estrategias dominantes o la implementación del equilibrio de Bayes-Nash. Luego demostramos que permitir la aleatorización en el mecanismo hace que el problema de diseño en todos estos escenarios sea computacionalmente sencillo. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (que maximiza los ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar un mecanismo determinístico óptimo es NP-completo incluso con un agente, pero diseñar un mecanismo aleatorio óptimo es fácil. La investigación futura incluye estudiar el diseño automatizado de mecanismos con un diseñador interesado en sí mismo en entornos más restringidos, como subastas (donde el objetivo del diseñador puede incluir preferencias sobre qué postor debería recibir el bien, así como los pagos). También queremos estudiar la complejidad del diseño de mecanismos automatizados en entornos donde los espacios de resultados y tipos tienen una estructura especial para que puedan representarse de manera más concisa. Finalmente, planeamos reunir un conjunto de datos de problemas de diseño de mecanismos del mundo real, tanto históricos como actuales, y aplicar el diseño de mecanismos automatizado a esos problemas. 10. REFERENCIAS [1] M. Armstrong. Subastas multi-objetivo óptimas. Revisión de Estudios Económicos, 67:455-481, 2000. [2] K. Arrow. La doctrina de los derechos de propiedad y la revelación de la demanda bajo información incompleta. En M. Boskin, editor, Economía y bienestar humano. New York Academic Press, 1979. [3] C. Avery y T. Hendershott. Agrupación y subastas óptimas de múltiples productos. Revisión de Estudios Económicos, 67:483-497, 2000. [4] E. H. Clarke. Precios escalonados de bienes públicos. Elección Pública, 11:17-33, 1971. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Actas de la 18ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI-02), páginas 103-110, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Diseño de mecanismos automatizados: Resultados de complejidad derivados del entorno de un solo agente. En Actas de la 5ta Conferencia Internacional de Comercio Electrónico (ICEC-03), páginas 17-24, Pittsburgh, PA, EE. UU., 2003. [7] V. Conitzer y T. Sandholm. Críticas computacionales del principio de revelación. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), Nueva York, NY, 2004. Breve ensayo. La versión completa apareció en el taller AAMAS-03 sobre Comercio Electrónico Mediado por Agentes (AMEC). [8] C. d'Aspremont y L. A. Gérard-Varet. Incentivos e información incompleta. Revista de Economía Pública, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou y S. Shenker. Compartiendo el costo de las transmisiones de multidifusión. Revista de Ciencias de la Computación y de Sistemas, 63:21-41, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 2000. [10] A. Gibbard. Manipulación de esquemas de votación. Econometrica, 41:587-602, 1973. [11] T. Groves.\nEconometrica, 41:587-602, 1973. [11] T. Groves. Incentivos en equipos. Econometrica, 41:617-631, 1973. [12] J. Hershberger y S. Suri. Precios de Vickrey y caminos más cortos: ¿Cuánto vale una arista? En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [13] L. Khachiyan. Un algoritmo polinómico en programación lineal. Matemática soviética. Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi y P. Mirchandani. El problema de satisfacibilidad mínimo. Revista SIAM de Matemáticas Discretas, 7(2):275-283, 1994. [15] D. Lehmann, L. I. O'Callaghan y Y. Shoham. Revelación de la verdad en subastas combinatorias rápidas y aproximadamente eficientes. Revista de la ACM, 49(5):577-602, 2002. La versión inicial apareció en las Actas de la Conferencia de Comercio Electrónico de la ACM (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [17] E. S. Maskin y J. Riley. Subastas multiunidad óptimas. En F. Hahn, editor, \"La economía de los mercados faltantes, la información y los juegos\", capítulo 14, páginas 312-335. Clarendon Press, Oxford, 1989. [18] R. Myerson.\nPrensa Clarendon, Oxford, 1989. [18] R. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6:58-73, 1981. [19] N. Nisan y A. Ronen. Mecanismos VCG computacionalmente factibles. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 242-252, Minneapolis, MN, 2000. [20] N. Nisan y A. Ronen. Diseño de mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166-196, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 1999. [21] T. Roughgarden. Diseñar redes para usuarios egoístas es difícil. En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [22] T. Sandholm. Problemas en subastas computacionales de Vickrey. Revista Internacional de Comercio Electrónico, 4(3):107-129, 2000. Número especial sobre la Aplicación de Agentes Inteligentes para el Comercio Electrónico. Una versión corta y temprana apareció en la Segunda Conferencia Internacional sobre Sistemas Multiagente (ICMAS), páginas 299-306, 1996. [23] M. A. Satterthwaite. In Spanish, the translation would be: \"Inmutabilidad estratégica y condiciones de Arrow: teoremas de existencia y correspondencia para procedimientos de votación y funciones de bienestar social.\" Revista de Teoría Económica, 10:187-217, 1975. [24] W. Vickrey. Contrarrestando la especulación, subastas y ofertas selladas competitivas. Revista de Finanzas, 16:8-37, 1961. [25] R. V. Vohra. Problemas de investigación en subastas combinatorias. Mimeo, versión 29 de octubre de 2001. 141",
    "original_sentences": [
        "Self-interested Automated Mechanism Design and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
        "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
        "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
        "In a recently proposed approach-called automated mechanism design-a mechanism is computed for the preference aggregation setting at hand.",
        "This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
        "Unlike the earlier work on automated mechanism design that studied a benevolent designer, in this paper we study automated mechanism design problems where the designer is self-interested.",
        "In this case, the center cares only about which outcome is chosen and what payments are made to it.",
        "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
        "In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
        "We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy.",
        "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
        "We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy.",
        "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1.",
        "INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents.",
        "Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc.",
        "The preference aggregator generally does not know the agents preferences a priori.",
        "Rather, the agents report their preferences to the coordinator.",
        "Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully.",
        "Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen.",
        "Manipulability is a pervasive problem across preference aggregation mechanisms.",
        "A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.)",
        "What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective.",
        "This is the classic setting of mechanism design in game theory.",
        "In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself.",
        "This is the mechanism design setting most relevant to electronic commerce.",
        "In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear.",
        "It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences.",
        "The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments.",
        "The most common such constraint is that of individual rationality (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
        "For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences.",
        "Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it.",
        "Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off.",
        "On the other hand, the designer will not necessarily choose a social welfare maximizing outcome.",
        "For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected.",
        "Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0.",
        "Classical mechanism design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective.",
        "The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]).",
        "However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare.",
        "If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization.",
        "In practice, the designer may also be interested in the outcome per se.",
        "For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical.",
        "For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed.",
        "Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments.",
        "In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand.",
        "This approach addresses all of the downsides listed above.",
        "We formulate the mechanism design problem as an optimization problem.",
        "The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types.",
        "The output is a nonmanipulable mechanism that is optimal with respect to some objective.",
        "This approach is called automated mechanism design.",
        "The automated mechanism design approach has four advantages over the classical approach of designing general mechanisms.",
        "First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare).",
        "Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences.",
        "When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally.",
        "Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types).",
        "Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information.",
        "For example, imagine a company automatically creating its procurement mechanism based on statistical knowledge about its suppliers, rather than using a classical descending procurement auction.",
        "Fourth, the burden of design is shifted from humans to a machine.",
        "However, automated mechanism design requires the mechanism design optimization problem to be solved anew for each setting.",
        "Hence its computational complexity becomes a key issue.",
        "Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6].",
        "In this paper we study the computational complexity of automated mechanism design in the case of a self-interested designer.",
        "This is an important setting for automated mechanism design due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested.",
        "We also show that this problem is closely related to a particular optimal (revenue-maximizing) combinatorial auction design problem. 133 The rest of this paper is organized as follows.",
        "In Section 2, we justify the focus on nonmanipulable mechanisms.",
        "In Section 3, we define the problem we study.",
        "In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it.",
        "In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen.",
        "In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case.",
        "Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2.",
        "JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of automated mechanism design, we should justify our focus on nonmanipulable mechanisms.",
        "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any nonmanipulable mechanism.",
        "This does, however, turn out to be the case: given any mechanism, we can construct a nonmanipulable mechanism whose performance is identical, as follows.",
        "We build an interface layer between the agents and the original mechanism.",
        "The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer.",
        "The resulting outcome is the outcome of the new mechanism.",
        "Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism.",
        "This argument is known in the mechanism design literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22].",
        "However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.)",
        "Given this, we can focus on truthful mechanisms in the rest of the paper. 3.",
        "DEFINITIONS We now formalize the automated mechanism design setting.",
        "Definition 1.",
        "In an automated mechanism design setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize.",
        "There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent).",
        "In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness.",
        "However, in this paper, we focus on the case of a self-interested designer.",
        "A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer.",
        "Definition 2.",
        "A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i.",
        "In the case where g = 0 everywhere, the designer is said to be payment maximizing.",
        "In the case where payments are not possible, g constitutes the objective function by itself.",
        "We now define the kinds of mechanisms under study.",
        "By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them.",
        "Definition 3.",
        "We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing.",
        "The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator.",
        "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 Individual rationality (IR) constraints The first type of constraint is the following.",
        "The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism.",
        "Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.)",
        "This type of constraint is called an IR (individual rationality) constraint.",
        "There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism.",
        "Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type).",
        "We will not study this concept in this paper.",
        "Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others.",
        "Ex post IR means that the agent would always participate even if it knew everybodys type.",
        "We will define the latter two notions of IR formally.",
        "First, we need to formalize the concept of the fallback outcome.",
        "We assume that each agents fallback utility is zero for each one of its types.",
        "This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16].",
        "Definition 4.",
        "In any automated mechanism design setting with an IR constraint, there is a fallback outcome o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)",
        "We can now to define the notions of individual rationality.",
        "Definition 5.",
        "Individual rationality (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
        "A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments.",
        "A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
        "The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle).",
        "For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium.",
        "Definition 6.",
        "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known.",
        "Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
        "In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
        "The terms involving payments can be left out in the case where payments are not possible.",
        "Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report.",
        "If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium.",
        "Definition 7.",
        "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth.",
        "Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
        "In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
        "The terms involving payments can be left out in the case where payments are not possible. 135 3.3 Automated mechanism design We can now define the computational problem we study.",
        "Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an automated mechanism design setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective.",
        "An interesting special case is the setting where there is only one agent.",
        "In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents.",
        "Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here.",
        "Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here.",
        "This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4.",
        "PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents.",
        "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
        "To demonstrate NPhardness, we reduce from the MINSAT problem.",
        "Definition 9 (MINSAT).",
        "We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|).",
        "We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied.",
        "MINSAT was recently shown to be NP-complete [14].",
        "We can now present our result.",
        "Theorem 1.",
        "Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types.",
        "Proof.",
        "It is easy to show that the problem is in NP.",
        "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent payment-maximizing deterministic AMD instance.",
        "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
        "Let the probability distribution over these types be uniform.",
        "Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
        "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
        "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
        "We show the instances are equivalent.",
        "First, suppose there is a solution to the MINSAT instance.",
        "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
        "Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|.",
        "For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the MINSAT solution, and π(θc) = |Θ| if c is satisfied.",
        "It is straightforward to check that the IR constraint is satisfied.",
        "We now check that the agent has no incentive to misreport.",
        "If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
        "If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
        "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
        "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
        "Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent.",
        "Clearly the agent is better off reporting truthfully, for a total utility of 0.",
        "This establishes that the agent never has an incentive to misreport.",
        "Finally, we show that the goal is reached.",
        "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
        "Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π.",
        "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
        "Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type.",
        "Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
        "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
        "We claim this assignment is a solution to the MINSAT instance.",
        "By the IR constraint, the maximum payment we can extract from any type θv is |Θ|.",
        "Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.)",
        "Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1.",
        "It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses.",
        "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
        "Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible.",
        "However, it does not yet imply hardness for the special case where payments are not possible.",
        "We will prove hardness in this case in the next section. 5.",
        "SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible.",
        "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
        "Theorem 2.",
        "Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types.",
        "Proof.",
        "It is easy to show that the problem is in NP.",
        "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent self-interested deterministic AMD without payments instance.",
        "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
        "Let the probability distribution over these types be uniform.",
        "Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
        "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
        "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1.",
        "Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
        "We show the instances are equivalent.",
        "First, suppose there is a solution to the MINSAT instance.",
        "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
        "Then, for every v ∈ V , let o(θv) = of(v).",
        "For every c ∈ C that is satisfied in the MINSAT solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ .",
        "It is straightforward to check that the IR constraint is satisfied.",
        "We now check that the agent has no incentive to misreport.",
        "If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport.",
        "If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport.",
        "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
        "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
        "Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely.",
        "This establishes that the agent never has an incentive to misreport.",
        "Finally, we show that the goal is reached.",
        "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
        "Now suppose there is a solution to the AMD instance, given by an outcome function o.",
        "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
        "The only other outcome that the mechanism is allowed to choose under the IR constraint is o0.",
        "This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
        "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}.",
        "We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
        "We claim this assignment is a solution to the MINSAT instance.",
        "By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|.",
        "For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).)",
        "Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes.",
        "It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses.",
        "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
        "Both of our hardness results relied on the constraint that the mechanism should be deterministic.",
        "In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6.",
        "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of self-interested AMD tractable through linear programming, for any constant number of agents.",
        "Theorem 3.",
        "Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated.",
        "Proof.",
        "Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}.",
        "The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.)",
        "First, we show the IR constraints.",
        "For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
        "For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
        "Now, we show the solution concept constraints.",
        "For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
        "Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
        "All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
        "As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents.",
        "Thus the problem is solvable in polynomial time. 7.",
        "IMPLICATIONS FOR AN OPTIMAL COMBINATORIAL AUCTION DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated mechanism design for a self-interested designer on designing optimal combinatorial auctions.",
        "Consider a combinatorial auction with a set S of items for sale.",
        "For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi.",
        "The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.)",
        "The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18].",
        "However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25].",
        "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of complementarity and no substitutability has been solved recently [1].)",
        "Suppose we have free disposal-items can be thrown away at no cost.",
        "Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.)",
        "Definition 10.",
        "Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
        "We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item.",
        "The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type.",
        "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the payment maximizing AMD problem!",
        "Theorem 4.",
        "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types.",
        "Proof.",
        "The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming.",
        "To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal combinatorial auction design problem instance with a single bidder with best-only preferences.",
        "For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance).",
        "Let the expected revenue target value be the same in both instances.",
        "We show the instances are equivalent.",
        "First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function.",
        "Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.)",
        "Let the payment functions be the same in both instances.",
        "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution.",
        "Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same.",
        "It follows that there exists a solution to the optimal auction design instance.",
        "Now suppose there exists a solution to the optimal auction design instance.",
        "By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item.",
        "Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type.",
        "If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type.",
        "Let the payment functions be the same.",
        "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution.",
        "Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same.",
        "It follows that there exists a solution to the AMD instance.",
        "Fortunately, we can also carry through the easiness result for randomized mechanisms to this combinatorial auction setting-giving us one of the few known polynomial-time algorithms for an optimal combinatorial auction design problem.",
        "Theorem 5.",
        "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.)",
        "Proof.",
        "By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item.",
        "There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations.",
        "Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8.",
        "RELATED RESEARCH ON COMPLEXITY IN MECHANISM DESIGN There has been considerable recent interest in mechanism design in computer science.",
        "Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism.",
        "The closest piece of earlier work studied the complexity of automated mechanism design by a benevolent designer [5, 6].",
        "Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21].",
        "This is related to mechanism design, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments).",
        "Also, there is no explicit reporting of preferences. 9.",
        "CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
        "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
        "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
        "In a recently emerging approach-called automated mechanism design-a mechanism is computed for the specific preference aggregation setting at hand.",
        "This has several advantages, 139 but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
        "Unlike earlier work on automated mechanism design that studied a benevolent designer, in this paper we studied automated mechanism design problems where the designer is self-interesteda setting much more relevant for electronic commerce.",
        "In this setting, the center cares only about which outcome is chosen and what payments are made to it.",
        "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
        "In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
        "These hardness results imply hardness in all more general automated mechanism design settings with a self-interested designer.",
        "The hardness results apply whether the individual rationality (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation.",
        "We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy.",
        "Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
        "We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy.",
        "Future research includes studying automated mechanism design with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments).",
        "We also want to study the complexity of automated mechanism design in settings where the outcome and type spaces have special structure so they can be represented more concisely.",
        "Finally, we plan to assemble a data set of real-world mechanism design problems-both historical and current-and apply automated mechanism design to those problems. 10.",
        "REFERENCES [1] M. Armstrong.",
        "Optimal multi-object auctions.",
        "Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow.",
        "The property rights doctrine and demand revelation under incomplete information.",
        "In M. Boskin, editor, Economics and human welfare.",
        "New York Academic Press, 1979. [3] C. Avery and T. Hendershott.",
        "Bundling and optimal auctions of multiple products.",
        "Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke.",
        "Multipart pricing of public goods.",
        "Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm.",
        "Complexity of mechanism design.",
        "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
        "Automated mechanism design: Complexity results stemming from the single-agent setting.",
        "In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm.",
        "Computational criticisms of the revelation principle.",
        "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004.",
        "Short paper.",
        "Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet.",
        "Incentives and incomplete information.",
        "Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker.",
        "Sharing the cost of muliticast transmissions.",
        "Journal of Computer and System Sciences, 63:21-41, 2001.",
        "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard.",
        "Manipulation of voting schemes.",
        "Econometrica, 41:587-602, 1973. [11] T. Groves.",
        "Incentives in teams.",
        "Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri.",
        "Vickrey prices and shortest paths: What is an edge worth?",
        "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan.",
        "A polynomial algorithm in linear programming.",
        "Soviet Math.",
        "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani.",
        "The minimum satisfiability problem.",
        "SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham.",
        "Truth revelation in rapid, approximately efficient combinatorial auctions.",
        "Journal of the ACM, 49(5):577-602, 2002.",
        "Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green.",
        "Microeconomic Theory.",
        "Oxford University Press, 1995. [17] E. S. Maskin and J. Riley.",
        "Optimal multi-unit auctions.",
        "In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335.",
        "Clarendon Press, Oxford, 1989. [18] R. Myerson.",
        "Optimal auction design.",
        "Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen.",
        "Computationally feasible VCG mechanisms.",
        "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen.",
        "Algorithmic mechanism design.",
        "Games and Economic Behavior, 35:166-196, 2001.",
        "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden.",
        "Designing networks for selfish users is hard.",
        "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm.",
        "Issues in computational Vickrey auctions.",
        "International Journal of Electronic Commerce, 4(3):107-129, 2000.",
        "Special Issue on 140 Applying Intelligent Agents for Electronic Commerce.",
        "A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite.",
        "Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions.",
        "Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey.",
        "Counterspeculation, auctions, and competitive sealed tenders.",
        "Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra.",
        "Research problems in combinatorial auctions.",
        "Mimeo, version Oct. 29, 2001. 141"
    ],
    "translated_text_sentences": [
        "Diseño de mecanismos automatizados de interés propio e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes.",
        "La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les resulte más favorable.",
        "El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable.",
        "En un enfoque recientemente propuesto, llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración de agregación de preferencias actual.",
        "Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez.",
        "A diferencia de trabajos anteriores sobre el diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo.",
        "En este caso, al centro solo le importa qué resultado se elige y qué pagos se le hacen.",
        "La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo.",
        "En este contexto, demostramos que el diseño de mecanismos deterministas óptimos es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido.",
        "Luego mostramos cómo permitir la aleatorización en el mecanismo hace que los problemas en este entorno sean computacionalmente fáciles.",
        "Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (maximizadora de ingresos), donde los postores tienen preferencias solo por lo mejor.",
        "Mostramos que aquí también, diseñar una subasta determinista óptima es NP-completo, pero diseñar una subasta aleatoria óptima es fácil.",
        "Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Teoría 1.",
        "En entornos multiagentes, a menudo se debe elegir un resultado en función de las preferencias informadas por un grupo de agentes.",
        "Tales resultados podrían ser presidentes potenciales, planes conjuntos, asignaciones de bienes o recursos, etc.",
        "El agregador de preferencias generalmente no conoce las preferencias de los agentes de antemano.",
        "Más bien, los agentes informan sus preferencias al coordinador.",
        "Desafortunadamente, un agente puede tener un incentivo para informar incorrectamente sus preferencias con el fin de engañar al mecanismo y lograr que seleccione un resultado que sea más deseable para el agente que el resultado que se seleccionaría si el agente revelara sus preferencias de manera honesta.",
        "Tal manipulación es indeseable porque los mecanismos de agregación de preferencias están diseñados para agrupar las preferencias de una manera socialmente deseable, y si los agentes revelan sus preferencias de manera insincera, se podría elegir un resultado socialmente indeseable.",
        "La manipulabilidad es un problema generalizado en los mecanismos de agregación de preferencias.",
        "Un resultado negativo seminal, el teorema de Gibbard-Satterthwaite, muestra que bajo cualquier esquema de agregación de preferencias no dictatorial, si hay al menos 3 posibles resultados, existen preferencias bajo las cuales un agente está mejor reportando falsamente [10, 23]. (Un esquema de agregación de preferencias se llama dictatorial si uno de los agentes dicta el resultado sin importar las preferencias que reporten los otros agentes).",
        "Lo que le gustaría hacer al agregador es diseñar un mecanismo de agregación de preferencias para que 1) los agentes interesados reporten sus preferencias de manera veraz, y 2) el mecanismo elija un resultado que sea deseable desde la perspectiva de algún objetivo.",
        "Esta es la configuración clásica del diseño de mecanismos en la teoría de juegos.",
        "En este documento, estudiamos el caso en el que el diseñador actúa por interés propio, es decir, al diseñador no le importa directamente cómo se relaciona el resultado con las preferencias de los agentes, sino que está más preocupado por su propia agenda sobre cuál resultado debería ser elegido y en maximizar los pagos para sí mismo.",
        "Este es el entorno de diseño de mecanismos más relevante para el comercio electrónico.",
        "En el caso en que el diseñador del mecanismo esté interesado en maximizar alguna noción de bienestar social, la importancia de recopilar las preferencias de los agentes es clara.",
        "Quizás sea menos obvio por qué deberían ser recopilados cuando el diseñador está interesado en sí mismo y, por lo tanto, su objetivo no está directamente relacionado con las preferencias de los agentes.",
        "La razón de esto es que a menudo las preferencias de los agentes imponen límites en cómo el diseñador elige el resultado y los pagos.",
        "La restricción más común de este tipo es la de racionalidad individual (RI), lo que significa que el mecanismo no puede dejar a ningún agente en una situación peor a la que hubiera estado si no hubiera participado en el mecanismo.",
        "Por ejemplo, en el contexto del diseño óptimo de subastas, el diseñador (subastador) solo se preocupa por cuántos ingresos se recaudan, y no en sí mismo por cuán bien la asignación del bien (o bienes) corresponde a las preferencias de los agentes.",
        "Sin embargo, el diseñador no puede obligar a un agente a pagar más de lo que valora el paquete de bienes asignado a él.",
        "Por lo tanto, incluso un diseñador interesado en sí mismo elegirá un resultado que beneficie razonablemente a los agentes.",
        "Por otro lado, el diseñador no necesariamente elegirá un resultado que maximice el bienestar social.",
        "Por ejemplo, si el diseñador siempre elige un resultado que maximiza el bienestar social con respecto a las preferencias informadas, y obliga a cada agente a pagar la diferencia entre la utilidad que tiene ahora y la utilidad que habría tenido si no hubiera participado en el mecanismo, es fácil ver que los agentes pueden tener un incentivo para informar incorrectamente sus preferencias, lo que puede llevar realmente a recaudar menos ingresos.",
        "De hecho, uno de los resultados contraintuitivos de la teoría del diseño de subastas óptimas es que a veces el bien se asigna a nadie incluso cuando el subastador tiene un precio de reserva de 0.",
        "El diseño de mecanismos clásicos proporciona algunos mecanismos generales, que, bajo ciertas suposiciones, satisfacen alguna noción de no manipulabilidad y maximizan algún objetivo.",
        "La ventaja de estos mecanismos es que no dependen de información (incluso probabilística) sobre las preferencias de los agentes (por ejemplo, el mecanismo de Vickrey-Clarke-Groves (VCG) [24, 4, 11]), o pueden aplicarse fácilmente a cualquier distribución de probabilidad sobre las preferencias (por ejemplo, el mecanismo dAGVA [8, 2], la subasta de Myerson [18], y la subasta multiunidad de Maskin-Riley [17]).",
        "Sin embargo, los mecanismos generales también tienen importantes desventajas: • Los mecanismos generales más famosos y ampliamente aplicables, VCG y dAGVA, solo maximizan el bienestar social.",
        "Si el diseñador está interesado en sí mismo, como es el caso en muchos entornos de comercio electrónico, estos mecanismos no maximizan el objetivo del diseñador. • Los mecanismos generales que se centran en un diseñador interesado en sí mismo solo son aplicables en entornos muy restringidos, como la subasta de maximización de ingresos esperados de Myerson para vender un solo artículo, y la subasta de maximización de ingresos esperados de Maskin y Riley para vender múltiples unidades idénticas de un artículo. • Incluso en los entornos restringidos en los que se aplican estos mecanismos, solo permiten la maximización de pagos.",
        "En la práctica, el diseñador también puede estar interesado en el resultado en sí mismo.",
        "Por ejemplo, a un subastador le puede importar qué postor recibe el artículo. • A menudo se asume que los pagos laterales pueden ser utilizados para adaptar los incentivos de los agentes, pero esto no siempre es práctico.",
        "Por ejemplo, en los mercados electrónicos basados en trueque, como Recipco, firstbarter.com, BarterOne e Intagio, no se permiten los pagos laterales.",
        "Además, entre los agentes de software, podría ser más deseable construir mecanismos que no dependan de la capacidad de realizar pagos, ya que muchos agentes de software no cuentan con la infraestructura para hacer pagos.",
        "Por el contrario, seguimos un enfoque reciente donde el mecanismo se diseña automáticamente para el problema específico en cuestión.",
        "Este enfoque aborda todos los inconvenientes mencionados anteriormente.",
        "Formulamos el problema de diseño de mecanismos como un problema de optimización.",
        "La entrada se caracteriza por el número de agentes, los posibles tipos de agentes (preferencias) y las distribuciones previas de los agregadores sobre los tipos de agentes.",
        "La salida es un mecanismo no manipulable que es óptimo con respecto a algún objetivo.",
        "Este enfoque se llama diseño de mecanismos automatizado.",
        "El enfoque de diseño de mecanismos automatizado tiene cuatro ventajas sobre el enfoque clásico de diseñar mecanismos generales.",
        "Primero, se puede utilizar incluso en entornos que no cumplen con las suposiciones de los mecanismos clásicos (como la disponibilidad de pagos laterales o que el objetivo sea el bienestar social).",
        "Segundo, puede permitir a uno eludir resultados de imposibilidad (como el teorema de Gibbard-Satterthwaite) que establecen que no existe un mecanismo que sea deseable para todas las preferencias.",
        "Cuando el mecanismo está diseñado para la configuración actual, no importa que no funcione de manera más general.",
        "Tercero, puede generar mecanismos mejores (en términos de garantías de no manipulabilidad más sólidas y/o mejores resultados) que los mecanismos clásicos porque el mecanismo aprovecha las particularidades del entorno (la información probabilística que el diseñador tiene sobre los tipos de agentes).",
        "Dada la gran cantidad de información que las partes tienen entre sí hoy en día, es probable que este enfoque conduzca a ahorros enormes en comparación con los mecanismos clásicos, que en su mayoría ignoran esa información.",
        "Por ejemplo, imagina una empresa creando automáticamente su mecanismo de adquisiciones basado en el conocimiento estadístico sobre sus proveedores, en lugar de utilizar una subasta de adquisiciones descendente clásica.",
        "Cuarto, la carga del diseño se traslada de los humanos a una máquina.",
        "Sin embargo, el diseño automatizado de mecanismos requiere que el problema de optimización del diseño del mecanismo se resuelva de nuevo para cada configuración.",
        "Por lo tanto, su complejidad computacional se convierte en un tema clave.",
        "Investigaciones previas han estudiado esta pregunta para diseñadores benevolentes que desean maximizar, por ejemplo, el bienestar social [5, 6].",
        "En este artículo estudiamos la complejidad computacional del diseño automatizado de mecanismos en el caso de un diseñador con interés propio.",
        "Esta es una configuración importante para el diseño de mecanismos automatizados debido a la escasez de mecanismos generales en esta área, y al hecho de que en la mayoría de las configuraciones de comercio electrónico el diseñador actúa en su propio interés.",
        "También demostramos que este problema está estrechamente relacionado con un problema de diseño de subasta combinatoria óptima (maximización de ingresos) particular. El resto de este documento está organizado de la siguiente manera.",
        "En la Sección 2, justificamos el enfoque en mecanismos no manipulables.",
        "En la Sección 3, definimos el problema que estudiamos.",
        "En la Sección 4, demostramos que diseñar un mecanismo determinista óptimo es NP-completo incluso cuando al diseñador solo le importan los pagos que recibe.",
        "En la Sección 5, demostramos que diseñar un mecanismo determinista óptimo también es NP-completo cuando los pagos no son posibles y el diseñador solo está interesado en el resultado elegido.",
        "En la Sección 6, demostramos que un mecanismo óptimo aleatorizado puede ser diseñado en tiempo polinómico incluso en el caso general.",
        "Finalmente, en la Sección 7, demostramos que para diseñar subastas combinatorias óptimas bajo preferencias de mejor opción solamente, nuestros resultados sobre AMD implican que este problema es NP-completo para subastas determinísticas, pero sencillo para subastas aleatorias. 2.",
        "JUSTIFICANDO EL ENFOQUE EN MECANISMOS NO MANIPULABLES Antes de definir el problema computacional del diseño automatizado de mecanismos, debemos justificar nuestro enfoque en mecanismos no manipulables.",
        "Después de todo, no es inmediatamente obvio que no haya mecanismos manipulables que, incluso cuando los agentes informan estratégicamente sus tipos y, por lo tanto, a veces de manera no veraz, aún logren mejores resultados (según el objetivo que usemos) que cualquier mecanismo no manipulable.",
        "Sin embargo, resulta ser el caso que, dado cualquier mecanismo, podemos construir un mecanismo no manipulable cuyo rendimiento es idéntico, de la siguiente manera.",
        "Construimos una capa de interfaz entre los agentes y el mecanismo original.",
        "Los agentes informan sus preferencias (o tipos) a la capa de interfaz; posteriormente, la capa de interfaz introduce en el mecanismo original los tipos que los agentes habrían informado estratégicamente al mecanismo original, si sus tipos fueran los declarados a la capa de interfaz.",
        "El resultado resultante es el resultado del nuevo mecanismo.",
        "Dado que la capa de interfaz actúa estratégicamente en nombre de cada agente, nunca hay un incentivo para informar falsamente a la capa de interfaz; por lo tanto, los tipos informados por la capa de interfaz son los tipos estratégicos que se habrían informado sin la capa de interfaz, por lo que los resultados son exactamente como habrían sido con el mecanismo original.",
        "Este argumento es conocido en la literatura de diseño de mecanismos como el principio de revelación [16]. (Existen dificultades computacionales al aplicar el principio de revelación en espacios de resultados y tipos combinatorios grandes [7, 22]).",
        "Sin embargo, dado que aquí nos enfocamos en espacios de resultados y tipos representados de forma plana, esto no es una preocupación aquí.",
        "Dado esto, podemos centrarnos en mecanismos veraces en el resto del documento. 3.",
        "DEFINICIONES Ahora formalizamos el entorno del diseño automatizado de mecanismos.",
        "Definición 1.",
        "En un entorno de diseño de mecanismos automatizados, se nos proporciona: • un conjunto finito de resultados O; • un conjunto finito de N agentes; • para cada agente i, 1. un conjunto finito de tipos Θi, 2. una distribución de probabilidad γi sobre Θi (en el caso de tipos correlacionados, hay una única distribución conjunta γ sobre Θ1 × . . . × ΘN), y 3. una función de utilidad ui: Θi × O → R; 1 • Una función objetivo cuya expectativa el diseñador desea maximizar.",
        "Existen muchas posibles funciones objetivo que el diseñador podría tener, por ejemplo, el bienestar social (donde el diseñador busca maximizar la suma de las utilidades de los agentes), o la utilidad mínima de cualquier agente (donde el diseñador busca maximizar la peor utilidad experimentada por cualquier agente).",
        "En ambos casos, el diseñador es benevolente, ya que, de alguna manera, el diseñador está buscando la felicidad colectiva de los agentes.",
        "Sin embargo, en este documento nos enfocamos en el caso de un diseñador interesado en sí mismo.",
        "Un diseñador egoísta solo se preocupa por el resultado elegido (es decir, al diseñador no le importa cómo se relaciona el resultado con las preferencias de los agentes, sino que tiene una preferencia fija sobre los resultados) y sobre los pagos netos realizados por los agentes, que fluyen hacia el diseñador.",
        "Definición 2.",
        "Un diseñador interesado tiene una función objetivo dada por g(o) + Σ i=1 πi, donde g : O → R indica las preferencias del diseñador sobre los resultados, y πi es el pago realizado por el agente i.",
        "En el caso en que g = 0 en todas partes, se dice que el diseñador está maximizando el pago.",
        "En el caso en que los pagos no sean posibles, g constituye la función objetivo por sí sola.",
        "Ahora definimos los tipos de mecanismos en estudio.",
        "Por el principio de revelación, podemos restringir la atención a mecanismos de revelación directa y veraz, donde los agentes informan directamente sus tipos y nunca tienen incentivos para informarlos de manera incorrecta.",
        "Definición 3.",
        "Consideramos los siguientes tipos de mecanismos: • Un mecanismo determinista sin pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O. • Un mecanismo aleatorio sin pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), donde P(O) es el conjunto de distribuciones de probabilidad sobre O. • Un mecanismo determinista con pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O y, para cada agente i, una función de selección de pagos πi: Θ1 × Θ2 × . . . × ΘN → R, donde πi(θ1, . . . , θN ) da el pago realizado por el agente i cuando los tipos reportados son θ1, . . . , θN. Aunque esto sigue la notación estándar de la teoría de juegos [16], el hecho de que el agente tenga tanto una función de utilidad como un tipo puede resultar confuso.",
        "Los tipos codifican las diversas preferencias posibles que el agente pueda tener, y el tipo de los agentes no es conocido por el agregador.",
        "La función de utilidad es un conocimiento común, pero debido a que el tipo de agente es un parámetro en la función de utilidad de los agentes, el agregador no puede saber cuál es la utilidad de los agentes sin conocer el tipo de agente. Un mecanismo aleatorio con pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), y para cada agente i, una función de selección de pago πi: Θ1 × Θ2 × . . . × ΘN → R. Hay dos tipos de restricciones para el diseñador al construir el mecanismo. 3.1 Restricciones de racionalidad individual (IR) El primer tipo de restricción es el siguiente.",
        "La utilidad de cada agente debe ser al menos tan grande como la utilidad de respaldo de los agentes, es decir, la utilidad que el agente recibiría si no participara en el mecanismo.",
        "De lo contrario, ese agente no participaría en el mecanismo, y la participación de ningún agente puede perjudicar el objetivo de los diseñadores del mecanismo, ya que en el peor de los casos, el mecanismo puede ignorar a un agente fingiendo que el agente no está presente. (Además, si no se aplicara tal restricción, el diseñador simplemente podría hacer que los agentes paguen una cantidad infinita).",
        "Este tipo de restricción se llama restricción de IR (racionalidad individual).",
        "Existen tres posibles restricciones de IR diferentes: ex ante, ex interim y ex post, dependiendo de lo que el agente sabe sobre su propio tipo y los tipos de los demás al decidir si participar en el mecanismo.",
        "Ex ante IR significa que el agente participaría si no supiera absolutamente nada (ni siquiera su propio tipo).",
        "No estudiaremos este concepto en este documento.",
        "Ex interim IR significa que el agente siempre participaría si conociera solo su propio tipo, pero no el de los demás.",
        "Ex post IR significa que el agente siempre participaría incluso si conociera el tipo de todos.",
        "Definiremos formalmente las dos últimas nociones de IR.",
        "Primero, necesitamos formalizar el concepto del resultado de respaldo.",
        "Suponemos que la utilidad de respaldo de cada agente es cero para cada uno de sus tipos.",
        "Esto se hace sin pérdida de generalidad porque podemos agregar un término constante a la función de utilidad de un agente (para un tipo dado), sin afectar el comportamiento de toma de decisiones de ese agente maximizador de utilidad esperada [16].",
        "Definición 4.",
        "En cualquier entorno de diseño de mecanismos automatizados con una restricción de IR, existe un resultado de contingencia o0 ∈ O donde, para cualquier agente i y cualquier tipo θi ∈ Θi, tenemos ui(θi, o0) = 0. (Además, en el caso de un diseñador egoísta, g(o0) = 0).",
        "Ahora podemos definir las nociones de racionalidad individual.",
        "Definición 5.",
        "La racionalidad individual (RI) se define como: • Un mecanismo determinista es ex interim RI si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
        "Un mecanismo aleatorio es ex interim IR si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • Un mecanismo determinista es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 No aleatorizamos sobre los pagos porque mientras los agentes y el diseñador sean neutrales al riesgo con respecto a los pagos, es decir, su utilidad es lineal en los pagos, no hay razón para aleatorizar sobre los pagos.",
        "Un mecanismo aleatorio es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
        "Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 3.2 Restricciones de compatibilidad de incentivos (IC) El segundo tipo de restricción establece que los agentes nunca deben tener un incentivo para informar incorrectamente su tipo (como se justificó anteriormente mediante el principio de revelación).",
        "Para este tipo de restricción, las dos variantes más comunes (o conceptos de solución) son la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash.",
        "Definición 6.",
        "En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en estrategias dominantes si decir la verdad siempre es óptimo incluso cuando los tipos reportados por los otros agentes ya son conocidos.",
        "Formalmente, para cualquier agente i, cualquier vector de tipos (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
        "En el caso de mecanismos aleatorios tenemos Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
        "Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles.",
        "Por lo tanto, en la implementación de estrategias dominantes, decir la verdad es óptimo independientemente de lo que informen los otros agentes.",
        "Si es óptimo solo dado que los otros agentes son veraces, y dado que uno no conoce los tipos de los otros agentes, tenemos implementación en equilibrio de Bayes-Nash.",
        "Definición 7.",
        "En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en equilibrio de Bayes-Nash si decir la verdad siempre es óptimo para un agente cuando ese agente aún no sabe nada sobre los tipos de los otros agentes, y los otros agentes están diciendo la verdad.",
        "Formalmente, para cualquier agente i, cualquier tipo θi ∈ Θi, y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
        "En el caso de mecanismos aleatorios tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
        "Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 135 3.3 Diseño de mecanismos automatizados Ahora podemos definir el problema computacional que estudiamos.",
        "Definición 8. (DISEÑO DE MECANISMOS AUTOMATIZADOS (AMD)) Se nos da: • un entorno de diseño de mecanismos automatizados, • una noción de IR (ex interim, ex post, o ninguna), • un concepto de solución (estrategias dominantes o Bayes-Nash), • si los pagos son posibles, • si la aleatorización es posible, • (en la variante de decisión del problema) un valor objetivo G. Se nos pregunta si existe un mecanismo del tipo especificado (en términos de pagos y aleatorización) que satisfaga tanto la noción de IR como el concepto de solución, y proporcione un valor esperado de al menos G para el objetivo.",
        "Un caso especial interesante es aquel en el que solo hay un agente.",
        "En este caso, el agente informante siempre sabe todo lo que hay que saber sobre los otros tipos de agentes, porque no hay otros agentes.",
        "Dado que el IR ex post y el IR ex interim solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de IR coinciden aquí.",
        "Además, dado que la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de solución coinciden aquí.",
        "Esta observación resultará ser una herramienta útil para demostrar resultados de dificultad: si demostramos dificultad computacional en el escenario de un solo agente, esto implica inmediatamente dificultad para ambos conceptos de IR, para ambos conceptos de solución, para cualquier número de agentes. 4.",
        "En esta sección demostramos que es NP-completo diseñar un mecanismo determinístico que maximice la suma esperada de los pagos recolectados de los agentes.",
        "Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución.",
        "Para demostrar la NP-dureza, reducimos desde el problema MINSAT.",
        "Definición 9 (MINSAT).",
        "Se nos da una fórmula φ en forma normal conjuntiva, representada por un conjunto de variables booleanas V y un conjunto de cláusulas C, y un entero K (K < |C|).",
        "Se nos pregunta si existe una asignación a las variables en V tal que se satisfacen a lo sumo K cláusulas en φ.",
        "MINSAT fue recientemente demostrado como NP-completo [14].",
        "Ahora podemos presentar nuestro resultado.",
        "Teorema 1.",
        "El problema determinista de maximización de pagos de AMD es NP-completo, incluso para un solo agente, incluso con una distribución uniforme de tipos.",
        "Prueba.",
        "Es fácil demostrar que el problema está en NP.",
        "Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista de maximización de pagos de un solo agente.",
        "Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables.",
        "Que la distribución de probabilidad sobre estos tipos sea uniforme.",
        "Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
        "Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}.",
        "Sea l ∈ c denota que el literal l ocurre en la cláusula c. Entonces, la función de utilidad de los agentes está dada por u(θc, ol) = |Θ| + 1 para todo l ∈ L con l ∈ c; u(θc, ol) = 0 para todo l ∈ L con l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc) = 0 para todo c ∈ C con c = c; u(θv, ol) = |Θ| para todo l ∈ L con v(l) = v; u(θv, ol) = 0 para todo l ∈ L con v(l) = v; u(θv, oc) = 0 para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ|, donde K es el objetivo de la instancia de MINSAT.",
        "Mostramos que las instancias son equivalentes.",
        "Primero, supongamos que hay una solución para la instancia de MINSAT.",
        "Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V).",
        "Entonces, para cada v ∈ V, sea o(θv) = of(v) y π(θv) = |Θ|.",
        "Para cada c ∈ C, sea o(θc) = oc; sea π(θc) = |Θ| + 1 si c no está satisfecha en la solución MINSAT, y π(θc) = |Θ| si c está satisfecha.",
        "Es sencillo comprobar que se cumple la restricción de IR.",
        "Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta.",
        "Si el tipo de los agentes es θv, entonces cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivo para informar de manera incorrecta.",
        "Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivos para informar de manera incorrecta.",
        "El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha.",
        "En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT.",
        "Porque además, ningún tipo que no sea θc conduce al resultado oc, informar cualquier otro tipo dará como resultado una utilidad de 0, mientras que aún se requiere un pago de al menos |Θ| por parte del agente.",
        "Claramente, el agente está mejor reportando honestamente, para una utilidad total de 0.",
        "Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta.",
        "Finalmente, demostramos que se alcanza el objetivo.",
        "Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), el pago esperado de este mecanismo es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD.",
        "Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o y una función de pago π.",
        "Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}.",
        "Entonces, la utilidad que el agente obtiene del resultado dado para este tipo es 0, y por lo tanto, según la IR, no se puede extraer ningún pago del agente para este tipo.",
        "Dado que, nuevamente por IR, el pago máximo que se puede extraer para cualquier otro tipo es |Θ| + 1, se sigue que el pago esperado máximo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo cual contradice que esta sea una solución para la instancia de AMD.",
        "Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o−v.",
        "Reclamamos que esta tarea es una solución a la instancia de MINSAT.",
        "Por la restricción de IR, el pago máximo que podemos extraer de cualquier tipo θv es |Θ|.",
        "Dado que no puede haber incentivos para que el agente informe falsamente, para cualquier cláusula c satisfecha por la asignación dada, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ|. (Pues si extrajéramos más de este tipo, la utilidad del agente en este caso sería menor que 1; y si v es la variable que satisface c en la asignación, de modo que o(θv) = ol donde l ocurre en c, entonces al agente le convendría más informar θv en lugar del informe veraz θc, para obtener un resultado que valga |Θ|+1 para él mientras tiene que pagar como máximo |Θ|.)",
        "Finalmente, para cualquier cláusula insatisfecha c, según la restricción de IR, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ| + 1.",
        "Se deduce que el pago esperado de nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas satisfechas.",
        "Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia de MINSAT.",
        "Dado que AMD, que maximiza el pago, es solo un caso especial de AMD para un diseñador egoísta en el que el diseñador no tiene preferencias sobre el resultado elegido, esto implica inmediatamente dificultades para el caso general de AMD para un diseñador egoísta en el que los pagos son posibles.",
        "Sin embargo, esto aún no implica dureza para el caso especial donde los pagos no son posibles.",
        "Demostraremos la dificultad en este caso en la próxima sección. 5.",
        "En esta sección demostramos que es NP-completo diseñar un mecanismo determinista que maximice la expectativa del objetivo del diseñador cuando no son posibles los pagos.",
        "Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución.",
        "Teorema 2.",
        "Sin pagos, el diseño determinista de AMD para un diseñador egoísta es NP-completo, incluso para un solo agente, incluso con una distribución uniforme sobre los tipos.",
        "Prueba.",
        "Es fácil demostrar que el problema está en NP.",
        "Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista auto-interesada de un solo agente sin pagos.",
        "Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables.",
        "Que la distribución de probabilidad sobre estos tipos sea uniforme.",
        "Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L} ∪ {o∗}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V} ∪ {−v : v ∈ V}.",
        "Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}.",
        "Deje que l ∈ c denote que el literal l ocurre en la cláusula c. Luego, deje que la función de utilidad de los agentes esté dada por u(θc, ol) = 2 para todo l ∈ L con l ∈ c; u(θc, ol) = −1 para todo l ∈ L con l /∈ c; u(θc, oc) = 2; u(θc, oc) = −1 para todo c ∈ C con c = c; u(θc, o∗) = 1; u(θv, ol) = 1 para todo l ∈ L con v(l) = v; u(θv, ol) = −1 para todo l ∈ L con v(l) = v; u(θv, oc) = −1 para todo c ∈ C; u(θv, o∗) = −1.",
        "Que la función objetivo de los diseñadores esté dada por g(o∗ ) = |Θ|+1; g(ol) = |Θ| para todo l ∈ L; g(oc) = |Θ| para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ| , donde K es el objetivo de la instancia de MINSAT.",
        "Mostramos que las instancias son equivalentes.",
        "Primero, supongamos que hay una solución para la instancia de MINSAT.",
        "Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V).",
        "Entonces, para cada v ∈ V, sea o(θv) = of(v).",
        "Para cada c ∈ C que se cumpla en la solución MINSAT, sea o(θc) = oc; para cada c ∈ C no satisfecho, sea o(θc) = o∗.",
        "Es sencillo comprobar que se cumple la restricción de IR.",
        "Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta.",
        "Si el tipo de los agentes es algún θv, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para reportar de manera incorrecta.",
        "Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para informar de manera incorrecta.",
        "El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha.",
        "En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT.",
        "Debido a que tampoco ningún tipo conduce al resultado oc, no hay ningún resultado que el mecanismo seleccione que le daría al agente una utilidad mayor a 1 para el tipo θc, y por lo tanto el agente no tiene incentivo para informar falsamente.",
        "Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta.",
        "Finalmente, demostramos que se alcanza el objetivo.",
        "Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), entonces el valor esperado de la función objetivo de los diseñadores es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD.",
        "Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o.",
        "Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}.",
        "El único otro resultado que el mecanismo puede elegir bajo la restricción de IR es o0.",
        "Esto tiene un valor objetivo de 0, y dado que el valor más alto que la función objetivo alcanza es |Θ| + 1, se sigue que el valor esperado máximo de la función objetivo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo que contradice que esta sea una solución para la instancia de AMD.",
        "Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}.",
        "Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o-v.",
        "Reclamamos que esta tarea es una solución a la instancia de MINSAT.",
        "Por lo anterior, para cualquier tipo θv, el valor de la función objetivo en este mecanismo será |Θ|.",
        "Para cualquier cláusula c satisfecha por la asignación dada, el valor de la función objetivo en el caso en que el agente informe el tipo θc será como máximo |Θ|. (Esto se debe a que no podemos elegir el resultado o∗ para dicho tipo, ya que en este caso el agente tendría un incentivo para informar θv en su lugar, donde v es la variable que satisface c en la asignación (de modo que o(θv) = ol donde l ocurre en c).)",
        "Finalmente, para cualquier cláusula insatisfecha c, el valor máximo que la función objetivo puede alcanzar en el caso en que el agente informa el tipo θc es |Θ| + 1, simplemente porque este es el valor más grande que la función alcanza en cualquier momento.",
        "Se deduce que el valor esperado de la función objetivo para nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas 137 satisfechas.",
        "Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia MINSAT.",
        "Ambos de nuestros resultados de dureza se basaron en la restricción de que el mecanismo debería ser determinista.",
        "En la siguiente sección, mostramos que la dificultad del diseño desaparece cuando permitimos la aleatorización en el mecanismo. 6.",
        "La aleatorización de AMD para un diseñador interesado en sí mismo es fácil. Ahora mostramos cómo permitir la aleatorización sobre los resultados hace que el problema de AMD auto-interesado sea manejable a través de la programación lineal, para cualquier número constante de agentes.",
        "Teorema 3.",
        "El AMD aleatorio con interés propio con un número constante de agentes es resoluble en tiempo polinómico mediante programación lineal, tanto con pagos como sin pagos, tanto para IR ex post como ex interim, y tanto para la implementación en estrategias dominantes como para la implementación en equilibrio de Bayes-Nash, incluso si los tipos están correlacionados.",
        "Prueba.",
        "Dado que los programas lineales pueden resolverse en tiempo polinómico [13], todo lo que necesitamos demostrar es que el número de variables y ecuaciones en nuestro programa es polinomial para cualquier número constante de agentes, es decir, exponencial solo en N. En todo momento, para determinar el tamaño del programa lineal, consideremos T = maxi{|Θi|}.",
        "Las variables de nuestro programa lineal serán las probabilidades (p(θ1, θ2, . . . , θN ))(o) (como máximo TN |O| variables) y los pagos πi(θ1, θ2, . . . , θN ) (como máximo NTN variables). (Mostramos el programa lineal para el caso en que los pagos son posibles; el caso sin pagos se obtiene fácilmente de esto simplemente omitiendo todas las variables de pago en el programa, o agregando restricciones adicionales que obliguen a los pagos a ser 0).",
        "Primero, mostramos las restricciones de IR.",
        "Para el IR ex post, agregamos las siguientes restricciones (como máximo NTN) al LP: • Para cada i ∈ {1, 2, . . . , N}, y para cada (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , agregamos ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
        "Para el ex interino IR, agregamos las siguientes restricciones (como máximo NT) al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada θi ∈ Θi, agregamos θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
        "Ahora, mostramos las restricciones del concepto de solución.",
        "Para la implementación en estrategias dominantes, agregamos las siguientes (a lo sumo NTN+1) restricciones al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
        "Finalmente, para la implementación en el equilibrio de Bayes-Nash, agregamos las siguientes (a lo sumo NT2) restricciones al LP: • Para cada i ∈ {1, 2, ..., N}, para cada θi ∈ Θi, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
        "Todo lo que queda por hacer es dar la expresión que el diseñador busca maximizar, que es: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
        "Como indicamos, el número de variables y restricciones es exponencial solo en N, por lo tanto, el programa lineal tiene un tamaño polinómico para un número constante de agentes.",
        "Por lo tanto, el problema es resoluble en tiempo polinómico.",
        "IMPLICACIONES PARA UN PROBLEMA DE DISEÑO DE SUBASTA COMBINATORIA ÓPTIMA En esta sección, demostraremos algunas consecuencias interesantes del problema de diseño de mecanismos automatizados para un diseñador interesado en sí mismo en el diseño de subastas combinatorias óptimas.",
        "Considera una subasta combinatoria con un conjunto S de artículos en venta.",
        "Para cualquier conjunto B ⊆ S, dejemos que ui(θi, B) sea la utilidad del postor i al recibir el conjunto B cuando el tipo del postor es θi.",
        "El problema de diseño de subasta óptima consiste en especificar las reglas de la subasta de manera que se maximice los ingresos esperados para el subastador. (Por el principio de revelación, sin pérdida de generalidad, podemos asumir que la subasta es veraz).",
        "El problema de diseño de subasta óptima se resuelve para el caso de un solo artículo mediante la famosa subasta de Myerson [18].",
        "Sin embargo, el diseño de subastas óptimas en subastas combinatorias es un problema de investigación abierto reconocido [3, 25].",
        "El problema está abierto incluso si solo hay dos artículos en venta. (El caso de dos artículos con una forma muy especial de complementariedad y sin sustituibilidad ha sido resuelto recientemente [1].)",
        "Supongamos que tenemos disposición libre: los artículos pueden ser desechados sin costo alguno.",
        "Además, supongamos que las preferencias de los postores tienen la siguiente estructura: cuando un postor recibe un conjunto de artículos, la utilidad del postor por ese conjunto está determinada únicamente por el mejor artículo en el conjunto. (Enfatizamos que qué artículo es el mejor puede depender del tipo de postor).",
        "Definición 10.",
        "Se dice que el postor i tiene preferencias solo por lo mejor sobre paquetes de artículos si existe una función vi: Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
        "Hacemos la siguiente observación útil en este contexto: no tiene sentido otorgarle a un postor más de un artículo.",
        "La razón es que si el postor está informando honestamente, quitarle todos los artículos menos el de mayor valor no perjudicará al postor; y, mediante la disposición gratuita, hacerlo solo reducirá el incentivo para que este postor informe falsamente este tipo, cuando en realidad tiene otro tipo.",
        "Ahora demostramos que el problema de diseñar una subasta óptima determinista es NP-completo, mediante una reducción del problema AMD de maximización de pagos.",
        "Teorema 4.",
        "Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de artículos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), diseñar la subasta determinística óptima es NP-completo, incluso para un único postor con una distribución uniforme sobre los tipos.",
        "Prueba.",
        "El problema está en NP porque podemos generar de manera no determinista una regla de asignación, y luego establecer los pagos utilizando programación lineal.",
        "Para demostrar la NP-dificultad, reducimos una instancia arbitraria de AMD determinista que maximiza el pago, con un único agente y una distribución uniforme de tipos, al siguiente problema de diseño de subasta combinatoria óptima con una única postor con preferencias de solo los mejores.",
        "Para cada resultado o ∈ O en la instancia de AMD (excepto el resultado o0), que haya un artículo so ∈ S. Que el espacio de tipos sea el mismo, y que v(θi, so) = ui(θi, o) (donde u está especificado en la instancia de AMD).",
        "Que el valor objetivo de ingresos esperados sea el mismo en ambas instancias.",
        "Mostramos que las instancias son equivalentes.",
        "Primero supongamos que existe una solución para la instancia de AMD, dada por una función de resultado y una función de pago.",
        "Entonces, si la solución de AMD elige el resultado o para un tipo, en la solución de subasta óptima, asignamos {so} al postor para este tipo. (A menos que o = o0, en cuyo caso asignamos {} al postor).",
        "Que las funciones de pago sean las mismas en ambas instancias.",
        "Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo verdadero) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución óptima de la subasta.",
        "Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el subastador/diseñador son los mismos.",
        "Se deduce que existe una solución para la instancia de diseño de subasta óptima.",
        "Ahora supongamos que existe una solución para la instancia de diseño de subasta óptima.",
        "Por la observación de que como máximo se puede tener un artículo, podemos asumir sin pérdida de generalidad que la solución nunca asigna más de un artículo.",
        "Entonces, si la solución de subasta óptima asigna el artículo al postor para un tipo, en la solución de AMD, permita que el mecanismo elija el resultado o para ese tipo.",
        "Si la solución de subasta óptima no asigna nada al postor para un tipo, en la solución AMD, permita que el mecanismo elija el resultado o0 para ese tipo.",
        "Que las funciones de pago sean las mismas.",
        "Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo real) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución AMD.",
        "Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el diseñador/subastador son los mismos.",
        "Se deduce que existe una solución para la instancia de AMD.",
        "Afortunadamente, también podemos extender el resultado de facilidad para mecanismos aleatorios a este escenario de subasta combinatoria, lo que nos proporciona uno de los pocos algoritmos de tiempo polinómico conocidos para un problema de diseño óptimo de subasta combinatoria.",
        "Teorema 5.",
        "Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de elementos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), si el número de postores es una constante k, entonces la subasta aleatoria óptima puede ser diseñada en tiempo polinómico. (Para cualquier restricción de IC e IR.)",
        "Prueba.",
        "Por la observación de que a lo sumo un artículo, podemos sin pérdida de generalidad restringirnos a asignaciones donde cada postor recibe como máximo un artículo.",
        "Hay menos de (|S| + 1)k asignaciones de ese tipo, es decir, un número polinómico de asignaciones.",
        "Dado que podemos enumerar explícitamente los resultados, simplemente podemos resolver esto como una instancia de AMD que maximiza el pago, con programación lineal. 8.",
        "Investigaciones relacionadas sobre la complejidad en el diseño de mecanismos. Ha habido un considerable interés reciente en el diseño de mecanismos en la informática.",
        "Parte de ello se ha centrado en cuestiones de complejidad computacional, pero la mayor parte de ese trabajo ha buscado diseñar mecanismos que sean fáciles de ejecutar (por ejemplo, [20, 15, 19, 9, 12]), en lugar de estudiar la complejidad de diseñar el mecanismo.",
        "La pieza más cercana de trabajo anterior estudió la complejidad del diseño automatizado de mecanismos por un diseñador benevolente [5, 6].",
        "Roughgarden ha estudiado la complejidad de diseñar una buena topología de red para agentes que eligen egoístamente los enlaces que utilizan [21].",
        "Esto está relacionado con el diseño de mecanismos, pero difiere significativamente en que el diseñador solo tiene un control restringido sobre las reglas del juego porque no hay ninguna parte que pueda imponer el resultado (o pagos laterales).",
        "Además, no hay un informe explícito de preferencias. 9.",
        "CONCLUSIONES E INVESTIGACIONES FUTURAS A menudo, un resultado debe ser elegido en función de las preferencias informadas por un grupo de agentes.",
        "La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les sea más favorable.",
        "El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable.",
        "En un enfoque recientemente emergente llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración específica de agregación de preferencias en cuestión.",
        "Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez.",
        "A diferencia de trabajos anteriores sobre diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo, un entorno mucho más relevante para el comercio electrónico.",
        "En este contexto, al centro solo le importa qué resultado se elige y qué pagos se le realizan.",
        "La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo.",
        "En este escenario, demostramos que diseñar un mecanismo determinista óptimo es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido.",
        "Estos resultados de dureza implican dificultad en todos los entornos de diseño de mecanismos automatizados más generales con un diseñador egoísta.",
        "Los resultados de dureza se aplican ya sea que las restricciones de racionalidad individual (participación) se apliquen ex interim o ex post, y ya sea que el concepto de solución sea la implementación de estrategias dominantes o la implementación del equilibrio de Bayes-Nash.",
        "Luego demostramos que permitir la aleatorización en el mecanismo hace que el problema de diseño en todos estos escenarios sea computacionalmente sencillo.",
        "Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (que maximiza los ingresos), donde los postores tienen preferencias solo por lo mejor.",
        "Mostramos que aquí también, diseñar un mecanismo determinístico óptimo es NP-completo incluso con un agente, pero diseñar un mecanismo aleatorio óptimo es fácil.",
        "La investigación futura incluye estudiar el diseño automatizado de mecanismos con un diseñador interesado en sí mismo en entornos más restringidos, como subastas (donde el objetivo del diseñador puede incluir preferencias sobre qué postor debería recibir el bien, así como los pagos).",
        "También queremos estudiar la complejidad del diseño de mecanismos automatizados en entornos donde los espacios de resultados y tipos tienen una estructura especial para que puedan representarse de manera más concisa.",
        "Finalmente, planeamos reunir un conjunto de datos de problemas de diseño de mecanismos del mundo real, tanto históricos como actuales, y aplicar el diseño de mecanismos automatizado a esos problemas. 10.",
        "REFERENCIAS [1] M. Armstrong.",
        "Subastas multi-objetivo óptimas.",
        "Revisión de Estudios Económicos, 67:455-481, 2000. [2] K. Arrow.",
        "La doctrina de los derechos de propiedad y la revelación de la demanda bajo información incompleta.",
        "En M. Boskin, editor, Economía y bienestar humano.",
        "New York Academic Press, 1979. [3] C. Avery y T. Hendershott.",
        "Agrupación y subastas óptimas de múltiples productos.",
        "Revisión de Estudios Económicos, 67:483-497, 2000. [4] E. H. Clarke.",
        "Precios escalonados de bienes públicos.",
        "Elección Pública, 11:17-33, 1971. [5] V. Conitzer y T. Sandholm.",
        "Complejidad del diseño de mecanismos.",
        "En Actas de la 18ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI-02), páginas 103-110, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm.",
        "Diseño de mecanismos automatizados: Resultados de complejidad derivados del entorno de un solo agente.",
        "En Actas de la 5ta Conferencia Internacional de Comercio Electrónico (ICEC-03), páginas 17-24, Pittsburgh, PA, EE. UU., 2003. [7] V. Conitzer y T. Sandholm.",
        "Críticas computacionales del principio de revelación.",
        "En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), Nueva York, NY, 2004.",
        "Breve ensayo.",
        "La versión completa apareció en el taller AAMAS-03 sobre Comercio Electrónico Mediado por Agentes (AMEC). [8] C. d'Aspremont y L. A. Gérard-Varet.",
        "Incentivos e información incompleta.",
        "Revista de Economía Pública, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou y S. Shenker.",
        "Compartiendo el costo de las transmisiones de multidifusión.",
        "Revista de Ciencias de la Computación y de Sistemas, 63:21-41, 2001.",
        "Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 2000. [10] A. Gibbard.",
        "Manipulación de esquemas de votación.",
        "Econometrica, 41:587-602, 1973. [11] T. Groves.\nEconometrica, 41:587-602, 1973. [11] T. Groves.",
        "Incentivos en equipos.",
        "Econometrica, 41:617-631, 1973. [12] J. Hershberger y S. Suri.",
        "Precios de Vickrey y caminos más cortos: ¿Cuánto vale una arista?",
        "En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [13] L. Khachiyan.",
        "Un algoritmo polinómico en programación lineal.",
        "Matemática soviética.",
        "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi y P. Mirchandani.",
        "El problema de satisfacibilidad mínimo.",
        "Revista SIAM de Matemáticas Discretas, 7(2):275-283, 1994. [15] D. Lehmann, L. I. O'Callaghan y Y. Shoham.",
        "Revelación de la verdad en subastas combinatorias rápidas y aproximadamente eficientes.",
        "Revista de la ACM, 49(5):577-602, 2002.",
        "La versión inicial apareció en las Actas de la Conferencia de Comercio Electrónico de la ACM (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston y J. R. Green.",
        "Teoría microeconómica.",
        "Oxford University Press, 1995. [17] E. S. Maskin y J. Riley.",
        "Subastas multiunidad óptimas.",
        "En F. Hahn, editor, \"La economía de los mercados faltantes, la información y los juegos\", capítulo 14, páginas 312-335.",
        "Clarendon Press, Oxford, 1989. [18] R. Myerson.\nPrensa Clarendon, Oxford, 1989. [18] R. Myerson.",
        "Diseño óptimo de subasta.",
        "Matemáticas de la Investigación de Operaciones, 6:58-73, 1981. [19] N. Nisan y A. Ronen.",
        "Mecanismos VCG computacionalmente factibles.",
        "En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 242-252, Minneapolis, MN, 2000. [20] N. Nisan y A. Ronen.",
        "Diseño de mecanismos algorítmicos.",
        "Juegos y Comportamiento Económico, 35:166-196, 2001.",
        "Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 1999. [21] T. Roughgarden.",
        "Diseñar redes para usuarios egoístas es difícil.",
        "En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [22] T. Sandholm.",
        "Problemas en subastas computacionales de Vickrey.",
        "Revista Internacional de Comercio Electrónico, 4(3):107-129, 2000.",
        "Número especial sobre la Aplicación de Agentes Inteligentes para el Comercio Electrónico.",
        "Una versión corta y temprana apareció en la Segunda Conferencia Internacional sobre Sistemas Multiagente (ICMAS), páginas 299-306, 1996. [23] M. A. Satterthwaite.",
        "In Spanish, the translation would be: \"Inmutabilidad estratégica y condiciones de Arrow: teoremas de existencia y correspondencia para procedimientos de votación y funciones de bienestar social.\"",
        "Revista de Teoría Económica, 10:187-217, 1975. [24] W. Vickrey.",
        "Contrarrestando la especulación, subastas y ofertas selladas competitivas.",
        "Revista de Finanzas, 16:8-37, 1961. [25] R. V. Vohra.",
        "Problemas de investigación en subastas combinatorias.",
        "Mimeo, versión 29 de octubre de 2001. 141"
    ],
    "error_count": 2,
    "keys": {
        "mechanism design": {
            "translated_key": "diseño de mecanismos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-interested Automated <br>mechanism design</br> and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "<br>mechanism design</br> is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently proposed approach-called automated <br>mechanism design</br>-a mechanism is computed for the preference aggregation setting at hand.",
                "This has several advantages, but the downside is that the <br>mechanism design</br> optimization problem needs to be solved anew each time.",
                "Unlike the earlier work on automated <br>mechanism design</br> that studied a benevolent designer, in this paper we study automated <br>mechanism design</br> problems where the designer is self-interested.",
                "In this case, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy.",
                "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy.",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc.",
                "The preference aggregator generally does not know the agents preferences a priori.",
                "Rather, the agents report their preferences to the coordinator.",
                "Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully.",
                "Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen.",
                "Manipulability is a pervasive problem across preference aggregation mechanisms.",
                "A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.)",
                "What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective.",
                "This is the classic setting of <br>mechanism design</br> in game theory.",
                "In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself.",
                "This is the <br>mechanism design</br> setting most relevant to electronic commerce.",
                "In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear.",
                "It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences.",
                "The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments.",
                "The most common such constraint is that of individual rationality (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
                "For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences.",
                "Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it.",
                "Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off.",
                "On the other hand, the designer will not necessarily choose a social welfare maximizing outcome.",
                "For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected.",
                "Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0.",
                "Classical <br>mechanism design</br> provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective.",
                "The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]).",
                "However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare.",
                "If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization.",
                "In practice, the designer may also be interested in the outcome per se.",
                "For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical.",
                "For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed.",
                "Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments.",
                "In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand.",
                "This approach addresses all of the downsides listed above.",
                "We formulate the <br>mechanism design</br> problem as an optimization problem.",
                "The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types.",
                "The output is a nonmanipulable mechanism that is optimal with respect to some objective.",
                "This approach is called automated <br>mechanism design</br>.",
                "The automated <br>mechanism design</br> approach has four advantages over the classical approach of designing general mechanisms.",
                "First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare).",
                "Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences.",
                "When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally.",
                "Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types).",
                "Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information.",
                "For example, imagine a company automatically creating its procurement mechanism based on statistical knowledge about its suppliers, rather than using a classical descending procurement auction.",
                "Fourth, the burden of design is shifted from humans to a machine.",
                "However, automated <br>mechanism design</br> requires the <br>mechanism design</br> optimization problem to be solved anew for each setting.",
                "Hence its computational complexity becomes a key issue.",
                "Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6].",
                "In this paper we study the computational complexity of automated <br>mechanism design</br> in the case of a self-interested designer.",
                "This is an important setting for automated <br>mechanism design</br> due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested.",
                "We also show that this problem is closely related to a particular optimal (revenue-maximizing) combinatorial auction design problem. 133 The rest of this paper is organized as follows.",
                "In Section 2, we justify the focus on nonmanipulable mechanisms.",
                "In Section 3, we define the problem we study.",
                "In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it.",
                "In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen.",
                "In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case.",
                "Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2.",
                "JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of automated <br>mechanism design</br>, we should justify our focus on nonmanipulable mechanisms.",
                "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any nonmanipulable mechanism.",
                "This does, however, turn out to be the case: given any mechanism, we can construct a nonmanipulable mechanism whose performance is identical, as follows.",
                "We build an interface layer between the agents and the original mechanism.",
                "The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer.",
                "The resulting outcome is the outcome of the new mechanism.",
                "Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism.",
                "This argument is known in the <br>mechanism design</br> literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22].",
                "However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.)",
                "Given this, we can focus on truthful mechanisms in the rest of the paper. 3.",
                "DEFINITIONS We now formalize the automated <br>mechanism design</br> setting.",
                "Definition 1.",
                "In an automated <br>mechanism design</br> setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize.",
                "There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent).",
                "In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness.",
                "However, in this paper, we focus on the case of a self-interested designer.",
                "A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer.",
                "Definition 2.",
                "A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i.",
                "In the case where g = 0 everywhere, the designer is said to be payment maximizing.",
                "In the case where payments are not possible, g constitutes the objective function by itself.",
                "We now define the kinds of mechanisms under study.",
                "By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them.",
                "Definition 3.",
                "We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing.",
                "The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator.",
                "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 Individual rationality (IR) constraints The first type of constraint is the following.",
                "The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism.",
                "Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.)",
                "This type of constraint is called an IR (individual rationality) constraint.",
                "There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism.",
                "Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type).",
                "We will not study this concept in this paper.",
                "Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others.",
                "Ex post IR means that the agent would always participate even if it knew everybodys type.",
                "We will define the latter two notions of IR formally.",
                "First, we need to formalize the concept of the fallback outcome.",
                "We assume that each agents fallback utility is zero for each one of its types.",
                "This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16].",
                "Definition 4.",
                "In any automated <br>mechanism design</br> setting with an IR constraint, there is a fallback outcome o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)",
                "We can now to define the notions of individual rationality.",
                "Definition 5.",
                "Individual rationality (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
                "A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments.",
                "A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
                "The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle).",
                "For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium.",
                "Definition 6.",
                "Given an automated <br>mechanism design</br> setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known.",
                "Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
                "In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible.",
                "Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report.",
                "If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium.",
                "Definition 7.",
                "Given an automated <br>mechanism design</br> setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth.",
                "Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible. 135 3.3 Automated <br>mechanism design</br> We can now define the computational problem we study.",
                "Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an automated <br>mechanism design</br> setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective.",
                "An interesting special case is the setting where there is only one agent.",
                "In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents.",
                "Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here.",
                "Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here.",
                "This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4.",
                "PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "To demonstrate NPhardness, we reduce from the MINSAT problem.",
                "Definition 9 (MINSAT).",
                "We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|).",
                "We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied.",
                "MINSAT was recently shown to be NP-complete [14].",
                "We can now present our result.",
                "Theorem 1.",
                "Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent payment-maximizing deterministic AMD instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|.",
                "For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the MINSAT solution, and π(θc) = |Θ| if c is satisfied.",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent.",
                "Clearly the agent is better off reporting truthfully, for a total utility of 0.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type.",
                "Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the IR constraint, the maximum payment we can extract from any type θv is |Θ|.",
                "Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.)",
                "Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1.",
                "It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible.",
                "However, it does not yet imply hardness for the special case where payments are not possible.",
                "We will prove hardness in this case in the next section. 5.",
                "SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "Theorem 2.",
                "Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent self-interested deterministic AMD without payments instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1.",
                "Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v).",
                "For every c ∈ C that is satisfied in the MINSAT solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ .",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "The only other outcome that the mechanism is allowed to choose under the IR constraint is o0.",
                "This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}.",
                "We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|.",
                "For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).)",
                "Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes.",
                "It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Both of our hardness results relied on the constraint that the mechanism should be deterministic.",
                "In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6.",
                "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of self-interested AMD tractable through linear programming, for any constant number of agents.",
                "Theorem 3.",
                "Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated.",
                "Proof.",
                "Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}.",
                "The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.)",
                "First, we show the IR constraints.",
                "For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
                "For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
                "Now, we show the solution concept constraints.",
                "For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
                "Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
                "All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
                "As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents.",
                "Thus the problem is solvable in polynomial time. 7.",
                "IMPLICATIONS FOR AN OPTIMAL COMBINATORIAL AUCTION DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated <br>mechanism design</br> for a self-interested designer on designing optimal combinatorial auctions.",
                "Consider a combinatorial auction with a set S of items for sale.",
                "For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi.",
                "The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.)",
                "The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18].",
                "However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25].",
                "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of complementarity and no substitutability has been solved recently [1].)",
                "Suppose we have free disposal-items can be thrown away at no cost.",
                "Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.)",
                "Definition 10.",
                "Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
                "We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item.",
                "The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type.",
                "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the payment maximizing AMD problem!",
                "Theorem 4.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types.",
                "Proof.",
                "The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming.",
                "To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal combinatorial auction design problem instance with a single bidder with best-only preferences.",
                "For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance).",
                "Let the expected revenue target value be the same in both instances.",
                "We show the instances are equivalent.",
                "First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function.",
                "Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.)",
                "Let the payment functions be the same in both instances.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same.",
                "It follows that there exists a solution to the optimal auction design instance.",
                "Now suppose there exists a solution to the optimal auction design instance.",
                "By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item.",
                "Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type.",
                "If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type.",
                "Let the payment functions be the same.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same.",
                "It follows that there exists a solution to the AMD instance.",
                "Fortunately, we can also carry through the easiness result for randomized mechanisms to this combinatorial auction setting-giving us one of the few known polynomial-time algorithms for an optimal combinatorial auction design problem.",
                "Theorem 5.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.)",
                "Proof.",
                "By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item.",
                "There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations.",
                "Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8.",
                "RELATED RESEARCH ON COMPLEXITY IN <br>mechanism design</br> There has been considerable recent interest in <br>mechanism design</br> in computer science.",
                "Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism.",
                "The closest piece of earlier work studied the complexity of automated <br>mechanism design</br> by a benevolent designer [5, 6].",
                "Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21].",
                "This is related to <br>mechanism design</br>, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments).",
                "Also, there is no explicit reporting of preferences. 9.",
                "CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "<br>mechanism design</br> is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently emerging approach-called automated <br>mechanism design</br>-a mechanism is computed for the specific preference aggregation setting at hand.",
                "This has several advantages, 139 but the downside is that the <br>mechanism design</br> optimization problem needs to be solved anew each time.",
                "Unlike earlier work on automated <br>mechanism design</br> that studied a benevolent designer, in this paper we studied automated <br>mechanism design</br> problems where the designer is self-interesteda setting much more relevant for electronic commerce.",
                "In this setting, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "These hardness results imply hardness in all more general automated <br>mechanism design</br> settings with a self-interested designer.",
                "The hardness results apply whether the individual rationality (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation.",
                "We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy.",
                "Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy.",
                "Future research includes studying automated <br>mechanism design</br> with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments).",
                "We also want to study the complexity of automated <br>mechanism design</br> in settings where the outcome and type spaces have special structure so they can be represented more concisely.",
                "Finally, we plan to assemble a data set of real-world <br>mechanism design</br> problems-both historical and current-and apply automated <br>mechanism design</br> to those problems. 10.",
                "REFERENCES [1] M. Armstrong.",
                "Optimal multi-object auctions.",
                "Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow.",
                "The property rights doctrine and demand revelation under incomplete information.",
                "In M. Boskin, editor, Economics and human welfare.",
                "New York Academic Press, 1979. [3] C. Avery and T. Hendershott.",
                "Bundling and optimal auctions of multiple products.",
                "Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke.",
                "Multipart pricing of public goods.",
                "Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm.",
                "Complexity of <br>mechanism design</br>.",
                "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Automated <br>mechanism design</br>: Complexity results stemming from the single-agent setting.",
                "In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm.",
                "Computational criticisms of the revelation principle.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004.",
                "Short paper.",
                "Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet.",
                "Incentives and incomplete information.",
                "Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker.",
                "Sharing the cost of muliticast transmissions.",
                "Journal of Computer and System Sciences, 63:21-41, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard.",
                "Manipulation of voting schemes.",
                "Econometrica, 41:587-602, 1973. [11] T. Groves.",
                "Incentives in teams.",
                "Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri.",
                "Vickrey prices and shortest paths: What is an edge worth?",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan.",
                "A polynomial algorithm in linear programming.",
                "Soviet Math.",
                "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani.",
                "The minimum satisfiability problem.",
                "SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham.",
                "Truth revelation in rapid, approximately efficient combinatorial auctions.",
                "Journal of the ACM, 49(5):577-602, 2002.",
                "Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [17] E. S. Maskin and J. Riley.",
                "Optimal multi-unit auctions.",
                "In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335.",
                "Clarendon Press, Oxford, 1989. [18] R. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen.",
                "Computationally feasible VCG mechanisms.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen.",
                "Algorithmic <br>mechanism design</br>.",
                "Games and Economic Behavior, 35:166-196, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden.",
                "Designing networks for selfish users is hard.",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm.",
                "Issues in computational Vickrey auctions.",
                "International Journal of Electronic Commerce, 4(3):107-129, 2000.",
                "Special Issue on 140 Applying Intelligent Agents for Electronic Commerce.",
                "A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite.",
                "Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions.",
                "Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey.",
                "Counterspeculation, auctions, and competitive sealed tenders.",
                "Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra.",
                "Research problems in combinatorial auctions.",
                "Mimeo, version Oct. 29, 2001. 141"
            ],
            "original_annotated_samples": [
                "Self-interested Automated <br>mechanism design</br> and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "<br>mechanism design</br> is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently proposed approach-called automated <br>mechanism design</br>-a mechanism is computed for the preference aggregation setting at hand.",
                "This has several advantages, but the downside is that the <br>mechanism design</br> optimization problem needs to be solved anew each time.",
                "Unlike the earlier work on automated <br>mechanism design</br> that studied a benevolent designer, in this paper we study automated <br>mechanism design</br> problems where the designer is self-interested."
            ],
            "translated_annotated_samples": [
                "Diseño de mecanismos automatizados de interés propio e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes.",
                "El <br>diseño de mecanismos</br> es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable.",
                "En un enfoque recientemente propuesto, llamado <br>diseño de mecanismos</br> automatizado, se calcula un mecanismo para la configuración de agregación de preferencias actual.",
                "Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del <br>diseño del mecanismo</br> debe resolverse de nuevo cada vez.",
                "A diferencia de trabajos anteriores sobre el <br>diseño automatizado de mecanismos</br> que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de <br>diseño automatizado de mecanismos</br> donde el diseñador está interesado en sí mismo."
            ],
            "translated_text": "Diseño de mecanismos automatizados de interés propio e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les resulte más favorable. El <br>diseño de mecanismos</br> es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente propuesto, llamado <br>diseño de mecanismos</br> automatizado, se calcula un mecanismo para la configuración de agregación de preferencias actual. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del <br>diseño del mecanismo</br> debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre el <br>diseño automatizado de mecanismos</br> que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de <br>diseño automatizado de mecanismos</br> donde el diseñador está interesado en sí mismo. ",
            "candidates": [],
            "error": [
                [
                    "diseño de mecanismos",
                    "diseño de mecanismos",
                    "diseño del mecanismo",
                    "diseño automatizado de mecanismos",
                    "diseño automatizado de mecanismos"
                ]
            ]
        },
        "desirable outcome": {
            "translated_key": "resultado deseable",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-interested Automated Mechanism Design and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a <br>desirable outcome</br> is chosen.",
                "In a recently proposed approach-called automated mechanism design-a mechanism is computed for the preference aggregation setting at hand.",
                "This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike the earlier work on automated mechanism design that studied a benevolent designer, in this paper we study automated mechanism design problems where the designer is self-interested.",
                "In this case, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy.",
                "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy.",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc.",
                "The preference aggregator generally does not know the agents preferences a priori.",
                "Rather, the agents report their preferences to the coordinator.",
                "Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully.",
                "Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen.",
                "Manipulability is a pervasive problem across preference aggregation mechanisms.",
                "A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.)",
                "What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective.",
                "This is the classic setting of mechanism design in game theory.",
                "In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself.",
                "This is the mechanism design setting most relevant to electronic commerce.",
                "In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear.",
                "It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences.",
                "The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments.",
                "The most common such constraint is that of individual rationality (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
                "For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences.",
                "Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it.",
                "Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off.",
                "On the other hand, the designer will not necessarily choose a social welfare maximizing outcome.",
                "For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected.",
                "Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0.",
                "Classical mechanism design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective.",
                "The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]).",
                "However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare.",
                "If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization.",
                "In practice, the designer may also be interested in the outcome per se.",
                "For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical.",
                "For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed.",
                "Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments.",
                "In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand.",
                "This approach addresses all of the downsides listed above.",
                "We formulate the mechanism design problem as an optimization problem.",
                "The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types.",
                "The output is a nonmanipulable mechanism that is optimal with respect to some objective.",
                "This approach is called automated mechanism design.",
                "The automated mechanism design approach has four advantages over the classical approach of designing general mechanisms.",
                "First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare).",
                "Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences.",
                "When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally.",
                "Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types).",
                "Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information.",
                "For example, imagine a company automatically creating its procurement mechanism based on statistical knowledge about its suppliers, rather than using a classical descending procurement auction.",
                "Fourth, the burden of design is shifted from humans to a machine.",
                "However, automated mechanism design requires the mechanism design optimization problem to be solved anew for each setting.",
                "Hence its computational complexity becomes a key issue.",
                "Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6].",
                "In this paper we study the computational complexity of automated mechanism design in the case of a self-interested designer.",
                "This is an important setting for automated mechanism design due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested.",
                "We also show that this problem is closely related to a particular optimal (revenue-maximizing) combinatorial auction design problem. 133 The rest of this paper is organized as follows.",
                "In Section 2, we justify the focus on nonmanipulable mechanisms.",
                "In Section 3, we define the problem we study.",
                "In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it.",
                "In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen.",
                "In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case.",
                "Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2.",
                "JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of automated mechanism design, we should justify our focus on nonmanipulable mechanisms.",
                "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any nonmanipulable mechanism.",
                "This does, however, turn out to be the case: given any mechanism, we can construct a nonmanipulable mechanism whose performance is identical, as follows.",
                "We build an interface layer between the agents and the original mechanism.",
                "The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer.",
                "The resulting outcome is the outcome of the new mechanism.",
                "Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism.",
                "This argument is known in the mechanism design literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22].",
                "However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.)",
                "Given this, we can focus on truthful mechanisms in the rest of the paper. 3.",
                "DEFINITIONS We now formalize the automated mechanism design setting.",
                "Definition 1.",
                "In an automated mechanism design setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize.",
                "There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent).",
                "In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness.",
                "However, in this paper, we focus on the case of a self-interested designer.",
                "A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer.",
                "Definition 2.",
                "A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i.",
                "In the case where g = 0 everywhere, the designer is said to be payment maximizing.",
                "In the case where payments are not possible, g constitutes the objective function by itself.",
                "We now define the kinds of mechanisms under study.",
                "By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them.",
                "Definition 3.",
                "We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing.",
                "The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator.",
                "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 Individual rationality (IR) constraints The first type of constraint is the following.",
                "The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism.",
                "Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.)",
                "This type of constraint is called an IR (individual rationality) constraint.",
                "There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism.",
                "Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type).",
                "We will not study this concept in this paper.",
                "Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others.",
                "Ex post IR means that the agent would always participate even if it knew everybodys type.",
                "We will define the latter two notions of IR formally.",
                "First, we need to formalize the concept of the fallback outcome.",
                "We assume that each agents fallback utility is zero for each one of its types.",
                "This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16].",
                "Definition 4.",
                "In any automated mechanism design setting with an IR constraint, there is a fallback outcome o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)",
                "We can now to define the notions of individual rationality.",
                "Definition 5.",
                "Individual rationality (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
                "A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments.",
                "A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
                "The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle).",
                "For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium.",
                "Definition 6.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known.",
                "Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
                "In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible.",
                "Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report.",
                "If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium.",
                "Definition 7.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth.",
                "Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible. 135 3.3 Automated mechanism design We can now define the computational problem we study.",
                "Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an automated mechanism design setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective.",
                "An interesting special case is the setting where there is only one agent.",
                "In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents.",
                "Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here.",
                "Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here.",
                "This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4.",
                "PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "To demonstrate NPhardness, we reduce from the MINSAT problem.",
                "Definition 9 (MINSAT).",
                "We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|).",
                "We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied.",
                "MINSAT was recently shown to be NP-complete [14].",
                "We can now present our result.",
                "Theorem 1.",
                "Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent payment-maximizing deterministic AMD instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|.",
                "For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the MINSAT solution, and π(θc) = |Θ| if c is satisfied.",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent.",
                "Clearly the agent is better off reporting truthfully, for a total utility of 0.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type.",
                "Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the IR constraint, the maximum payment we can extract from any type θv is |Θ|.",
                "Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.)",
                "Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1.",
                "It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible.",
                "However, it does not yet imply hardness for the special case where payments are not possible.",
                "We will prove hardness in this case in the next section. 5.",
                "SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "Theorem 2.",
                "Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent self-interested deterministic AMD without payments instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1.",
                "Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v).",
                "For every c ∈ C that is satisfied in the MINSAT solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ .",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "The only other outcome that the mechanism is allowed to choose under the IR constraint is o0.",
                "This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}.",
                "We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|.",
                "For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).)",
                "Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes.",
                "It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Both of our hardness results relied on the constraint that the mechanism should be deterministic.",
                "In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6.",
                "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of self-interested AMD tractable through linear programming, for any constant number of agents.",
                "Theorem 3.",
                "Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated.",
                "Proof.",
                "Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}.",
                "The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.)",
                "First, we show the IR constraints.",
                "For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
                "For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
                "Now, we show the solution concept constraints.",
                "For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
                "Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
                "All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
                "As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents.",
                "Thus the problem is solvable in polynomial time. 7.",
                "IMPLICATIONS FOR AN OPTIMAL COMBINATORIAL AUCTION DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated mechanism design for a self-interested designer on designing optimal combinatorial auctions.",
                "Consider a combinatorial auction with a set S of items for sale.",
                "For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi.",
                "The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.)",
                "The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18].",
                "However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25].",
                "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of complementarity and no substitutability has been solved recently [1].)",
                "Suppose we have free disposal-items can be thrown away at no cost.",
                "Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.)",
                "Definition 10.",
                "Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
                "We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item.",
                "The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type.",
                "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the payment maximizing AMD problem!",
                "Theorem 4.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types.",
                "Proof.",
                "The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming.",
                "To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal combinatorial auction design problem instance with a single bidder with best-only preferences.",
                "For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance).",
                "Let the expected revenue target value be the same in both instances.",
                "We show the instances are equivalent.",
                "First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function.",
                "Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.)",
                "Let the payment functions be the same in both instances.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same.",
                "It follows that there exists a solution to the optimal auction design instance.",
                "Now suppose there exists a solution to the optimal auction design instance.",
                "By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item.",
                "Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type.",
                "If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type.",
                "Let the payment functions be the same.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same.",
                "It follows that there exists a solution to the AMD instance.",
                "Fortunately, we can also carry through the easiness result for randomized mechanisms to this combinatorial auction setting-giving us one of the few known polynomial-time algorithms for an optimal combinatorial auction design problem.",
                "Theorem 5.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.)",
                "Proof.",
                "By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item.",
                "There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations.",
                "Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8.",
                "RELATED RESEARCH ON COMPLEXITY IN MECHANISM DESIGN There has been considerable recent interest in mechanism design in computer science.",
                "Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism.",
                "The closest piece of earlier work studied the complexity of automated mechanism design by a benevolent designer [5, 6].",
                "Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21].",
                "This is related to mechanism design, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments).",
                "Also, there is no explicit reporting of preferences. 9.",
                "CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a <br>desirable outcome</br> is chosen.",
                "In a recently emerging approach-called automated mechanism design-a mechanism is computed for the specific preference aggregation setting at hand.",
                "This has several advantages, 139 but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike earlier work on automated mechanism design that studied a benevolent designer, in this paper we studied automated mechanism design problems where the designer is self-interesteda setting much more relevant for electronic commerce.",
                "In this setting, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "These hardness results imply hardness in all more general automated mechanism design settings with a self-interested designer.",
                "The hardness results apply whether the individual rationality (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation.",
                "We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy.",
                "Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy.",
                "Future research includes studying automated mechanism design with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments).",
                "We also want to study the complexity of automated mechanism design in settings where the outcome and type spaces have special structure so they can be represented more concisely.",
                "Finally, we plan to assemble a data set of real-world mechanism design problems-both historical and current-and apply automated mechanism design to those problems. 10.",
                "REFERENCES [1] M. Armstrong.",
                "Optimal multi-object auctions.",
                "Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow.",
                "The property rights doctrine and demand revelation under incomplete information.",
                "In M. Boskin, editor, Economics and human welfare.",
                "New York Academic Press, 1979. [3] C. Avery and T. Hendershott.",
                "Bundling and optimal auctions of multiple products.",
                "Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke.",
                "Multipart pricing of public goods.",
                "Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Automated mechanism design: Complexity results stemming from the single-agent setting.",
                "In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm.",
                "Computational criticisms of the revelation principle.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004.",
                "Short paper.",
                "Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet.",
                "Incentives and incomplete information.",
                "Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker.",
                "Sharing the cost of muliticast transmissions.",
                "Journal of Computer and System Sciences, 63:21-41, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard.",
                "Manipulation of voting schemes.",
                "Econometrica, 41:587-602, 1973. [11] T. Groves.",
                "Incentives in teams.",
                "Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri.",
                "Vickrey prices and shortest paths: What is an edge worth?",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan.",
                "A polynomial algorithm in linear programming.",
                "Soviet Math.",
                "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani.",
                "The minimum satisfiability problem.",
                "SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham.",
                "Truth revelation in rapid, approximately efficient combinatorial auctions.",
                "Journal of the ACM, 49(5):577-602, 2002.",
                "Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [17] E. S. Maskin and J. Riley.",
                "Optimal multi-unit auctions.",
                "In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335.",
                "Clarendon Press, Oxford, 1989. [18] R. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen.",
                "Computationally feasible VCG mechanisms.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behavior, 35:166-196, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden.",
                "Designing networks for selfish users is hard.",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm.",
                "Issues in computational Vickrey auctions.",
                "International Journal of Electronic Commerce, 4(3):107-129, 2000.",
                "Special Issue on 140 Applying Intelligent Agents for Electronic Commerce.",
                "A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite.",
                "Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions.",
                "Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey.",
                "Counterspeculation, auctions, and competitive sealed tenders.",
                "Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra.",
                "Research problems in combinatorial auctions.",
                "Mimeo, version Oct. 29, 2001. 141"
            ],
            "original_annotated_samples": [
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a <br>desirable outcome</br> is chosen.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a <br>desirable outcome</br> is chosen."
            ],
            "translated_annotated_samples": [
                "El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un <br>resultado deseable</br>.",
                "El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un <br>resultado deseable</br>."
            ],
            "translated_text": "Diseño de mecanismos automatizados de interés propio e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les resulte más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un <br>resultado deseable</br>. En un enfoque recientemente propuesto, llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración de agregación de preferencias actual. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre el diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo. En este caso, al centro solo le importa qué resultado se elige y qué pagos se le hacen. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este contexto, demostramos que el diseño de mecanismos deterministas óptimos es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Luego mostramos cómo permitir la aleatorización en el mecanismo hace que los problemas en este entorno sean computacionalmente fáciles. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (maximizadora de ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar una subasta determinista óptima es NP-completo, pero diseñar una subasta aleatoria óptima es fácil. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Teoría 1. En entornos multiagentes, a menudo se debe elegir un resultado en función de las preferencias informadas por un grupo de agentes. Tales resultados podrían ser presidentes potenciales, planes conjuntos, asignaciones de bienes o recursos, etc. El agregador de preferencias generalmente no conoce las preferencias de los agentes de antemano. Más bien, los agentes informan sus preferencias al coordinador. Desafortunadamente, un agente puede tener un incentivo para informar incorrectamente sus preferencias con el fin de engañar al mecanismo y lograr que seleccione un resultado que sea más deseable para el agente que el resultado que se seleccionaría si el agente revelara sus preferencias de manera honesta. Tal manipulación es indeseable porque los mecanismos de agregación de preferencias están diseñados para agrupar las preferencias de una manera socialmente deseable, y si los agentes revelan sus preferencias de manera insincera, se podría elegir un resultado socialmente indeseable. La manipulabilidad es un problema generalizado en los mecanismos de agregación de preferencias. Un resultado negativo seminal, el teorema de Gibbard-Satterthwaite, muestra que bajo cualquier esquema de agregación de preferencias no dictatorial, si hay al menos 3 posibles resultados, existen preferencias bajo las cuales un agente está mejor reportando falsamente [10, 23]. (Un esquema de agregación de preferencias se llama dictatorial si uno de los agentes dicta el resultado sin importar las preferencias que reporten los otros agentes). Lo que le gustaría hacer al agregador es diseñar un mecanismo de agregación de preferencias para que 1) los agentes interesados reporten sus preferencias de manera veraz, y 2) el mecanismo elija un resultado que sea deseable desde la perspectiva de algún objetivo. Esta es la configuración clásica del diseño de mecanismos en la teoría de juegos. En este documento, estudiamos el caso en el que el diseñador actúa por interés propio, es decir, al diseñador no le importa directamente cómo se relaciona el resultado con las preferencias de los agentes, sino que está más preocupado por su propia agenda sobre cuál resultado debería ser elegido y en maximizar los pagos para sí mismo. Este es el entorno de diseño de mecanismos más relevante para el comercio electrónico. En el caso en que el diseñador del mecanismo esté interesado en maximizar alguna noción de bienestar social, la importancia de recopilar las preferencias de los agentes es clara. Quizás sea menos obvio por qué deberían ser recopilados cuando el diseñador está interesado en sí mismo y, por lo tanto, su objetivo no está directamente relacionado con las preferencias de los agentes. La razón de esto es que a menudo las preferencias de los agentes imponen límites en cómo el diseñador elige el resultado y los pagos. La restricción más común de este tipo es la de racionalidad individual (RI), lo que significa que el mecanismo no puede dejar a ningún agente en una situación peor a la que hubiera estado si no hubiera participado en el mecanismo. Por ejemplo, en el contexto del diseño óptimo de subastas, el diseñador (subastador) solo se preocupa por cuántos ingresos se recaudan, y no en sí mismo por cuán bien la asignación del bien (o bienes) corresponde a las preferencias de los agentes. Sin embargo, el diseñador no puede obligar a un agente a pagar más de lo que valora el paquete de bienes asignado a él. Por lo tanto, incluso un diseñador interesado en sí mismo elegirá un resultado que beneficie razonablemente a los agentes. Por otro lado, el diseñador no necesariamente elegirá un resultado que maximice el bienestar social. Por ejemplo, si el diseñador siempre elige un resultado que maximiza el bienestar social con respecto a las preferencias informadas, y obliga a cada agente a pagar la diferencia entre la utilidad que tiene ahora y la utilidad que habría tenido si no hubiera participado en el mecanismo, es fácil ver que los agentes pueden tener un incentivo para informar incorrectamente sus preferencias, lo que puede llevar realmente a recaudar menos ingresos. De hecho, uno de los resultados contraintuitivos de la teoría del diseño de subastas óptimas es que a veces el bien se asigna a nadie incluso cuando el subastador tiene un precio de reserva de 0. El diseño de mecanismos clásicos proporciona algunos mecanismos generales, que, bajo ciertas suposiciones, satisfacen alguna noción de no manipulabilidad y maximizan algún objetivo. La ventaja de estos mecanismos es que no dependen de información (incluso probabilística) sobre las preferencias de los agentes (por ejemplo, el mecanismo de Vickrey-Clarke-Groves (VCG) [24, 4, 11]), o pueden aplicarse fácilmente a cualquier distribución de probabilidad sobre las preferencias (por ejemplo, el mecanismo dAGVA [8, 2], la subasta de Myerson [18], y la subasta multiunidad de Maskin-Riley [17]). Sin embargo, los mecanismos generales también tienen importantes desventajas: • Los mecanismos generales más famosos y ampliamente aplicables, VCG y dAGVA, solo maximizan el bienestar social. Si el diseñador está interesado en sí mismo, como es el caso en muchos entornos de comercio electrónico, estos mecanismos no maximizan el objetivo del diseñador. • Los mecanismos generales que se centran en un diseñador interesado en sí mismo solo son aplicables en entornos muy restringidos, como la subasta de maximización de ingresos esperados de Myerson para vender un solo artículo, y la subasta de maximización de ingresos esperados de Maskin y Riley para vender múltiples unidades idénticas de un artículo. • Incluso en los entornos restringidos en los que se aplican estos mecanismos, solo permiten la maximización de pagos. En la práctica, el diseñador también puede estar interesado en el resultado en sí mismo. Por ejemplo, a un subastador le puede importar qué postor recibe el artículo. • A menudo se asume que los pagos laterales pueden ser utilizados para adaptar los incentivos de los agentes, pero esto no siempre es práctico. Por ejemplo, en los mercados electrónicos basados en trueque, como Recipco, firstbarter.com, BarterOne e Intagio, no se permiten los pagos laterales. Además, entre los agentes de software, podría ser más deseable construir mecanismos que no dependan de la capacidad de realizar pagos, ya que muchos agentes de software no cuentan con la infraestructura para hacer pagos. Por el contrario, seguimos un enfoque reciente donde el mecanismo se diseña automáticamente para el problema específico en cuestión. Este enfoque aborda todos los inconvenientes mencionados anteriormente. Formulamos el problema de diseño de mecanismos como un problema de optimización. La entrada se caracteriza por el número de agentes, los posibles tipos de agentes (preferencias) y las distribuciones previas de los agregadores sobre los tipos de agentes. La salida es un mecanismo no manipulable que es óptimo con respecto a algún objetivo. Este enfoque se llama diseño de mecanismos automatizado. El enfoque de diseño de mecanismos automatizado tiene cuatro ventajas sobre el enfoque clásico de diseñar mecanismos generales. Primero, se puede utilizar incluso en entornos que no cumplen con las suposiciones de los mecanismos clásicos (como la disponibilidad de pagos laterales o que el objetivo sea el bienestar social). Segundo, puede permitir a uno eludir resultados de imposibilidad (como el teorema de Gibbard-Satterthwaite) que establecen que no existe un mecanismo que sea deseable para todas las preferencias. Cuando el mecanismo está diseñado para la configuración actual, no importa que no funcione de manera más general. Tercero, puede generar mecanismos mejores (en términos de garantías de no manipulabilidad más sólidas y/o mejores resultados) que los mecanismos clásicos porque el mecanismo aprovecha las particularidades del entorno (la información probabilística que el diseñador tiene sobre los tipos de agentes). Dada la gran cantidad de información que las partes tienen entre sí hoy en día, es probable que este enfoque conduzca a ahorros enormes en comparación con los mecanismos clásicos, que en su mayoría ignoran esa información. Por ejemplo, imagina una empresa creando automáticamente su mecanismo de adquisiciones basado en el conocimiento estadístico sobre sus proveedores, en lugar de utilizar una subasta de adquisiciones descendente clásica. Cuarto, la carga del diseño se traslada de los humanos a una máquina. Sin embargo, el diseño automatizado de mecanismos requiere que el problema de optimización del diseño del mecanismo se resuelva de nuevo para cada configuración. Por lo tanto, su complejidad computacional se convierte en un tema clave. Investigaciones previas han estudiado esta pregunta para diseñadores benevolentes que desean maximizar, por ejemplo, el bienestar social [5, 6]. En este artículo estudiamos la complejidad computacional del diseño automatizado de mecanismos en el caso de un diseñador con interés propio. Esta es una configuración importante para el diseño de mecanismos automatizados debido a la escasez de mecanismos generales en esta área, y al hecho de que en la mayoría de las configuraciones de comercio electrónico el diseñador actúa en su propio interés. También demostramos que este problema está estrechamente relacionado con un problema de diseño de subasta combinatoria óptima (maximización de ingresos) particular. El resto de este documento está organizado de la siguiente manera. En la Sección 2, justificamos el enfoque en mecanismos no manipulables. En la Sección 3, definimos el problema que estudiamos. En la Sección 4, demostramos que diseñar un mecanismo determinista óptimo es NP-completo incluso cuando al diseñador solo le importan los pagos que recibe. En la Sección 5, demostramos que diseñar un mecanismo determinista óptimo también es NP-completo cuando los pagos no son posibles y el diseñador solo está interesado en el resultado elegido. En la Sección 6, demostramos que un mecanismo óptimo aleatorizado puede ser diseñado en tiempo polinómico incluso en el caso general. Finalmente, en la Sección 7, demostramos que para diseñar subastas combinatorias óptimas bajo preferencias de mejor opción solamente, nuestros resultados sobre AMD implican que este problema es NP-completo para subastas determinísticas, pero sencillo para subastas aleatorias. 2. JUSTIFICANDO EL ENFOQUE EN MECANISMOS NO MANIPULABLES Antes de definir el problema computacional del diseño automatizado de mecanismos, debemos justificar nuestro enfoque en mecanismos no manipulables. Después de todo, no es inmediatamente obvio que no haya mecanismos manipulables que, incluso cuando los agentes informan estratégicamente sus tipos y, por lo tanto, a veces de manera no veraz, aún logren mejores resultados (según el objetivo que usemos) que cualquier mecanismo no manipulable. Sin embargo, resulta ser el caso que, dado cualquier mecanismo, podemos construir un mecanismo no manipulable cuyo rendimiento es idéntico, de la siguiente manera. Construimos una capa de interfaz entre los agentes y el mecanismo original. Los agentes informan sus preferencias (o tipos) a la capa de interfaz; posteriormente, la capa de interfaz introduce en el mecanismo original los tipos que los agentes habrían informado estratégicamente al mecanismo original, si sus tipos fueran los declarados a la capa de interfaz. El resultado resultante es el resultado del nuevo mecanismo. Dado que la capa de interfaz actúa estratégicamente en nombre de cada agente, nunca hay un incentivo para informar falsamente a la capa de interfaz; por lo tanto, los tipos informados por la capa de interfaz son los tipos estratégicos que se habrían informado sin la capa de interfaz, por lo que los resultados son exactamente como habrían sido con el mecanismo original. Este argumento es conocido en la literatura de diseño de mecanismos como el principio de revelación [16]. (Existen dificultades computacionales al aplicar el principio de revelación en espacios de resultados y tipos combinatorios grandes [7, 22]). Sin embargo, dado que aquí nos enfocamos en espacios de resultados y tipos representados de forma plana, esto no es una preocupación aquí. Dado esto, podemos centrarnos en mecanismos veraces en el resto del documento. 3. DEFINICIONES Ahora formalizamos el entorno del diseño automatizado de mecanismos. Definición 1. En un entorno de diseño de mecanismos automatizados, se nos proporciona: • un conjunto finito de resultados O; • un conjunto finito de N agentes; • para cada agente i, 1. un conjunto finito de tipos Θi, 2. una distribución de probabilidad γi sobre Θi (en el caso de tipos correlacionados, hay una única distribución conjunta γ sobre Θ1 × . . . × ΘN), y 3. una función de utilidad ui: Θi × O → R; 1 • Una función objetivo cuya expectativa el diseñador desea maximizar. Existen muchas posibles funciones objetivo que el diseñador podría tener, por ejemplo, el bienestar social (donde el diseñador busca maximizar la suma de las utilidades de los agentes), o la utilidad mínima de cualquier agente (donde el diseñador busca maximizar la peor utilidad experimentada por cualquier agente). En ambos casos, el diseñador es benevolente, ya que, de alguna manera, el diseñador está buscando la felicidad colectiva de los agentes. Sin embargo, en este documento nos enfocamos en el caso de un diseñador interesado en sí mismo. Un diseñador egoísta solo se preocupa por el resultado elegido (es decir, al diseñador no le importa cómo se relaciona el resultado con las preferencias de los agentes, sino que tiene una preferencia fija sobre los resultados) y sobre los pagos netos realizados por los agentes, que fluyen hacia el diseñador. Definición 2. Un diseñador interesado tiene una función objetivo dada por g(o) + Σ i=1 πi, donde g : O → R indica las preferencias del diseñador sobre los resultados, y πi es el pago realizado por el agente i. En el caso en que g = 0 en todas partes, se dice que el diseñador está maximizando el pago. En el caso en que los pagos no sean posibles, g constituye la función objetivo por sí sola. Ahora definimos los tipos de mecanismos en estudio. Por el principio de revelación, podemos restringir la atención a mecanismos de revelación directa y veraz, donde los agentes informan directamente sus tipos y nunca tienen incentivos para informarlos de manera incorrecta. Definición 3. Consideramos los siguientes tipos de mecanismos: • Un mecanismo determinista sin pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O. • Un mecanismo aleatorio sin pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), donde P(O) es el conjunto de distribuciones de probabilidad sobre O. • Un mecanismo determinista con pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O y, para cada agente i, una función de selección de pagos πi: Θ1 × Θ2 × . . . × ΘN → R, donde πi(θ1, . . . , θN ) da el pago realizado por el agente i cuando los tipos reportados son θ1, . . . , θN. Aunque esto sigue la notación estándar de la teoría de juegos [16], el hecho de que el agente tenga tanto una función de utilidad como un tipo puede resultar confuso. Los tipos codifican las diversas preferencias posibles que el agente pueda tener, y el tipo de los agentes no es conocido por el agregador. La función de utilidad es un conocimiento común, pero debido a que el tipo de agente es un parámetro en la función de utilidad de los agentes, el agregador no puede saber cuál es la utilidad de los agentes sin conocer el tipo de agente. Un mecanismo aleatorio con pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), y para cada agente i, una función de selección de pago πi: Θ1 × Θ2 × . . . × ΘN → R. Hay dos tipos de restricciones para el diseñador al construir el mecanismo. 3.1 Restricciones de racionalidad individual (IR) El primer tipo de restricción es el siguiente. La utilidad de cada agente debe ser al menos tan grande como la utilidad de respaldo de los agentes, es decir, la utilidad que el agente recibiría si no participara en el mecanismo. De lo contrario, ese agente no participaría en el mecanismo, y la participación de ningún agente puede perjudicar el objetivo de los diseñadores del mecanismo, ya que en el peor de los casos, el mecanismo puede ignorar a un agente fingiendo que el agente no está presente. (Además, si no se aplicara tal restricción, el diseñador simplemente podría hacer que los agentes paguen una cantidad infinita). Este tipo de restricción se llama restricción de IR (racionalidad individual). Existen tres posibles restricciones de IR diferentes: ex ante, ex interim y ex post, dependiendo de lo que el agente sabe sobre su propio tipo y los tipos de los demás al decidir si participar en el mecanismo. Ex ante IR significa que el agente participaría si no supiera absolutamente nada (ni siquiera su propio tipo). No estudiaremos este concepto en este documento. Ex interim IR significa que el agente siempre participaría si conociera solo su propio tipo, pero no el de los demás. Ex post IR significa que el agente siempre participaría incluso si conociera el tipo de todos. Definiremos formalmente las dos últimas nociones de IR. Primero, necesitamos formalizar el concepto del resultado de respaldo. Suponemos que la utilidad de respaldo de cada agente es cero para cada uno de sus tipos. Esto se hace sin pérdida de generalidad porque podemos agregar un término constante a la función de utilidad de un agente (para un tipo dado), sin afectar el comportamiento de toma de decisiones de ese agente maximizador de utilidad esperada [16]. Definición 4. En cualquier entorno de diseño de mecanismos automatizados con una restricción de IR, existe un resultado de contingencia o0 ∈ O donde, para cualquier agente i y cualquier tipo θi ∈ Θi, tenemos ui(θi, o0) = 0. (Además, en el caso de un diseñador egoísta, g(o0) = 0). Ahora podemos definir las nociones de racionalidad individual. Definición 5. La racionalidad individual (RI) se define como: • Un mecanismo determinista es ex interim RI si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0. Un mecanismo aleatorio es ex interim IR si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • Un mecanismo determinista es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 No aleatorizamos sobre los pagos porque mientras los agentes y el diseñador sean neutrales al riesgo con respecto a los pagos, es decir, su utilidad es lineal en los pagos, no hay razón para aleatorizar sobre los pagos. Un mecanismo aleatorio es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 3.2 Restricciones de compatibilidad de incentivos (IC) El segundo tipo de restricción establece que los agentes nunca deben tener un incentivo para informar incorrectamente su tipo (como se justificó anteriormente mediante el principio de revelación). Para este tipo de restricción, las dos variantes más comunes (o conceptos de solución) son la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash. Definición 6. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en estrategias dominantes si decir la verdad siempre es óptimo incluso cuando los tipos reportados por los otros agentes ya son conocidos. Formalmente, para cualquier agente i, cualquier vector de tipos (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ). En el caso de mecanismos aleatorios tenemos Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. Por lo tanto, en la implementación de estrategias dominantes, decir la verdad es óptimo independientemente de lo que informen los otros agentes. Si es óptimo solo dado que los otros agentes son veraces, y dado que uno no conoce los tipos de los otros agentes, tenemos implementación en equilibrio de Bayes-Nash. Definición 7. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en equilibrio de Bayes-Nash si decir la verdad siempre es óptimo para un agente cuando ese agente aún no sabe nada sobre los tipos de los otros agentes, y los otros agentes están diciendo la verdad. Formalmente, para cualquier agente i, cualquier tipo θi ∈ Θi, y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )]. En el caso de mecanismos aleatorios tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 135 3.3 Diseño de mecanismos automatizados Ahora podemos definir el problema computacional que estudiamos. Definición 8. (DISEÑO DE MECANISMOS AUTOMATIZADOS (AMD)) Se nos da: • un entorno de diseño de mecanismos automatizados, • una noción de IR (ex interim, ex post, o ninguna), • un concepto de solución (estrategias dominantes o Bayes-Nash), • si los pagos son posibles, • si la aleatorización es posible, • (en la variante de decisión del problema) un valor objetivo G. Se nos pregunta si existe un mecanismo del tipo especificado (en términos de pagos y aleatorización) que satisfaga tanto la noción de IR como el concepto de solución, y proporcione un valor esperado de al menos G para el objetivo. Un caso especial interesante es aquel en el que solo hay un agente. En este caso, el agente informante siempre sabe todo lo que hay que saber sobre los otros tipos de agentes, porque no hay otros agentes. Dado que el IR ex post y el IR ex interim solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de IR coinciden aquí. Además, dado que la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de solución coinciden aquí. Esta observación resultará ser una herramienta útil para demostrar resultados de dificultad: si demostramos dificultad computacional en el escenario de un solo agente, esto implica inmediatamente dificultad para ambos conceptos de IR, para ambos conceptos de solución, para cualquier número de agentes. 4. En esta sección demostramos que es NP-completo diseñar un mecanismo determinístico que maximice la suma esperada de los pagos recolectados de los agentes. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Para demostrar la NP-dureza, reducimos desde el problema MINSAT. Definición 9 (MINSAT). Se nos da una fórmula φ en forma normal conjuntiva, representada por un conjunto de variables booleanas V y un conjunto de cláusulas C, y un entero K (K < |C|). Se nos pregunta si existe una asignación a las variables en V tal que se satisfacen a lo sumo K cláusulas en φ. MINSAT fue recientemente demostrado como NP-completo [14]. Ahora podemos presentar nuestro resultado. Teorema 1. El problema determinista de maximización de pagos de AMD es NP-completo, incluso para un solo agente, incluso con una distribución uniforme de tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista de maximización de pagos de un solo agente. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V } ∪ {−v : v ∈ V }. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Sea l ∈ c denota que el literal l ocurre en la cláusula c. Entonces, la función de utilidad de los agentes está dada por u(θc, ol) = |Θ| + 1 para todo l ∈ L con l ∈ c; u(θc, ol) = 0 para todo l ∈ L con l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc) = 0 para todo c ∈ C con c = c; u(θv, ol) = |Θ| para todo l ∈ L con v(l) = v; u(θv, ol) = 0 para todo l ∈ L con v(l) = v; u(θv, oc) = 0 para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ|, donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v) y π(θv) = |Θ|. Para cada c ∈ C, sea o(θc) = oc; sea π(θc) = |Θ| + 1 si c no está satisfecha en la solución MINSAT, y π(θc) = |Θ| si c está satisfecha. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es θv, entonces cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivo para informar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Porque además, ningún tipo que no sea θc conduce al resultado oc, informar cualquier otro tipo dará como resultado una utilidad de 0, mientras que aún se requiere un pago de al menos |Θ| por parte del agente. Claramente, el agente está mejor reportando honestamente, para una utilidad total de 0. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), el pago esperado de este mecanismo es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o y una función de pago π. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. Entonces, la utilidad que el agente obtiene del resultado dado para este tipo es 0, y por lo tanto, según la IR, no se puede extraer ningún pago del agente para este tipo. Dado que, nuevamente por IR, el pago máximo que se puede extraer para cualquier otro tipo es |Θ| + 1, se sigue que el pago esperado máximo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo cual contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o−v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por la restricción de IR, el pago máximo que podemos extraer de cualquier tipo θv es |Θ|. Dado que no puede haber incentivos para que el agente informe falsamente, para cualquier cláusula c satisfecha por la asignación dada, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ|. (Pues si extrajéramos más de este tipo, la utilidad del agente en este caso sería menor que 1; y si v es la variable que satisface c en la asignación, de modo que o(θv) = ol donde l ocurre en c, entonces al agente le convendría más informar θv en lugar del informe veraz θc, para obtener un resultado que valga |Θ|+1 para él mientras tiene que pagar como máximo |Θ|.) Finalmente, para cualquier cláusula insatisfecha c, según la restricción de IR, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ| + 1. Se deduce que el pago esperado de nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia de MINSAT. Dado que AMD, que maximiza el pago, es solo un caso especial de AMD para un diseñador egoísta en el que el diseñador no tiene preferencias sobre el resultado elegido, esto implica inmediatamente dificultades para el caso general de AMD para un diseñador egoísta en el que los pagos son posibles. Sin embargo, esto aún no implica dureza para el caso especial donde los pagos no son posibles. Demostraremos la dificultad en este caso en la próxima sección. 5. En esta sección demostramos que es NP-completo diseñar un mecanismo determinista que maximice la expectativa del objetivo del diseñador cuando no son posibles los pagos. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Teorema 2. Sin pagos, el diseño determinista de AMD para un diseñador egoísta es NP-completo, incluso para un solo agente, incluso con una distribución uniforme sobre los tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista auto-interesada de un solo agente sin pagos. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L} ∪ {o∗}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V} ∪ {−v : v ∈ V}. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Deje que l ∈ c denote que el literal l ocurre en la cláusula c. Luego, deje que la función de utilidad de los agentes esté dada por u(θc, ol) = 2 para todo l ∈ L con l ∈ c; u(θc, ol) = −1 para todo l ∈ L con l /∈ c; u(θc, oc) = 2; u(θc, oc) = −1 para todo c ∈ C con c = c; u(θc, o∗) = 1; u(θv, ol) = 1 para todo l ∈ L con v(l) = v; u(θv, ol) = −1 para todo l ∈ L con v(l) = v; u(θv, oc) = −1 para todo c ∈ C; u(θv, o∗) = −1. Que la función objetivo de los diseñadores esté dada por g(o∗ ) = |Θ|+1; g(ol) = |Θ| para todo l ∈ L; g(oc) = |Θ| para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ| , donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v). Para cada c ∈ C que se cumpla en la solución MINSAT, sea o(θc) = oc; para cada c ∈ C no satisfecho, sea o(θc) = o∗. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es algún θv, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para reportar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Debido a que tampoco ningún tipo conduce al resultado oc, no hay ningún resultado que el mecanismo seleccione que le daría al agente una utilidad mayor a 1 para el tipo θc, y por lo tanto el agente no tiene incentivo para informar falsamente. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), entonces el valor esperado de la función objetivo de los diseñadores es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. El único otro resultado que el mecanismo puede elegir bajo la restricción de IR es o0. Esto tiene un valor objetivo de 0, y dado que el valor más alto que la función objetivo alcanza es |Θ| + 1, se sigue que el valor esperado máximo de la función objetivo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo que contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o-v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por lo anterior, para cualquier tipo θv, el valor de la función objetivo en este mecanismo será |Θ|. Para cualquier cláusula c satisfecha por la asignación dada, el valor de la función objetivo en el caso en que el agente informe el tipo θc será como máximo |Θ|. (Esto se debe a que no podemos elegir el resultado o∗ para dicho tipo, ya que en este caso el agente tendría un incentivo para informar θv en su lugar, donde v es la variable que satisface c en la asignación (de modo que o(θv) = ol donde l ocurre en c).) Finalmente, para cualquier cláusula insatisfecha c, el valor máximo que la función objetivo puede alcanzar en el caso en que el agente informa el tipo θc es |Θ| + 1, simplemente porque este es el valor más grande que la función alcanza en cualquier momento. Se deduce que el valor esperado de la función objetivo para nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas 137 satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia MINSAT. Ambos de nuestros resultados de dureza se basaron en la restricción de que el mecanismo debería ser determinista. En la siguiente sección, mostramos que la dificultad del diseño desaparece cuando permitimos la aleatorización en el mecanismo. 6. La aleatorización de AMD para un diseñador interesado en sí mismo es fácil. Ahora mostramos cómo permitir la aleatorización sobre los resultados hace que el problema de AMD auto-interesado sea manejable a través de la programación lineal, para cualquier número constante de agentes. Teorema 3. El AMD aleatorio con interés propio con un número constante de agentes es resoluble en tiempo polinómico mediante programación lineal, tanto con pagos como sin pagos, tanto para IR ex post como ex interim, y tanto para la implementación en estrategias dominantes como para la implementación en equilibrio de Bayes-Nash, incluso si los tipos están correlacionados. Prueba. Dado que los programas lineales pueden resolverse en tiempo polinómico [13], todo lo que necesitamos demostrar es que el número de variables y ecuaciones en nuestro programa es polinomial para cualquier número constante de agentes, es decir, exponencial solo en N. En todo momento, para determinar el tamaño del programa lineal, consideremos T = maxi{|Θi|}. Las variables de nuestro programa lineal serán las probabilidades (p(θ1, θ2, . . . , θN ))(o) (como máximo TN |O| variables) y los pagos πi(θ1, θ2, . . . , θN ) (como máximo NTN variables). (Mostramos el programa lineal para el caso en que los pagos son posibles; el caso sin pagos se obtiene fácilmente de esto simplemente omitiendo todas las variables de pago en el programa, o agregando restricciones adicionales que obliguen a los pagos a ser 0). Primero, mostramos las restricciones de IR. Para el IR ex post, agregamos las siguientes restricciones (como máximo NTN) al LP: • Para cada i ∈ {1, 2, . . . , N}, y para cada (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , agregamos ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0. Para el ex interino IR, agregamos las siguientes restricciones (como máximo NT) al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada θi ∈ Θi, agregamos θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0. Ahora, mostramos las restricciones del concepto de solución. Para la implementación en estrategias dominantes, agregamos las siguientes (a lo sumo NTN+1) restricciones al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ). Finalmente, para la implementación en el equilibrio de Bayes-Nash, agregamos las siguientes (a lo sumo NT2) restricciones al LP: • Para cada i ∈ {1, 2, ..., N}, para cada θi ∈ Θi, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )). Todo lo que queda por hacer es dar la expresión que el diseñador busca maximizar, que es: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )). Como indicamos, el número de variables y restricciones es exponencial solo en N, por lo tanto, el programa lineal tiene un tamaño polinómico para un número constante de agentes. Por lo tanto, el problema es resoluble en tiempo polinómico. IMPLICACIONES PARA UN PROBLEMA DE DISEÑO DE SUBASTA COMBINATORIA ÓPTIMA En esta sección, demostraremos algunas consecuencias interesantes del problema de diseño de mecanismos automatizados para un diseñador interesado en sí mismo en el diseño de subastas combinatorias óptimas. Considera una subasta combinatoria con un conjunto S de artículos en venta. Para cualquier conjunto B ⊆ S, dejemos que ui(θi, B) sea la utilidad del postor i al recibir el conjunto B cuando el tipo del postor es θi. El problema de diseño de subasta óptima consiste en especificar las reglas de la subasta de manera que se maximice los ingresos esperados para el subastador. (Por el principio de revelación, sin pérdida de generalidad, podemos asumir que la subasta es veraz). El problema de diseño de subasta óptima se resuelve para el caso de un solo artículo mediante la famosa subasta de Myerson [18]. Sin embargo, el diseño de subastas óptimas en subastas combinatorias es un problema de investigación abierto reconocido [3, 25]. El problema está abierto incluso si solo hay dos artículos en venta. (El caso de dos artículos con una forma muy especial de complementariedad y sin sustituibilidad ha sido resuelto recientemente [1].) Supongamos que tenemos disposición libre: los artículos pueden ser desechados sin costo alguno. Además, supongamos que las preferencias de los postores tienen la siguiente estructura: cuando un postor recibe un conjunto de artículos, la utilidad del postor por ese conjunto está determinada únicamente por el mejor artículo en el conjunto. (Enfatizamos que qué artículo es el mejor puede depender del tipo de postor). Definición 10. Se dice que el postor i tiene preferencias solo por lo mejor sobre paquetes de artículos si existe una función vi: Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s). Hacemos la siguiente observación útil en este contexto: no tiene sentido otorgarle a un postor más de un artículo. La razón es que si el postor está informando honestamente, quitarle todos los artículos menos el de mayor valor no perjudicará al postor; y, mediante la disposición gratuita, hacerlo solo reducirá el incentivo para que este postor informe falsamente este tipo, cuando en realidad tiene otro tipo. Ahora demostramos que el problema de diseñar una subasta óptima determinista es NP-completo, mediante una reducción del problema AMD de maximización de pagos. Teorema 4. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de artículos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), diseñar la subasta determinística óptima es NP-completo, incluso para un único postor con una distribución uniforme sobre los tipos. Prueba. El problema está en NP porque podemos generar de manera no determinista una regla de asignación, y luego establecer los pagos utilizando programación lineal. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de AMD determinista que maximiza el pago, con un único agente y una distribución uniforme de tipos, al siguiente problema de diseño de subasta combinatoria óptima con una única postor con preferencias de solo los mejores. Para cada resultado o ∈ O en la instancia de AMD (excepto el resultado o0), que haya un artículo so ∈ S. Que el espacio de tipos sea el mismo, y que v(θi, so) = ui(θi, o) (donde u está especificado en la instancia de AMD). Que el valor objetivo de ingresos esperados sea el mismo en ambas instancias. Mostramos que las instancias son equivalentes. Primero supongamos que existe una solución para la instancia de AMD, dada por una función de resultado y una función de pago. Entonces, si la solución de AMD elige el resultado o para un tipo, en la solución de subasta óptima, asignamos {so} al postor para este tipo. (A menos que o = o0, en cuyo caso asignamos {} al postor). Que las funciones de pago sean las mismas en ambas instancias. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo verdadero) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución óptima de la subasta. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el subastador/diseñador son los mismos. Se deduce que existe una solución para la instancia de diseño de subasta óptima. Ahora supongamos que existe una solución para la instancia de diseño de subasta óptima. Por la observación de que como máximo se puede tener un artículo, podemos asumir sin pérdida de generalidad que la solución nunca asigna más de un artículo. Entonces, si la solución de subasta óptima asigna el artículo al postor para un tipo, en la solución de AMD, permita que el mecanismo elija el resultado o para ese tipo. Si la solución de subasta óptima no asigna nada al postor para un tipo, en la solución AMD, permita que el mecanismo elija el resultado o0 para ese tipo. Que las funciones de pago sean las mismas. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo real) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución AMD. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el diseñador/subastador son los mismos. Se deduce que existe una solución para la instancia de AMD. Afortunadamente, también podemos extender el resultado de facilidad para mecanismos aleatorios a este escenario de subasta combinatoria, lo que nos proporciona uno de los pocos algoritmos de tiempo polinómico conocidos para un problema de diseño óptimo de subasta combinatoria. Teorema 5. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de elementos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), si el número de postores es una constante k, entonces la subasta aleatoria óptima puede ser diseñada en tiempo polinómico. (Para cualquier restricción de IC e IR.) Prueba. Por la observación de que a lo sumo un artículo, podemos sin pérdida de generalidad restringirnos a asignaciones donde cada postor recibe como máximo un artículo. Hay menos de (|S| + 1)k asignaciones de ese tipo, es decir, un número polinómico de asignaciones. Dado que podemos enumerar explícitamente los resultados, simplemente podemos resolver esto como una instancia de AMD que maximiza el pago, con programación lineal. 8. Investigaciones relacionadas sobre la complejidad en el diseño de mecanismos. Ha habido un considerable interés reciente en el diseño de mecanismos en la informática. Parte de ello se ha centrado en cuestiones de complejidad computacional, pero la mayor parte de ese trabajo ha buscado diseñar mecanismos que sean fáciles de ejecutar (por ejemplo, [20, 15, 19, 9, 12]), en lugar de estudiar la complejidad de diseñar el mecanismo. La pieza más cercana de trabajo anterior estudió la complejidad del diseño automatizado de mecanismos por un diseñador benevolente [5, 6]. Roughgarden ha estudiado la complejidad de diseñar una buena topología de red para agentes que eligen egoístamente los enlaces que utilizan [21]. Esto está relacionado con el diseño de mecanismos, pero difiere significativamente en que el diseñador solo tiene un control restringido sobre las reglas del juego porque no hay ninguna parte que pueda imponer el resultado (o pagos laterales). Además, no hay un informe explícito de preferencias. 9. CONCLUSIONES E INVESTIGACIONES FUTURAS A menudo, un resultado debe ser elegido en función de las preferencias informadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les sea más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un <br>resultado deseable</br>. En un enfoque recientemente emergente llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración específica de agregación de preferencias en cuestión. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo, un entorno mucho más relevante para el comercio electrónico. En este contexto, al centro solo le importa qué resultado se elige y qué pagos se le realizan. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este escenario, demostramos que diseñar un mecanismo determinista óptimo es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Estos resultados de dureza implican dificultad en todos los entornos de diseño de mecanismos automatizados más generales con un diseñador egoísta. Los resultados de dureza se aplican ya sea que las restricciones de racionalidad individual (participación) se apliquen ex interim o ex post, y ya sea que el concepto de solución sea la implementación de estrategias dominantes o la implementación del equilibrio de Bayes-Nash. Luego demostramos que permitir la aleatorización en el mecanismo hace que el problema de diseño en todos estos escenarios sea computacionalmente sencillo. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (que maximiza los ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar un mecanismo determinístico óptimo es NP-completo incluso con un agente, pero diseñar un mecanismo aleatorio óptimo es fácil. La investigación futura incluye estudiar el diseño automatizado de mecanismos con un diseñador interesado en sí mismo en entornos más restringidos, como subastas (donde el objetivo del diseñador puede incluir preferencias sobre qué postor debería recibir el bien, así como los pagos). También queremos estudiar la complejidad del diseño de mecanismos automatizados en entornos donde los espacios de resultados y tipos tienen una estructura especial para que puedan representarse de manera más concisa. Finalmente, planeamos reunir un conjunto de datos de problemas de diseño de mecanismos del mundo real, tanto históricos como actuales, y aplicar el diseño de mecanismos automatizado a esos problemas. 10. REFERENCIAS [1] M. Armstrong. Subastas multi-objetivo óptimas. Revisión de Estudios Económicos, 67:455-481, 2000. [2] K. Arrow. La doctrina de los derechos de propiedad y la revelación de la demanda bajo información incompleta. En M. Boskin, editor, Economía y bienestar humano. New York Academic Press, 1979. [3] C. Avery y T. Hendershott. Agrupación y subastas óptimas de múltiples productos. Revisión de Estudios Económicos, 67:483-497, 2000. [4] E. H. Clarke. Precios escalonados de bienes públicos. Elección Pública, 11:17-33, 1971. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Actas de la 18ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI-02), páginas 103-110, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Diseño de mecanismos automatizados: Resultados de complejidad derivados del entorno de un solo agente. En Actas de la 5ta Conferencia Internacional de Comercio Electrónico (ICEC-03), páginas 17-24, Pittsburgh, PA, EE. UU., 2003. [7] V. Conitzer y T. Sandholm. Críticas computacionales del principio de revelación. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), Nueva York, NY, 2004. Breve ensayo. La versión completa apareció en el taller AAMAS-03 sobre Comercio Electrónico Mediado por Agentes (AMEC). [8] C. d'Aspremont y L. A. Gérard-Varet. Incentivos e información incompleta. Revista de Economía Pública, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou y S. Shenker. Compartiendo el costo de las transmisiones de multidifusión. Revista de Ciencias de la Computación y de Sistemas, 63:21-41, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 2000. [10] A. Gibbard. Manipulación de esquemas de votación. Econometrica, 41:587-602, 1973. [11] T. Groves.\nEconometrica, 41:587-602, 1973. [11] T. Groves. Incentivos en equipos. Econometrica, 41:617-631, 1973. [12] J. Hershberger y S. Suri. Precios de Vickrey y caminos más cortos: ¿Cuánto vale una arista? En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [13] L. Khachiyan. Un algoritmo polinómico en programación lineal. Matemática soviética. Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi y P. Mirchandani. El problema de satisfacibilidad mínimo. Revista SIAM de Matemáticas Discretas, 7(2):275-283, 1994. [15] D. Lehmann, L. I. O'Callaghan y Y. Shoham. Revelación de la verdad en subastas combinatorias rápidas y aproximadamente eficientes. Revista de la ACM, 49(5):577-602, 2002. La versión inicial apareció en las Actas de la Conferencia de Comercio Electrónico de la ACM (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [17] E. S. Maskin y J. Riley. Subastas multiunidad óptimas. En F. Hahn, editor, \"La economía de los mercados faltantes, la información y los juegos\", capítulo 14, páginas 312-335. Clarendon Press, Oxford, 1989. [18] R. Myerson.\nPrensa Clarendon, Oxford, 1989. [18] R. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6:58-73, 1981. [19] N. Nisan y A. Ronen. Mecanismos VCG computacionalmente factibles. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 242-252, Minneapolis, MN, 2000. [20] N. Nisan y A. Ronen. Diseño de mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166-196, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 1999. [21] T. Roughgarden. Diseñar redes para usuarios egoístas es difícil. En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [22] T. Sandholm. Problemas en subastas computacionales de Vickrey. Revista Internacional de Comercio Electrónico, 4(3):107-129, 2000. Número especial sobre la Aplicación de Agentes Inteligentes para el Comercio Electrónico. Una versión corta y temprana apareció en la Segunda Conferencia Internacional sobre Sistemas Multiagente (ICMAS), páginas 299-306, 1996. [23] M. A. Satterthwaite. In Spanish, the translation would be: \"Inmutabilidad estratégica y condiciones de Arrow: teoremas de existencia y correspondencia para procedimientos de votación y funciones de bienestar social.\" Revista de Teoría Económica, 10:187-217, 1975. [24] W. Vickrey. Contrarrestando la especulación, subastas y ofertas selladas competitivas. Revista de Finanzas, 16:8-37, 1961. [25] R. V. Vohra. Problemas de investigación en subastas combinatorias. Mimeo, versión 29 de octubre de 2001. 141 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "manipulability": {
            "translated_key": "manipulabilidad",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-interested Automated Mechanism Design and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently proposed approach-called automated mechanism design-a mechanism is computed for the preference aggregation setting at hand.",
                "This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike the earlier work on automated mechanism design that studied a benevolent designer, in this paper we study automated mechanism design problems where the designer is self-interested.",
                "In this case, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy.",
                "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy.",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc.",
                "The preference aggregator generally does not know the agents preferences a priori.",
                "Rather, the agents report their preferences to the coordinator.",
                "Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully.",
                "Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen.",
                "<br>manipulability</br> is a pervasive problem across preference aggregation mechanisms.",
                "A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.)",
                "What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective.",
                "This is the classic setting of mechanism design in game theory.",
                "In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself.",
                "This is the mechanism design setting most relevant to electronic commerce.",
                "In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear.",
                "It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences.",
                "The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments.",
                "The most common such constraint is that of individual rationality (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
                "For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences.",
                "Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it.",
                "Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off.",
                "On the other hand, the designer will not necessarily choose a social welfare maximizing outcome.",
                "For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected.",
                "Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0.",
                "Classical mechanism design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective.",
                "The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]).",
                "However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare.",
                "If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization.",
                "In practice, the designer may also be interested in the outcome per se.",
                "For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical.",
                "For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed.",
                "Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments.",
                "In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand.",
                "This approach addresses all of the downsides listed above.",
                "We formulate the mechanism design problem as an optimization problem.",
                "The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types.",
                "The output is a nonmanipulable mechanism that is optimal with respect to some objective.",
                "This approach is called automated mechanism design.",
                "The automated mechanism design approach has four advantages over the classical approach of designing general mechanisms.",
                "First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare).",
                "Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences.",
                "When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally.",
                "Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types).",
                "Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information.",
                "For example, imagine a company automatically creating its procurement mechanism based on statistical knowledge about its suppliers, rather than using a classical descending procurement auction.",
                "Fourth, the burden of design is shifted from humans to a machine.",
                "However, automated mechanism design requires the mechanism design optimization problem to be solved anew for each setting.",
                "Hence its computational complexity becomes a key issue.",
                "Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6].",
                "In this paper we study the computational complexity of automated mechanism design in the case of a self-interested designer.",
                "This is an important setting for automated mechanism design due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested.",
                "We also show that this problem is closely related to a particular optimal (revenue-maximizing) combinatorial auction design problem. 133 The rest of this paper is organized as follows.",
                "In Section 2, we justify the focus on nonmanipulable mechanisms.",
                "In Section 3, we define the problem we study.",
                "In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it.",
                "In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen.",
                "In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case.",
                "Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2.",
                "JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of automated mechanism design, we should justify our focus on nonmanipulable mechanisms.",
                "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any nonmanipulable mechanism.",
                "This does, however, turn out to be the case: given any mechanism, we can construct a nonmanipulable mechanism whose performance is identical, as follows.",
                "We build an interface layer between the agents and the original mechanism.",
                "The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer.",
                "The resulting outcome is the outcome of the new mechanism.",
                "Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism.",
                "This argument is known in the mechanism design literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22].",
                "However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.)",
                "Given this, we can focus on truthful mechanisms in the rest of the paper. 3.",
                "DEFINITIONS We now formalize the automated mechanism design setting.",
                "Definition 1.",
                "In an automated mechanism design setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize.",
                "There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent).",
                "In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness.",
                "However, in this paper, we focus on the case of a self-interested designer.",
                "A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer.",
                "Definition 2.",
                "A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i.",
                "In the case where g = 0 everywhere, the designer is said to be payment maximizing.",
                "In the case where payments are not possible, g constitutes the objective function by itself.",
                "We now define the kinds of mechanisms under study.",
                "By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them.",
                "Definition 3.",
                "We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing.",
                "The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator.",
                "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 Individual rationality (IR) constraints The first type of constraint is the following.",
                "The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism.",
                "Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.)",
                "This type of constraint is called an IR (individual rationality) constraint.",
                "There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism.",
                "Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type).",
                "We will not study this concept in this paper.",
                "Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others.",
                "Ex post IR means that the agent would always participate even if it knew everybodys type.",
                "We will define the latter two notions of IR formally.",
                "First, we need to formalize the concept of the fallback outcome.",
                "We assume that each agents fallback utility is zero for each one of its types.",
                "This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16].",
                "Definition 4.",
                "In any automated mechanism design setting with an IR constraint, there is a fallback outcome o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)",
                "We can now to define the notions of individual rationality.",
                "Definition 5.",
                "Individual rationality (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
                "A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments.",
                "A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
                "The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle).",
                "For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium.",
                "Definition 6.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known.",
                "Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
                "In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible.",
                "Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report.",
                "If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium.",
                "Definition 7.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth.",
                "Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible. 135 3.3 Automated mechanism design We can now define the computational problem we study.",
                "Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an automated mechanism design setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective.",
                "An interesting special case is the setting where there is only one agent.",
                "In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents.",
                "Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here.",
                "Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here.",
                "This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4.",
                "PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "To demonstrate NPhardness, we reduce from the MINSAT problem.",
                "Definition 9 (MINSAT).",
                "We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|).",
                "We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied.",
                "MINSAT was recently shown to be NP-complete [14].",
                "We can now present our result.",
                "Theorem 1.",
                "Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent payment-maximizing deterministic AMD instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|.",
                "For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the MINSAT solution, and π(θc) = |Θ| if c is satisfied.",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent.",
                "Clearly the agent is better off reporting truthfully, for a total utility of 0.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type.",
                "Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the IR constraint, the maximum payment we can extract from any type θv is |Θ|.",
                "Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.)",
                "Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1.",
                "It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible.",
                "However, it does not yet imply hardness for the special case where payments are not possible.",
                "We will prove hardness in this case in the next section. 5.",
                "SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "Theorem 2.",
                "Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent self-interested deterministic AMD without payments instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1.",
                "Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v).",
                "For every c ∈ C that is satisfied in the MINSAT solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ .",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "The only other outcome that the mechanism is allowed to choose under the IR constraint is o0.",
                "This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}.",
                "We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|.",
                "For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).)",
                "Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes.",
                "It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Both of our hardness results relied on the constraint that the mechanism should be deterministic.",
                "In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6.",
                "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of self-interested AMD tractable through linear programming, for any constant number of agents.",
                "Theorem 3.",
                "Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated.",
                "Proof.",
                "Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}.",
                "The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.)",
                "First, we show the IR constraints.",
                "For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
                "For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
                "Now, we show the solution concept constraints.",
                "For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
                "Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
                "All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
                "As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents.",
                "Thus the problem is solvable in polynomial time. 7.",
                "IMPLICATIONS FOR AN OPTIMAL COMBINATORIAL AUCTION DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated mechanism design for a self-interested designer on designing optimal combinatorial auctions.",
                "Consider a combinatorial auction with a set S of items for sale.",
                "For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi.",
                "The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.)",
                "The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18].",
                "However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25].",
                "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of complementarity and no substitutability has been solved recently [1].)",
                "Suppose we have free disposal-items can be thrown away at no cost.",
                "Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.)",
                "Definition 10.",
                "Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
                "We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item.",
                "The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type.",
                "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the payment maximizing AMD problem!",
                "Theorem 4.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types.",
                "Proof.",
                "The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming.",
                "To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal combinatorial auction design problem instance with a single bidder with best-only preferences.",
                "For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance).",
                "Let the expected revenue target value be the same in both instances.",
                "We show the instances are equivalent.",
                "First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function.",
                "Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.)",
                "Let the payment functions be the same in both instances.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same.",
                "It follows that there exists a solution to the optimal auction design instance.",
                "Now suppose there exists a solution to the optimal auction design instance.",
                "By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item.",
                "Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type.",
                "If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type.",
                "Let the payment functions be the same.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same.",
                "It follows that there exists a solution to the AMD instance.",
                "Fortunately, we can also carry through the easiness result for randomized mechanisms to this combinatorial auction setting-giving us one of the few known polynomial-time algorithms for an optimal combinatorial auction design problem.",
                "Theorem 5.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.)",
                "Proof.",
                "By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item.",
                "There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations.",
                "Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8.",
                "RELATED RESEARCH ON COMPLEXITY IN MECHANISM DESIGN There has been considerable recent interest in mechanism design in computer science.",
                "Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism.",
                "The closest piece of earlier work studied the complexity of automated mechanism design by a benevolent designer [5, 6].",
                "Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21].",
                "This is related to mechanism design, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments).",
                "Also, there is no explicit reporting of preferences. 9.",
                "CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently emerging approach-called automated mechanism design-a mechanism is computed for the specific preference aggregation setting at hand.",
                "This has several advantages, 139 but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike earlier work on automated mechanism design that studied a benevolent designer, in this paper we studied automated mechanism design problems where the designer is self-interesteda setting much more relevant for electronic commerce.",
                "In this setting, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "These hardness results imply hardness in all more general automated mechanism design settings with a self-interested designer.",
                "The hardness results apply whether the individual rationality (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation.",
                "We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy.",
                "Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy.",
                "Future research includes studying automated mechanism design with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments).",
                "We also want to study the complexity of automated mechanism design in settings where the outcome and type spaces have special structure so they can be represented more concisely.",
                "Finally, we plan to assemble a data set of real-world mechanism design problems-both historical and current-and apply automated mechanism design to those problems. 10.",
                "REFERENCES [1] M. Armstrong.",
                "Optimal multi-object auctions.",
                "Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow.",
                "The property rights doctrine and demand revelation under incomplete information.",
                "In M. Boskin, editor, Economics and human welfare.",
                "New York Academic Press, 1979. [3] C. Avery and T. Hendershott.",
                "Bundling and optimal auctions of multiple products.",
                "Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke.",
                "Multipart pricing of public goods.",
                "Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Automated mechanism design: Complexity results stemming from the single-agent setting.",
                "In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm.",
                "Computational criticisms of the revelation principle.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004.",
                "Short paper.",
                "Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet.",
                "Incentives and incomplete information.",
                "Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker.",
                "Sharing the cost of muliticast transmissions.",
                "Journal of Computer and System Sciences, 63:21-41, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard.",
                "Manipulation of voting schemes.",
                "Econometrica, 41:587-602, 1973. [11] T. Groves.",
                "Incentives in teams.",
                "Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri.",
                "Vickrey prices and shortest paths: What is an edge worth?",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan.",
                "A polynomial algorithm in linear programming.",
                "Soviet Math.",
                "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani.",
                "The minimum satisfiability problem.",
                "SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham.",
                "Truth revelation in rapid, approximately efficient combinatorial auctions.",
                "Journal of the ACM, 49(5):577-602, 2002.",
                "Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [17] E. S. Maskin and J. Riley.",
                "Optimal multi-unit auctions.",
                "In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335.",
                "Clarendon Press, Oxford, 1989. [18] R. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen.",
                "Computationally feasible VCG mechanisms.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behavior, 35:166-196, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden.",
                "Designing networks for selfish users is hard.",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm.",
                "Issues in computational Vickrey auctions.",
                "International Journal of Electronic Commerce, 4(3):107-129, 2000.",
                "Special Issue on 140 Applying Intelligent Agents for Electronic Commerce.",
                "A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite.",
                "Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions.",
                "Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey.",
                "Counterspeculation, auctions, and competitive sealed tenders.",
                "Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra.",
                "Research problems in combinatorial auctions.",
                "Mimeo, version Oct. 29, 2001. 141"
            ],
            "original_annotated_samples": [
                "<br>manipulability</br> is a pervasive problem across preference aggregation mechanisms."
            ],
            "translated_annotated_samples": [
                "La <br>manipulabilidad</br> es un problema generalizado en los mecanismos de agregación de preferencias."
            ],
            "translated_text": "Diseño de mecanismos automatizados de interés propio e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les resulte más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente propuesto, llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración de agregación de preferencias actual. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre el diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo. En este caso, al centro solo le importa qué resultado se elige y qué pagos se le hacen. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este contexto, demostramos que el diseño de mecanismos deterministas óptimos es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Luego mostramos cómo permitir la aleatorización en el mecanismo hace que los problemas en este entorno sean computacionalmente fáciles. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (maximizadora de ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar una subasta determinista óptima es NP-completo, pero diseñar una subasta aleatoria óptima es fácil. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Teoría 1. En entornos multiagentes, a menudo se debe elegir un resultado en función de las preferencias informadas por un grupo de agentes. Tales resultados podrían ser presidentes potenciales, planes conjuntos, asignaciones de bienes o recursos, etc. El agregador de preferencias generalmente no conoce las preferencias de los agentes de antemano. Más bien, los agentes informan sus preferencias al coordinador. Desafortunadamente, un agente puede tener un incentivo para informar incorrectamente sus preferencias con el fin de engañar al mecanismo y lograr que seleccione un resultado que sea más deseable para el agente que el resultado que se seleccionaría si el agente revelara sus preferencias de manera honesta. Tal manipulación es indeseable porque los mecanismos de agregación de preferencias están diseñados para agrupar las preferencias de una manera socialmente deseable, y si los agentes revelan sus preferencias de manera insincera, se podría elegir un resultado socialmente indeseable. La <br>manipulabilidad</br> es un problema generalizado en los mecanismos de agregación de preferencias. Un resultado negativo seminal, el teorema de Gibbard-Satterthwaite, muestra que bajo cualquier esquema de agregación de preferencias no dictatorial, si hay al menos 3 posibles resultados, existen preferencias bajo las cuales un agente está mejor reportando falsamente [10, 23]. (Un esquema de agregación de preferencias se llama dictatorial si uno de los agentes dicta el resultado sin importar las preferencias que reporten los otros agentes). Lo que le gustaría hacer al agregador es diseñar un mecanismo de agregación de preferencias para que 1) los agentes interesados reporten sus preferencias de manera veraz, y 2) el mecanismo elija un resultado que sea deseable desde la perspectiva de algún objetivo. Esta es la configuración clásica del diseño de mecanismos en la teoría de juegos. En este documento, estudiamos el caso en el que el diseñador actúa por interés propio, es decir, al diseñador no le importa directamente cómo se relaciona el resultado con las preferencias de los agentes, sino que está más preocupado por su propia agenda sobre cuál resultado debería ser elegido y en maximizar los pagos para sí mismo. Este es el entorno de diseño de mecanismos más relevante para el comercio electrónico. En el caso en que el diseñador del mecanismo esté interesado en maximizar alguna noción de bienestar social, la importancia de recopilar las preferencias de los agentes es clara. Quizás sea menos obvio por qué deberían ser recopilados cuando el diseñador está interesado en sí mismo y, por lo tanto, su objetivo no está directamente relacionado con las preferencias de los agentes. La razón de esto es que a menudo las preferencias de los agentes imponen límites en cómo el diseñador elige el resultado y los pagos. La restricción más común de este tipo es la de racionalidad individual (RI), lo que significa que el mecanismo no puede dejar a ningún agente en una situación peor a la que hubiera estado si no hubiera participado en el mecanismo. Por ejemplo, en el contexto del diseño óptimo de subastas, el diseñador (subastador) solo se preocupa por cuántos ingresos se recaudan, y no en sí mismo por cuán bien la asignación del bien (o bienes) corresponde a las preferencias de los agentes. Sin embargo, el diseñador no puede obligar a un agente a pagar más de lo que valora el paquete de bienes asignado a él. Por lo tanto, incluso un diseñador interesado en sí mismo elegirá un resultado que beneficie razonablemente a los agentes. Por otro lado, el diseñador no necesariamente elegirá un resultado que maximice el bienestar social. Por ejemplo, si el diseñador siempre elige un resultado que maximiza el bienestar social con respecto a las preferencias informadas, y obliga a cada agente a pagar la diferencia entre la utilidad que tiene ahora y la utilidad que habría tenido si no hubiera participado en el mecanismo, es fácil ver que los agentes pueden tener un incentivo para informar incorrectamente sus preferencias, lo que puede llevar realmente a recaudar menos ingresos. De hecho, uno de los resultados contraintuitivos de la teoría del diseño de subastas óptimas es que a veces el bien se asigna a nadie incluso cuando el subastador tiene un precio de reserva de 0. El diseño de mecanismos clásicos proporciona algunos mecanismos generales, que, bajo ciertas suposiciones, satisfacen alguna noción de no manipulabilidad y maximizan algún objetivo. La ventaja de estos mecanismos es que no dependen de información (incluso probabilística) sobre las preferencias de los agentes (por ejemplo, el mecanismo de Vickrey-Clarke-Groves (VCG) [24, 4, 11]), o pueden aplicarse fácilmente a cualquier distribución de probabilidad sobre las preferencias (por ejemplo, el mecanismo dAGVA [8, 2], la subasta de Myerson [18], y la subasta multiunidad de Maskin-Riley [17]). Sin embargo, los mecanismos generales también tienen importantes desventajas: • Los mecanismos generales más famosos y ampliamente aplicables, VCG y dAGVA, solo maximizan el bienestar social. Si el diseñador está interesado en sí mismo, como es el caso en muchos entornos de comercio electrónico, estos mecanismos no maximizan el objetivo del diseñador. • Los mecanismos generales que se centran en un diseñador interesado en sí mismo solo son aplicables en entornos muy restringidos, como la subasta de maximización de ingresos esperados de Myerson para vender un solo artículo, y la subasta de maximización de ingresos esperados de Maskin y Riley para vender múltiples unidades idénticas de un artículo. • Incluso en los entornos restringidos en los que se aplican estos mecanismos, solo permiten la maximización de pagos. En la práctica, el diseñador también puede estar interesado en el resultado en sí mismo. Por ejemplo, a un subastador le puede importar qué postor recibe el artículo. • A menudo se asume que los pagos laterales pueden ser utilizados para adaptar los incentivos de los agentes, pero esto no siempre es práctico. Por ejemplo, en los mercados electrónicos basados en trueque, como Recipco, firstbarter.com, BarterOne e Intagio, no se permiten los pagos laterales. Además, entre los agentes de software, podría ser más deseable construir mecanismos que no dependan de la capacidad de realizar pagos, ya que muchos agentes de software no cuentan con la infraestructura para hacer pagos. Por el contrario, seguimos un enfoque reciente donde el mecanismo se diseña automáticamente para el problema específico en cuestión. Este enfoque aborda todos los inconvenientes mencionados anteriormente. Formulamos el problema de diseño de mecanismos como un problema de optimización. La entrada se caracteriza por el número de agentes, los posibles tipos de agentes (preferencias) y las distribuciones previas de los agregadores sobre los tipos de agentes. La salida es un mecanismo no manipulable que es óptimo con respecto a algún objetivo. Este enfoque se llama diseño de mecanismos automatizado. El enfoque de diseño de mecanismos automatizado tiene cuatro ventajas sobre el enfoque clásico de diseñar mecanismos generales. Primero, se puede utilizar incluso en entornos que no cumplen con las suposiciones de los mecanismos clásicos (como la disponibilidad de pagos laterales o que el objetivo sea el bienestar social). Segundo, puede permitir a uno eludir resultados de imposibilidad (como el teorema de Gibbard-Satterthwaite) que establecen que no existe un mecanismo que sea deseable para todas las preferencias. Cuando el mecanismo está diseñado para la configuración actual, no importa que no funcione de manera más general. Tercero, puede generar mecanismos mejores (en términos de garantías de no manipulabilidad más sólidas y/o mejores resultados) que los mecanismos clásicos porque el mecanismo aprovecha las particularidades del entorno (la información probabilística que el diseñador tiene sobre los tipos de agentes). Dada la gran cantidad de información que las partes tienen entre sí hoy en día, es probable que este enfoque conduzca a ahorros enormes en comparación con los mecanismos clásicos, que en su mayoría ignoran esa información. Por ejemplo, imagina una empresa creando automáticamente su mecanismo de adquisiciones basado en el conocimiento estadístico sobre sus proveedores, en lugar de utilizar una subasta de adquisiciones descendente clásica. Cuarto, la carga del diseño se traslada de los humanos a una máquina. Sin embargo, el diseño automatizado de mecanismos requiere que el problema de optimización del diseño del mecanismo se resuelva de nuevo para cada configuración. Por lo tanto, su complejidad computacional se convierte en un tema clave. Investigaciones previas han estudiado esta pregunta para diseñadores benevolentes que desean maximizar, por ejemplo, el bienestar social [5, 6]. En este artículo estudiamos la complejidad computacional del diseño automatizado de mecanismos en el caso de un diseñador con interés propio. Esta es una configuración importante para el diseño de mecanismos automatizados debido a la escasez de mecanismos generales en esta área, y al hecho de que en la mayoría de las configuraciones de comercio electrónico el diseñador actúa en su propio interés. También demostramos que este problema está estrechamente relacionado con un problema de diseño de subasta combinatoria óptima (maximización de ingresos) particular. El resto de este documento está organizado de la siguiente manera. En la Sección 2, justificamos el enfoque en mecanismos no manipulables. En la Sección 3, definimos el problema que estudiamos. En la Sección 4, demostramos que diseñar un mecanismo determinista óptimo es NP-completo incluso cuando al diseñador solo le importan los pagos que recibe. En la Sección 5, demostramos que diseñar un mecanismo determinista óptimo también es NP-completo cuando los pagos no son posibles y el diseñador solo está interesado en el resultado elegido. En la Sección 6, demostramos que un mecanismo óptimo aleatorizado puede ser diseñado en tiempo polinómico incluso en el caso general. Finalmente, en la Sección 7, demostramos que para diseñar subastas combinatorias óptimas bajo preferencias de mejor opción solamente, nuestros resultados sobre AMD implican que este problema es NP-completo para subastas determinísticas, pero sencillo para subastas aleatorias. 2. JUSTIFICANDO EL ENFOQUE EN MECANISMOS NO MANIPULABLES Antes de definir el problema computacional del diseño automatizado de mecanismos, debemos justificar nuestro enfoque en mecanismos no manipulables. Después de todo, no es inmediatamente obvio que no haya mecanismos manipulables que, incluso cuando los agentes informan estratégicamente sus tipos y, por lo tanto, a veces de manera no veraz, aún logren mejores resultados (según el objetivo que usemos) que cualquier mecanismo no manipulable. Sin embargo, resulta ser el caso que, dado cualquier mecanismo, podemos construir un mecanismo no manipulable cuyo rendimiento es idéntico, de la siguiente manera. Construimos una capa de interfaz entre los agentes y el mecanismo original. Los agentes informan sus preferencias (o tipos) a la capa de interfaz; posteriormente, la capa de interfaz introduce en el mecanismo original los tipos que los agentes habrían informado estratégicamente al mecanismo original, si sus tipos fueran los declarados a la capa de interfaz. El resultado resultante es el resultado del nuevo mecanismo. Dado que la capa de interfaz actúa estratégicamente en nombre de cada agente, nunca hay un incentivo para informar falsamente a la capa de interfaz; por lo tanto, los tipos informados por la capa de interfaz son los tipos estratégicos que se habrían informado sin la capa de interfaz, por lo que los resultados son exactamente como habrían sido con el mecanismo original. Este argumento es conocido en la literatura de diseño de mecanismos como el principio de revelación [16]. (Existen dificultades computacionales al aplicar el principio de revelación en espacios de resultados y tipos combinatorios grandes [7, 22]). Sin embargo, dado que aquí nos enfocamos en espacios de resultados y tipos representados de forma plana, esto no es una preocupación aquí. Dado esto, podemos centrarnos en mecanismos veraces en el resto del documento. 3. DEFINICIONES Ahora formalizamos el entorno del diseño automatizado de mecanismos. Definición 1. En un entorno de diseño de mecanismos automatizados, se nos proporciona: • un conjunto finito de resultados O; • un conjunto finito de N agentes; • para cada agente i, 1. un conjunto finito de tipos Θi, 2. una distribución de probabilidad γi sobre Θi (en el caso de tipos correlacionados, hay una única distribución conjunta γ sobre Θ1 × . . . × ΘN), y 3. una función de utilidad ui: Θi × O → R; 1 • Una función objetivo cuya expectativa el diseñador desea maximizar. Existen muchas posibles funciones objetivo que el diseñador podría tener, por ejemplo, el bienestar social (donde el diseñador busca maximizar la suma de las utilidades de los agentes), o la utilidad mínima de cualquier agente (donde el diseñador busca maximizar la peor utilidad experimentada por cualquier agente). En ambos casos, el diseñador es benevolente, ya que, de alguna manera, el diseñador está buscando la felicidad colectiva de los agentes. Sin embargo, en este documento nos enfocamos en el caso de un diseñador interesado en sí mismo. Un diseñador egoísta solo se preocupa por el resultado elegido (es decir, al diseñador no le importa cómo se relaciona el resultado con las preferencias de los agentes, sino que tiene una preferencia fija sobre los resultados) y sobre los pagos netos realizados por los agentes, que fluyen hacia el diseñador. Definición 2. Un diseñador interesado tiene una función objetivo dada por g(o) + Σ i=1 πi, donde g : O → R indica las preferencias del diseñador sobre los resultados, y πi es el pago realizado por el agente i. En el caso en que g = 0 en todas partes, se dice que el diseñador está maximizando el pago. En el caso en que los pagos no sean posibles, g constituye la función objetivo por sí sola. Ahora definimos los tipos de mecanismos en estudio. Por el principio de revelación, podemos restringir la atención a mecanismos de revelación directa y veraz, donde los agentes informan directamente sus tipos y nunca tienen incentivos para informarlos de manera incorrecta. Definición 3. Consideramos los siguientes tipos de mecanismos: • Un mecanismo determinista sin pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O. • Un mecanismo aleatorio sin pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), donde P(O) es el conjunto de distribuciones de probabilidad sobre O. • Un mecanismo determinista con pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O y, para cada agente i, una función de selección de pagos πi: Θ1 × Θ2 × . . . × ΘN → R, donde πi(θ1, . . . , θN ) da el pago realizado por el agente i cuando los tipos reportados son θ1, . . . , θN. Aunque esto sigue la notación estándar de la teoría de juegos [16], el hecho de que el agente tenga tanto una función de utilidad como un tipo puede resultar confuso. Los tipos codifican las diversas preferencias posibles que el agente pueda tener, y el tipo de los agentes no es conocido por el agregador. La función de utilidad es un conocimiento común, pero debido a que el tipo de agente es un parámetro en la función de utilidad de los agentes, el agregador no puede saber cuál es la utilidad de los agentes sin conocer el tipo de agente. Un mecanismo aleatorio con pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), y para cada agente i, una función de selección de pago πi: Θ1 × Θ2 × . . . × ΘN → R. Hay dos tipos de restricciones para el diseñador al construir el mecanismo. 3.1 Restricciones de racionalidad individual (IR) El primer tipo de restricción es el siguiente. La utilidad de cada agente debe ser al menos tan grande como la utilidad de respaldo de los agentes, es decir, la utilidad que el agente recibiría si no participara en el mecanismo. De lo contrario, ese agente no participaría en el mecanismo, y la participación de ningún agente puede perjudicar el objetivo de los diseñadores del mecanismo, ya que en el peor de los casos, el mecanismo puede ignorar a un agente fingiendo que el agente no está presente. (Además, si no se aplicara tal restricción, el diseñador simplemente podría hacer que los agentes paguen una cantidad infinita). Este tipo de restricción se llama restricción de IR (racionalidad individual). Existen tres posibles restricciones de IR diferentes: ex ante, ex interim y ex post, dependiendo de lo que el agente sabe sobre su propio tipo y los tipos de los demás al decidir si participar en el mecanismo. Ex ante IR significa que el agente participaría si no supiera absolutamente nada (ni siquiera su propio tipo). No estudiaremos este concepto en este documento. Ex interim IR significa que el agente siempre participaría si conociera solo su propio tipo, pero no el de los demás. Ex post IR significa que el agente siempre participaría incluso si conociera el tipo de todos. Definiremos formalmente las dos últimas nociones de IR. Primero, necesitamos formalizar el concepto del resultado de respaldo. Suponemos que la utilidad de respaldo de cada agente es cero para cada uno de sus tipos. Esto se hace sin pérdida de generalidad porque podemos agregar un término constante a la función de utilidad de un agente (para un tipo dado), sin afectar el comportamiento de toma de decisiones de ese agente maximizador de utilidad esperada [16]. Definición 4. En cualquier entorno de diseño de mecanismos automatizados con una restricción de IR, existe un resultado de contingencia o0 ∈ O donde, para cualquier agente i y cualquier tipo θi ∈ Θi, tenemos ui(θi, o0) = 0. (Además, en el caso de un diseñador egoísta, g(o0) = 0). Ahora podemos definir las nociones de racionalidad individual. Definición 5. La racionalidad individual (RI) se define como: • Un mecanismo determinista es ex interim RI si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0. Un mecanismo aleatorio es ex interim IR si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • Un mecanismo determinista es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 No aleatorizamos sobre los pagos porque mientras los agentes y el diseñador sean neutrales al riesgo con respecto a los pagos, es decir, su utilidad es lineal en los pagos, no hay razón para aleatorizar sobre los pagos. Un mecanismo aleatorio es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 3.2 Restricciones de compatibilidad de incentivos (IC) El segundo tipo de restricción establece que los agentes nunca deben tener un incentivo para informar incorrectamente su tipo (como se justificó anteriormente mediante el principio de revelación). Para este tipo de restricción, las dos variantes más comunes (o conceptos de solución) son la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash. Definición 6. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en estrategias dominantes si decir la verdad siempre es óptimo incluso cuando los tipos reportados por los otros agentes ya son conocidos. Formalmente, para cualquier agente i, cualquier vector de tipos (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ). En el caso de mecanismos aleatorios tenemos Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. Por lo tanto, en la implementación de estrategias dominantes, decir la verdad es óptimo independientemente de lo que informen los otros agentes. Si es óptimo solo dado que los otros agentes son veraces, y dado que uno no conoce los tipos de los otros agentes, tenemos implementación en equilibrio de Bayes-Nash. Definición 7. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en equilibrio de Bayes-Nash si decir la verdad siempre es óptimo para un agente cuando ese agente aún no sabe nada sobre los tipos de los otros agentes, y los otros agentes están diciendo la verdad. Formalmente, para cualquier agente i, cualquier tipo θi ∈ Θi, y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )]. En el caso de mecanismos aleatorios tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 135 3.3 Diseño de mecanismos automatizados Ahora podemos definir el problema computacional que estudiamos. Definición 8. (DISEÑO DE MECANISMOS AUTOMATIZADOS (AMD)) Se nos da: • un entorno de diseño de mecanismos automatizados, • una noción de IR (ex interim, ex post, o ninguna), • un concepto de solución (estrategias dominantes o Bayes-Nash), • si los pagos son posibles, • si la aleatorización es posible, • (en la variante de decisión del problema) un valor objetivo G. Se nos pregunta si existe un mecanismo del tipo especificado (en términos de pagos y aleatorización) que satisfaga tanto la noción de IR como el concepto de solución, y proporcione un valor esperado de al menos G para el objetivo. Un caso especial interesante es aquel en el que solo hay un agente. En este caso, el agente informante siempre sabe todo lo que hay que saber sobre los otros tipos de agentes, porque no hay otros agentes. Dado que el IR ex post y el IR ex interim solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de IR coinciden aquí. Además, dado que la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de solución coinciden aquí. Esta observación resultará ser una herramienta útil para demostrar resultados de dificultad: si demostramos dificultad computacional en el escenario de un solo agente, esto implica inmediatamente dificultad para ambos conceptos de IR, para ambos conceptos de solución, para cualquier número de agentes. 4. En esta sección demostramos que es NP-completo diseñar un mecanismo determinístico que maximice la suma esperada de los pagos recolectados de los agentes. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Para demostrar la NP-dureza, reducimos desde el problema MINSAT. Definición 9 (MINSAT). Se nos da una fórmula φ en forma normal conjuntiva, representada por un conjunto de variables booleanas V y un conjunto de cláusulas C, y un entero K (K < |C|). Se nos pregunta si existe una asignación a las variables en V tal que se satisfacen a lo sumo K cláusulas en φ. MINSAT fue recientemente demostrado como NP-completo [14]. Ahora podemos presentar nuestro resultado. Teorema 1. El problema determinista de maximización de pagos de AMD es NP-completo, incluso para un solo agente, incluso con una distribución uniforme de tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista de maximización de pagos de un solo agente. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V } ∪ {−v : v ∈ V }. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Sea l ∈ c denota que el literal l ocurre en la cláusula c. Entonces, la función de utilidad de los agentes está dada por u(θc, ol) = |Θ| + 1 para todo l ∈ L con l ∈ c; u(θc, ol) = 0 para todo l ∈ L con l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc) = 0 para todo c ∈ C con c = c; u(θv, ol) = |Θ| para todo l ∈ L con v(l) = v; u(θv, ol) = 0 para todo l ∈ L con v(l) = v; u(θv, oc) = 0 para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ|, donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v) y π(θv) = |Θ|. Para cada c ∈ C, sea o(θc) = oc; sea π(θc) = |Θ| + 1 si c no está satisfecha en la solución MINSAT, y π(θc) = |Θ| si c está satisfecha. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es θv, entonces cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivo para informar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Porque además, ningún tipo que no sea θc conduce al resultado oc, informar cualquier otro tipo dará como resultado una utilidad de 0, mientras que aún se requiere un pago de al menos |Θ| por parte del agente. Claramente, el agente está mejor reportando honestamente, para una utilidad total de 0. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), el pago esperado de este mecanismo es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o y una función de pago π. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. Entonces, la utilidad que el agente obtiene del resultado dado para este tipo es 0, y por lo tanto, según la IR, no se puede extraer ningún pago del agente para este tipo. Dado que, nuevamente por IR, el pago máximo que se puede extraer para cualquier otro tipo es |Θ| + 1, se sigue que el pago esperado máximo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo cual contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o−v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por la restricción de IR, el pago máximo que podemos extraer de cualquier tipo θv es |Θ|. Dado que no puede haber incentivos para que el agente informe falsamente, para cualquier cláusula c satisfecha por la asignación dada, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ|. (Pues si extrajéramos más de este tipo, la utilidad del agente en este caso sería menor que 1; y si v es la variable que satisface c en la asignación, de modo que o(θv) = ol donde l ocurre en c, entonces al agente le convendría más informar θv en lugar del informe veraz θc, para obtener un resultado que valga |Θ|+1 para él mientras tiene que pagar como máximo |Θ|.) Finalmente, para cualquier cláusula insatisfecha c, según la restricción de IR, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ| + 1. Se deduce que el pago esperado de nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia de MINSAT. Dado que AMD, que maximiza el pago, es solo un caso especial de AMD para un diseñador egoísta en el que el diseñador no tiene preferencias sobre el resultado elegido, esto implica inmediatamente dificultades para el caso general de AMD para un diseñador egoísta en el que los pagos son posibles. Sin embargo, esto aún no implica dureza para el caso especial donde los pagos no son posibles. Demostraremos la dificultad en este caso en la próxima sección. 5. En esta sección demostramos que es NP-completo diseñar un mecanismo determinista que maximice la expectativa del objetivo del diseñador cuando no son posibles los pagos. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Teorema 2. Sin pagos, el diseño determinista de AMD para un diseñador egoísta es NP-completo, incluso para un solo agente, incluso con una distribución uniforme sobre los tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista auto-interesada de un solo agente sin pagos. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L} ∪ {o∗}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V} ∪ {−v : v ∈ V}. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Deje que l ∈ c denote que el literal l ocurre en la cláusula c. Luego, deje que la función de utilidad de los agentes esté dada por u(θc, ol) = 2 para todo l ∈ L con l ∈ c; u(θc, ol) = −1 para todo l ∈ L con l /∈ c; u(θc, oc) = 2; u(θc, oc) = −1 para todo c ∈ C con c = c; u(θc, o∗) = 1; u(θv, ol) = 1 para todo l ∈ L con v(l) = v; u(θv, ol) = −1 para todo l ∈ L con v(l) = v; u(θv, oc) = −1 para todo c ∈ C; u(θv, o∗) = −1. Que la función objetivo de los diseñadores esté dada por g(o∗ ) = |Θ|+1; g(ol) = |Θ| para todo l ∈ L; g(oc) = |Θ| para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ| , donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v). Para cada c ∈ C que se cumpla en la solución MINSAT, sea o(θc) = oc; para cada c ∈ C no satisfecho, sea o(θc) = o∗. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es algún θv, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para reportar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Debido a que tampoco ningún tipo conduce al resultado oc, no hay ningún resultado que el mecanismo seleccione que le daría al agente una utilidad mayor a 1 para el tipo θc, y por lo tanto el agente no tiene incentivo para informar falsamente. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), entonces el valor esperado de la función objetivo de los diseñadores es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. El único otro resultado que el mecanismo puede elegir bajo la restricción de IR es o0. Esto tiene un valor objetivo de 0, y dado que el valor más alto que la función objetivo alcanza es |Θ| + 1, se sigue que el valor esperado máximo de la función objetivo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo que contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o-v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por lo anterior, para cualquier tipo θv, el valor de la función objetivo en este mecanismo será |Θ|. Para cualquier cláusula c satisfecha por la asignación dada, el valor de la función objetivo en el caso en que el agente informe el tipo θc será como máximo |Θ|. (Esto se debe a que no podemos elegir el resultado o∗ para dicho tipo, ya que en este caso el agente tendría un incentivo para informar θv en su lugar, donde v es la variable que satisface c en la asignación (de modo que o(θv) = ol donde l ocurre en c).) Finalmente, para cualquier cláusula insatisfecha c, el valor máximo que la función objetivo puede alcanzar en el caso en que el agente informa el tipo θc es |Θ| + 1, simplemente porque este es el valor más grande que la función alcanza en cualquier momento. Se deduce que el valor esperado de la función objetivo para nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas 137 satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia MINSAT. Ambos de nuestros resultados de dureza se basaron en la restricción de que el mecanismo debería ser determinista. En la siguiente sección, mostramos que la dificultad del diseño desaparece cuando permitimos la aleatorización en el mecanismo. 6. La aleatorización de AMD para un diseñador interesado en sí mismo es fácil. Ahora mostramos cómo permitir la aleatorización sobre los resultados hace que el problema de AMD auto-interesado sea manejable a través de la programación lineal, para cualquier número constante de agentes. Teorema 3. El AMD aleatorio con interés propio con un número constante de agentes es resoluble en tiempo polinómico mediante programación lineal, tanto con pagos como sin pagos, tanto para IR ex post como ex interim, y tanto para la implementación en estrategias dominantes como para la implementación en equilibrio de Bayes-Nash, incluso si los tipos están correlacionados. Prueba. Dado que los programas lineales pueden resolverse en tiempo polinómico [13], todo lo que necesitamos demostrar es que el número de variables y ecuaciones en nuestro programa es polinomial para cualquier número constante de agentes, es decir, exponencial solo en N. En todo momento, para determinar el tamaño del programa lineal, consideremos T = maxi{|Θi|}. Las variables de nuestro programa lineal serán las probabilidades (p(θ1, θ2, . . . , θN ))(o) (como máximo TN |O| variables) y los pagos πi(θ1, θ2, . . . , θN ) (como máximo NTN variables). (Mostramos el programa lineal para el caso en que los pagos son posibles; el caso sin pagos se obtiene fácilmente de esto simplemente omitiendo todas las variables de pago en el programa, o agregando restricciones adicionales que obliguen a los pagos a ser 0). Primero, mostramos las restricciones de IR. Para el IR ex post, agregamos las siguientes restricciones (como máximo NTN) al LP: • Para cada i ∈ {1, 2, . . . , N}, y para cada (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , agregamos ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0. Para el ex interino IR, agregamos las siguientes restricciones (como máximo NT) al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada θi ∈ Θi, agregamos θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0. Ahora, mostramos las restricciones del concepto de solución. Para la implementación en estrategias dominantes, agregamos las siguientes (a lo sumo NTN+1) restricciones al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ). Finalmente, para la implementación en el equilibrio de Bayes-Nash, agregamos las siguientes (a lo sumo NT2) restricciones al LP: • Para cada i ∈ {1, 2, ..., N}, para cada θi ∈ Θi, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )). Todo lo que queda por hacer es dar la expresión que el diseñador busca maximizar, que es: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )). Como indicamos, el número de variables y restricciones es exponencial solo en N, por lo tanto, el programa lineal tiene un tamaño polinómico para un número constante de agentes. Por lo tanto, el problema es resoluble en tiempo polinómico. IMPLICACIONES PARA UN PROBLEMA DE DISEÑO DE SUBASTA COMBINATORIA ÓPTIMA En esta sección, demostraremos algunas consecuencias interesantes del problema de diseño de mecanismos automatizados para un diseñador interesado en sí mismo en el diseño de subastas combinatorias óptimas. Considera una subasta combinatoria con un conjunto S de artículos en venta. Para cualquier conjunto B ⊆ S, dejemos que ui(θi, B) sea la utilidad del postor i al recibir el conjunto B cuando el tipo del postor es θi. El problema de diseño de subasta óptima consiste en especificar las reglas de la subasta de manera que se maximice los ingresos esperados para el subastador. (Por el principio de revelación, sin pérdida de generalidad, podemos asumir que la subasta es veraz). El problema de diseño de subasta óptima se resuelve para el caso de un solo artículo mediante la famosa subasta de Myerson [18]. Sin embargo, el diseño de subastas óptimas en subastas combinatorias es un problema de investigación abierto reconocido [3, 25]. El problema está abierto incluso si solo hay dos artículos en venta. (El caso de dos artículos con una forma muy especial de complementariedad y sin sustituibilidad ha sido resuelto recientemente [1].) Supongamos que tenemos disposición libre: los artículos pueden ser desechados sin costo alguno. Además, supongamos que las preferencias de los postores tienen la siguiente estructura: cuando un postor recibe un conjunto de artículos, la utilidad del postor por ese conjunto está determinada únicamente por el mejor artículo en el conjunto. (Enfatizamos que qué artículo es el mejor puede depender del tipo de postor). Definición 10. Se dice que el postor i tiene preferencias solo por lo mejor sobre paquetes de artículos si existe una función vi: Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s). Hacemos la siguiente observación útil en este contexto: no tiene sentido otorgarle a un postor más de un artículo. La razón es que si el postor está informando honestamente, quitarle todos los artículos menos el de mayor valor no perjudicará al postor; y, mediante la disposición gratuita, hacerlo solo reducirá el incentivo para que este postor informe falsamente este tipo, cuando en realidad tiene otro tipo. Ahora demostramos que el problema de diseñar una subasta óptima determinista es NP-completo, mediante una reducción del problema AMD de maximización de pagos. Teorema 4. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de artículos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), diseñar la subasta determinística óptima es NP-completo, incluso para un único postor con una distribución uniforme sobre los tipos. Prueba. El problema está en NP porque podemos generar de manera no determinista una regla de asignación, y luego establecer los pagos utilizando programación lineal. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de AMD determinista que maximiza el pago, con un único agente y una distribución uniforme de tipos, al siguiente problema de diseño de subasta combinatoria óptima con una única postor con preferencias de solo los mejores. Para cada resultado o ∈ O en la instancia de AMD (excepto el resultado o0), que haya un artículo so ∈ S. Que el espacio de tipos sea el mismo, y que v(θi, so) = ui(θi, o) (donde u está especificado en la instancia de AMD). Que el valor objetivo de ingresos esperados sea el mismo en ambas instancias. Mostramos que las instancias son equivalentes. Primero supongamos que existe una solución para la instancia de AMD, dada por una función de resultado y una función de pago. Entonces, si la solución de AMD elige el resultado o para un tipo, en la solución de subasta óptima, asignamos {so} al postor para este tipo. (A menos que o = o0, en cuyo caso asignamos {} al postor). Que las funciones de pago sean las mismas en ambas instancias. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo verdadero) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución óptima de la subasta. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el subastador/diseñador son los mismos. Se deduce que existe una solución para la instancia de diseño de subasta óptima. Ahora supongamos que existe una solución para la instancia de diseño de subasta óptima. Por la observación de que como máximo se puede tener un artículo, podemos asumir sin pérdida de generalidad que la solución nunca asigna más de un artículo. Entonces, si la solución de subasta óptima asigna el artículo al postor para un tipo, en la solución de AMD, permita que el mecanismo elija el resultado o para ese tipo. Si la solución de subasta óptima no asigna nada al postor para un tipo, en la solución AMD, permita que el mecanismo elija el resultado o0 para ese tipo. Que las funciones de pago sean las mismas. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo real) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución AMD. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el diseñador/subastador son los mismos. Se deduce que existe una solución para la instancia de AMD. Afortunadamente, también podemos extender el resultado de facilidad para mecanismos aleatorios a este escenario de subasta combinatoria, lo que nos proporciona uno de los pocos algoritmos de tiempo polinómico conocidos para un problema de diseño óptimo de subasta combinatoria. Teorema 5. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de elementos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), si el número de postores es una constante k, entonces la subasta aleatoria óptima puede ser diseñada en tiempo polinómico. (Para cualquier restricción de IC e IR.) Prueba. Por la observación de que a lo sumo un artículo, podemos sin pérdida de generalidad restringirnos a asignaciones donde cada postor recibe como máximo un artículo. Hay menos de (|S| + 1)k asignaciones de ese tipo, es decir, un número polinómico de asignaciones. Dado que podemos enumerar explícitamente los resultados, simplemente podemos resolver esto como una instancia de AMD que maximiza el pago, con programación lineal. 8. Investigaciones relacionadas sobre la complejidad en el diseño de mecanismos. Ha habido un considerable interés reciente en el diseño de mecanismos en la informática. Parte de ello se ha centrado en cuestiones de complejidad computacional, pero la mayor parte de ese trabajo ha buscado diseñar mecanismos que sean fáciles de ejecutar (por ejemplo, [20, 15, 19, 9, 12]), en lugar de estudiar la complejidad de diseñar el mecanismo. La pieza más cercana de trabajo anterior estudió la complejidad del diseño automatizado de mecanismos por un diseñador benevolente [5, 6]. Roughgarden ha estudiado la complejidad de diseñar una buena topología de red para agentes que eligen egoístamente los enlaces que utilizan [21]. Esto está relacionado con el diseño de mecanismos, pero difiere significativamente en que el diseñador solo tiene un control restringido sobre las reglas del juego porque no hay ninguna parte que pueda imponer el resultado (o pagos laterales). Además, no hay un informe explícito de preferencias. 9. CONCLUSIONES E INVESTIGACIONES FUTURAS A menudo, un resultado debe ser elegido en función de las preferencias informadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les sea más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente emergente llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración específica de agregación de preferencias en cuestión. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo, un entorno mucho más relevante para el comercio electrónico. En este contexto, al centro solo le importa qué resultado se elige y qué pagos se le realizan. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este escenario, demostramos que diseñar un mecanismo determinista óptimo es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Estos resultados de dureza implican dificultad en todos los entornos de diseño de mecanismos automatizados más generales con un diseñador egoísta. Los resultados de dureza se aplican ya sea que las restricciones de racionalidad individual (participación) se apliquen ex interim o ex post, y ya sea que el concepto de solución sea la implementación de estrategias dominantes o la implementación del equilibrio de Bayes-Nash. Luego demostramos que permitir la aleatorización en el mecanismo hace que el problema de diseño en todos estos escenarios sea computacionalmente sencillo. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (que maximiza los ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar un mecanismo determinístico óptimo es NP-completo incluso con un agente, pero diseñar un mecanismo aleatorio óptimo es fácil. La investigación futura incluye estudiar el diseño automatizado de mecanismos con un diseñador interesado en sí mismo en entornos más restringidos, como subastas (donde el objetivo del diseñador puede incluir preferencias sobre qué postor debería recibir el bien, así como los pagos). También queremos estudiar la complejidad del diseño de mecanismos automatizados en entornos donde los espacios de resultados y tipos tienen una estructura especial para que puedan representarse de manera más concisa. Finalmente, planeamos reunir un conjunto de datos de problemas de diseño de mecanismos del mundo real, tanto históricos como actuales, y aplicar el diseño de mecanismos automatizado a esos problemas. 10. REFERENCIAS [1] M. Armstrong. Subastas multi-objetivo óptimas. Revisión de Estudios Económicos, 67:455-481, 2000. [2] K. Arrow. La doctrina de los derechos de propiedad y la revelación de la demanda bajo información incompleta. En M. Boskin, editor, Economía y bienestar humano. New York Academic Press, 1979. [3] C. Avery y T. Hendershott. Agrupación y subastas óptimas de múltiples productos. Revisión de Estudios Económicos, 67:483-497, 2000. [4] E. H. Clarke. Precios escalonados de bienes públicos. Elección Pública, 11:17-33, 1971. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Actas de la 18ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI-02), páginas 103-110, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Diseño de mecanismos automatizados: Resultados de complejidad derivados del entorno de un solo agente. En Actas de la 5ta Conferencia Internacional de Comercio Electrónico (ICEC-03), páginas 17-24, Pittsburgh, PA, EE. UU., 2003. [7] V. Conitzer y T. Sandholm. Críticas computacionales del principio de revelación. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), Nueva York, NY, 2004. Breve ensayo. La versión completa apareció en el taller AAMAS-03 sobre Comercio Electrónico Mediado por Agentes (AMEC). [8] C. d'Aspremont y L. A. Gérard-Varet. Incentivos e información incompleta. Revista de Economía Pública, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou y S. Shenker. Compartiendo el costo de las transmisiones de multidifusión. Revista de Ciencias de la Computación y de Sistemas, 63:21-41, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 2000. [10] A. Gibbard. Manipulación de esquemas de votación. Econometrica, 41:587-602, 1973. [11] T. Groves.\nEconometrica, 41:587-602, 1973. [11] T. Groves. Incentivos en equipos. Econometrica, 41:617-631, 1973. [12] J. Hershberger y S. Suri. Precios de Vickrey y caminos más cortos: ¿Cuánto vale una arista? En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [13] L. Khachiyan. Un algoritmo polinómico en programación lineal. Matemática soviética. Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi y P. Mirchandani. El problema de satisfacibilidad mínimo. Revista SIAM de Matemáticas Discretas, 7(2):275-283, 1994. [15] D. Lehmann, L. I. O'Callaghan y Y. Shoham. Revelación de la verdad en subastas combinatorias rápidas y aproximadamente eficientes. Revista de la ACM, 49(5):577-602, 2002. La versión inicial apareció en las Actas de la Conferencia de Comercio Electrónico de la ACM (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [17] E. S. Maskin y J. Riley. Subastas multiunidad óptimas. En F. Hahn, editor, \"La economía de los mercados faltantes, la información y los juegos\", capítulo 14, páginas 312-335. Clarendon Press, Oxford, 1989. [18] R. Myerson.\nPrensa Clarendon, Oxford, 1989. [18] R. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6:58-73, 1981. [19] N. Nisan y A. Ronen. Mecanismos VCG computacionalmente factibles. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 242-252, Minneapolis, MN, 2000. [20] N. Nisan y A. Ronen. Diseño de mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166-196, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 1999. [21] T. Roughgarden. Diseñar redes para usuarios egoístas es difícil. En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [22] T. Sandholm. Problemas en subastas computacionales de Vickrey. Revista Internacional de Comercio Electrónico, 4(3):107-129, 2000. Número especial sobre la Aplicación de Agentes Inteligentes para el Comercio Electrónico. Una versión corta y temprana apareció en la Segunda Conferencia Internacional sobre Sistemas Multiagente (ICMAS), páginas 299-306, 1996. [23] M. A. Satterthwaite. In Spanish, the translation would be: \"Inmutabilidad estratégica y condiciones de Arrow: teoremas de existencia y correspondencia para procedimientos de votación y funciones de bienestar social.\" Revista de Teoría Económica, 10:187-217, 1975. [24] W. Vickrey. Contrarrestando la especulación, subastas y ofertas selladas competitivas. Revista de Finanzas, 16:8-37, 1961. [25] R. V. Vohra. Problemas de investigación en subastas combinatorias. Mimeo, versión 29 de octubre de 2001. 141 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "preference aggregator": {
            "translated_key": "agregador de preferencias",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-interested Automated Mechanism Design and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently proposed approach-called automated mechanism design-a mechanism is computed for the preference aggregation setting at hand.",
                "This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike the earlier work on automated mechanism design that studied a benevolent designer, in this paper we study automated mechanism design problems where the designer is self-interested.",
                "In this case, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy.",
                "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy.",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc.",
                "The <br>preference aggregator</br> generally does not know the agents preferences a priori.",
                "Rather, the agents report their preferences to the coordinator.",
                "Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully.",
                "Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen.",
                "Manipulability is a pervasive problem across preference aggregation mechanisms.",
                "A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.)",
                "What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective.",
                "This is the classic setting of mechanism design in game theory.",
                "In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself.",
                "This is the mechanism design setting most relevant to electronic commerce.",
                "In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear.",
                "It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences.",
                "The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments.",
                "The most common such constraint is that of individual rationality (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
                "For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences.",
                "Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it.",
                "Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off.",
                "On the other hand, the designer will not necessarily choose a social welfare maximizing outcome.",
                "For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected.",
                "Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0.",
                "Classical mechanism design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective.",
                "The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]).",
                "However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare.",
                "If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization.",
                "In practice, the designer may also be interested in the outcome per se.",
                "For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical.",
                "For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed.",
                "Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments.",
                "In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand.",
                "This approach addresses all of the downsides listed above.",
                "We formulate the mechanism design problem as an optimization problem.",
                "The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types.",
                "The output is a nonmanipulable mechanism that is optimal with respect to some objective.",
                "This approach is called automated mechanism design.",
                "The automated mechanism design approach has four advantages over the classical approach of designing general mechanisms.",
                "First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare).",
                "Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences.",
                "When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally.",
                "Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types).",
                "Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information.",
                "For example, imagine a company automatically creating its procurement mechanism based on statistical knowledge about its suppliers, rather than using a classical descending procurement auction.",
                "Fourth, the burden of design is shifted from humans to a machine.",
                "However, automated mechanism design requires the mechanism design optimization problem to be solved anew for each setting.",
                "Hence its computational complexity becomes a key issue.",
                "Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6].",
                "In this paper we study the computational complexity of automated mechanism design in the case of a self-interested designer.",
                "This is an important setting for automated mechanism design due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested.",
                "We also show that this problem is closely related to a particular optimal (revenue-maximizing) combinatorial auction design problem. 133 The rest of this paper is organized as follows.",
                "In Section 2, we justify the focus on nonmanipulable mechanisms.",
                "In Section 3, we define the problem we study.",
                "In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it.",
                "In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen.",
                "In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case.",
                "Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2.",
                "JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of automated mechanism design, we should justify our focus on nonmanipulable mechanisms.",
                "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any nonmanipulable mechanism.",
                "This does, however, turn out to be the case: given any mechanism, we can construct a nonmanipulable mechanism whose performance is identical, as follows.",
                "We build an interface layer between the agents and the original mechanism.",
                "The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer.",
                "The resulting outcome is the outcome of the new mechanism.",
                "Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism.",
                "This argument is known in the mechanism design literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22].",
                "However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.)",
                "Given this, we can focus on truthful mechanisms in the rest of the paper. 3.",
                "DEFINITIONS We now formalize the automated mechanism design setting.",
                "Definition 1.",
                "In an automated mechanism design setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize.",
                "There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent).",
                "In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness.",
                "However, in this paper, we focus on the case of a self-interested designer.",
                "A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer.",
                "Definition 2.",
                "A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i.",
                "In the case where g = 0 everywhere, the designer is said to be payment maximizing.",
                "In the case where payments are not possible, g constitutes the objective function by itself.",
                "We now define the kinds of mechanisms under study.",
                "By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them.",
                "Definition 3.",
                "We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing.",
                "The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator.",
                "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 Individual rationality (IR) constraints The first type of constraint is the following.",
                "The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism.",
                "Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.)",
                "This type of constraint is called an IR (individual rationality) constraint.",
                "There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism.",
                "Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type).",
                "We will not study this concept in this paper.",
                "Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others.",
                "Ex post IR means that the agent would always participate even if it knew everybodys type.",
                "We will define the latter two notions of IR formally.",
                "First, we need to formalize the concept of the fallback outcome.",
                "We assume that each agents fallback utility is zero for each one of its types.",
                "This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16].",
                "Definition 4.",
                "In any automated mechanism design setting with an IR constraint, there is a fallback outcome o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)",
                "We can now to define the notions of individual rationality.",
                "Definition 5.",
                "Individual rationality (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
                "A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments.",
                "A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
                "The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle).",
                "For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium.",
                "Definition 6.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known.",
                "Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
                "In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible.",
                "Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report.",
                "If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium.",
                "Definition 7.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth.",
                "Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible. 135 3.3 Automated mechanism design We can now define the computational problem we study.",
                "Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an automated mechanism design setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective.",
                "An interesting special case is the setting where there is only one agent.",
                "In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents.",
                "Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here.",
                "Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here.",
                "This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4.",
                "PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "To demonstrate NPhardness, we reduce from the MINSAT problem.",
                "Definition 9 (MINSAT).",
                "We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|).",
                "We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied.",
                "MINSAT was recently shown to be NP-complete [14].",
                "We can now present our result.",
                "Theorem 1.",
                "Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent payment-maximizing deterministic AMD instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|.",
                "For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the MINSAT solution, and π(θc) = |Θ| if c is satisfied.",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent.",
                "Clearly the agent is better off reporting truthfully, for a total utility of 0.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type.",
                "Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the IR constraint, the maximum payment we can extract from any type θv is |Θ|.",
                "Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.)",
                "Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1.",
                "It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible.",
                "However, it does not yet imply hardness for the special case where payments are not possible.",
                "We will prove hardness in this case in the next section. 5.",
                "SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "Theorem 2.",
                "Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent self-interested deterministic AMD without payments instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1.",
                "Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v).",
                "For every c ∈ C that is satisfied in the MINSAT solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ .",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "The only other outcome that the mechanism is allowed to choose under the IR constraint is o0.",
                "This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}.",
                "We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|.",
                "For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).)",
                "Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes.",
                "It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Both of our hardness results relied on the constraint that the mechanism should be deterministic.",
                "In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6.",
                "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of self-interested AMD tractable through linear programming, for any constant number of agents.",
                "Theorem 3.",
                "Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated.",
                "Proof.",
                "Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}.",
                "The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.)",
                "First, we show the IR constraints.",
                "For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
                "For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
                "Now, we show the solution concept constraints.",
                "For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
                "Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
                "All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
                "As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents.",
                "Thus the problem is solvable in polynomial time. 7.",
                "IMPLICATIONS FOR AN OPTIMAL COMBINATORIAL AUCTION DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated mechanism design for a self-interested designer on designing optimal combinatorial auctions.",
                "Consider a combinatorial auction with a set S of items for sale.",
                "For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi.",
                "The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.)",
                "The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18].",
                "However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25].",
                "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of complementarity and no substitutability has been solved recently [1].)",
                "Suppose we have free disposal-items can be thrown away at no cost.",
                "Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.)",
                "Definition 10.",
                "Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
                "We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item.",
                "The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type.",
                "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the payment maximizing AMD problem!",
                "Theorem 4.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types.",
                "Proof.",
                "The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming.",
                "To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal combinatorial auction design problem instance with a single bidder with best-only preferences.",
                "For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance).",
                "Let the expected revenue target value be the same in both instances.",
                "We show the instances are equivalent.",
                "First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function.",
                "Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.)",
                "Let the payment functions be the same in both instances.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same.",
                "It follows that there exists a solution to the optimal auction design instance.",
                "Now suppose there exists a solution to the optimal auction design instance.",
                "By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item.",
                "Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type.",
                "If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type.",
                "Let the payment functions be the same.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same.",
                "It follows that there exists a solution to the AMD instance.",
                "Fortunately, we can also carry through the easiness result for randomized mechanisms to this combinatorial auction setting-giving us one of the few known polynomial-time algorithms for an optimal combinatorial auction design problem.",
                "Theorem 5.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.)",
                "Proof.",
                "By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item.",
                "There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations.",
                "Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8.",
                "RELATED RESEARCH ON COMPLEXITY IN MECHANISM DESIGN There has been considerable recent interest in mechanism design in computer science.",
                "Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism.",
                "The closest piece of earlier work studied the complexity of automated mechanism design by a benevolent designer [5, 6].",
                "Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21].",
                "This is related to mechanism design, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments).",
                "Also, there is no explicit reporting of preferences. 9.",
                "CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently emerging approach-called automated mechanism design-a mechanism is computed for the specific preference aggregation setting at hand.",
                "This has several advantages, 139 but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike earlier work on automated mechanism design that studied a benevolent designer, in this paper we studied automated mechanism design problems where the designer is self-interesteda setting much more relevant for electronic commerce.",
                "In this setting, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "These hardness results imply hardness in all more general automated mechanism design settings with a self-interested designer.",
                "The hardness results apply whether the individual rationality (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation.",
                "We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy.",
                "Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy.",
                "Future research includes studying automated mechanism design with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments).",
                "We also want to study the complexity of automated mechanism design in settings where the outcome and type spaces have special structure so they can be represented more concisely.",
                "Finally, we plan to assemble a data set of real-world mechanism design problems-both historical and current-and apply automated mechanism design to those problems. 10.",
                "REFERENCES [1] M. Armstrong.",
                "Optimal multi-object auctions.",
                "Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow.",
                "The property rights doctrine and demand revelation under incomplete information.",
                "In M. Boskin, editor, Economics and human welfare.",
                "New York Academic Press, 1979. [3] C. Avery and T. Hendershott.",
                "Bundling and optimal auctions of multiple products.",
                "Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke.",
                "Multipart pricing of public goods.",
                "Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Automated mechanism design: Complexity results stemming from the single-agent setting.",
                "In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm.",
                "Computational criticisms of the revelation principle.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004.",
                "Short paper.",
                "Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet.",
                "Incentives and incomplete information.",
                "Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker.",
                "Sharing the cost of muliticast transmissions.",
                "Journal of Computer and System Sciences, 63:21-41, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard.",
                "Manipulation of voting schemes.",
                "Econometrica, 41:587-602, 1973. [11] T. Groves.",
                "Incentives in teams.",
                "Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri.",
                "Vickrey prices and shortest paths: What is an edge worth?",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan.",
                "A polynomial algorithm in linear programming.",
                "Soviet Math.",
                "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani.",
                "The minimum satisfiability problem.",
                "SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham.",
                "Truth revelation in rapid, approximately efficient combinatorial auctions.",
                "Journal of the ACM, 49(5):577-602, 2002.",
                "Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [17] E. S. Maskin and J. Riley.",
                "Optimal multi-unit auctions.",
                "In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335.",
                "Clarendon Press, Oxford, 1989. [18] R. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen.",
                "Computationally feasible VCG mechanisms.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behavior, 35:166-196, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden.",
                "Designing networks for selfish users is hard.",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm.",
                "Issues in computational Vickrey auctions.",
                "International Journal of Electronic Commerce, 4(3):107-129, 2000.",
                "Special Issue on 140 Applying Intelligent Agents for Electronic Commerce.",
                "A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite.",
                "Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions.",
                "Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey.",
                "Counterspeculation, auctions, and competitive sealed tenders.",
                "Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra.",
                "Research problems in combinatorial auctions.",
                "Mimeo, version Oct. 29, 2001. 141"
            ],
            "original_annotated_samples": [
                "The <br>preference aggregator</br> generally does not know the agents preferences a priori."
            ],
            "translated_annotated_samples": [
                "El <br>agregador de preferencias</br> generalmente no conoce las preferencias de los agentes de antemano."
            ],
            "translated_text": "Diseño de mecanismos automatizados de interés propio e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les resulte más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente propuesto, llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración de agregación de preferencias actual. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre el diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo. En este caso, al centro solo le importa qué resultado se elige y qué pagos se le hacen. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este contexto, demostramos que el diseño de mecanismos deterministas óptimos es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Luego mostramos cómo permitir la aleatorización en el mecanismo hace que los problemas en este entorno sean computacionalmente fáciles. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (maximizadora de ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar una subasta determinista óptima es NP-completo, pero diseñar una subasta aleatoria óptima es fácil. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Teoría 1. En entornos multiagentes, a menudo se debe elegir un resultado en función de las preferencias informadas por un grupo de agentes. Tales resultados podrían ser presidentes potenciales, planes conjuntos, asignaciones de bienes o recursos, etc. El <br>agregador de preferencias</br> generalmente no conoce las preferencias de los agentes de antemano. Más bien, los agentes informan sus preferencias al coordinador. Desafortunadamente, un agente puede tener un incentivo para informar incorrectamente sus preferencias con el fin de engañar al mecanismo y lograr que seleccione un resultado que sea más deseable para el agente que el resultado que se seleccionaría si el agente revelara sus preferencias de manera honesta. Tal manipulación es indeseable porque los mecanismos de agregación de preferencias están diseñados para agrupar las preferencias de una manera socialmente deseable, y si los agentes revelan sus preferencias de manera insincera, se podría elegir un resultado socialmente indeseable. La manipulabilidad es un problema generalizado en los mecanismos de agregación de preferencias. Un resultado negativo seminal, el teorema de Gibbard-Satterthwaite, muestra que bajo cualquier esquema de agregación de preferencias no dictatorial, si hay al menos 3 posibles resultados, existen preferencias bajo las cuales un agente está mejor reportando falsamente [10, 23]. (Un esquema de agregación de preferencias se llama dictatorial si uno de los agentes dicta el resultado sin importar las preferencias que reporten los otros agentes). Lo que le gustaría hacer al agregador es diseñar un mecanismo de agregación de preferencias para que 1) los agentes interesados reporten sus preferencias de manera veraz, y 2) el mecanismo elija un resultado que sea deseable desde la perspectiva de algún objetivo. Esta es la configuración clásica del diseño de mecanismos en la teoría de juegos. En este documento, estudiamos el caso en el que el diseñador actúa por interés propio, es decir, al diseñador no le importa directamente cómo se relaciona el resultado con las preferencias de los agentes, sino que está más preocupado por su propia agenda sobre cuál resultado debería ser elegido y en maximizar los pagos para sí mismo. Este es el entorno de diseño de mecanismos más relevante para el comercio electrónico. En el caso en que el diseñador del mecanismo esté interesado en maximizar alguna noción de bienestar social, la importancia de recopilar las preferencias de los agentes es clara. Quizás sea menos obvio por qué deberían ser recopilados cuando el diseñador está interesado en sí mismo y, por lo tanto, su objetivo no está directamente relacionado con las preferencias de los agentes. La razón de esto es que a menudo las preferencias de los agentes imponen límites en cómo el diseñador elige el resultado y los pagos. La restricción más común de este tipo es la de racionalidad individual (RI), lo que significa que el mecanismo no puede dejar a ningún agente en una situación peor a la que hubiera estado si no hubiera participado en el mecanismo. Por ejemplo, en el contexto del diseño óptimo de subastas, el diseñador (subastador) solo se preocupa por cuántos ingresos se recaudan, y no en sí mismo por cuán bien la asignación del bien (o bienes) corresponde a las preferencias de los agentes. Sin embargo, el diseñador no puede obligar a un agente a pagar más de lo que valora el paquete de bienes asignado a él. Por lo tanto, incluso un diseñador interesado en sí mismo elegirá un resultado que beneficie razonablemente a los agentes. Por otro lado, el diseñador no necesariamente elegirá un resultado que maximice el bienestar social. Por ejemplo, si el diseñador siempre elige un resultado que maximiza el bienestar social con respecto a las preferencias informadas, y obliga a cada agente a pagar la diferencia entre la utilidad que tiene ahora y la utilidad que habría tenido si no hubiera participado en el mecanismo, es fácil ver que los agentes pueden tener un incentivo para informar incorrectamente sus preferencias, lo que puede llevar realmente a recaudar menos ingresos. De hecho, uno de los resultados contraintuitivos de la teoría del diseño de subastas óptimas es que a veces el bien se asigna a nadie incluso cuando el subastador tiene un precio de reserva de 0. El diseño de mecanismos clásicos proporciona algunos mecanismos generales, que, bajo ciertas suposiciones, satisfacen alguna noción de no manipulabilidad y maximizan algún objetivo. La ventaja de estos mecanismos es que no dependen de información (incluso probabilística) sobre las preferencias de los agentes (por ejemplo, el mecanismo de Vickrey-Clarke-Groves (VCG) [24, 4, 11]), o pueden aplicarse fácilmente a cualquier distribución de probabilidad sobre las preferencias (por ejemplo, el mecanismo dAGVA [8, 2], la subasta de Myerson [18], y la subasta multiunidad de Maskin-Riley [17]). Sin embargo, los mecanismos generales también tienen importantes desventajas: • Los mecanismos generales más famosos y ampliamente aplicables, VCG y dAGVA, solo maximizan el bienestar social. Si el diseñador está interesado en sí mismo, como es el caso en muchos entornos de comercio electrónico, estos mecanismos no maximizan el objetivo del diseñador. • Los mecanismos generales que se centran en un diseñador interesado en sí mismo solo son aplicables en entornos muy restringidos, como la subasta de maximización de ingresos esperados de Myerson para vender un solo artículo, y la subasta de maximización de ingresos esperados de Maskin y Riley para vender múltiples unidades idénticas de un artículo. • Incluso en los entornos restringidos en los que se aplican estos mecanismos, solo permiten la maximización de pagos. En la práctica, el diseñador también puede estar interesado en el resultado en sí mismo. Por ejemplo, a un subastador le puede importar qué postor recibe el artículo. • A menudo se asume que los pagos laterales pueden ser utilizados para adaptar los incentivos de los agentes, pero esto no siempre es práctico. Por ejemplo, en los mercados electrónicos basados en trueque, como Recipco, firstbarter.com, BarterOne e Intagio, no se permiten los pagos laterales. Además, entre los agentes de software, podría ser más deseable construir mecanismos que no dependan de la capacidad de realizar pagos, ya que muchos agentes de software no cuentan con la infraestructura para hacer pagos. Por el contrario, seguimos un enfoque reciente donde el mecanismo se diseña automáticamente para el problema específico en cuestión. Este enfoque aborda todos los inconvenientes mencionados anteriormente. Formulamos el problema de diseño de mecanismos como un problema de optimización. La entrada se caracteriza por el número de agentes, los posibles tipos de agentes (preferencias) y las distribuciones previas de los agregadores sobre los tipos de agentes. La salida es un mecanismo no manipulable que es óptimo con respecto a algún objetivo. Este enfoque se llama diseño de mecanismos automatizado. El enfoque de diseño de mecanismos automatizado tiene cuatro ventajas sobre el enfoque clásico de diseñar mecanismos generales. Primero, se puede utilizar incluso en entornos que no cumplen con las suposiciones de los mecanismos clásicos (como la disponibilidad de pagos laterales o que el objetivo sea el bienestar social). Segundo, puede permitir a uno eludir resultados de imposibilidad (como el teorema de Gibbard-Satterthwaite) que establecen que no existe un mecanismo que sea deseable para todas las preferencias. Cuando el mecanismo está diseñado para la configuración actual, no importa que no funcione de manera más general. Tercero, puede generar mecanismos mejores (en términos de garantías de no manipulabilidad más sólidas y/o mejores resultados) que los mecanismos clásicos porque el mecanismo aprovecha las particularidades del entorno (la información probabilística que el diseñador tiene sobre los tipos de agentes). Dada la gran cantidad de información que las partes tienen entre sí hoy en día, es probable que este enfoque conduzca a ahorros enormes en comparación con los mecanismos clásicos, que en su mayoría ignoran esa información. Por ejemplo, imagina una empresa creando automáticamente su mecanismo de adquisiciones basado en el conocimiento estadístico sobre sus proveedores, en lugar de utilizar una subasta de adquisiciones descendente clásica. Cuarto, la carga del diseño se traslada de los humanos a una máquina. Sin embargo, el diseño automatizado de mecanismos requiere que el problema de optimización del diseño del mecanismo se resuelva de nuevo para cada configuración. Por lo tanto, su complejidad computacional se convierte en un tema clave. Investigaciones previas han estudiado esta pregunta para diseñadores benevolentes que desean maximizar, por ejemplo, el bienestar social [5, 6]. En este artículo estudiamos la complejidad computacional del diseño automatizado de mecanismos en el caso de un diseñador con interés propio. Esta es una configuración importante para el diseño de mecanismos automatizados debido a la escasez de mecanismos generales en esta área, y al hecho de que en la mayoría de las configuraciones de comercio electrónico el diseñador actúa en su propio interés. También demostramos que este problema está estrechamente relacionado con un problema de diseño de subasta combinatoria óptima (maximización de ingresos) particular. El resto de este documento está organizado de la siguiente manera. En la Sección 2, justificamos el enfoque en mecanismos no manipulables. En la Sección 3, definimos el problema que estudiamos. En la Sección 4, demostramos que diseñar un mecanismo determinista óptimo es NP-completo incluso cuando al diseñador solo le importan los pagos que recibe. En la Sección 5, demostramos que diseñar un mecanismo determinista óptimo también es NP-completo cuando los pagos no son posibles y el diseñador solo está interesado en el resultado elegido. En la Sección 6, demostramos que un mecanismo óptimo aleatorizado puede ser diseñado en tiempo polinómico incluso en el caso general. Finalmente, en la Sección 7, demostramos que para diseñar subastas combinatorias óptimas bajo preferencias de mejor opción solamente, nuestros resultados sobre AMD implican que este problema es NP-completo para subastas determinísticas, pero sencillo para subastas aleatorias. 2. JUSTIFICANDO EL ENFOQUE EN MECANISMOS NO MANIPULABLES Antes de definir el problema computacional del diseño automatizado de mecanismos, debemos justificar nuestro enfoque en mecanismos no manipulables. Después de todo, no es inmediatamente obvio que no haya mecanismos manipulables que, incluso cuando los agentes informan estratégicamente sus tipos y, por lo tanto, a veces de manera no veraz, aún logren mejores resultados (según el objetivo que usemos) que cualquier mecanismo no manipulable. Sin embargo, resulta ser el caso que, dado cualquier mecanismo, podemos construir un mecanismo no manipulable cuyo rendimiento es idéntico, de la siguiente manera. Construimos una capa de interfaz entre los agentes y el mecanismo original. Los agentes informan sus preferencias (o tipos) a la capa de interfaz; posteriormente, la capa de interfaz introduce en el mecanismo original los tipos que los agentes habrían informado estratégicamente al mecanismo original, si sus tipos fueran los declarados a la capa de interfaz. El resultado resultante es el resultado del nuevo mecanismo. Dado que la capa de interfaz actúa estratégicamente en nombre de cada agente, nunca hay un incentivo para informar falsamente a la capa de interfaz; por lo tanto, los tipos informados por la capa de interfaz son los tipos estratégicos que se habrían informado sin la capa de interfaz, por lo que los resultados son exactamente como habrían sido con el mecanismo original. Este argumento es conocido en la literatura de diseño de mecanismos como el principio de revelación [16]. (Existen dificultades computacionales al aplicar el principio de revelación en espacios de resultados y tipos combinatorios grandes [7, 22]). Sin embargo, dado que aquí nos enfocamos en espacios de resultados y tipos representados de forma plana, esto no es una preocupación aquí. Dado esto, podemos centrarnos en mecanismos veraces en el resto del documento. 3. DEFINICIONES Ahora formalizamos el entorno del diseño automatizado de mecanismos. Definición 1. En un entorno de diseño de mecanismos automatizados, se nos proporciona: • un conjunto finito de resultados O; • un conjunto finito de N agentes; • para cada agente i, 1. un conjunto finito de tipos Θi, 2. una distribución de probabilidad γi sobre Θi (en el caso de tipos correlacionados, hay una única distribución conjunta γ sobre Θ1 × . . . × ΘN), y 3. una función de utilidad ui: Θi × O → R; 1 • Una función objetivo cuya expectativa el diseñador desea maximizar. Existen muchas posibles funciones objetivo que el diseñador podría tener, por ejemplo, el bienestar social (donde el diseñador busca maximizar la suma de las utilidades de los agentes), o la utilidad mínima de cualquier agente (donde el diseñador busca maximizar la peor utilidad experimentada por cualquier agente). En ambos casos, el diseñador es benevolente, ya que, de alguna manera, el diseñador está buscando la felicidad colectiva de los agentes. Sin embargo, en este documento nos enfocamos en el caso de un diseñador interesado en sí mismo. Un diseñador egoísta solo se preocupa por el resultado elegido (es decir, al diseñador no le importa cómo se relaciona el resultado con las preferencias de los agentes, sino que tiene una preferencia fija sobre los resultados) y sobre los pagos netos realizados por los agentes, que fluyen hacia el diseñador. Definición 2. Un diseñador interesado tiene una función objetivo dada por g(o) + Σ i=1 πi, donde g : O → R indica las preferencias del diseñador sobre los resultados, y πi es el pago realizado por el agente i. En el caso en que g = 0 en todas partes, se dice que el diseñador está maximizando el pago. En el caso en que los pagos no sean posibles, g constituye la función objetivo por sí sola. Ahora definimos los tipos de mecanismos en estudio. Por el principio de revelación, podemos restringir la atención a mecanismos de revelación directa y veraz, donde los agentes informan directamente sus tipos y nunca tienen incentivos para informarlos de manera incorrecta. Definición 3. Consideramos los siguientes tipos de mecanismos: • Un mecanismo determinista sin pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O. • Un mecanismo aleatorio sin pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), donde P(O) es el conjunto de distribuciones de probabilidad sobre O. • Un mecanismo determinista con pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O y, para cada agente i, una función de selección de pagos πi: Θ1 × Θ2 × . . . × ΘN → R, donde πi(θ1, . . . , θN ) da el pago realizado por el agente i cuando los tipos reportados son θ1, . . . , θN. Aunque esto sigue la notación estándar de la teoría de juegos [16], el hecho de que el agente tenga tanto una función de utilidad como un tipo puede resultar confuso. Los tipos codifican las diversas preferencias posibles que el agente pueda tener, y el tipo de los agentes no es conocido por el agregador. La función de utilidad es un conocimiento común, pero debido a que el tipo de agente es un parámetro en la función de utilidad de los agentes, el agregador no puede saber cuál es la utilidad de los agentes sin conocer el tipo de agente. Un mecanismo aleatorio con pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), y para cada agente i, una función de selección de pago πi: Θ1 × Θ2 × . . . × ΘN → R. Hay dos tipos de restricciones para el diseñador al construir el mecanismo. 3.1 Restricciones de racionalidad individual (IR) El primer tipo de restricción es el siguiente. La utilidad de cada agente debe ser al menos tan grande como la utilidad de respaldo de los agentes, es decir, la utilidad que el agente recibiría si no participara en el mecanismo. De lo contrario, ese agente no participaría en el mecanismo, y la participación de ningún agente puede perjudicar el objetivo de los diseñadores del mecanismo, ya que en el peor de los casos, el mecanismo puede ignorar a un agente fingiendo que el agente no está presente. (Además, si no se aplicara tal restricción, el diseñador simplemente podría hacer que los agentes paguen una cantidad infinita). Este tipo de restricción se llama restricción de IR (racionalidad individual). Existen tres posibles restricciones de IR diferentes: ex ante, ex interim y ex post, dependiendo de lo que el agente sabe sobre su propio tipo y los tipos de los demás al decidir si participar en el mecanismo. Ex ante IR significa que el agente participaría si no supiera absolutamente nada (ni siquiera su propio tipo). No estudiaremos este concepto en este documento. Ex interim IR significa que el agente siempre participaría si conociera solo su propio tipo, pero no el de los demás. Ex post IR significa que el agente siempre participaría incluso si conociera el tipo de todos. Definiremos formalmente las dos últimas nociones de IR. Primero, necesitamos formalizar el concepto del resultado de respaldo. Suponemos que la utilidad de respaldo de cada agente es cero para cada uno de sus tipos. Esto se hace sin pérdida de generalidad porque podemos agregar un término constante a la función de utilidad de un agente (para un tipo dado), sin afectar el comportamiento de toma de decisiones de ese agente maximizador de utilidad esperada [16]. Definición 4. En cualquier entorno de diseño de mecanismos automatizados con una restricción de IR, existe un resultado de contingencia o0 ∈ O donde, para cualquier agente i y cualquier tipo θi ∈ Θi, tenemos ui(θi, o0) = 0. (Además, en el caso de un diseñador egoísta, g(o0) = 0). Ahora podemos definir las nociones de racionalidad individual. Definición 5. La racionalidad individual (RI) se define como: • Un mecanismo determinista es ex interim RI si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0. Un mecanismo aleatorio es ex interim IR si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • Un mecanismo determinista es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 No aleatorizamos sobre los pagos porque mientras los agentes y el diseñador sean neutrales al riesgo con respecto a los pagos, es decir, su utilidad es lineal en los pagos, no hay razón para aleatorizar sobre los pagos. Un mecanismo aleatorio es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 3.2 Restricciones de compatibilidad de incentivos (IC) El segundo tipo de restricción establece que los agentes nunca deben tener un incentivo para informar incorrectamente su tipo (como se justificó anteriormente mediante el principio de revelación). Para este tipo de restricción, las dos variantes más comunes (o conceptos de solución) son la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash. Definición 6. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en estrategias dominantes si decir la verdad siempre es óptimo incluso cuando los tipos reportados por los otros agentes ya son conocidos. Formalmente, para cualquier agente i, cualquier vector de tipos (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ). En el caso de mecanismos aleatorios tenemos Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. Por lo tanto, en la implementación de estrategias dominantes, decir la verdad es óptimo independientemente de lo que informen los otros agentes. Si es óptimo solo dado que los otros agentes son veraces, y dado que uno no conoce los tipos de los otros agentes, tenemos implementación en equilibrio de Bayes-Nash. Definición 7. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en equilibrio de Bayes-Nash si decir la verdad siempre es óptimo para un agente cuando ese agente aún no sabe nada sobre los tipos de los otros agentes, y los otros agentes están diciendo la verdad. Formalmente, para cualquier agente i, cualquier tipo θi ∈ Θi, y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )]. En el caso de mecanismos aleatorios tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 135 3.3 Diseño de mecanismos automatizados Ahora podemos definir el problema computacional que estudiamos. Definición 8. (DISEÑO DE MECANISMOS AUTOMATIZADOS (AMD)) Se nos da: • un entorno de diseño de mecanismos automatizados, • una noción de IR (ex interim, ex post, o ninguna), • un concepto de solución (estrategias dominantes o Bayes-Nash), • si los pagos son posibles, • si la aleatorización es posible, • (en la variante de decisión del problema) un valor objetivo G. Se nos pregunta si existe un mecanismo del tipo especificado (en términos de pagos y aleatorización) que satisfaga tanto la noción de IR como el concepto de solución, y proporcione un valor esperado de al menos G para el objetivo. Un caso especial interesante es aquel en el que solo hay un agente. En este caso, el agente informante siempre sabe todo lo que hay que saber sobre los otros tipos de agentes, porque no hay otros agentes. Dado que el IR ex post y el IR ex interim solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de IR coinciden aquí. Además, dado que la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de solución coinciden aquí. Esta observación resultará ser una herramienta útil para demostrar resultados de dificultad: si demostramos dificultad computacional en el escenario de un solo agente, esto implica inmediatamente dificultad para ambos conceptos de IR, para ambos conceptos de solución, para cualquier número de agentes. 4. En esta sección demostramos que es NP-completo diseñar un mecanismo determinístico que maximice la suma esperada de los pagos recolectados de los agentes. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Para demostrar la NP-dureza, reducimos desde el problema MINSAT. Definición 9 (MINSAT). Se nos da una fórmula φ en forma normal conjuntiva, representada por un conjunto de variables booleanas V y un conjunto de cláusulas C, y un entero K (K < |C|). Se nos pregunta si existe una asignación a las variables en V tal que se satisfacen a lo sumo K cláusulas en φ. MINSAT fue recientemente demostrado como NP-completo [14]. Ahora podemos presentar nuestro resultado. Teorema 1. El problema determinista de maximización de pagos de AMD es NP-completo, incluso para un solo agente, incluso con una distribución uniforme de tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista de maximización de pagos de un solo agente. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V } ∪ {−v : v ∈ V }. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Sea l ∈ c denota que el literal l ocurre en la cláusula c. Entonces, la función de utilidad de los agentes está dada por u(θc, ol) = |Θ| + 1 para todo l ∈ L con l ∈ c; u(θc, ol) = 0 para todo l ∈ L con l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc) = 0 para todo c ∈ C con c = c; u(θv, ol) = |Θ| para todo l ∈ L con v(l) = v; u(θv, ol) = 0 para todo l ∈ L con v(l) = v; u(θv, oc) = 0 para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ|, donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v) y π(θv) = |Θ|. Para cada c ∈ C, sea o(θc) = oc; sea π(θc) = |Θ| + 1 si c no está satisfecha en la solución MINSAT, y π(θc) = |Θ| si c está satisfecha. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es θv, entonces cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivo para informar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Porque además, ningún tipo que no sea θc conduce al resultado oc, informar cualquier otro tipo dará como resultado una utilidad de 0, mientras que aún se requiere un pago de al menos |Θ| por parte del agente. Claramente, el agente está mejor reportando honestamente, para una utilidad total de 0. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), el pago esperado de este mecanismo es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o y una función de pago π. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. Entonces, la utilidad que el agente obtiene del resultado dado para este tipo es 0, y por lo tanto, según la IR, no se puede extraer ningún pago del agente para este tipo. Dado que, nuevamente por IR, el pago máximo que se puede extraer para cualquier otro tipo es |Θ| + 1, se sigue que el pago esperado máximo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo cual contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o−v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por la restricción de IR, el pago máximo que podemos extraer de cualquier tipo θv es |Θ|. Dado que no puede haber incentivos para que el agente informe falsamente, para cualquier cláusula c satisfecha por la asignación dada, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ|. (Pues si extrajéramos más de este tipo, la utilidad del agente en este caso sería menor que 1; y si v es la variable que satisface c en la asignación, de modo que o(θv) = ol donde l ocurre en c, entonces al agente le convendría más informar θv en lugar del informe veraz θc, para obtener un resultado que valga |Θ|+1 para él mientras tiene que pagar como máximo |Θ|.) Finalmente, para cualquier cláusula insatisfecha c, según la restricción de IR, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ| + 1. Se deduce que el pago esperado de nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia de MINSAT. Dado que AMD, que maximiza el pago, es solo un caso especial de AMD para un diseñador egoísta en el que el diseñador no tiene preferencias sobre el resultado elegido, esto implica inmediatamente dificultades para el caso general de AMD para un diseñador egoísta en el que los pagos son posibles. Sin embargo, esto aún no implica dureza para el caso especial donde los pagos no son posibles. Demostraremos la dificultad en este caso en la próxima sección. 5. En esta sección demostramos que es NP-completo diseñar un mecanismo determinista que maximice la expectativa del objetivo del diseñador cuando no son posibles los pagos. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Teorema 2. Sin pagos, el diseño determinista de AMD para un diseñador egoísta es NP-completo, incluso para un solo agente, incluso con una distribución uniforme sobre los tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista auto-interesada de un solo agente sin pagos. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L} ∪ {o∗}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V} ∪ {−v : v ∈ V}. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Deje que l ∈ c denote que el literal l ocurre en la cláusula c. Luego, deje que la función de utilidad de los agentes esté dada por u(θc, ol) = 2 para todo l ∈ L con l ∈ c; u(θc, ol) = −1 para todo l ∈ L con l /∈ c; u(θc, oc) = 2; u(θc, oc) = −1 para todo c ∈ C con c = c; u(θc, o∗) = 1; u(θv, ol) = 1 para todo l ∈ L con v(l) = v; u(θv, ol) = −1 para todo l ∈ L con v(l) = v; u(θv, oc) = −1 para todo c ∈ C; u(θv, o∗) = −1. Que la función objetivo de los diseñadores esté dada por g(o∗ ) = |Θ|+1; g(ol) = |Θ| para todo l ∈ L; g(oc) = |Θ| para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ| , donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v). Para cada c ∈ C que se cumpla en la solución MINSAT, sea o(θc) = oc; para cada c ∈ C no satisfecho, sea o(θc) = o∗. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es algún θv, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para reportar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Debido a que tampoco ningún tipo conduce al resultado oc, no hay ningún resultado que el mecanismo seleccione que le daría al agente una utilidad mayor a 1 para el tipo θc, y por lo tanto el agente no tiene incentivo para informar falsamente. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), entonces el valor esperado de la función objetivo de los diseñadores es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. El único otro resultado que el mecanismo puede elegir bajo la restricción de IR es o0. Esto tiene un valor objetivo de 0, y dado que el valor más alto que la función objetivo alcanza es |Θ| + 1, se sigue que el valor esperado máximo de la función objetivo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo que contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o-v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por lo anterior, para cualquier tipo θv, el valor de la función objetivo en este mecanismo será |Θ|. Para cualquier cláusula c satisfecha por la asignación dada, el valor de la función objetivo en el caso en que el agente informe el tipo θc será como máximo |Θ|. (Esto se debe a que no podemos elegir el resultado o∗ para dicho tipo, ya que en este caso el agente tendría un incentivo para informar θv en su lugar, donde v es la variable que satisface c en la asignación (de modo que o(θv) = ol donde l ocurre en c).) Finalmente, para cualquier cláusula insatisfecha c, el valor máximo que la función objetivo puede alcanzar en el caso en que el agente informa el tipo θc es |Θ| + 1, simplemente porque este es el valor más grande que la función alcanza en cualquier momento. Se deduce que el valor esperado de la función objetivo para nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas 137 satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia MINSAT. Ambos de nuestros resultados de dureza se basaron en la restricción de que el mecanismo debería ser determinista. En la siguiente sección, mostramos que la dificultad del diseño desaparece cuando permitimos la aleatorización en el mecanismo. 6. La aleatorización de AMD para un diseñador interesado en sí mismo es fácil. Ahora mostramos cómo permitir la aleatorización sobre los resultados hace que el problema de AMD auto-interesado sea manejable a través de la programación lineal, para cualquier número constante de agentes. Teorema 3. El AMD aleatorio con interés propio con un número constante de agentes es resoluble en tiempo polinómico mediante programación lineal, tanto con pagos como sin pagos, tanto para IR ex post como ex interim, y tanto para la implementación en estrategias dominantes como para la implementación en equilibrio de Bayes-Nash, incluso si los tipos están correlacionados. Prueba. Dado que los programas lineales pueden resolverse en tiempo polinómico [13], todo lo que necesitamos demostrar es que el número de variables y ecuaciones en nuestro programa es polinomial para cualquier número constante de agentes, es decir, exponencial solo en N. En todo momento, para determinar el tamaño del programa lineal, consideremos T = maxi{|Θi|}. Las variables de nuestro programa lineal serán las probabilidades (p(θ1, θ2, . . . , θN ))(o) (como máximo TN |O| variables) y los pagos πi(θ1, θ2, . . . , θN ) (como máximo NTN variables). (Mostramos el programa lineal para el caso en que los pagos son posibles; el caso sin pagos se obtiene fácilmente de esto simplemente omitiendo todas las variables de pago en el programa, o agregando restricciones adicionales que obliguen a los pagos a ser 0). Primero, mostramos las restricciones de IR. Para el IR ex post, agregamos las siguientes restricciones (como máximo NTN) al LP: • Para cada i ∈ {1, 2, . . . , N}, y para cada (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , agregamos ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0. Para el ex interino IR, agregamos las siguientes restricciones (como máximo NT) al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada θi ∈ Θi, agregamos θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0. Ahora, mostramos las restricciones del concepto de solución. Para la implementación en estrategias dominantes, agregamos las siguientes (a lo sumo NTN+1) restricciones al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ). Finalmente, para la implementación en el equilibrio de Bayes-Nash, agregamos las siguientes (a lo sumo NT2) restricciones al LP: • Para cada i ∈ {1, 2, ..., N}, para cada θi ∈ Θi, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )). Todo lo que queda por hacer es dar la expresión que el diseñador busca maximizar, que es: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )). Como indicamos, el número de variables y restricciones es exponencial solo en N, por lo tanto, el programa lineal tiene un tamaño polinómico para un número constante de agentes. Por lo tanto, el problema es resoluble en tiempo polinómico. IMPLICACIONES PARA UN PROBLEMA DE DISEÑO DE SUBASTA COMBINATORIA ÓPTIMA En esta sección, demostraremos algunas consecuencias interesantes del problema de diseño de mecanismos automatizados para un diseñador interesado en sí mismo en el diseño de subastas combinatorias óptimas. Considera una subasta combinatoria con un conjunto S de artículos en venta. Para cualquier conjunto B ⊆ S, dejemos que ui(θi, B) sea la utilidad del postor i al recibir el conjunto B cuando el tipo del postor es θi. El problema de diseño de subasta óptima consiste en especificar las reglas de la subasta de manera que se maximice los ingresos esperados para el subastador. (Por el principio de revelación, sin pérdida de generalidad, podemos asumir que la subasta es veraz). El problema de diseño de subasta óptima se resuelve para el caso de un solo artículo mediante la famosa subasta de Myerson [18]. Sin embargo, el diseño de subastas óptimas en subastas combinatorias es un problema de investigación abierto reconocido [3, 25]. El problema está abierto incluso si solo hay dos artículos en venta. (El caso de dos artículos con una forma muy especial de complementariedad y sin sustituibilidad ha sido resuelto recientemente [1].) Supongamos que tenemos disposición libre: los artículos pueden ser desechados sin costo alguno. Además, supongamos que las preferencias de los postores tienen la siguiente estructura: cuando un postor recibe un conjunto de artículos, la utilidad del postor por ese conjunto está determinada únicamente por el mejor artículo en el conjunto. (Enfatizamos que qué artículo es el mejor puede depender del tipo de postor). Definición 10. Se dice que el postor i tiene preferencias solo por lo mejor sobre paquetes de artículos si existe una función vi: Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s). Hacemos la siguiente observación útil en este contexto: no tiene sentido otorgarle a un postor más de un artículo. La razón es que si el postor está informando honestamente, quitarle todos los artículos menos el de mayor valor no perjudicará al postor; y, mediante la disposición gratuita, hacerlo solo reducirá el incentivo para que este postor informe falsamente este tipo, cuando en realidad tiene otro tipo. Ahora demostramos que el problema de diseñar una subasta óptima determinista es NP-completo, mediante una reducción del problema AMD de maximización de pagos. Teorema 4. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de artículos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), diseñar la subasta determinística óptima es NP-completo, incluso para un único postor con una distribución uniforme sobre los tipos. Prueba. El problema está en NP porque podemos generar de manera no determinista una regla de asignación, y luego establecer los pagos utilizando programación lineal. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de AMD determinista que maximiza el pago, con un único agente y una distribución uniforme de tipos, al siguiente problema de diseño de subasta combinatoria óptima con una única postor con preferencias de solo los mejores. Para cada resultado o ∈ O en la instancia de AMD (excepto el resultado o0), que haya un artículo so ∈ S. Que el espacio de tipos sea el mismo, y que v(θi, so) = ui(θi, o) (donde u está especificado en la instancia de AMD). Que el valor objetivo de ingresos esperados sea el mismo en ambas instancias. Mostramos que las instancias son equivalentes. Primero supongamos que existe una solución para la instancia de AMD, dada por una función de resultado y una función de pago. Entonces, si la solución de AMD elige el resultado o para un tipo, en la solución de subasta óptima, asignamos {so} al postor para este tipo. (A menos que o = o0, en cuyo caso asignamos {} al postor). Que las funciones de pago sean las mismas en ambas instancias. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo verdadero) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución óptima de la subasta. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el subastador/diseñador son los mismos. Se deduce que existe una solución para la instancia de diseño de subasta óptima. Ahora supongamos que existe una solución para la instancia de diseño de subasta óptima. Por la observación de que como máximo se puede tener un artículo, podemos asumir sin pérdida de generalidad que la solución nunca asigna más de un artículo. Entonces, si la solución de subasta óptima asigna el artículo al postor para un tipo, en la solución de AMD, permita que el mecanismo elija el resultado o para ese tipo. Si la solución de subasta óptima no asigna nada al postor para un tipo, en la solución AMD, permita que el mecanismo elija el resultado o0 para ese tipo. Que las funciones de pago sean las mismas. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo real) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución AMD. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el diseñador/subastador son los mismos. Se deduce que existe una solución para la instancia de AMD. Afortunadamente, también podemos extender el resultado de facilidad para mecanismos aleatorios a este escenario de subasta combinatoria, lo que nos proporciona uno de los pocos algoritmos de tiempo polinómico conocidos para un problema de diseño óptimo de subasta combinatoria. Teorema 5. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de elementos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), si el número de postores es una constante k, entonces la subasta aleatoria óptima puede ser diseñada en tiempo polinómico. (Para cualquier restricción de IC e IR.) Prueba. Por la observación de que a lo sumo un artículo, podemos sin pérdida de generalidad restringirnos a asignaciones donde cada postor recibe como máximo un artículo. Hay menos de (|S| + 1)k asignaciones de ese tipo, es decir, un número polinómico de asignaciones. Dado que podemos enumerar explícitamente los resultados, simplemente podemos resolver esto como una instancia de AMD que maximiza el pago, con programación lineal. 8. Investigaciones relacionadas sobre la complejidad en el diseño de mecanismos. Ha habido un considerable interés reciente en el diseño de mecanismos en la informática. Parte de ello se ha centrado en cuestiones de complejidad computacional, pero la mayor parte de ese trabajo ha buscado diseñar mecanismos que sean fáciles de ejecutar (por ejemplo, [20, 15, 19, 9, 12]), en lugar de estudiar la complejidad de diseñar el mecanismo. La pieza más cercana de trabajo anterior estudió la complejidad del diseño automatizado de mecanismos por un diseñador benevolente [5, 6]. Roughgarden ha estudiado la complejidad de diseñar una buena topología de red para agentes que eligen egoístamente los enlaces que utilizan [21]. Esto está relacionado con el diseño de mecanismos, pero difiere significativamente en que el diseñador solo tiene un control restringido sobre las reglas del juego porque no hay ninguna parte que pueda imponer el resultado (o pagos laterales). Además, no hay un informe explícito de preferencias. 9. CONCLUSIONES E INVESTIGACIONES FUTURAS A menudo, un resultado debe ser elegido en función de las preferencias informadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les sea más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente emergente llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración específica de agregación de preferencias en cuestión. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo, un entorno mucho más relevante para el comercio electrónico. En este contexto, al centro solo le importa qué resultado se elige y qué pagos se le realizan. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este escenario, demostramos que diseñar un mecanismo determinista óptimo es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Estos resultados de dureza implican dificultad en todos los entornos de diseño de mecanismos automatizados más generales con un diseñador egoísta. Los resultados de dureza se aplican ya sea que las restricciones de racionalidad individual (participación) se apliquen ex interim o ex post, y ya sea que el concepto de solución sea la implementación de estrategias dominantes o la implementación del equilibrio de Bayes-Nash. Luego demostramos que permitir la aleatorización en el mecanismo hace que el problema de diseño en todos estos escenarios sea computacionalmente sencillo. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (que maximiza los ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar un mecanismo determinístico óptimo es NP-completo incluso con un agente, pero diseñar un mecanismo aleatorio óptimo es fácil. La investigación futura incluye estudiar el diseño automatizado de mecanismos con un diseñador interesado en sí mismo en entornos más restringidos, como subastas (donde el objetivo del diseñador puede incluir preferencias sobre qué postor debería recibir el bien, así como los pagos). También queremos estudiar la complejidad del diseño de mecanismos automatizados en entornos donde los espacios de resultados y tipos tienen una estructura especial para que puedan representarse de manera más concisa. Finalmente, planeamos reunir un conjunto de datos de problemas de diseño de mecanismos del mundo real, tanto históricos como actuales, y aplicar el diseño de mecanismos automatizado a esos problemas. 10. REFERENCIAS [1] M. Armstrong. Subastas multi-objetivo óptimas. Revisión de Estudios Económicos, 67:455-481, 2000. [2] K. Arrow. La doctrina de los derechos de propiedad y la revelación de la demanda bajo información incompleta. En M. Boskin, editor, Economía y bienestar humano. New York Academic Press, 1979. [3] C. Avery y T. Hendershott. Agrupación y subastas óptimas de múltiples productos. Revisión de Estudios Económicos, 67:483-497, 2000. [4] E. H. Clarke. Precios escalonados de bienes públicos. Elección Pública, 11:17-33, 1971. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Actas de la 18ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI-02), páginas 103-110, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Diseño de mecanismos automatizados: Resultados de complejidad derivados del entorno de un solo agente. En Actas de la 5ta Conferencia Internacional de Comercio Electrónico (ICEC-03), páginas 17-24, Pittsburgh, PA, EE. UU., 2003. [7] V. Conitzer y T. Sandholm. Críticas computacionales del principio de revelación. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), Nueva York, NY, 2004. Breve ensayo. La versión completa apareció en el taller AAMAS-03 sobre Comercio Electrónico Mediado por Agentes (AMEC). [8] C. d'Aspremont y L. A. Gérard-Varet. Incentivos e información incompleta. Revista de Economía Pública, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou y S. Shenker. Compartiendo el costo de las transmisiones de multidifusión. Revista de Ciencias de la Computación y de Sistemas, 63:21-41, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 2000. [10] A. Gibbard. Manipulación de esquemas de votación. Econometrica, 41:587-602, 1973. [11] T. Groves.\nEconometrica, 41:587-602, 1973. [11] T. Groves. Incentivos en equipos. Econometrica, 41:617-631, 1973. [12] J. Hershberger y S. Suri. Precios de Vickrey y caminos más cortos: ¿Cuánto vale una arista? En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [13] L. Khachiyan. Un algoritmo polinómico en programación lineal. Matemática soviética. Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi y P. Mirchandani. El problema de satisfacibilidad mínimo. Revista SIAM de Matemáticas Discretas, 7(2):275-283, 1994. [15] D. Lehmann, L. I. O'Callaghan y Y. Shoham. Revelación de la verdad en subastas combinatorias rápidas y aproximadamente eficientes. Revista de la ACM, 49(5):577-602, 2002. La versión inicial apareció en las Actas de la Conferencia de Comercio Electrónico de la ACM (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [17] E. S. Maskin y J. Riley. Subastas multiunidad óptimas. En F. Hahn, editor, \"La economía de los mercados faltantes, la información y los juegos\", capítulo 14, páginas 312-335. Clarendon Press, Oxford, 1989. [18] R. Myerson.\nPrensa Clarendon, Oxford, 1989. [18] R. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6:58-73, 1981. [19] N. Nisan y A. Ronen. Mecanismos VCG computacionalmente factibles. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 242-252, Minneapolis, MN, 2000. [20] N. Nisan y A. Ronen. Diseño de mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166-196, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 1999. [21] T. Roughgarden. Diseñar redes para usuarios egoístas es difícil. En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [22] T. Sandholm. Problemas en subastas computacionales de Vickrey. Revista Internacional de Comercio Electrónico, 4(3):107-129, 2000. Número especial sobre la Aplicación de Agentes Inteligentes para el Comercio Electrónico. Una versión corta y temprana apareció en la Segunda Conferencia Internacional sobre Sistemas Multiagente (ICMAS), páginas 299-306, 1996. [23] M. A. Satterthwaite. In Spanish, the translation would be: \"Inmutabilidad estratégica y condiciones de Arrow: teoremas de existencia y correspondencia para procedimientos de votación y funciones de bienestar social.\" Revista de Teoría Económica, 10:187-217, 1975. [24] W. Vickrey. Contrarrestando la especulación, subastas y ofertas selladas competitivas. Revista de Finanzas, 16:8-37, 1961. [25] R. V. Vohra. Problemas de investigación en subastas combinatorias. Mimeo, versión 29 de octubre de 2001. 141 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "individual rationality": {
            "translated_key": "racionalidad individual",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-interested Automated Mechanism Design and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently proposed approach-called automated mechanism design-a mechanism is computed for the preference aggregation setting at hand.",
                "This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike the earlier work on automated mechanism design that studied a benevolent designer, in this paper we study automated mechanism design problems where the designer is self-interested.",
                "In this case, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy.",
                "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy.",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc.",
                "The preference aggregator generally does not know the agents preferences a priori.",
                "Rather, the agents report their preferences to the coordinator.",
                "Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully.",
                "Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen.",
                "Manipulability is a pervasive problem across preference aggregation mechanisms.",
                "A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.)",
                "What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective.",
                "This is the classic setting of mechanism design in game theory.",
                "In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself.",
                "This is the mechanism design setting most relevant to electronic commerce.",
                "In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear.",
                "It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences.",
                "The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments.",
                "The most common such constraint is that of <br>individual rationality</br> (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
                "For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences.",
                "Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it.",
                "Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off.",
                "On the other hand, the designer will not necessarily choose a social welfare maximizing outcome.",
                "For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected.",
                "Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0.",
                "Classical mechanism design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective.",
                "The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]).",
                "However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare.",
                "If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization.",
                "In practice, the designer may also be interested in the outcome per se.",
                "For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical.",
                "For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed.",
                "Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments.",
                "In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand.",
                "This approach addresses all of the downsides listed above.",
                "We formulate the mechanism design problem as an optimization problem.",
                "The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types.",
                "The output is a nonmanipulable mechanism that is optimal with respect to some objective.",
                "This approach is called automated mechanism design.",
                "The automated mechanism design approach has four advantages over the classical approach of designing general mechanisms.",
                "First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare).",
                "Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences.",
                "When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally.",
                "Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types).",
                "Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information.",
                "For example, imagine a company automatically creating its procurement mechanism based on statistical knowledge about its suppliers, rather than using a classical descending procurement auction.",
                "Fourth, the burden of design is shifted from humans to a machine.",
                "However, automated mechanism design requires the mechanism design optimization problem to be solved anew for each setting.",
                "Hence its computational complexity becomes a key issue.",
                "Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6].",
                "In this paper we study the computational complexity of automated mechanism design in the case of a self-interested designer.",
                "This is an important setting for automated mechanism design due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested.",
                "We also show that this problem is closely related to a particular optimal (revenue-maximizing) combinatorial auction design problem. 133 The rest of this paper is organized as follows.",
                "In Section 2, we justify the focus on nonmanipulable mechanisms.",
                "In Section 3, we define the problem we study.",
                "In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it.",
                "In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen.",
                "In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case.",
                "Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2.",
                "JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of automated mechanism design, we should justify our focus on nonmanipulable mechanisms.",
                "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any nonmanipulable mechanism.",
                "This does, however, turn out to be the case: given any mechanism, we can construct a nonmanipulable mechanism whose performance is identical, as follows.",
                "We build an interface layer between the agents and the original mechanism.",
                "The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer.",
                "The resulting outcome is the outcome of the new mechanism.",
                "Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism.",
                "This argument is known in the mechanism design literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22].",
                "However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.)",
                "Given this, we can focus on truthful mechanisms in the rest of the paper. 3.",
                "DEFINITIONS We now formalize the automated mechanism design setting.",
                "Definition 1.",
                "In an automated mechanism design setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize.",
                "There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent).",
                "In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness.",
                "However, in this paper, we focus on the case of a self-interested designer.",
                "A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer.",
                "Definition 2.",
                "A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i.",
                "In the case where g = 0 everywhere, the designer is said to be payment maximizing.",
                "In the case where payments are not possible, g constitutes the objective function by itself.",
                "We now define the kinds of mechanisms under study.",
                "By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them.",
                "Definition 3.",
                "We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing.",
                "The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator.",
                "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 <br>individual rationality</br> (IR) constraints The first type of constraint is the following.",
                "The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism.",
                "Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.)",
                "This type of constraint is called an IR (<br>individual rationality</br>) constraint.",
                "There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism.",
                "Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type).",
                "We will not study this concept in this paper.",
                "Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others.",
                "Ex post IR means that the agent would always participate even if it knew everybodys type.",
                "We will define the latter two notions of IR formally.",
                "First, we need to formalize the concept of the fallback outcome.",
                "We assume that each agents fallback utility is zero for each one of its types.",
                "This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16].",
                "Definition 4.",
                "In any automated mechanism design setting with an IR constraint, there is a fallback outcome o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)",
                "We can now to define the notions of <br>individual rationality</br>.",
                "Definition 5.",
                "<br>individual rationality</br> (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
                "A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments.",
                "A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
                "The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle).",
                "For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium.",
                "Definition 6.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known.",
                "Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
                "In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible.",
                "Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report.",
                "If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium.",
                "Definition 7.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth.",
                "Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible. 135 3.3 Automated mechanism design We can now define the computational problem we study.",
                "Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an automated mechanism design setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective.",
                "An interesting special case is the setting where there is only one agent.",
                "In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents.",
                "Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here.",
                "Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here.",
                "This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4.",
                "PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "To demonstrate NPhardness, we reduce from the MINSAT problem.",
                "Definition 9 (MINSAT).",
                "We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|).",
                "We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied.",
                "MINSAT was recently shown to be NP-complete [14].",
                "We can now present our result.",
                "Theorem 1.",
                "Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent payment-maximizing deterministic AMD instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|.",
                "For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the MINSAT solution, and π(θc) = |Θ| if c is satisfied.",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent.",
                "Clearly the agent is better off reporting truthfully, for a total utility of 0.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type.",
                "Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the IR constraint, the maximum payment we can extract from any type θv is |Θ|.",
                "Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.)",
                "Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1.",
                "It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible.",
                "However, it does not yet imply hardness for the special case where payments are not possible.",
                "We will prove hardness in this case in the next section. 5.",
                "SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "Theorem 2.",
                "Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent self-interested deterministic AMD without payments instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1.",
                "Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v).",
                "For every c ∈ C that is satisfied in the MINSAT solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ .",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "The only other outcome that the mechanism is allowed to choose under the IR constraint is o0.",
                "This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}.",
                "We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|.",
                "For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).)",
                "Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes.",
                "It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Both of our hardness results relied on the constraint that the mechanism should be deterministic.",
                "In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6.",
                "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of self-interested AMD tractable through linear programming, for any constant number of agents.",
                "Theorem 3.",
                "Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated.",
                "Proof.",
                "Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}.",
                "The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.)",
                "First, we show the IR constraints.",
                "For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
                "For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
                "Now, we show the solution concept constraints.",
                "For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
                "Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
                "All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
                "As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents.",
                "Thus the problem is solvable in polynomial time. 7.",
                "IMPLICATIONS FOR AN OPTIMAL COMBINATORIAL AUCTION DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated mechanism design for a self-interested designer on designing optimal combinatorial auctions.",
                "Consider a combinatorial auction with a set S of items for sale.",
                "For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi.",
                "The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.)",
                "The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18].",
                "However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25].",
                "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of complementarity and no substitutability has been solved recently [1].)",
                "Suppose we have free disposal-items can be thrown away at no cost.",
                "Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.)",
                "Definition 10.",
                "Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
                "We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item.",
                "The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type.",
                "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the payment maximizing AMD problem!",
                "Theorem 4.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types.",
                "Proof.",
                "The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming.",
                "To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal combinatorial auction design problem instance with a single bidder with best-only preferences.",
                "For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance).",
                "Let the expected revenue target value be the same in both instances.",
                "We show the instances are equivalent.",
                "First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function.",
                "Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.)",
                "Let the payment functions be the same in both instances.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same.",
                "It follows that there exists a solution to the optimal auction design instance.",
                "Now suppose there exists a solution to the optimal auction design instance.",
                "By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item.",
                "Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type.",
                "If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type.",
                "Let the payment functions be the same.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same.",
                "It follows that there exists a solution to the AMD instance.",
                "Fortunately, we can also carry through the easiness result for randomized mechanisms to this combinatorial auction setting-giving us one of the few known polynomial-time algorithms for an optimal combinatorial auction design problem.",
                "Theorem 5.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.)",
                "Proof.",
                "By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item.",
                "There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations.",
                "Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8.",
                "RELATED RESEARCH ON COMPLEXITY IN MECHANISM DESIGN There has been considerable recent interest in mechanism design in computer science.",
                "Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism.",
                "The closest piece of earlier work studied the complexity of automated mechanism design by a benevolent designer [5, 6].",
                "Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21].",
                "This is related to mechanism design, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments).",
                "Also, there is no explicit reporting of preferences. 9.",
                "CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently emerging approach-called automated mechanism design-a mechanism is computed for the specific preference aggregation setting at hand.",
                "This has several advantages, 139 but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike earlier work on automated mechanism design that studied a benevolent designer, in this paper we studied automated mechanism design problems where the designer is self-interesteda setting much more relevant for electronic commerce.",
                "In this setting, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "These hardness results imply hardness in all more general automated mechanism design settings with a self-interested designer.",
                "The hardness results apply whether the <br>individual rationality</br> (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation.",
                "We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy.",
                "Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy.",
                "Future research includes studying automated mechanism design with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments).",
                "We also want to study the complexity of automated mechanism design in settings where the outcome and type spaces have special structure so they can be represented more concisely.",
                "Finally, we plan to assemble a data set of real-world mechanism design problems-both historical and current-and apply automated mechanism design to those problems. 10.",
                "REFERENCES [1] M. Armstrong.",
                "Optimal multi-object auctions.",
                "Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow.",
                "The property rights doctrine and demand revelation under incomplete information.",
                "In M. Boskin, editor, Economics and human welfare.",
                "New York Academic Press, 1979. [3] C. Avery and T. Hendershott.",
                "Bundling and optimal auctions of multiple products.",
                "Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke.",
                "Multipart pricing of public goods.",
                "Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Automated mechanism design: Complexity results stemming from the single-agent setting.",
                "In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm.",
                "Computational criticisms of the revelation principle.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004.",
                "Short paper.",
                "Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet.",
                "Incentives and incomplete information.",
                "Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker.",
                "Sharing the cost of muliticast transmissions.",
                "Journal of Computer and System Sciences, 63:21-41, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard.",
                "Manipulation of voting schemes.",
                "Econometrica, 41:587-602, 1973. [11] T. Groves.",
                "Incentives in teams.",
                "Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri.",
                "Vickrey prices and shortest paths: What is an edge worth?",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan.",
                "A polynomial algorithm in linear programming.",
                "Soviet Math.",
                "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani.",
                "The minimum satisfiability problem.",
                "SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham.",
                "Truth revelation in rapid, approximately efficient combinatorial auctions.",
                "Journal of the ACM, 49(5):577-602, 2002.",
                "Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [17] E. S. Maskin and J. Riley.",
                "Optimal multi-unit auctions.",
                "In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335.",
                "Clarendon Press, Oxford, 1989. [18] R. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen.",
                "Computationally feasible VCG mechanisms.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behavior, 35:166-196, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden.",
                "Designing networks for selfish users is hard.",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm.",
                "Issues in computational Vickrey auctions.",
                "International Journal of Electronic Commerce, 4(3):107-129, 2000.",
                "Special Issue on 140 Applying Intelligent Agents for Electronic Commerce.",
                "A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite.",
                "Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions.",
                "Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey.",
                "Counterspeculation, auctions, and competitive sealed tenders.",
                "Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra.",
                "Research problems in combinatorial auctions.",
                "Mimeo, version Oct. 29, 2001. 141"
            ],
            "original_annotated_samples": [
                "The most common such constraint is that of <br>individual rationality</br> (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
                "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 <br>individual rationality</br> (IR) constraints The first type of constraint is the following.",
                "This type of constraint is called an IR (<br>individual rationality</br>) constraint.",
                "We can now to define the notions of <br>individual rationality</br>.",
                "<br>individual rationality</br> (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0."
            ],
            "translated_annotated_samples": [
                "La restricción más común de este tipo es la de <br>racionalidad individual</br> (RI), lo que significa que el mecanismo no puede dejar a ningún agente en una situación peor a la que hubiera estado si no hubiera participado en el mecanismo.",
                "La función de utilidad es un conocimiento común, pero debido a que el tipo de agente es un parámetro en la función de utilidad de los agentes, el agregador no puede saber cuál es la utilidad de los agentes sin conocer el tipo de agente. Un mecanismo aleatorio con pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), y para cada agente i, una función de selección de pago πi: Θ1 × Θ2 × . . . × ΘN → R. Hay dos tipos de restricciones para el diseñador al construir el mecanismo. 3.1 Restricciones de <br>racionalidad individual</br> (IR) El primer tipo de restricción es el siguiente.",
                "Este tipo de restricción se llama restricción de IR (<br>racionalidad individual</br>).",
                "Ahora podemos definir las nociones de <br>racionalidad individual</br>.",
                "La <br>racionalidad individual</br> (RI) se define como: • Un mecanismo determinista es ex interim RI si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0."
            ],
            "translated_text": "Diseño de mecanismos automatizados de interés propio e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les resulte más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente propuesto, llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración de agregación de preferencias actual. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre el diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo. En este caso, al centro solo le importa qué resultado se elige y qué pagos se le hacen. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este contexto, demostramos que el diseño de mecanismos deterministas óptimos es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Luego mostramos cómo permitir la aleatorización en el mecanismo hace que los problemas en este entorno sean computacionalmente fáciles. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (maximizadora de ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar una subasta determinista óptima es NP-completo, pero diseñar una subasta aleatoria óptima es fácil. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Teoría 1. En entornos multiagentes, a menudo se debe elegir un resultado en función de las preferencias informadas por un grupo de agentes. Tales resultados podrían ser presidentes potenciales, planes conjuntos, asignaciones de bienes o recursos, etc. El agregador de preferencias generalmente no conoce las preferencias de los agentes de antemano. Más bien, los agentes informan sus preferencias al coordinador. Desafortunadamente, un agente puede tener un incentivo para informar incorrectamente sus preferencias con el fin de engañar al mecanismo y lograr que seleccione un resultado que sea más deseable para el agente que el resultado que se seleccionaría si el agente revelara sus preferencias de manera honesta. Tal manipulación es indeseable porque los mecanismos de agregación de preferencias están diseñados para agrupar las preferencias de una manera socialmente deseable, y si los agentes revelan sus preferencias de manera insincera, se podría elegir un resultado socialmente indeseable. La manipulabilidad es un problema generalizado en los mecanismos de agregación de preferencias. Un resultado negativo seminal, el teorema de Gibbard-Satterthwaite, muestra que bajo cualquier esquema de agregación de preferencias no dictatorial, si hay al menos 3 posibles resultados, existen preferencias bajo las cuales un agente está mejor reportando falsamente [10, 23]. (Un esquema de agregación de preferencias se llama dictatorial si uno de los agentes dicta el resultado sin importar las preferencias que reporten los otros agentes). Lo que le gustaría hacer al agregador es diseñar un mecanismo de agregación de preferencias para que 1) los agentes interesados reporten sus preferencias de manera veraz, y 2) el mecanismo elija un resultado que sea deseable desde la perspectiva de algún objetivo. Esta es la configuración clásica del diseño de mecanismos en la teoría de juegos. En este documento, estudiamos el caso en el que el diseñador actúa por interés propio, es decir, al diseñador no le importa directamente cómo se relaciona el resultado con las preferencias de los agentes, sino que está más preocupado por su propia agenda sobre cuál resultado debería ser elegido y en maximizar los pagos para sí mismo. Este es el entorno de diseño de mecanismos más relevante para el comercio electrónico. En el caso en que el diseñador del mecanismo esté interesado en maximizar alguna noción de bienestar social, la importancia de recopilar las preferencias de los agentes es clara. Quizás sea menos obvio por qué deberían ser recopilados cuando el diseñador está interesado en sí mismo y, por lo tanto, su objetivo no está directamente relacionado con las preferencias de los agentes. La razón de esto es que a menudo las preferencias de los agentes imponen límites en cómo el diseñador elige el resultado y los pagos. La restricción más común de este tipo es la de <br>racionalidad individual</br> (RI), lo que significa que el mecanismo no puede dejar a ningún agente en una situación peor a la que hubiera estado si no hubiera participado en el mecanismo. Por ejemplo, en el contexto del diseño óptimo de subastas, el diseñador (subastador) solo se preocupa por cuántos ingresos se recaudan, y no en sí mismo por cuán bien la asignación del bien (o bienes) corresponde a las preferencias de los agentes. Sin embargo, el diseñador no puede obligar a un agente a pagar más de lo que valora el paquete de bienes asignado a él. Por lo tanto, incluso un diseñador interesado en sí mismo elegirá un resultado que beneficie razonablemente a los agentes. Por otro lado, el diseñador no necesariamente elegirá un resultado que maximice el bienestar social. Por ejemplo, si el diseñador siempre elige un resultado que maximiza el bienestar social con respecto a las preferencias informadas, y obliga a cada agente a pagar la diferencia entre la utilidad que tiene ahora y la utilidad que habría tenido si no hubiera participado en el mecanismo, es fácil ver que los agentes pueden tener un incentivo para informar incorrectamente sus preferencias, lo que puede llevar realmente a recaudar menos ingresos. De hecho, uno de los resultados contraintuitivos de la teoría del diseño de subastas óptimas es que a veces el bien se asigna a nadie incluso cuando el subastador tiene un precio de reserva de 0. El diseño de mecanismos clásicos proporciona algunos mecanismos generales, que, bajo ciertas suposiciones, satisfacen alguna noción de no manipulabilidad y maximizan algún objetivo. La ventaja de estos mecanismos es que no dependen de información (incluso probabilística) sobre las preferencias de los agentes (por ejemplo, el mecanismo de Vickrey-Clarke-Groves (VCG) [24, 4, 11]), o pueden aplicarse fácilmente a cualquier distribución de probabilidad sobre las preferencias (por ejemplo, el mecanismo dAGVA [8, 2], la subasta de Myerson [18], y la subasta multiunidad de Maskin-Riley [17]). Sin embargo, los mecanismos generales también tienen importantes desventajas: • Los mecanismos generales más famosos y ampliamente aplicables, VCG y dAGVA, solo maximizan el bienestar social. Si el diseñador está interesado en sí mismo, como es el caso en muchos entornos de comercio electrónico, estos mecanismos no maximizan el objetivo del diseñador. • Los mecanismos generales que se centran en un diseñador interesado en sí mismo solo son aplicables en entornos muy restringidos, como la subasta de maximización de ingresos esperados de Myerson para vender un solo artículo, y la subasta de maximización de ingresos esperados de Maskin y Riley para vender múltiples unidades idénticas de un artículo. • Incluso en los entornos restringidos en los que se aplican estos mecanismos, solo permiten la maximización de pagos. En la práctica, el diseñador también puede estar interesado en el resultado en sí mismo. Por ejemplo, a un subastador le puede importar qué postor recibe el artículo. • A menudo se asume que los pagos laterales pueden ser utilizados para adaptar los incentivos de los agentes, pero esto no siempre es práctico. Por ejemplo, en los mercados electrónicos basados en trueque, como Recipco, firstbarter.com, BarterOne e Intagio, no se permiten los pagos laterales. Además, entre los agentes de software, podría ser más deseable construir mecanismos que no dependan de la capacidad de realizar pagos, ya que muchos agentes de software no cuentan con la infraestructura para hacer pagos. Por el contrario, seguimos un enfoque reciente donde el mecanismo se diseña automáticamente para el problema específico en cuestión. Este enfoque aborda todos los inconvenientes mencionados anteriormente. Formulamos el problema de diseño de mecanismos como un problema de optimización. La entrada se caracteriza por el número de agentes, los posibles tipos de agentes (preferencias) y las distribuciones previas de los agregadores sobre los tipos de agentes. La salida es un mecanismo no manipulable que es óptimo con respecto a algún objetivo. Este enfoque se llama diseño de mecanismos automatizado. El enfoque de diseño de mecanismos automatizado tiene cuatro ventajas sobre el enfoque clásico de diseñar mecanismos generales. Primero, se puede utilizar incluso en entornos que no cumplen con las suposiciones de los mecanismos clásicos (como la disponibilidad de pagos laterales o que el objetivo sea el bienestar social). Segundo, puede permitir a uno eludir resultados de imposibilidad (como el teorema de Gibbard-Satterthwaite) que establecen que no existe un mecanismo que sea deseable para todas las preferencias. Cuando el mecanismo está diseñado para la configuración actual, no importa que no funcione de manera más general. Tercero, puede generar mecanismos mejores (en términos de garantías de no manipulabilidad más sólidas y/o mejores resultados) que los mecanismos clásicos porque el mecanismo aprovecha las particularidades del entorno (la información probabilística que el diseñador tiene sobre los tipos de agentes). Dada la gran cantidad de información que las partes tienen entre sí hoy en día, es probable que este enfoque conduzca a ahorros enormes en comparación con los mecanismos clásicos, que en su mayoría ignoran esa información. Por ejemplo, imagina una empresa creando automáticamente su mecanismo de adquisiciones basado en el conocimiento estadístico sobre sus proveedores, en lugar de utilizar una subasta de adquisiciones descendente clásica. Cuarto, la carga del diseño se traslada de los humanos a una máquina. Sin embargo, el diseño automatizado de mecanismos requiere que el problema de optimización del diseño del mecanismo se resuelva de nuevo para cada configuración. Por lo tanto, su complejidad computacional se convierte en un tema clave. Investigaciones previas han estudiado esta pregunta para diseñadores benevolentes que desean maximizar, por ejemplo, el bienestar social [5, 6]. En este artículo estudiamos la complejidad computacional del diseño automatizado de mecanismos en el caso de un diseñador con interés propio. Esta es una configuración importante para el diseño de mecanismos automatizados debido a la escasez de mecanismos generales en esta área, y al hecho de que en la mayoría de las configuraciones de comercio electrónico el diseñador actúa en su propio interés. También demostramos que este problema está estrechamente relacionado con un problema de diseño de subasta combinatoria óptima (maximización de ingresos) particular. El resto de este documento está organizado de la siguiente manera. En la Sección 2, justificamos el enfoque en mecanismos no manipulables. En la Sección 3, definimos el problema que estudiamos. En la Sección 4, demostramos que diseñar un mecanismo determinista óptimo es NP-completo incluso cuando al diseñador solo le importan los pagos que recibe. En la Sección 5, demostramos que diseñar un mecanismo determinista óptimo también es NP-completo cuando los pagos no son posibles y el diseñador solo está interesado en el resultado elegido. En la Sección 6, demostramos que un mecanismo óptimo aleatorizado puede ser diseñado en tiempo polinómico incluso en el caso general. Finalmente, en la Sección 7, demostramos que para diseñar subastas combinatorias óptimas bajo preferencias de mejor opción solamente, nuestros resultados sobre AMD implican que este problema es NP-completo para subastas determinísticas, pero sencillo para subastas aleatorias. 2. JUSTIFICANDO EL ENFOQUE EN MECANISMOS NO MANIPULABLES Antes de definir el problema computacional del diseño automatizado de mecanismos, debemos justificar nuestro enfoque en mecanismos no manipulables. Después de todo, no es inmediatamente obvio que no haya mecanismos manipulables que, incluso cuando los agentes informan estratégicamente sus tipos y, por lo tanto, a veces de manera no veraz, aún logren mejores resultados (según el objetivo que usemos) que cualquier mecanismo no manipulable. Sin embargo, resulta ser el caso que, dado cualquier mecanismo, podemos construir un mecanismo no manipulable cuyo rendimiento es idéntico, de la siguiente manera. Construimos una capa de interfaz entre los agentes y el mecanismo original. Los agentes informan sus preferencias (o tipos) a la capa de interfaz; posteriormente, la capa de interfaz introduce en el mecanismo original los tipos que los agentes habrían informado estratégicamente al mecanismo original, si sus tipos fueran los declarados a la capa de interfaz. El resultado resultante es el resultado del nuevo mecanismo. Dado que la capa de interfaz actúa estratégicamente en nombre de cada agente, nunca hay un incentivo para informar falsamente a la capa de interfaz; por lo tanto, los tipos informados por la capa de interfaz son los tipos estratégicos que se habrían informado sin la capa de interfaz, por lo que los resultados son exactamente como habrían sido con el mecanismo original. Este argumento es conocido en la literatura de diseño de mecanismos como el principio de revelación [16]. (Existen dificultades computacionales al aplicar el principio de revelación en espacios de resultados y tipos combinatorios grandes [7, 22]). Sin embargo, dado que aquí nos enfocamos en espacios de resultados y tipos representados de forma plana, esto no es una preocupación aquí. Dado esto, podemos centrarnos en mecanismos veraces en el resto del documento. 3. DEFINICIONES Ahora formalizamos el entorno del diseño automatizado de mecanismos. Definición 1. En un entorno de diseño de mecanismos automatizados, se nos proporciona: • un conjunto finito de resultados O; • un conjunto finito de N agentes; • para cada agente i, 1. un conjunto finito de tipos Θi, 2. una distribución de probabilidad γi sobre Θi (en el caso de tipos correlacionados, hay una única distribución conjunta γ sobre Θ1 × . . . × ΘN), y 3. una función de utilidad ui: Θi × O → R; 1 • Una función objetivo cuya expectativa el diseñador desea maximizar. Existen muchas posibles funciones objetivo que el diseñador podría tener, por ejemplo, el bienestar social (donde el diseñador busca maximizar la suma de las utilidades de los agentes), o la utilidad mínima de cualquier agente (donde el diseñador busca maximizar la peor utilidad experimentada por cualquier agente). En ambos casos, el diseñador es benevolente, ya que, de alguna manera, el diseñador está buscando la felicidad colectiva de los agentes. Sin embargo, en este documento nos enfocamos en el caso de un diseñador interesado en sí mismo. Un diseñador egoísta solo se preocupa por el resultado elegido (es decir, al diseñador no le importa cómo se relaciona el resultado con las preferencias de los agentes, sino que tiene una preferencia fija sobre los resultados) y sobre los pagos netos realizados por los agentes, que fluyen hacia el diseñador. Definición 2. Un diseñador interesado tiene una función objetivo dada por g(o) + Σ i=1 πi, donde g : O → R indica las preferencias del diseñador sobre los resultados, y πi es el pago realizado por el agente i. En el caso en que g = 0 en todas partes, se dice que el diseñador está maximizando el pago. En el caso en que los pagos no sean posibles, g constituye la función objetivo por sí sola. Ahora definimos los tipos de mecanismos en estudio. Por el principio de revelación, podemos restringir la atención a mecanismos de revelación directa y veraz, donde los agentes informan directamente sus tipos y nunca tienen incentivos para informarlos de manera incorrecta. Definición 3. Consideramos los siguientes tipos de mecanismos: • Un mecanismo determinista sin pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O. • Un mecanismo aleatorio sin pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), donde P(O) es el conjunto de distribuciones de probabilidad sobre O. • Un mecanismo determinista con pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O y, para cada agente i, una función de selección de pagos πi: Θ1 × Θ2 × . . . × ΘN → R, donde πi(θ1, . . . , θN ) da el pago realizado por el agente i cuando los tipos reportados son θ1, . . . , θN. Aunque esto sigue la notación estándar de la teoría de juegos [16], el hecho de que el agente tenga tanto una función de utilidad como un tipo puede resultar confuso. Los tipos codifican las diversas preferencias posibles que el agente pueda tener, y el tipo de los agentes no es conocido por el agregador. La función de utilidad es un conocimiento común, pero debido a que el tipo de agente es un parámetro en la función de utilidad de los agentes, el agregador no puede saber cuál es la utilidad de los agentes sin conocer el tipo de agente. Un mecanismo aleatorio con pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), y para cada agente i, una función de selección de pago πi: Θ1 × Θ2 × . . . × ΘN → R. Hay dos tipos de restricciones para el diseñador al construir el mecanismo. 3.1 Restricciones de <br>racionalidad individual</br> (IR) El primer tipo de restricción es el siguiente. La utilidad de cada agente debe ser al menos tan grande como la utilidad de respaldo de los agentes, es decir, la utilidad que el agente recibiría si no participara en el mecanismo. De lo contrario, ese agente no participaría en el mecanismo, y la participación de ningún agente puede perjudicar el objetivo de los diseñadores del mecanismo, ya que en el peor de los casos, el mecanismo puede ignorar a un agente fingiendo que el agente no está presente. (Además, si no se aplicara tal restricción, el diseñador simplemente podría hacer que los agentes paguen una cantidad infinita). Este tipo de restricción se llama restricción de IR (<br>racionalidad individual</br>). Existen tres posibles restricciones de IR diferentes: ex ante, ex interim y ex post, dependiendo de lo que el agente sabe sobre su propio tipo y los tipos de los demás al decidir si participar en el mecanismo. Ex ante IR significa que el agente participaría si no supiera absolutamente nada (ni siquiera su propio tipo). No estudiaremos este concepto en este documento. Ex interim IR significa que el agente siempre participaría si conociera solo su propio tipo, pero no el de los demás. Ex post IR significa que el agente siempre participaría incluso si conociera el tipo de todos. Definiremos formalmente las dos últimas nociones de IR. Primero, necesitamos formalizar el concepto del resultado de respaldo. Suponemos que la utilidad de respaldo de cada agente es cero para cada uno de sus tipos. Esto se hace sin pérdida de generalidad porque podemos agregar un término constante a la función de utilidad de un agente (para un tipo dado), sin afectar el comportamiento de toma de decisiones de ese agente maximizador de utilidad esperada [16]. Definición 4. En cualquier entorno de diseño de mecanismos automatizados con una restricción de IR, existe un resultado de contingencia o0 ∈ O donde, para cualquier agente i y cualquier tipo θi ∈ Θi, tenemos ui(θi, o0) = 0. (Además, en el caso de un diseñador egoísta, g(o0) = 0). Ahora podemos definir las nociones de <br>racionalidad individual</br>. Definición 5. La <br>racionalidad individual</br> (RI) se define como: • Un mecanismo determinista es ex interim RI si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "nonmanipulable mechanism": {
            "translated_key": "mecanismo no manipulable",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-interested Automated Mechanism Design and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently proposed approach-called automated mechanism design-a mechanism is computed for the preference aggregation setting at hand.",
                "This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike the earlier work on automated mechanism design that studied a benevolent designer, in this paper we study automated mechanism design problems where the designer is self-interested.",
                "In this case, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy.",
                "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy.",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc.",
                "The preference aggregator generally does not know the agents preferences a priori.",
                "Rather, the agents report their preferences to the coordinator.",
                "Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully.",
                "Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen.",
                "Manipulability is a pervasive problem across preference aggregation mechanisms.",
                "A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.)",
                "What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective.",
                "This is the classic setting of mechanism design in game theory.",
                "In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself.",
                "This is the mechanism design setting most relevant to electronic commerce.",
                "In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear.",
                "It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences.",
                "The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments.",
                "The most common such constraint is that of individual rationality (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
                "For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences.",
                "Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it.",
                "Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off.",
                "On the other hand, the designer will not necessarily choose a social welfare maximizing outcome.",
                "For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected.",
                "Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0.",
                "Classical mechanism design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective.",
                "The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]).",
                "However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare.",
                "If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization.",
                "In practice, the designer may also be interested in the outcome per se.",
                "For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical.",
                "For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed.",
                "Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments.",
                "In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand.",
                "This approach addresses all of the downsides listed above.",
                "We formulate the mechanism design problem as an optimization problem.",
                "The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types.",
                "The output is a <br>nonmanipulable mechanism</br> that is optimal with respect to some objective.",
                "This approach is called automated mechanism design.",
                "The automated mechanism design approach has four advantages over the classical approach of designing general mechanisms.",
                "First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare).",
                "Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences.",
                "When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally.",
                "Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types).",
                "Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information.",
                "For example, imagine a company automatically creating its procurement mechanism based on statistical knowledge about its suppliers, rather than using a classical descending procurement auction.",
                "Fourth, the burden of design is shifted from humans to a machine.",
                "However, automated mechanism design requires the mechanism design optimization problem to be solved anew for each setting.",
                "Hence its computational complexity becomes a key issue.",
                "Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6].",
                "In this paper we study the computational complexity of automated mechanism design in the case of a self-interested designer.",
                "This is an important setting for automated mechanism design due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested.",
                "We also show that this problem is closely related to a particular optimal (revenue-maximizing) combinatorial auction design problem. 133 The rest of this paper is organized as follows.",
                "In Section 2, we justify the focus on nonmanipulable mechanisms.",
                "In Section 3, we define the problem we study.",
                "In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it.",
                "In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen.",
                "In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case.",
                "Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2.",
                "JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of automated mechanism design, we should justify our focus on nonmanipulable mechanisms.",
                "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any <br>nonmanipulable mechanism</br>.",
                "This does, however, turn out to be the case: given any mechanism, we can construct a <br>nonmanipulable mechanism</br> whose performance is identical, as follows.",
                "We build an interface layer between the agents and the original mechanism.",
                "The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer.",
                "The resulting outcome is the outcome of the new mechanism.",
                "Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism.",
                "This argument is known in the mechanism design literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22].",
                "However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.)",
                "Given this, we can focus on truthful mechanisms in the rest of the paper. 3.",
                "DEFINITIONS We now formalize the automated mechanism design setting.",
                "Definition 1.",
                "In an automated mechanism design setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize.",
                "There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent).",
                "In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness.",
                "However, in this paper, we focus on the case of a self-interested designer.",
                "A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer.",
                "Definition 2.",
                "A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i.",
                "In the case where g = 0 everywhere, the designer is said to be payment maximizing.",
                "In the case where payments are not possible, g constitutes the objective function by itself.",
                "We now define the kinds of mechanisms under study.",
                "By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them.",
                "Definition 3.",
                "We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing.",
                "The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator.",
                "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 Individual rationality (IR) constraints The first type of constraint is the following.",
                "The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism.",
                "Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.)",
                "This type of constraint is called an IR (individual rationality) constraint.",
                "There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism.",
                "Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type).",
                "We will not study this concept in this paper.",
                "Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others.",
                "Ex post IR means that the agent would always participate even if it knew everybodys type.",
                "We will define the latter two notions of IR formally.",
                "First, we need to formalize the concept of the fallback outcome.",
                "We assume that each agents fallback utility is zero for each one of its types.",
                "This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16].",
                "Definition 4.",
                "In any automated mechanism design setting with an IR constraint, there is a fallback outcome o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)",
                "We can now to define the notions of individual rationality.",
                "Definition 5.",
                "Individual rationality (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
                "A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments.",
                "A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
                "The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle).",
                "For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium.",
                "Definition 6.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known.",
                "Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
                "In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible.",
                "Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report.",
                "If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium.",
                "Definition 7.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth.",
                "Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible. 135 3.3 Automated mechanism design We can now define the computational problem we study.",
                "Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an automated mechanism design setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective.",
                "An interesting special case is the setting where there is only one agent.",
                "In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents.",
                "Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here.",
                "Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here.",
                "This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4.",
                "PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "To demonstrate NPhardness, we reduce from the MINSAT problem.",
                "Definition 9 (MINSAT).",
                "We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|).",
                "We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied.",
                "MINSAT was recently shown to be NP-complete [14].",
                "We can now present our result.",
                "Theorem 1.",
                "Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent payment-maximizing deterministic AMD instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|.",
                "For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the MINSAT solution, and π(θc) = |Θ| if c is satisfied.",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent.",
                "Clearly the agent is better off reporting truthfully, for a total utility of 0.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type.",
                "Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the IR constraint, the maximum payment we can extract from any type θv is |Θ|.",
                "Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.)",
                "Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1.",
                "It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible.",
                "However, it does not yet imply hardness for the special case where payments are not possible.",
                "We will prove hardness in this case in the next section. 5.",
                "SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "Theorem 2.",
                "Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent self-interested deterministic AMD without payments instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1.",
                "Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v).",
                "For every c ∈ C that is satisfied in the MINSAT solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ .",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "The only other outcome that the mechanism is allowed to choose under the IR constraint is o0.",
                "This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}.",
                "We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|.",
                "For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).)",
                "Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes.",
                "It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Both of our hardness results relied on the constraint that the mechanism should be deterministic.",
                "In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6.",
                "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of self-interested AMD tractable through linear programming, for any constant number of agents.",
                "Theorem 3.",
                "Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated.",
                "Proof.",
                "Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}.",
                "The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.)",
                "First, we show the IR constraints.",
                "For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
                "For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
                "Now, we show the solution concept constraints.",
                "For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
                "Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
                "All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
                "As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents.",
                "Thus the problem is solvable in polynomial time. 7.",
                "IMPLICATIONS FOR AN OPTIMAL COMBINATORIAL AUCTION DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated mechanism design for a self-interested designer on designing optimal combinatorial auctions.",
                "Consider a combinatorial auction with a set S of items for sale.",
                "For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi.",
                "The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.)",
                "The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18].",
                "However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25].",
                "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of complementarity and no substitutability has been solved recently [1].)",
                "Suppose we have free disposal-items can be thrown away at no cost.",
                "Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.)",
                "Definition 10.",
                "Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
                "We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item.",
                "The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type.",
                "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the payment maximizing AMD problem!",
                "Theorem 4.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types.",
                "Proof.",
                "The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming.",
                "To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal combinatorial auction design problem instance with a single bidder with best-only preferences.",
                "For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance).",
                "Let the expected revenue target value be the same in both instances.",
                "We show the instances are equivalent.",
                "First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function.",
                "Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.)",
                "Let the payment functions be the same in both instances.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same.",
                "It follows that there exists a solution to the optimal auction design instance.",
                "Now suppose there exists a solution to the optimal auction design instance.",
                "By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item.",
                "Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type.",
                "If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type.",
                "Let the payment functions be the same.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same.",
                "It follows that there exists a solution to the AMD instance.",
                "Fortunately, we can also carry through the easiness result for randomized mechanisms to this combinatorial auction setting-giving us one of the few known polynomial-time algorithms for an optimal combinatorial auction design problem.",
                "Theorem 5.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.)",
                "Proof.",
                "By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item.",
                "There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations.",
                "Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8.",
                "RELATED RESEARCH ON COMPLEXITY IN MECHANISM DESIGN There has been considerable recent interest in mechanism design in computer science.",
                "Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism.",
                "The closest piece of earlier work studied the complexity of automated mechanism design by a benevolent designer [5, 6].",
                "Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21].",
                "This is related to mechanism design, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments).",
                "Also, there is no explicit reporting of preferences. 9.",
                "CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently emerging approach-called automated mechanism design-a mechanism is computed for the specific preference aggregation setting at hand.",
                "This has several advantages, 139 but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike earlier work on automated mechanism design that studied a benevolent designer, in this paper we studied automated mechanism design problems where the designer is self-interesteda setting much more relevant for electronic commerce.",
                "In this setting, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "These hardness results imply hardness in all more general automated mechanism design settings with a self-interested designer.",
                "The hardness results apply whether the individual rationality (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation.",
                "We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy.",
                "Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy.",
                "Future research includes studying automated mechanism design with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments).",
                "We also want to study the complexity of automated mechanism design in settings where the outcome and type spaces have special structure so they can be represented more concisely.",
                "Finally, we plan to assemble a data set of real-world mechanism design problems-both historical and current-and apply automated mechanism design to those problems. 10.",
                "REFERENCES [1] M. Armstrong.",
                "Optimal multi-object auctions.",
                "Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow.",
                "The property rights doctrine and demand revelation under incomplete information.",
                "In M. Boskin, editor, Economics and human welfare.",
                "New York Academic Press, 1979. [3] C. Avery and T. Hendershott.",
                "Bundling and optimal auctions of multiple products.",
                "Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke.",
                "Multipart pricing of public goods.",
                "Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Automated mechanism design: Complexity results stemming from the single-agent setting.",
                "In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm.",
                "Computational criticisms of the revelation principle.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004.",
                "Short paper.",
                "Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet.",
                "Incentives and incomplete information.",
                "Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker.",
                "Sharing the cost of muliticast transmissions.",
                "Journal of Computer and System Sciences, 63:21-41, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard.",
                "Manipulation of voting schemes.",
                "Econometrica, 41:587-602, 1973. [11] T. Groves.",
                "Incentives in teams.",
                "Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri.",
                "Vickrey prices and shortest paths: What is an edge worth?",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan.",
                "A polynomial algorithm in linear programming.",
                "Soviet Math.",
                "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani.",
                "The minimum satisfiability problem.",
                "SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham.",
                "Truth revelation in rapid, approximately efficient combinatorial auctions.",
                "Journal of the ACM, 49(5):577-602, 2002.",
                "Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [17] E. S. Maskin and J. Riley.",
                "Optimal multi-unit auctions.",
                "In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335.",
                "Clarendon Press, Oxford, 1989. [18] R. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen.",
                "Computationally feasible VCG mechanisms.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behavior, 35:166-196, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden.",
                "Designing networks for selfish users is hard.",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm.",
                "Issues in computational Vickrey auctions.",
                "International Journal of Electronic Commerce, 4(3):107-129, 2000.",
                "Special Issue on 140 Applying Intelligent Agents for Electronic Commerce.",
                "A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite.",
                "Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions.",
                "Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey.",
                "Counterspeculation, auctions, and competitive sealed tenders.",
                "Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra.",
                "Research problems in combinatorial auctions.",
                "Mimeo, version Oct. 29, 2001. 141"
            ],
            "original_annotated_samples": [
                "The output is a <br>nonmanipulable mechanism</br> that is optimal with respect to some objective.",
                "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any <br>nonmanipulable mechanism</br>.",
                "This does, however, turn out to be the case: given any mechanism, we can construct a <br>nonmanipulable mechanism</br> whose performance is identical, as follows."
            ],
            "translated_annotated_samples": [
                "La salida es un <br>mecanismo no manipulable</br> que es óptimo con respecto a algún objetivo.",
                "Después de todo, no es inmediatamente obvio que no haya mecanismos manipulables que, incluso cuando los agentes informan estratégicamente sus tipos y, por lo tanto, a veces de manera no veraz, aún logren mejores resultados (según el objetivo que usemos) que cualquier <br>mecanismo no manipulable</br>.",
                "Sin embargo, resulta ser el caso que, dado cualquier mecanismo, podemos construir un <br>mecanismo no manipulable</br> cuyo rendimiento es idéntico, de la siguiente manera."
            ],
            "translated_text": "Diseño de mecanismos automatizados de interés propio e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les resulte más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente propuesto, llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración de agregación de preferencias actual. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre el diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo. En este caso, al centro solo le importa qué resultado se elige y qué pagos se le hacen. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este contexto, demostramos que el diseño de mecanismos deterministas óptimos es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Luego mostramos cómo permitir la aleatorización en el mecanismo hace que los problemas en este entorno sean computacionalmente fáciles. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (maximizadora de ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar una subasta determinista óptima es NP-completo, pero diseñar una subasta aleatoria óptima es fácil. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Teoría 1. En entornos multiagentes, a menudo se debe elegir un resultado en función de las preferencias informadas por un grupo de agentes. Tales resultados podrían ser presidentes potenciales, planes conjuntos, asignaciones de bienes o recursos, etc. El agregador de preferencias generalmente no conoce las preferencias de los agentes de antemano. Más bien, los agentes informan sus preferencias al coordinador. Desafortunadamente, un agente puede tener un incentivo para informar incorrectamente sus preferencias con el fin de engañar al mecanismo y lograr que seleccione un resultado que sea más deseable para el agente que el resultado que se seleccionaría si el agente revelara sus preferencias de manera honesta. Tal manipulación es indeseable porque los mecanismos de agregación de preferencias están diseñados para agrupar las preferencias de una manera socialmente deseable, y si los agentes revelan sus preferencias de manera insincera, se podría elegir un resultado socialmente indeseable. La manipulabilidad es un problema generalizado en los mecanismos de agregación de preferencias. Un resultado negativo seminal, el teorema de Gibbard-Satterthwaite, muestra que bajo cualquier esquema de agregación de preferencias no dictatorial, si hay al menos 3 posibles resultados, existen preferencias bajo las cuales un agente está mejor reportando falsamente [10, 23]. (Un esquema de agregación de preferencias se llama dictatorial si uno de los agentes dicta el resultado sin importar las preferencias que reporten los otros agentes). Lo que le gustaría hacer al agregador es diseñar un mecanismo de agregación de preferencias para que 1) los agentes interesados reporten sus preferencias de manera veraz, y 2) el mecanismo elija un resultado que sea deseable desde la perspectiva de algún objetivo. Esta es la configuración clásica del diseño de mecanismos en la teoría de juegos. En este documento, estudiamos el caso en el que el diseñador actúa por interés propio, es decir, al diseñador no le importa directamente cómo se relaciona el resultado con las preferencias de los agentes, sino que está más preocupado por su propia agenda sobre cuál resultado debería ser elegido y en maximizar los pagos para sí mismo. Este es el entorno de diseño de mecanismos más relevante para el comercio electrónico. En el caso en que el diseñador del mecanismo esté interesado en maximizar alguna noción de bienestar social, la importancia de recopilar las preferencias de los agentes es clara. Quizás sea menos obvio por qué deberían ser recopilados cuando el diseñador está interesado en sí mismo y, por lo tanto, su objetivo no está directamente relacionado con las preferencias de los agentes. La razón de esto es que a menudo las preferencias de los agentes imponen límites en cómo el diseñador elige el resultado y los pagos. La restricción más común de este tipo es la de racionalidad individual (RI), lo que significa que el mecanismo no puede dejar a ningún agente en una situación peor a la que hubiera estado si no hubiera participado en el mecanismo. Por ejemplo, en el contexto del diseño óptimo de subastas, el diseñador (subastador) solo se preocupa por cuántos ingresos se recaudan, y no en sí mismo por cuán bien la asignación del bien (o bienes) corresponde a las preferencias de los agentes. Sin embargo, el diseñador no puede obligar a un agente a pagar más de lo que valora el paquete de bienes asignado a él. Por lo tanto, incluso un diseñador interesado en sí mismo elegirá un resultado que beneficie razonablemente a los agentes. Por otro lado, el diseñador no necesariamente elegirá un resultado que maximice el bienestar social. Por ejemplo, si el diseñador siempre elige un resultado que maximiza el bienestar social con respecto a las preferencias informadas, y obliga a cada agente a pagar la diferencia entre la utilidad que tiene ahora y la utilidad que habría tenido si no hubiera participado en el mecanismo, es fácil ver que los agentes pueden tener un incentivo para informar incorrectamente sus preferencias, lo que puede llevar realmente a recaudar menos ingresos. De hecho, uno de los resultados contraintuitivos de la teoría del diseño de subastas óptimas es que a veces el bien se asigna a nadie incluso cuando el subastador tiene un precio de reserva de 0. El diseño de mecanismos clásicos proporciona algunos mecanismos generales, que, bajo ciertas suposiciones, satisfacen alguna noción de no manipulabilidad y maximizan algún objetivo. La ventaja de estos mecanismos es que no dependen de información (incluso probabilística) sobre las preferencias de los agentes (por ejemplo, el mecanismo de Vickrey-Clarke-Groves (VCG) [24, 4, 11]), o pueden aplicarse fácilmente a cualquier distribución de probabilidad sobre las preferencias (por ejemplo, el mecanismo dAGVA [8, 2], la subasta de Myerson [18], y la subasta multiunidad de Maskin-Riley [17]). Sin embargo, los mecanismos generales también tienen importantes desventajas: • Los mecanismos generales más famosos y ampliamente aplicables, VCG y dAGVA, solo maximizan el bienestar social. Si el diseñador está interesado en sí mismo, como es el caso en muchos entornos de comercio electrónico, estos mecanismos no maximizan el objetivo del diseñador. • Los mecanismos generales que se centran en un diseñador interesado en sí mismo solo son aplicables en entornos muy restringidos, como la subasta de maximización de ingresos esperados de Myerson para vender un solo artículo, y la subasta de maximización de ingresos esperados de Maskin y Riley para vender múltiples unidades idénticas de un artículo. • Incluso en los entornos restringidos en los que se aplican estos mecanismos, solo permiten la maximización de pagos. En la práctica, el diseñador también puede estar interesado en el resultado en sí mismo. Por ejemplo, a un subastador le puede importar qué postor recibe el artículo. • A menudo se asume que los pagos laterales pueden ser utilizados para adaptar los incentivos de los agentes, pero esto no siempre es práctico. Por ejemplo, en los mercados electrónicos basados en trueque, como Recipco, firstbarter.com, BarterOne e Intagio, no se permiten los pagos laterales. Además, entre los agentes de software, podría ser más deseable construir mecanismos que no dependan de la capacidad de realizar pagos, ya que muchos agentes de software no cuentan con la infraestructura para hacer pagos. Por el contrario, seguimos un enfoque reciente donde el mecanismo se diseña automáticamente para el problema específico en cuestión. Este enfoque aborda todos los inconvenientes mencionados anteriormente. Formulamos el problema de diseño de mecanismos como un problema de optimización. La entrada se caracteriza por el número de agentes, los posibles tipos de agentes (preferencias) y las distribuciones previas de los agregadores sobre los tipos de agentes. La salida es un <br>mecanismo no manipulable</br> que es óptimo con respecto a algún objetivo. Este enfoque se llama diseño de mecanismos automatizado. El enfoque de diseño de mecanismos automatizado tiene cuatro ventajas sobre el enfoque clásico de diseñar mecanismos generales. Primero, se puede utilizar incluso en entornos que no cumplen con las suposiciones de los mecanismos clásicos (como la disponibilidad de pagos laterales o que el objetivo sea el bienestar social). Segundo, puede permitir a uno eludir resultados de imposibilidad (como el teorema de Gibbard-Satterthwaite) que establecen que no existe un mecanismo que sea deseable para todas las preferencias. Cuando el mecanismo está diseñado para la configuración actual, no importa que no funcione de manera más general. Tercero, puede generar mecanismos mejores (en términos de garantías de no manipulabilidad más sólidas y/o mejores resultados) que los mecanismos clásicos porque el mecanismo aprovecha las particularidades del entorno (la información probabilística que el diseñador tiene sobre los tipos de agentes). Dada la gran cantidad de información que las partes tienen entre sí hoy en día, es probable que este enfoque conduzca a ahorros enormes en comparación con los mecanismos clásicos, que en su mayoría ignoran esa información. Por ejemplo, imagina una empresa creando automáticamente su mecanismo de adquisiciones basado en el conocimiento estadístico sobre sus proveedores, en lugar de utilizar una subasta de adquisiciones descendente clásica. Cuarto, la carga del diseño se traslada de los humanos a una máquina. Sin embargo, el diseño automatizado de mecanismos requiere que el problema de optimización del diseño del mecanismo se resuelva de nuevo para cada configuración. Por lo tanto, su complejidad computacional se convierte en un tema clave. Investigaciones previas han estudiado esta pregunta para diseñadores benevolentes que desean maximizar, por ejemplo, el bienestar social [5, 6]. En este artículo estudiamos la complejidad computacional del diseño automatizado de mecanismos en el caso de un diseñador con interés propio. Esta es una configuración importante para el diseño de mecanismos automatizados debido a la escasez de mecanismos generales en esta área, y al hecho de que en la mayoría de las configuraciones de comercio electrónico el diseñador actúa en su propio interés. También demostramos que este problema está estrechamente relacionado con un problema de diseño de subasta combinatoria óptima (maximización de ingresos) particular. El resto de este documento está organizado de la siguiente manera. En la Sección 2, justificamos el enfoque en mecanismos no manipulables. En la Sección 3, definimos el problema que estudiamos. En la Sección 4, demostramos que diseñar un mecanismo determinista óptimo es NP-completo incluso cuando al diseñador solo le importan los pagos que recibe. En la Sección 5, demostramos que diseñar un mecanismo determinista óptimo también es NP-completo cuando los pagos no son posibles y el diseñador solo está interesado en el resultado elegido. En la Sección 6, demostramos que un mecanismo óptimo aleatorizado puede ser diseñado en tiempo polinómico incluso en el caso general. Finalmente, en la Sección 7, demostramos que para diseñar subastas combinatorias óptimas bajo preferencias de mejor opción solamente, nuestros resultados sobre AMD implican que este problema es NP-completo para subastas determinísticas, pero sencillo para subastas aleatorias. 2. JUSTIFICANDO EL ENFOQUE EN MECANISMOS NO MANIPULABLES Antes de definir el problema computacional del diseño automatizado de mecanismos, debemos justificar nuestro enfoque en mecanismos no manipulables. Después de todo, no es inmediatamente obvio que no haya mecanismos manipulables que, incluso cuando los agentes informan estratégicamente sus tipos y, por lo tanto, a veces de manera no veraz, aún logren mejores resultados (según el objetivo que usemos) que cualquier <br>mecanismo no manipulable</br>. Sin embargo, resulta ser el caso que, dado cualquier mecanismo, podemos construir un <br>mecanismo no manipulable</br> cuyo rendimiento es idéntico, de la siguiente manera. Construimos una capa de interfaz entre los agentes y el mecanismo original. Los agentes informan sus preferencias (o tipos) a la capa de interfaz; posteriormente, la capa de interfaz introduce en el mecanismo original los tipos que los agentes habrían informado estratégicamente al mecanismo original, si sus tipos fueran los declarados a la capa de interfaz. El resultado resultante es el resultado del nuevo mecanismo. Dado que la capa de interfaz actúa estratégicamente en nombre de cada agente, nunca hay un incentivo para informar falsamente a la capa de interfaz; por lo tanto, los tipos informados por la capa de interfaz son los tipos estratégicos que se habrían informado sin la capa de interfaz, por lo que los resultados son exactamente como habrían sido con el mecanismo original. Este argumento es conocido en la literatura de diseño de mecanismos como el principio de revelación [16]. (Existen dificultades computacionales al aplicar el principio de revelación en espacios de resultados y tipos combinatorios grandes [7, 22]). Sin embargo, dado que aquí nos enfocamos en espacios de resultados y tipos representados de forma plana, esto no es una preocupación aquí. Dado esto, podemos centrarnos en mecanismos veraces en el resto del documento. 3. DEFINICIONES Ahora formalizamos el entorno del diseño automatizado de mecanismos. Definición 1. En un entorno de diseño de mecanismos automatizados, se nos proporciona: • un conjunto finito de resultados O; • un conjunto finito de N agentes; • para cada agente i, 1. un conjunto finito de tipos Θi, 2. una distribución de probabilidad γi sobre Θi (en el caso de tipos correlacionados, hay una única distribución conjunta γ sobre Θ1 × . . . × ΘN), y 3. una función de utilidad ui: Θi × O → R; 1 • Una función objetivo cuya expectativa el diseñador desea maximizar. Existen muchas posibles funciones objetivo que el diseñador podría tener, por ejemplo, el bienestar social (donde el diseñador busca maximizar la suma de las utilidades de los agentes), o la utilidad mínima de cualquier agente (donde el diseñador busca maximizar la peor utilidad experimentada por cualquier agente). En ambos casos, el diseñador es benevolente, ya que, de alguna manera, el diseñador está buscando la felicidad colectiva de los agentes. Sin embargo, en este documento nos enfocamos en el caso de un diseñador interesado en sí mismo. Un diseñador egoísta solo se preocupa por el resultado elegido (es decir, al diseñador no le importa cómo se relaciona el resultado con las preferencias de los agentes, sino que tiene una preferencia fija sobre los resultados) y sobre los pagos netos realizados por los agentes, que fluyen hacia el diseñador. Definición 2. Un diseñador interesado tiene una función objetivo dada por g(o) + Σ i=1 πi, donde g : O → R indica las preferencias del diseñador sobre los resultados, y πi es el pago realizado por el agente i. En el caso en que g = 0 en todas partes, se dice que el diseñador está maximizando el pago. En el caso en que los pagos no sean posibles, g constituye la función objetivo por sí sola. Ahora definimos los tipos de mecanismos en estudio. Por el principio de revelación, podemos restringir la atención a mecanismos de revelación directa y veraz, donde los agentes informan directamente sus tipos y nunca tienen incentivos para informarlos de manera incorrecta. Definición 3. Consideramos los siguientes tipos de mecanismos: • Un mecanismo determinista sin pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O. • Un mecanismo aleatorio sin pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), donde P(O) es el conjunto de distribuciones de probabilidad sobre O. • Un mecanismo determinista con pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O y, para cada agente i, una función de selección de pagos πi: Θ1 × Θ2 × . . . × ΘN → R, donde πi(θ1, . . . , θN ) da el pago realizado por el agente i cuando los tipos reportados son θ1, . . . , θN. Aunque esto sigue la notación estándar de la teoría de juegos [16], el hecho de que el agente tenga tanto una función de utilidad como un tipo puede resultar confuso. Los tipos codifican las diversas preferencias posibles que el agente pueda tener, y el tipo de los agentes no es conocido por el agregador. La función de utilidad es un conocimiento común, pero debido a que el tipo de agente es un parámetro en la función de utilidad de los agentes, el agregador no puede saber cuál es la utilidad de los agentes sin conocer el tipo de agente. Un mecanismo aleatorio con pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), y para cada agente i, una función de selección de pago πi: Θ1 × Θ2 × . . . × ΘN → R. Hay dos tipos de restricciones para el diseñador al construir el mecanismo. 3.1 Restricciones de racionalidad individual (IR) El primer tipo de restricción es el siguiente. La utilidad de cada agente debe ser al menos tan grande como la utilidad de respaldo de los agentes, es decir, la utilidad que el agente recibiría si no participara en el mecanismo. De lo contrario, ese agente no participaría en el mecanismo, y la participación de ningún agente puede perjudicar el objetivo de los diseñadores del mecanismo, ya que en el peor de los casos, el mecanismo puede ignorar a un agente fingiendo que el agente no está presente. (Además, si no se aplicara tal restricción, el diseñador simplemente podría hacer que los agentes paguen una cantidad infinita). Este tipo de restricción se llama restricción de IR (racionalidad individual). Existen tres posibles restricciones de IR diferentes: ex ante, ex interim y ex post, dependiendo de lo que el agente sabe sobre su propio tipo y los tipos de los demás al decidir si participar en el mecanismo. Ex ante IR significa que el agente participaría si no supiera absolutamente nada (ni siquiera su propio tipo). No estudiaremos este concepto en este documento. Ex interim IR significa que el agente siempre participaría si conociera solo su propio tipo, pero no el de los demás. Ex post IR significa que el agente siempre participaría incluso si conociera el tipo de todos. Definiremos formalmente las dos últimas nociones de IR. Primero, necesitamos formalizar el concepto del resultado de respaldo. Suponemos que la utilidad de respaldo de cada agente es cero para cada uno de sus tipos. Esto se hace sin pérdida de generalidad porque podemos agregar un término constante a la función de utilidad de un agente (para un tipo dado), sin afectar el comportamiento de toma de decisiones de ese agente maximizador de utilidad esperada [16]. Definición 4. En cualquier entorno de diseño de mecanismos automatizados con una restricción de IR, existe un resultado de contingencia o0 ∈ O donde, para cualquier agente i y cualquier tipo θi ∈ Θi, tenemos ui(θi, o0) = 0. (Además, en el caso de un diseñador egoísta, g(o0) = 0). Ahora podemos definir las nociones de racionalidad individual. Definición 5. La racionalidad individual (RI) se define como: • Un mecanismo determinista es ex interim RI si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0. Un mecanismo aleatorio es ex interim IR si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • Un mecanismo determinista es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 No aleatorizamos sobre los pagos porque mientras los agentes y el diseñador sean neutrales al riesgo con respecto a los pagos, es decir, su utilidad es lineal en los pagos, no hay razón para aleatorizar sobre los pagos. Un mecanismo aleatorio es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 3.2 Restricciones de compatibilidad de incentivos (IC) El segundo tipo de restricción establece que los agentes nunca deben tener un incentivo para informar incorrectamente su tipo (como se justificó anteriormente mediante el principio de revelación). Para este tipo de restricción, las dos variantes más comunes (o conceptos de solución) son la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash. Definición 6. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en estrategias dominantes si decir la verdad siempre es óptimo incluso cuando los tipos reportados por los otros agentes ya son conocidos. Formalmente, para cualquier agente i, cualquier vector de tipos (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ). En el caso de mecanismos aleatorios tenemos Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. Por lo tanto, en la implementación de estrategias dominantes, decir la verdad es óptimo independientemente de lo que informen los otros agentes. Si es óptimo solo dado que los otros agentes son veraces, y dado que uno no conoce los tipos de los otros agentes, tenemos implementación en equilibrio de Bayes-Nash. Definición 7. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en equilibrio de Bayes-Nash si decir la verdad siempre es óptimo para un agente cuando ese agente aún no sabe nada sobre los tipos de los otros agentes, y los otros agentes están diciendo la verdad. Formalmente, para cualquier agente i, cualquier tipo θi ∈ Θi, y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )]. En el caso de mecanismos aleatorios tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 135 3.3 Diseño de mecanismos automatizados Ahora podemos definir el problema computacional que estudiamos. Definición 8. (DISEÑO DE MECANISMOS AUTOMATIZADOS (AMD)) Se nos da: • un entorno de diseño de mecanismos automatizados, • una noción de IR (ex interim, ex post, o ninguna), • un concepto de solución (estrategias dominantes o Bayes-Nash), • si los pagos son posibles, • si la aleatorización es posible, • (en la variante de decisión del problema) un valor objetivo G. Se nos pregunta si existe un mecanismo del tipo especificado (en términos de pagos y aleatorización) que satisfaga tanto la noción de IR como el concepto de solución, y proporcione un valor esperado de al menos G para el objetivo. Un caso especial interesante es aquel en el que solo hay un agente. En este caso, el agente informante siempre sabe todo lo que hay que saber sobre los otros tipos de agentes, porque no hay otros agentes. Dado que el IR ex post y el IR ex interim solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de IR coinciden aquí. Además, dado que la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de solución coinciden aquí. Esta observación resultará ser una herramienta útil para demostrar resultados de dificultad: si demostramos dificultad computacional en el escenario de un solo agente, esto implica inmediatamente dificultad para ambos conceptos de IR, para ambos conceptos de solución, para cualquier número de agentes. 4. En esta sección demostramos que es NP-completo diseñar un mecanismo determinístico que maximice la suma esperada de los pagos recolectados de los agentes. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Para demostrar la NP-dureza, reducimos desde el problema MINSAT. Definición 9 (MINSAT). Se nos da una fórmula φ en forma normal conjuntiva, representada por un conjunto de variables booleanas V y un conjunto de cláusulas C, y un entero K (K < |C|). Se nos pregunta si existe una asignación a las variables en V tal que se satisfacen a lo sumo K cláusulas en φ. MINSAT fue recientemente demostrado como NP-completo [14]. Ahora podemos presentar nuestro resultado. Teorema 1. El problema determinista de maximización de pagos de AMD es NP-completo, incluso para un solo agente, incluso con una distribución uniforme de tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista de maximización de pagos de un solo agente. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V } ∪ {−v : v ∈ V }. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Sea l ∈ c denota que el literal l ocurre en la cláusula c. Entonces, la función de utilidad de los agentes está dada por u(θc, ol) = |Θ| + 1 para todo l ∈ L con l ∈ c; u(θc, ol) = 0 para todo l ∈ L con l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc) = 0 para todo c ∈ C con c = c; u(θv, ol) = |Θ| para todo l ∈ L con v(l) = v; u(θv, ol) = 0 para todo l ∈ L con v(l) = v; u(θv, oc) = 0 para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ|, donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v) y π(θv) = |Θ|. Para cada c ∈ C, sea o(θc) = oc; sea π(θc) = |Θ| + 1 si c no está satisfecha en la solución MINSAT, y π(θc) = |Θ| si c está satisfecha. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es θv, entonces cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivo para informar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Porque además, ningún tipo que no sea θc conduce al resultado oc, informar cualquier otro tipo dará como resultado una utilidad de 0, mientras que aún se requiere un pago de al menos |Θ| por parte del agente. Claramente, el agente está mejor reportando honestamente, para una utilidad total de 0. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), el pago esperado de este mecanismo es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o y una función de pago π. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. Entonces, la utilidad que el agente obtiene del resultado dado para este tipo es 0, y por lo tanto, según la IR, no se puede extraer ningún pago del agente para este tipo. Dado que, nuevamente por IR, el pago máximo que se puede extraer para cualquier otro tipo es |Θ| + 1, se sigue que el pago esperado máximo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo cual contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o−v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por la restricción de IR, el pago máximo que podemos extraer de cualquier tipo θv es |Θ|. Dado que no puede haber incentivos para que el agente informe falsamente, para cualquier cláusula c satisfecha por la asignación dada, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ|. (Pues si extrajéramos más de este tipo, la utilidad del agente en este caso sería menor que 1; y si v es la variable que satisface c en la asignación, de modo que o(θv) = ol donde l ocurre en c, entonces al agente le convendría más informar θv en lugar del informe veraz θc, para obtener un resultado que valga |Θ|+1 para él mientras tiene que pagar como máximo |Θ|.) Finalmente, para cualquier cláusula insatisfecha c, según la restricción de IR, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ| + 1. Se deduce que el pago esperado de nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia de MINSAT. Dado que AMD, que maximiza el pago, es solo un caso especial de AMD para un diseñador egoísta en el que el diseñador no tiene preferencias sobre el resultado elegido, esto implica inmediatamente dificultades para el caso general de AMD para un diseñador egoísta en el que los pagos son posibles. Sin embargo, esto aún no implica dureza para el caso especial donde los pagos no son posibles. Demostraremos la dificultad en este caso en la próxima sección. 5. En esta sección demostramos que es NP-completo diseñar un mecanismo determinista que maximice la expectativa del objetivo del diseñador cuando no son posibles los pagos. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Teorema 2. Sin pagos, el diseño determinista de AMD para un diseñador egoísta es NP-completo, incluso para un solo agente, incluso con una distribución uniforme sobre los tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista auto-interesada de un solo agente sin pagos. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L} ∪ {o∗}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V} ∪ {−v : v ∈ V}. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Deje que l ∈ c denote que el literal l ocurre en la cláusula c. Luego, deje que la función de utilidad de los agentes esté dada por u(θc, ol) = 2 para todo l ∈ L con l ∈ c; u(θc, ol) = −1 para todo l ∈ L con l /∈ c; u(θc, oc) = 2; u(θc, oc) = −1 para todo c ∈ C con c = c; u(θc, o∗) = 1; u(θv, ol) = 1 para todo l ∈ L con v(l) = v; u(θv, ol) = −1 para todo l ∈ L con v(l) = v; u(θv, oc) = −1 para todo c ∈ C; u(θv, o∗) = −1. Que la función objetivo de los diseñadores esté dada por g(o∗ ) = |Θ|+1; g(ol) = |Θ| para todo l ∈ L; g(oc) = |Θ| para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ| , donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v). Para cada c ∈ C que se cumpla en la solución MINSAT, sea o(θc) = oc; para cada c ∈ C no satisfecho, sea o(θc) = o∗. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es algún θv, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para reportar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Debido a que tampoco ningún tipo conduce al resultado oc, no hay ningún resultado que el mecanismo seleccione que le daría al agente una utilidad mayor a 1 para el tipo θc, y por lo tanto el agente no tiene incentivo para informar falsamente. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), entonces el valor esperado de la función objetivo de los diseñadores es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. El único otro resultado que el mecanismo puede elegir bajo la restricción de IR es o0. Esto tiene un valor objetivo de 0, y dado que el valor más alto que la función objetivo alcanza es |Θ| + 1, se sigue que el valor esperado máximo de la función objetivo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo que contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o-v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por lo anterior, para cualquier tipo θv, el valor de la función objetivo en este mecanismo será |Θ|. Para cualquier cláusula c satisfecha por la asignación dada, el valor de la función objetivo en el caso en que el agente informe el tipo θc será como máximo |Θ|. (Esto se debe a que no podemos elegir el resultado o∗ para dicho tipo, ya que en este caso el agente tendría un incentivo para informar θv en su lugar, donde v es la variable que satisface c en la asignación (de modo que o(θv) = ol donde l ocurre en c).) Finalmente, para cualquier cláusula insatisfecha c, el valor máximo que la función objetivo puede alcanzar en el caso en que el agente informa el tipo θc es |Θ| + 1, simplemente porque este es el valor más grande que la función alcanza en cualquier momento. Se deduce que el valor esperado de la función objetivo para nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas 137 satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia MINSAT. Ambos de nuestros resultados de dureza se basaron en la restricción de que el mecanismo debería ser determinista. En la siguiente sección, mostramos que la dificultad del diseño desaparece cuando permitimos la aleatorización en el mecanismo. 6. La aleatorización de AMD para un diseñador interesado en sí mismo es fácil. Ahora mostramos cómo permitir la aleatorización sobre los resultados hace que el problema de AMD auto-interesado sea manejable a través de la programación lineal, para cualquier número constante de agentes. Teorema 3. El AMD aleatorio con interés propio con un número constante de agentes es resoluble en tiempo polinómico mediante programación lineal, tanto con pagos como sin pagos, tanto para IR ex post como ex interim, y tanto para la implementación en estrategias dominantes como para la implementación en equilibrio de Bayes-Nash, incluso si los tipos están correlacionados. Prueba. Dado que los programas lineales pueden resolverse en tiempo polinómico [13], todo lo que necesitamos demostrar es que el número de variables y ecuaciones en nuestro programa es polinomial para cualquier número constante de agentes, es decir, exponencial solo en N. En todo momento, para determinar el tamaño del programa lineal, consideremos T = maxi{|Θi|}. Las variables de nuestro programa lineal serán las probabilidades (p(θ1, θ2, . . . , θN ))(o) (como máximo TN |O| variables) y los pagos πi(θ1, θ2, . . . , θN ) (como máximo NTN variables). (Mostramos el programa lineal para el caso en que los pagos son posibles; el caso sin pagos se obtiene fácilmente de esto simplemente omitiendo todas las variables de pago en el programa, o agregando restricciones adicionales que obliguen a los pagos a ser 0). Primero, mostramos las restricciones de IR. Para el IR ex post, agregamos las siguientes restricciones (como máximo NTN) al LP: • Para cada i ∈ {1, 2, . . . , N}, y para cada (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , agregamos ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0. Para el ex interino IR, agregamos las siguientes restricciones (como máximo NT) al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada θi ∈ Θi, agregamos θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0. Ahora, mostramos las restricciones del concepto de solución. Para la implementación en estrategias dominantes, agregamos las siguientes (a lo sumo NTN+1) restricciones al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ). Finalmente, para la implementación en el equilibrio de Bayes-Nash, agregamos las siguientes (a lo sumo NT2) restricciones al LP: • Para cada i ∈ {1, 2, ..., N}, para cada θi ∈ Θi, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )). Todo lo que queda por hacer es dar la expresión que el diseñador busca maximizar, que es: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )). Como indicamos, el número de variables y restricciones es exponencial solo en N, por lo tanto, el programa lineal tiene un tamaño polinómico para un número constante de agentes. Por lo tanto, el problema es resoluble en tiempo polinómico. IMPLICACIONES PARA UN PROBLEMA DE DISEÑO DE SUBASTA COMBINATORIA ÓPTIMA En esta sección, demostraremos algunas consecuencias interesantes del problema de diseño de mecanismos automatizados para un diseñador interesado en sí mismo en el diseño de subastas combinatorias óptimas. Considera una subasta combinatoria con un conjunto S de artículos en venta. Para cualquier conjunto B ⊆ S, dejemos que ui(θi, B) sea la utilidad del postor i al recibir el conjunto B cuando el tipo del postor es θi. El problema de diseño de subasta óptima consiste en especificar las reglas de la subasta de manera que se maximice los ingresos esperados para el subastador. (Por el principio de revelación, sin pérdida de generalidad, podemos asumir que la subasta es veraz). El problema de diseño de subasta óptima se resuelve para el caso de un solo artículo mediante la famosa subasta de Myerson [18]. Sin embargo, el diseño de subastas óptimas en subastas combinatorias es un problema de investigación abierto reconocido [3, 25]. El problema está abierto incluso si solo hay dos artículos en venta. (El caso de dos artículos con una forma muy especial de complementariedad y sin sustituibilidad ha sido resuelto recientemente [1].) Supongamos que tenemos disposición libre: los artículos pueden ser desechados sin costo alguno. Además, supongamos que las preferencias de los postores tienen la siguiente estructura: cuando un postor recibe un conjunto de artículos, la utilidad del postor por ese conjunto está determinada únicamente por el mejor artículo en el conjunto. (Enfatizamos que qué artículo es el mejor puede depender del tipo de postor). Definición 10. Se dice que el postor i tiene preferencias solo por lo mejor sobre paquetes de artículos si existe una función vi: Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s). Hacemos la siguiente observación útil en este contexto: no tiene sentido otorgarle a un postor más de un artículo. La razón es que si el postor está informando honestamente, quitarle todos los artículos menos el de mayor valor no perjudicará al postor; y, mediante la disposición gratuita, hacerlo solo reducirá el incentivo para que este postor informe falsamente este tipo, cuando en realidad tiene otro tipo. Ahora demostramos que el problema de diseñar una subasta óptima determinista es NP-completo, mediante una reducción del problema AMD de maximización de pagos. Teorema 4. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de artículos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), diseñar la subasta determinística óptima es NP-completo, incluso para un único postor con una distribución uniforme sobre los tipos. Prueba. El problema está en NP porque podemos generar de manera no determinista una regla de asignación, y luego establecer los pagos utilizando programación lineal. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de AMD determinista que maximiza el pago, con un único agente y una distribución uniforme de tipos, al siguiente problema de diseño de subasta combinatoria óptima con una única postor con preferencias de solo los mejores. Para cada resultado o ∈ O en la instancia de AMD (excepto el resultado o0), que haya un artículo so ∈ S. Que el espacio de tipos sea el mismo, y que v(θi, so) = ui(θi, o) (donde u está especificado en la instancia de AMD). Que el valor objetivo de ingresos esperados sea el mismo en ambas instancias. Mostramos que las instancias son equivalentes. Primero supongamos que existe una solución para la instancia de AMD, dada por una función de resultado y una función de pago. Entonces, si la solución de AMD elige el resultado o para un tipo, en la solución de subasta óptima, asignamos {so} al postor para este tipo. (A menos que o = o0, en cuyo caso asignamos {} al postor). Que las funciones de pago sean las mismas en ambas instancias. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo verdadero) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución óptima de la subasta. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el subastador/diseñador son los mismos. Se deduce que existe una solución para la instancia de diseño de subasta óptima. Ahora supongamos que existe una solución para la instancia de diseño de subasta óptima. Por la observación de que como máximo se puede tener un artículo, podemos asumir sin pérdida de generalidad que la solución nunca asigna más de un artículo. Entonces, si la solución de subasta óptima asigna el artículo al postor para un tipo, en la solución de AMD, permita que el mecanismo elija el resultado o para ese tipo. Si la solución de subasta óptima no asigna nada al postor para un tipo, en la solución AMD, permita que el mecanismo elija el resultado o0 para ese tipo. Que las funciones de pago sean las mismas. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo real) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución AMD. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el diseñador/subastador son los mismos. Se deduce que existe una solución para la instancia de AMD. Afortunadamente, también podemos extender el resultado de facilidad para mecanismos aleatorios a este escenario de subasta combinatoria, lo que nos proporciona uno de los pocos algoritmos de tiempo polinómico conocidos para un problema de diseño óptimo de subasta combinatoria. Teorema 5. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de elementos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), si el número de postores es una constante k, entonces la subasta aleatoria óptima puede ser diseñada en tiempo polinómico. (Para cualquier restricción de IC e IR.) Prueba. Por la observación de que a lo sumo un artículo, podemos sin pérdida de generalidad restringirnos a asignaciones donde cada postor recibe como máximo un artículo. Hay menos de (|S| + 1)k asignaciones de ese tipo, es decir, un número polinómico de asignaciones. Dado que podemos enumerar explícitamente los resultados, simplemente podemos resolver esto como una instancia de AMD que maximiza el pago, con programación lineal. 8. Investigaciones relacionadas sobre la complejidad en el diseño de mecanismos. Ha habido un considerable interés reciente en el diseño de mecanismos en la informática. Parte de ello se ha centrado en cuestiones de complejidad computacional, pero la mayor parte de ese trabajo ha buscado diseñar mecanismos que sean fáciles de ejecutar (por ejemplo, [20, 15, 19, 9, 12]), en lugar de estudiar la complejidad de diseñar el mecanismo. La pieza más cercana de trabajo anterior estudió la complejidad del diseño automatizado de mecanismos por un diseñador benevolente [5, 6]. Roughgarden ha estudiado la complejidad de diseñar una buena topología de red para agentes que eligen egoístamente los enlaces que utilizan [21]. Esto está relacionado con el diseño de mecanismos, pero difiere significativamente en que el diseñador solo tiene un control restringido sobre las reglas del juego porque no hay ninguna parte que pueda imponer el resultado (o pagos laterales). Además, no hay un informe explícito de preferencias. 9. CONCLUSIONES E INVESTIGACIONES FUTURAS A menudo, un resultado debe ser elegido en función de las preferencias informadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les sea más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente emergente llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración específica de agregación de preferencias en cuestión. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo, un entorno mucho más relevante para el comercio electrónico. En este contexto, al centro solo le importa qué resultado se elige y qué pagos se le realizan. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este escenario, demostramos que diseñar un mecanismo determinista óptimo es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Estos resultados de dureza implican dificultad en todos los entornos de diseño de mecanismos automatizados más generales con un diseñador egoísta. Los resultados de dureza se aplican ya sea que las restricciones de racionalidad individual (participación) se apliquen ex interim o ex post, y ya sea que el concepto de solución sea la implementación de estrategias dominantes o la implementación del equilibrio de Bayes-Nash. Luego demostramos que permitir la aleatorización en el mecanismo hace que el problema de diseño en todos estos escenarios sea computacionalmente sencillo. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (que maximiza los ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar un mecanismo determinístico óptimo es NP-completo incluso con un agente, pero diseñar un mecanismo aleatorio óptimo es fácil. La investigación futura incluye estudiar el diseño automatizado de mecanismos con un diseñador interesado en sí mismo en entornos más restringidos, como subastas (donde el objetivo del diseñador puede incluir preferencias sobre qué postor debería recibir el bien, así como los pagos). También queremos estudiar la complejidad del diseño de mecanismos automatizados en entornos donde los espacios de resultados y tipos tienen una estructura especial para que puedan representarse de manera más concisa. Finalmente, planeamos reunir un conjunto de datos de problemas de diseño de mecanismos del mundo real, tanto históricos como actuales, y aplicar el diseño de mecanismos automatizado a esos problemas. 10. REFERENCIAS [1] M. Armstrong. Subastas multi-objetivo óptimas. Revisión de Estudios Económicos, 67:455-481, 2000. [2] K. Arrow. La doctrina de los derechos de propiedad y la revelación de la demanda bajo información incompleta. En M. Boskin, editor, Economía y bienestar humano. New York Academic Press, 1979. [3] C. Avery y T. Hendershott. Agrupación y subastas óptimas de múltiples productos. Revisión de Estudios Económicos, 67:483-497, 2000. [4] E. H. Clarke. Precios escalonados de bienes públicos. Elección Pública, 11:17-33, 1971. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Actas de la 18ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI-02), páginas 103-110, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Diseño de mecanismos automatizados: Resultados de complejidad derivados del entorno de un solo agente. En Actas de la 5ta Conferencia Internacional de Comercio Electrónico (ICEC-03), páginas 17-24, Pittsburgh, PA, EE. UU., 2003. [7] V. Conitzer y T. Sandholm. Críticas computacionales del principio de revelación. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), Nueva York, NY, 2004. Breve ensayo. La versión completa apareció en el taller AAMAS-03 sobre Comercio Electrónico Mediado por Agentes (AMEC). [8] C. d'Aspremont y L. A. Gérard-Varet. Incentivos e información incompleta. Revista de Economía Pública, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou y S. Shenker. Compartiendo el costo de las transmisiones de multidifusión. Revista de Ciencias de la Computación y de Sistemas, 63:21-41, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 2000. [10] A. Gibbard. Manipulación de esquemas de votación. Econometrica, 41:587-602, 1973. [11] T. Groves.\nEconometrica, 41:587-602, 1973. [11] T. Groves. Incentivos en equipos. Econometrica, 41:617-631, 1973. [12] J. Hershberger y S. Suri. Precios de Vickrey y caminos más cortos: ¿Cuánto vale una arista? En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [13] L. Khachiyan. Un algoritmo polinómico en programación lineal. Matemática soviética. Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi y P. Mirchandani. El problema de satisfacibilidad mínimo. Revista SIAM de Matemáticas Discretas, 7(2):275-283, 1994. [15] D. Lehmann, L. I. O'Callaghan y Y. Shoham. Revelación de la verdad en subastas combinatorias rápidas y aproximadamente eficientes. Revista de la ACM, 49(5):577-602, 2002. La versión inicial apareció en las Actas de la Conferencia de Comercio Electrónico de la ACM (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [17] E. S. Maskin y J. Riley. Subastas multiunidad óptimas. En F. Hahn, editor, \"La economía de los mercados faltantes, la información y los juegos\", capítulo 14, páginas 312-335. Clarendon Press, Oxford, 1989. [18] R. Myerson.\nPrensa Clarendon, Oxford, 1989. [18] R. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6:58-73, 1981. [19] N. Nisan y A. Ronen. Mecanismos VCG computacionalmente factibles. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 242-252, Minneapolis, MN, 2000. [20] N. Nisan y A. Ronen. Diseño de mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166-196, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 1999. [21] T. Roughgarden. Diseñar redes para usuarios egoístas es difícil. En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [22] T. Sandholm. Problemas en subastas computacionales de Vickrey. Revista Internacional de Comercio Electrónico, 4(3):107-129, 2000. Número especial sobre la Aplicación de Agentes Inteligentes para el Comercio Electrónico. Una versión corta y temprana apareció en la Segunda Conferencia Internacional sobre Sistemas Multiagente (ICMAS), páginas 299-306, 1996. [23] M. A. Satterthwaite. In Spanish, the translation would be: \"Inmutabilidad estratégica y condiciones de Arrow: teoremas de existencia y correspondencia para procedimientos de votación y funciones de bienestar social.\" Revista de Teoría Económica, 10:187-217, 1975. [24] W. Vickrey. Contrarrestando la especulación, subastas y ofertas selladas competitivas. Revista de Finanzas, 16:8-37, 1961. [25] R. V. Vohra. Problemas de investigación en subastas combinatorias. Mimeo, versión 29 de octubre de 2001. 141 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "statistical knowledge": {
            "translated_key": "conocimiento estadístico",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-interested Automated Mechanism Design and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently proposed approach-called automated mechanism design-a mechanism is computed for the preference aggregation setting at hand.",
                "This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike the earlier work on automated mechanism design that studied a benevolent designer, in this paper we study automated mechanism design problems where the designer is self-interested.",
                "In this case, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy.",
                "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy.",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc.",
                "The preference aggregator generally does not know the agents preferences a priori.",
                "Rather, the agents report their preferences to the coordinator.",
                "Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully.",
                "Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen.",
                "Manipulability is a pervasive problem across preference aggregation mechanisms.",
                "A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.)",
                "What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective.",
                "This is the classic setting of mechanism design in game theory.",
                "In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself.",
                "This is the mechanism design setting most relevant to electronic commerce.",
                "In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear.",
                "It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences.",
                "The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments.",
                "The most common such constraint is that of individual rationality (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
                "For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences.",
                "Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it.",
                "Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off.",
                "On the other hand, the designer will not necessarily choose a social welfare maximizing outcome.",
                "For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected.",
                "Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0.",
                "Classical mechanism design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective.",
                "The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]).",
                "However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare.",
                "If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization.",
                "In practice, the designer may also be interested in the outcome per se.",
                "For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical.",
                "For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed.",
                "Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments.",
                "In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand.",
                "This approach addresses all of the downsides listed above.",
                "We formulate the mechanism design problem as an optimization problem.",
                "The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types.",
                "The output is a nonmanipulable mechanism that is optimal with respect to some objective.",
                "This approach is called automated mechanism design.",
                "The automated mechanism design approach has four advantages over the classical approach of designing general mechanisms.",
                "First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare).",
                "Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences.",
                "When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally.",
                "Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types).",
                "Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information.",
                "For example, imagine a company automatically creating its procurement mechanism based on <br>statistical knowledge</br> about its suppliers, rather than using a classical descending procurement auction.",
                "Fourth, the burden of design is shifted from humans to a machine.",
                "However, automated mechanism design requires the mechanism design optimization problem to be solved anew for each setting.",
                "Hence its computational complexity becomes a key issue.",
                "Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6].",
                "In this paper we study the computational complexity of automated mechanism design in the case of a self-interested designer.",
                "This is an important setting for automated mechanism design due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested.",
                "We also show that this problem is closely related to a particular optimal (revenue-maximizing) combinatorial auction design problem. 133 The rest of this paper is organized as follows.",
                "In Section 2, we justify the focus on nonmanipulable mechanisms.",
                "In Section 3, we define the problem we study.",
                "In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it.",
                "In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen.",
                "In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case.",
                "Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2.",
                "JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of automated mechanism design, we should justify our focus on nonmanipulable mechanisms.",
                "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any nonmanipulable mechanism.",
                "This does, however, turn out to be the case: given any mechanism, we can construct a nonmanipulable mechanism whose performance is identical, as follows.",
                "We build an interface layer between the agents and the original mechanism.",
                "The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer.",
                "The resulting outcome is the outcome of the new mechanism.",
                "Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism.",
                "This argument is known in the mechanism design literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22].",
                "However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.)",
                "Given this, we can focus on truthful mechanisms in the rest of the paper. 3.",
                "DEFINITIONS We now formalize the automated mechanism design setting.",
                "Definition 1.",
                "In an automated mechanism design setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize.",
                "There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent).",
                "In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness.",
                "However, in this paper, we focus on the case of a self-interested designer.",
                "A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer.",
                "Definition 2.",
                "A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i.",
                "In the case where g = 0 everywhere, the designer is said to be payment maximizing.",
                "In the case where payments are not possible, g constitutes the objective function by itself.",
                "We now define the kinds of mechanisms under study.",
                "By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them.",
                "Definition 3.",
                "We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing.",
                "The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator.",
                "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 Individual rationality (IR) constraints The first type of constraint is the following.",
                "The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism.",
                "Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.)",
                "This type of constraint is called an IR (individual rationality) constraint.",
                "There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism.",
                "Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type).",
                "We will not study this concept in this paper.",
                "Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others.",
                "Ex post IR means that the agent would always participate even if it knew everybodys type.",
                "We will define the latter two notions of IR formally.",
                "First, we need to formalize the concept of the fallback outcome.",
                "We assume that each agents fallback utility is zero for each one of its types.",
                "This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16].",
                "Definition 4.",
                "In any automated mechanism design setting with an IR constraint, there is a fallback outcome o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)",
                "We can now to define the notions of individual rationality.",
                "Definition 5.",
                "Individual rationality (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
                "A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments.",
                "A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
                "The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle).",
                "For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium.",
                "Definition 6.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known.",
                "Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
                "In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible.",
                "Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report.",
                "If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium.",
                "Definition 7.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth.",
                "Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible. 135 3.3 Automated mechanism design We can now define the computational problem we study.",
                "Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an automated mechanism design setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective.",
                "An interesting special case is the setting where there is only one agent.",
                "In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents.",
                "Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here.",
                "Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here.",
                "This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4.",
                "PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "To demonstrate NPhardness, we reduce from the MINSAT problem.",
                "Definition 9 (MINSAT).",
                "We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|).",
                "We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied.",
                "MINSAT was recently shown to be NP-complete [14].",
                "We can now present our result.",
                "Theorem 1.",
                "Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent payment-maximizing deterministic AMD instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|.",
                "For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the MINSAT solution, and π(θc) = |Θ| if c is satisfied.",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent.",
                "Clearly the agent is better off reporting truthfully, for a total utility of 0.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type.",
                "Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the IR constraint, the maximum payment we can extract from any type θv is |Θ|.",
                "Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.)",
                "Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1.",
                "It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible.",
                "However, it does not yet imply hardness for the special case where payments are not possible.",
                "We will prove hardness in this case in the next section. 5.",
                "SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "Theorem 2.",
                "Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent self-interested deterministic AMD without payments instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1.",
                "Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v).",
                "For every c ∈ C that is satisfied in the MINSAT solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ .",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "The only other outcome that the mechanism is allowed to choose under the IR constraint is o0.",
                "This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}.",
                "We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|.",
                "For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).)",
                "Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes.",
                "It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Both of our hardness results relied on the constraint that the mechanism should be deterministic.",
                "In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6.",
                "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of self-interested AMD tractable through linear programming, for any constant number of agents.",
                "Theorem 3.",
                "Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated.",
                "Proof.",
                "Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}.",
                "The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.)",
                "First, we show the IR constraints.",
                "For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
                "For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
                "Now, we show the solution concept constraints.",
                "For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
                "Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
                "All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
                "As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents.",
                "Thus the problem is solvable in polynomial time. 7.",
                "IMPLICATIONS FOR AN OPTIMAL COMBINATORIAL AUCTION DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated mechanism design for a self-interested designer on designing optimal combinatorial auctions.",
                "Consider a combinatorial auction with a set S of items for sale.",
                "For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi.",
                "The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.)",
                "The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18].",
                "However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25].",
                "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of complementarity and no substitutability has been solved recently [1].)",
                "Suppose we have free disposal-items can be thrown away at no cost.",
                "Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.)",
                "Definition 10.",
                "Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
                "We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item.",
                "The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type.",
                "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the payment maximizing AMD problem!",
                "Theorem 4.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types.",
                "Proof.",
                "The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming.",
                "To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal combinatorial auction design problem instance with a single bidder with best-only preferences.",
                "For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance).",
                "Let the expected revenue target value be the same in both instances.",
                "We show the instances are equivalent.",
                "First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function.",
                "Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.)",
                "Let the payment functions be the same in both instances.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same.",
                "It follows that there exists a solution to the optimal auction design instance.",
                "Now suppose there exists a solution to the optimal auction design instance.",
                "By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item.",
                "Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type.",
                "If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type.",
                "Let the payment functions be the same.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same.",
                "It follows that there exists a solution to the AMD instance.",
                "Fortunately, we can also carry through the easiness result for randomized mechanisms to this combinatorial auction setting-giving us one of the few known polynomial-time algorithms for an optimal combinatorial auction design problem.",
                "Theorem 5.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.)",
                "Proof.",
                "By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item.",
                "There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations.",
                "Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8.",
                "RELATED RESEARCH ON COMPLEXITY IN MECHANISM DESIGN There has been considerable recent interest in mechanism design in computer science.",
                "Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism.",
                "The closest piece of earlier work studied the complexity of automated mechanism design by a benevolent designer [5, 6].",
                "Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21].",
                "This is related to mechanism design, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments).",
                "Also, there is no explicit reporting of preferences. 9.",
                "CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently emerging approach-called automated mechanism design-a mechanism is computed for the specific preference aggregation setting at hand.",
                "This has several advantages, 139 but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike earlier work on automated mechanism design that studied a benevolent designer, in this paper we studied automated mechanism design problems where the designer is self-interesteda setting much more relevant for electronic commerce.",
                "In this setting, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "These hardness results imply hardness in all more general automated mechanism design settings with a self-interested designer.",
                "The hardness results apply whether the individual rationality (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation.",
                "We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy.",
                "Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy.",
                "Future research includes studying automated mechanism design with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments).",
                "We also want to study the complexity of automated mechanism design in settings where the outcome and type spaces have special structure so they can be represented more concisely.",
                "Finally, we plan to assemble a data set of real-world mechanism design problems-both historical and current-and apply automated mechanism design to those problems. 10.",
                "REFERENCES [1] M. Armstrong.",
                "Optimal multi-object auctions.",
                "Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow.",
                "The property rights doctrine and demand revelation under incomplete information.",
                "In M. Boskin, editor, Economics and human welfare.",
                "New York Academic Press, 1979. [3] C. Avery and T. Hendershott.",
                "Bundling and optimal auctions of multiple products.",
                "Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke.",
                "Multipart pricing of public goods.",
                "Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Automated mechanism design: Complexity results stemming from the single-agent setting.",
                "In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm.",
                "Computational criticisms of the revelation principle.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004.",
                "Short paper.",
                "Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet.",
                "Incentives and incomplete information.",
                "Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker.",
                "Sharing the cost of muliticast transmissions.",
                "Journal of Computer and System Sciences, 63:21-41, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard.",
                "Manipulation of voting schemes.",
                "Econometrica, 41:587-602, 1973. [11] T. Groves.",
                "Incentives in teams.",
                "Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri.",
                "Vickrey prices and shortest paths: What is an edge worth?",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan.",
                "A polynomial algorithm in linear programming.",
                "Soviet Math.",
                "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani.",
                "The minimum satisfiability problem.",
                "SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham.",
                "Truth revelation in rapid, approximately efficient combinatorial auctions.",
                "Journal of the ACM, 49(5):577-602, 2002.",
                "Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [17] E. S. Maskin and J. Riley.",
                "Optimal multi-unit auctions.",
                "In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335.",
                "Clarendon Press, Oxford, 1989. [18] R. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen.",
                "Computationally feasible VCG mechanisms.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behavior, 35:166-196, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden.",
                "Designing networks for selfish users is hard.",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm.",
                "Issues in computational Vickrey auctions.",
                "International Journal of Electronic Commerce, 4(3):107-129, 2000.",
                "Special Issue on 140 Applying Intelligent Agents for Electronic Commerce.",
                "A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite.",
                "Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions.",
                "Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey.",
                "Counterspeculation, auctions, and competitive sealed tenders.",
                "Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra.",
                "Research problems in combinatorial auctions.",
                "Mimeo, version Oct. 29, 2001. 141"
            ],
            "original_annotated_samples": [
                "For example, imagine a company automatically creating its procurement mechanism based on <br>statistical knowledge</br> about its suppliers, rather than using a classical descending procurement auction."
            ],
            "translated_annotated_samples": [
                "Por ejemplo, imagina una empresa creando automáticamente su mecanismo de adquisiciones basado en el <br>conocimiento estadístico</br> sobre sus proveedores, en lugar de utilizar una subasta de adquisiciones descendente clásica."
            ],
            "translated_text": "Diseño de mecanismos automatizados de interés propio e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les resulte más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente propuesto, llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración de agregación de preferencias actual. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre el diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo. En este caso, al centro solo le importa qué resultado se elige y qué pagos se le hacen. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este contexto, demostramos que el diseño de mecanismos deterministas óptimos es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Luego mostramos cómo permitir la aleatorización en el mecanismo hace que los problemas en este entorno sean computacionalmente fáciles. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (maximizadora de ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar una subasta determinista óptima es NP-completo, pero diseñar una subasta aleatoria óptima es fácil. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Teoría 1. En entornos multiagentes, a menudo se debe elegir un resultado en función de las preferencias informadas por un grupo de agentes. Tales resultados podrían ser presidentes potenciales, planes conjuntos, asignaciones de bienes o recursos, etc. El agregador de preferencias generalmente no conoce las preferencias de los agentes de antemano. Más bien, los agentes informan sus preferencias al coordinador. Desafortunadamente, un agente puede tener un incentivo para informar incorrectamente sus preferencias con el fin de engañar al mecanismo y lograr que seleccione un resultado que sea más deseable para el agente que el resultado que se seleccionaría si el agente revelara sus preferencias de manera honesta. Tal manipulación es indeseable porque los mecanismos de agregación de preferencias están diseñados para agrupar las preferencias de una manera socialmente deseable, y si los agentes revelan sus preferencias de manera insincera, se podría elegir un resultado socialmente indeseable. La manipulabilidad es un problema generalizado en los mecanismos de agregación de preferencias. Un resultado negativo seminal, el teorema de Gibbard-Satterthwaite, muestra que bajo cualquier esquema de agregación de preferencias no dictatorial, si hay al menos 3 posibles resultados, existen preferencias bajo las cuales un agente está mejor reportando falsamente [10, 23]. (Un esquema de agregación de preferencias se llama dictatorial si uno de los agentes dicta el resultado sin importar las preferencias que reporten los otros agentes). Lo que le gustaría hacer al agregador es diseñar un mecanismo de agregación de preferencias para que 1) los agentes interesados reporten sus preferencias de manera veraz, y 2) el mecanismo elija un resultado que sea deseable desde la perspectiva de algún objetivo. Esta es la configuración clásica del diseño de mecanismos en la teoría de juegos. En este documento, estudiamos el caso en el que el diseñador actúa por interés propio, es decir, al diseñador no le importa directamente cómo se relaciona el resultado con las preferencias de los agentes, sino que está más preocupado por su propia agenda sobre cuál resultado debería ser elegido y en maximizar los pagos para sí mismo. Este es el entorno de diseño de mecanismos más relevante para el comercio electrónico. En el caso en que el diseñador del mecanismo esté interesado en maximizar alguna noción de bienestar social, la importancia de recopilar las preferencias de los agentes es clara. Quizás sea menos obvio por qué deberían ser recopilados cuando el diseñador está interesado en sí mismo y, por lo tanto, su objetivo no está directamente relacionado con las preferencias de los agentes. La razón de esto es que a menudo las preferencias de los agentes imponen límites en cómo el diseñador elige el resultado y los pagos. La restricción más común de este tipo es la de racionalidad individual (RI), lo que significa que el mecanismo no puede dejar a ningún agente en una situación peor a la que hubiera estado si no hubiera participado en el mecanismo. Por ejemplo, en el contexto del diseño óptimo de subastas, el diseñador (subastador) solo se preocupa por cuántos ingresos se recaudan, y no en sí mismo por cuán bien la asignación del bien (o bienes) corresponde a las preferencias de los agentes. Sin embargo, el diseñador no puede obligar a un agente a pagar más de lo que valora el paquete de bienes asignado a él. Por lo tanto, incluso un diseñador interesado en sí mismo elegirá un resultado que beneficie razonablemente a los agentes. Por otro lado, el diseñador no necesariamente elegirá un resultado que maximice el bienestar social. Por ejemplo, si el diseñador siempre elige un resultado que maximiza el bienestar social con respecto a las preferencias informadas, y obliga a cada agente a pagar la diferencia entre la utilidad que tiene ahora y la utilidad que habría tenido si no hubiera participado en el mecanismo, es fácil ver que los agentes pueden tener un incentivo para informar incorrectamente sus preferencias, lo que puede llevar realmente a recaudar menos ingresos. De hecho, uno de los resultados contraintuitivos de la teoría del diseño de subastas óptimas es que a veces el bien se asigna a nadie incluso cuando el subastador tiene un precio de reserva de 0. El diseño de mecanismos clásicos proporciona algunos mecanismos generales, que, bajo ciertas suposiciones, satisfacen alguna noción de no manipulabilidad y maximizan algún objetivo. La ventaja de estos mecanismos es que no dependen de información (incluso probabilística) sobre las preferencias de los agentes (por ejemplo, el mecanismo de Vickrey-Clarke-Groves (VCG) [24, 4, 11]), o pueden aplicarse fácilmente a cualquier distribución de probabilidad sobre las preferencias (por ejemplo, el mecanismo dAGVA [8, 2], la subasta de Myerson [18], y la subasta multiunidad de Maskin-Riley [17]). Sin embargo, los mecanismos generales también tienen importantes desventajas: • Los mecanismos generales más famosos y ampliamente aplicables, VCG y dAGVA, solo maximizan el bienestar social. Si el diseñador está interesado en sí mismo, como es el caso en muchos entornos de comercio electrónico, estos mecanismos no maximizan el objetivo del diseñador. • Los mecanismos generales que se centran en un diseñador interesado en sí mismo solo son aplicables en entornos muy restringidos, como la subasta de maximización de ingresos esperados de Myerson para vender un solo artículo, y la subasta de maximización de ingresos esperados de Maskin y Riley para vender múltiples unidades idénticas de un artículo. • Incluso en los entornos restringidos en los que se aplican estos mecanismos, solo permiten la maximización de pagos. En la práctica, el diseñador también puede estar interesado en el resultado en sí mismo. Por ejemplo, a un subastador le puede importar qué postor recibe el artículo. • A menudo se asume que los pagos laterales pueden ser utilizados para adaptar los incentivos de los agentes, pero esto no siempre es práctico. Por ejemplo, en los mercados electrónicos basados en trueque, como Recipco, firstbarter.com, BarterOne e Intagio, no se permiten los pagos laterales. Además, entre los agentes de software, podría ser más deseable construir mecanismos que no dependan de la capacidad de realizar pagos, ya que muchos agentes de software no cuentan con la infraestructura para hacer pagos. Por el contrario, seguimos un enfoque reciente donde el mecanismo se diseña automáticamente para el problema específico en cuestión. Este enfoque aborda todos los inconvenientes mencionados anteriormente. Formulamos el problema de diseño de mecanismos como un problema de optimización. La entrada se caracteriza por el número de agentes, los posibles tipos de agentes (preferencias) y las distribuciones previas de los agregadores sobre los tipos de agentes. La salida es un mecanismo no manipulable que es óptimo con respecto a algún objetivo. Este enfoque se llama diseño de mecanismos automatizado. El enfoque de diseño de mecanismos automatizado tiene cuatro ventajas sobre el enfoque clásico de diseñar mecanismos generales. Primero, se puede utilizar incluso en entornos que no cumplen con las suposiciones de los mecanismos clásicos (como la disponibilidad de pagos laterales o que el objetivo sea el bienestar social). Segundo, puede permitir a uno eludir resultados de imposibilidad (como el teorema de Gibbard-Satterthwaite) que establecen que no existe un mecanismo que sea deseable para todas las preferencias. Cuando el mecanismo está diseñado para la configuración actual, no importa que no funcione de manera más general. Tercero, puede generar mecanismos mejores (en términos de garantías de no manipulabilidad más sólidas y/o mejores resultados) que los mecanismos clásicos porque el mecanismo aprovecha las particularidades del entorno (la información probabilística que el diseñador tiene sobre los tipos de agentes). Dada la gran cantidad de información que las partes tienen entre sí hoy en día, es probable que este enfoque conduzca a ahorros enormes en comparación con los mecanismos clásicos, que en su mayoría ignoran esa información. Por ejemplo, imagina una empresa creando automáticamente su mecanismo de adquisiciones basado en el <br>conocimiento estadístico</br> sobre sus proveedores, en lugar de utilizar una subasta de adquisiciones descendente clásica. Cuarto, la carga del diseño se traslada de los humanos a una máquina. Sin embargo, el diseño automatizado de mecanismos requiere que el problema de optimización del diseño del mecanismo se resuelva de nuevo para cada configuración. Por lo tanto, su complejidad computacional se convierte en un tema clave. Investigaciones previas han estudiado esta pregunta para diseñadores benevolentes que desean maximizar, por ejemplo, el bienestar social [5, 6]. En este artículo estudiamos la complejidad computacional del diseño automatizado de mecanismos en el caso de un diseñador con interés propio. Esta es una configuración importante para el diseño de mecanismos automatizados debido a la escasez de mecanismos generales en esta área, y al hecho de que en la mayoría de las configuraciones de comercio electrónico el diseñador actúa en su propio interés. También demostramos que este problema está estrechamente relacionado con un problema de diseño de subasta combinatoria óptima (maximización de ingresos) particular. El resto de este documento está organizado de la siguiente manera. En la Sección 2, justificamos el enfoque en mecanismos no manipulables. En la Sección 3, definimos el problema que estudiamos. En la Sección 4, demostramos que diseñar un mecanismo determinista óptimo es NP-completo incluso cuando al diseñador solo le importan los pagos que recibe. En la Sección 5, demostramos que diseñar un mecanismo determinista óptimo también es NP-completo cuando los pagos no son posibles y el diseñador solo está interesado en el resultado elegido. En la Sección 6, demostramos que un mecanismo óptimo aleatorizado puede ser diseñado en tiempo polinómico incluso en el caso general. Finalmente, en la Sección 7, demostramos que para diseñar subastas combinatorias óptimas bajo preferencias de mejor opción solamente, nuestros resultados sobre AMD implican que este problema es NP-completo para subastas determinísticas, pero sencillo para subastas aleatorias. 2. JUSTIFICANDO EL ENFOQUE EN MECANISMOS NO MANIPULABLES Antes de definir el problema computacional del diseño automatizado de mecanismos, debemos justificar nuestro enfoque en mecanismos no manipulables. Después de todo, no es inmediatamente obvio que no haya mecanismos manipulables que, incluso cuando los agentes informan estratégicamente sus tipos y, por lo tanto, a veces de manera no veraz, aún logren mejores resultados (según el objetivo que usemos) que cualquier mecanismo no manipulable. Sin embargo, resulta ser el caso que, dado cualquier mecanismo, podemos construir un mecanismo no manipulable cuyo rendimiento es idéntico, de la siguiente manera. Construimos una capa de interfaz entre los agentes y el mecanismo original. Los agentes informan sus preferencias (o tipos) a la capa de interfaz; posteriormente, la capa de interfaz introduce en el mecanismo original los tipos que los agentes habrían informado estratégicamente al mecanismo original, si sus tipos fueran los declarados a la capa de interfaz. El resultado resultante es el resultado del nuevo mecanismo. Dado que la capa de interfaz actúa estratégicamente en nombre de cada agente, nunca hay un incentivo para informar falsamente a la capa de interfaz; por lo tanto, los tipos informados por la capa de interfaz son los tipos estratégicos que se habrían informado sin la capa de interfaz, por lo que los resultados son exactamente como habrían sido con el mecanismo original. Este argumento es conocido en la literatura de diseño de mecanismos como el principio de revelación [16]. (Existen dificultades computacionales al aplicar el principio de revelación en espacios de resultados y tipos combinatorios grandes [7, 22]). Sin embargo, dado que aquí nos enfocamos en espacios de resultados y tipos representados de forma plana, esto no es una preocupación aquí. Dado esto, podemos centrarnos en mecanismos veraces en el resto del documento. 3. DEFINICIONES Ahora formalizamos el entorno del diseño automatizado de mecanismos. Definición 1. En un entorno de diseño de mecanismos automatizados, se nos proporciona: • un conjunto finito de resultados O; • un conjunto finito de N agentes; • para cada agente i, 1. un conjunto finito de tipos Θi, 2. una distribución de probabilidad γi sobre Θi (en el caso de tipos correlacionados, hay una única distribución conjunta γ sobre Θ1 × . . . × ΘN), y 3. una función de utilidad ui: Θi × O → R; 1 • Una función objetivo cuya expectativa el diseñador desea maximizar. Existen muchas posibles funciones objetivo que el diseñador podría tener, por ejemplo, el bienestar social (donde el diseñador busca maximizar la suma de las utilidades de los agentes), o la utilidad mínima de cualquier agente (donde el diseñador busca maximizar la peor utilidad experimentada por cualquier agente). En ambos casos, el diseñador es benevolente, ya que, de alguna manera, el diseñador está buscando la felicidad colectiva de los agentes. Sin embargo, en este documento nos enfocamos en el caso de un diseñador interesado en sí mismo. Un diseñador egoísta solo se preocupa por el resultado elegido (es decir, al diseñador no le importa cómo se relaciona el resultado con las preferencias de los agentes, sino que tiene una preferencia fija sobre los resultados) y sobre los pagos netos realizados por los agentes, que fluyen hacia el diseñador. Definición 2. Un diseñador interesado tiene una función objetivo dada por g(o) + Σ i=1 πi, donde g : O → R indica las preferencias del diseñador sobre los resultados, y πi es el pago realizado por el agente i. En el caso en que g = 0 en todas partes, se dice que el diseñador está maximizando el pago. En el caso en que los pagos no sean posibles, g constituye la función objetivo por sí sola. Ahora definimos los tipos de mecanismos en estudio. Por el principio de revelación, podemos restringir la atención a mecanismos de revelación directa y veraz, donde los agentes informan directamente sus tipos y nunca tienen incentivos para informarlos de manera incorrecta. Definición 3. Consideramos los siguientes tipos de mecanismos: • Un mecanismo determinista sin pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O. • Un mecanismo aleatorio sin pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), donde P(O) es el conjunto de distribuciones de probabilidad sobre O. • Un mecanismo determinista con pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O y, para cada agente i, una función de selección de pagos πi: Θ1 × Θ2 × . . . × ΘN → R, donde πi(θ1, . . . , θN ) da el pago realizado por el agente i cuando los tipos reportados son θ1, . . . , θN. Aunque esto sigue la notación estándar de la teoría de juegos [16], el hecho de que el agente tenga tanto una función de utilidad como un tipo puede resultar confuso. Los tipos codifican las diversas preferencias posibles que el agente pueda tener, y el tipo de los agentes no es conocido por el agregador. La función de utilidad es un conocimiento común, pero debido a que el tipo de agente es un parámetro en la función de utilidad de los agentes, el agregador no puede saber cuál es la utilidad de los agentes sin conocer el tipo de agente. Un mecanismo aleatorio con pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), y para cada agente i, una función de selección de pago πi: Θ1 × Θ2 × . . . × ΘN → R. Hay dos tipos de restricciones para el diseñador al construir el mecanismo. 3.1 Restricciones de racionalidad individual (IR) El primer tipo de restricción es el siguiente. La utilidad de cada agente debe ser al menos tan grande como la utilidad de respaldo de los agentes, es decir, la utilidad que el agente recibiría si no participara en el mecanismo. De lo contrario, ese agente no participaría en el mecanismo, y la participación de ningún agente puede perjudicar el objetivo de los diseñadores del mecanismo, ya que en el peor de los casos, el mecanismo puede ignorar a un agente fingiendo que el agente no está presente. (Además, si no se aplicara tal restricción, el diseñador simplemente podría hacer que los agentes paguen una cantidad infinita). Este tipo de restricción se llama restricción de IR (racionalidad individual). Existen tres posibles restricciones de IR diferentes: ex ante, ex interim y ex post, dependiendo de lo que el agente sabe sobre su propio tipo y los tipos de los demás al decidir si participar en el mecanismo. Ex ante IR significa que el agente participaría si no supiera absolutamente nada (ni siquiera su propio tipo). No estudiaremos este concepto en este documento. Ex interim IR significa que el agente siempre participaría si conociera solo su propio tipo, pero no el de los demás. Ex post IR significa que el agente siempre participaría incluso si conociera el tipo de todos. Definiremos formalmente las dos últimas nociones de IR. Primero, necesitamos formalizar el concepto del resultado de respaldo. Suponemos que la utilidad de respaldo de cada agente es cero para cada uno de sus tipos. Esto se hace sin pérdida de generalidad porque podemos agregar un término constante a la función de utilidad de un agente (para un tipo dado), sin afectar el comportamiento de toma de decisiones de ese agente maximizador de utilidad esperada [16]. Definición 4. En cualquier entorno de diseño de mecanismos automatizados con una restricción de IR, existe un resultado de contingencia o0 ∈ O donde, para cualquier agente i y cualquier tipo θi ∈ Θi, tenemos ui(θi, o0) = 0. (Además, en el caso de un diseñador egoísta, g(o0) = 0). Ahora podemos definir las nociones de racionalidad individual. Definición 5. La racionalidad individual (RI) se define como: • Un mecanismo determinista es ex interim RI si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0. Un mecanismo aleatorio es ex interim IR si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • Un mecanismo determinista es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 No aleatorizamos sobre los pagos porque mientras los agentes y el diseñador sean neutrales al riesgo con respecto a los pagos, es decir, su utilidad es lineal en los pagos, no hay razón para aleatorizar sobre los pagos. Un mecanismo aleatorio es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 3.2 Restricciones de compatibilidad de incentivos (IC) El segundo tipo de restricción establece que los agentes nunca deben tener un incentivo para informar incorrectamente su tipo (como se justificó anteriormente mediante el principio de revelación). Para este tipo de restricción, las dos variantes más comunes (o conceptos de solución) son la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash. Definición 6. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en estrategias dominantes si decir la verdad siempre es óptimo incluso cuando los tipos reportados por los otros agentes ya son conocidos. Formalmente, para cualquier agente i, cualquier vector de tipos (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ). En el caso de mecanismos aleatorios tenemos Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. Por lo tanto, en la implementación de estrategias dominantes, decir la verdad es óptimo independientemente de lo que informen los otros agentes. Si es óptimo solo dado que los otros agentes son veraces, y dado que uno no conoce los tipos de los otros agentes, tenemos implementación en equilibrio de Bayes-Nash. Definición 7. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en equilibrio de Bayes-Nash si decir la verdad siempre es óptimo para un agente cuando ese agente aún no sabe nada sobre los tipos de los otros agentes, y los otros agentes están diciendo la verdad. Formalmente, para cualquier agente i, cualquier tipo θi ∈ Θi, y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )]. En el caso de mecanismos aleatorios tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 135 3.3 Diseño de mecanismos automatizados Ahora podemos definir el problema computacional que estudiamos. Definición 8. (DISEÑO DE MECANISMOS AUTOMATIZADOS (AMD)) Se nos da: • un entorno de diseño de mecanismos automatizados, • una noción de IR (ex interim, ex post, o ninguna), • un concepto de solución (estrategias dominantes o Bayes-Nash), • si los pagos son posibles, • si la aleatorización es posible, • (en la variante de decisión del problema) un valor objetivo G. Se nos pregunta si existe un mecanismo del tipo especificado (en términos de pagos y aleatorización) que satisfaga tanto la noción de IR como el concepto de solución, y proporcione un valor esperado de al menos G para el objetivo. Un caso especial interesante es aquel en el que solo hay un agente. En este caso, el agente informante siempre sabe todo lo que hay que saber sobre los otros tipos de agentes, porque no hay otros agentes. Dado que el IR ex post y el IR ex interim solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de IR coinciden aquí. Además, dado que la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de solución coinciden aquí. Esta observación resultará ser una herramienta útil para demostrar resultados de dificultad: si demostramos dificultad computacional en el escenario de un solo agente, esto implica inmediatamente dificultad para ambos conceptos de IR, para ambos conceptos de solución, para cualquier número de agentes. 4. En esta sección demostramos que es NP-completo diseñar un mecanismo determinístico que maximice la suma esperada de los pagos recolectados de los agentes. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Para demostrar la NP-dureza, reducimos desde el problema MINSAT. Definición 9 (MINSAT). Se nos da una fórmula φ en forma normal conjuntiva, representada por un conjunto de variables booleanas V y un conjunto de cláusulas C, y un entero K (K < |C|). Se nos pregunta si existe una asignación a las variables en V tal que se satisfacen a lo sumo K cláusulas en φ. MINSAT fue recientemente demostrado como NP-completo [14]. Ahora podemos presentar nuestro resultado. Teorema 1. El problema determinista de maximización de pagos de AMD es NP-completo, incluso para un solo agente, incluso con una distribución uniforme de tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista de maximización de pagos de un solo agente. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V } ∪ {−v : v ∈ V }. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Sea l ∈ c denota que el literal l ocurre en la cláusula c. Entonces, la función de utilidad de los agentes está dada por u(θc, ol) = |Θ| + 1 para todo l ∈ L con l ∈ c; u(θc, ol) = 0 para todo l ∈ L con l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc) = 0 para todo c ∈ C con c = c; u(θv, ol) = |Θ| para todo l ∈ L con v(l) = v; u(θv, ol) = 0 para todo l ∈ L con v(l) = v; u(θv, oc) = 0 para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ|, donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v) y π(θv) = |Θ|. Para cada c ∈ C, sea o(θc) = oc; sea π(θc) = |Θ| + 1 si c no está satisfecha en la solución MINSAT, y π(θc) = |Θ| si c está satisfecha. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es θv, entonces cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivo para informar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Porque además, ningún tipo que no sea θc conduce al resultado oc, informar cualquier otro tipo dará como resultado una utilidad de 0, mientras que aún se requiere un pago de al menos |Θ| por parte del agente. Claramente, el agente está mejor reportando honestamente, para una utilidad total de 0. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), el pago esperado de este mecanismo es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o y una función de pago π. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. Entonces, la utilidad que el agente obtiene del resultado dado para este tipo es 0, y por lo tanto, según la IR, no se puede extraer ningún pago del agente para este tipo. Dado que, nuevamente por IR, el pago máximo que se puede extraer para cualquier otro tipo es |Θ| + 1, se sigue que el pago esperado máximo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo cual contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o−v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por la restricción de IR, el pago máximo que podemos extraer de cualquier tipo θv es |Θ|. Dado que no puede haber incentivos para que el agente informe falsamente, para cualquier cláusula c satisfecha por la asignación dada, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ|. (Pues si extrajéramos más de este tipo, la utilidad del agente en este caso sería menor que 1; y si v es la variable que satisface c en la asignación, de modo que o(θv) = ol donde l ocurre en c, entonces al agente le convendría más informar θv en lugar del informe veraz θc, para obtener un resultado que valga |Θ|+1 para él mientras tiene que pagar como máximo |Θ|.) Finalmente, para cualquier cláusula insatisfecha c, según la restricción de IR, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ| + 1. Se deduce que el pago esperado de nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia de MINSAT. Dado que AMD, que maximiza el pago, es solo un caso especial de AMD para un diseñador egoísta en el que el diseñador no tiene preferencias sobre el resultado elegido, esto implica inmediatamente dificultades para el caso general de AMD para un diseñador egoísta en el que los pagos son posibles. Sin embargo, esto aún no implica dureza para el caso especial donde los pagos no son posibles. Demostraremos la dificultad en este caso en la próxima sección. 5. En esta sección demostramos que es NP-completo diseñar un mecanismo determinista que maximice la expectativa del objetivo del diseñador cuando no son posibles los pagos. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Teorema 2. Sin pagos, el diseño determinista de AMD para un diseñador egoísta es NP-completo, incluso para un solo agente, incluso con una distribución uniforme sobre los tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista auto-interesada de un solo agente sin pagos. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L} ∪ {o∗}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V} ∪ {−v : v ∈ V}. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Deje que l ∈ c denote que el literal l ocurre en la cláusula c. Luego, deje que la función de utilidad de los agentes esté dada por u(θc, ol) = 2 para todo l ∈ L con l ∈ c; u(θc, ol) = −1 para todo l ∈ L con l /∈ c; u(θc, oc) = 2; u(θc, oc) = −1 para todo c ∈ C con c = c; u(θc, o∗) = 1; u(θv, ol) = 1 para todo l ∈ L con v(l) = v; u(θv, ol) = −1 para todo l ∈ L con v(l) = v; u(θv, oc) = −1 para todo c ∈ C; u(θv, o∗) = −1. Que la función objetivo de los diseñadores esté dada por g(o∗ ) = |Θ|+1; g(ol) = |Θ| para todo l ∈ L; g(oc) = |Θ| para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ| , donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v). Para cada c ∈ C que se cumpla en la solución MINSAT, sea o(θc) = oc; para cada c ∈ C no satisfecho, sea o(θc) = o∗. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es algún θv, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para reportar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Debido a que tampoco ningún tipo conduce al resultado oc, no hay ningún resultado que el mecanismo seleccione que le daría al agente una utilidad mayor a 1 para el tipo θc, y por lo tanto el agente no tiene incentivo para informar falsamente. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), entonces el valor esperado de la función objetivo de los diseñadores es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. El único otro resultado que el mecanismo puede elegir bajo la restricción de IR es o0. Esto tiene un valor objetivo de 0, y dado que el valor más alto que la función objetivo alcanza es |Θ| + 1, se sigue que el valor esperado máximo de la función objetivo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo que contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o-v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por lo anterior, para cualquier tipo θv, el valor de la función objetivo en este mecanismo será |Θ|. Para cualquier cláusula c satisfecha por la asignación dada, el valor de la función objetivo en el caso en que el agente informe el tipo θc será como máximo |Θ|. (Esto se debe a que no podemos elegir el resultado o∗ para dicho tipo, ya que en este caso el agente tendría un incentivo para informar θv en su lugar, donde v es la variable que satisface c en la asignación (de modo que o(θv) = ol donde l ocurre en c).) Finalmente, para cualquier cláusula insatisfecha c, el valor máximo que la función objetivo puede alcanzar en el caso en que el agente informa el tipo θc es |Θ| + 1, simplemente porque este es el valor más grande que la función alcanza en cualquier momento. Se deduce que el valor esperado de la función objetivo para nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas 137 satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia MINSAT. Ambos de nuestros resultados de dureza se basaron en la restricción de que el mecanismo debería ser determinista. En la siguiente sección, mostramos que la dificultad del diseño desaparece cuando permitimos la aleatorización en el mecanismo. 6. La aleatorización de AMD para un diseñador interesado en sí mismo es fácil. Ahora mostramos cómo permitir la aleatorización sobre los resultados hace que el problema de AMD auto-interesado sea manejable a través de la programación lineal, para cualquier número constante de agentes. Teorema 3. El AMD aleatorio con interés propio con un número constante de agentes es resoluble en tiempo polinómico mediante programación lineal, tanto con pagos como sin pagos, tanto para IR ex post como ex interim, y tanto para la implementación en estrategias dominantes como para la implementación en equilibrio de Bayes-Nash, incluso si los tipos están correlacionados. Prueba. Dado que los programas lineales pueden resolverse en tiempo polinómico [13], todo lo que necesitamos demostrar es que el número de variables y ecuaciones en nuestro programa es polinomial para cualquier número constante de agentes, es decir, exponencial solo en N. En todo momento, para determinar el tamaño del programa lineal, consideremos T = maxi{|Θi|}. Las variables de nuestro programa lineal serán las probabilidades (p(θ1, θ2, . . . , θN ))(o) (como máximo TN |O| variables) y los pagos πi(θ1, θ2, . . . , θN ) (como máximo NTN variables). (Mostramos el programa lineal para el caso en que los pagos son posibles; el caso sin pagos se obtiene fácilmente de esto simplemente omitiendo todas las variables de pago en el programa, o agregando restricciones adicionales que obliguen a los pagos a ser 0). Primero, mostramos las restricciones de IR. Para el IR ex post, agregamos las siguientes restricciones (como máximo NTN) al LP: • Para cada i ∈ {1, 2, . . . , N}, y para cada (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , agregamos ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0. Para el ex interino IR, agregamos las siguientes restricciones (como máximo NT) al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada θi ∈ Θi, agregamos θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0. Ahora, mostramos las restricciones del concepto de solución. Para la implementación en estrategias dominantes, agregamos las siguientes (a lo sumo NTN+1) restricciones al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ). Finalmente, para la implementación en el equilibrio de Bayes-Nash, agregamos las siguientes (a lo sumo NT2) restricciones al LP: • Para cada i ∈ {1, 2, ..., N}, para cada θi ∈ Θi, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )). Todo lo que queda por hacer es dar la expresión que el diseñador busca maximizar, que es: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )). Como indicamos, el número de variables y restricciones es exponencial solo en N, por lo tanto, el programa lineal tiene un tamaño polinómico para un número constante de agentes. Por lo tanto, el problema es resoluble en tiempo polinómico. IMPLICACIONES PARA UN PROBLEMA DE DISEÑO DE SUBASTA COMBINATORIA ÓPTIMA En esta sección, demostraremos algunas consecuencias interesantes del problema de diseño de mecanismos automatizados para un diseñador interesado en sí mismo en el diseño de subastas combinatorias óptimas. Considera una subasta combinatoria con un conjunto S de artículos en venta. Para cualquier conjunto B ⊆ S, dejemos que ui(θi, B) sea la utilidad del postor i al recibir el conjunto B cuando el tipo del postor es θi. El problema de diseño de subasta óptima consiste en especificar las reglas de la subasta de manera que se maximice los ingresos esperados para el subastador. (Por el principio de revelación, sin pérdida de generalidad, podemos asumir que la subasta es veraz). El problema de diseño de subasta óptima se resuelve para el caso de un solo artículo mediante la famosa subasta de Myerson [18]. Sin embargo, el diseño de subastas óptimas en subastas combinatorias es un problema de investigación abierto reconocido [3, 25]. El problema está abierto incluso si solo hay dos artículos en venta. (El caso de dos artículos con una forma muy especial de complementariedad y sin sustituibilidad ha sido resuelto recientemente [1].) Supongamos que tenemos disposición libre: los artículos pueden ser desechados sin costo alguno. Además, supongamos que las preferencias de los postores tienen la siguiente estructura: cuando un postor recibe un conjunto de artículos, la utilidad del postor por ese conjunto está determinada únicamente por el mejor artículo en el conjunto. (Enfatizamos que qué artículo es el mejor puede depender del tipo de postor). Definición 10. Se dice que el postor i tiene preferencias solo por lo mejor sobre paquetes de artículos si existe una función vi: Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s). Hacemos la siguiente observación útil en este contexto: no tiene sentido otorgarle a un postor más de un artículo. La razón es que si el postor está informando honestamente, quitarle todos los artículos menos el de mayor valor no perjudicará al postor; y, mediante la disposición gratuita, hacerlo solo reducirá el incentivo para que este postor informe falsamente este tipo, cuando en realidad tiene otro tipo. Ahora demostramos que el problema de diseñar una subasta óptima determinista es NP-completo, mediante una reducción del problema AMD de maximización de pagos. Teorema 4. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de artículos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), diseñar la subasta determinística óptima es NP-completo, incluso para un único postor con una distribución uniforme sobre los tipos. Prueba. El problema está en NP porque podemos generar de manera no determinista una regla de asignación, y luego establecer los pagos utilizando programación lineal. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de AMD determinista que maximiza el pago, con un único agente y una distribución uniforme de tipos, al siguiente problema de diseño de subasta combinatoria óptima con una única postor con preferencias de solo los mejores. Para cada resultado o ∈ O en la instancia de AMD (excepto el resultado o0), que haya un artículo so ∈ S. Que el espacio de tipos sea el mismo, y que v(θi, so) = ui(θi, o) (donde u está especificado en la instancia de AMD). Que el valor objetivo de ingresos esperados sea el mismo en ambas instancias. Mostramos que las instancias son equivalentes. Primero supongamos que existe una solución para la instancia de AMD, dada por una función de resultado y una función de pago. Entonces, si la solución de AMD elige el resultado o para un tipo, en la solución de subasta óptima, asignamos {so} al postor para este tipo. (A menos que o = o0, en cuyo caso asignamos {} al postor). Que las funciones de pago sean las mismas en ambas instancias. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo verdadero) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución óptima de la subasta. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el subastador/diseñador son los mismos. Se deduce que existe una solución para la instancia de diseño de subasta óptima. Ahora supongamos que existe una solución para la instancia de diseño de subasta óptima. Por la observación de que como máximo se puede tener un artículo, podemos asumir sin pérdida de generalidad que la solución nunca asigna más de un artículo. Entonces, si la solución de subasta óptima asigna el artículo al postor para un tipo, en la solución de AMD, permita que el mecanismo elija el resultado o para ese tipo. Si la solución de subasta óptima no asigna nada al postor para un tipo, en la solución AMD, permita que el mecanismo elija el resultado o0 para ese tipo. Que las funciones de pago sean las mismas. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo real) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución AMD. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el diseñador/subastador son los mismos. Se deduce que existe una solución para la instancia de AMD. Afortunadamente, también podemos extender el resultado de facilidad para mecanismos aleatorios a este escenario de subasta combinatoria, lo que nos proporciona uno de los pocos algoritmos de tiempo polinómico conocidos para un problema de diseño óptimo de subasta combinatoria. Teorema 5. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de elementos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), si el número de postores es una constante k, entonces la subasta aleatoria óptima puede ser diseñada en tiempo polinómico. (Para cualquier restricción de IC e IR.) Prueba. Por la observación de que a lo sumo un artículo, podemos sin pérdida de generalidad restringirnos a asignaciones donde cada postor recibe como máximo un artículo. Hay menos de (|S| + 1)k asignaciones de ese tipo, es decir, un número polinómico de asignaciones. Dado que podemos enumerar explícitamente los resultados, simplemente podemos resolver esto como una instancia de AMD que maximiza el pago, con programación lineal. 8. Investigaciones relacionadas sobre la complejidad en el diseño de mecanismos. Ha habido un considerable interés reciente en el diseño de mecanismos en la informática. Parte de ello se ha centrado en cuestiones de complejidad computacional, pero la mayor parte de ese trabajo ha buscado diseñar mecanismos que sean fáciles de ejecutar (por ejemplo, [20, 15, 19, 9, 12]), en lugar de estudiar la complejidad de diseñar el mecanismo. La pieza más cercana de trabajo anterior estudió la complejidad del diseño automatizado de mecanismos por un diseñador benevolente [5, 6]. Roughgarden ha estudiado la complejidad de diseñar una buena topología de red para agentes que eligen egoístamente los enlaces que utilizan [21]. Esto está relacionado con el diseño de mecanismos, pero difiere significativamente en que el diseñador solo tiene un control restringido sobre las reglas del juego porque no hay ninguna parte que pueda imponer el resultado (o pagos laterales). Además, no hay un informe explícito de preferencias. 9. CONCLUSIONES E INVESTIGACIONES FUTURAS A menudo, un resultado debe ser elegido en función de las preferencias informadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les sea más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente emergente llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración específica de agregación de preferencias en cuestión. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo, un entorno mucho más relevante para el comercio electrónico. En este contexto, al centro solo le importa qué resultado se elige y qué pagos se le realizan. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este escenario, demostramos que diseñar un mecanismo determinista óptimo es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Estos resultados de dureza implican dificultad en todos los entornos de diseño de mecanismos automatizados más generales con un diseñador egoísta. Los resultados de dureza se aplican ya sea que las restricciones de racionalidad individual (participación) se apliquen ex interim o ex post, y ya sea que el concepto de solución sea la implementación de estrategias dominantes o la implementación del equilibrio de Bayes-Nash. Luego demostramos que permitir la aleatorización en el mecanismo hace que el problema de diseño en todos estos escenarios sea computacionalmente sencillo. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (que maximiza los ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar un mecanismo determinístico óptimo es NP-completo incluso con un agente, pero diseñar un mecanismo aleatorio óptimo es fácil. La investigación futura incluye estudiar el diseño automatizado de mecanismos con un diseñador interesado en sí mismo en entornos más restringidos, como subastas (donde el objetivo del diseñador puede incluir preferencias sobre qué postor debería recibir el bien, así como los pagos). También queremos estudiar la complejidad del diseño de mecanismos automatizados en entornos donde los espacios de resultados y tipos tienen una estructura especial para que puedan representarse de manera más concisa. Finalmente, planeamos reunir un conjunto de datos de problemas de diseño de mecanismos del mundo real, tanto históricos como actuales, y aplicar el diseño de mecanismos automatizado a esos problemas. 10. REFERENCIAS [1] M. Armstrong. Subastas multi-objetivo óptimas. Revisión de Estudios Económicos, 67:455-481, 2000. [2] K. Arrow. La doctrina de los derechos de propiedad y la revelación de la demanda bajo información incompleta. En M. Boskin, editor, Economía y bienestar humano. New York Academic Press, 1979. [3] C. Avery y T. Hendershott. Agrupación y subastas óptimas de múltiples productos. Revisión de Estudios Económicos, 67:483-497, 2000. [4] E. H. Clarke. Precios escalonados de bienes públicos. Elección Pública, 11:17-33, 1971. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Actas de la 18ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI-02), páginas 103-110, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Diseño de mecanismos automatizados: Resultados de complejidad derivados del entorno de un solo agente. En Actas de la 5ta Conferencia Internacional de Comercio Electrónico (ICEC-03), páginas 17-24, Pittsburgh, PA, EE. UU., 2003. [7] V. Conitzer y T. Sandholm. Críticas computacionales del principio de revelación. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), Nueva York, NY, 2004. Breve ensayo. La versión completa apareció en el taller AAMAS-03 sobre Comercio Electrónico Mediado por Agentes (AMEC). [8] C. d'Aspremont y L. A. Gérard-Varet. Incentivos e información incompleta. Revista de Economía Pública, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou y S. Shenker. Compartiendo el costo de las transmisiones de multidifusión. Revista de Ciencias de la Computación y de Sistemas, 63:21-41, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 2000. [10] A. Gibbard. Manipulación de esquemas de votación. Econometrica, 41:587-602, 1973. [11] T. Groves.\nEconometrica, 41:587-602, 1973. [11] T. Groves. Incentivos en equipos. Econometrica, 41:617-631, 1973. [12] J. Hershberger y S. Suri. Precios de Vickrey y caminos más cortos: ¿Cuánto vale una arista? En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [13] L. Khachiyan. Un algoritmo polinómico en programación lineal. Matemática soviética. Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi y P. Mirchandani. El problema de satisfacibilidad mínimo. Revista SIAM de Matemáticas Discretas, 7(2):275-283, 1994. [15] D. Lehmann, L. I. O'Callaghan y Y. Shoham. Revelación de la verdad en subastas combinatorias rápidas y aproximadamente eficientes. Revista de la ACM, 49(5):577-602, 2002. La versión inicial apareció en las Actas de la Conferencia de Comercio Electrónico de la ACM (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [17] E. S. Maskin y J. Riley. Subastas multiunidad óptimas. En F. Hahn, editor, \"La economía de los mercados faltantes, la información y los juegos\", capítulo 14, páginas 312-335. Clarendon Press, Oxford, 1989. [18] R. Myerson.\nPrensa Clarendon, Oxford, 1989. [18] R. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6:58-73, 1981. [19] N. Nisan y A. Ronen. Mecanismos VCG computacionalmente factibles. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 242-252, Minneapolis, MN, 2000. [20] N. Nisan y A. Ronen. Diseño de mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166-196, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 1999. [21] T. Roughgarden. Diseñar redes para usuarios egoístas es difícil. En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [22] T. Sandholm. Problemas en subastas computacionales de Vickrey. Revista Internacional de Comercio Electrónico, 4(3):107-129, 2000. Número especial sobre la Aplicación de Agentes Inteligentes para el Comercio Electrónico. Una versión corta y temprana apareció en la Segunda Conferencia Internacional sobre Sistemas Multiagente (ICMAS), páginas 299-306, 1996. [23] M. A. Satterthwaite. In Spanish, the translation would be: \"Inmutabilidad estratégica y condiciones de Arrow: teoremas de existencia y correspondencia para procedimientos de votación y funciones de bienestar social.\" Revista de Teoría Económica, 10:187-217, 1975. [24] W. Vickrey. Contrarrestando la especulación, subastas y ofertas selladas competitivas. Revista de Finanzas, 16:8-37, 1961. [25] R. V. Vohra. Problemas de investigación en subastas combinatorias. Mimeo, versión 29 de octubre de 2001. 141 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "classical mechanism": {
            "translated_key": "mecanismo clásico",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-interested Automated Mechanism Design and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently proposed approach-called automated mechanism design-a mechanism is computed for the preference aggregation setting at hand.",
                "This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike the earlier work on automated mechanism design that studied a benevolent designer, in this paper we study automated mechanism design problems where the designer is self-interested.",
                "In this case, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy.",
                "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy.",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc.",
                "The preference aggregator generally does not know the agents preferences a priori.",
                "Rather, the agents report their preferences to the coordinator.",
                "Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully.",
                "Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen.",
                "Manipulability is a pervasive problem across preference aggregation mechanisms.",
                "A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.)",
                "What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective.",
                "This is the classic setting of mechanism design in game theory.",
                "In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself.",
                "This is the mechanism design setting most relevant to electronic commerce.",
                "In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear.",
                "It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences.",
                "The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments.",
                "The most common such constraint is that of individual rationality (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
                "For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences.",
                "Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it.",
                "Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off.",
                "On the other hand, the designer will not necessarily choose a social welfare maximizing outcome.",
                "For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected.",
                "Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0.",
                "<br>classical mechanism</br> design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective.",
                "The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]).",
                "However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare.",
                "If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization.",
                "In practice, the designer may also be interested in the outcome per se.",
                "For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical.",
                "For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed.",
                "Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments.",
                "In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand.",
                "This approach addresses all of the downsides listed above.",
                "We formulate the mechanism design problem as an optimization problem.",
                "The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types.",
                "The output is a nonmanipulable mechanism that is optimal with respect to some objective.",
                "This approach is called automated mechanism design.",
                "The automated mechanism design approach has four advantages over the classical approach of designing general mechanisms.",
                "First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare).",
                "Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences.",
                "When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally.",
                "Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types).",
                "Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information.",
                "For example, imagine a company automatically creating its procurement mechanism based on statistical knowledge about its suppliers, rather than using a classical descending procurement auction.",
                "Fourth, the burden of design is shifted from humans to a machine.",
                "However, automated mechanism design requires the mechanism design optimization problem to be solved anew for each setting.",
                "Hence its computational complexity becomes a key issue.",
                "Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6].",
                "In this paper we study the computational complexity of automated mechanism design in the case of a self-interested designer.",
                "This is an important setting for automated mechanism design due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested.",
                "We also show that this problem is closely related to a particular optimal (revenue-maximizing) combinatorial auction design problem. 133 The rest of this paper is organized as follows.",
                "In Section 2, we justify the focus on nonmanipulable mechanisms.",
                "In Section 3, we define the problem we study.",
                "In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it.",
                "In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen.",
                "In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case.",
                "Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2.",
                "JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of automated mechanism design, we should justify our focus on nonmanipulable mechanisms.",
                "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any nonmanipulable mechanism.",
                "This does, however, turn out to be the case: given any mechanism, we can construct a nonmanipulable mechanism whose performance is identical, as follows.",
                "We build an interface layer between the agents and the original mechanism.",
                "The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer.",
                "The resulting outcome is the outcome of the new mechanism.",
                "Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism.",
                "This argument is known in the mechanism design literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22].",
                "However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.)",
                "Given this, we can focus on truthful mechanisms in the rest of the paper. 3.",
                "DEFINITIONS We now formalize the automated mechanism design setting.",
                "Definition 1.",
                "In an automated mechanism design setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize.",
                "There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent).",
                "In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness.",
                "However, in this paper, we focus on the case of a self-interested designer.",
                "A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer.",
                "Definition 2.",
                "A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i.",
                "In the case where g = 0 everywhere, the designer is said to be payment maximizing.",
                "In the case where payments are not possible, g constitutes the objective function by itself.",
                "We now define the kinds of mechanisms under study.",
                "By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them.",
                "Definition 3.",
                "We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing.",
                "The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator.",
                "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 Individual rationality (IR) constraints The first type of constraint is the following.",
                "The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism.",
                "Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.)",
                "This type of constraint is called an IR (individual rationality) constraint.",
                "There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism.",
                "Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type).",
                "We will not study this concept in this paper.",
                "Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others.",
                "Ex post IR means that the agent would always participate even if it knew everybodys type.",
                "We will define the latter two notions of IR formally.",
                "First, we need to formalize the concept of the fallback outcome.",
                "We assume that each agents fallback utility is zero for each one of its types.",
                "This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16].",
                "Definition 4.",
                "In any automated mechanism design setting with an IR constraint, there is a fallback outcome o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)",
                "We can now to define the notions of individual rationality.",
                "Definition 5.",
                "Individual rationality (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
                "A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments.",
                "A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
                "The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle).",
                "For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium.",
                "Definition 6.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known.",
                "Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
                "In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible.",
                "Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report.",
                "If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium.",
                "Definition 7.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth.",
                "Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible. 135 3.3 Automated mechanism design We can now define the computational problem we study.",
                "Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an automated mechanism design setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective.",
                "An interesting special case is the setting where there is only one agent.",
                "In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents.",
                "Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here.",
                "Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here.",
                "This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4.",
                "PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "To demonstrate NPhardness, we reduce from the MINSAT problem.",
                "Definition 9 (MINSAT).",
                "We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|).",
                "We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied.",
                "MINSAT was recently shown to be NP-complete [14].",
                "We can now present our result.",
                "Theorem 1.",
                "Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent payment-maximizing deterministic AMD instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|.",
                "For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the MINSAT solution, and π(θc) = |Θ| if c is satisfied.",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent.",
                "Clearly the agent is better off reporting truthfully, for a total utility of 0.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type.",
                "Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the IR constraint, the maximum payment we can extract from any type θv is |Θ|.",
                "Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.)",
                "Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1.",
                "It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible.",
                "However, it does not yet imply hardness for the special case where payments are not possible.",
                "We will prove hardness in this case in the next section. 5.",
                "SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "Theorem 2.",
                "Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent self-interested deterministic AMD without payments instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1.",
                "Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v).",
                "For every c ∈ C that is satisfied in the MINSAT solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ .",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "The only other outcome that the mechanism is allowed to choose under the IR constraint is o0.",
                "This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}.",
                "We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|.",
                "For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).)",
                "Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes.",
                "It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Both of our hardness results relied on the constraint that the mechanism should be deterministic.",
                "In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6.",
                "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of self-interested AMD tractable through linear programming, for any constant number of agents.",
                "Theorem 3.",
                "Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated.",
                "Proof.",
                "Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}.",
                "The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.)",
                "First, we show the IR constraints.",
                "For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
                "For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
                "Now, we show the solution concept constraints.",
                "For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
                "Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
                "All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
                "As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents.",
                "Thus the problem is solvable in polynomial time. 7.",
                "IMPLICATIONS FOR AN OPTIMAL COMBINATORIAL AUCTION DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated mechanism design for a self-interested designer on designing optimal combinatorial auctions.",
                "Consider a combinatorial auction with a set S of items for sale.",
                "For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi.",
                "The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.)",
                "The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18].",
                "However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25].",
                "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of complementarity and no substitutability has been solved recently [1].)",
                "Suppose we have free disposal-items can be thrown away at no cost.",
                "Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.)",
                "Definition 10.",
                "Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
                "We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item.",
                "The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type.",
                "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the payment maximizing AMD problem!",
                "Theorem 4.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types.",
                "Proof.",
                "The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming.",
                "To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal combinatorial auction design problem instance with a single bidder with best-only preferences.",
                "For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance).",
                "Let the expected revenue target value be the same in both instances.",
                "We show the instances are equivalent.",
                "First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function.",
                "Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.)",
                "Let the payment functions be the same in both instances.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same.",
                "It follows that there exists a solution to the optimal auction design instance.",
                "Now suppose there exists a solution to the optimal auction design instance.",
                "By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item.",
                "Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type.",
                "If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type.",
                "Let the payment functions be the same.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same.",
                "It follows that there exists a solution to the AMD instance.",
                "Fortunately, we can also carry through the easiness result for randomized mechanisms to this combinatorial auction setting-giving us one of the few known polynomial-time algorithms for an optimal combinatorial auction design problem.",
                "Theorem 5.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.)",
                "Proof.",
                "By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item.",
                "There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations.",
                "Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8.",
                "RELATED RESEARCH ON COMPLEXITY IN MECHANISM DESIGN There has been considerable recent interest in mechanism design in computer science.",
                "Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism.",
                "The closest piece of earlier work studied the complexity of automated mechanism design by a benevolent designer [5, 6].",
                "Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21].",
                "This is related to mechanism design, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments).",
                "Also, there is no explicit reporting of preferences. 9.",
                "CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently emerging approach-called automated mechanism design-a mechanism is computed for the specific preference aggregation setting at hand.",
                "This has several advantages, 139 but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike earlier work on automated mechanism design that studied a benevolent designer, in this paper we studied automated mechanism design problems where the designer is self-interesteda setting much more relevant for electronic commerce.",
                "In this setting, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "These hardness results imply hardness in all more general automated mechanism design settings with a self-interested designer.",
                "The hardness results apply whether the individual rationality (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation.",
                "We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy.",
                "Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy.",
                "Future research includes studying automated mechanism design with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments).",
                "We also want to study the complexity of automated mechanism design in settings where the outcome and type spaces have special structure so they can be represented more concisely.",
                "Finally, we plan to assemble a data set of real-world mechanism design problems-both historical and current-and apply automated mechanism design to those problems. 10.",
                "REFERENCES [1] M. Armstrong.",
                "Optimal multi-object auctions.",
                "Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow.",
                "The property rights doctrine and demand revelation under incomplete information.",
                "In M. Boskin, editor, Economics and human welfare.",
                "New York Academic Press, 1979. [3] C. Avery and T. Hendershott.",
                "Bundling and optimal auctions of multiple products.",
                "Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke.",
                "Multipart pricing of public goods.",
                "Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Automated mechanism design: Complexity results stemming from the single-agent setting.",
                "In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm.",
                "Computational criticisms of the revelation principle.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004.",
                "Short paper.",
                "Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet.",
                "Incentives and incomplete information.",
                "Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker.",
                "Sharing the cost of muliticast transmissions.",
                "Journal of Computer and System Sciences, 63:21-41, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard.",
                "Manipulation of voting schemes.",
                "Econometrica, 41:587-602, 1973. [11] T. Groves.",
                "Incentives in teams.",
                "Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri.",
                "Vickrey prices and shortest paths: What is an edge worth?",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan.",
                "A polynomial algorithm in linear programming.",
                "Soviet Math.",
                "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani.",
                "The minimum satisfiability problem.",
                "SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham.",
                "Truth revelation in rapid, approximately efficient combinatorial auctions.",
                "Journal of the ACM, 49(5):577-602, 2002.",
                "Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [17] E. S. Maskin and J. Riley.",
                "Optimal multi-unit auctions.",
                "In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335.",
                "Clarendon Press, Oxford, 1989. [18] R. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen.",
                "Computationally feasible VCG mechanisms.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behavior, 35:166-196, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden.",
                "Designing networks for selfish users is hard.",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm.",
                "Issues in computational Vickrey auctions.",
                "International Journal of Electronic Commerce, 4(3):107-129, 2000.",
                "Special Issue on 140 Applying Intelligent Agents for Electronic Commerce.",
                "A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite.",
                "Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions.",
                "Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey.",
                "Counterspeculation, auctions, and competitive sealed tenders.",
                "Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra.",
                "Research problems in combinatorial auctions.",
                "Mimeo, version Oct. 29, 2001. 141"
            ],
            "original_annotated_samples": [
                "<br>classical mechanism</br> design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective."
            ],
            "translated_annotated_samples": [
                "El diseño de mecanismos clásicos proporciona algunos mecanismos generales, que, bajo ciertas suposiciones, satisfacen alguna noción de no manipulabilidad y maximizan algún objetivo."
            ],
            "translated_text": "Diseño de mecanismos automatizados de interés propio e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les resulte más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente propuesto, llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración de agregación de preferencias actual. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre el diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo. En este caso, al centro solo le importa qué resultado se elige y qué pagos se le hacen. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este contexto, demostramos que el diseño de mecanismos deterministas óptimos es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Luego mostramos cómo permitir la aleatorización en el mecanismo hace que los problemas en este entorno sean computacionalmente fáciles. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (maximizadora de ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar una subasta determinista óptima es NP-completo, pero diseñar una subasta aleatoria óptima es fácil. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Teoría 1. En entornos multiagentes, a menudo se debe elegir un resultado en función de las preferencias informadas por un grupo de agentes. Tales resultados podrían ser presidentes potenciales, planes conjuntos, asignaciones de bienes o recursos, etc. El agregador de preferencias generalmente no conoce las preferencias de los agentes de antemano. Más bien, los agentes informan sus preferencias al coordinador. Desafortunadamente, un agente puede tener un incentivo para informar incorrectamente sus preferencias con el fin de engañar al mecanismo y lograr que seleccione un resultado que sea más deseable para el agente que el resultado que se seleccionaría si el agente revelara sus preferencias de manera honesta. Tal manipulación es indeseable porque los mecanismos de agregación de preferencias están diseñados para agrupar las preferencias de una manera socialmente deseable, y si los agentes revelan sus preferencias de manera insincera, se podría elegir un resultado socialmente indeseable. La manipulabilidad es un problema generalizado en los mecanismos de agregación de preferencias. Un resultado negativo seminal, el teorema de Gibbard-Satterthwaite, muestra que bajo cualquier esquema de agregación de preferencias no dictatorial, si hay al menos 3 posibles resultados, existen preferencias bajo las cuales un agente está mejor reportando falsamente [10, 23]. (Un esquema de agregación de preferencias se llama dictatorial si uno de los agentes dicta el resultado sin importar las preferencias que reporten los otros agentes). Lo que le gustaría hacer al agregador es diseñar un mecanismo de agregación de preferencias para que 1) los agentes interesados reporten sus preferencias de manera veraz, y 2) el mecanismo elija un resultado que sea deseable desde la perspectiva de algún objetivo. Esta es la configuración clásica del diseño de mecanismos en la teoría de juegos. En este documento, estudiamos el caso en el que el diseñador actúa por interés propio, es decir, al diseñador no le importa directamente cómo se relaciona el resultado con las preferencias de los agentes, sino que está más preocupado por su propia agenda sobre cuál resultado debería ser elegido y en maximizar los pagos para sí mismo. Este es el entorno de diseño de mecanismos más relevante para el comercio electrónico. En el caso en que el diseñador del mecanismo esté interesado en maximizar alguna noción de bienestar social, la importancia de recopilar las preferencias de los agentes es clara. Quizás sea menos obvio por qué deberían ser recopilados cuando el diseñador está interesado en sí mismo y, por lo tanto, su objetivo no está directamente relacionado con las preferencias de los agentes. La razón de esto es que a menudo las preferencias de los agentes imponen límites en cómo el diseñador elige el resultado y los pagos. La restricción más común de este tipo es la de racionalidad individual (RI), lo que significa que el mecanismo no puede dejar a ningún agente en una situación peor a la que hubiera estado si no hubiera participado en el mecanismo. Por ejemplo, en el contexto del diseño óptimo de subastas, el diseñador (subastador) solo se preocupa por cuántos ingresos se recaudan, y no en sí mismo por cuán bien la asignación del bien (o bienes) corresponde a las preferencias de los agentes. Sin embargo, el diseñador no puede obligar a un agente a pagar más de lo que valora el paquete de bienes asignado a él. Por lo tanto, incluso un diseñador interesado en sí mismo elegirá un resultado que beneficie razonablemente a los agentes. Por otro lado, el diseñador no necesariamente elegirá un resultado que maximice el bienestar social. Por ejemplo, si el diseñador siempre elige un resultado que maximiza el bienestar social con respecto a las preferencias informadas, y obliga a cada agente a pagar la diferencia entre la utilidad que tiene ahora y la utilidad que habría tenido si no hubiera participado en el mecanismo, es fácil ver que los agentes pueden tener un incentivo para informar incorrectamente sus preferencias, lo que puede llevar realmente a recaudar menos ingresos. De hecho, uno de los resultados contraintuitivos de la teoría del diseño de subastas óptimas es que a veces el bien se asigna a nadie incluso cuando el subastador tiene un precio de reserva de 0. El diseño de mecanismos clásicos proporciona algunos mecanismos generales, que, bajo ciertas suposiciones, satisfacen alguna noción de no manipulabilidad y maximizan algún objetivo. La ventaja de estos mecanismos es que no dependen de información (incluso probabilística) sobre las preferencias de los agentes (por ejemplo, el mecanismo de Vickrey-Clarke-Groves (VCG) [24, 4, 11]), o pueden aplicarse fácilmente a cualquier distribución de probabilidad sobre las preferencias (por ejemplo, el mecanismo dAGVA [8, 2], la subasta de Myerson [18], y la subasta multiunidad de Maskin-Riley [17]). Sin embargo, los mecanismos generales también tienen importantes desventajas: • Los mecanismos generales más famosos y ampliamente aplicables, VCG y dAGVA, solo maximizan el bienestar social. Si el diseñador está interesado en sí mismo, como es el caso en muchos entornos de comercio electrónico, estos mecanismos no maximizan el objetivo del diseñador. • Los mecanismos generales que se centran en un diseñador interesado en sí mismo solo son aplicables en entornos muy restringidos, como la subasta de maximización de ingresos esperados de Myerson para vender un solo artículo, y la subasta de maximización de ingresos esperados de Maskin y Riley para vender múltiples unidades idénticas de un artículo. • Incluso en los entornos restringidos en los que se aplican estos mecanismos, solo permiten la maximización de pagos. En la práctica, el diseñador también puede estar interesado en el resultado en sí mismo. Por ejemplo, a un subastador le puede importar qué postor recibe el artículo. • A menudo se asume que los pagos laterales pueden ser utilizados para adaptar los incentivos de los agentes, pero esto no siempre es práctico. Por ejemplo, en los mercados electrónicos basados en trueque, como Recipco, firstbarter.com, BarterOne e Intagio, no se permiten los pagos laterales. Además, entre los agentes de software, podría ser más deseable construir mecanismos que no dependan de la capacidad de realizar pagos, ya que muchos agentes de software no cuentan con la infraestructura para hacer pagos. Por el contrario, seguimos un enfoque reciente donde el mecanismo se diseña automáticamente para el problema específico en cuestión. Este enfoque aborda todos los inconvenientes mencionados anteriormente. Formulamos el problema de diseño de mecanismos como un problema de optimización. La entrada se caracteriza por el número de agentes, los posibles tipos de agentes (preferencias) y las distribuciones previas de los agregadores sobre los tipos de agentes. La salida es un mecanismo no manipulable que es óptimo con respecto a algún objetivo. Este enfoque se llama diseño de mecanismos automatizado. El enfoque de diseño de mecanismos automatizado tiene cuatro ventajas sobre el enfoque clásico de diseñar mecanismos generales. Primero, se puede utilizar incluso en entornos que no cumplen con las suposiciones de los mecanismos clásicos (como la disponibilidad de pagos laterales o que el objetivo sea el bienestar social). Segundo, puede permitir a uno eludir resultados de imposibilidad (como el teorema de Gibbard-Satterthwaite) que establecen que no existe un mecanismo que sea deseable para todas las preferencias. Cuando el mecanismo está diseñado para la configuración actual, no importa que no funcione de manera más general. Tercero, puede generar mecanismos mejores (en términos de garantías de no manipulabilidad más sólidas y/o mejores resultados) que los mecanismos clásicos porque el mecanismo aprovecha las particularidades del entorno (la información probabilística que el diseñador tiene sobre los tipos de agentes). Dada la gran cantidad de información que las partes tienen entre sí hoy en día, es probable que este enfoque conduzca a ahorros enormes en comparación con los mecanismos clásicos, que en su mayoría ignoran esa información. Por ejemplo, imagina una empresa creando automáticamente su mecanismo de adquisiciones basado en el conocimiento estadístico sobre sus proveedores, en lugar de utilizar una subasta de adquisiciones descendente clásica. Cuarto, la carga del diseño se traslada de los humanos a una máquina. Sin embargo, el diseño automatizado de mecanismos requiere que el problema de optimización del diseño del mecanismo se resuelva de nuevo para cada configuración. Por lo tanto, su complejidad computacional se convierte en un tema clave. Investigaciones previas han estudiado esta pregunta para diseñadores benevolentes que desean maximizar, por ejemplo, el bienestar social [5, 6]. En este artículo estudiamos la complejidad computacional del diseño automatizado de mecanismos en el caso de un diseñador con interés propio. Esta es una configuración importante para el diseño de mecanismos automatizados debido a la escasez de mecanismos generales en esta área, y al hecho de que en la mayoría de las configuraciones de comercio electrónico el diseñador actúa en su propio interés. También demostramos que este problema está estrechamente relacionado con un problema de diseño de subasta combinatoria óptima (maximización de ingresos) particular. El resto de este documento está organizado de la siguiente manera. En la Sección 2, justificamos el enfoque en mecanismos no manipulables. En la Sección 3, definimos el problema que estudiamos. En la Sección 4, demostramos que diseñar un mecanismo determinista óptimo es NP-completo incluso cuando al diseñador solo le importan los pagos que recibe. En la Sección 5, demostramos que diseñar un mecanismo determinista óptimo también es NP-completo cuando los pagos no son posibles y el diseñador solo está interesado en el resultado elegido. En la Sección 6, demostramos que un mecanismo óptimo aleatorizado puede ser diseñado en tiempo polinómico incluso en el caso general. Finalmente, en la Sección 7, demostramos que para diseñar subastas combinatorias óptimas bajo preferencias de mejor opción solamente, nuestros resultados sobre AMD implican que este problema es NP-completo para subastas determinísticas, pero sencillo para subastas aleatorias. 2. JUSTIFICANDO EL ENFOQUE EN MECANISMOS NO MANIPULABLES Antes de definir el problema computacional del diseño automatizado de mecanismos, debemos justificar nuestro enfoque en mecanismos no manipulables. Después de todo, no es inmediatamente obvio que no haya mecanismos manipulables que, incluso cuando los agentes informan estratégicamente sus tipos y, por lo tanto, a veces de manera no veraz, aún logren mejores resultados (según el objetivo que usemos) que cualquier mecanismo no manipulable. Sin embargo, resulta ser el caso que, dado cualquier mecanismo, podemos construir un mecanismo no manipulable cuyo rendimiento es idéntico, de la siguiente manera. Construimos una capa de interfaz entre los agentes y el mecanismo original. Los agentes informan sus preferencias (o tipos) a la capa de interfaz; posteriormente, la capa de interfaz introduce en el mecanismo original los tipos que los agentes habrían informado estratégicamente al mecanismo original, si sus tipos fueran los declarados a la capa de interfaz. El resultado resultante es el resultado del nuevo mecanismo. Dado que la capa de interfaz actúa estratégicamente en nombre de cada agente, nunca hay un incentivo para informar falsamente a la capa de interfaz; por lo tanto, los tipos informados por la capa de interfaz son los tipos estratégicos que se habrían informado sin la capa de interfaz, por lo que los resultados son exactamente como habrían sido con el mecanismo original. Este argumento es conocido en la literatura de diseño de mecanismos como el principio de revelación [16]. (Existen dificultades computacionales al aplicar el principio de revelación en espacios de resultados y tipos combinatorios grandes [7, 22]). Sin embargo, dado que aquí nos enfocamos en espacios de resultados y tipos representados de forma plana, esto no es una preocupación aquí. Dado esto, podemos centrarnos en mecanismos veraces en el resto del documento. 3. DEFINICIONES Ahora formalizamos el entorno del diseño automatizado de mecanismos. Definición 1. En un entorno de diseño de mecanismos automatizados, se nos proporciona: • un conjunto finito de resultados O; • un conjunto finito de N agentes; • para cada agente i, 1. un conjunto finito de tipos Θi, 2. una distribución de probabilidad γi sobre Θi (en el caso de tipos correlacionados, hay una única distribución conjunta γ sobre Θ1 × . . . × ΘN), y 3. una función de utilidad ui: Θi × O → R; 1 • Una función objetivo cuya expectativa el diseñador desea maximizar. Existen muchas posibles funciones objetivo que el diseñador podría tener, por ejemplo, el bienestar social (donde el diseñador busca maximizar la suma de las utilidades de los agentes), o la utilidad mínima de cualquier agente (donde el diseñador busca maximizar la peor utilidad experimentada por cualquier agente). En ambos casos, el diseñador es benevolente, ya que, de alguna manera, el diseñador está buscando la felicidad colectiva de los agentes. Sin embargo, en este documento nos enfocamos en el caso de un diseñador interesado en sí mismo. Un diseñador egoísta solo se preocupa por el resultado elegido (es decir, al diseñador no le importa cómo se relaciona el resultado con las preferencias de los agentes, sino que tiene una preferencia fija sobre los resultados) y sobre los pagos netos realizados por los agentes, que fluyen hacia el diseñador. Definición 2. Un diseñador interesado tiene una función objetivo dada por g(o) + Σ i=1 πi, donde g : O → R indica las preferencias del diseñador sobre los resultados, y πi es el pago realizado por el agente i. En el caso en que g = 0 en todas partes, se dice que el diseñador está maximizando el pago. En el caso en que los pagos no sean posibles, g constituye la función objetivo por sí sola. Ahora definimos los tipos de mecanismos en estudio. Por el principio de revelación, podemos restringir la atención a mecanismos de revelación directa y veraz, donde los agentes informan directamente sus tipos y nunca tienen incentivos para informarlos de manera incorrecta. Definición 3. Consideramos los siguientes tipos de mecanismos: • Un mecanismo determinista sin pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O. • Un mecanismo aleatorio sin pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), donde P(O) es el conjunto de distribuciones de probabilidad sobre O. • Un mecanismo determinista con pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O y, para cada agente i, una función de selección de pagos πi: Θ1 × Θ2 × . . . × ΘN → R, donde πi(θ1, . . . , θN ) da el pago realizado por el agente i cuando los tipos reportados son θ1, . . . , θN. Aunque esto sigue la notación estándar de la teoría de juegos [16], el hecho de que el agente tenga tanto una función de utilidad como un tipo puede resultar confuso. Los tipos codifican las diversas preferencias posibles que el agente pueda tener, y el tipo de los agentes no es conocido por el agregador. La función de utilidad es un conocimiento común, pero debido a que el tipo de agente es un parámetro en la función de utilidad de los agentes, el agregador no puede saber cuál es la utilidad de los agentes sin conocer el tipo de agente. Un mecanismo aleatorio con pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), y para cada agente i, una función de selección de pago πi: Θ1 × Θ2 × . . . × ΘN → R. Hay dos tipos de restricciones para el diseñador al construir el mecanismo. 3.1 Restricciones de racionalidad individual (IR) El primer tipo de restricción es el siguiente. La utilidad de cada agente debe ser al menos tan grande como la utilidad de respaldo de los agentes, es decir, la utilidad que el agente recibiría si no participara en el mecanismo. De lo contrario, ese agente no participaría en el mecanismo, y la participación de ningún agente puede perjudicar el objetivo de los diseñadores del mecanismo, ya que en el peor de los casos, el mecanismo puede ignorar a un agente fingiendo que el agente no está presente. (Además, si no se aplicara tal restricción, el diseñador simplemente podría hacer que los agentes paguen una cantidad infinita). Este tipo de restricción se llama restricción de IR (racionalidad individual). Existen tres posibles restricciones de IR diferentes: ex ante, ex interim y ex post, dependiendo de lo que el agente sabe sobre su propio tipo y los tipos de los demás al decidir si participar en el mecanismo. Ex ante IR significa que el agente participaría si no supiera absolutamente nada (ni siquiera su propio tipo). No estudiaremos este concepto en este documento. Ex interim IR significa que el agente siempre participaría si conociera solo su propio tipo, pero no el de los demás. Ex post IR significa que el agente siempre participaría incluso si conociera el tipo de todos. Definiremos formalmente las dos últimas nociones de IR. Primero, necesitamos formalizar el concepto del resultado de respaldo. Suponemos que la utilidad de respaldo de cada agente es cero para cada uno de sus tipos. Esto se hace sin pérdida de generalidad porque podemos agregar un término constante a la función de utilidad de un agente (para un tipo dado), sin afectar el comportamiento de toma de decisiones de ese agente maximizador de utilidad esperada [16]. Definición 4. En cualquier entorno de diseño de mecanismos automatizados con una restricción de IR, existe un resultado de contingencia o0 ∈ O donde, para cualquier agente i y cualquier tipo θi ∈ Θi, tenemos ui(θi, o0) = 0. (Además, en el caso de un diseñador egoísta, g(o0) = 0). Ahora podemos definir las nociones de racionalidad individual. Definición 5. La racionalidad individual (RI) se define como: • Un mecanismo determinista es ex interim RI si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0. Un mecanismo aleatorio es ex interim IR si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • Un mecanismo determinista es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 No aleatorizamos sobre los pagos porque mientras los agentes y el diseñador sean neutrales al riesgo con respecto a los pagos, es decir, su utilidad es lineal en los pagos, no hay razón para aleatorizar sobre los pagos. Un mecanismo aleatorio es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 3.2 Restricciones de compatibilidad de incentivos (IC) El segundo tipo de restricción establece que los agentes nunca deben tener un incentivo para informar incorrectamente su tipo (como se justificó anteriormente mediante el principio de revelación). Para este tipo de restricción, las dos variantes más comunes (o conceptos de solución) son la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash. Definición 6. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en estrategias dominantes si decir la verdad siempre es óptimo incluso cuando los tipos reportados por los otros agentes ya son conocidos. Formalmente, para cualquier agente i, cualquier vector de tipos (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ). En el caso de mecanismos aleatorios tenemos Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. Por lo tanto, en la implementación de estrategias dominantes, decir la verdad es óptimo independientemente de lo que informen los otros agentes. Si es óptimo solo dado que los otros agentes son veraces, y dado que uno no conoce los tipos de los otros agentes, tenemos implementación en equilibrio de Bayes-Nash. Definición 7. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en equilibrio de Bayes-Nash si decir la verdad siempre es óptimo para un agente cuando ese agente aún no sabe nada sobre los tipos de los otros agentes, y los otros agentes están diciendo la verdad. Formalmente, para cualquier agente i, cualquier tipo θi ∈ Θi, y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )]. En el caso de mecanismos aleatorios tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 135 3.3 Diseño de mecanismos automatizados Ahora podemos definir el problema computacional que estudiamos. Definición 8. (DISEÑO DE MECANISMOS AUTOMATIZADOS (AMD)) Se nos da: • un entorno de diseño de mecanismos automatizados, • una noción de IR (ex interim, ex post, o ninguna), • un concepto de solución (estrategias dominantes o Bayes-Nash), • si los pagos son posibles, • si la aleatorización es posible, • (en la variante de decisión del problema) un valor objetivo G. Se nos pregunta si existe un mecanismo del tipo especificado (en términos de pagos y aleatorización) que satisfaga tanto la noción de IR como el concepto de solución, y proporcione un valor esperado de al menos G para el objetivo. Un caso especial interesante es aquel en el que solo hay un agente. En este caso, el agente informante siempre sabe todo lo que hay que saber sobre los otros tipos de agentes, porque no hay otros agentes. Dado que el IR ex post y el IR ex interim solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de IR coinciden aquí. Además, dado que la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de solución coinciden aquí. Esta observación resultará ser una herramienta útil para demostrar resultados de dificultad: si demostramos dificultad computacional en el escenario de un solo agente, esto implica inmediatamente dificultad para ambos conceptos de IR, para ambos conceptos de solución, para cualquier número de agentes. 4. En esta sección demostramos que es NP-completo diseñar un mecanismo determinístico que maximice la suma esperada de los pagos recolectados de los agentes. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Para demostrar la NP-dureza, reducimos desde el problema MINSAT. Definición 9 (MINSAT). Se nos da una fórmula φ en forma normal conjuntiva, representada por un conjunto de variables booleanas V y un conjunto de cláusulas C, y un entero K (K < |C|). Se nos pregunta si existe una asignación a las variables en V tal que se satisfacen a lo sumo K cláusulas en φ. MINSAT fue recientemente demostrado como NP-completo [14]. Ahora podemos presentar nuestro resultado. Teorema 1. El problema determinista de maximización de pagos de AMD es NP-completo, incluso para un solo agente, incluso con una distribución uniforme de tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista de maximización de pagos de un solo agente. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V } ∪ {−v : v ∈ V }. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Sea l ∈ c denota que el literal l ocurre en la cláusula c. Entonces, la función de utilidad de los agentes está dada por u(θc, ol) = |Θ| + 1 para todo l ∈ L con l ∈ c; u(θc, ol) = 0 para todo l ∈ L con l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc) = 0 para todo c ∈ C con c = c; u(θv, ol) = |Θ| para todo l ∈ L con v(l) = v; u(θv, ol) = 0 para todo l ∈ L con v(l) = v; u(θv, oc) = 0 para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ|, donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v) y π(θv) = |Θ|. Para cada c ∈ C, sea o(θc) = oc; sea π(θc) = |Θ| + 1 si c no está satisfecha en la solución MINSAT, y π(θc) = |Θ| si c está satisfecha. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es θv, entonces cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivo para informar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Porque además, ningún tipo que no sea θc conduce al resultado oc, informar cualquier otro tipo dará como resultado una utilidad de 0, mientras que aún se requiere un pago de al menos |Θ| por parte del agente. Claramente, el agente está mejor reportando honestamente, para una utilidad total de 0. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), el pago esperado de este mecanismo es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o y una función de pago π. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. Entonces, la utilidad que el agente obtiene del resultado dado para este tipo es 0, y por lo tanto, según la IR, no se puede extraer ningún pago del agente para este tipo. Dado que, nuevamente por IR, el pago máximo que se puede extraer para cualquier otro tipo es |Θ| + 1, se sigue que el pago esperado máximo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo cual contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o−v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por la restricción de IR, el pago máximo que podemos extraer de cualquier tipo θv es |Θ|. Dado que no puede haber incentivos para que el agente informe falsamente, para cualquier cláusula c satisfecha por la asignación dada, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ|. (Pues si extrajéramos más de este tipo, la utilidad del agente en este caso sería menor que 1; y si v es la variable que satisface c en la asignación, de modo que o(θv) = ol donde l ocurre en c, entonces al agente le convendría más informar θv en lugar del informe veraz θc, para obtener un resultado que valga |Θ|+1 para él mientras tiene que pagar como máximo |Θ|.) Finalmente, para cualquier cláusula insatisfecha c, según la restricción de IR, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ| + 1. Se deduce que el pago esperado de nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia de MINSAT. Dado que AMD, que maximiza el pago, es solo un caso especial de AMD para un diseñador egoísta en el que el diseñador no tiene preferencias sobre el resultado elegido, esto implica inmediatamente dificultades para el caso general de AMD para un diseñador egoísta en el que los pagos son posibles. Sin embargo, esto aún no implica dureza para el caso especial donde los pagos no son posibles. Demostraremos la dificultad en este caso en la próxima sección. 5. En esta sección demostramos que es NP-completo diseñar un mecanismo determinista que maximice la expectativa del objetivo del diseñador cuando no son posibles los pagos. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Teorema 2. Sin pagos, el diseño determinista de AMD para un diseñador egoísta es NP-completo, incluso para un solo agente, incluso con una distribución uniforme sobre los tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista auto-interesada de un solo agente sin pagos. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L} ∪ {o∗}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V} ∪ {−v : v ∈ V}. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Deje que l ∈ c denote que el literal l ocurre en la cláusula c. Luego, deje que la función de utilidad de los agentes esté dada por u(θc, ol) = 2 para todo l ∈ L con l ∈ c; u(θc, ol) = −1 para todo l ∈ L con l /∈ c; u(θc, oc) = 2; u(θc, oc) = −1 para todo c ∈ C con c = c; u(θc, o∗) = 1; u(θv, ol) = 1 para todo l ∈ L con v(l) = v; u(θv, ol) = −1 para todo l ∈ L con v(l) = v; u(θv, oc) = −1 para todo c ∈ C; u(θv, o∗) = −1. Que la función objetivo de los diseñadores esté dada por g(o∗ ) = |Θ|+1; g(ol) = |Θ| para todo l ∈ L; g(oc) = |Θ| para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ| , donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v). Para cada c ∈ C que se cumpla en la solución MINSAT, sea o(θc) = oc; para cada c ∈ C no satisfecho, sea o(θc) = o∗. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es algún θv, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para reportar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Debido a que tampoco ningún tipo conduce al resultado oc, no hay ningún resultado que el mecanismo seleccione que le daría al agente una utilidad mayor a 1 para el tipo θc, y por lo tanto el agente no tiene incentivo para informar falsamente. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), entonces el valor esperado de la función objetivo de los diseñadores es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. El único otro resultado que el mecanismo puede elegir bajo la restricción de IR es o0. Esto tiene un valor objetivo de 0, y dado que el valor más alto que la función objetivo alcanza es |Θ| + 1, se sigue que el valor esperado máximo de la función objetivo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo que contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o-v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por lo anterior, para cualquier tipo θv, el valor de la función objetivo en este mecanismo será |Θ|. Para cualquier cláusula c satisfecha por la asignación dada, el valor de la función objetivo en el caso en que el agente informe el tipo θc será como máximo |Θ|. (Esto se debe a que no podemos elegir el resultado o∗ para dicho tipo, ya que en este caso el agente tendría un incentivo para informar θv en su lugar, donde v es la variable que satisface c en la asignación (de modo que o(θv) = ol donde l ocurre en c).) Finalmente, para cualquier cláusula insatisfecha c, el valor máximo que la función objetivo puede alcanzar en el caso en que el agente informa el tipo θc es |Θ| + 1, simplemente porque este es el valor más grande que la función alcanza en cualquier momento. Se deduce que el valor esperado de la función objetivo para nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas 137 satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia MINSAT. Ambos de nuestros resultados de dureza se basaron en la restricción de que el mecanismo debería ser determinista. En la siguiente sección, mostramos que la dificultad del diseño desaparece cuando permitimos la aleatorización en el mecanismo. 6. La aleatorización de AMD para un diseñador interesado en sí mismo es fácil. Ahora mostramos cómo permitir la aleatorización sobre los resultados hace que el problema de AMD auto-interesado sea manejable a través de la programación lineal, para cualquier número constante de agentes. Teorema 3. El AMD aleatorio con interés propio con un número constante de agentes es resoluble en tiempo polinómico mediante programación lineal, tanto con pagos como sin pagos, tanto para IR ex post como ex interim, y tanto para la implementación en estrategias dominantes como para la implementación en equilibrio de Bayes-Nash, incluso si los tipos están correlacionados. Prueba. Dado que los programas lineales pueden resolverse en tiempo polinómico [13], todo lo que necesitamos demostrar es que el número de variables y ecuaciones en nuestro programa es polinomial para cualquier número constante de agentes, es decir, exponencial solo en N. En todo momento, para determinar el tamaño del programa lineal, consideremos T = maxi{|Θi|}. Las variables de nuestro programa lineal serán las probabilidades (p(θ1, θ2, . . . , θN ))(o) (como máximo TN |O| variables) y los pagos πi(θ1, θ2, . . . , θN ) (como máximo NTN variables). (Mostramos el programa lineal para el caso en que los pagos son posibles; el caso sin pagos se obtiene fácilmente de esto simplemente omitiendo todas las variables de pago en el programa, o agregando restricciones adicionales que obliguen a los pagos a ser 0). Primero, mostramos las restricciones de IR. Para el IR ex post, agregamos las siguientes restricciones (como máximo NTN) al LP: • Para cada i ∈ {1, 2, . . . , N}, y para cada (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , agregamos ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0. Para el ex interino IR, agregamos las siguientes restricciones (como máximo NT) al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada θi ∈ Θi, agregamos θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0. Ahora, mostramos las restricciones del concepto de solución. Para la implementación en estrategias dominantes, agregamos las siguientes (a lo sumo NTN+1) restricciones al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ). Finalmente, para la implementación en el equilibrio de Bayes-Nash, agregamos las siguientes (a lo sumo NT2) restricciones al LP: • Para cada i ∈ {1, 2, ..., N}, para cada θi ∈ Θi, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )). Todo lo que queda por hacer es dar la expresión que el diseñador busca maximizar, que es: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )). Como indicamos, el número de variables y restricciones es exponencial solo en N, por lo tanto, el programa lineal tiene un tamaño polinómico para un número constante de agentes. Por lo tanto, el problema es resoluble en tiempo polinómico. IMPLICACIONES PARA UN PROBLEMA DE DISEÑO DE SUBASTA COMBINATORIA ÓPTIMA En esta sección, demostraremos algunas consecuencias interesantes del problema de diseño de mecanismos automatizados para un diseñador interesado en sí mismo en el diseño de subastas combinatorias óptimas. Considera una subasta combinatoria con un conjunto S de artículos en venta. Para cualquier conjunto B ⊆ S, dejemos que ui(θi, B) sea la utilidad del postor i al recibir el conjunto B cuando el tipo del postor es θi. El problema de diseño de subasta óptima consiste en especificar las reglas de la subasta de manera que se maximice los ingresos esperados para el subastador. (Por el principio de revelación, sin pérdida de generalidad, podemos asumir que la subasta es veraz). El problema de diseño de subasta óptima se resuelve para el caso de un solo artículo mediante la famosa subasta de Myerson [18]. Sin embargo, el diseño de subastas óptimas en subastas combinatorias es un problema de investigación abierto reconocido [3, 25]. El problema está abierto incluso si solo hay dos artículos en venta. (El caso de dos artículos con una forma muy especial de complementariedad y sin sustituibilidad ha sido resuelto recientemente [1].) Supongamos que tenemos disposición libre: los artículos pueden ser desechados sin costo alguno. Además, supongamos que las preferencias de los postores tienen la siguiente estructura: cuando un postor recibe un conjunto de artículos, la utilidad del postor por ese conjunto está determinada únicamente por el mejor artículo en el conjunto. (Enfatizamos que qué artículo es el mejor puede depender del tipo de postor). Definición 10. Se dice que el postor i tiene preferencias solo por lo mejor sobre paquetes de artículos si existe una función vi: Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s). Hacemos la siguiente observación útil en este contexto: no tiene sentido otorgarle a un postor más de un artículo. La razón es que si el postor está informando honestamente, quitarle todos los artículos menos el de mayor valor no perjudicará al postor; y, mediante la disposición gratuita, hacerlo solo reducirá el incentivo para que este postor informe falsamente este tipo, cuando en realidad tiene otro tipo. Ahora demostramos que el problema de diseñar una subasta óptima determinista es NP-completo, mediante una reducción del problema AMD de maximización de pagos. Teorema 4. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de artículos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), diseñar la subasta determinística óptima es NP-completo, incluso para un único postor con una distribución uniforme sobre los tipos. Prueba. El problema está en NP porque podemos generar de manera no determinista una regla de asignación, y luego establecer los pagos utilizando programación lineal. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de AMD determinista que maximiza el pago, con un único agente y una distribución uniforme de tipos, al siguiente problema de diseño de subasta combinatoria óptima con una única postor con preferencias de solo los mejores. Para cada resultado o ∈ O en la instancia de AMD (excepto el resultado o0), que haya un artículo so ∈ S. Que el espacio de tipos sea el mismo, y que v(θi, so) = ui(θi, o) (donde u está especificado en la instancia de AMD). Que el valor objetivo de ingresos esperados sea el mismo en ambas instancias. Mostramos que las instancias son equivalentes. Primero supongamos que existe una solución para la instancia de AMD, dada por una función de resultado y una función de pago. Entonces, si la solución de AMD elige el resultado o para un tipo, en la solución de subasta óptima, asignamos {so} al postor para este tipo. (A menos que o = o0, en cuyo caso asignamos {} al postor). Que las funciones de pago sean las mismas en ambas instancias. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo verdadero) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución óptima de la subasta. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el subastador/diseñador son los mismos. Se deduce que existe una solución para la instancia de diseño de subasta óptima. Ahora supongamos que existe una solución para la instancia de diseño de subasta óptima. Por la observación de que como máximo se puede tener un artículo, podemos asumir sin pérdida de generalidad que la solución nunca asigna más de un artículo. Entonces, si la solución de subasta óptima asigna el artículo al postor para un tipo, en la solución de AMD, permita que el mecanismo elija el resultado o para ese tipo. Si la solución de subasta óptima no asigna nada al postor para un tipo, en la solución AMD, permita que el mecanismo elija el resultado o0 para ese tipo. Que las funciones de pago sean las mismas. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo real) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución AMD. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el diseñador/subastador son los mismos. Se deduce que existe una solución para la instancia de AMD. Afortunadamente, también podemos extender el resultado de facilidad para mecanismos aleatorios a este escenario de subasta combinatoria, lo que nos proporciona uno de los pocos algoritmos de tiempo polinómico conocidos para un problema de diseño óptimo de subasta combinatoria. Teorema 5. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de elementos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), si el número de postores es una constante k, entonces la subasta aleatoria óptima puede ser diseñada en tiempo polinómico. (Para cualquier restricción de IC e IR.) Prueba. Por la observación de que a lo sumo un artículo, podemos sin pérdida de generalidad restringirnos a asignaciones donde cada postor recibe como máximo un artículo. Hay menos de (|S| + 1)k asignaciones de ese tipo, es decir, un número polinómico de asignaciones. Dado que podemos enumerar explícitamente los resultados, simplemente podemos resolver esto como una instancia de AMD que maximiza el pago, con programación lineal. 8. Investigaciones relacionadas sobre la complejidad en el diseño de mecanismos. Ha habido un considerable interés reciente en el diseño de mecanismos en la informática. Parte de ello se ha centrado en cuestiones de complejidad computacional, pero la mayor parte de ese trabajo ha buscado diseñar mecanismos que sean fáciles de ejecutar (por ejemplo, [20, 15, 19, 9, 12]), en lugar de estudiar la complejidad de diseñar el mecanismo. La pieza más cercana de trabajo anterior estudió la complejidad del diseño automatizado de mecanismos por un diseñador benevolente [5, 6]. Roughgarden ha estudiado la complejidad de diseñar una buena topología de red para agentes que eligen egoístamente los enlaces que utilizan [21]. Esto está relacionado con el diseño de mecanismos, pero difiere significativamente en que el diseñador solo tiene un control restringido sobre las reglas del juego porque no hay ninguna parte que pueda imponer el resultado (o pagos laterales). Además, no hay un informe explícito de preferencias. 9. CONCLUSIONES E INVESTIGACIONES FUTURAS A menudo, un resultado debe ser elegido en función de las preferencias informadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les sea más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente emergente llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración específica de agregación de preferencias en cuestión. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo, un entorno mucho más relevante para el comercio electrónico. En este contexto, al centro solo le importa qué resultado se elige y qué pagos se le realizan. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este escenario, demostramos que diseñar un mecanismo determinista óptimo es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Estos resultados de dureza implican dificultad en todos los entornos de diseño de mecanismos automatizados más generales con un diseñador egoísta. Los resultados de dureza se aplican ya sea que las restricciones de racionalidad individual (participación) se apliquen ex interim o ex post, y ya sea que el concepto de solución sea la implementación de estrategias dominantes o la implementación del equilibrio de Bayes-Nash. Luego demostramos que permitir la aleatorización en el mecanismo hace que el problema de diseño en todos estos escenarios sea computacionalmente sencillo. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (que maximiza los ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar un mecanismo determinístico óptimo es NP-completo incluso con un agente, pero diseñar un mecanismo aleatorio óptimo es fácil. La investigación futura incluye estudiar el diseño automatizado de mecanismos con un diseñador interesado en sí mismo en entornos más restringidos, como subastas (donde el objetivo del diseñador puede incluir preferencias sobre qué postor debería recibir el bien, así como los pagos). También queremos estudiar la complejidad del diseño de mecanismos automatizados en entornos donde los espacios de resultados y tipos tienen una estructura especial para que puedan representarse de manera más concisa. Finalmente, planeamos reunir un conjunto de datos de problemas de diseño de mecanismos del mundo real, tanto históricos como actuales, y aplicar el diseño de mecanismos automatizado a esos problemas. 10. REFERENCIAS [1] M. Armstrong. Subastas multi-objetivo óptimas. Revisión de Estudios Económicos, 67:455-481, 2000. [2] K. Arrow. La doctrina de los derechos de propiedad y la revelación de la demanda bajo información incompleta. En M. Boskin, editor, Economía y bienestar humano. New York Academic Press, 1979. [3] C. Avery y T. Hendershott. Agrupación y subastas óptimas de múltiples productos. Revisión de Estudios Económicos, 67:483-497, 2000. [4] E. H. Clarke. Precios escalonados de bienes públicos. Elección Pública, 11:17-33, 1971. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Actas de la 18ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI-02), páginas 103-110, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Diseño de mecanismos automatizados: Resultados de complejidad derivados del entorno de un solo agente. En Actas de la 5ta Conferencia Internacional de Comercio Electrónico (ICEC-03), páginas 17-24, Pittsburgh, PA, EE. UU., 2003. [7] V. Conitzer y T. Sandholm. Críticas computacionales del principio de revelación. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), Nueva York, NY, 2004. Breve ensayo. La versión completa apareció en el taller AAMAS-03 sobre Comercio Electrónico Mediado por Agentes (AMEC). [8] C. d'Aspremont y L. A. Gérard-Varet. Incentivos e información incompleta. Revista de Economía Pública, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou y S. Shenker. Compartiendo el costo de las transmisiones de multidifusión. Revista de Ciencias de la Computación y de Sistemas, 63:21-41, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 2000. [10] A. Gibbard. Manipulación de esquemas de votación. Econometrica, 41:587-602, 1973. [11] T. Groves.\nEconometrica, 41:587-602, 1973. [11] T. Groves. Incentivos en equipos. Econometrica, 41:617-631, 1973. [12] J. Hershberger y S. Suri. Precios de Vickrey y caminos más cortos: ¿Cuánto vale una arista? En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [13] L. Khachiyan. Un algoritmo polinómico en programación lineal. Matemática soviética. Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi y P. Mirchandani. El problema de satisfacibilidad mínimo. Revista SIAM de Matemáticas Discretas, 7(2):275-283, 1994. [15] D. Lehmann, L. I. O'Callaghan y Y. Shoham. Revelación de la verdad en subastas combinatorias rápidas y aproximadamente eficientes. Revista de la ACM, 49(5):577-602, 2002. La versión inicial apareció en las Actas de la Conferencia de Comercio Electrónico de la ACM (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [17] E. S. Maskin y J. Riley. Subastas multiunidad óptimas. En F. Hahn, editor, \"La economía de los mercados faltantes, la información y los juegos\", capítulo 14, páginas 312-335. Clarendon Press, Oxford, 1989. [18] R. Myerson.\nPrensa Clarendon, Oxford, 1989. [18] R. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6:58-73, 1981. [19] N. Nisan y A. Ronen. Mecanismos VCG computacionalmente factibles. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 242-252, Minneapolis, MN, 2000. [20] N. Nisan y A. Ronen. Diseño de mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166-196, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 1999. [21] T. Roughgarden. Diseñar redes para usuarios egoístas es difícil. En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [22] T. Sandholm. Problemas en subastas computacionales de Vickrey. Revista Internacional de Comercio Electrónico, 4(3):107-129, 2000. Número especial sobre la Aplicación de Agentes Inteligentes para el Comercio Electrónico. Una versión corta y temprana apareció en la Segunda Conferencia Internacional sobre Sistemas Multiagente (ICMAS), páginas 299-306, 1996. [23] M. A. Satterthwaite. In Spanish, the translation would be: \"Inmutabilidad estratégica y condiciones de Arrow: teoremas de existencia y correspondencia para procedimientos de votación y funciones de bienestar social.\" Revista de Teoría Económica, 10:187-217, 1975. [24] W. Vickrey. Contrarrestando la especulación, subastas y ofertas selladas competitivas. Revista de Finanzas, 16:8-37, 1961. [25] R. V. Vohra. Problemas de investigación en subastas combinatorias. Mimeo, versión 29 de octubre de 2001. 141 ",
            "candidates": [],
            "error": [
                []
            ]
        },
        "payment maximizing": {
            "translated_key": "maximizando el pago",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-interested Automated Mechanism Design and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently proposed approach-called automated mechanism design-a mechanism is computed for the preference aggregation setting at hand.",
                "This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike the earlier work on automated mechanism design that studied a benevolent designer, in this paper we study automated mechanism design problems where the designer is self-interested.",
                "In this case, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy.",
                "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy.",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc.",
                "The preference aggregator generally does not know the agents preferences a priori.",
                "Rather, the agents report their preferences to the coordinator.",
                "Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully.",
                "Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen.",
                "Manipulability is a pervasive problem across preference aggregation mechanisms.",
                "A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.)",
                "What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective.",
                "This is the classic setting of mechanism design in game theory.",
                "In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself.",
                "This is the mechanism design setting most relevant to electronic commerce.",
                "In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear.",
                "It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences.",
                "The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments.",
                "The most common such constraint is that of individual rationality (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
                "For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences.",
                "Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it.",
                "Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off.",
                "On the other hand, the designer will not necessarily choose a social welfare maximizing outcome.",
                "For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected.",
                "Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0.",
                "Classical mechanism design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective.",
                "The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]).",
                "However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare.",
                "If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization.",
                "In practice, the designer may also be interested in the outcome per se.",
                "For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical.",
                "For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed.",
                "Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments.",
                "In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand.",
                "This approach addresses all of the downsides listed above.",
                "We formulate the mechanism design problem as an optimization problem.",
                "The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types.",
                "The output is a nonmanipulable mechanism that is optimal with respect to some objective.",
                "This approach is called automated mechanism design.",
                "The automated mechanism design approach has four advantages over the classical approach of designing general mechanisms.",
                "First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare).",
                "Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences.",
                "When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally.",
                "Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types).",
                "Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information.",
                "For example, imagine a company automatically creating its procurement mechanism based on statistical knowledge about its suppliers, rather than using a classical descending procurement auction.",
                "Fourth, the burden of design is shifted from humans to a machine.",
                "However, automated mechanism design requires the mechanism design optimization problem to be solved anew for each setting.",
                "Hence its computational complexity becomes a key issue.",
                "Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6].",
                "In this paper we study the computational complexity of automated mechanism design in the case of a self-interested designer.",
                "This is an important setting for automated mechanism design due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested.",
                "We also show that this problem is closely related to a particular optimal (revenue-maximizing) combinatorial auction design problem. 133 The rest of this paper is organized as follows.",
                "In Section 2, we justify the focus on nonmanipulable mechanisms.",
                "In Section 3, we define the problem we study.",
                "In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it.",
                "In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen.",
                "In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case.",
                "Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2.",
                "JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of automated mechanism design, we should justify our focus on nonmanipulable mechanisms.",
                "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any nonmanipulable mechanism.",
                "This does, however, turn out to be the case: given any mechanism, we can construct a nonmanipulable mechanism whose performance is identical, as follows.",
                "We build an interface layer between the agents and the original mechanism.",
                "The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer.",
                "The resulting outcome is the outcome of the new mechanism.",
                "Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism.",
                "This argument is known in the mechanism design literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22].",
                "However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.)",
                "Given this, we can focus on truthful mechanisms in the rest of the paper. 3.",
                "DEFINITIONS We now formalize the automated mechanism design setting.",
                "Definition 1.",
                "In an automated mechanism design setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize.",
                "There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent).",
                "In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness.",
                "However, in this paper, we focus on the case of a self-interested designer.",
                "A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer.",
                "Definition 2.",
                "A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i.",
                "In the case where g = 0 everywhere, the designer is said to be <br>payment maximizing</br>.",
                "In the case where payments are not possible, g constitutes the objective function by itself.",
                "We now define the kinds of mechanisms under study.",
                "By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them.",
                "Definition 3.",
                "We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing.",
                "The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator.",
                "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 Individual rationality (IR) constraints The first type of constraint is the following.",
                "The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism.",
                "Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.)",
                "This type of constraint is called an IR (individual rationality) constraint.",
                "There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism.",
                "Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type).",
                "We will not study this concept in this paper.",
                "Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others.",
                "Ex post IR means that the agent would always participate even if it knew everybodys type.",
                "We will define the latter two notions of IR formally.",
                "First, we need to formalize the concept of the fallback outcome.",
                "We assume that each agents fallback utility is zero for each one of its types.",
                "This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16].",
                "Definition 4.",
                "In any automated mechanism design setting with an IR constraint, there is a fallback outcome o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)",
                "We can now to define the notions of individual rationality.",
                "Definition 5.",
                "Individual rationality (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
                "A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments.",
                "A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
                "The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle).",
                "For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium.",
                "Definition 6.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known.",
                "Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
                "In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible.",
                "Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report.",
                "If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium.",
                "Definition 7.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth.",
                "Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible. 135 3.3 Automated mechanism design We can now define the computational problem we study.",
                "Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an automated mechanism design setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective.",
                "An interesting special case is the setting where there is only one agent.",
                "In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents.",
                "Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here.",
                "Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here.",
                "This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4.",
                "PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "To demonstrate NPhardness, we reduce from the MINSAT problem.",
                "Definition 9 (MINSAT).",
                "We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|).",
                "We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied.",
                "MINSAT was recently shown to be NP-complete [14].",
                "We can now present our result.",
                "Theorem 1.",
                "Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent payment-maximizing deterministic AMD instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|.",
                "For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the MINSAT solution, and π(θc) = |Θ| if c is satisfied.",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent.",
                "Clearly the agent is better off reporting truthfully, for a total utility of 0.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type.",
                "Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the IR constraint, the maximum payment we can extract from any type θv is |Θ|.",
                "Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.)",
                "Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1.",
                "It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible.",
                "However, it does not yet imply hardness for the special case where payments are not possible.",
                "We will prove hardness in this case in the next section. 5.",
                "SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "Theorem 2.",
                "Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent self-interested deterministic AMD without payments instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1.",
                "Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v).",
                "For every c ∈ C that is satisfied in the MINSAT solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ .",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "The only other outcome that the mechanism is allowed to choose under the IR constraint is o0.",
                "This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}.",
                "We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|.",
                "For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).)",
                "Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes.",
                "It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Both of our hardness results relied on the constraint that the mechanism should be deterministic.",
                "In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6.",
                "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of self-interested AMD tractable through linear programming, for any constant number of agents.",
                "Theorem 3.",
                "Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated.",
                "Proof.",
                "Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}.",
                "The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.)",
                "First, we show the IR constraints.",
                "For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
                "For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
                "Now, we show the solution concept constraints.",
                "For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
                "Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
                "All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
                "As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents.",
                "Thus the problem is solvable in polynomial time. 7.",
                "IMPLICATIONS FOR AN OPTIMAL COMBINATORIAL AUCTION DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated mechanism design for a self-interested designer on designing optimal combinatorial auctions.",
                "Consider a combinatorial auction with a set S of items for sale.",
                "For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi.",
                "The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.)",
                "The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18].",
                "However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25].",
                "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of complementarity and no substitutability has been solved recently [1].)",
                "Suppose we have free disposal-items can be thrown away at no cost.",
                "Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.)",
                "Definition 10.",
                "Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
                "We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item.",
                "The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type.",
                "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the <br>payment maximizing</br> AMD problem!",
                "Theorem 4.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types.",
                "Proof.",
                "The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming.",
                "To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal combinatorial auction design problem instance with a single bidder with best-only preferences.",
                "For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance).",
                "Let the expected revenue target value be the same in both instances.",
                "We show the instances are equivalent.",
                "First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function.",
                "Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.)",
                "Let the payment functions be the same in both instances.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same.",
                "It follows that there exists a solution to the optimal auction design instance.",
                "Now suppose there exists a solution to the optimal auction design instance.",
                "By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item.",
                "Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type.",
                "If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type.",
                "Let the payment functions be the same.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same.",
                "It follows that there exists a solution to the AMD instance.",
                "Fortunately, we can also carry through the easiness result for randomized mechanisms to this combinatorial auction setting-giving us one of the few known polynomial-time algorithms for an optimal combinatorial auction design problem.",
                "Theorem 5.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.)",
                "Proof.",
                "By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item.",
                "There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations.",
                "Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8.",
                "RELATED RESEARCH ON COMPLEXITY IN MECHANISM DESIGN There has been considerable recent interest in mechanism design in computer science.",
                "Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism.",
                "The closest piece of earlier work studied the complexity of automated mechanism design by a benevolent designer [5, 6].",
                "Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21].",
                "This is related to mechanism design, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments).",
                "Also, there is no explicit reporting of preferences. 9.",
                "CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently emerging approach-called automated mechanism design-a mechanism is computed for the specific preference aggregation setting at hand.",
                "This has several advantages, 139 but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike earlier work on automated mechanism design that studied a benevolent designer, in this paper we studied automated mechanism design problems where the designer is self-interesteda setting much more relevant for electronic commerce.",
                "In this setting, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "These hardness results imply hardness in all more general automated mechanism design settings with a self-interested designer.",
                "The hardness results apply whether the individual rationality (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation.",
                "We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy.",
                "Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy.",
                "Future research includes studying automated mechanism design with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments).",
                "We also want to study the complexity of automated mechanism design in settings where the outcome and type spaces have special structure so they can be represented more concisely.",
                "Finally, we plan to assemble a data set of real-world mechanism design problems-both historical and current-and apply automated mechanism design to those problems. 10.",
                "REFERENCES [1] M. Armstrong.",
                "Optimal multi-object auctions.",
                "Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow.",
                "The property rights doctrine and demand revelation under incomplete information.",
                "In M. Boskin, editor, Economics and human welfare.",
                "New York Academic Press, 1979. [3] C. Avery and T. Hendershott.",
                "Bundling and optimal auctions of multiple products.",
                "Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke.",
                "Multipart pricing of public goods.",
                "Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Automated mechanism design: Complexity results stemming from the single-agent setting.",
                "In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm.",
                "Computational criticisms of the revelation principle.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004.",
                "Short paper.",
                "Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet.",
                "Incentives and incomplete information.",
                "Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker.",
                "Sharing the cost of muliticast transmissions.",
                "Journal of Computer and System Sciences, 63:21-41, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard.",
                "Manipulation of voting schemes.",
                "Econometrica, 41:587-602, 1973. [11] T. Groves.",
                "Incentives in teams.",
                "Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri.",
                "Vickrey prices and shortest paths: What is an edge worth?",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan.",
                "A polynomial algorithm in linear programming.",
                "Soviet Math.",
                "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani.",
                "The minimum satisfiability problem.",
                "SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham.",
                "Truth revelation in rapid, approximately efficient combinatorial auctions.",
                "Journal of the ACM, 49(5):577-602, 2002.",
                "Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [17] E. S. Maskin and J. Riley.",
                "Optimal multi-unit auctions.",
                "In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335.",
                "Clarendon Press, Oxford, 1989. [18] R. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen.",
                "Computationally feasible VCG mechanisms.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behavior, 35:166-196, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden.",
                "Designing networks for selfish users is hard.",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm.",
                "Issues in computational Vickrey auctions.",
                "International Journal of Electronic Commerce, 4(3):107-129, 2000.",
                "Special Issue on 140 Applying Intelligent Agents for Electronic Commerce.",
                "A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite.",
                "Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions.",
                "Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey.",
                "Counterspeculation, auctions, and competitive sealed tenders.",
                "Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra.",
                "Research problems in combinatorial auctions.",
                "Mimeo, version Oct. 29, 2001. 141"
            ],
            "original_annotated_samples": [
                "In the case where g = 0 everywhere, the designer is said to be <br>payment maximizing</br>.",
                "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the <br>payment maximizing</br> AMD problem!"
            ],
            "translated_annotated_samples": [
                "En el caso en que g = 0 en todas partes, se dice que el diseñador está <br>maximizando el pago</br>.",
                "Ahora demostramos que el problema de diseñar una subasta óptima determinista es NP-completo, mediante una reducción del problema AMD de <br>maximización de pagos</br>."
            ],
            "translated_text": "Diseño de mecanismos automatizados de interés propio e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les resulte más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente propuesto, llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración de agregación de preferencias actual. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre el diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo. En este caso, al centro solo le importa qué resultado se elige y qué pagos se le hacen. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este contexto, demostramos que el diseño de mecanismos deterministas óptimos es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Luego mostramos cómo permitir la aleatorización en el mecanismo hace que los problemas en este entorno sean computacionalmente fáciles. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (maximizadora de ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar una subasta determinista óptima es NP-completo, pero diseñar una subasta aleatoria óptima es fácil. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Teoría 1. En entornos multiagentes, a menudo se debe elegir un resultado en función de las preferencias informadas por un grupo de agentes. Tales resultados podrían ser presidentes potenciales, planes conjuntos, asignaciones de bienes o recursos, etc. El agregador de preferencias generalmente no conoce las preferencias de los agentes de antemano. Más bien, los agentes informan sus preferencias al coordinador. Desafortunadamente, un agente puede tener un incentivo para informar incorrectamente sus preferencias con el fin de engañar al mecanismo y lograr que seleccione un resultado que sea más deseable para el agente que el resultado que se seleccionaría si el agente revelara sus preferencias de manera honesta. Tal manipulación es indeseable porque los mecanismos de agregación de preferencias están diseñados para agrupar las preferencias de una manera socialmente deseable, y si los agentes revelan sus preferencias de manera insincera, se podría elegir un resultado socialmente indeseable. La manipulabilidad es un problema generalizado en los mecanismos de agregación de preferencias. Un resultado negativo seminal, el teorema de Gibbard-Satterthwaite, muestra que bajo cualquier esquema de agregación de preferencias no dictatorial, si hay al menos 3 posibles resultados, existen preferencias bajo las cuales un agente está mejor reportando falsamente [10, 23]. (Un esquema de agregación de preferencias se llama dictatorial si uno de los agentes dicta el resultado sin importar las preferencias que reporten los otros agentes). Lo que le gustaría hacer al agregador es diseñar un mecanismo de agregación de preferencias para que 1) los agentes interesados reporten sus preferencias de manera veraz, y 2) el mecanismo elija un resultado que sea deseable desde la perspectiva de algún objetivo. Esta es la configuración clásica del diseño de mecanismos en la teoría de juegos. En este documento, estudiamos el caso en el que el diseñador actúa por interés propio, es decir, al diseñador no le importa directamente cómo se relaciona el resultado con las preferencias de los agentes, sino que está más preocupado por su propia agenda sobre cuál resultado debería ser elegido y en maximizar los pagos para sí mismo. Este es el entorno de diseño de mecanismos más relevante para el comercio electrónico. En el caso en que el diseñador del mecanismo esté interesado en maximizar alguna noción de bienestar social, la importancia de recopilar las preferencias de los agentes es clara. Quizás sea menos obvio por qué deberían ser recopilados cuando el diseñador está interesado en sí mismo y, por lo tanto, su objetivo no está directamente relacionado con las preferencias de los agentes. La razón de esto es que a menudo las preferencias de los agentes imponen límites en cómo el diseñador elige el resultado y los pagos. La restricción más común de este tipo es la de racionalidad individual (RI), lo que significa que el mecanismo no puede dejar a ningún agente en una situación peor a la que hubiera estado si no hubiera participado en el mecanismo. Por ejemplo, en el contexto del diseño óptimo de subastas, el diseñador (subastador) solo se preocupa por cuántos ingresos se recaudan, y no en sí mismo por cuán bien la asignación del bien (o bienes) corresponde a las preferencias de los agentes. Sin embargo, el diseñador no puede obligar a un agente a pagar más de lo que valora el paquete de bienes asignado a él. Por lo tanto, incluso un diseñador interesado en sí mismo elegirá un resultado que beneficie razonablemente a los agentes. Por otro lado, el diseñador no necesariamente elegirá un resultado que maximice el bienestar social. Por ejemplo, si el diseñador siempre elige un resultado que maximiza el bienestar social con respecto a las preferencias informadas, y obliga a cada agente a pagar la diferencia entre la utilidad que tiene ahora y la utilidad que habría tenido si no hubiera participado en el mecanismo, es fácil ver que los agentes pueden tener un incentivo para informar incorrectamente sus preferencias, lo que puede llevar realmente a recaudar menos ingresos. De hecho, uno de los resultados contraintuitivos de la teoría del diseño de subastas óptimas es que a veces el bien se asigna a nadie incluso cuando el subastador tiene un precio de reserva de 0. El diseño de mecanismos clásicos proporciona algunos mecanismos generales, que, bajo ciertas suposiciones, satisfacen alguna noción de no manipulabilidad y maximizan algún objetivo. La ventaja de estos mecanismos es que no dependen de información (incluso probabilística) sobre las preferencias de los agentes (por ejemplo, el mecanismo de Vickrey-Clarke-Groves (VCG) [24, 4, 11]), o pueden aplicarse fácilmente a cualquier distribución de probabilidad sobre las preferencias (por ejemplo, el mecanismo dAGVA [8, 2], la subasta de Myerson [18], y la subasta multiunidad de Maskin-Riley [17]). Sin embargo, los mecanismos generales también tienen importantes desventajas: • Los mecanismos generales más famosos y ampliamente aplicables, VCG y dAGVA, solo maximizan el bienestar social. Si el diseñador está interesado en sí mismo, como es el caso en muchos entornos de comercio electrónico, estos mecanismos no maximizan el objetivo del diseñador. • Los mecanismos generales que se centran en un diseñador interesado en sí mismo solo son aplicables en entornos muy restringidos, como la subasta de maximización de ingresos esperados de Myerson para vender un solo artículo, y la subasta de maximización de ingresos esperados de Maskin y Riley para vender múltiples unidades idénticas de un artículo. • Incluso en los entornos restringidos en los que se aplican estos mecanismos, solo permiten la maximización de pagos. En la práctica, el diseñador también puede estar interesado en el resultado en sí mismo. Por ejemplo, a un subastador le puede importar qué postor recibe el artículo. • A menudo se asume que los pagos laterales pueden ser utilizados para adaptar los incentivos de los agentes, pero esto no siempre es práctico. Por ejemplo, en los mercados electrónicos basados en trueque, como Recipco, firstbarter.com, BarterOne e Intagio, no se permiten los pagos laterales. Además, entre los agentes de software, podría ser más deseable construir mecanismos que no dependan de la capacidad de realizar pagos, ya que muchos agentes de software no cuentan con la infraestructura para hacer pagos. Por el contrario, seguimos un enfoque reciente donde el mecanismo se diseña automáticamente para el problema específico en cuestión. Este enfoque aborda todos los inconvenientes mencionados anteriormente. Formulamos el problema de diseño de mecanismos como un problema de optimización. La entrada se caracteriza por el número de agentes, los posibles tipos de agentes (preferencias) y las distribuciones previas de los agregadores sobre los tipos de agentes. La salida es un mecanismo no manipulable que es óptimo con respecto a algún objetivo. Este enfoque se llama diseño de mecanismos automatizado. El enfoque de diseño de mecanismos automatizado tiene cuatro ventajas sobre el enfoque clásico de diseñar mecanismos generales. Primero, se puede utilizar incluso en entornos que no cumplen con las suposiciones de los mecanismos clásicos (como la disponibilidad de pagos laterales o que el objetivo sea el bienestar social). Segundo, puede permitir a uno eludir resultados de imposibilidad (como el teorema de Gibbard-Satterthwaite) que establecen que no existe un mecanismo que sea deseable para todas las preferencias. Cuando el mecanismo está diseñado para la configuración actual, no importa que no funcione de manera más general. Tercero, puede generar mecanismos mejores (en términos de garantías de no manipulabilidad más sólidas y/o mejores resultados) que los mecanismos clásicos porque el mecanismo aprovecha las particularidades del entorno (la información probabilística que el diseñador tiene sobre los tipos de agentes). Dada la gran cantidad de información que las partes tienen entre sí hoy en día, es probable que este enfoque conduzca a ahorros enormes en comparación con los mecanismos clásicos, que en su mayoría ignoran esa información. Por ejemplo, imagina una empresa creando automáticamente su mecanismo de adquisiciones basado en el conocimiento estadístico sobre sus proveedores, en lugar de utilizar una subasta de adquisiciones descendente clásica. Cuarto, la carga del diseño se traslada de los humanos a una máquina. Sin embargo, el diseño automatizado de mecanismos requiere que el problema de optimización del diseño del mecanismo se resuelva de nuevo para cada configuración. Por lo tanto, su complejidad computacional se convierte en un tema clave. Investigaciones previas han estudiado esta pregunta para diseñadores benevolentes que desean maximizar, por ejemplo, el bienestar social [5, 6]. En este artículo estudiamos la complejidad computacional del diseño automatizado de mecanismos en el caso de un diseñador con interés propio. Esta es una configuración importante para el diseño de mecanismos automatizados debido a la escasez de mecanismos generales en esta área, y al hecho de que en la mayoría de las configuraciones de comercio electrónico el diseñador actúa en su propio interés. También demostramos que este problema está estrechamente relacionado con un problema de diseño de subasta combinatoria óptima (maximización de ingresos) particular. El resto de este documento está organizado de la siguiente manera. En la Sección 2, justificamos el enfoque en mecanismos no manipulables. En la Sección 3, definimos el problema que estudiamos. En la Sección 4, demostramos que diseñar un mecanismo determinista óptimo es NP-completo incluso cuando al diseñador solo le importan los pagos que recibe. En la Sección 5, demostramos que diseñar un mecanismo determinista óptimo también es NP-completo cuando los pagos no son posibles y el diseñador solo está interesado en el resultado elegido. En la Sección 6, demostramos que un mecanismo óptimo aleatorizado puede ser diseñado en tiempo polinómico incluso en el caso general. Finalmente, en la Sección 7, demostramos que para diseñar subastas combinatorias óptimas bajo preferencias de mejor opción solamente, nuestros resultados sobre AMD implican que este problema es NP-completo para subastas determinísticas, pero sencillo para subastas aleatorias. 2. JUSTIFICANDO EL ENFOQUE EN MECANISMOS NO MANIPULABLES Antes de definir el problema computacional del diseño automatizado de mecanismos, debemos justificar nuestro enfoque en mecanismos no manipulables. Después de todo, no es inmediatamente obvio que no haya mecanismos manipulables que, incluso cuando los agentes informan estratégicamente sus tipos y, por lo tanto, a veces de manera no veraz, aún logren mejores resultados (según el objetivo que usemos) que cualquier mecanismo no manipulable. Sin embargo, resulta ser el caso que, dado cualquier mecanismo, podemos construir un mecanismo no manipulable cuyo rendimiento es idéntico, de la siguiente manera. Construimos una capa de interfaz entre los agentes y el mecanismo original. Los agentes informan sus preferencias (o tipos) a la capa de interfaz; posteriormente, la capa de interfaz introduce en el mecanismo original los tipos que los agentes habrían informado estratégicamente al mecanismo original, si sus tipos fueran los declarados a la capa de interfaz. El resultado resultante es el resultado del nuevo mecanismo. Dado que la capa de interfaz actúa estratégicamente en nombre de cada agente, nunca hay un incentivo para informar falsamente a la capa de interfaz; por lo tanto, los tipos informados por la capa de interfaz son los tipos estratégicos que se habrían informado sin la capa de interfaz, por lo que los resultados son exactamente como habrían sido con el mecanismo original. Este argumento es conocido en la literatura de diseño de mecanismos como el principio de revelación [16]. (Existen dificultades computacionales al aplicar el principio de revelación en espacios de resultados y tipos combinatorios grandes [7, 22]). Sin embargo, dado que aquí nos enfocamos en espacios de resultados y tipos representados de forma plana, esto no es una preocupación aquí. Dado esto, podemos centrarnos en mecanismos veraces en el resto del documento. 3. DEFINICIONES Ahora formalizamos el entorno del diseño automatizado de mecanismos. Definición 1. En un entorno de diseño de mecanismos automatizados, se nos proporciona: • un conjunto finito de resultados O; • un conjunto finito de N agentes; • para cada agente i, 1. un conjunto finito de tipos Θi, 2. una distribución de probabilidad γi sobre Θi (en el caso de tipos correlacionados, hay una única distribución conjunta γ sobre Θ1 × . . . × ΘN), y 3. una función de utilidad ui: Θi × O → R; 1 • Una función objetivo cuya expectativa el diseñador desea maximizar. Existen muchas posibles funciones objetivo que el diseñador podría tener, por ejemplo, el bienestar social (donde el diseñador busca maximizar la suma de las utilidades de los agentes), o la utilidad mínima de cualquier agente (donde el diseñador busca maximizar la peor utilidad experimentada por cualquier agente). En ambos casos, el diseñador es benevolente, ya que, de alguna manera, el diseñador está buscando la felicidad colectiva de los agentes. Sin embargo, en este documento nos enfocamos en el caso de un diseñador interesado en sí mismo. Un diseñador egoísta solo se preocupa por el resultado elegido (es decir, al diseñador no le importa cómo se relaciona el resultado con las preferencias de los agentes, sino que tiene una preferencia fija sobre los resultados) y sobre los pagos netos realizados por los agentes, que fluyen hacia el diseñador. Definición 2. Un diseñador interesado tiene una función objetivo dada por g(o) + Σ i=1 πi, donde g : O → R indica las preferencias del diseñador sobre los resultados, y πi es el pago realizado por el agente i. En el caso en que g = 0 en todas partes, se dice que el diseñador está <br>maximizando el pago</br>. En el caso en que los pagos no sean posibles, g constituye la función objetivo por sí sola. Ahora definimos los tipos de mecanismos en estudio. Por el principio de revelación, podemos restringir la atención a mecanismos de revelación directa y veraz, donde los agentes informan directamente sus tipos y nunca tienen incentivos para informarlos de manera incorrecta. Definición 3. Consideramos los siguientes tipos de mecanismos: • Un mecanismo determinista sin pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O. • Un mecanismo aleatorio sin pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), donde P(O) es el conjunto de distribuciones de probabilidad sobre O. • Un mecanismo determinista con pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O y, para cada agente i, una función de selección de pagos πi: Θ1 × Θ2 × . . . × ΘN → R, donde πi(θ1, . . . , θN ) da el pago realizado por el agente i cuando los tipos reportados son θ1, . . . , θN. Aunque esto sigue la notación estándar de la teoría de juegos [16], el hecho de que el agente tenga tanto una función de utilidad como un tipo puede resultar confuso. Los tipos codifican las diversas preferencias posibles que el agente pueda tener, y el tipo de los agentes no es conocido por el agregador. La función de utilidad es un conocimiento común, pero debido a que el tipo de agente es un parámetro en la función de utilidad de los agentes, el agregador no puede saber cuál es la utilidad de los agentes sin conocer el tipo de agente. Un mecanismo aleatorio con pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), y para cada agente i, una función de selección de pago πi: Θ1 × Θ2 × . . . × ΘN → R. Hay dos tipos de restricciones para el diseñador al construir el mecanismo. 3.1 Restricciones de racionalidad individual (IR) El primer tipo de restricción es el siguiente. La utilidad de cada agente debe ser al menos tan grande como la utilidad de respaldo de los agentes, es decir, la utilidad que el agente recibiría si no participara en el mecanismo. De lo contrario, ese agente no participaría en el mecanismo, y la participación de ningún agente puede perjudicar el objetivo de los diseñadores del mecanismo, ya que en el peor de los casos, el mecanismo puede ignorar a un agente fingiendo que el agente no está presente. (Además, si no se aplicara tal restricción, el diseñador simplemente podría hacer que los agentes paguen una cantidad infinita). Este tipo de restricción se llama restricción de IR (racionalidad individual). Existen tres posibles restricciones de IR diferentes: ex ante, ex interim y ex post, dependiendo de lo que el agente sabe sobre su propio tipo y los tipos de los demás al decidir si participar en el mecanismo. Ex ante IR significa que el agente participaría si no supiera absolutamente nada (ni siquiera su propio tipo). No estudiaremos este concepto en este documento. Ex interim IR significa que el agente siempre participaría si conociera solo su propio tipo, pero no el de los demás. Ex post IR significa que el agente siempre participaría incluso si conociera el tipo de todos. Definiremos formalmente las dos últimas nociones de IR. Primero, necesitamos formalizar el concepto del resultado de respaldo. Suponemos que la utilidad de respaldo de cada agente es cero para cada uno de sus tipos. Esto se hace sin pérdida de generalidad porque podemos agregar un término constante a la función de utilidad de un agente (para un tipo dado), sin afectar el comportamiento de toma de decisiones de ese agente maximizador de utilidad esperada [16]. Definición 4. En cualquier entorno de diseño de mecanismos automatizados con una restricción de IR, existe un resultado de contingencia o0 ∈ O donde, para cualquier agente i y cualquier tipo θi ∈ Θi, tenemos ui(θi, o0) = 0. (Además, en el caso de un diseñador egoísta, g(o0) = 0). Ahora podemos definir las nociones de racionalidad individual. Definición 5. La racionalidad individual (RI) se define como: • Un mecanismo determinista es ex interim RI si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0. Un mecanismo aleatorio es ex interim IR si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • Un mecanismo determinista es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 No aleatorizamos sobre los pagos porque mientras los agentes y el diseñador sean neutrales al riesgo con respecto a los pagos, es decir, su utilidad es lineal en los pagos, no hay razón para aleatorizar sobre los pagos. Un mecanismo aleatorio es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 3.2 Restricciones de compatibilidad de incentivos (IC) El segundo tipo de restricción establece que los agentes nunca deben tener un incentivo para informar incorrectamente su tipo (como se justificó anteriormente mediante el principio de revelación). Para este tipo de restricción, las dos variantes más comunes (o conceptos de solución) son la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash. Definición 6. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en estrategias dominantes si decir la verdad siempre es óptimo incluso cuando los tipos reportados por los otros agentes ya son conocidos. Formalmente, para cualquier agente i, cualquier vector de tipos (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ). En el caso de mecanismos aleatorios tenemos Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. Por lo tanto, en la implementación de estrategias dominantes, decir la verdad es óptimo independientemente de lo que informen los otros agentes. Si es óptimo solo dado que los otros agentes son veraces, y dado que uno no conoce los tipos de los otros agentes, tenemos implementación en equilibrio de Bayes-Nash. Definición 7. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en equilibrio de Bayes-Nash si decir la verdad siempre es óptimo para un agente cuando ese agente aún no sabe nada sobre los tipos de los otros agentes, y los otros agentes están diciendo la verdad. Formalmente, para cualquier agente i, cualquier tipo θi ∈ Θi, y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )]. En el caso de mecanismos aleatorios tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 135 3.3 Diseño de mecanismos automatizados Ahora podemos definir el problema computacional que estudiamos. Definición 8. (DISEÑO DE MECANISMOS AUTOMATIZADOS (AMD)) Se nos da: • un entorno de diseño de mecanismos automatizados, • una noción de IR (ex interim, ex post, o ninguna), • un concepto de solución (estrategias dominantes o Bayes-Nash), • si los pagos son posibles, • si la aleatorización es posible, • (en la variante de decisión del problema) un valor objetivo G. Se nos pregunta si existe un mecanismo del tipo especificado (en términos de pagos y aleatorización) que satisfaga tanto la noción de IR como el concepto de solución, y proporcione un valor esperado de al menos G para el objetivo. Un caso especial interesante es aquel en el que solo hay un agente. En este caso, el agente informante siempre sabe todo lo que hay que saber sobre los otros tipos de agentes, porque no hay otros agentes. Dado que el IR ex post y el IR ex interim solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de IR coinciden aquí. Además, dado que la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de solución coinciden aquí. Esta observación resultará ser una herramienta útil para demostrar resultados de dificultad: si demostramos dificultad computacional en el escenario de un solo agente, esto implica inmediatamente dificultad para ambos conceptos de IR, para ambos conceptos de solución, para cualquier número de agentes. 4. En esta sección demostramos que es NP-completo diseñar un mecanismo determinístico que maximice la suma esperada de los pagos recolectados de los agentes. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Para demostrar la NP-dureza, reducimos desde el problema MINSAT. Definición 9 (MINSAT). Se nos da una fórmula φ en forma normal conjuntiva, representada por un conjunto de variables booleanas V y un conjunto de cláusulas C, y un entero K (K < |C|). Se nos pregunta si existe una asignación a las variables en V tal que se satisfacen a lo sumo K cláusulas en φ. MINSAT fue recientemente demostrado como NP-completo [14]. Ahora podemos presentar nuestro resultado. Teorema 1. El problema determinista de maximización de pagos de AMD es NP-completo, incluso para un solo agente, incluso con una distribución uniforme de tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista de maximización de pagos de un solo agente. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V } ∪ {−v : v ∈ V }. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Sea l ∈ c denota que el literal l ocurre en la cláusula c. Entonces, la función de utilidad de los agentes está dada por u(θc, ol) = |Θ| + 1 para todo l ∈ L con l ∈ c; u(θc, ol) = 0 para todo l ∈ L con l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc) = 0 para todo c ∈ C con c = c; u(θv, ol) = |Θ| para todo l ∈ L con v(l) = v; u(θv, ol) = 0 para todo l ∈ L con v(l) = v; u(θv, oc) = 0 para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ|, donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v) y π(θv) = |Θ|. Para cada c ∈ C, sea o(θc) = oc; sea π(θc) = |Θ| + 1 si c no está satisfecha en la solución MINSAT, y π(θc) = |Θ| si c está satisfecha. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es θv, entonces cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivo para informar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Porque además, ningún tipo que no sea θc conduce al resultado oc, informar cualquier otro tipo dará como resultado una utilidad de 0, mientras que aún se requiere un pago de al menos |Θ| por parte del agente. Claramente, el agente está mejor reportando honestamente, para una utilidad total de 0. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), el pago esperado de este mecanismo es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o y una función de pago π. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. Entonces, la utilidad que el agente obtiene del resultado dado para este tipo es 0, y por lo tanto, según la IR, no se puede extraer ningún pago del agente para este tipo. Dado que, nuevamente por IR, el pago máximo que se puede extraer para cualquier otro tipo es |Θ| + 1, se sigue que el pago esperado máximo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo cual contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o−v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por la restricción de IR, el pago máximo que podemos extraer de cualquier tipo θv es |Θ|. Dado que no puede haber incentivos para que el agente informe falsamente, para cualquier cláusula c satisfecha por la asignación dada, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ|. (Pues si extrajéramos más de este tipo, la utilidad del agente en este caso sería menor que 1; y si v es la variable que satisface c en la asignación, de modo que o(θv) = ol donde l ocurre en c, entonces al agente le convendría más informar θv en lugar del informe veraz θc, para obtener un resultado que valga |Θ|+1 para él mientras tiene que pagar como máximo |Θ|.) Finalmente, para cualquier cláusula insatisfecha c, según la restricción de IR, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ| + 1. Se deduce que el pago esperado de nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia de MINSAT. Dado que AMD, que maximiza el pago, es solo un caso especial de AMD para un diseñador egoísta en el que el diseñador no tiene preferencias sobre el resultado elegido, esto implica inmediatamente dificultades para el caso general de AMD para un diseñador egoísta en el que los pagos son posibles. Sin embargo, esto aún no implica dureza para el caso especial donde los pagos no son posibles. Demostraremos la dificultad en este caso en la próxima sección. 5. En esta sección demostramos que es NP-completo diseñar un mecanismo determinista que maximice la expectativa del objetivo del diseñador cuando no son posibles los pagos. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Teorema 2. Sin pagos, el diseño determinista de AMD para un diseñador egoísta es NP-completo, incluso para un solo agente, incluso con una distribución uniforme sobre los tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista auto-interesada de un solo agente sin pagos. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L} ∪ {o∗}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V} ∪ {−v : v ∈ V}. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Deje que l ∈ c denote que el literal l ocurre en la cláusula c. Luego, deje que la función de utilidad de los agentes esté dada por u(θc, ol) = 2 para todo l ∈ L con l ∈ c; u(θc, ol) = −1 para todo l ∈ L con l /∈ c; u(θc, oc) = 2; u(θc, oc) = −1 para todo c ∈ C con c = c; u(θc, o∗) = 1; u(θv, ol) = 1 para todo l ∈ L con v(l) = v; u(θv, ol) = −1 para todo l ∈ L con v(l) = v; u(θv, oc) = −1 para todo c ∈ C; u(θv, o∗) = −1. Que la función objetivo de los diseñadores esté dada por g(o∗ ) = |Θ|+1; g(ol) = |Θ| para todo l ∈ L; g(oc) = |Θ| para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ| , donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v). Para cada c ∈ C que se cumpla en la solución MINSAT, sea o(θc) = oc; para cada c ∈ C no satisfecho, sea o(θc) = o∗. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es algún θv, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para reportar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Debido a que tampoco ningún tipo conduce al resultado oc, no hay ningún resultado que el mecanismo seleccione que le daría al agente una utilidad mayor a 1 para el tipo θc, y por lo tanto el agente no tiene incentivo para informar falsamente. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), entonces el valor esperado de la función objetivo de los diseñadores es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. El único otro resultado que el mecanismo puede elegir bajo la restricción de IR es o0. Esto tiene un valor objetivo de 0, y dado que el valor más alto que la función objetivo alcanza es |Θ| + 1, se sigue que el valor esperado máximo de la función objetivo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo que contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o-v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por lo anterior, para cualquier tipo θv, el valor de la función objetivo en este mecanismo será |Θ|. Para cualquier cláusula c satisfecha por la asignación dada, el valor de la función objetivo en el caso en que el agente informe el tipo θc será como máximo |Θ|. (Esto se debe a que no podemos elegir el resultado o∗ para dicho tipo, ya que en este caso el agente tendría un incentivo para informar θv en su lugar, donde v es la variable que satisface c en la asignación (de modo que o(θv) = ol donde l ocurre en c).) Finalmente, para cualquier cláusula insatisfecha c, el valor máximo que la función objetivo puede alcanzar en el caso en que el agente informa el tipo θc es |Θ| + 1, simplemente porque este es el valor más grande que la función alcanza en cualquier momento. Se deduce que el valor esperado de la función objetivo para nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas 137 satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia MINSAT. Ambos de nuestros resultados de dureza se basaron en la restricción de que el mecanismo debería ser determinista. En la siguiente sección, mostramos que la dificultad del diseño desaparece cuando permitimos la aleatorización en el mecanismo. 6. La aleatorización de AMD para un diseñador interesado en sí mismo es fácil. Ahora mostramos cómo permitir la aleatorización sobre los resultados hace que el problema de AMD auto-interesado sea manejable a través de la programación lineal, para cualquier número constante de agentes. Teorema 3. El AMD aleatorio con interés propio con un número constante de agentes es resoluble en tiempo polinómico mediante programación lineal, tanto con pagos como sin pagos, tanto para IR ex post como ex interim, y tanto para la implementación en estrategias dominantes como para la implementación en equilibrio de Bayes-Nash, incluso si los tipos están correlacionados. Prueba. Dado que los programas lineales pueden resolverse en tiempo polinómico [13], todo lo que necesitamos demostrar es que el número de variables y ecuaciones en nuestro programa es polinomial para cualquier número constante de agentes, es decir, exponencial solo en N. En todo momento, para determinar el tamaño del programa lineal, consideremos T = maxi{|Θi|}. Las variables de nuestro programa lineal serán las probabilidades (p(θ1, θ2, . . . , θN ))(o) (como máximo TN |O| variables) y los pagos πi(θ1, θ2, . . . , θN ) (como máximo NTN variables). (Mostramos el programa lineal para el caso en que los pagos son posibles; el caso sin pagos se obtiene fácilmente de esto simplemente omitiendo todas las variables de pago en el programa, o agregando restricciones adicionales que obliguen a los pagos a ser 0). Primero, mostramos las restricciones de IR. Para el IR ex post, agregamos las siguientes restricciones (como máximo NTN) al LP: • Para cada i ∈ {1, 2, . . . , N}, y para cada (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , agregamos ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0. Para el ex interino IR, agregamos las siguientes restricciones (como máximo NT) al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada θi ∈ Θi, agregamos θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0. Ahora, mostramos las restricciones del concepto de solución. Para la implementación en estrategias dominantes, agregamos las siguientes (a lo sumo NTN+1) restricciones al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ). Finalmente, para la implementación en el equilibrio de Bayes-Nash, agregamos las siguientes (a lo sumo NT2) restricciones al LP: • Para cada i ∈ {1, 2, ..., N}, para cada θi ∈ Θi, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )). Todo lo que queda por hacer es dar la expresión que el diseñador busca maximizar, que es: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )). Como indicamos, el número de variables y restricciones es exponencial solo en N, por lo tanto, el programa lineal tiene un tamaño polinómico para un número constante de agentes. Por lo tanto, el problema es resoluble en tiempo polinómico. IMPLICACIONES PARA UN PROBLEMA DE DISEÑO DE SUBASTA COMBINATORIA ÓPTIMA En esta sección, demostraremos algunas consecuencias interesantes del problema de diseño de mecanismos automatizados para un diseñador interesado en sí mismo en el diseño de subastas combinatorias óptimas. Considera una subasta combinatoria con un conjunto S de artículos en venta. Para cualquier conjunto B ⊆ S, dejemos que ui(θi, B) sea la utilidad del postor i al recibir el conjunto B cuando el tipo del postor es θi. El problema de diseño de subasta óptima consiste en especificar las reglas de la subasta de manera que se maximice los ingresos esperados para el subastador. (Por el principio de revelación, sin pérdida de generalidad, podemos asumir que la subasta es veraz). El problema de diseño de subasta óptima se resuelve para el caso de un solo artículo mediante la famosa subasta de Myerson [18]. Sin embargo, el diseño de subastas óptimas en subastas combinatorias es un problema de investigación abierto reconocido [3, 25]. El problema está abierto incluso si solo hay dos artículos en venta. (El caso de dos artículos con una forma muy especial de complementariedad y sin sustituibilidad ha sido resuelto recientemente [1].) Supongamos que tenemos disposición libre: los artículos pueden ser desechados sin costo alguno. Además, supongamos que las preferencias de los postores tienen la siguiente estructura: cuando un postor recibe un conjunto de artículos, la utilidad del postor por ese conjunto está determinada únicamente por el mejor artículo en el conjunto. (Enfatizamos que qué artículo es el mejor puede depender del tipo de postor). Definición 10. Se dice que el postor i tiene preferencias solo por lo mejor sobre paquetes de artículos si existe una función vi: Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s). Hacemos la siguiente observación útil en este contexto: no tiene sentido otorgarle a un postor más de un artículo. La razón es que si el postor está informando honestamente, quitarle todos los artículos menos el de mayor valor no perjudicará al postor; y, mediante la disposición gratuita, hacerlo solo reducirá el incentivo para que este postor informe falsamente este tipo, cuando en realidad tiene otro tipo. Ahora demostramos que el problema de diseñar una subasta óptima determinista es NP-completo, mediante una reducción del problema AMD de <br>maximización de pagos</br>. Teorema 4. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de artículos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), diseñar la subasta determinística óptima es NP-completo, incluso para un único postor con una distribución uniforme sobre los tipos. Prueba. El problema está en NP porque podemos generar de manera no determinista una regla de asignación, y luego establecer los pagos utilizando programación lineal. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de AMD determinista que maximiza el pago, con un único agente y una distribución uniforme de tipos, al siguiente problema de diseño de subasta combinatoria óptima con una única postor con preferencias de solo los mejores. Para cada resultado o ∈ O en la instancia de AMD (excepto el resultado o0), que haya un artículo so ∈ S. Que el espacio de tipos sea el mismo, y que v(θi, so) = ui(θi, o) (donde u está especificado en la instancia de AMD). Que el valor objetivo de ingresos esperados sea el mismo en ambas instancias. Mostramos que las instancias son equivalentes. Primero supongamos que existe una solución para la instancia de AMD, dada por una función de resultado y una función de pago. Entonces, si la solución de AMD elige el resultado o para un tipo, en la solución de subasta óptima, asignamos {so} al postor para este tipo. (A menos que o = o0, en cuyo caso asignamos {} al postor). Que las funciones de pago sean las mismas en ambas instancias. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo verdadero) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución óptima de la subasta. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el subastador/diseñador son los mismos. Se deduce que existe una solución para la instancia de diseño de subasta óptima. Ahora supongamos que existe una solución para la instancia de diseño de subasta óptima. Por la observación de que como máximo se puede tener un artículo, podemos asumir sin pérdida de generalidad que la solución nunca asigna más de un artículo. Entonces, si la solución de subasta óptima asigna el artículo al postor para un tipo, en la solución de AMD, permita que el mecanismo elija el resultado o para ese tipo. Si la solución de subasta óptima no asigna nada al postor para un tipo, en la solución AMD, permita que el mecanismo elija el resultado o0 para ese tipo. Que las funciones de pago sean las mismas. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo real) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución AMD. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el diseñador/subastador son los mismos. Se deduce que existe una solución para la instancia de AMD. Afortunadamente, también podemos extender el resultado de facilidad para mecanismos aleatorios a este escenario de subasta combinatoria, lo que nos proporciona uno de los pocos algoritmos de tiempo polinómico conocidos para un problema de diseño óptimo de subasta combinatoria. Teorema 5. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de elementos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), si el número de postores es una constante k, entonces la subasta aleatoria óptima puede ser diseñada en tiempo polinómico. (Para cualquier restricción de IC e IR.) Prueba. Por la observación de que a lo sumo un artículo, podemos sin pérdida de generalidad restringirnos a asignaciones donde cada postor recibe como máximo un artículo. Hay menos de (|S| + 1)k asignaciones de ese tipo, es decir, un número polinómico de asignaciones. Dado que podemos enumerar explícitamente los resultados, simplemente podemos resolver esto como una instancia de AMD que maximiza el pago, con programación lineal. 8. Investigaciones relacionadas sobre la complejidad en el diseño de mecanismos. Ha habido un considerable interés reciente en el diseño de mecanismos en la informática. Parte de ello se ha centrado en cuestiones de complejidad computacional, pero la mayor parte de ese trabajo ha buscado diseñar mecanismos que sean fáciles de ejecutar (por ejemplo, [20, 15, 19, 9, 12]), en lugar de estudiar la complejidad de diseñar el mecanismo. La pieza más cercana de trabajo anterior estudió la complejidad del diseño automatizado de mecanismos por un diseñador benevolente [5, 6]. Roughgarden ha estudiado la complejidad de diseñar una buena topología de red para agentes que eligen egoístamente los enlaces que utilizan [21]. Esto está relacionado con el diseño de mecanismos, pero difiere significativamente en que el diseñador solo tiene un control restringido sobre las reglas del juego porque no hay ninguna parte que pueda imponer el resultado (o pagos laterales). Además, no hay un informe explícito de preferencias. 9. CONCLUSIONES E INVESTIGACIONES FUTURAS A menudo, un resultado debe ser elegido en función de las preferencias informadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les sea más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente emergente llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración específica de agregación de preferencias en cuestión. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo, un entorno mucho más relevante para el comercio electrónico. En este contexto, al centro solo le importa qué resultado se elige y qué pagos se le realizan. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este escenario, demostramos que diseñar un mecanismo determinista óptimo es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Estos resultados de dureza implican dificultad en todos los entornos de diseño de mecanismos automatizados más generales con un diseñador egoísta. Los resultados de dureza se aplican ya sea que las restricciones de racionalidad individual (participación) se apliquen ex interim o ex post, y ya sea que el concepto de solución sea la implementación de estrategias dominantes o la implementación del equilibrio de Bayes-Nash. Luego demostramos que permitir la aleatorización en el mecanismo hace que el problema de diseño en todos estos escenarios sea computacionalmente sencillo. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (que maximiza los ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar un mecanismo determinístico óptimo es NP-completo incluso con un agente, pero diseñar un mecanismo aleatorio óptimo es fácil. La investigación futura incluye estudiar el diseño automatizado de mecanismos con un diseñador interesado en sí mismo en entornos más restringidos, como subastas (donde el objetivo del diseñador puede incluir preferencias sobre qué postor debería recibir el bien, así como los pagos). También queremos estudiar la complejidad del diseño de mecanismos automatizados en entornos donde los espacios de resultados y tipos tienen una estructura especial para que puedan representarse de manera más concisa. Finalmente, planeamos reunir un conjunto de datos de problemas de diseño de mecanismos del mundo real, tanto históricos como actuales, y aplicar el diseño de mecanismos automatizado a esos problemas. 10. REFERENCIAS [1] M. Armstrong. Subastas multi-objetivo óptimas. Revisión de Estudios Económicos, 67:455-481, 2000. [2] K. Arrow. La doctrina de los derechos de propiedad y la revelación de la demanda bajo información incompleta. En M. Boskin, editor, Economía y bienestar humano. New York Academic Press, 1979. [3] C. Avery y T. Hendershott. Agrupación y subastas óptimas de múltiples productos. Revisión de Estudios Económicos, 67:483-497, 2000. [4] E. H. Clarke. Precios escalonados de bienes públicos. Elección Pública, 11:17-33, 1971. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Actas de la 18ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI-02), páginas 103-110, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Diseño de mecanismos automatizados: Resultados de complejidad derivados del entorno de un solo agente. En Actas de la 5ta Conferencia Internacional de Comercio Electrónico (ICEC-03), páginas 17-24, Pittsburgh, PA, EE. UU., 2003. [7] V. Conitzer y T. Sandholm. Críticas computacionales del principio de revelación. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), Nueva York, NY, 2004. Breve ensayo. La versión completa apareció en el taller AAMAS-03 sobre Comercio Electrónico Mediado por Agentes (AMEC). [8] C. d'Aspremont y L. A. Gérard-Varet. Incentivos e información incompleta. Revista de Economía Pública, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou y S. Shenker. Compartiendo el costo de las transmisiones de multidifusión. Revista de Ciencias de la Computación y de Sistemas, 63:21-41, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 2000. [10] A. Gibbard. Manipulación de esquemas de votación. Econometrica, 41:587-602, 1973. [11] T. Groves.\nEconometrica, 41:587-602, 1973. [11] T. Groves. Incentivos en equipos. Econometrica, 41:617-631, 1973. [12] J. Hershberger y S. Suri. Precios de Vickrey y caminos más cortos: ¿Cuánto vale una arista? En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [13] L. Khachiyan. Un algoritmo polinómico en programación lineal. Matemática soviética. Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi y P. Mirchandani. El problema de satisfacibilidad mínimo. Revista SIAM de Matemáticas Discretas, 7(2):275-283, 1994. [15] D. Lehmann, L. I. O'Callaghan y Y. Shoham. Revelación de la verdad en subastas combinatorias rápidas y aproximadamente eficientes. Revista de la ACM, 49(5):577-602, 2002. La versión inicial apareció en las Actas de la Conferencia de Comercio Electrónico de la ACM (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [17] E. S. Maskin y J. Riley. Subastas multiunidad óptimas. En F. Hahn, editor, \"La economía de los mercados faltantes, la información y los juegos\", capítulo 14, páginas 312-335. Clarendon Press, Oxford, 1989. [18] R. Myerson.\nPrensa Clarendon, Oxford, 1989. [18] R. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6:58-73, 1981. [19] N. Nisan y A. Ronen. Mecanismos VCG computacionalmente factibles. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 242-252, Minneapolis, MN, 2000. [20] N. Nisan y A. Ronen. Diseño de mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166-196, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 1999. [21] T. Roughgarden. Diseñar redes para usuarios egoístas es difícil. En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [22] T. Sandholm. Problemas en subastas computacionales de Vickrey. Revista Internacional de Comercio Electrónico, 4(3):107-129, 2000. Número especial sobre la Aplicación de Agentes Inteligentes para el Comercio Electrónico. Una versión corta y temprana apareció en la Segunda Conferencia Internacional sobre Sistemas Multiagente (ICMAS), páginas 299-306, 1996. [23] M. A. Satterthwaite. In Spanish, the translation would be: \"Inmutabilidad estratégica y condiciones de Arrow: teoremas de existencia y correspondencia para procedimientos de votación y funciones de bienestar social.\" Revista de Teoría Económica, 10:187-217, 1975. [24] W. Vickrey. Contrarrestando la especulación, subastas y ofertas selladas competitivas. Revista de Finanzas, 16:8-37, 1961. [25] R. V. Vohra. Problemas de investigación en subastas combinatorias. Mimeo, versión 29 de octubre de 2001. 141 ",
            "candidates": [],
            "error": [
                [
                    "maximizando el pago",
                    "maximización de pagos"
                ]
            ]
        },
        "fallback outcome": {
            "translated_key": "resultado de respaldo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-interested Automated Mechanism Design and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently proposed approach-called automated mechanism design-a mechanism is computed for the preference aggregation setting at hand.",
                "This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike the earlier work on automated mechanism design that studied a benevolent designer, in this paper we study automated mechanism design problems where the designer is self-interested.",
                "In this case, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy.",
                "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy.",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc.",
                "The preference aggregator generally does not know the agents preferences a priori.",
                "Rather, the agents report their preferences to the coordinator.",
                "Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully.",
                "Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen.",
                "Manipulability is a pervasive problem across preference aggregation mechanisms.",
                "A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.)",
                "What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective.",
                "This is the classic setting of mechanism design in game theory.",
                "In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself.",
                "This is the mechanism design setting most relevant to electronic commerce.",
                "In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear.",
                "It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences.",
                "The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments.",
                "The most common such constraint is that of individual rationality (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
                "For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences.",
                "Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it.",
                "Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off.",
                "On the other hand, the designer will not necessarily choose a social welfare maximizing outcome.",
                "For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected.",
                "Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0.",
                "Classical mechanism design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective.",
                "The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]).",
                "However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare.",
                "If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization.",
                "In practice, the designer may also be interested in the outcome per se.",
                "For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical.",
                "For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed.",
                "Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments.",
                "In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand.",
                "This approach addresses all of the downsides listed above.",
                "We formulate the mechanism design problem as an optimization problem.",
                "The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types.",
                "The output is a nonmanipulable mechanism that is optimal with respect to some objective.",
                "This approach is called automated mechanism design.",
                "The automated mechanism design approach has four advantages over the classical approach of designing general mechanisms.",
                "First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare).",
                "Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences.",
                "When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally.",
                "Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types).",
                "Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information.",
                "For example, imagine a company automatically creating its procurement mechanism based on statistical knowledge about its suppliers, rather than using a classical descending procurement auction.",
                "Fourth, the burden of design is shifted from humans to a machine.",
                "However, automated mechanism design requires the mechanism design optimization problem to be solved anew for each setting.",
                "Hence its computational complexity becomes a key issue.",
                "Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6].",
                "In this paper we study the computational complexity of automated mechanism design in the case of a self-interested designer.",
                "This is an important setting for automated mechanism design due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested.",
                "We also show that this problem is closely related to a particular optimal (revenue-maximizing) combinatorial auction design problem. 133 The rest of this paper is organized as follows.",
                "In Section 2, we justify the focus on nonmanipulable mechanisms.",
                "In Section 3, we define the problem we study.",
                "In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it.",
                "In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen.",
                "In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case.",
                "Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2.",
                "JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of automated mechanism design, we should justify our focus on nonmanipulable mechanisms.",
                "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any nonmanipulable mechanism.",
                "This does, however, turn out to be the case: given any mechanism, we can construct a nonmanipulable mechanism whose performance is identical, as follows.",
                "We build an interface layer between the agents and the original mechanism.",
                "The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer.",
                "The resulting outcome is the outcome of the new mechanism.",
                "Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism.",
                "This argument is known in the mechanism design literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22].",
                "However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.)",
                "Given this, we can focus on truthful mechanisms in the rest of the paper. 3.",
                "DEFINITIONS We now formalize the automated mechanism design setting.",
                "Definition 1.",
                "In an automated mechanism design setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize.",
                "There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent).",
                "In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness.",
                "However, in this paper, we focus on the case of a self-interested designer.",
                "A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer.",
                "Definition 2.",
                "A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i.",
                "In the case where g = 0 everywhere, the designer is said to be payment maximizing.",
                "In the case where payments are not possible, g constitutes the objective function by itself.",
                "We now define the kinds of mechanisms under study.",
                "By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them.",
                "Definition 3.",
                "We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing.",
                "The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator.",
                "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 Individual rationality (IR) constraints The first type of constraint is the following.",
                "The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism.",
                "Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.)",
                "This type of constraint is called an IR (individual rationality) constraint.",
                "There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism.",
                "Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type).",
                "We will not study this concept in this paper.",
                "Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others.",
                "Ex post IR means that the agent would always participate even if it knew everybodys type.",
                "We will define the latter two notions of IR formally.",
                "First, we need to formalize the concept of the <br>fallback outcome</br>.",
                "We assume that each agents fallback utility is zero for each one of its types.",
                "This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16].",
                "Definition 4.",
                "In any automated mechanism design setting with an IR constraint, there is a <br>fallback outcome</br> o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)",
                "We can now to define the notions of individual rationality.",
                "Definition 5.",
                "Individual rationality (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
                "A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments.",
                "A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
                "The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle).",
                "For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium.",
                "Definition 6.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known.",
                "Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
                "In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible.",
                "Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report.",
                "If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium.",
                "Definition 7.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth.",
                "Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible. 135 3.3 Automated mechanism design We can now define the computational problem we study.",
                "Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an automated mechanism design setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective.",
                "An interesting special case is the setting where there is only one agent.",
                "In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents.",
                "Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here.",
                "Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here.",
                "This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4.",
                "PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "To demonstrate NPhardness, we reduce from the MINSAT problem.",
                "Definition 9 (MINSAT).",
                "We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|).",
                "We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied.",
                "MINSAT was recently shown to be NP-complete [14].",
                "We can now present our result.",
                "Theorem 1.",
                "Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent payment-maximizing deterministic AMD instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|.",
                "For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the MINSAT solution, and π(θc) = |Θ| if c is satisfied.",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent.",
                "Clearly the agent is better off reporting truthfully, for a total utility of 0.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type.",
                "Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the IR constraint, the maximum payment we can extract from any type θv is |Θ|.",
                "Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.)",
                "Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1.",
                "It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible.",
                "However, it does not yet imply hardness for the special case where payments are not possible.",
                "We will prove hardness in this case in the next section. 5.",
                "SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "Theorem 2.",
                "Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent self-interested deterministic AMD without payments instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1.",
                "Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v).",
                "For every c ∈ C that is satisfied in the MINSAT solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ .",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "The only other outcome that the mechanism is allowed to choose under the IR constraint is o0.",
                "This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}.",
                "We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|.",
                "For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).)",
                "Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes.",
                "It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Both of our hardness results relied on the constraint that the mechanism should be deterministic.",
                "In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6.",
                "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of self-interested AMD tractable through linear programming, for any constant number of agents.",
                "Theorem 3.",
                "Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated.",
                "Proof.",
                "Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}.",
                "The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.)",
                "First, we show the IR constraints.",
                "For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
                "For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
                "Now, we show the solution concept constraints.",
                "For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
                "Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
                "All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
                "As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents.",
                "Thus the problem is solvable in polynomial time. 7.",
                "IMPLICATIONS FOR AN OPTIMAL COMBINATORIAL AUCTION DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated mechanism design for a self-interested designer on designing optimal combinatorial auctions.",
                "Consider a combinatorial auction with a set S of items for sale.",
                "For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi.",
                "The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.)",
                "The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18].",
                "However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25].",
                "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of complementarity and no substitutability has been solved recently [1].)",
                "Suppose we have free disposal-items can be thrown away at no cost.",
                "Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.)",
                "Definition 10.",
                "Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
                "We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item.",
                "The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type.",
                "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the payment maximizing AMD problem!",
                "Theorem 4.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types.",
                "Proof.",
                "The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming.",
                "To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal combinatorial auction design problem instance with a single bidder with best-only preferences.",
                "For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance).",
                "Let the expected revenue target value be the same in both instances.",
                "We show the instances are equivalent.",
                "First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function.",
                "Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.)",
                "Let the payment functions be the same in both instances.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same.",
                "It follows that there exists a solution to the optimal auction design instance.",
                "Now suppose there exists a solution to the optimal auction design instance.",
                "By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item.",
                "Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type.",
                "If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type.",
                "Let the payment functions be the same.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same.",
                "It follows that there exists a solution to the AMD instance.",
                "Fortunately, we can also carry through the easiness result for randomized mechanisms to this combinatorial auction setting-giving us one of the few known polynomial-time algorithms for an optimal combinatorial auction design problem.",
                "Theorem 5.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.)",
                "Proof.",
                "By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item.",
                "There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations.",
                "Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8.",
                "RELATED RESEARCH ON COMPLEXITY IN MECHANISM DESIGN There has been considerable recent interest in mechanism design in computer science.",
                "Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism.",
                "The closest piece of earlier work studied the complexity of automated mechanism design by a benevolent designer [5, 6].",
                "Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21].",
                "This is related to mechanism design, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments).",
                "Also, there is no explicit reporting of preferences. 9.",
                "CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently emerging approach-called automated mechanism design-a mechanism is computed for the specific preference aggregation setting at hand.",
                "This has several advantages, 139 but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike earlier work on automated mechanism design that studied a benevolent designer, in this paper we studied automated mechanism design problems where the designer is self-interesteda setting much more relevant for electronic commerce.",
                "In this setting, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "These hardness results imply hardness in all more general automated mechanism design settings with a self-interested designer.",
                "The hardness results apply whether the individual rationality (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation.",
                "We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy.",
                "Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy.",
                "Future research includes studying automated mechanism design with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments).",
                "We also want to study the complexity of automated mechanism design in settings where the outcome and type spaces have special structure so they can be represented more concisely.",
                "Finally, we plan to assemble a data set of real-world mechanism design problems-both historical and current-and apply automated mechanism design to those problems. 10.",
                "REFERENCES [1] M. Armstrong.",
                "Optimal multi-object auctions.",
                "Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow.",
                "The property rights doctrine and demand revelation under incomplete information.",
                "In M. Boskin, editor, Economics and human welfare.",
                "New York Academic Press, 1979. [3] C. Avery and T. Hendershott.",
                "Bundling and optimal auctions of multiple products.",
                "Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke.",
                "Multipart pricing of public goods.",
                "Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Automated mechanism design: Complexity results stemming from the single-agent setting.",
                "In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm.",
                "Computational criticisms of the revelation principle.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004.",
                "Short paper.",
                "Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet.",
                "Incentives and incomplete information.",
                "Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker.",
                "Sharing the cost of muliticast transmissions.",
                "Journal of Computer and System Sciences, 63:21-41, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard.",
                "Manipulation of voting schemes.",
                "Econometrica, 41:587-602, 1973. [11] T. Groves.",
                "Incentives in teams.",
                "Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri.",
                "Vickrey prices and shortest paths: What is an edge worth?",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan.",
                "A polynomial algorithm in linear programming.",
                "Soviet Math.",
                "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani.",
                "The minimum satisfiability problem.",
                "SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham.",
                "Truth revelation in rapid, approximately efficient combinatorial auctions.",
                "Journal of the ACM, 49(5):577-602, 2002.",
                "Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [17] E. S. Maskin and J. Riley.",
                "Optimal multi-unit auctions.",
                "In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335.",
                "Clarendon Press, Oxford, 1989. [18] R. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen.",
                "Computationally feasible VCG mechanisms.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behavior, 35:166-196, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden.",
                "Designing networks for selfish users is hard.",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm.",
                "Issues in computational Vickrey auctions.",
                "International Journal of Electronic Commerce, 4(3):107-129, 2000.",
                "Special Issue on 140 Applying Intelligent Agents for Electronic Commerce.",
                "A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite.",
                "Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions.",
                "Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey.",
                "Counterspeculation, auctions, and competitive sealed tenders.",
                "Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra.",
                "Research problems in combinatorial auctions.",
                "Mimeo, version Oct. 29, 2001. 141"
            ],
            "original_annotated_samples": [
                "First, we need to formalize the concept of the <br>fallback outcome</br>.",
                "In any automated mechanism design setting with an IR constraint, there is a <br>fallback outcome</br> o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)"
            ],
            "translated_annotated_samples": [
                "Primero, necesitamos formalizar el concepto del <br>resultado de respaldo</br>.",
                "En cualquier entorno de diseño de mecanismos automatizados con una restricción de IR, existe un <br>resultado de contingencia</br> o0 ∈ O donde, para cualquier agente i y cualquier tipo θi ∈ Θi, tenemos ui(θi, o0) = 0. (Además, en el caso de un diseñador egoísta, g(o0) = 0)."
            ],
            "translated_text": "Diseño de mecanismos automatizados de interés propio e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les resulte más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente propuesto, llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración de agregación de preferencias actual. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre el diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo. En este caso, al centro solo le importa qué resultado se elige y qué pagos se le hacen. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este contexto, demostramos que el diseño de mecanismos deterministas óptimos es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Luego mostramos cómo permitir la aleatorización en el mecanismo hace que los problemas en este entorno sean computacionalmente fáciles. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (maximizadora de ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar una subasta determinista óptima es NP-completo, pero diseñar una subasta aleatoria óptima es fácil. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Teoría 1. En entornos multiagentes, a menudo se debe elegir un resultado en función de las preferencias informadas por un grupo de agentes. Tales resultados podrían ser presidentes potenciales, planes conjuntos, asignaciones de bienes o recursos, etc. El agregador de preferencias generalmente no conoce las preferencias de los agentes de antemano. Más bien, los agentes informan sus preferencias al coordinador. Desafortunadamente, un agente puede tener un incentivo para informar incorrectamente sus preferencias con el fin de engañar al mecanismo y lograr que seleccione un resultado que sea más deseable para el agente que el resultado que se seleccionaría si el agente revelara sus preferencias de manera honesta. Tal manipulación es indeseable porque los mecanismos de agregación de preferencias están diseñados para agrupar las preferencias de una manera socialmente deseable, y si los agentes revelan sus preferencias de manera insincera, se podría elegir un resultado socialmente indeseable. La manipulabilidad es un problema generalizado en los mecanismos de agregación de preferencias. Un resultado negativo seminal, el teorema de Gibbard-Satterthwaite, muestra que bajo cualquier esquema de agregación de preferencias no dictatorial, si hay al menos 3 posibles resultados, existen preferencias bajo las cuales un agente está mejor reportando falsamente [10, 23]. (Un esquema de agregación de preferencias se llama dictatorial si uno de los agentes dicta el resultado sin importar las preferencias que reporten los otros agentes). Lo que le gustaría hacer al agregador es diseñar un mecanismo de agregación de preferencias para que 1) los agentes interesados reporten sus preferencias de manera veraz, y 2) el mecanismo elija un resultado que sea deseable desde la perspectiva de algún objetivo. Esta es la configuración clásica del diseño de mecanismos en la teoría de juegos. En este documento, estudiamos el caso en el que el diseñador actúa por interés propio, es decir, al diseñador no le importa directamente cómo se relaciona el resultado con las preferencias de los agentes, sino que está más preocupado por su propia agenda sobre cuál resultado debería ser elegido y en maximizar los pagos para sí mismo. Este es el entorno de diseño de mecanismos más relevante para el comercio electrónico. En el caso en que el diseñador del mecanismo esté interesado en maximizar alguna noción de bienestar social, la importancia de recopilar las preferencias de los agentes es clara. Quizás sea menos obvio por qué deberían ser recopilados cuando el diseñador está interesado en sí mismo y, por lo tanto, su objetivo no está directamente relacionado con las preferencias de los agentes. La razón de esto es que a menudo las preferencias de los agentes imponen límites en cómo el diseñador elige el resultado y los pagos. La restricción más común de este tipo es la de racionalidad individual (RI), lo que significa que el mecanismo no puede dejar a ningún agente en una situación peor a la que hubiera estado si no hubiera participado en el mecanismo. Por ejemplo, en el contexto del diseño óptimo de subastas, el diseñador (subastador) solo se preocupa por cuántos ingresos se recaudan, y no en sí mismo por cuán bien la asignación del bien (o bienes) corresponde a las preferencias de los agentes. Sin embargo, el diseñador no puede obligar a un agente a pagar más de lo que valora el paquete de bienes asignado a él. Por lo tanto, incluso un diseñador interesado en sí mismo elegirá un resultado que beneficie razonablemente a los agentes. Por otro lado, el diseñador no necesariamente elegirá un resultado que maximice el bienestar social. Por ejemplo, si el diseñador siempre elige un resultado que maximiza el bienestar social con respecto a las preferencias informadas, y obliga a cada agente a pagar la diferencia entre la utilidad que tiene ahora y la utilidad que habría tenido si no hubiera participado en el mecanismo, es fácil ver que los agentes pueden tener un incentivo para informar incorrectamente sus preferencias, lo que puede llevar realmente a recaudar menos ingresos. De hecho, uno de los resultados contraintuitivos de la teoría del diseño de subastas óptimas es que a veces el bien se asigna a nadie incluso cuando el subastador tiene un precio de reserva de 0. El diseño de mecanismos clásicos proporciona algunos mecanismos generales, que, bajo ciertas suposiciones, satisfacen alguna noción de no manipulabilidad y maximizan algún objetivo. La ventaja de estos mecanismos es que no dependen de información (incluso probabilística) sobre las preferencias de los agentes (por ejemplo, el mecanismo de Vickrey-Clarke-Groves (VCG) [24, 4, 11]), o pueden aplicarse fácilmente a cualquier distribución de probabilidad sobre las preferencias (por ejemplo, el mecanismo dAGVA [8, 2], la subasta de Myerson [18], y la subasta multiunidad de Maskin-Riley [17]). Sin embargo, los mecanismos generales también tienen importantes desventajas: • Los mecanismos generales más famosos y ampliamente aplicables, VCG y dAGVA, solo maximizan el bienestar social. Si el diseñador está interesado en sí mismo, como es el caso en muchos entornos de comercio electrónico, estos mecanismos no maximizan el objetivo del diseñador. • Los mecanismos generales que se centran en un diseñador interesado en sí mismo solo son aplicables en entornos muy restringidos, como la subasta de maximización de ingresos esperados de Myerson para vender un solo artículo, y la subasta de maximización de ingresos esperados de Maskin y Riley para vender múltiples unidades idénticas de un artículo. • Incluso en los entornos restringidos en los que se aplican estos mecanismos, solo permiten la maximización de pagos. En la práctica, el diseñador también puede estar interesado en el resultado en sí mismo. Por ejemplo, a un subastador le puede importar qué postor recibe el artículo. • A menudo se asume que los pagos laterales pueden ser utilizados para adaptar los incentivos de los agentes, pero esto no siempre es práctico. Por ejemplo, en los mercados electrónicos basados en trueque, como Recipco, firstbarter.com, BarterOne e Intagio, no se permiten los pagos laterales. Además, entre los agentes de software, podría ser más deseable construir mecanismos que no dependan de la capacidad de realizar pagos, ya que muchos agentes de software no cuentan con la infraestructura para hacer pagos. Por el contrario, seguimos un enfoque reciente donde el mecanismo se diseña automáticamente para el problema específico en cuestión. Este enfoque aborda todos los inconvenientes mencionados anteriormente. Formulamos el problema de diseño de mecanismos como un problema de optimización. La entrada se caracteriza por el número de agentes, los posibles tipos de agentes (preferencias) y las distribuciones previas de los agregadores sobre los tipos de agentes. La salida es un mecanismo no manipulable que es óptimo con respecto a algún objetivo. Este enfoque se llama diseño de mecanismos automatizado. El enfoque de diseño de mecanismos automatizado tiene cuatro ventajas sobre el enfoque clásico de diseñar mecanismos generales. Primero, se puede utilizar incluso en entornos que no cumplen con las suposiciones de los mecanismos clásicos (como la disponibilidad de pagos laterales o que el objetivo sea el bienestar social). Segundo, puede permitir a uno eludir resultados de imposibilidad (como el teorema de Gibbard-Satterthwaite) que establecen que no existe un mecanismo que sea deseable para todas las preferencias. Cuando el mecanismo está diseñado para la configuración actual, no importa que no funcione de manera más general. Tercero, puede generar mecanismos mejores (en términos de garantías de no manipulabilidad más sólidas y/o mejores resultados) que los mecanismos clásicos porque el mecanismo aprovecha las particularidades del entorno (la información probabilística que el diseñador tiene sobre los tipos de agentes). Dada la gran cantidad de información que las partes tienen entre sí hoy en día, es probable que este enfoque conduzca a ahorros enormes en comparación con los mecanismos clásicos, que en su mayoría ignoran esa información. Por ejemplo, imagina una empresa creando automáticamente su mecanismo de adquisiciones basado en el conocimiento estadístico sobre sus proveedores, en lugar de utilizar una subasta de adquisiciones descendente clásica. Cuarto, la carga del diseño se traslada de los humanos a una máquina. Sin embargo, el diseño automatizado de mecanismos requiere que el problema de optimización del diseño del mecanismo se resuelva de nuevo para cada configuración. Por lo tanto, su complejidad computacional se convierte en un tema clave. Investigaciones previas han estudiado esta pregunta para diseñadores benevolentes que desean maximizar, por ejemplo, el bienestar social [5, 6]. En este artículo estudiamos la complejidad computacional del diseño automatizado de mecanismos en el caso de un diseñador con interés propio. Esta es una configuración importante para el diseño de mecanismos automatizados debido a la escasez de mecanismos generales en esta área, y al hecho de que en la mayoría de las configuraciones de comercio electrónico el diseñador actúa en su propio interés. También demostramos que este problema está estrechamente relacionado con un problema de diseño de subasta combinatoria óptima (maximización de ingresos) particular. El resto de este documento está organizado de la siguiente manera. En la Sección 2, justificamos el enfoque en mecanismos no manipulables. En la Sección 3, definimos el problema que estudiamos. En la Sección 4, demostramos que diseñar un mecanismo determinista óptimo es NP-completo incluso cuando al diseñador solo le importan los pagos que recibe. En la Sección 5, demostramos que diseñar un mecanismo determinista óptimo también es NP-completo cuando los pagos no son posibles y el diseñador solo está interesado en el resultado elegido. En la Sección 6, demostramos que un mecanismo óptimo aleatorizado puede ser diseñado en tiempo polinómico incluso en el caso general. Finalmente, en la Sección 7, demostramos que para diseñar subastas combinatorias óptimas bajo preferencias de mejor opción solamente, nuestros resultados sobre AMD implican que este problema es NP-completo para subastas determinísticas, pero sencillo para subastas aleatorias. 2. JUSTIFICANDO EL ENFOQUE EN MECANISMOS NO MANIPULABLES Antes de definir el problema computacional del diseño automatizado de mecanismos, debemos justificar nuestro enfoque en mecanismos no manipulables. Después de todo, no es inmediatamente obvio que no haya mecanismos manipulables que, incluso cuando los agentes informan estratégicamente sus tipos y, por lo tanto, a veces de manera no veraz, aún logren mejores resultados (según el objetivo que usemos) que cualquier mecanismo no manipulable. Sin embargo, resulta ser el caso que, dado cualquier mecanismo, podemos construir un mecanismo no manipulable cuyo rendimiento es idéntico, de la siguiente manera. Construimos una capa de interfaz entre los agentes y el mecanismo original. Los agentes informan sus preferencias (o tipos) a la capa de interfaz; posteriormente, la capa de interfaz introduce en el mecanismo original los tipos que los agentes habrían informado estratégicamente al mecanismo original, si sus tipos fueran los declarados a la capa de interfaz. El resultado resultante es el resultado del nuevo mecanismo. Dado que la capa de interfaz actúa estratégicamente en nombre de cada agente, nunca hay un incentivo para informar falsamente a la capa de interfaz; por lo tanto, los tipos informados por la capa de interfaz son los tipos estratégicos que se habrían informado sin la capa de interfaz, por lo que los resultados son exactamente como habrían sido con el mecanismo original. Este argumento es conocido en la literatura de diseño de mecanismos como el principio de revelación [16]. (Existen dificultades computacionales al aplicar el principio de revelación en espacios de resultados y tipos combinatorios grandes [7, 22]). Sin embargo, dado que aquí nos enfocamos en espacios de resultados y tipos representados de forma plana, esto no es una preocupación aquí. Dado esto, podemos centrarnos en mecanismos veraces en el resto del documento. 3. DEFINICIONES Ahora formalizamos el entorno del diseño automatizado de mecanismos. Definición 1. En un entorno de diseño de mecanismos automatizados, se nos proporciona: • un conjunto finito de resultados O; • un conjunto finito de N agentes; • para cada agente i, 1. un conjunto finito de tipos Θi, 2. una distribución de probabilidad γi sobre Θi (en el caso de tipos correlacionados, hay una única distribución conjunta γ sobre Θ1 × . . . × ΘN), y 3. una función de utilidad ui: Θi × O → R; 1 • Una función objetivo cuya expectativa el diseñador desea maximizar. Existen muchas posibles funciones objetivo que el diseñador podría tener, por ejemplo, el bienestar social (donde el diseñador busca maximizar la suma de las utilidades de los agentes), o la utilidad mínima de cualquier agente (donde el diseñador busca maximizar la peor utilidad experimentada por cualquier agente). En ambos casos, el diseñador es benevolente, ya que, de alguna manera, el diseñador está buscando la felicidad colectiva de los agentes. Sin embargo, en este documento nos enfocamos en el caso de un diseñador interesado en sí mismo. Un diseñador egoísta solo se preocupa por el resultado elegido (es decir, al diseñador no le importa cómo se relaciona el resultado con las preferencias de los agentes, sino que tiene una preferencia fija sobre los resultados) y sobre los pagos netos realizados por los agentes, que fluyen hacia el diseñador. Definición 2. Un diseñador interesado tiene una función objetivo dada por g(o) + Σ i=1 πi, donde g : O → R indica las preferencias del diseñador sobre los resultados, y πi es el pago realizado por el agente i. En el caso en que g = 0 en todas partes, se dice que el diseñador está maximizando el pago. En el caso en que los pagos no sean posibles, g constituye la función objetivo por sí sola. Ahora definimos los tipos de mecanismos en estudio. Por el principio de revelación, podemos restringir la atención a mecanismos de revelación directa y veraz, donde los agentes informan directamente sus tipos y nunca tienen incentivos para informarlos de manera incorrecta. Definición 3. Consideramos los siguientes tipos de mecanismos: • Un mecanismo determinista sin pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O. • Un mecanismo aleatorio sin pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), donde P(O) es el conjunto de distribuciones de probabilidad sobre O. • Un mecanismo determinista con pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O y, para cada agente i, una función de selección de pagos πi: Θ1 × Θ2 × . . . × ΘN → R, donde πi(θ1, . . . , θN ) da el pago realizado por el agente i cuando los tipos reportados son θ1, . . . , θN. Aunque esto sigue la notación estándar de la teoría de juegos [16], el hecho de que el agente tenga tanto una función de utilidad como un tipo puede resultar confuso. Los tipos codifican las diversas preferencias posibles que el agente pueda tener, y el tipo de los agentes no es conocido por el agregador. La función de utilidad es un conocimiento común, pero debido a que el tipo de agente es un parámetro en la función de utilidad de los agentes, el agregador no puede saber cuál es la utilidad de los agentes sin conocer el tipo de agente. Un mecanismo aleatorio con pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), y para cada agente i, una función de selección de pago πi: Θ1 × Θ2 × . . . × ΘN → R. Hay dos tipos de restricciones para el diseñador al construir el mecanismo. 3.1 Restricciones de racionalidad individual (IR) El primer tipo de restricción es el siguiente. La utilidad de cada agente debe ser al menos tan grande como la utilidad de respaldo de los agentes, es decir, la utilidad que el agente recibiría si no participara en el mecanismo. De lo contrario, ese agente no participaría en el mecanismo, y la participación de ningún agente puede perjudicar el objetivo de los diseñadores del mecanismo, ya que en el peor de los casos, el mecanismo puede ignorar a un agente fingiendo que el agente no está presente. (Además, si no se aplicara tal restricción, el diseñador simplemente podría hacer que los agentes paguen una cantidad infinita). Este tipo de restricción se llama restricción de IR (racionalidad individual). Existen tres posibles restricciones de IR diferentes: ex ante, ex interim y ex post, dependiendo de lo que el agente sabe sobre su propio tipo y los tipos de los demás al decidir si participar en el mecanismo. Ex ante IR significa que el agente participaría si no supiera absolutamente nada (ni siquiera su propio tipo). No estudiaremos este concepto en este documento. Ex interim IR significa que el agente siempre participaría si conociera solo su propio tipo, pero no el de los demás. Ex post IR significa que el agente siempre participaría incluso si conociera el tipo de todos. Definiremos formalmente las dos últimas nociones de IR. Primero, necesitamos formalizar el concepto del <br>resultado de respaldo</br>. Suponemos que la utilidad de respaldo de cada agente es cero para cada uno de sus tipos. Esto se hace sin pérdida de generalidad porque podemos agregar un término constante a la función de utilidad de un agente (para un tipo dado), sin afectar el comportamiento de toma de decisiones de ese agente maximizador de utilidad esperada [16]. Definición 4. En cualquier entorno de diseño de mecanismos automatizados con una restricción de IR, existe un <br>resultado de contingencia</br> o0 ∈ O donde, para cualquier agente i y cualquier tipo θi ∈ Θi, tenemos ui(θi, o0) = 0. (Además, en el caso de un diseñador egoísta, g(o0) = 0). Ahora podemos definir las nociones de racionalidad individual. Definición 5. La racionalidad individual (RI) se define como: • Un mecanismo determinista es ex interim RI si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0. Un mecanismo aleatorio es ex interim IR si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • Un mecanismo determinista es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 No aleatorizamos sobre los pagos porque mientras los agentes y el diseñador sean neutrales al riesgo con respecto a los pagos, es decir, su utilidad es lineal en los pagos, no hay razón para aleatorizar sobre los pagos. Un mecanismo aleatorio es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 3.2 Restricciones de compatibilidad de incentivos (IC) El segundo tipo de restricción establece que los agentes nunca deben tener un incentivo para informar incorrectamente su tipo (como se justificó anteriormente mediante el principio de revelación). Para este tipo de restricción, las dos variantes más comunes (o conceptos de solución) son la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash. Definición 6. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en estrategias dominantes si decir la verdad siempre es óptimo incluso cuando los tipos reportados por los otros agentes ya son conocidos. Formalmente, para cualquier agente i, cualquier vector de tipos (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ). En el caso de mecanismos aleatorios tenemos Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. Por lo tanto, en la implementación de estrategias dominantes, decir la verdad es óptimo independientemente de lo que informen los otros agentes. Si es óptimo solo dado que los otros agentes son veraces, y dado que uno no conoce los tipos de los otros agentes, tenemos implementación en equilibrio de Bayes-Nash. Definición 7. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en equilibrio de Bayes-Nash si decir la verdad siempre es óptimo para un agente cuando ese agente aún no sabe nada sobre los tipos de los otros agentes, y los otros agentes están diciendo la verdad. Formalmente, para cualquier agente i, cualquier tipo θi ∈ Θi, y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )]. En el caso de mecanismos aleatorios tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 135 3.3 Diseño de mecanismos automatizados Ahora podemos definir el problema computacional que estudiamos. Definición 8. (DISEÑO DE MECANISMOS AUTOMATIZADOS (AMD)) Se nos da: • un entorno de diseño de mecanismos automatizados, • una noción de IR (ex interim, ex post, o ninguna), • un concepto de solución (estrategias dominantes o Bayes-Nash), • si los pagos son posibles, • si la aleatorización es posible, • (en la variante de decisión del problema) un valor objetivo G. Se nos pregunta si existe un mecanismo del tipo especificado (en términos de pagos y aleatorización) que satisfaga tanto la noción de IR como el concepto de solución, y proporcione un valor esperado de al menos G para el objetivo. Un caso especial interesante es aquel en el que solo hay un agente. En este caso, el agente informante siempre sabe todo lo que hay que saber sobre los otros tipos de agentes, porque no hay otros agentes. Dado que el IR ex post y el IR ex interim solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de IR coinciden aquí. Además, dado que la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de solución coinciden aquí. Esta observación resultará ser una herramienta útil para demostrar resultados de dificultad: si demostramos dificultad computacional en el escenario de un solo agente, esto implica inmediatamente dificultad para ambos conceptos de IR, para ambos conceptos de solución, para cualquier número de agentes. 4. En esta sección demostramos que es NP-completo diseñar un mecanismo determinístico que maximice la suma esperada de los pagos recolectados de los agentes. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Para demostrar la NP-dureza, reducimos desde el problema MINSAT. Definición 9 (MINSAT). Se nos da una fórmula φ en forma normal conjuntiva, representada por un conjunto de variables booleanas V y un conjunto de cláusulas C, y un entero K (K < |C|). Se nos pregunta si existe una asignación a las variables en V tal que se satisfacen a lo sumo K cláusulas en φ. MINSAT fue recientemente demostrado como NP-completo [14]. Ahora podemos presentar nuestro resultado. Teorema 1. El problema determinista de maximización de pagos de AMD es NP-completo, incluso para un solo agente, incluso con una distribución uniforme de tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista de maximización de pagos de un solo agente. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V } ∪ {−v : v ∈ V }. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Sea l ∈ c denota que el literal l ocurre en la cláusula c. Entonces, la función de utilidad de los agentes está dada por u(θc, ol) = |Θ| + 1 para todo l ∈ L con l ∈ c; u(θc, ol) = 0 para todo l ∈ L con l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc) = 0 para todo c ∈ C con c = c; u(θv, ol) = |Θ| para todo l ∈ L con v(l) = v; u(θv, ol) = 0 para todo l ∈ L con v(l) = v; u(θv, oc) = 0 para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ|, donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v) y π(θv) = |Θ|. Para cada c ∈ C, sea o(θc) = oc; sea π(θc) = |Θ| + 1 si c no está satisfecha en la solución MINSAT, y π(θc) = |Θ| si c está satisfecha. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es θv, entonces cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivo para informar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Porque además, ningún tipo que no sea θc conduce al resultado oc, informar cualquier otro tipo dará como resultado una utilidad de 0, mientras que aún se requiere un pago de al menos |Θ| por parte del agente. Claramente, el agente está mejor reportando honestamente, para una utilidad total de 0. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), el pago esperado de este mecanismo es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o y una función de pago π. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. Entonces, la utilidad que el agente obtiene del resultado dado para este tipo es 0, y por lo tanto, según la IR, no se puede extraer ningún pago del agente para este tipo. Dado que, nuevamente por IR, el pago máximo que se puede extraer para cualquier otro tipo es |Θ| + 1, se sigue que el pago esperado máximo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo cual contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o−v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por la restricción de IR, el pago máximo que podemos extraer de cualquier tipo θv es |Θ|. Dado que no puede haber incentivos para que el agente informe falsamente, para cualquier cláusula c satisfecha por la asignación dada, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ|. (Pues si extrajéramos más de este tipo, la utilidad del agente en este caso sería menor que 1; y si v es la variable que satisface c en la asignación, de modo que o(θv) = ol donde l ocurre en c, entonces al agente le convendría más informar θv en lugar del informe veraz θc, para obtener un resultado que valga |Θ|+1 para él mientras tiene que pagar como máximo |Θ|.) Finalmente, para cualquier cláusula insatisfecha c, según la restricción de IR, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ| + 1. Se deduce que el pago esperado de nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia de MINSAT. Dado que AMD, que maximiza el pago, es solo un caso especial de AMD para un diseñador egoísta en el que el diseñador no tiene preferencias sobre el resultado elegido, esto implica inmediatamente dificultades para el caso general de AMD para un diseñador egoísta en el que los pagos son posibles. Sin embargo, esto aún no implica dureza para el caso especial donde los pagos no son posibles. Demostraremos la dificultad en este caso en la próxima sección. 5. En esta sección demostramos que es NP-completo diseñar un mecanismo determinista que maximice la expectativa del objetivo del diseñador cuando no son posibles los pagos. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Teorema 2. Sin pagos, el diseño determinista de AMD para un diseñador egoísta es NP-completo, incluso para un solo agente, incluso con una distribución uniforme sobre los tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista auto-interesada de un solo agente sin pagos. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L} ∪ {o∗}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V} ∪ {−v : v ∈ V}. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Deje que l ∈ c denote que el literal l ocurre en la cláusula c. Luego, deje que la función de utilidad de los agentes esté dada por u(θc, ol) = 2 para todo l ∈ L con l ∈ c; u(θc, ol) = −1 para todo l ∈ L con l /∈ c; u(θc, oc) = 2; u(θc, oc) = −1 para todo c ∈ C con c = c; u(θc, o∗) = 1; u(θv, ol) = 1 para todo l ∈ L con v(l) = v; u(θv, ol) = −1 para todo l ∈ L con v(l) = v; u(θv, oc) = −1 para todo c ∈ C; u(θv, o∗) = −1. Que la función objetivo de los diseñadores esté dada por g(o∗ ) = |Θ|+1; g(ol) = |Θ| para todo l ∈ L; g(oc) = |Θ| para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ| , donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v). Para cada c ∈ C que se cumpla en la solución MINSAT, sea o(θc) = oc; para cada c ∈ C no satisfecho, sea o(θc) = o∗. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es algún θv, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para reportar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Debido a que tampoco ningún tipo conduce al resultado oc, no hay ningún resultado que el mecanismo seleccione que le daría al agente una utilidad mayor a 1 para el tipo θc, y por lo tanto el agente no tiene incentivo para informar falsamente. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), entonces el valor esperado de la función objetivo de los diseñadores es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. El único otro resultado que el mecanismo puede elegir bajo la restricción de IR es o0. Esto tiene un valor objetivo de 0, y dado que el valor más alto que la función objetivo alcanza es |Θ| + 1, se sigue que el valor esperado máximo de la función objetivo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo que contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o-v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por lo anterior, para cualquier tipo θv, el valor de la función objetivo en este mecanismo será |Θ|. Para cualquier cláusula c satisfecha por la asignación dada, el valor de la función objetivo en el caso en que el agente informe el tipo θc será como máximo |Θ|. (Esto se debe a que no podemos elegir el resultado o∗ para dicho tipo, ya que en este caso el agente tendría un incentivo para informar θv en su lugar, donde v es la variable que satisface c en la asignación (de modo que o(θv) = ol donde l ocurre en c).) Finalmente, para cualquier cláusula insatisfecha c, el valor máximo que la función objetivo puede alcanzar en el caso en que el agente informa el tipo θc es |Θ| + 1, simplemente porque este es el valor más grande que la función alcanza en cualquier momento. Se deduce que el valor esperado de la función objetivo para nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas 137 satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia MINSAT. Ambos de nuestros resultados de dureza se basaron en la restricción de que el mecanismo debería ser determinista. En la siguiente sección, mostramos que la dificultad del diseño desaparece cuando permitimos la aleatorización en el mecanismo. 6. La aleatorización de AMD para un diseñador interesado en sí mismo es fácil. Ahora mostramos cómo permitir la aleatorización sobre los resultados hace que el problema de AMD auto-interesado sea manejable a través de la programación lineal, para cualquier número constante de agentes. Teorema 3. El AMD aleatorio con interés propio con un número constante de agentes es resoluble en tiempo polinómico mediante programación lineal, tanto con pagos como sin pagos, tanto para IR ex post como ex interim, y tanto para la implementación en estrategias dominantes como para la implementación en equilibrio de Bayes-Nash, incluso si los tipos están correlacionados. Prueba. Dado que los programas lineales pueden resolverse en tiempo polinómico [13], todo lo que necesitamos demostrar es que el número de variables y ecuaciones en nuestro programa es polinomial para cualquier número constante de agentes, es decir, exponencial solo en N. En todo momento, para determinar el tamaño del programa lineal, consideremos T = maxi{|Θi|}. Las variables de nuestro programa lineal serán las probabilidades (p(θ1, θ2, . . . , θN ))(o) (como máximo TN |O| variables) y los pagos πi(θ1, θ2, . . . , θN ) (como máximo NTN variables). (Mostramos el programa lineal para el caso en que los pagos son posibles; el caso sin pagos se obtiene fácilmente de esto simplemente omitiendo todas las variables de pago en el programa, o agregando restricciones adicionales que obliguen a los pagos a ser 0). Primero, mostramos las restricciones de IR. Para el IR ex post, agregamos las siguientes restricciones (como máximo NTN) al LP: • Para cada i ∈ {1, 2, . . . , N}, y para cada (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , agregamos ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0. Para el ex interino IR, agregamos las siguientes restricciones (como máximo NT) al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada θi ∈ Θi, agregamos θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0. Ahora, mostramos las restricciones del concepto de solución. Para la implementación en estrategias dominantes, agregamos las siguientes (a lo sumo NTN+1) restricciones al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ). Finalmente, para la implementación en el equilibrio de Bayes-Nash, agregamos las siguientes (a lo sumo NT2) restricciones al LP: • Para cada i ∈ {1, 2, ..., N}, para cada θi ∈ Θi, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )). Todo lo que queda por hacer es dar la expresión que el diseñador busca maximizar, que es: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )). Como indicamos, el número de variables y restricciones es exponencial solo en N, por lo tanto, el programa lineal tiene un tamaño polinómico para un número constante de agentes. Por lo tanto, el problema es resoluble en tiempo polinómico. IMPLICACIONES PARA UN PROBLEMA DE DISEÑO DE SUBASTA COMBINATORIA ÓPTIMA En esta sección, demostraremos algunas consecuencias interesantes del problema de diseño de mecanismos automatizados para un diseñador interesado en sí mismo en el diseño de subastas combinatorias óptimas. Considera una subasta combinatoria con un conjunto S de artículos en venta. Para cualquier conjunto B ⊆ S, dejemos que ui(θi, B) sea la utilidad del postor i al recibir el conjunto B cuando el tipo del postor es θi. El problema de diseño de subasta óptima consiste en especificar las reglas de la subasta de manera que se maximice los ingresos esperados para el subastador. (Por el principio de revelación, sin pérdida de generalidad, podemos asumir que la subasta es veraz). El problema de diseño de subasta óptima se resuelve para el caso de un solo artículo mediante la famosa subasta de Myerson [18]. Sin embargo, el diseño de subastas óptimas en subastas combinatorias es un problema de investigación abierto reconocido [3, 25]. El problema está abierto incluso si solo hay dos artículos en venta. (El caso de dos artículos con una forma muy especial de complementariedad y sin sustituibilidad ha sido resuelto recientemente [1].) Supongamos que tenemos disposición libre: los artículos pueden ser desechados sin costo alguno. Además, supongamos que las preferencias de los postores tienen la siguiente estructura: cuando un postor recibe un conjunto de artículos, la utilidad del postor por ese conjunto está determinada únicamente por el mejor artículo en el conjunto. (Enfatizamos que qué artículo es el mejor puede depender del tipo de postor). Definición 10. Se dice que el postor i tiene preferencias solo por lo mejor sobre paquetes de artículos si existe una función vi: Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s). Hacemos la siguiente observación útil en este contexto: no tiene sentido otorgarle a un postor más de un artículo. La razón es que si el postor está informando honestamente, quitarle todos los artículos menos el de mayor valor no perjudicará al postor; y, mediante la disposición gratuita, hacerlo solo reducirá el incentivo para que este postor informe falsamente este tipo, cuando en realidad tiene otro tipo. Ahora demostramos que el problema de diseñar una subasta óptima determinista es NP-completo, mediante una reducción del problema AMD de maximización de pagos. Teorema 4. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de artículos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), diseñar la subasta determinística óptima es NP-completo, incluso para un único postor con una distribución uniforme sobre los tipos. Prueba. El problema está en NP porque podemos generar de manera no determinista una regla de asignación, y luego establecer los pagos utilizando programación lineal. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de AMD determinista que maximiza el pago, con un único agente y una distribución uniforme de tipos, al siguiente problema de diseño de subasta combinatoria óptima con una única postor con preferencias de solo los mejores. Para cada resultado o ∈ O en la instancia de AMD (excepto el resultado o0), que haya un artículo so ∈ S. Que el espacio de tipos sea el mismo, y que v(θi, so) = ui(θi, o) (donde u está especificado en la instancia de AMD). Que el valor objetivo de ingresos esperados sea el mismo en ambas instancias. Mostramos que las instancias son equivalentes. Primero supongamos que existe una solución para la instancia de AMD, dada por una función de resultado y una función de pago. Entonces, si la solución de AMD elige el resultado o para un tipo, en la solución de subasta óptima, asignamos {so} al postor para este tipo. (A menos que o = o0, en cuyo caso asignamos {} al postor). Que las funciones de pago sean las mismas en ambas instancias. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo verdadero) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución óptima de la subasta. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el subastador/diseñador son los mismos. Se deduce que existe una solución para la instancia de diseño de subasta óptima. Ahora supongamos que existe una solución para la instancia de diseño de subasta óptima. Por la observación de que como máximo se puede tener un artículo, podemos asumir sin pérdida de generalidad que la solución nunca asigna más de un artículo. Entonces, si la solución de subasta óptima asigna el artículo al postor para un tipo, en la solución de AMD, permita que el mecanismo elija el resultado o para ese tipo. Si la solución de subasta óptima no asigna nada al postor para un tipo, en la solución AMD, permita que el mecanismo elija el resultado o0 para ese tipo. Que las funciones de pago sean las mismas. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo real) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución AMD. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el diseñador/subastador son los mismos. Se deduce que existe una solución para la instancia de AMD. Afortunadamente, también podemos extender el resultado de facilidad para mecanismos aleatorios a este escenario de subasta combinatoria, lo que nos proporciona uno de los pocos algoritmos de tiempo polinómico conocidos para un problema de diseño óptimo de subasta combinatoria. Teorema 5. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de elementos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), si el número de postores es una constante k, entonces la subasta aleatoria óptima puede ser diseñada en tiempo polinómico. (Para cualquier restricción de IC e IR.) Prueba. Por la observación de que a lo sumo un artículo, podemos sin pérdida de generalidad restringirnos a asignaciones donde cada postor recibe como máximo un artículo. Hay menos de (|S| + 1)k asignaciones de ese tipo, es decir, un número polinómico de asignaciones. Dado que podemos enumerar explícitamente los resultados, simplemente podemos resolver esto como una instancia de AMD que maximiza el pago, con programación lineal. 8. Investigaciones relacionadas sobre la complejidad en el diseño de mecanismos. Ha habido un considerable interés reciente en el diseño de mecanismos en la informática. Parte de ello se ha centrado en cuestiones de complejidad computacional, pero la mayor parte de ese trabajo ha buscado diseñar mecanismos que sean fáciles de ejecutar (por ejemplo, [20, 15, 19, 9, 12]), en lugar de estudiar la complejidad de diseñar el mecanismo. La pieza más cercana de trabajo anterior estudió la complejidad del diseño automatizado de mecanismos por un diseñador benevolente [5, 6]. Roughgarden ha estudiado la complejidad de diseñar una buena topología de red para agentes que eligen egoístamente los enlaces que utilizan [21]. Esto está relacionado con el diseño de mecanismos, pero difiere significativamente en que el diseñador solo tiene un control restringido sobre las reglas del juego porque no hay ninguna parte que pueda imponer el resultado (o pagos laterales). Además, no hay un informe explícito de preferencias. 9. CONCLUSIONES E INVESTIGACIONES FUTURAS A menudo, un resultado debe ser elegido en función de las preferencias informadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les sea más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente emergente llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración específica de agregación de preferencias en cuestión. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo, un entorno mucho más relevante para el comercio electrónico. En este contexto, al centro solo le importa qué resultado se elige y qué pagos se le realizan. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este escenario, demostramos que diseñar un mecanismo determinista óptimo es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Estos resultados de dureza implican dificultad en todos los entornos de diseño de mecanismos automatizados más generales con un diseñador egoísta. Los resultados de dureza se aplican ya sea que las restricciones de racionalidad individual (participación) se apliquen ex interim o ex post, y ya sea que el concepto de solución sea la implementación de estrategias dominantes o la implementación del equilibrio de Bayes-Nash. Luego demostramos que permitir la aleatorización en el mecanismo hace que el problema de diseño en todos estos escenarios sea computacionalmente sencillo. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (que maximiza los ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar un mecanismo determinístico óptimo es NP-completo incluso con un agente, pero diseñar un mecanismo aleatorio óptimo es fácil. La investigación futura incluye estudiar el diseño automatizado de mecanismos con un diseñador interesado en sí mismo en entornos más restringidos, como subastas (donde el objetivo del diseñador puede incluir preferencias sobre qué postor debería recibir el bien, así como los pagos). También queremos estudiar la complejidad del diseño de mecanismos automatizados en entornos donde los espacios de resultados y tipos tienen una estructura especial para que puedan representarse de manera más concisa. Finalmente, planeamos reunir un conjunto de datos de problemas de diseño de mecanismos del mundo real, tanto históricos como actuales, y aplicar el diseño de mecanismos automatizado a esos problemas. 10. REFERENCIAS [1] M. Armstrong. Subastas multi-objetivo óptimas. Revisión de Estudios Económicos, 67:455-481, 2000. [2] K. Arrow. La doctrina de los derechos de propiedad y la revelación de la demanda bajo información incompleta. En M. Boskin, editor, Economía y bienestar humano. New York Academic Press, 1979. [3] C. Avery y T. Hendershott. Agrupación y subastas óptimas de múltiples productos. Revisión de Estudios Económicos, 67:483-497, 2000. [4] E. H. Clarke. Precios escalonados de bienes públicos. Elección Pública, 11:17-33, 1971. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Actas de la 18ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI-02), páginas 103-110, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Diseño de mecanismos automatizados: Resultados de complejidad derivados del entorno de un solo agente. En Actas de la 5ta Conferencia Internacional de Comercio Electrónico (ICEC-03), páginas 17-24, Pittsburgh, PA, EE. UU., 2003. [7] V. Conitzer y T. Sandholm. Críticas computacionales del principio de revelación. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), Nueva York, NY, 2004. Breve ensayo. La versión completa apareció en el taller AAMAS-03 sobre Comercio Electrónico Mediado por Agentes (AMEC). [8] C. d'Aspremont y L. A. Gérard-Varet. Incentivos e información incompleta. Revista de Economía Pública, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou y S. Shenker. Compartiendo el costo de las transmisiones de multidifusión. Revista de Ciencias de la Computación y de Sistemas, 63:21-41, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 2000. [10] A. Gibbard. Manipulación de esquemas de votación. Econometrica, 41:587-602, 1973. [11] T. Groves.\nEconometrica, 41:587-602, 1973. [11] T. Groves. Incentivos en equipos. Econometrica, 41:617-631, 1973. [12] J. Hershberger y S. Suri. Precios de Vickrey y caminos más cortos: ¿Cuánto vale una arista? En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [13] L. Khachiyan. Un algoritmo polinómico en programación lineal. Matemática soviética. Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi y P. Mirchandani. El problema de satisfacibilidad mínimo. Revista SIAM de Matemáticas Discretas, 7(2):275-283, 1994. [15] D. Lehmann, L. I. O'Callaghan y Y. Shoham. Revelación de la verdad en subastas combinatorias rápidas y aproximadamente eficientes. Revista de la ACM, 49(5):577-602, 2002. La versión inicial apareció en las Actas de la Conferencia de Comercio Electrónico de la ACM (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [17] E. S. Maskin y J. Riley. Subastas multiunidad óptimas. En F. Hahn, editor, \"La economía de los mercados faltantes, la información y los juegos\", capítulo 14, páginas 312-335. Clarendon Press, Oxford, 1989. [18] R. Myerson.\nPrensa Clarendon, Oxford, 1989. [18] R. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6:58-73, 1981. [19] N. Nisan y A. Ronen. Mecanismos VCG computacionalmente factibles. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 242-252, Minneapolis, MN, 2000. [20] N. Nisan y A. Ronen. Diseño de mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166-196, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 1999. [21] T. Roughgarden. Diseñar redes para usuarios egoístas es difícil. En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [22] T. Sandholm. Problemas en subastas computacionales de Vickrey. Revista Internacional de Comercio Electrónico, 4(3):107-129, 2000. Número especial sobre la Aplicación de Agentes Inteligentes para el Comercio Electrónico. Una versión corta y temprana apareció en la Segunda Conferencia Internacional sobre Sistemas Multiagente (ICMAS), páginas 299-306, 1996. [23] M. A. Satterthwaite. In Spanish, the translation would be: \"Inmutabilidad estratégica y condiciones de Arrow: teoremas de existencia y correspondencia para procedimientos de votación y funciones de bienestar social.\" Revista de Teoría Económica, 10:187-217, 1975. [24] W. Vickrey. Contrarrestando la especulación, subastas y ofertas selladas competitivas. Revista de Finanzas, 16:8-37, 1961. [25] R. V. Vohra. Problemas de investigación en subastas combinatorias. Mimeo, versión 29 de octubre de 2001. 141 ",
            "candidates": [],
            "error": [
                [
                    "resultado de respaldo",
                    "resultado de contingencia"
                ]
            ]
        },
        "automated mechanism design": {
            "translated_key": "diseño de mecanismos automatizado",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-interested <br>automated mechanism design</br> and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently proposed approach-called <br>automated mechanism design</br>-a mechanism is computed for the preference aggregation setting at hand.",
                "This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike the earlier work on <br>automated mechanism design</br> that studied a benevolent designer, in this paper we study <br>automated mechanism design</br> problems where the designer is self-interested.",
                "In this case, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy.",
                "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy.",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc.",
                "The preference aggregator generally does not know the agents preferences a priori.",
                "Rather, the agents report their preferences to the coordinator.",
                "Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully.",
                "Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen.",
                "Manipulability is a pervasive problem across preference aggregation mechanisms.",
                "A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.)",
                "What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective.",
                "This is the classic setting of mechanism design in game theory.",
                "In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself.",
                "This is the mechanism design setting most relevant to electronic commerce.",
                "In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear.",
                "It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences.",
                "The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments.",
                "The most common such constraint is that of individual rationality (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
                "For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences.",
                "Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it.",
                "Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off.",
                "On the other hand, the designer will not necessarily choose a social welfare maximizing outcome.",
                "For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected.",
                "Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0.",
                "Classical mechanism design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective.",
                "The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]).",
                "However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare.",
                "If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization.",
                "In practice, the designer may also be interested in the outcome per se.",
                "For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical.",
                "For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed.",
                "Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments.",
                "In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand.",
                "This approach addresses all of the downsides listed above.",
                "We formulate the mechanism design problem as an optimization problem.",
                "The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types.",
                "The output is a nonmanipulable mechanism that is optimal with respect to some objective.",
                "This approach is called <br>automated mechanism design</br>.",
                "The <br>automated mechanism design</br> approach has four advantages over the classical approach of designing general mechanisms.",
                "First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare).",
                "Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences.",
                "When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally.",
                "Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types).",
                "Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information.",
                "For example, imagine a company automatically creating its procurement mechanism based on statistical knowledge about its suppliers, rather than using a classical descending procurement auction.",
                "Fourth, the burden of design is shifted from humans to a machine.",
                "However, <br>automated mechanism design</br> requires the mechanism design optimization problem to be solved anew for each setting.",
                "Hence its computational complexity becomes a key issue.",
                "Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6].",
                "In this paper we study the computational complexity of <br>automated mechanism design</br> in the case of a self-interested designer.",
                "This is an important setting for <br>automated mechanism design</br> due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested.",
                "We also show that this problem is closely related to a particular optimal (revenue-maximizing) combinatorial auction design problem. 133 The rest of this paper is organized as follows.",
                "In Section 2, we justify the focus on nonmanipulable mechanisms.",
                "In Section 3, we define the problem we study.",
                "In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it.",
                "In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen.",
                "In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case.",
                "Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2.",
                "JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of <br>automated mechanism design</br>, we should justify our focus on nonmanipulable mechanisms.",
                "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any nonmanipulable mechanism.",
                "This does, however, turn out to be the case: given any mechanism, we can construct a nonmanipulable mechanism whose performance is identical, as follows.",
                "We build an interface layer between the agents and the original mechanism.",
                "The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer.",
                "The resulting outcome is the outcome of the new mechanism.",
                "Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism.",
                "This argument is known in the mechanism design literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22].",
                "However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.)",
                "Given this, we can focus on truthful mechanisms in the rest of the paper. 3.",
                "DEFINITIONS We now formalize the <br>automated mechanism design</br> setting.",
                "Definition 1.",
                "In an <br>automated mechanism design</br> setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize.",
                "There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent).",
                "In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness.",
                "However, in this paper, we focus on the case of a self-interested designer.",
                "A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer.",
                "Definition 2.",
                "A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i.",
                "In the case where g = 0 everywhere, the designer is said to be payment maximizing.",
                "In the case where payments are not possible, g constitutes the objective function by itself.",
                "We now define the kinds of mechanisms under study.",
                "By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them.",
                "Definition 3.",
                "We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing.",
                "The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator.",
                "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 Individual rationality (IR) constraints The first type of constraint is the following.",
                "The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism.",
                "Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.)",
                "This type of constraint is called an IR (individual rationality) constraint.",
                "There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism.",
                "Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type).",
                "We will not study this concept in this paper.",
                "Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others.",
                "Ex post IR means that the agent would always participate even if it knew everybodys type.",
                "We will define the latter two notions of IR formally.",
                "First, we need to formalize the concept of the fallback outcome.",
                "We assume that each agents fallback utility is zero for each one of its types.",
                "This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16].",
                "Definition 4.",
                "In any <br>automated mechanism design</br> setting with an IR constraint, there is a fallback outcome o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)",
                "We can now to define the notions of individual rationality.",
                "Definition 5.",
                "Individual rationality (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
                "A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments.",
                "A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
                "The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle).",
                "For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium.",
                "Definition 6.",
                "Given an <br>automated mechanism design</br> setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known.",
                "Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
                "In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible.",
                "Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report.",
                "If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium.",
                "Definition 7.",
                "Given an <br>automated mechanism design</br> setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth.",
                "Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible. 135 3.3 <br>automated mechanism design</br> We can now define the computational problem we study.",
                "Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an <br>automated mechanism design</br> setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective.",
                "An interesting special case is the setting where there is only one agent.",
                "In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents.",
                "Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here.",
                "Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here.",
                "This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4.",
                "PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "To demonstrate NPhardness, we reduce from the MINSAT problem.",
                "Definition 9 (MINSAT).",
                "We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|).",
                "We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied.",
                "MINSAT was recently shown to be NP-complete [14].",
                "We can now present our result.",
                "Theorem 1.",
                "Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent payment-maximizing deterministic AMD instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|.",
                "For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the MINSAT solution, and π(θc) = |Θ| if c is satisfied.",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent.",
                "Clearly the agent is better off reporting truthfully, for a total utility of 0.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type.",
                "Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the IR constraint, the maximum payment we can extract from any type θv is |Θ|.",
                "Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.)",
                "Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1.",
                "It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible.",
                "However, it does not yet imply hardness for the special case where payments are not possible.",
                "We will prove hardness in this case in the next section. 5.",
                "SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "Theorem 2.",
                "Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent self-interested deterministic AMD without payments instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1.",
                "Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v).",
                "For every c ∈ C that is satisfied in the MINSAT solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ .",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "The only other outcome that the mechanism is allowed to choose under the IR constraint is o0.",
                "This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}.",
                "We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|.",
                "For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).)",
                "Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes.",
                "It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Both of our hardness results relied on the constraint that the mechanism should be deterministic.",
                "In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6.",
                "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of self-interested AMD tractable through linear programming, for any constant number of agents.",
                "Theorem 3.",
                "Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated.",
                "Proof.",
                "Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}.",
                "The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.)",
                "First, we show the IR constraints.",
                "For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
                "For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
                "Now, we show the solution concept constraints.",
                "For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
                "Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
                "All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
                "As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents.",
                "Thus the problem is solvable in polynomial time. 7.",
                "IMPLICATIONS FOR AN OPTIMAL COMBINATORIAL AUCTION DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of <br>automated mechanism design</br> for a self-interested designer on designing optimal combinatorial auctions.",
                "Consider a combinatorial auction with a set S of items for sale.",
                "For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi.",
                "The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.)",
                "The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18].",
                "However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25].",
                "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of complementarity and no substitutability has been solved recently [1].)",
                "Suppose we have free disposal-items can be thrown away at no cost.",
                "Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.)",
                "Definition 10.",
                "Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
                "We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item.",
                "The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type.",
                "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the payment maximizing AMD problem!",
                "Theorem 4.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types.",
                "Proof.",
                "The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming.",
                "To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal combinatorial auction design problem instance with a single bidder with best-only preferences.",
                "For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance).",
                "Let the expected revenue target value be the same in both instances.",
                "We show the instances are equivalent.",
                "First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function.",
                "Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.)",
                "Let the payment functions be the same in both instances.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same.",
                "It follows that there exists a solution to the optimal auction design instance.",
                "Now suppose there exists a solution to the optimal auction design instance.",
                "By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item.",
                "Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type.",
                "If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type.",
                "Let the payment functions be the same.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same.",
                "It follows that there exists a solution to the AMD instance.",
                "Fortunately, we can also carry through the easiness result for randomized mechanisms to this combinatorial auction setting-giving us one of the few known polynomial-time algorithms for an optimal combinatorial auction design problem.",
                "Theorem 5.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.)",
                "Proof.",
                "By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item.",
                "There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations.",
                "Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8.",
                "RELATED RESEARCH ON COMPLEXITY IN MECHANISM DESIGN There has been considerable recent interest in mechanism design in computer science.",
                "Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism.",
                "The closest piece of earlier work studied the complexity of <br>automated mechanism design</br> by a benevolent designer [5, 6].",
                "Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21].",
                "This is related to mechanism design, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments).",
                "Also, there is no explicit reporting of preferences. 9.",
                "CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently emerging approach-called <br>automated mechanism design</br>-a mechanism is computed for the specific preference aggregation setting at hand.",
                "This has several advantages, 139 but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike earlier work on <br>automated mechanism design</br> that studied a benevolent designer, in this paper we studied <br>automated mechanism design</br> problems where the designer is self-interesteda setting much more relevant for electronic commerce.",
                "In this setting, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "These hardness results imply hardness in all more general <br>automated mechanism design</br> settings with a self-interested designer.",
                "The hardness results apply whether the individual rationality (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation.",
                "We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy.",
                "Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy.",
                "Future research includes studying <br>automated mechanism design</br> with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments).",
                "We also want to study the complexity of <br>automated mechanism design</br> in settings where the outcome and type spaces have special structure so they can be represented more concisely.",
                "Finally, we plan to assemble a data set of real-world mechanism design problems-both historical and current-and apply <br>automated mechanism design</br> to those problems. 10.",
                "REFERENCES [1] M. Armstrong.",
                "Optimal multi-object auctions.",
                "Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow.",
                "The property rights doctrine and demand revelation under incomplete information.",
                "In M. Boskin, editor, Economics and human welfare.",
                "New York Academic Press, 1979. [3] C. Avery and T. Hendershott.",
                "Bundling and optimal auctions of multiple products.",
                "Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke.",
                "Multipart pricing of public goods.",
                "Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "<br>automated mechanism design</br>: Complexity results stemming from the single-agent setting.",
                "In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm.",
                "Computational criticisms of the revelation principle.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004.",
                "Short paper.",
                "Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet.",
                "Incentives and incomplete information.",
                "Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker.",
                "Sharing the cost of muliticast transmissions.",
                "Journal of Computer and System Sciences, 63:21-41, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard.",
                "Manipulation of voting schemes.",
                "Econometrica, 41:587-602, 1973. [11] T. Groves.",
                "Incentives in teams.",
                "Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri.",
                "Vickrey prices and shortest paths: What is an edge worth?",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan.",
                "A polynomial algorithm in linear programming.",
                "Soviet Math.",
                "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani.",
                "The minimum satisfiability problem.",
                "SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham.",
                "Truth revelation in rapid, approximately efficient combinatorial auctions.",
                "Journal of the ACM, 49(5):577-602, 2002.",
                "Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [17] E. S. Maskin and J. Riley.",
                "Optimal multi-unit auctions.",
                "In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335.",
                "Clarendon Press, Oxford, 1989. [18] R. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen.",
                "Computationally feasible VCG mechanisms.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behavior, 35:166-196, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden.",
                "Designing networks for selfish users is hard.",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm.",
                "Issues in computational Vickrey auctions.",
                "International Journal of Electronic Commerce, 4(3):107-129, 2000.",
                "Special Issue on 140 Applying Intelligent Agents for Electronic Commerce.",
                "A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite.",
                "Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions.",
                "Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey.",
                "Counterspeculation, auctions, and competitive sealed tenders.",
                "Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra.",
                "Research problems in combinatorial auctions.",
                "Mimeo, version Oct. 29, 2001. 141"
            ],
            "original_annotated_samples": [
                "Self-interested <br>automated mechanism design</br> and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "In a recently proposed approach-called <br>automated mechanism design</br>-a mechanism is computed for the preference aggregation setting at hand.",
                "Unlike the earlier work on <br>automated mechanism design</br> that studied a benevolent designer, in this paper we study <br>automated mechanism design</br> problems where the designer is self-interested.",
                "This approach is called <br>automated mechanism design</br>.",
                "The <br>automated mechanism design</br> approach has four advantages over the classical approach of designing general mechanisms."
            ],
            "translated_annotated_samples": [
                "Diseño de <br>mecanismos automatizados de interés propio</br> e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes.",
                "En un enfoque recientemente propuesto, llamado <br>diseño de mecanismos automatizado</br>, se calcula un mecanismo para la configuración de agregación de preferencias actual.",
                "A diferencia de trabajos anteriores sobre el <br>diseño automatizado de mecanismos</br> que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de <br>diseño automatizado de mecanismos</br> donde el diseñador está interesado en sí mismo.",
                "Este enfoque se llama <br>diseño de mecanismos automatizado</br>.",
                "El enfoque de <br>diseño de mecanismos automatizado</br> tiene cuatro ventajas sobre el enfoque clásico de diseñar mecanismos generales."
            ],
            "translated_text": "Diseño de <br>mecanismos automatizados de interés propio</br> e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les resulte más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente propuesto, llamado <br>diseño de mecanismos automatizado</br>, se calcula un mecanismo para la configuración de agregación de preferencias actual. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre el <br>diseño automatizado de mecanismos</br> que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de <br>diseño automatizado de mecanismos</br> donde el diseñador está interesado en sí mismo. En este caso, al centro solo le importa qué resultado se elige y qué pagos se le hacen. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este contexto, demostramos que el diseño de mecanismos deterministas óptimos es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Luego mostramos cómo permitir la aleatorización en el mecanismo hace que los problemas en este entorno sean computacionalmente fáciles. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (maximizadora de ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar una subasta determinista óptima es NP-completo, pero diseñar una subasta aleatoria óptima es fácil. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Teoría 1. En entornos multiagentes, a menudo se debe elegir un resultado en función de las preferencias informadas por un grupo de agentes. Tales resultados podrían ser presidentes potenciales, planes conjuntos, asignaciones de bienes o recursos, etc. El agregador de preferencias generalmente no conoce las preferencias de los agentes de antemano. Más bien, los agentes informan sus preferencias al coordinador. Desafortunadamente, un agente puede tener un incentivo para informar incorrectamente sus preferencias con el fin de engañar al mecanismo y lograr que seleccione un resultado que sea más deseable para el agente que el resultado que se seleccionaría si el agente revelara sus preferencias de manera honesta. Tal manipulación es indeseable porque los mecanismos de agregación de preferencias están diseñados para agrupar las preferencias de una manera socialmente deseable, y si los agentes revelan sus preferencias de manera insincera, se podría elegir un resultado socialmente indeseable. La manipulabilidad es un problema generalizado en los mecanismos de agregación de preferencias. Un resultado negativo seminal, el teorema de Gibbard-Satterthwaite, muestra que bajo cualquier esquema de agregación de preferencias no dictatorial, si hay al menos 3 posibles resultados, existen preferencias bajo las cuales un agente está mejor reportando falsamente [10, 23]. (Un esquema de agregación de preferencias se llama dictatorial si uno de los agentes dicta el resultado sin importar las preferencias que reporten los otros agentes). Lo que le gustaría hacer al agregador es diseñar un mecanismo de agregación de preferencias para que 1) los agentes interesados reporten sus preferencias de manera veraz, y 2) el mecanismo elija un resultado que sea deseable desde la perspectiva de algún objetivo. Esta es la configuración clásica del diseño de mecanismos en la teoría de juegos. En este documento, estudiamos el caso en el que el diseñador actúa por interés propio, es decir, al diseñador no le importa directamente cómo se relaciona el resultado con las preferencias de los agentes, sino que está más preocupado por su propia agenda sobre cuál resultado debería ser elegido y en maximizar los pagos para sí mismo. Este es el entorno de diseño de mecanismos más relevante para el comercio electrónico. En el caso en que el diseñador del mecanismo esté interesado en maximizar alguna noción de bienestar social, la importancia de recopilar las preferencias de los agentes es clara. Quizás sea menos obvio por qué deberían ser recopilados cuando el diseñador está interesado en sí mismo y, por lo tanto, su objetivo no está directamente relacionado con las preferencias de los agentes. La razón de esto es que a menudo las preferencias de los agentes imponen límites en cómo el diseñador elige el resultado y los pagos. La restricción más común de este tipo es la de racionalidad individual (RI), lo que significa que el mecanismo no puede dejar a ningún agente en una situación peor a la que hubiera estado si no hubiera participado en el mecanismo. Por ejemplo, en el contexto del diseño óptimo de subastas, el diseñador (subastador) solo se preocupa por cuántos ingresos se recaudan, y no en sí mismo por cuán bien la asignación del bien (o bienes) corresponde a las preferencias de los agentes. Sin embargo, el diseñador no puede obligar a un agente a pagar más de lo que valora el paquete de bienes asignado a él. Por lo tanto, incluso un diseñador interesado en sí mismo elegirá un resultado que beneficie razonablemente a los agentes. Por otro lado, el diseñador no necesariamente elegirá un resultado que maximice el bienestar social. Por ejemplo, si el diseñador siempre elige un resultado que maximiza el bienestar social con respecto a las preferencias informadas, y obliga a cada agente a pagar la diferencia entre la utilidad que tiene ahora y la utilidad que habría tenido si no hubiera participado en el mecanismo, es fácil ver que los agentes pueden tener un incentivo para informar incorrectamente sus preferencias, lo que puede llevar realmente a recaudar menos ingresos. De hecho, uno de los resultados contraintuitivos de la teoría del diseño de subastas óptimas es que a veces el bien se asigna a nadie incluso cuando el subastador tiene un precio de reserva de 0. El diseño de mecanismos clásicos proporciona algunos mecanismos generales, que, bajo ciertas suposiciones, satisfacen alguna noción de no manipulabilidad y maximizan algún objetivo. La ventaja de estos mecanismos es que no dependen de información (incluso probabilística) sobre las preferencias de los agentes (por ejemplo, el mecanismo de Vickrey-Clarke-Groves (VCG) [24, 4, 11]), o pueden aplicarse fácilmente a cualquier distribución de probabilidad sobre las preferencias (por ejemplo, el mecanismo dAGVA [8, 2], la subasta de Myerson [18], y la subasta multiunidad de Maskin-Riley [17]). Sin embargo, los mecanismos generales también tienen importantes desventajas: • Los mecanismos generales más famosos y ampliamente aplicables, VCG y dAGVA, solo maximizan el bienestar social. Si el diseñador está interesado en sí mismo, como es el caso en muchos entornos de comercio electrónico, estos mecanismos no maximizan el objetivo del diseñador. • Los mecanismos generales que se centran en un diseñador interesado en sí mismo solo son aplicables en entornos muy restringidos, como la subasta de maximización de ingresos esperados de Myerson para vender un solo artículo, y la subasta de maximización de ingresos esperados de Maskin y Riley para vender múltiples unidades idénticas de un artículo. • Incluso en los entornos restringidos en los que se aplican estos mecanismos, solo permiten la maximización de pagos. En la práctica, el diseñador también puede estar interesado en el resultado en sí mismo. Por ejemplo, a un subastador le puede importar qué postor recibe el artículo. • A menudo se asume que los pagos laterales pueden ser utilizados para adaptar los incentivos de los agentes, pero esto no siempre es práctico. Por ejemplo, en los mercados electrónicos basados en trueque, como Recipco, firstbarter.com, BarterOne e Intagio, no se permiten los pagos laterales. Además, entre los agentes de software, podría ser más deseable construir mecanismos que no dependan de la capacidad de realizar pagos, ya que muchos agentes de software no cuentan con la infraestructura para hacer pagos. Por el contrario, seguimos un enfoque reciente donde el mecanismo se diseña automáticamente para el problema específico en cuestión. Este enfoque aborda todos los inconvenientes mencionados anteriormente. Formulamos el problema de diseño de mecanismos como un problema de optimización. La entrada se caracteriza por el número de agentes, los posibles tipos de agentes (preferencias) y las distribuciones previas de los agregadores sobre los tipos de agentes. La salida es un mecanismo no manipulable que es óptimo con respecto a algún objetivo. Este enfoque se llama <br>diseño de mecanismos automatizado</br>. El enfoque de <br>diseño de mecanismos automatizado</br> tiene cuatro ventajas sobre el enfoque clásico de diseñar mecanismos generales. ",
            "candidates": [],
            "error": [
                [
                    "mecanismos automatizados de interés propio",
                    "diseño de mecanismos automatizado",
                    "diseño automatizado de mecanismos",
                    "diseño automatizado de mecanismos",
                    "diseño de mecanismos automatizado",
                    "diseño de mecanismos automatizado"
                ]
            ]
        },
        "minsat": {
            "translated_key": "problema MINSAT",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-interested Automated Mechanism Design and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently proposed approach-called automated mechanism design-a mechanism is computed for the preference aggregation setting at hand.",
                "This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike the earlier work on automated mechanism design that studied a benevolent designer, in this paper we study automated mechanism design problems where the designer is self-interested.",
                "In this case, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy.",
                "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy.",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc.",
                "The preference aggregator generally does not know the agents preferences a priori.",
                "Rather, the agents report their preferences to the coordinator.",
                "Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully.",
                "Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen.",
                "Manipulability is a pervasive problem across preference aggregation mechanisms.",
                "A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.)",
                "What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective.",
                "This is the classic setting of mechanism design in game theory.",
                "In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself.",
                "This is the mechanism design setting most relevant to electronic commerce.",
                "In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear.",
                "It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences.",
                "The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments.",
                "The most common such constraint is that of individual rationality (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
                "For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences.",
                "Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it.",
                "Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off.",
                "On the other hand, the designer will not necessarily choose a social welfare maximizing outcome.",
                "For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected.",
                "Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0.",
                "Classical mechanism design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective.",
                "The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]).",
                "However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare.",
                "If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization.",
                "In practice, the designer may also be interested in the outcome per se.",
                "For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical.",
                "For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed.",
                "Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments.",
                "In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand.",
                "This approach addresses all of the downsides listed above.",
                "We formulate the mechanism design problem as an optimization problem.",
                "The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types.",
                "The output is a nonmanipulable mechanism that is optimal with respect to some objective.",
                "This approach is called automated mechanism design.",
                "The automated mechanism design approach has four advantages over the classical approach of designing general mechanisms.",
                "First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare).",
                "Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences.",
                "When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally.",
                "Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types).",
                "Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information.",
                "For example, imagine a company automatically creating its procurement mechanism based on statistical knowledge about its suppliers, rather than using a classical descending procurement auction.",
                "Fourth, the burden of design is shifted from humans to a machine.",
                "However, automated mechanism design requires the mechanism design optimization problem to be solved anew for each setting.",
                "Hence its computational complexity becomes a key issue.",
                "Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6].",
                "In this paper we study the computational complexity of automated mechanism design in the case of a self-interested designer.",
                "This is an important setting for automated mechanism design due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested.",
                "We also show that this problem is closely related to a particular optimal (revenue-maximizing) combinatorial auction design problem. 133 The rest of this paper is organized as follows.",
                "In Section 2, we justify the focus on nonmanipulable mechanisms.",
                "In Section 3, we define the problem we study.",
                "In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it.",
                "In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen.",
                "In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case.",
                "Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2.",
                "JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of automated mechanism design, we should justify our focus on nonmanipulable mechanisms.",
                "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any nonmanipulable mechanism.",
                "This does, however, turn out to be the case: given any mechanism, we can construct a nonmanipulable mechanism whose performance is identical, as follows.",
                "We build an interface layer between the agents and the original mechanism.",
                "The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer.",
                "The resulting outcome is the outcome of the new mechanism.",
                "Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism.",
                "This argument is known in the mechanism design literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22].",
                "However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.)",
                "Given this, we can focus on truthful mechanisms in the rest of the paper. 3.",
                "DEFINITIONS We now formalize the automated mechanism design setting.",
                "Definition 1.",
                "In an automated mechanism design setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize.",
                "There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent).",
                "In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness.",
                "However, in this paper, we focus on the case of a self-interested designer.",
                "A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer.",
                "Definition 2.",
                "A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i.",
                "In the case where g = 0 everywhere, the designer is said to be payment maximizing.",
                "In the case where payments are not possible, g constitutes the objective function by itself.",
                "We now define the kinds of mechanisms under study.",
                "By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them.",
                "Definition 3.",
                "We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing.",
                "The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator.",
                "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 Individual rationality (IR) constraints The first type of constraint is the following.",
                "The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism.",
                "Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.)",
                "This type of constraint is called an IR (individual rationality) constraint.",
                "There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism.",
                "Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type).",
                "We will not study this concept in this paper.",
                "Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others.",
                "Ex post IR means that the agent would always participate even if it knew everybodys type.",
                "We will define the latter two notions of IR formally.",
                "First, we need to formalize the concept of the fallback outcome.",
                "We assume that each agents fallback utility is zero for each one of its types.",
                "This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16].",
                "Definition 4.",
                "In any automated mechanism design setting with an IR constraint, there is a fallback outcome o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)",
                "We can now to define the notions of individual rationality.",
                "Definition 5.",
                "Individual rationality (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
                "A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments.",
                "A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
                "The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle).",
                "For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium.",
                "Definition 6.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known.",
                "Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
                "In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible.",
                "Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report.",
                "If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium.",
                "Definition 7.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth.",
                "Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible. 135 3.3 Automated mechanism design We can now define the computational problem we study.",
                "Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an automated mechanism design setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective.",
                "An interesting special case is the setting where there is only one agent.",
                "In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents.",
                "Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here.",
                "Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here.",
                "This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4.",
                "PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "To demonstrate NPhardness, we reduce from the <br>minsat</br> problem.",
                "Definition 9 (<br>minsat</br>).",
                "We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|).",
                "We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied.",
                "<br>minsat</br> was recently shown to be NP-complete [14].",
                "We can now present our result.",
                "Theorem 1.",
                "Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary <br>minsat</br> instance to the following single-agent payment-maximizing deterministic AMD instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the <br>minsat</br> instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the <br>minsat</br> instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the <br>minsat</br> instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|.",
                "For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the <br>minsat</br> solution, and π(θc) = |Θ| if c is satisfied.",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the <br>minsat</br> instance.",
                "Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent.",
                "Clearly the agent is better off reporting truthfully, for a total utility of 0.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the <br>minsat</br> solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type.",
                "Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the <br>minsat</br> instance.",
                "By the IR constraint, the maximum payment we can extract from any type θv is |Θ|.",
                "Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.)",
                "Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1.",
                "It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the <br>minsat</br> instance.",
                "Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible.",
                "However, it does not yet imply hardness for the special case where payments are not possible.",
                "We will prove hardness in this case in the next section. 5.",
                "SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "Theorem 2.",
                "Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary <br>minsat</br> instance to the following single-agent self-interested deterministic AMD without payments instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the <br>minsat</br> instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1.",
                "Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the <br>minsat</br> instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the <br>minsat</br> instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v).",
                "For every c ∈ C that is satisfied in the <br>minsat</br> solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ .",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the <br>minsat</br> instance.",
                "Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the <br>minsat</br> solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "The only other outcome that the mechanism is allowed to choose under the IR constraint is o0.",
                "This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}.",
                "We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the <br>minsat</br> instance.",
                "By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|.",
                "For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).)",
                "Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes.",
                "It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the <br>minsat</br> instance.",
                "Both of our hardness results relied on the constraint that the mechanism should be deterministic.",
                "In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6.",
                "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of self-interested AMD tractable through linear programming, for any constant number of agents.",
                "Theorem 3.",
                "Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated.",
                "Proof.",
                "Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}.",
                "The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.)",
                "First, we show the IR constraints.",
                "For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
                "For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
                "Now, we show the solution concept constraints.",
                "For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
                "Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
                "All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
                "As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents.",
                "Thus the problem is solvable in polynomial time. 7.",
                "IMPLICATIONS FOR AN OPTIMAL COMBINATORIAL AUCTION DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated mechanism design for a self-interested designer on designing optimal combinatorial auctions.",
                "Consider a combinatorial auction with a set S of items for sale.",
                "For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi.",
                "The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.)",
                "The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18].",
                "However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25].",
                "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of complementarity and no substitutability has been solved recently [1].)",
                "Suppose we have free disposal-items can be thrown away at no cost.",
                "Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.)",
                "Definition 10.",
                "Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
                "We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item.",
                "The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type.",
                "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the payment maximizing AMD problem!",
                "Theorem 4.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types.",
                "Proof.",
                "The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming.",
                "To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal combinatorial auction design problem instance with a single bidder with best-only preferences.",
                "For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance).",
                "Let the expected revenue target value be the same in both instances.",
                "We show the instances are equivalent.",
                "First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function.",
                "Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.)",
                "Let the payment functions be the same in both instances.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same.",
                "It follows that there exists a solution to the optimal auction design instance.",
                "Now suppose there exists a solution to the optimal auction design instance.",
                "By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item.",
                "Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type.",
                "If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type.",
                "Let the payment functions be the same.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same.",
                "It follows that there exists a solution to the AMD instance.",
                "Fortunately, we can also carry through the easiness result for randomized mechanisms to this combinatorial auction setting-giving us one of the few known polynomial-time algorithms for an optimal combinatorial auction design problem.",
                "Theorem 5.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.)",
                "Proof.",
                "By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item.",
                "There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations.",
                "Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8.",
                "RELATED RESEARCH ON COMPLEXITY IN MECHANISM DESIGN There has been considerable recent interest in mechanism design in computer science.",
                "Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism.",
                "The closest piece of earlier work studied the complexity of automated mechanism design by a benevolent designer [5, 6].",
                "Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21].",
                "This is related to mechanism design, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments).",
                "Also, there is no explicit reporting of preferences. 9.",
                "CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently emerging approach-called automated mechanism design-a mechanism is computed for the specific preference aggregation setting at hand.",
                "This has several advantages, 139 but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike earlier work on automated mechanism design that studied a benevolent designer, in this paper we studied automated mechanism design problems where the designer is self-interesteda setting much more relevant for electronic commerce.",
                "In this setting, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "These hardness results imply hardness in all more general automated mechanism design settings with a self-interested designer.",
                "The hardness results apply whether the individual rationality (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation.",
                "We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy.",
                "Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy.",
                "Future research includes studying automated mechanism design with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments).",
                "We also want to study the complexity of automated mechanism design in settings where the outcome and type spaces have special structure so they can be represented more concisely.",
                "Finally, we plan to assemble a data set of real-world mechanism design problems-both historical and current-and apply automated mechanism design to those problems. 10.",
                "REFERENCES [1] M. Armstrong.",
                "Optimal multi-object auctions.",
                "Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow.",
                "The property rights doctrine and demand revelation under incomplete information.",
                "In M. Boskin, editor, Economics and human welfare.",
                "New York Academic Press, 1979. [3] C. Avery and T. Hendershott.",
                "Bundling and optimal auctions of multiple products.",
                "Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke.",
                "Multipart pricing of public goods.",
                "Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Automated mechanism design: Complexity results stemming from the single-agent setting.",
                "In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm.",
                "Computational criticisms of the revelation principle.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004.",
                "Short paper.",
                "Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet.",
                "Incentives and incomplete information.",
                "Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker.",
                "Sharing the cost of muliticast transmissions.",
                "Journal of Computer and System Sciences, 63:21-41, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard.",
                "Manipulation of voting schemes.",
                "Econometrica, 41:587-602, 1973. [11] T. Groves.",
                "Incentives in teams.",
                "Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri.",
                "Vickrey prices and shortest paths: What is an edge worth?",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan.",
                "A polynomial algorithm in linear programming.",
                "Soviet Math.",
                "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani.",
                "The minimum satisfiability problem.",
                "SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham.",
                "Truth revelation in rapid, approximately efficient combinatorial auctions.",
                "Journal of the ACM, 49(5):577-602, 2002.",
                "Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [17] E. S. Maskin and J. Riley.",
                "Optimal multi-unit auctions.",
                "In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335.",
                "Clarendon Press, Oxford, 1989. [18] R. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen.",
                "Computationally feasible VCG mechanisms.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behavior, 35:166-196, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden.",
                "Designing networks for selfish users is hard.",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm.",
                "Issues in computational Vickrey auctions.",
                "International Journal of Electronic Commerce, 4(3):107-129, 2000.",
                "Special Issue on 140 Applying Intelligent Agents for Electronic Commerce.",
                "A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite.",
                "Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions.",
                "Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey.",
                "Counterspeculation, auctions, and competitive sealed tenders.",
                "Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra.",
                "Research problems in combinatorial auctions.",
                "Mimeo, version Oct. 29, 2001. 141"
            ],
            "original_annotated_samples": [
                "To demonstrate NPhardness, we reduce from the <br>minsat</br> problem.",
                "Definition 9 (<br>minsat</br>).",
                "<br>minsat</br> was recently shown to be NP-complete [14].",
                "To show NP-hardness, we reduce an arbitrary <br>minsat</br> instance to the following single-agent payment-maximizing deterministic AMD instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the <br>minsat</br> instance, and V is the set of variables."
            ],
            "translated_annotated_samples": [
                "Para demostrar la NP-dureza, reducimos desde el <br>problema MINSAT</br>.",
                "Definición 9 (MINSAT).",
                "MINSAT fue recientemente demostrado como NP-completo [14].",
                "Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista de maximización de pagos de un solo agente.",
                "Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables."
            ],
            "translated_text": "Diseño de mecanismos automatizados de interés propio e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les resulte más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente propuesto, llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración de agregación de preferencias actual. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre el diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo. En este caso, al centro solo le importa qué resultado se elige y qué pagos se le hacen. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este contexto, demostramos que el diseño de mecanismos deterministas óptimos es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Luego mostramos cómo permitir la aleatorización en el mecanismo hace que los problemas en este entorno sean computacionalmente fáciles. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (maximizadora de ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar una subasta determinista óptima es NP-completo, pero diseñar una subasta aleatoria óptima es fácil. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Teoría 1. En entornos multiagentes, a menudo se debe elegir un resultado en función de las preferencias informadas por un grupo de agentes. Tales resultados podrían ser presidentes potenciales, planes conjuntos, asignaciones de bienes o recursos, etc. El agregador de preferencias generalmente no conoce las preferencias de los agentes de antemano. Más bien, los agentes informan sus preferencias al coordinador. Desafortunadamente, un agente puede tener un incentivo para informar incorrectamente sus preferencias con el fin de engañar al mecanismo y lograr que seleccione un resultado que sea más deseable para el agente que el resultado que se seleccionaría si el agente revelara sus preferencias de manera honesta. Tal manipulación es indeseable porque los mecanismos de agregación de preferencias están diseñados para agrupar las preferencias de una manera socialmente deseable, y si los agentes revelan sus preferencias de manera insincera, se podría elegir un resultado socialmente indeseable. La manipulabilidad es un problema generalizado en los mecanismos de agregación de preferencias. Un resultado negativo seminal, el teorema de Gibbard-Satterthwaite, muestra que bajo cualquier esquema de agregación de preferencias no dictatorial, si hay al menos 3 posibles resultados, existen preferencias bajo las cuales un agente está mejor reportando falsamente [10, 23]. (Un esquema de agregación de preferencias se llama dictatorial si uno de los agentes dicta el resultado sin importar las preferencias que reporten los otros agentes). Lo que le gustaría hacer al agregador es diseñar un mecanismo de agregación de preferencias para que 1) los agentes interesados reporten sus preferencias de manera veraz, y 2) el mecanismo elija un resultado que sea deseable desde la perspectiva de algún objetivo. Esta es la configuración clásica del diseño de mecanismos en la teoría de juegos. En este documento, estudiamos el caso en el que el diseñador actúa por interés propio, es decir, al diseñador no le importa directamente cómo se relaciona el resultado con las preferencias de los agentes, sino que está más preocupado por su propia agenda sobre cuál resultado debería ser elegido y en maximizar los pagos para sí mismo. Este es el entorno de diseño de mecanismos más relevante para el comercio electrónico. En el caso en que el diseñador del mecanismo esté interesado en maximizar alguna noción de bienestar social, la importancia de recopilar las preferencias de los agentes es clara. Quizás sea menos obvio por qué deberían ser recopilados cuando el diseñador está interesado en sí mismo y, por lo tanto, su objetivo no está directamente relacionado con las preferencias de los agentes. La razón de esto es que a menudo las preferencias de los agentes imponen límites en cómo el diseñador elige el resultado y los pagos. La restricción más común de este tipo es la de racionalidad individual (RI), lo que significa que el mecanismo no puede dejar a ningún agente en una situación peor a la que hubiera estado si no hubiera participado en el mecanismo. Por ejemplo, en el contexto del diseño óptimo de subastas, el diseñador (subastador) solo se preocupa por cuántos ingresos se recaudan, y no en sí mismo por cuán bien la asignación del bien (o bienes) corresponde a las preferencias de los agentes. Sin embargo, el diseñador no puede obligar a un agente a pagar más de lo que valora el paquete de bienes asignado a él. Por lo tanto, incluso un diseñador interesado en sí mismo elegirá un resultado que beneficie razonablemente a los agentes. Por otro lado, el diseñador no necesariamente elegirá un resultado que maximice el bienestar social. Por ejemplo, si el diseñador siempre elige un resultado que maximiza el bienestar social con respecto a las preferencias informadas, y obliga a cada agente a pagar la diferencia entre la utilidad que tiene ahora y la utilidad que habría tenido si no hubiera participado en el mecanismo, es fácil ver que los agentes pueden tener un incentivo para informar incorrectamente sus preferencias, lo que puede llevar realmente a recaudar menos ingresos. De hecho, uno de los resultados contraintuitivos de la teoría del diseño de subastas óptimas es que a veces el bien se asigna a nadie incluso cuando el subastador tiene un precio de reserva de 0. El diseño de mecanismos clásicos proporciona algunos mecanismos generales, que, bajo ciertas suposiciones, satisfacen alguna noción de no manipulabilidad y maximizan algún objetivo. La ventaja de estos mecanismos es que no dependen de información (incluso probabilística) sobre las preferencias de los agentes (por ejemplo, el mecanismo de Vickrey-Clarke-Groves (VCG) [24, 4, 11]), o pueden aplicarse fácilmente a cualquier distribución de probabilidad sobre las preferencias (por ejemplo, el mecanismo dAGVA [8, 2], la subasta de Myerson [18], y la subasta multiunidad de Maskin-Riley [17]). Sin embargo, los mecanismos generales también tienen importantes desventajas: • Los mecanismos generales más famosos y ampliamente aplicables, VCG y dAGVA, solo maximizan el bienestar social. Si el diseñador está interesado en sí mismo, como es el caso en muchos entornos de comercio electrónico, estos mecanismos no maximizan el objetivo del diseñador. • Los mecanismos generales que se centran en un diseñador interesado en sí mismo solo son aplicables en entornos muy restringidos, como la subasta de maximización de ingresos esperados de Myerson para vender un solo artículo, y la subasta de maximización de ingresos esperados de Maskin y Riley para vender múltiples unidades idénticas de un artículo. • Incluso en los entornos restringidos en los que se aplican estos mecanismos, solo permiten la maximización de pagos. En la práctica, el diseñador también puede estar interesado en el resultado en sí mismo. Por ejemplo, a un subastador le puede importar qué postor recibe el artículo. • A menudo se asume que los pagos laterales pueden ser utilizados para adaptar los incentivos de los agentes, pero esto no siempre es práctico. Por ejemplo, en los mercados electrónicos basados en trueque, como Recipco, firstbarter.com, BarterOne e Intagio, no se permiten los pagos laterales. Además, entre los agentes de software, podría ser más deseable construir mecanismos que no dependan de la capacidad de realizar pagos, ya que muchos agentes de software no cuentan con la infraestructura para hacer pagos. Por el contrario, seguimos un enfoque reciente donde el mecanismo se diseña automáticamente para el problema específico en cuestión. Este enfoque aborda todos los inconvenientes mencionados anteriormente. Formulamos el problema de diseño de mecanismos como un problema de optimización. La entrada se caracteriza por el número de agentes, los posibles tipos de agentes (preferencias) y las distribuciones previas de los agregadores sobre los tipos de agentes. La salida es un mecanismo no manipulable que es óptimo con respecto a algún objetivo. Este enfoque se llama diseño de mecanismos automatizado. El enfoque de diseño de mecanismos automatizado tiene cuatro ventajas sobre el enfoque clásico de diseñar mecanismos generales. Primero, se puede utilizar incluso en entornos que no cumplen con las suposiciones de los mecanismos clásicos (como la disponibilidad de pagos laterales o que el objetivo sea el bienestar social). Segundo, puede permitir a uno eludir resultados de imposibilidad (como el teorema de Gibbard-Satterthwaite) que establecen que no existe un mecanismo que sea deseable para todas las preferencias. Cuando el mecanismo está diseñado para la configuración actual, no importa que no funcione de manera más general. Tercero, puede generar mecanismos mejores (en términos de garantías de no manipulabilidad más sólidas y/o mejores resultados) que los mecanismos clásicos porque el mecanismo aprovecha las particularidades del entorno (la información probabilística que el diseñador tiene sobre los tipos de agentes). Dada la gran cantidad de información que las partes tienen entre sí hoy en día, es probable que este enfoque conduzca a ahorros enormes en comparación con los mecanismos clásicos, que en su mayoría ignoran esa información. Por ejemplo, imagina una empresa creando automáticamente su mecanismo de adquisiciones basado en el conocimiento estadístico sobre sus proveedores, en lugar de utilizar una subasta de adquisiciones descendente clásica. Cuarto, la carga del diseño se traslada de los humanos a una máquina. Sin embargo, el diseño automatizado de mecanismos requiere que el problema de optimización del diseño del mecanismo se resuelva de nuevo para cada configuración. Por lo tanto, su complejidad computacional se convierte en un tema clave. Investigaciones previas han estudiado esta pregunta para diseñadores benevolentes que desean maximizar, por ejemplo, el bienestar social [5, 6]. En este artículo estudiamos la complejidad computacional del diseño automatizado de mecanismos en el caso de un diseñador con interés propio. Esta es una configuración importante para el diseño de mecanismos automatizados debido a la escasez de mecanismos generales en esta área, y al hecho de que en la mayoría de las configuraciones de comercio electrónico el diseñador actúa en su propio interés. También demostramos que este problema está estrechamente relacionado con un problema de diseño de subasta combinatoria óptima (maximización de ingresos) particular. El resto de este documento está organizado de la siguiente manera. En la Sección 2, justificamos el enfoque en mecanismos no manipulables. En la Sección 3, definimos el problema que estudiamos. En la Sección 4, demostramos que diseñar un mecanismo determinista óptimo es NP-completo incluso cuando al diseñador solo le importan los pagos que recibe. En la Sección 5, demostramos que diseñar un mecanismo determinista óptimo también es NP-completo cuando los pagos no son posibles y el diseñador solo está interesado en el resultado elegido. En la Sección 6, demostramos que un mecanismo óptimo aleatorizado puede ser diseñado en tiempo polinómico incluso en el caso general. Finalmente, en la Sección 7, demostramos que para diseñar subastas combinatorias óptimas bajo preferencias de mejor opción solamente, nuestros resultados sobre AMD implican que este problema es NP-completo para subastas determinísticas, pero sencillo para subastas aleatorias. 2. JUSTIFICANDO EL ENFOQUE EN MECANISMOS NO MANIPULABLES Antes de definir el problema computacional del diseño automatizado de mecanismos, debemos justificar nuestro enfoque en mecanismos no manipulables. Después de todo, no es inmediatamente obvio que no haya mecanismos manipulables que, incluso cuando los agentes informan estratégicamente sus tipos y, por lo tanto, a veces de manera no veraz, aún logren mejores resultados (según el objetivo que usemos) que cualquier mecanismo no manipulable. Sin embargo, resulta ser el caso que, dado cualquier mecanismo, podemos construir un mecanismo no manipulable cuyo rendimiento es idéntico, de la siguiente manera. Construimos una capa de interfaz entre los agentes y el mecanismo original. Los agentes informan sus preferencias (o tipos) a la capa de interfaz; posteriormente, la capa de interfaz introduce en el mecanismo original los tipos que los agentes habrían informado estratégicamente al mecanismo original, si sus tipos fueran los declarados a la capa de interfaz. El resultado resultante es el resultado del nuevo mecanismo. Dado que la capa de interfaz actúa estratégicamente en nombre de cada agente, nunca hay un incentivo para informar falsamente a la capa de interfaz; por lo tanto, los tipos informados por la capa de interfaz son los tipos estratégicos que se habrían informado sin la capa de interfaz, por lo que los resultados son exactamente como habrían sido con el mecanismo original. Este argumento es conocido en la literatura de diseño de mecanismos como el principio de revelación [16]. (Existen dificultades computacionales al aplicar el principio de revelación en espacios de resultados y tipos combinatorios grandes [7, 22]). Sin embargo, dado que aquí nos enfocamos en espacios de resultados y tipos representados de forma plana, esto no es una preocupación aquí. Dado esto, podemos centrarnos en mecanismos veraces en el resto del documento. 3. DEFINICIONES Ahora formalizamos el entorno del diseño automatizado de mecanismos. Definición 1. En un entorno de diseño de mecanismos automatizados, se nos proporciona: • un conjunto finito de resultados O; • un conjunto finito de N agentes; • para cada agente i, 1. un conjunto finito de tipos Θi, 2. una distribución de probabilidad γi sobre Θi (en el caso de tipos correlacionados, hay una única distribución conjunta γ sobre Θ1 × . . . × ΘN), y 3. una función de utilidad ui: Θi × O → R; 1 • Una función objetivo cuya expectativa el diseñador desea maximizar. Existen muchas posibles funciones objetivo que el diseñador podría tener, por ejemplo, el bienestar social (donde el diseñador busca maximizar la suma de las utilidades de los agentes), o la utilidad mínima de cualquier agente (donde el diseñador busca maximizar la peor utilidad experimentada por cualquier agente). En ambos casos, el diseñador es benevolente, ya que, de alguna manera, el diseñador está buscando la felicidad colectiva de los agentes. Sin embargo, en este documento nos enfocamos en el caso de un diseñador interesado en sí mismo. Un diseñador egoísta solo se preocupa por el resultado elegido (es decir, al diseñador no le importa cómo se relaciona el resultado con las preferencias de los agentes, sino que tiene una preferencia fija sobre los resultados) y sobre los pagos netos realizados por los agentes, que fluyen hacia el diseñador. Definición 2. Un diseñador interesado tiene una función objetivo dada por g(o) + Σ i=1 πi, donde g : O → R indica las preferencias del diseñador sobre los resultados, y πi es el pago realizado por el agente i. En el caso en que g = 0 en todas partes, se dice que el diseñador está maximizando el pago. En el caso en que los pagos no sean posibles, g constituye la función objetivo por sí sola. Ahora definimos los tipos de mecanismos en estudio. Por el principio de revelación, podemos restringir la atención a mecanismos de revelación directa y veraz, donde los agentes informan directamente sus tipos y nunca tienen incentivos para informarlos de manera incorrecta. Definición 3. Consideramos los siguientes tipos de mecanismos: • Un mecanismo determinista sin pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O. • Un mecanismo aleatorio sin pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), donde P(O) es el conjunto de distribuciones de probabilidad sobre O. • Un mecanismo determinista con pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O y, para cada agente i, una función de selección de pagos πi: Θ1 × Θ2 × . . . × ΘN → R, donde πi(θ1, . . . , θN ) da el pago realizado por el agente i cuando los tipos reportados son θ1, . . . , θN. Aunque esto sigue la notación estándar de la teoría de juegos [16], el hecho de que el agente tenga tanto una función de utilidad como un tipo puede resultar confuso. Los tipos codifican las diversas preferencias posibles que el agente pueda tener, y el tipo de los agentes no es conocido por el agregador. La función de utilidad es un conocimiento común, pero debido a que el tipo de agente es un parámetro en la función de utilidad de los agentes, el agregador no puede saber cuál es la utilidad de los agentes sin conocer el tipo de agente. Un mecanismo aleatorio con pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), y para cada agente i, una función de selección de pago πi: Θ1 × Θ2 × . . . × ΘN → R. Hay dos tipos de restricciones para el diseñador al construir el mecanismo. 3.1 Restricciones de racionalidad individual (IR) El primer tipo de restricción es el siguiente. La utilidad de cada agente debe ser al menos tan grande como la utilidad de respaldo de los agentes, es decir, la utilidad que el agente recibiría si no participara en el mecanismo. De lo contrario, ese agente no participaría en el mecanismo, y la participación de ningún agente puede perjudicar el objetivo de los diseñadores del mecanismo, ya que en el peor de los casos, el mecanismo puede ignorar a un agente fingiendo que el agente no está presente. (Además, si no se aplicara tal restricción, el diseñador simplemente podría hacer que los agentes paguen una cantidad infinita). Este tipo de restricción se llama restricción de IR (racionalidad individual). Existen tres posibles restricciones de IR diferentes: ex ante, ex interim y ex post, dependiendo de lo que el agente sabe sobre su propio tipo y los tipos de los demás al decidir si participar en el mecanismo. Ex ante IR significa que el agente participaría si no supiera absolutamente nada (ni siquiera su propio tipo). No estudiaremos este concepto en este documento. Ex interim IR significa que el agente siempre participaría si conociera solo su propio tipo, pero no el de los demás. Ex post IR significa que el agente siempre participaría incluso si conociera el tipo de todos. Definiremos formalmente las dos últimas nociones de IR. Primero, necesitamos formalizar el concepto del resultado de respaldo. Suponemos que la utilidad de respaldo de cada agente es cero para cada uno de sus tipos. Esto se hace sin pérdida de generalidad porque podemos agregar un término constante a la función de utilidad de un agente (para un tipo dado), sin afectar el comportamiento de toma de decisiones de ese agente maximizador de utilidad esperada [16]. Definición 4. En cualquier entorno de diseño de mecanismos automatizados con una restricción de IR, existe un resultado de contingencia o0 ∈ O donde, para cualquier agente i y cualquier tipo θi ∈ Θi, tenemos ui(θi, o0) = 0. (Además, en el caso de un diseñador egoísta, g(o0) = 0). Ahora podemos definir las nociones de racionalidad individual. Definición 5. La racionalidad individual (RI) se define como: • Un mecanismo determinista es ex interim RI si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0. Un mecanismo aleatorio es ex interim IR si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • Un mecanismo determinista es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 No aleatorizamos sobre los pagos porque mientras los agentes y el diseñador sean neutrales al riesgo con respecto a los pagos, es decir, su utilidad es lineal en los pagos, no hay razón para aleatorizar sobre los pagos. Un mecanismo aleatorio es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 3.2 Restricciones de compatibilidad de incentivos (IC) El segundo tipo de restricción establece que los agentes nunca deben tener un incentivo para informar incorrectamente su tipo (como se justificó anteriormente mediante el principio de revelación). Para este tipo de restricción, las dos variantes más comunes (o conceptos de solución) son la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash. Definición 6. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en estrategias dominantes si decir la verdad siempre es óptimo incluso cuando los tipos reportados por los otros agentes ya son conocidos. Formalmente, para cualquier agente i, cualquier vector de tipos (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ). En el caso de mecanismos aleatorios tenemos Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. Por lo tanto, en la implementación de estrategias dominantes, decir la verdad es óptimo independientemente de lo que informen los otros agentes. Si es óptimo solo dado que los otros agentes son veraces, y dado que uno no conoce los tipos de los otros agentes, tenemos implementación en equilibrio de Bayes-Nash. Definición 7. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en equilibrio de Bayes-Nash si decir la verdad siempre es óptimo para un agente cuando ese agente aún no sabe nada sobre los tipos de los otros agentes, y los otros agentes están diciendo la verdad. Formalmente, para cualquier agente i, cualquier tipo θi ∈ Θi, y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )]. En el caso de mecanismos aleatorios tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 135 3.3 Diseño de mecanismos automatizados Ahora podemos definir el problema computacional que estudiamos. Definición 8. (DISEÑO DE MECANISMOS AUTOMATIZADOS (AMD)) Se nos da: • un entorno de diseño de mecanismos automatizados, • una noción de IR (ex interim, ex post, o ninguna), • un concepto de solución (estrategias dominantes o Bayes-Nash), • si los pagos son posibles, • si la aleatorización es posible, • (en la variante de decisión del problema) un valor objetivo G. Se nos pregunta si existe un mecanismo del tipo especificado (en términos de pagos y aleatorización) que satisfaga tanto la noción de IR como el concepto de solución, y proporcione un valor esperado de al menos G para el objetivo. Un caso especial interesante es aquel en el que solo hay un agente. En este caso, el agente informante siempre sabe todo lo que hay que saber sobre los otros tipos de agentes, porque no hay otros agentes. Dado que el IR ex post y el IR ex interim solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de IR coinciden aquí. Además, dado que la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de solución coinciden aquí. Esta observación resultará ser una herramienta útil para demostrar resultados de dificultad: si demostramos dificultad computacional en el escenario de un solo agente, esto implica inmediatamente dificultad para ambos conceptos de IR, para ambos conceptos de solución, para cualquier número de agentes. 4. En esta sección demostramos que es NP-completo diseñar un mecanismo determinístico que maximice la suma esperada de los pagos recolectados de los agentes. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Para demostrar la NP-dureza, reducimos desde el <br>problema MINSAT</br>. Definición 9 (MINSAT). Se nos da una fórmula φ en forma normal conjuntiva, representada por un conjunto de variables booleanas V y un conjunto de cláusulas C, y un entero K (K < |C|). Se nos pregunta si existe una asignación a las variables en V tal que se satisfacen a lo sumo K cláusulas en φ. MINSAT fue recientemente demostrado como NP-completo [14]. Ahora podemos presentar nuestro resultado. Teorema 1. El problema determinista de maximización de pagos de AMD es NP-completo, incluso para un solo agente, incluso con una distribución uniforme de tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista de maximización de pagos de un solo agente. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "self-interested amd": {
            "translated_key": "AMD auto-interesado",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-interested Automated Mechanism Design and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently proposed approach-called automated mechanism design-a mechanism is computed for the preference aggregation setting at hand.",
                "This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike the earlier work on automated mechanism design that studied a benevolent designer, in this paper we study automated mechanism design problems where the designer is self-interested.",
                "In this case, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy.",
                "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy.",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc.",
                "The preference aggregator generally does not know the agents preferences a priori.",
                "Rather, the agents report their preferences to the coordinator.",
                "Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully.",
                "Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen.",
                "Manipulability is a pervasive problem across preference aggregation mechanisms.",
                "A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.)",
                "What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective.",
                "This is the classic setting of mechanism design in game theory.",
                "In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself.",
                "This is the mechanism design setting most relevant to electronic commerce.",
                "In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear.",
                "It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences.",
                "The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments.",
                "The most common such constraint is that of individual rationality (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
                "For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences.",
                "Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it.",
                "Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off.",
                "On the other hand, the designer will not necessarily choose a social welfare maximizing outcome.",
                "For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected.",
                "Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0.",
                "Classical mechanism design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective.",
                "The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]).",
                "However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare.",
                "If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization.",
                "In practice, the designer may also be interested in the outcome per se.",
                "For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical.",
                "For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed.",
                "Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments.",
                "In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand.",
                "This approach addresses all of the downsides listed above.",
                "We formulate the mechanism design problem as an optimization problem.",
                "The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types.",
                "The output is a nonmanipulable mechanism that is optimal with respect to some objective.",
                "This approach is called automated mechanism design.",
                "The automated mechanism design approach has four advantages over the classical approach of designing general mechanisms.",
                "First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare).",
                "Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences.",
                "When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally.",
                "Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types).",
                "Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information.",
                "For example, imagine a company automatically creating its procurement mechanism based on statistical knowledge about its suppliers, rather than using a classical descending procurement auction.",
                "Fourth, the burden of design is shifted from humans to a machine.",
                "However, automated mechanism design requires the mechanism design optimization problem to be solved anew for each setting.",
                "Hence its computational complexity becomes a key issue.",
                "Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6].",
                "In this paper we study the computational complexity of automated mechanism design in the case of a self-interested designer.",
                "This is an important setting for automated mechanism design due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested.",
                "We also show that this problem is closely related to a particular optimal (revenue-maximizing) combinatorial auction design problem. 133 The rest of this paper is organized as follows.",
                "In Section 2, we justify the focus on nonmanipulable mechanisms.",
                "In Section 3, we define the problem we study.",
                "In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it.",
                "In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen.",
                "In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case.",
                "Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2.",
                "JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of automated mechanism design, we should justify our focus on nonmanipulable mechanisms.",
                "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any nonmanipulable mechanism.",
                "This does, however, turn out to be the case: given any mechanism, we can construct a nonmanipulable mechanism whose performance is identical, as follows.",
                "We build an interface layer between the agents and the original mechanism.",
                "The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer.",
                "The resulting outcome is the outcome of the new mechanism.",
                "Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism.",
                "This argument is known in the mechanism design literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22].",
                "However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.)",
                "Given this, we can focus on truthful mechanisms in the rest of the paper. 3.",
                "DEFINITIONS We now formalize the automated mechanism design setting.",
                "Definition 1.",
                "In an automated mechanism design setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize.",
                "There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent).",
                "In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness.",
                "However, in this paper, we focus on the case of a self-interested designer.",
                "A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer.",
                "Definition 2.",
                "A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i.",
                "In the case where g = 0 everywhere, the designer is said to be payment maximizing.",
                "In the case where payments are not possible, g constitutes the objective function by itself.",
                "We now define the kinds of mechanisms under study.",
                "By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them.",
                "Definition 3.",
                "We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing.",
                "The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator.",
                "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 Individual rationality (IR) constraints The first type of constraint is the following.",
                "The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism.",
                "Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.)",
                "This type of constraint is called an IR (individual rationality) constraint.",
                "There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism.",
                "Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type).",
                "We will not study this concept in this paper.",
                "Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others.",
                "Ex post IR means that the agent would always participate even if it knew everybodys type.",
                "We will define the latter two notions of IR formally.",
                "First, we need to formalize the concept of the fallback outcome.",
                "We assume that each agents fallback utility is zero for each one of its types.",
                "This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16].",
                "Definition 4.",
                "In any automated mechanism design setting with an IR constraint, there is a fallback outcome o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)",
                "We can now to define the notions of individual rationality.",
                "Definition 5.",
                "Individual rationality (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
                "A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments.",
                "A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
                "The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle).",
                "For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium.",
                "Definition 6.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known.",
                "Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
                "In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible.",
                "Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report.",
                "If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium.",
                "Definition 7.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth.",
                "Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible. 135 3.3 Automated mechanism design We can now define the computational problem we study.",
                "Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an automated mechanism design setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective.",
                "An interesting special case is the setting where there is only one agent.",
                "In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents.",
                "Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here.",
                "Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here.",
                "This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4.",
                "PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "To demonstrate NPhardness, we reduce from the MINSAT problem.",
                "Definition 9 (MINSAT).",
                "We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|).",
                "We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied.",
                "MINSAT was recently shown to be NP-complete [14].",
                "We can now present our result.",
                "Theorem 1.",
                "Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent payment-maximizing deterministic AMD instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|.",
                "For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the MINSAT solution, and π(θc) = |Θ| if c is satisfied.",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent.",
                "Clearly the agent is better off reporting truthfully, for a total utility of 0.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type.",
                "Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the IR constraint, the maximum payment we can extract from any type θv is |Θ|.",
                "Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.)",
                "Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1.",
                "It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible.",
                "However, it does not yet imply hardness for the special case where payments are not possible.",
                "We will prove hardness in this case in the next section. 5.",
                "SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "Theorem 2.",
                "Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent self-interested deterministic AMD without payments instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1.",
                "Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v).",
                "For every c ∈ C that is satisfied in the MINSAT solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ .",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "The only other outcome that the mechanism is allowed to choose under the IR constraint is o0.",
                "This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}.",
                "We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|.",
                "For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).)",
                "Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes.",
                "It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Both of our hardness results relied on the constraint that the mechanism should be deterministic.",
                "In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6.",
                "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of <br>self-interested amd</br> tractable through linear programming, for any constant number of agents.",
                "Theorem 3.",
                "Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated.",
                "Proof.",
                "Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}.",
                "The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.)",
                "First, we show the IR constraints.",
                "For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
                "For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
                "Now, we show the solution concept constraints.",
                "For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
                "Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
                "All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
                "As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents.",
                "Thus the problem is solvable in polynomial time. 7.",
                "IMPLICATIONS FOR AN OPTIMAL COMBINATORIAL AUCTION DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated mechanism design for a self-interested designer on designing optimal combinatorial auctions.",
                "Consider a combinatorial auction with a set S of items for sale.",
                "For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi.",
                "The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.)",
                "The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18].",
                "However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25].",
                "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of complementarity and no substitutability has been solved recently [1].)",
                "Suppose we have free disposal-items can be thrown away at no cost.",
                "Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.)",
                "Definition 10.",
                "Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
                "We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item.",
                "The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type.",
                "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the payment maximizing AMD problem!",
                "Theorem 4.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types.",
                "Proof.",
                "The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming.",
                "To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal combinatorial auction design problem instance with a single bidder with best-only preferences.",
                "For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance).",
                "Let the expected revenue target value be the same in both instances.",
                "We show the instances are equivalent.",
                "First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function.",
                "Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.)",
                "Let the payment functions be the same in both instances.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same.",
                "It follows that there exists a solution to the optimal auction design instance.",
                "Now suppose there exists a solution to the optimal auction design instance.",
                "By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item.",
                "Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type.",
                "If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type.",
                "Let the payment functions be the same.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same.",
                "It follows that there exists a solution to the AMD instance.",
                "Fortunately, we can also carry through the easiness result for randomized mechanisms to this combinatorial auction setting-giving us one of the few known polynomial-time algorithms for an optimal combinatorial auction design problem.",
                "Theorem 5.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.)",
                "Proof.",
                "By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item.",
                "There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations.",
                "Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8.",
                "RELATED RESEARCH ON COMPLEXITY IN MECHANISM DESIGN There has been considerable recent interest in mechanism design in computer science.",
                "Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism.",
                "The closest piece of earlier work studied the complexity of automated mechanism design by a benevolent designer [5, 6].",
                "Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21].",
                "This is related to mechanism design, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments).",
                "Also, there is no explicit reporting of preferences. 9.",
                "CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently emerging approach-called automated mechanism design-a mechanism is computed for the specific preference aggregation setting at hand.",
                "This has several advantages, 139 but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike earlier work on automated mechanism design that studied a benevolent designer, in this paper we studied automated mechanism design problems where the designer is self-interesteda setting much more relevant for electronic commerce.",
                "In this setting, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "These hardness results imply hardness in all more general automated mechanism design settings with a self-interested designer.",
                "The hardness results apply whether the individual rationality (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation.",
                "We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy.",
                "Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy.",
                "Future research includes studying automated mechanism design with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments).",
                "We also want to study the complexity of automated mechanism design in settings where the outcome and type spaces have special structure so they can be represented more concisely.",
                "Finally, we plan to assemble a data set of real-world mechanism design problems-both historical and current-and apply automated mechanism design to those problems. 10.",
                "REFERENCES [1] M. Armstrong.",
                "Optimal multi-object auctions.",
                "Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow.",
                "The property rights doctrine and demand revelation under incomplete information.",
                "In M. Boskin, editor, Economics and human welfare.",
                "New York Academic Press, 1979. [3] C. Avery and T. Hendershott.",
                "Bundling and optimal auctions of multiple products.",
                "Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke.",
                "Multipart pricing of public goods.",
                "Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Automated mechanism design: Complexity results stemming from the single-agent setting.",
                "In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm.",
                "Computational criticisms of the revelation principle.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004.",
                "Short paper.",
                "Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet.",
                "Incentives and incomplete information.",
                "Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker.",
                "Sharing the cost of muliticast transmissions.",
                "Journal of Computer and System Sciences, 63:21-41, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard.",
                "Manipulation of voting schemes.",
                "Econometrica, 41:587-602, 1973. [11] T. Groves.",
                "Incentives in teams.",
                "Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri.",
                "Vickrey prices and shortest paths: What is an edge worth?",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan.",
                "A polynomial algorithm in linear programming.",
                "Soviet Math.",
                "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani.",
                "The minimum satisfiability problem.",
                "SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham.",
                "Truth revelation in rapid, approximately efficient combinatorial auctions.",
                "Journal of the ACM, 49(5):577-602, 2002.",
                "Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [17] E. S. Maskin and J. Riley.",
                "Optimal multi-unit auctions.",
                "In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335.",
                "Clarendon Press, Oxford, 1989. [18] R. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen.",
                "Computationally feasible VCG mechanisms.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behavior, 35:166-196, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden.",
                "Designing networks for selfish users is hard.",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm.",
                "Issues in computational Vickrey auctions.",
                "International Journal of Electronic Commerce, 4(3):107-129, 2000.",
                "Special Issue on 140 Applying Intelligent Agents for Electronic Commerce.",
                "A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite.",
                "Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions.",
                "Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey.",
                "Counterspeculation, auctions, and competitive sealed tenders.",
                "Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra.",
                "Research problems in combinatorial auctions.",
                "Mimeo, version Oct. 29, 2001. 141"
            ],
            "original_annotated_samples": [
                "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of <br>self-interested amd</br> tractable through linear programming, for any constant number of agents."
            ],
            "translated_annotated_samples": [
                "La aleatorización de AMD para un diseñador interesado en sí mismo es fácil. Ahora mostramos cómo permitir la aleatorización sobre los resultados hace que el problema de <br>AMD auto-interesado</br> sea manejable a través de la programación lineal, para cualquier número constante de agentes."
            ],
            "translated_text": "Diseño de mecanismos automatizados de interés propio e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les resulte más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente propuesto, llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración de agregación de preferencias actual. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre el diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo. En este caso, al centro solo le importa qué resultado se elige y qué pagos se le hacen. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este contexto, demostramos que el diseño de mecanismos deterministas óptimos es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Luego mostramos cómo permitir la aleatorización en el mecanismo hace que los problemas en este entorno sean computacionalmente fáciles. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (maximizadora de ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar una subasta determinista óptima es NP-completo, pero diseñar una subasta aleatoria óptima es fácil. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Teoría 1. En entornos multiagentes, a menudo se debe elegir un resultado en función de las preferencias informadas por un grupo de agentes. Tales resultados podrían ser presidentes potenciales, planes conjuntos, asignaciones de bienes o recursos, etc. El agregador de preferencias generalmente no conoce las preferencias de los agentes de antemano. Más bien, los agentes informan sus preferencias al coordinador. Desafortunadamente, un agente puede tener un incentivo para informar incorrectamente sus preferencias con el fin de engañar al mecanismo y lograr que seleccione un resultado que sea más deseable para el agente que el resultado que se seleccionaría si el agente revelara sus preferencias de manera honesta. Tal manipulación es indeseable porque los mecanismos de agregación de preferencias están diseñados para agrupar las preferencias de una manera socialmente deseable, y si los agentes revelan sus preferencias de manera insincera, se podría elegir un resultado socialmente indeseable. La manipulabilidad es un problema generalizado en los mecanismos de agregación de preferencias. Un resultado negativo seminal, el teorema de Gibbard-Satterthwaite, muestra que bajo cualquier esquema de agregación de preferencias no dictatorial, si hay al menos 3 posibles resultados, existen preferencias bajo las cuales un agente está mejor reportando falsamente [10, 23]. (Un esquema de agregación de preferencias se llama dictatorial si uno de los agentes dicta el resultado sin importar las preferencias que reporten los otros agentes). Lo que le gustaría hacer al agregador es diseñar un mecanismo de agregación de preferencias para que 1) los agentes interesados reporten sus preferencias de manera veraz, y 2) el mecanismo elija un resultado que sea deseable desde la perspectiva de algún objetivo. Esta es la configuración clásica del diseño de mecanismos en la teoría de juegos. En este documento, estudiamos el caso en el que el diseñador actúa por interés propio, es decir, al diseñador no le importa directamente cómo se relaciona el resultado con las preferencias de los agentes, sino que está más preocupado por su propia agenda sobre cuál resultado debería ser elegido y en maximizar los pagos para sí mismo. Este es el entorno de diseño de mecanismos más relevante para el comercio electrónico. En el caso en que el diseñador del mecanismo esté interesado en maximizar alguna noción de bienestar social, la importancia de recopilar las preferencias de los agentes es clara. Quizás sea menos obvio por qué deberían ser recopilados cuando el diseñador está interesado en sí mismo y, por lo tanto, su objetivo no está directamente relacionado con las preferencias de los agentes. La razón de esto es que a menudo las preferencias de los agentes imponen límites en cómo el diseñador elige el resultado y los pagos. La restricción más común de este tipo es la de racionalidad individual (RI), lo que significa que el mecanismo no puede dejar a ningún agente en una situación peor a la que hubiera estado si no hubiera participado en el mecanismo. Por ejemplo, en el contexto del diseño óptimo de subastas, el diseñador (subastador) solo se preocupa por cuántos ingresos se recaudan, y no en sí mismo por cuán bien la asignación del bien (o bienes) corresponde a las preferencias de los agentes. Sin embargo, el diseñador no puede obligar a un agente a pagar más de lo que valora el paquete de bienes asignado a él. Por lo tanto, incluso un diseñador interesado en sí mismo elegirá un resultado que beneficie razonablemente a los agentes. Por otro lado, el diseñador no necesariamente elegirá un resultado que maximice el bienestar social. Por ejemplo, si el diseñador siempre elige un resultado que maximiza el bienestar social con respecto a las preferencias informadas, y obliga a cada agente a pagar la diferencia entre la utilidad que tiene ahora y la utilidad que habría tenido si no hubiera participado en el mecanismo, es fácil ver que los agentes pueden tener un incentivo para informar incorrectamente sus preferencias, lo que puede llevar realmente a recaudar menos ingresos. De hecho, uno de los resultados contraintuitivos de la teoría del diseño de subastas óptimas es que a veces el bien se asigna a nadie incluso cuando el subastador tiene un precio de reserva de 0. El diseño de mecanismos clásicos proporciona algunos mecanismos generales, que, bajo ciertas suposiciones, satisfacen alguna noción de no manipulabilidad y maximizan algún objetivo. La ventaja de estos mecanismos es que no dependen de información (incluso probabilística) sobre las preferencias de los agentes (por ejemplo, el mecanismo de Vickrey-Clarke-Groves (VCG) [24, 4, 11]), o pueden aplicarse fácilmente a cualquier distribución de probabilidad sobre las preferencias (por ejemplo, el mecanismo dAGVA [8, 2], la subasta de Myerson [18], y la subasta multiunidad de Maskin-Riley [17]). Sin embargo, los mecanismos generales también tienen importantes desventajas: • Los mecanismos generales más famosos y ampliamente aplicables, VCG y dAGVA, solo maximizan el bienestar social. Si el diseñador está interesado en sí mismo, como es el caso en muchos entornos de comercio electrónico, estos mecanismos no maximizan el objetivo del diseñador. • Los mecanismos generales que se centran en un diseñador interesado en sí mismo solo son aplicables en entornos muy restringidos, como la subasta de maximización de ingresos esperados de Myerson para vender un solo artículo, y la subasta de maximización de ingresos esperados de Maskin y Riley para vender múltiples unidades idénticas de un artículo. • Incluso en los entornos restringidos en los que se aplican estos mecanismos, solo permiten la maximización de pagos. En la práctica, el diseñador también puede estar interesado en el resultado en sí mismo. Por ejemplo, a un subastador le puede importar qué postor recibe el artículo. • A menudo se asume que los pagos laterales pueden ser utilizados para adaptar los incentivos de los agentes, pero esto no siempre es práctico. Por ejemplo, en los mercados electrónicos basados en trueque, como Recipco, firstbarter.com, BarterOne e Intagio, no se permiten los pagos laterales. Además, entre los agentes de software, podría ser más deseable construir mecanismos que no dependan de la capacidad de realizar pagos, ya que muchos agentes de software no cuentan con la infraestructura para hacer pagos. Por el contrario, seguimos un enfoque reciente donde el mecanismo se diseña automáticamente para el problema específico en cuestión. Este enfoque aborda todos los inconvenientes mencionados anteriormente. Formulamos el problema de diseño de mecanismos como un problema de optimización. La entrada se caracteriza por el número de agentes, los posibles tipos de agentes (preferencias) y las distribuciones previas de los agregadores sobre los tipos de agentes. La salida es un mecanismo no manipulable que es óptimo con respecto a algún objetivo. Este enfoque se llama diseño de mecanismos automatizado. El enfoque de diseño de mecanismos automatizado tiene cuatro ventajas sobre el enfoque clásico de diseñar mecanismos generales. Primero, se puede utilizar incluso en entornos que no cumplen con las suposiciones de los mecanismos clásicos (como la disponibilidad de pagos laterales o que el objetivo sea el bienestar social). Segundo, puede permitir a uno eludir resultados de imposibilidad (como el teorema de Gibbard-Satterthwaite) que establecen que no existe un mecanismo que sea deseable para todas las preferencias. Cuando el mecanismo está diseñado para la configuración actual, no importa que no funcione de manera más general. Tercero, puede generar mecanismos mejores (en términos de garantías de no manipulabilidad más sólidas y/o mejores resultados) que los mecanismos clásicos porque el mecanismo aprovecha las particularidades del entorno (la información probabilística que el diseñador tiene sobre los tipos de agentes). Dada la gran cantidad de información que las partes tienen entre sí hoy en día, es probable que este enfoque conduzca a ahorros enormes en comparación con los mecanismos clásicos, que en su mayoría ignoran esa información. Por ejemplo, imagina una empresa creando automáticamente su mecanismo de adquisiciones basado en el conocimiento estadístico sobre sus proveedores, en lugar de utilizar una subasta de adquisiciones descendente clásica. Cuarto, la carga del diseño se traslada de los humanos a una máquina. Sin embargo, el diseño automatizado de mecanismos requiere que el problema de optimización del diseño del mecanismo se resuelva de nuevo para cada configuración. Por lo tanto, su complejidad computacional se convierte en un tema clave. Investigaciones previas han estudiado esta pregunta para diseñadores benevolentes que desean maximizar, por ejemplo, el bienestar social [5, 6]. En este artículo estudiamos la complejidad computacional del diseño automatizado de mecanismos en el caso de un diseñador con interés propio. Esta es una configuración importante para el diseño de mecanismos automatizados debido a la escasez de mecanismos generales en esta área, y al hecho de que en la mayoría de las configuraciones de comercio electrónico el diseñador actúa en su propio interés. También demostramos que este problema está estrechamente relacionado con un problema de diseño de subasta combinatoria óptima (maximización de ingresos) particular. El resto de este documento está organizado de la siguiente manera. En la Sección 2, justificamos el enfoque en mecanismos no manipulables. En la Sección 3, definimos el problema que estudiamos. En la Sección 4, demostramos que diseñar un mecanismo determinista óptimo es NP-completo incluso cuando al diseñador solo le importan los pagos que recibe. En la Sección 5, demostramos que diseñar un mecanismo determinista óptimo también es NP-completo cuando los pagos no son posibles y el diseñador solo está interesado en el resultado elegido. En la Sección 6, demostramos que un mecanismo óptimo aleatorizado puede ser diseñado en tiempo polinómico incluso en el caso general. Finalmente, en la Sección 7, demostramos que para diseñar subastas combinatorias óptimas bajo preferencias de mejor opción solamente, nuestros resultados sobre AMD implican que este problema es NP-completo para subastas determinísticas, pero sencillo para subastas aleatorias. 2. JUSTIFICANDO EL ENFOQUE EN MECANISMOS NO MANIPULABLES Antes de definir el problema computacional del diseño automatizado de mecanismos, debemos justificar nuestro enfoque en mecanismos no manipulables. Después de todo, no es inmediatamente obvio que no haya mecanismos manipulables que, incluso cuando los agentes informan estratégicamente sus tipos y, por lo tanto, a veces de manera no veraz, aún logren mejores resultados (según el objetivo que usemos) que cualquier mecanismo no manipulable. Sin embargo, resulta ser el caso que, dado cualquier mecanismo, podemos construir un mecanismo no manipulable cuyo rendimiento es idéntico, de la siguiente manera. Construimos una capa de interfaz entre los agentes y el mecanismo original. Los agentes informan sus preferencias (o tipos) a la capa de interfaz; posteriormente, la capa de interfaz introduce en el mecanismo original los tipos que los agentes habrían informado estratégicamente al mecanismo original, si sus tipos fueran los declarados a la capa de interfaz. El resultado resultante es el resultado del nuevo mecanismo. Dado que la capa de interfaz actúa estratégicamente en nombre de cada agente, nunca hay un incentivo para informar falsamente a la capa de interfaz; por lo tanto, los tipos informados por la capa de interfaz son los tipos estratégicos que se habrían informado sin la capa de interfaz, por lo que los resultados son exactamente como habrían sido con el mecanismo original. Este argumento es conocido en la literatura de diseño de mecanismos como el principio de revelación [16]. (Existen dificultades computacionales al aplicar el principio de revelación en espacios de resultados y tipos combinatorios grandes [7, 22]). Sin embargo, dado que aquí nos enfocamos en espacios de resultados y tipos representados de forma plana, esto no es una preocupación aquí. Dado esto, podemos centrarnos en mecanismos veraces en el resto del documento. 3. DEFINICIONES Ahora formalizamos el entorno del diseño automatizado de mecanismos. Definición 1. En un entorno de diseño de mecanismos automatizados, se nos proporciona: • un conjunto finito de resultados O; • un conjunto finito de N agentes; • para cada agente i, 1. un conjunto finito de tipos Θi, 2. una distribución de probabilidad γi sobre Θi (en el caso de tipos correlacionados, hay una única distribución conjunta γ sobre Θ1 × . . . × ΘN), y 3. una función de utilidad ui: Θi × O → R; 1 • Una función objetivo cuya expectativa el diseñador desea maximizar. Existen muchas posibles funciones objetivo que el diseñador podría tener, por ejemplo, el bienestar social (donde el diseñador busca maximizar la suma de las utilidades de los agentes), o la utilidad mínima de cualquier agente (donde el diseñador busca maximizar la peor utilidad experimentada por cualquier agente). En ambos casos, el diseñador es benevolente, ya que, de alguna manera, el diseñador está buscando la felicidad colectiva de los agentes. Sin embargo, en este documento nos enfocamos en el caso de un diseñador interesado en sí mismo. Un diseñador egoísta solo se preocupa por el resultado elegido (es decir, al diseñador no le importa cómo se relaciona el resultado con las preferencias de los agentes, sino que tiene una preferencia fija sobre los resultados) y sobre los pagos netos realizados por los agentes, que fluyen hacia el diseñador. Definición 2. Un diseñador interesado tiene una función objetivo dada por g(o) + Σ i=1 πi, donde g : O → R indica las preferencias del diseñador sobre los resultados, y πi es el pago realizado por el agente i. En el caso en que g = 0 en todas partes, se dice que el diseñador está maximizando el pago. En el caso en que los pagos no sean posibles, g constituye la función objetivo por sí sola. Ahora definimos los tipos de mecanismos en estudio. Por el principio de revelación, podemos restringir la atención a mecanismos de revelación directa y veraz, donde los agentes informan directamente sus tipos y nunca tienen incentivos para informarlos de manera incorrecta. Definición 3. Consideramos los siguientes tipos de mecanismos: • Un mecanismo determinista sin pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O. • Un mecanismo aleatorio sin pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), donde P(O) es el conjunto de distribuciones de probabilidad sobre O. • Un mecanismo determinista con pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O y, para cada agente i, una función de selección de pagos πi: Θ1 × Θ2 × . . . × ΘN → R, donde πi(θ1, . . . , θN ) da el pago realizado por el agente i cuando los tipos reportados son θ1, . . . , θN. Aunque esto sigue la notación estándar de la teoría de juegos [16], el hecho de que el agente tenga tanto una función de utilidad como un tipo puede resultar confuso. Los tipos codifican las diversas preferencias posibles que el agente pueda tener, y el tipo de los agentes no es conocido por el agregador. La función de utilidad es un conocimiento común, pero debido a que el tipo de agente es un parámetro en la función de utilidad de los agentes, el agregador no puede saber cuál es la utilidad de los agentes sin conocer el tipo de agente. Un mecanismo aleatorio con pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), y para cada agente i, una función de selección de pago πi: Θ1 × Θ2 × . . . × ΘN → R. Hay dos tipos de restricciones para el diseñador al construir el mecanismo. 3.1 Restricciones de racionalidad individual (IR) El primer tipo de restricción es el siguiente. La utilidad de cada agente debe ser al menos tan grande como la utilidad de respaldo de los agentes, es decir, la utilidad que el agente recibiría si no participara en el mecanismo. De lo contrario, ese agente no participaría en el mecanismo, y la participación de ningún agente puede perjudicar el objetivo de los diseñadores del mecanismo, ya que en el peor de los casos, el mecanismo puede ignorar a un agente fingiendo que el agente no está presente. (Además, si no se aplicara tal restricción, el diseñador simplemente podría hacer que los agentes paguen una cantidad infinita). Este tipo de restricción se llama restricción de IR (racionalidad individual). Existen tres posibles restricciones de IR diferentes: ex ante, ex interim y ex post, dependiendo de lo que el agente sabe sobre su propio tipo y los tipos de los demás al decidir si participar en el mecanismo. Ex ante IR significa que el agente participaría si no supiera absolutamente nada (ni siquiera su propio tipo). No estudiaremos este concepto en este documento. Ex interim IR significa que el agente siempre participaría si conociera solo su propio tipo, pero no el de los demás. Ex post IR significa que el agente siempre participaría incluso si conociera el tipo de todos. Definiremos formalmente las dos últimas nociones de IR. Primero, necesitamos formalizar el concepto del resultado de respaldo. Suponemos que la utilidad de respaldo de cada agente es cero para cada uno de sus tipos. Esto se hace sin pérdida de generalidad porque podemos agregar un término constante a la función de utilidad de un agente (para un tipo dado), sin afectar el comportamiento de toma de decisiones de ese agente maximizador de utilidad esperada [16]. Definición 4. En cualquier entorno de diseño de mecanismos automatizados con una restricción de IR, existe un resultado de contingencia o0 ∈ O donde, para cualquier agente i y cualquier tipo θi ∈ Θi, tenemos ui(θi, o0) = 0. (Además, en el caso de un diseñador egoísta, g(o0) = 0). Ahora podemos definir las nociones de racionalidad individual. Definición 5. La racionalidad individual (RI) se define como: • Un mecanismo determinista es ex interim RI si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0. Un mecanismo aleatorio es ex interim IR si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • Un mecanismo determinista es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 No aleatorizamos sobre los pagos porque mientras los agentes y el diseñador sean neutrales al riesgo con respecto a los pagos, es decir, su utilidad es lineal en los pagos, no hay razón para aleatorizar sobre los pagos. Un mecanismo aleatorio es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 3.2 Restricciones de compatibilidad de incentivos (IC) El segundo tipo de restricción establece que los agentes nunca deben tener un incentivo para informar incorrectamente su tipo (como se justificó anteriormente mediante el principio de revelación). Para este tipo de restricción, las dos variantes más comunes (o conceptos de solución) son la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash. Definición 6. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en estrategias dominantes si decir la verdad siempre es óptimo incluso cuando los tipos reportados por los otros agentes ya son conocidos. Formalmente, para cualquier agente i, cualquier vector de tipos (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ). En el caso de mecanismos aleatorios tenemos Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. Por lo tanto, en la implementación de estrategias dominantes, decir la verdad es óptimo independientemente de lo que informen los otros agentes. Si es óptimo solo dado que los otros agentes son veraces, y dado que uno no conoce los tipos de los otros agentes, tenemos implementación en equilibrio de Bayes-Nash. Definición 7. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en equilibrio de Bayes-Nash si decir la verdad siempre es óptimo para un agente cuando ese agente aún no sabe nada sobre los tipos de los otros agentes, y los otros agentes están diciendo la verdad. Formalmente, para cualquier agente i, cualquier tipo θi ∈ Θi, y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )]. En el caso de mecanismos aleatorios tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 135 3.3 Diseño de mecanismos automatizados Ahora podemos definir el problema computacional que estudiamos. Definición 8. (DISEÑO DE MECANISMOS AUTOMATIZADOS (AMD)) Se nos da: • un entorno de diseño de mecanismos automatizados, • una noción de IR (ex interim, ex post, o ninguna), • un concepto de solución (estrategias dominantes o Bayes-Nash), • si los pagos son posibles, • si la aleatorización es posible, • (en la variante de decisión del problema) un valor objetivo G. Se nos pregunta si existe un mecanismo del tipo especificado (en términos de pagos y aleatorización) que satisfaga tanto la noción de IR como el concepto de solución, y proporcione un valor esperado de al menos G para el objetivo. Un caso especial interesante es aquel en el que solo hay un agente. En este caso, el agente informante siempre sabe todo lo que hay que saber sobre los otros tipos de agentes, porque no hay otros agentes. Dado que el IR ex post y el IR ex interim solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de IR coinciden aquí. Además, dado que la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de solución coinciden aquí. Esta observación resultará ser una herramienta útil para demostrar resultados de dificultad: si demostramos dificultad computacional en el escenario de un solo agente, esto implica inmediatamente dificultad para ambos conceptos de IR, para ambos conceptos de solución, para cualquier número de agentes. 4. En esta sección demostramos que es NP-completo diseñar un mecanismo determinístico que maximice la suma esperada de los pagos recolectados de los agentes. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Para demostrar la NP-dureza, reducimos desde el problema MINSAT. Definición 9 (MINSAT). Se nos da una fórmula φ en forma normal conjuntiva, representada por un conjunto de variables booleanas V y un conjunto de cláusulas C, y un entero K (K < |C|). Se nos pregunta si existe una asignación a las variables en V tal que se satisfacen a lo sumo K cláusulas en φ. MINSAT fue recientemente demostrado como NP-completo [14]. Ahora podemos presentar nuestro resultado. Teorema 1. El problema determinista de maximización de pagos de AMD es NP-completo, incluso para un solo agente, incluso con una distribución uniforme de tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista de maximización de pagos de un solo agente. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V } ∪ {−v : v ∈ V }. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Sea l ∈ c denota que el literal l ocurre en la cláusula c. Entonces, la función de utilidad de los agentes está dada por u(θc, ol) = |Θ| + 1 para todo l ∈ L con l ∈ c; u(θc, ol) = 0 para todo l ∈ L con l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc) = 0 para todo c ∈ C con c = c; u(θv, ol) = |Θ| para todo l ∈ L con v(l) = v; u(θv, ol) = 0 para todo l ∈ L con v(l) = v; u(θv, oc) = 0 para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ|, donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v) y π(θv) = |Θ|. Para cada c ∈ C, sea o(θc) = oc; sea π(θc) = |Θ| + 1 si c no está satisfecha en la solución MINSAT, y π(θc) = |Θ| si c está satisfecha. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es θv, entonces cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivo para informar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Porque además, ningún tipo que no sea θc conduce al resultado oc, informar cualquier otro tipo dará como resultado una utilidad de 0, mientras que aún se requiere un pago de al menos |Θ| por parte del agente. Claramente, el agente está mejor reportando honestamente, para una utilidad total de 0. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), el pago esperado de este mecanismo es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o y una función de pago π. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. Entonces, la utilidad que el agente obtiene del resultado dado para este tipo es 0, y por lo tanto, según la IR, no se puede extraer ningún pago del agente para este tipo. Dado que, nuevamente por IR, el pago máximo que se puede extraer para cualquier otro tipo es |Θ| + 1, se sigue que el pago esperado máximo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo cual contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o−v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por la restricción de IR, el pago máximo que podemos extraer de cualquier tipo θv es |Θ|. Dado que no puede haber incentivos para que el agente informe falsamente, para cualquier cláusula c satisfecha por la asignación dada, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ|. (Pues si extrajéramos más de este tipo, la utilidad del agente en este caso sería menor que 1; y si v es la variable que satisface c en la asignación, de modo que o(θv) = ol donde l ocurre en c, entonces al agente le convendría más informar θv en lugar del informe veraz θc, para obtener un resultado que valga |Θ|+1 para él mientras tiene que pagar como máximo |Θ|.) Finalmente, para cualquier cláusula insatisfecha c, según la restricción de IR, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ| + 1. Se deduce que el pago esperado de nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia de MINSAT. Dado que AMD, que maximiza el pago, es solo un caso especial de AMD para un diseñador egoísta en el que el diseñador no tiene preferencias sobre el resultado elegido, esto implica inmediatamente dificultades para el caso general de AMD para un diseñador egoísta en el que los pagos son posibles. Sin embargo, esto aún no implica dureza para el caso especial donde los pagos no son posibles. Demostraremos la dificultad en este caso en la próxima sección. 5. En esta sección demostramos que es NP-completo diseñar un mecanismo determinista que maximice la expectativa del objetivo del diseñador cuando no son posibles los pagos. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Teorema 2. Sin pagos, el diseño determinista de AMD para un diseñador egoísta es NP-completo, incluso para un solo agente, incluso con una distribución uniforme sobre los tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista auto-interesada de un solo agente sin pagos. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L} ∪ {o∗}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V} ∪ {−v : v ∈ V}. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Deje que l ∈ c denote que el literal l ocurre en la cláusula c. Luego, deje que la función de utilidad de los agentes esté dada por u(θc, ol) = 2 para todo l ∈ L con l ∈ c; u(θc, ol) = −1 para todo l ∈ L con l /∈ c; u(θc, oc) = 2; u(θc, oc) = −1 para todo c ∈ C con c = c; u(θc, o∗) = 1; u(θv, ol) = 1 para todo l ∈ L con v(l) = v; u(θv, ol) = −1 para todo l ∈ L con v(l) = v; u(θv, oc) = −1 para todo c ∈ C; u(θv, o∗) = −1. Que la función objetivo de los diseñadores esté dada por g(o∗ ) = |Θ|+1; g(ol) = |Θ| para todo l ∈ L; g(oc) = |Θ| para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ| , donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v). Para cada c ∈ C que se cumpla en la solución MINSAT, sea o(θc) = oc; para cada c ∈ C no satisfecho, sea o(θc) = o∗. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es algún θv, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para reportar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Debido a que tampoco ningún tipo conduce al resultado oc, no hay ningún resultado que el mecanismo seleccione que le daría al agente una utilidad mayor a 1 para el tipo θc, y por lo tanto el agente no tiene incentivo para informar falsamente. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), entonces el valor esperado de la función objetivo de los diseñadores es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. El único otro resultado que el mecanismo puede elegir bajo la restricción de IR es o0. Esto tiene un valor objetivo de 0, y dado que el valor más alto que la función objetivo alcanza es |Θ| + 1, se sigue que el valor esperado máximo de la función objetivo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo que contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o-v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por lo anterior, para cualquier tipo θv, el valor de la función objetivo en este mecanismo será |Θ|. Para cualquier cláusula c satisfecha por la asignación dada, el valor de la función objetivo en el caso en que el agente informe el tipo θc será como máximo |Θ|. (Esto se debe a que no podemos elegir el resultado o∗ para dicho tipo, ya que en este caso el agente tendría un incentivo para informar θv en su lugar, donde v es la variable que satisface c en la asignación (de modo que o(θv) = ol donde l ocurre en c).) Finalmente, para cualquier cláusula insatisfecha c, el valor máximo que la función objetivo puede alcanzar en el caso en que el agente informa el tipo θc es |Θ| + 1, simplemente porque este es el valor más grande que la función alcanza en cualquier momento. Se deduce que el valor esperado de la función objetivo para nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas 137 satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia MINSAT. Ambos de nuestros resultados de dureza se basaron en la restricción de que el mecanismo debería ser determinista. En la siguiente sección, mostramos que la dificultad del diseño desaparece cuando permitimos la aleatorización en el mecanismo. 6. La aleatorización de AMD para un diseñador interesado en sí mismo es fácil. Ahora mostramos cómo permitir la aleatorización sobre los resultados hace que el problema de <br>AMD auto-interesado</br> sea manejable a través de la programación lineal, para cualquier número constante de agentes. Teorema 3. El AMD aleatorio con interés propio con un número constante de agentes es resoluble en tiempo polinómico mediante programación lineal, tanto con pagos como sin pagos, tanto para IR ex post como ex interim, y tanto para la implementación en estrategias dominantes como para la implementación en equilibrio de Bayes-Nash, incluso si los tipos están correlacionados. Prueba. Dado que los programas lineales pueden resolverse en tiempo polinómico [13], todo lo que necesitamos demostrar es que el número de variables y ecuaciones en nuestro programa es polinomial para cualquier número constante de agentes, es decir, exponencial solo en N. En todo momento, para determinar el tamaño del programa lineal, consideremos T = maxi{|Θi|}. Las variables de nuestro programa lineal serán las probabilidades (p(θ1, θ2, . . . , θN ))(o) (como máximo TN |O| variables) y los pagos πi(θ1, θ2, . . . , θN ) (como máximo NTN variables). (Mostramos el programa lineal para el caso en que los pagos son posibles; el caso sin pagos se obtiene fácilmente de esto simplemente omitiendo todas las variables de pago en el programa, o agregando restricciones adicionales que obliguen a los pagos a ser 0). Primero, mostramos las restricciones de IR. Para el IR ex post, agregamos las siguientes restricciones (como máximo NTN) al LP: • Para cada i ∈ {1, 2, . . . , N}, y para cada (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , agregamos ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0. Para el ex interino IR, agregamos las siguientes restricciones (como máximo NT) al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada θi ∈ Θi, agregamos θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0. Ahora, mostramos las restricciones del concepto de solución. Para la implementación en estrategias dominantes, agregamos las siguientes (a lo sumo NTN+1) restricciones al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ). Finalmente, para la implementación en el equilibrio de Bayes-Nash, agregamos las siguientes (a lo sumo NT2) restricciones al LP: • Para cada i ∈ {1, 2, ..., N}, para cada θi ∈ Θi, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )). Todo lo que queda por hacer es dar la expresión que el diseñador busca maximizar, que es: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )). Como indicamos, el número de variables y restricciones es exponencial solo en N, por lo tanto, el programa lineal tiene un tamaño polinómico para un número constante de agentes. Por lo tanto, el problema es resoluble en tiempo polinómico. IMPLICACIONES PARA UN PROBLEMA DE DISEÑO DE SUBASTA COMBINATORIA ÓPTIMA En esta sección, demostraremos algunas consecuencias interesantes del problema de diseño de mecanismos automatizados para un diseñador interesado en sí mismo en el diseño de subastas combinatorias óptimas. Considera una subasta combinatoria con un conjunto S de artículos en venta. Para cualquier conjunto B ⊆ S, dejemos que ui(θi, B) sea la utilidad del postor i al recibir el conjunto B cuando el tipo del postor es θi. El problema de diseño de subasta óptima consiste en especificar las reglas de la subasta de manera que se maximice los ingresos esperados para el subastador. (Por el principio de revelación, sin pérdida de generalidad, podemos asumir que la subasta es veraz). El problema de diseño de subasta óptima se resuelve para el caso de un solo artículo mediante la famosa subasta de Myerson [18]. Sin embargo, el diseño de subastas óptimas en subastas combinatorias es un problema de investigación abierto reconocido [3, 25]. El problema está abierto incluso si solo hay dos artículos en venta. (El caso de dos artículos con una forma muy especial de complementariedad y sin sustituibilidad ha sido resuelto recientemente [1].) Supongamos que tenemos disposición libre: los artículos pueden ser desechados sin costo alguno. Además, supongamos que las preferencias de los postores tienen la siguiente estructura: cuando un postor recibe un conjunto de artículos, la utilidad del postor por ese conjunto está determinada únicamente por el mejor artículo en el conjunto. (Enfatizamos que qué artículo es el mejor puede depender del tipo de postor). Definición 10. Se dice que el postor i tiene preferencias solo por lo mejor sobre paquetes de artículos si existe una función vi: Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s). Hacemos la siguiente observación útil en este contexto: no tiene sentido otorgarle a un postor más de un artículo. La razón es que si el postor está informando honestamente, quitarle todos los artículos menos el de mayor valor no perjudicará al postor; y, mediante la disposición gratuita, hacerlo solo reducirá el incentivo para que este postor informe falsamente este tipo, cuando en realidad tiene otro tipo. Ahora demostramos que el problema de diseñar una subasta óptima determinista es NP-completo, mediante una reducción del problema AMD de maximización de pagos. Teorema 4. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de artículos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), diseñar la subasta determinística óptima es NP-completo, incluso para un único postor con una distribución uniforme sobre los tipos. Prueba. El problema está en NP porque podemos generar de manera no determinista una regla de asignación, y luego establecer los pagos utilizando programación lineal. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de AMD determinista que maximiza el pago, con un único agente y una distribución uniforme de tipos, al siguiente problema de diseño de subasta combinatoria óptima con una única postor con preferencias de solo los mejores. Para cada resultado o ∈ O en la instancia de AMD (excepto el resultado o0), que haya un artículo so ∈ S. Que el espacio de tipos sea el mismo, y que v(θi, so) = ui(θi, o) (donde u está especificado en la instancia de AMD). Que el valor objetivo de ingresos esperados sea el mismo en ambas instancias. Mostramos que las instancias son equivalentes. Primero supongamos que existe una solución para la instancia de AMD, dada por una función de resultado y una función de pago. Entonces, si la solución de AMD elige el resultado o para un tipo, en la solución de subasta óptima, asignamos {so} al postor para este tipo. (A menos que o = o0, en cuyo caso asignamos {} al postor). Que las funciones de pago sean las mismas en ambas instancias. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo verdadero) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución óptima de la subasta. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el subastador/diseñador son los mismos. Se deduce que existe una solución para la instancia de diseño de subasta óptima. Ahora supongamos que existe una solución para la instancia de diseño de subasta óptima. Por la observación de que como máximo se puede tener un artículo, podemos asumir sin pérdida de generalidad que la solución nunca asigna más de un artículo. Entonces, si la solución de subasta óptima asigna el artículo al postor para un tipo, en la solución de AMD, permita que el mecanismo elija el resultado o para ese tipo. Si la solución de subasta óptima no asigna nada al postor para un tipo, en la solución AMD, permita que el mecanismo elija el resultado o0 para ese tipo. Que las funciones de pago sean las mismas. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo real) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución AMD. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el diseñador/subastador son los mismos. Se deduce que existe una solución para la instancia de AMD. Afortunadamente, también podemos extender el resultado de facilidad para mecanismos aleatorios a este escenario de subasta combinatoria, lo que nos proporciona uno de los pocos algoritmos de tiempo polinómico conocidos para un problema de diseño óptimo de subasta combinatoria. Teorema 5. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de elementos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), si el número de postores es una constante k, entonces la subasta aleatoria óptima puede ser diseñada en tiempo polinómico. (Para cualquier restricción de IC e IR.) Prueba. Por la observación de que a lo sumo un artículo, podemos sin pérdida de generalidad restringirnos a asignaciones donde cada postor recibe como máximo un artículo. Hay menos de (|S| + 1)k asignaciones de ese tipo, es decir, un número polinómico de asignaciones. Dado que podemos enumerar explícitamente los resultados, simplemente podemos resolver esto como una instancia de AMD que maximiza el pago, con programación lineal. 8. Investigaciones relacionadas sobre la complejidad en el diseño de mecanismos. Ha habido un considerable interés reciente en el diseño de mecanismos en la informática. Parte de ello se ha centrado en cuestiones de complejidad computacional, pero la mayor parte de ese trabajo ha buscado diseñar mecanismos que sean fáciles de ejecutar (por ejemplo, [20, 15, 19, 9, 12]), en lugar de estudiar la complejidad de diseñar el mecanismo. La pieza más cercana de trabajo anterior estudió la complejidad del diseño automatizado de mecanismos por un diseñador benevolente [5, 6]. Roughgarden ha estudiado la complejidad de diseñar una buena topología de red para agentes que eligen egoístamente los enlaces que utilizan [21]. Esto está relacionado con el diseño de mecanismos, pero difiere significativamente en que el diseñador solo tiene un control restringido sobre las reglas del juego porque no hay ninguna parte que pueda imponer el resultado (o pagos laterales). Además, no hay un informe explícito de preferencias. 9. CONCLUSIONES E INVESTIGACIONES FUTURAS A menudo, un resultado debe ser elegido en función de las preferencias informadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les sea más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente emergente llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración específica de agregación de preferencias en cuestión. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo, un entorno mucho más relevante para el comercio electrónico. En este contexto, al centro solo le importa qué resultado se elige y qué pagos se le realizan. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este escenario, demostramos que diseñar un mecanismo determinista óptimo es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Estos resultados de dureza implican dificultad en todos los entornos de diseño de mecanismos automatizados más generales con un diseñador egoísta. Los resultados de dureza se aplican ya sea que las restricciones de racionalidad individual (participación) se apliquen ex interim o ex post, y ya sea que el concepto de solución sea la implementación de estrategias dominantes o la implementación del equilibrio de Bayes-Nash. Luego demostramos que permitir la aleatorización en el mecanismo hace que el problema de diseño en todos estos escenarios sea computacionalmente sencillo. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (que maximiza los ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar un mecanismo determinístico óptimo es NP-completo incluso con un agente, pero diseñar un mecanismo aleatorio óptimo es fácil. La investigación futura incluye estudiar el diseño automatizado de mecanismos con un diseñador interesado en sí mismo en entornos más restringidos, como subastas (donde el objetivo del diseñador puede incluir preferencias sobre qué postor debería recibir el bien, así como los pagos). También queremos estudiar la complejidad del diseño de mecanismos automatizados en entornos donde los espacios de resultados y tipos tienen una estructura especial para que puedan representarse de manera más concisa. Finalmente, planeamos reunir un conjunto de datos de problemas de diseño de mecanismos del mundo real, tanto históricos como actuales, y aplicar el diseño de mecanismos automatizado a esos problemas. 10. REFERENCIAS [1] M. Armstrong. Subastas multi-objetivo óptimas. Revisión de Estudios Económicos, 67:455-481, 2000. [2] K. Arrow. La doctrina de los derechos de propiedad y la revelación de la demanda bajo información incompleta. En M. Boskin, editor, Economía y bienestar humano. New York Academic Press, 1979. [3] C. Avery y T. Hendershott. Agrupación y subastas óptimas de múltiples productos. Revisión de Estudios Económicos, 67:483-497, 2000. [4] E. H. Clarke. Precios escalonados de bienes públicos. Elección Pública, 11:17-33, 1971. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Actas de la 18ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI-02), páginas 103-110, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Diseño de mecanismos automatizados: Resultados de complejidad derivados del entorno de un solo agente. En Actas de la 5ta Conferencia Internacional de Comercio Electrónico (ICEC-03), páginas 17-24, Pittsburgh, PA, EE. UU., 2003. [7] V. Conitzer y T. Sandholm. Críticas computacionales del principio de revelación. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), Nueva York, NY, 2004. Breve ensayo. La versión completa apareció en el taller AAMAS-03 sobre Comercio Electrónico Mediado por Agentes (AMEC). [8] C. d'Aspremont y L. A. Gérard-Varet. Incentivos e información incompleta. Revista de Economía Pública, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou y S. Shenker. Compartiendo el costo de las transmisiones de multidifusión. Revista de Ciencias de la Computación y de Sistemas, 63:21-41, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 2000. [10] A. Gibbard. Manipulación de esquemas de votación. Econometrica, 41:587-602, 1973. [11] T. Groves.\nEconometrica, 41:587-602, 1973. [11] T. Groves. Incentivos en equipos. Econometrica, 41:617-631, 1973. [12] J. Hershberger y S. Suri. Precios de Vickrey y caminos más cortos: ¿Cuánto vale una arista? En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [13] L. Khachiyan. Un algoritmo polinómico en programación lineal. Matemática soviética. Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi y P. Mirchandani. El problema de satisfacibilidad mínimo. Revista SIAM de Matemáticas Discretas, 7(2):275-283, 1994. [15] D. Lehmann, L. I. O'Callaghan y Y. Shoham. Revelación de la verdad en subastas combinatorias rápidas y aproximadamente eficientes. Revista de la ACM, 49(5):577-602, 2002. La versión inicial apareció en las Actas de la Conferencia de Comercio Electrónico de la ACM (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [17] E. S. Maskin y J. Riley. Subastas multiunidad óptimas. En F. Hahn, editor, \"La economía de los mercados faltantes, la información y los juegos\", capítulo 14, páginas 312-335. Clarendon Press, Oxford, 1989. [18] R. Myerson.\nPrensa Clarendon, Oxford, 1989. [18] R. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6:58-73, 1981. [19] N. Nisan y A. Ronen. Mecanismos VCG computacionalmente factibles. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 242-252, Minneapolis, MN, 2000. [20] N. Nisan y A. Ronen. Diseño de mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166-196, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 1999. [21] T. Roughgarden. Diseñar redes para usuarios egoístas es difícil. En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [22] T. Sandholm. Problemas en subastas computacionales de Vickrey. Revista Internacional de Comercio Electrónico, 4(3):107-129, 2000. Número especial sobre la Aplicación de Agentes Inteligentes para el Comercio Electrónico. Una versión corta y temprana apareció en la Segunda Conferencia Internacional sobre Sistemas Multiagente (ICMAS), páginas 299-306, 1996. [23] M. A. Satterthwaite. In Spanish, the translation would be: \"Inmutabilidad estratégica y condiciones de Arrow: teoremas de existencia y correspondencia para procedimientos de votación y funciones de bienestar social.\" Revista de Teoría Económica, 10:187-217, 1975. [24] W. Vickrey. Contrarrestando la especulación, subastas y ofertas selladas competitivas. Revista de Finanzas, 16:8-37, 1961. [25] R. V. Vohra. Problemas de investigación en subastas combinatorias. Mimeo, versión 29 de octubre de 2001. 141 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "complementarity": {
            "translated_key": "complementariedad",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-interested Automated Mechanism Design and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently proposed approach-called automated mechanism design-a mechanism is computed for the preference aggregation setting at hand.",
                "This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike the earlier work on automated mechanism design that studied a benevolent designer, in this paper we study automated mechanism design problems where the designer is self-interested.",
                "In this case, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy.",
                "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy.",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc.",
                "The preference aggregator generally does not know the agents preferences a priori.",
                "Rather, the agents report their preferences to the coordinator.",
                "Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully.",
                "Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen.",
                "Manipulability is a pervasive problem across preference aggregation mechanisms.",
                "A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.)",
                "What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective.",
                "This is the classic setting of mechanism design in game theory.",
                "In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself.",
                "This is the mechanism design setting most relevant to electronic commerce.",
                "In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear.",
                "It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences.",
                "The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments.",
                "The most common such constraint is that of individual rationality (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
                "For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences.",
                "Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it.",
                "Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off.",
                "On the other hand, the designer will not necessarily choose a social welfare maximizing outcome.",
                "For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected.",
                "Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0.",
                "Classical mechanism design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective.",
                "The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]).",
                "However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare.",
                "If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization.",
                "In practice, the designer may also be interested in the outcome per se.",
                "For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical.",
                "For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed.",
                "Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments.",
                "In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand.",
                "This approach addresses all of the downsides listed above.",
                "We formulate the mechanism design problem as an optimization problem.",
                "The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types.",
                "The output is a nonmanipulable mechanism that is optimal with respect to some objective.",
                "This approach is called automated mechanism design.",
                "The automated mechanism design approach has four advantages over the classical approach of designing general mechanisms.",
                "First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare).",
                "Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences.",
                "When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally.",
                "Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types).",
                "Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information.",
                "For example, imagine a company automatically creating its procurement mechanism based on statistical knowledge about its suppliers, rather than using a classical descending procurement auction.",
                "Fourth, the burden of design is shifted from humans to a machine.",
                "However, automated mechanism design requires the mechanism design optimization problem to be solved anew for each setting.",
                "Hence its computational complexity becomes a key issue.",
                "Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6].",
                "In this paper we study the computational complexity of automated mechanism design in the case of a self-interested designer.",
                "This is an important setting for automated mechanism design due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested.",
                "We also show that this problem is closely related to a particular optimal (revenue-maximizing) combinatorial auction design problem. 133 The rest of this paper is organized as follows.",
                "In Section 2, we justify the focus on nonmanipulable mechanisms.",
                "In Section 3, we define the problem we study.",
                "In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it.",
                "In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen.",
                "In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case.",
                "Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2.",
                "JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of automated mechanism design, we should justify our focus on nonmanipulable mechanisms.",
                "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any nonmanipulable mechanism.",
                "This does, however, turn out to be the case: given any mechanism, we can construct a nonmanipulable mechanism whose performance is identical, as follows.",
                "We build an interface layer between the agents and the original mechanism.",
                "The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer.",
                "The resulting outcome is the outcome of the new mechanism.",
                "Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism.",
                "This argument is known in the mechanism design literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22].",
                "However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.)",
                "Given this, we can focus on truthful mechanisms in the rest of the paper. 3.",
                "DEFINITIONS We now formalize the automated mechanism design setting.",
                "Definition 1.",
                "In an automated mechanism design setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize.",
                "There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent).",
                "In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness.",
                "However, in this paper, we focus on the case of a self-interested designer.",
                "A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer.",
                "Definition 2.",
                "A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i.",
                "In the case where g = 0 everywhere, the designer is said to be payment maximizing.",
                "In the case where payments are not possible, g constitutes the objective function by itself.",
                "We now define the kinds of mechanisms under study.",
                "By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them.",
                "Definition 3.",
                "We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing.",
                "The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator.",
                "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 Individual rationality (IR) constraints The first type of constraint is the following.",
                "The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism.",
                "Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.)",
                "This type of constraint is called an IR (individual rationality) constraint.",
                "There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism.",
                "Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type).",
                "We will not study this concept in this paper.",
                "Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others.",
                "Ex post IR means that the agent would always participate even if it knew everybodys type.",
                "We will define the latter two notions of IR formally.",
                "First, we need to formalize the concept of the fallback outcome.",
                "We assume that each agents fallback utility is zero for each one of its types.",
                "This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16].",
                "Definition 4.",
                "In any automated mechanism design setting with an IR constraint, there is a fallback outcome o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)",
                "We can now to define the notions of individual rationality.",
                "Definition 5.",
                "Individual rationality (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
                "A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments.",
                "A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
                "The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle).",
                "For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium.",
                "Definition 6.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known.",
                "Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
                "In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible.",
                "Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report.",
                "If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium.",
                "Definition 7.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth.",
                "Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible. 135 3.3 Automated mechanism design We can now define the computational problem we study.",
                "Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an automated mechanism design setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective.",
                "An interesting special case is the setting where there is only one agent.",
                "In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents.",
                "Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here.",
                "Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here.",
                "This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4.",
                "PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "To demonstrate NPhardness, we reduce from the MINSAT problem.",
                "Definition 9 (MINSAT).",
                "We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|).",
                "We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied.",
                "MINSAT was recently shown to be NP-complete [14].",
                "We can now present our result.",
                "Theorem 1.",
                "Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent payment-maximizing deterministic AMD instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|.",
                "For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the MINSAT solution, and π(θc) = |Θ| if c is satisfied.",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent.",
                "Clearly the agent is better off reporting truthfully, for a total utility of 0.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type.",
                "Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the IR constraint, the maximum payment we can extract from any type θv is |Θ|.",
                "Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.)",
                "Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1.",
                "It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible.",
                "However, it does not yet imply hardness for the special case where payments are not possible.",
                "We will prove hardness in this case in the next section. 5.",
                "SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "Theorem 2.",
                "Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent self-interested deterministic AMD without payments instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1.",
                "Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v).",
                "For every c ∈ C that is satisfied in the MINSAT solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ .",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "The only other outcome that the mechanism is allowed to choose under the IR constraint is o0.",
                "This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}.",
                "We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|.",
                "For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).)",
                "Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes.",
                "It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Both of our hardness results relied on the constraint that the mechanism should be deterministic.",
                "In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6.",
                "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of self-interested AMD tractable through linear programming, for any constant number of agents.",
                "Theorem 3.",
                "Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated.",
                "Proof.",
                "Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}.",
                "The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.)",
                "First, we show the IR constraints.",
                "For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
                "For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
                "Now, we show the solution concept constraints.",
                "For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
                "Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
                "All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
                "As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents.",
                "Thus the problem is solvable in polynomial time. 7.",
                "IMPLICATIONS FOR AN OPTIMAL COMBINATORIAL AUCTION DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated mechanism design for a self-interested designer on designing optimal combinatorial auctions.",
                "Consider a combinatorial auction with a set S of items for sale.",
                "For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi.",
                "The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.)",
                "The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18].",
                "However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25].",
                "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of <br>complementarity</br> and no substitutability has been solved recently [1].)",
                "Suppose we have free disposal-items can be thrown away at no cost.",
                "Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.)",
                "Definition 10.",
                "Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
                "We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item.",
                "The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type.",
                "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the payment maximizing AMD problem!",
                "Theorem 4.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types.",
                "Proof.",
                "The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming.",
                "To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal combinatorial auction design problem instance with a single bidder with best-only preferences.",
                "For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance).",
                "Let the expected revenue target value be the same in both instances.",
                "We show the instances are equivalent.",
                "First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function.",
                "Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.)",
                "Let the payment functions be the same in both instances.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same.",
                "It follows that there exists a solution to the optimal auction design instance.",
                "Now suppose there exists a solution to the optimal auction design instance.",
                "By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item.",
                "Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type.",
                "If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type.",
                "Let the payment functions be the same.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same.",
                "It follows that there exists a solution to the AMD instance.",
                "Fortunately, we can also carry through the easiness result for randomized mechanisms to this combinatorial auction setting-giving us one of the few known polynomial-time algorithms for an optimal combinatorial auction design problem.",
                "Theorem 5.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.)",
                "Proof.",
                "By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item.",
                "There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations.",
                "Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8.",
                "RELATED RESEARCH ON COMPLEXITY IN MECHANISM DESIGN There has been considerable recent interest in mechanism design in computer science.",
                "Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism.",
                "The closest piece of earlier work studied the complexity of automated mechanism design by a benevolent designer [5, 6].",
                "Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21].",
                "This is related to mechanism design, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments).",
                "Also, there is no explicit reporting of preferences. 9.",
                "CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently emerging approach-called automated mechanism design-a mechanism is computed for the specific preference aggregation setting at hand.",
                "This has several advantages, 139 but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike earlier work on automated mechanism design that studied a benevolent designer, in this paper we studied automated mechanism design problems where the designer is self-interesteda setting much more relevant for electronic commerce.",
                "In this setting, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "These hardness results imply hardness in all more general automated mechanism design settings with a self-interested designer.",
                "The hardness results apply whether the individual rationality (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation.",
                "We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy.",
                "Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy.",
                "Future research includes studying automated mechanism design with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments).",
                "We also want to study the complexity of automated mechanism design in settings where the outcome and type spaces have special structure so they can be represented more concisely.",
                "Finally, we plan to assemble a data set of real-world mechanism design problems-both historical and current-and apply automated mechanism design to those problems. 10.",
                "REFERENCES [1] M. Armstrong.",
                "Optimal multi-object auctions.",
                "Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow.",
                "The property rights doctrine and demand revelation under incomplete information.",
                "In M. Boskin, editor, Economics and human welfare.",
                "New York Academic Press, 1979. [3] C. Avery and T. Hendershott.",
                "Bundling and optimal auctions of multiple products.",
                "Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke.",
                "Multipart pricing of public goods.",
                "Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Automated mechanism design: Complexity results stemming from the single-agent setting.",
                "In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm.",
                "Computational criticisms of the revelation principle.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004.",
                "Short paper.",
                "Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet.",
                "Incentives and incomplete information.",
                "Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker.",
                "Sharing the cost of muliticast transmissions.",
                "Journal of Computer and System Sciences, 63:21-41, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard.",
                "Manipulation of voting schemes.",
                "Econometrica, 41:587-602, 1973. [11] T. Groves.",
                "Incentives in teams.",
                "Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri.",
                "Vickrey prices and shortest paths: What is an edge worth?",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan.",
                "A polynomial algorithm in linear programming.",
                "Soviet Math.",
                "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani.",
                "The minimum satisfiability problem.",
                "SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham.",
                "Truth revelation in rapid, approximately efficient combinatorial auctions.",
                "Journal of the ACM, 49(5):577-602, 2002.",
                "Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [17] E. S. Maskin and J. Riley.",
                "Optimal multi-unit auctions.",
                "In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335.",
                "Clarendon Press, Oxford, 1989. [18] R. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen.",
                "Computationally feasible VCG mechanisms.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behavior, 35:166-196, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden.",
                "Designing networks for selfish users is hard.",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm.",
                "Issues in computational Vickrey auctions.",
                "International Journal of Electronic Commerce, 4(3):107-129, 2000.",
                "Special Issue on 140 Applying Intelligent Agents for Electronic Commerce.",
                "A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite.",
                "Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions.",
                "Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey.",
                "Counterspeculation, auctions, and competitive sealed tenders.",
                "Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra.",
                "Research problems in combinatorial auctions.",
                "Mimeo, version Oct. 29, 2001. 141"
            ],
            "original_annotated_samples": [
                "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of <br>complementarity</br> and no substitutability has been solved recently [1].)"
            ],
            "translated_annotated_samples": [
                "El problema está abierto incluso si solo hay dos artículos en venta. (El caso de dos artículos con una forma muy especial de <br>complementariedad</br> y sin sustituibilidad ha sido resuelto recientemente [1].)"
            ],
            "translated_text": "Diseño de mecanismos automatizados de interés propio e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les resulte más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente propuesto, llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración de agregación de preferencias actual. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre el diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo. En este caso, al centro solo le importa qué resultado se elige y qué pagos se le hacen. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este contexto, demostramos que el diseño de mecanismos deterministas óptimos es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Luego mostramos cómo permitir la aleatorización en el mecanismo hace que los problemas en este entorno sean computacionalmente fáciles. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (maximizadora de ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar una subasta determinista óptima es NP-completo, pero diseñar una subasta aleatoria óptima es fácil. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Teoría 1. En entornos multiagentes, a menudo se debe elegir un resultado en función de las preferencias informadas por un grupo de agentes. Tales resultados podrían ser presidentes potenciales, planes conjuntos, asignaciones de bienes o recursos, etc. El agregador de preferencias generalmente no conoce las preferencias de los agentes de antemano. Más bien, los agentes informan sus preferencias al coordinador. Desafortunadamente, un agente puede tener un incentivo para informar incorrectamente sus preferencias con el fin de engañar al mecanismo y lograr que seleccione un resultado que sea más deseable para el agente que el resultado que se seleccionaría si el agente revelara sus preferencias de manera honesta. Tal manipulación es indeseable porque los mecanismos de agregación de preferencias están diseñados para agrupar las preferencias de una manera socialmente deseable, y si los agentes revelan sus preferencias de manera insincera, se podría elegir un resultado socialmente indeseable. La manipulabilidad es un problema generalizado en los mecanismos de agregación de preferencias. Un resultado negativo seminal, el teorema de Gibbard-Satterthwaite, muestra que bajo cualquier esquema de agregación de preferencias no dictatorial, si hay al menos 3 posibles resultados, existen preferencias bajo las cuales un agente está mejor reportando falsamente [10, 23]. (Un esquema de agregación de preferencias se llama dictatorial si uno de los agentes dicta el resultado sin importar las preferencias que reporten los otros agentes). Lo que le gustaría hacer al agregador es diseñar un mecanismo de agregación de preferencias para que 1) los agentes interesados reporten sus preferencias de manera veraz, y 2) el mecanismo elija un resultado que sea deseable desde la perspectiva de algún objetivo. Esta es la configuración clásica del diseño de mecanismos en la teoría de juegos. En este documento, estudiamos el caso en el que el diseñador actúa por interés propio, es decir, al diseñador no le importa directamente cómo se relaciona el resultado con las preferencias de los agentes, sino que está más preocupado por su propia agenda sobre cuál resultado debería ser elegido y en maximizar los pagos para sí mismo. Este es el entorno de diseño de mecanismos más relevante para el comercio electrónico. En el caso en que el diseñador del mecanismo esté interesado en maximizar alguna noción de bienestar social, la importancia de recopilar las preferencias de los agentes es clara. Quizás sea menos obvio por qué deberían ser recopilados cuando el diseñador está interesado en sí mismo y, por lo tanto, su objetivo no está directamente relacionado con las preferencias de los agentes. La razón de esto es que a menudo las preferencias de los agentes imponen límites en cómo el diseñador elige el resultado y los pagos. La restricción más común de este tipo es la de racionalidad individual (RI), lo que significa que el mecanismo no puede dejar a ningún agente en una situación peor a la que hubiera estado si no hubiera participado en el mecanismo. Por ejemplo, en el contexto del diseño óptimo de subastas, el diseñador (subastador) solo se preocupa por cuántos ingresos se recaudan, y no en sí mismo por cuán bien la asignación del bien (o bienes) corresponde a las preferencias de los agentes. Sin embargo, el diseñador no puede obligar a un agente a pagar más de lo que valora el paquete de bienes asignado a él. Por lo tanto, incluso un diseñador interesado en sí mismo elegirá un resultado que beneficie razonablemente a los agentes. Por otro lado, el diseñador no necesariamente elegirá un resultado que maximice el bienestar social. Por ejemplo, si el diseñador siempre elige un resultado que maximiza el bienestar social con respecto a las preferencias informadas, y obliga a cada agente a pagar la diferencia entre la utilidad que tiene ahora y la utilidad que habría tenido si no hubiera participado en el mecanismo, es fácil ver que los agentes pueden tener un incentivo para informar incorrectamente sus preferencias, lo que puede llevar realmente a recaudar menos ingresos. De hecho, uno de los resultados contraintuitivos de la teoría del diseño de subastas óptimas es que a veces el bien se asigna a nadie incluso cuando el subastador tiene un precio de reserva de 0. El diseño de mecanismos clásicos proporciona algunos mecanismos generales, que, bajo ciertas suposiciones, satisfacen alguna noción de no manipulabilidad y maximizan algún objetivo. La ventaja de estos mecanismos es que no dependen de información (incluso probabilística) sobre las preferencias de los agentes (por ejemplo, el mecanismo de Vickrey-Clarke-Groves (VCG) [24, 4, 11]), o pueden aplicarse fácilmente a cualquier distribución de probabilidad sobre las preferencias (por ejemplo, el mecanismo dAGVA [8, 2], la subasta de Myerson [18], y la subasta multiunidad de Maskin-Riley [17]). Sin embargo, los mecanismos generales también tienen importantes desventajas: • Los mecanismos generales más famosos y ampliamente aplicables, VCG y dAGVA, solo maximizan el bienestar social. Si el diseñador está interesado en sí mismo, como es el caso en muchos entornos de comercio electrónico, estos mecanismos no maximizan el objetivo del diseñador. • Los mecanismos generales que se centran en un diseñador interesado en sí mismo solo son aplicables en entornos muy restringidos, como la subasta de maximización de ingresos esperados de Myerson para vender un solo artículo, y la subasta de maximización de ingresos esperados de Maskin y Riley para vender múltiples unidades idénticas de un artículo. • Incluso en los entornos restringidos en los que se aplican estos mecanismos, solo permiten la maximización de pagos. En la práctica, el diseñador también puede estar interesado en el resultado en sí mismo. Por ejemplo, a un subastador le puede importar qué postor recibe el artículo. • A menudo se asume que los pagos laterales pueden ser utilizados para adaptar los incentivos de los agentes, pero esto no siempre es práctico. Por ejemplo, en los mercados electrónicos basados en trueque, como Recipco, firstbarter.com, BarterOne e Intagio, no se permiten los pagos laterales. Además, entre los agentes de software, podría ser más deseable construir mecanismos que no dependan de la capacidad de realizar pagos, ya que muchos agentes de software no cuentan con la infraestructura para hacer pagos. Por el contrario, seguimos un enfoque reciente donde el mecanismo se diseña automáticamente para el problema específico en cuestión. Este enfoque aborda todos los inconvenientes mencionados anteriormente. Formulamos el problema de diseño de mecanismos como un problema de optimización. La entrada se caracteriza por el número de agentes, los posibles tipos de agentes (preferencias) y las distribuciones previas de los agregadores sobre los tipos de agentes. La salida es un mecanismo no manipulable que es óptimo con respecto a algún objetivo. Este enfoque se llama diseño de mecanismos automatizado. El enfoque de diseño de mecanismos automatizado tiene cuatro ventajas sobre el enfoque clásico de diseñar mecanismos generales. Primero, se puede utilizar incluso en entornos que no cumplen con las suposiciones de los mecanismos clásicos (como la disponibilidad de pagos laterales o que el objetivo sea el bienestar social). Segundo, puede permitir a uno eludir resultados de imposibilidad (como el teorema de Gibbard-Satterthwaite) que establecen que no existe un mecanismo que sea deseable para todas las preferencias. Cuando el mecanismo está diseñado para la configuración actual, no importa que no funcione de manera más general. Tercero, puede generar mecanismos mejores (en términos de garantías de no manipulabilidad más sólidas y/o mejores resultados) que los mecanismos clásicos porque el mecanismo aprovecha las particularidades del entorno (la información probabilística que el diseñador tiene sobre los tipos de agentes). Dada la gran cantidad de información que las partes tienen entre sí hoy en día, es probable que este enfoque conduzca a ahorros enormes en comparación con los mecanismos clásicos, que en su mayoría ignoran esa información. Por ejemplo, imagina una empresa creando automáticamente su mecanismo de adquisiciones basado en el conocimiento estadístico sobre sus proveedores, en lugar de utilizar una subasta de adquisiciones descendente clásica. Cuarto, la carga del diseño se traslada de los humanos a una máquina. Sin embargo, el diseño automatizado de mecanismos requiere que el problema de optimización del diseño del mecanismo se resuelva de nuevo para cada configuración. Por lo tanto, su complejidad computacional se convierte en un tema clave. Investigaciones previas han estudiado esta pregunta para diseñadores benevolentes que desean maximizar, por ejemplo, el bienestar social [5, 6]. En este artículo estudiamos la complejidad computacional del diseño automatizado de mecanismos en el caso de un diseñador con interés propio. Esta es una configuración importante para el diseño de mecanismos automatizados debido a la escasez de mecanismos generales en esta área, y al hecho de que en la mayoría de las configuraciones de comercio electrónico el diseñador actúa en su propio interés. También demostramos que este problema está estrechamente relacionado con un problema de diseño de subasta combinatoria óptima (maximización de ingresos) particular. El resto de este documento está organizado de la siguiente manera. En la Sección 2, justificamos el enfoque en mecanismos no manipulables. En la Sección 3, definimos el problema que estudiamos. En la Sección 4, demostramos que diseñar un mecanismo determinista óptimo es NP-completo incluso cuando al diseñador solo le importan los pagos que recibe. En la Sección 5, demostramos que diseñar un mecanismo determinista óptimo también es NP-completo cuando los pagos no son posibles y el diseñador solo está interesado en el resultado elegido. En la Sección 6, demostramos que un mecanismo óptimo aleatorizado puede ser diseñado en tiempo polinómico incluso en el caso general. Finalmente, en la Sección 7, demostramos que para diseñar subastas combinatorias óptimas bajo preferencias de mejor opción solamente, nuestros resultados sobre AMD implican que este problema es NP-completo para subastas determinísticas, pero sencillo para subastas aleatorias. 2. JUSTIFICANDO EL ENFOQUE EN MECANISMOS NO MANIPULABLES Antes de definir el problema computacional del diseño automatizado de mecanismos, debemos justificar nuestro enfoque en mecanismos no manipulables. Después de todo, no es inmediatamente obvio que no haya mecanismos manipulables que, incluso cuando los agentes informan estratégicamente sus tipos y, por lo tanto, a veces de manera no veraz, aún logren mejores resultados (según el objetivo que usemos) que cualquier mecanismo no manipulable. Sin embargo, resulta ser el caso que, dado cualquier mecanismo, podemos construir un mecanismo no manipulable cuyo rendimiento es idéntico, de la siguiente manera. Construimos una capa de interfaz entre los agentes y el mecanismo original. Los agentes informan sus preferencias (o tipos) a la capa de interfaz; posteriormente, la capa de interfaz introduce en el mecanismo original los tipos que los agentes habrían informado estratégicamente al mecanismo original, si sus tipos fueran los declarados a la capa de interfaz. El resultado resultante es el resultado del nuevo mecanismo. Dado que la capa de interfaz actúa estratégicamente en nombre de cada agente, nunca hay un incentivo para informar falsamente a la capa de interfaz; por lo tanto, los tipos informados por la capa de interfaz son los tipos estratégicos que se habrían informado sin la capa de interfaz, por lo que los resultados son exactamente como habrían sido con el mecanismo original. Este argumento es conocido en la literatura de diseño de mecanismos como el principio de revelación [16]. (Existen dificultades computacionales al aplicar el principio de revelación en espacios de resultados y tipos combinatorios grandes [7, 22]). Sin embargo, dado que aquí nos enfocamos en espacios de resultados y tipos representados de forma plana, esto no es una preocupación aquí. Dado esto, podemos centrarnos en mecanismos veraces en el resto del documento. 3. DEFINICIONES Ahora formalizamos el entorno del diseño automatizado de mecanismos. Definición 1. En un entorno de diseño de mecanismos automatizados, se nos proporciona: • un conjunto finito de resultados O; • un conjunto finito de N agentes; • para cada agente i, 1. un conjunto finito de tipos Θi, 2. una distribución de probabilidad γi sobre Θi (en el caso de tipos correlacionados, hay una única distribución conjunta γ sobre Θ1 × . . . × ΘN), y 3. una función de utilidad ui: Θi × O → R; 1 • Una función objetivo cuya expectativa el diseñador desea maximizar. Existen muchas posibles funciones objetivo que el diseñador podría tener, por ejemplo, el bienestar social (donde el diseñador busca maximizar la suma de las utilidades de los agentes), o la utilidad mínima de cualquier agente (donde el diseñador busca maximizar la peor utilidad experimentada por cualquier agente). En ambos casos, el diseñador es benevolente, ya que, de alguna manera, el diseñador está buscando la felicidad colectiva de los agentes. Sin embargo, en este documento nos enfocamos en el caso de un diseñador interesado en sí mismo. Un diseñador egoísta solo se preocupa por el resultado elegido (es decir, al diseñador no le importa cómo se relaciona el resultado con las preferencias de los agentes, sino que tiene una preferencia fija sobre los resultados) y sobre los pagos netos realizados por los agentes, que fluyen hacia el diseñador. Definición 2. Un diseñador interesado tiene una función objetivo dada por g(o) + Σ i=1 πi, donde g : O → R indica las preferencias del diseñador sobre los resultados, y πi es el pago realizado por el agente i. En el caso en que g = 0 en todas partes, se dice que el diseñador está maximizando el pago. En el caso en que los pagos no sean posibles, g constituye la función objetivo por sí sola. Ahora definimos los tipos de mecanismos en estudio. Por el principio de revelación, podemos restringir la atención a mecanismos de revelación directa y veraz, donde los agentes informan directamente sus tipos y nunca tienen incentivos para informarlos de manera incorrecta. Definición 3. Consideramos los siguientes tipos de mecanismos: • Un mecanismo determinista sin pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O. • Un mecanismo aleatorio sin pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), donde P(O) es el conjunto de distribuciones de probabilidad sobre O. • Un mecanismo determinista con pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O y, para cada agente i, una función de selección de pagos πi: Θ1 × Θ2 × . . . × ΘN → R, donde πi(θ1, . . . , θN ) da el pago realizado por el agente i cuando los tipos reportados son θ1, . . . , θN. Aunque esto sigue la notación estándar de la teoría de juegos [16], el hecho de que el agente tenga tanto una función de utilidad como un tipo puede resultar confuso. Los tipos codifican las diversas preferencias posibles que el agente pueda tener, y el tipo de los agentes no es conocido por el agregador. La función de utilidad es un conocimiento común, pero debido a que el tipo de agente es un parámetro en la función de utilidad de los agentes, el agregador no puede saber cuál es la utilidad de los agentes sin conocer el tipo de agente. Un mecanismo aleatorio con pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), y para cada agente i, una función de selección de pago πi: Θ1 × Θ2 × . . . × ΘN → R. Hay dos tipos de restricciones para el diseñador al construir el mecanismo. 3.1 Restricciones de racionalidad individual (IR) El primer tipo de restricción es el siguiente. La utilidad de cada agente debe ser al menos tan grande como la utilidad de respaldo de los agentes, es decir, la utilidad que el agente recibiría si no participara en el mecanismo. De lo contrario, ese agente no participaría en el mecanismo, y la participación de ningún agente puede perjudicar el objetivo de los diseñadores del mecanismo, ya que en el peor de los casos, el mecanismo puede ignorar a un agente fingiendo que el agente no está presente. (Además, si no se aplicara tal restricción, el diseñador simplemente podría hacer que los agentes paguen una cantidad infinita). Este tipo de restricción se llama restricción de IR (racionalidad individual). Existen tres posibles restricciones de IR diferentes: ex ante, ex interim y ex post, dependiendo de lo que el agente sabe sobre su propio tipo y los tipos de los demás al decidir si participar en el mecanismo. Ex ante IR significa que el agente participaría si no supiera absolutamente nada (ni siquiera su propio tipo). No estudiaremos este concepto en este documento. Ex interim IR significa que el agente siempre participaría si conociera solo su propio tipo, pero no el de los demás. Ex post IR significa que el agente siempre participaría incluso si conociera el tipo de todos. Definiremos formalmente las dos últimas nociones de IR. Primero, necesitamos formalizar el concepto del resultado de respaldo. Suponemos que la utilidad de respaldo de cada agente es cero para cada uno de sus tipos. Esto se hace sin pérdida de generalidad porque podemos agregar un término constante a la función de utilidad de un agente (para un tipo dado), sin afectar el comportamiento de toma de decisiones de ese agente maximizador de utilidad esperada [16]. Definición 4. En cualquier entorno de diseño de mecanismos automatizados con una restricción de IR, existe un resultado de contingencia o0 ∈ O donde, para cualquier agente i y cualquier tipo θi ∈ Θi, tenemos ui(θi, o0) = 0. (Además, en el caso de un diseñador egoísta, g(o0) = 0). Ahora podemos definir las nociones de racionalidad individual. Definición 5. La racionalidad individual (RI) se define como: • Un mecanismo determinista es ex interim RI si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0. Un mecanismo aleatorio es ex interim IR si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • Un mecanismo determinista es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 No aleatorizamos sobre los pagos porque mientras los agentes y el diseñador sean neutrales al riesgo con respecto a los pagos, es decir, su utilidad es lineal en los pagos, no hay razón para aleatorizar sobre los pagos. Un mecanismo aleatorio es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 3.2 Restricciones de compatibilidad de incentivos (IC) El segundo tipo de restricción establece que los agentes nunca deben tener un incentivo para informar incorrectamente su tipo (como se justificó anteriormente mediante el principio de revelación). Para este tipo de restricción, las dos variantes más comunes (o conceptos de solución) son la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash. Definición 6. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en estrategias dominantes si decir la verdad siempre es óptimo incluso cuando los tipos reportados por los otros agentes ya son conocidos. Formalmente, para cualquier agente i, cualquier vector de tipos (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ). En el caso de mecanismos aleatorios tenemos Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. Por lo tanto, en la implementación de estrategias dominantes, decir la verdad es óptimo independientemente de lo que informen los otros agentes. Si es óptimo solo dado que los otros agentes son veraces, y dado que uno no conoce los tipos de los otros agentes, tenemos implementación en equilibrio de Bayes-Nash. Definición 7. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en equilibrio de Bayes-Nash si decir la verdad siempre es óptimo para un agente cuando ese agente aún no sabe nada sobre los tipos de los otros agentes, y los otros agentes están diciendo la verdad. Formalmente, para cualquier agente i, cualquier tipo θi ∈ Θi, y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )]. En el caso de mecanismos aleatorios tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 135 3.3 Diseño de mecanismos automatizados Ahora podemos definir el problema computacional que estudiamos. Definición 8. (DISEÑO DE MECANISMOS AUTOMATIZADOS (AMD)) Se nos da: • un entorno de diseño de mecanismos automatizados, • una noción de IR (ex interim, ex post, o ninguna), • un concepto de solución (estrategias dominantes o Bayes-Nash), • si los pagos son posibles, • si la aleatorización es posible, • (en la variante de decisión del problema) un valor objetivo G. Se nos pregunta si existe un mecanismo del tipo especificado (en términos de pagos y aleatorización) que satisfaga tanto la noción de IR como el concepto de solución, y proporcione un valor esperado de al menos G para el objetivo. Un caso especial interesante es aquel en el que solo hay un agente. En este caso, el agente informante siempre sabe todo lo que hay que saber sobre los otros tipos de agentes, porque no hay otros agentes. Dado que el IR ex post y el IR ex interim solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de IR coinciden aquí. Además, dado que la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de solución coinciden aquí. Esta observación resultará ser una herramienta útil para demostrar resultados de dificultad: si demostramos dificultad computacional en el escenario de un solo agente, esto implica inmediatamente dificultad para ambos conceptos de IR, para ambos conceptos de solución, para cualquier número de agentes. 4. En esta sección demostramos que es NP-completo diseñar un mecanismo determinístico que maximice la suma esperada de los pagos recolectados de los agentes. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Para demostrar la NP-dureza, reducimos desde el problema MINSAT. Definición 9 (MINSAT). Se nos da una fórmula φ en forma normal conjuntiva, representada por un conjunto de variables booleanas V y un conjunto de cláusulas C, y un entero K (K < |C|). Se nos pregunta si existe una asignación a las variables en V tal que se satisfacen a lo sumo K cláusulas en φ. MINSAT fue recientemente demostrado como NP-completo [14]. Ahora podemos presentar nuestro resultado. Teorema 1. El problema determinista de maximización de pagos de AMD es NP-completo, incluso para un solo agente, incluso con una distribución uniforme de tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista de maximización de pagos de un solo agente. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V } ∪ {−v : v ∈ V }. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Sea l ∈ c denota que el literal l ocurre en la cláusula c. Entonces, la función de utilidad de los agentes está dada por u(θc, ol) = |Θ| + 1 para todo l ∈ L con l ∈ c; u(θc, ol) = 0 para todo l ∈ L con l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc) = 0 para todo c ∈ C con c = c; u(θv, ol) = |Θ| para todo l ∈ L con v(l) = v; u(θv, ol) = 0 para todo l ∈ L con v(l) = v; u(θv, oc) = 0 para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ|, donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v) y π(θv) = |Θ|. Para cada c ∈ C, sea o(θc) = oc; sea π(θc) = |Θ| + 1 si c no está satisfecha en la solución MINSAT, y π(θc) = |Θ| si c está satisfecha. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es θv, entonces cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivo para informar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Porque además, ningún tipo que no sea θc conduce al resultado oc, informar cualquier otro tipo dará como resultado una utilidad de 0, mientras que aún se requiere un pago de al menos |Θ| por parte del agente. Claramente, el agente está mejor reportando honestamente, para una utilidad total de 0. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), el pago esperado de este mecanismo es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o y una función de pago π. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. Entonces, la utilidad que el agente obtiene del resultado dado para este tipo es 0, y por lo tanto, según la IR, no se puede extraer ningún pago del agente para este tipo. Dado que, nuevamente por IR, el pago máximo que se puede extraer para cualquier otro tipo es |Θ| + 1, se sigue que el pago esperado máximo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo cual contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o−v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por la restricción de IR, el pago máximo que podemos extraer de cualquier tipo θv es |Θ|. Dado que no puede haber incentivos para que el agente informe falsamente, para cualquier cláusula c satisfecha por la asignación dada, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ|. (Pues si extrajéramos más de este tipo, la utilidad del agente en este caso sería menor que 1; y si v es la variable que satisface c en la asignación, de modo que o(θv) = ol donde l ocurre en c, entonces al agente le convendría más informar θv en lugar del informe veraz θc, para obtener un resultado que valga |Θ|+1 para él mientras tiene que pagar como máximo |Θ|.) Finalmente, para cualquier cláusula insatisfecha c, según la restricción de IR, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ| + 1. Se deduce que el pago esperado de nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia de MINSAT. Dado que AMD, que maximiza el pago, es solo un caso especial de AMD para un diseñador egoísta en el que el diseñador no tiene preferencias sobre el resultado elegido, esto implica inmediatamente dificultades para el caso general de AMD para un diseñador egoísta en el que los pagos son posibles. Sin embargo, esto aún no implica dureza para el caso especial donde los pagos no son posibles. Demostraremos la dificultad en este caso en la próxima sección. 5. En esta sección demostramos que es NP-completo diseñar un mecanismo determinista que maximice la expectativa del objetivo del diseñador cuando no son posibles los pagos. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Teorema 2. Sin pagos, el diseño determinista de AMD para un diseñador egoísta es NP-completo, incluso para un solo agente, incluso con una distribución uniforme sobre los tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista auto-interesada de un solo agente sin pagos. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L} ∪ {o∗}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V} ∪ {−v : v ∈ V}. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Deje que l ∈ c denote que el literal l ocurre en la cláusula c. Luego, deje que la función de utilidad de los agentes esté dada por u(θc, ol) = 2 para todo l ∈ L con l ∈ c; u(θc, ol) = −1 para todo l ∈ L con l /∈ c; u(θc, oc) = 2; u(θc, oc) = −1 para todo c ∈ C con c = c; u(θc, o∗) = 1; u(θv, ol) = 1 para todo l ∈ L con v(l) = v; u(θv, ol) = −1 para todo l ∈ L con v(l) = v; u(θv, oc) = −1 para todo c ∈ C; u(θv, o∗) = −1. Que la función objetivo de los diseñadores esté dada por g(o∗ ) = |Θ|+1; g(ol) = |Θ| para todo l ∈ L; g(oc) = |Θ| para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ| , donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v). Para cada c ∈ C que se cumpla en la solución MINSAT, sea o(θc) = oc; para cada c ∈ C no satisfecho, sea o(θc) = o∗. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es algún θv, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para reportar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Debido a que tampoco ningún tipo conduce al resultado oc, no hay ningún resultado que el mecanismo seleccione que le daría al agente una utilidad mayor a 1 para el tipo θc, y por lo tanto el agente no tiene incentivo para informar falsamente. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), entonces el valor esperado de la función objetivo de los diseñadores es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. El único otro resultado que el mecanismo puede elegir bajo la restricción de IR es o0. Esto tiene un valor objetivo de 0, y dado que el valor más alto que la función objetivo alcanza es |Θ| + 1, se sigue que el valor esperado máximo de la función objetivo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo que contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o-v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por lo anterior, para cualquier tipo θv, el valor de la función objetivo en este mecanismo será |Θ|. Para cualquier cláusula c satisfecha por la asignación dada, el valor de la función objetivo en el caso en que el agente informe el tipo θc será como máximo |Θ|. (Esto se debe a que no podemos elegir el resultado o∗ para dicho tipo, ya que en este caso el agente tendría un incentivo para informar θv en su lugar, donde v es la variable que satisface c en la asignación (de modo que o(θv) = ol donde l ocurre en c).) Finalmente, para cualquier cláusula insatisfecha c, el valor máximo que la función objetivo puede alcanzar en el caso en que el agente informa el tipo θc es |Θ| + 1, simplemente porque este es el valor más grande que la función alcanza en cualquier momento. Se deduce que el valor esperado de la función objetivo para nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas 137 satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia MINSAT. Ambos de nuestros resultados de dureza se basaron en la restricción de que el mecanismo debería ser determinista. En la siguiente sección, mostramos que la dificultad del diseño desaparece cuando permitimos la aleatorización en el mecanismo. 6. La aleatorización de AMD para un diseñador interesado en sí mismo es fácil. Ahora mostramos cómo permitir la aleatorización sobre los resultados hace que el problema de AMD auto-interesado sea manejable a través de la programación lineal, para cualquier número constante de agentes. Teorema 3. El AMD aleatorio con interés propio con un número constante de agentes es resoluble en tiempo polinómico mediante programación lineal, tanto con pagos como sin pagos, tanto para IR ex post como ex interim, y tanto para la implementación en estrategias dominantes como para la implementación en equilibrio de Bayes-Nash, incluso si los tipos están correlacionados. Prueba. Dado que los programas lineales pueden resolverse en tiempo polinómico [13], todo lo que necesitamos demostrar es que el número de variables y ecuaciones en nuestro programa es polinomial para cualquier número constante de agentes, es decir, exponencial solo en N. En todo momento, para determinar el tamaño del programa lineal, consideremos T = maxi{|Θi|}. Las variables de nuestro programa lineal serán las probabilidades (p(θ1, θ2, . . . , θN ))(o) (como máximo TN |O| variables) y los pagos πi(θ1, θ2, . . . , θN ) (como máximo NTN variables). (Mostramos el programa lineal para el caso en que los pagos son posibles; el caso sin pagos se obtiene fácilmente de esto simplemente omitiendo todas las variables de pago en el programa, o agregando restricciones adicionales que obliguen a los pagos a ser 0). Primero, mostramos las restricciones de IR. Para el IR ex post, agregamos las siguientes restricciones (como máximo NTN) al LP: • Para cada i ∈ {1, 2, . . . , N}, y para cada (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , agregamos ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0. Para el ex interino IR, agregamos las siguientes restricciones (como máximo NT) al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada θi ∈ Θi, agregamos θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0. Ahora, mostramos las restricciones del concepto de solución. Para la implementación en estrategias dominantes, agregamos las siguientes (a lo sumo NTN+1) restricciones al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ). Finalmente, para la implementación en el equilibrio de Bayes-Nash, agregamos las siguientes (a lo sumo NT2) restricciones al LP: • Para cada i ∈ {1, 2, ..., N}, para cada θi ∈ Θi, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )). Todo lo que queda por hacer es dar la expresión que el diseñador busca maximizar, que es: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )). Como indicamos, el número de variables y restricciones es exponencial solo en N, por lo tanto, el programa lineal tiene un tamaño polinómico para un número constante de agentes. Por lo tanto, el problema es resoluble en tiempo polinómico. IMPLICACIONES PARA UN PROBLEMA DE DISEÑO DE SUBASTA COMBINATORIA ÓPTIMA En esta sección, demostraremos algunas consecuencias interesantes del problema de diseño de mecanismos automatizados para un diseñador interesado en sí mismo en el diseño de subastas combinatorias óptimas. Considera una subasta combinatoria con un conjunto S de artículos en venta. Para cualquier conjunto B ⊆ S, dejemos que ui(θi, B) sea la utilidad del postor i al recibir el conjunto B cuando el tipo del postor es θi. El problema de diseño de subasta óptima consiste en especificar las reglas de la subasta de manera que se maximice los ingresos esperados para el subastador. (Por el principio de revelación, sin pérdida de generalidad, podemos asumir que la subasta es veraz). El problema de diseño de subasta óptima se resuelve para el caso de un solo artículo mediante la famosa subasta de Myerson [18]. Sin embargo, el diseño de subastas óptimas en subastas combinatorias es un problema de investigación abierto reconocido [3, 25]. El problema está abierto incluso si solo hay dos artículos en venta. (El caso de dos artículos con una forma muy especial de <br>complementariedad</br> y sin sustituibilidad ha sido resuelto recientemente [1].) Supongamos que tenemos disposición libre: los artículos pueden ser desechados sin costo alguno. Además, supongamos que las preferencias de los postores tienen la siguiente estructura: cuando un postor recibe un conjunto de artículos, la utilidad del postor por ese conjunto está determinada únicamente por el mejor artículo en el conjunto. (Enfatizamos que qué artículo es el mejor puede depender del tipo de postor). Definición 10. Se dice que el postor i tiene preferencias solo por lo mejor sobre paquetes de artículos si existe una función vi: Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s). Hacemos la siguiente observación útil en este contexto: no tiene sentido otorgarle a un postor más de un artículo. La razón es que si el postor está informando honestamente, quitarle todos los artículos menos el de mayor valor no perjudicará al postor; y, mediante la disposición gratuita, hacerlo solo reducirá el incentivo para que este postor informe falsamente este tipo, cuando en realidad tiene otro tipo. Ahora demostramos que el problema de diseñar una subasta óptima determinista es NP-completo, mediante una reducción del problema AMD de maximización de pagos. Teorema 4. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de artículos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), diseñar la subasta determinística óptima es NP-completo, incluso para un único postor con una distribución uniforme sobre los tipos. Prueba. El problema está en NP porque podemos generar de manera no determinista una regla de asignación, y luego establecer los pagos utilizando programación lineal. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de AMD determinista que maximiza el pago, con un único agente y una distribución uniforme de tipos, al siguiente problema de diseño de subasta combinatoria óptima con una única postor con preferencias de solo los mejores. Para cada resultado o ∈ O en la instancia de AMD (excepto el resultado o0), que haya un artículo so ∈ S. Que el espacio de tipos sea el mismo, y que v(θi, so) = ui(θi, o) (donde u está especificado en la instancia de AMD). Que el valor objetivo de ingresos esperados sea el mismo en ambas instancias. Mostramos que las instancias son equivalentes. Primero supongamos que existe una solución para la instancia de AMD, dada por una función de resultado y una función de pago. Entonces, si la solución de AMD elige el resultado o para un tipo, en la solución de subasta óptima, asignamos {so} al postor para este tipo. (A menos que o = o0, en cuyo caso asignamos {} al postor). Que las funciones de pago sean las mismas en ambas instancias. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo verdadero) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución óptima de la subasta. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el subastador/diseñador son los mismos. Se deduce que existe una solución para la instancia de diseño de subasta óptima. Ahora supongamos que existe una solución para la instancia de diseño de subasta óptima. Por la observación de que como máximo se puede tener un artículo, podemos asumir sin pérdida de generalidad que la solución nunca asigna más de un artículo. Entonces, si la solución de subasta óptima asigna el artículo al postor para un tipo, en la solución de AMD, permita que el mecanismo elija el resultado o para ese tipo. Si la solución de subasta óptima no asigna nada al postor para un tipo, en la solución AMD, permita que el mecanismo elija el resultado o0 para ese tipo. Que las funciones de pago sean las mismas. Entonces, la utilidad que recibe un agente por informar un tipo (dado el tipo real) en cualquiera de las soluciones es la misma, por lo que tenemos compatibilidad de incentivos en la solución AMD. Además, dado que la distribución del tipo y la función de pago son iguales, los ingresos esperados para el diseñador/subastador son los mismos. Se deduce que existe una solución para la instancia de AMD. Afortunadamente, también podemos extender el resultado de facilidad para mecanismos aleatorios a este escenario de subasta combinatoria, lo que nos proporciona uno de los pocos algoritmos de tiempo polinómico conocidos para un problema de diseño óptimo de subasta combinatoria. Teorema 5. Dado un problema de diseño de subasta combinatoria óptima bajo preferencias de mejor opción (dado por un conjunto de elementos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), si el número de postores es una constante k, entonces la subasta aleatoria óptima puede ser diseñada en tiempo polinómico. (Para cualquier restricción de IC e IR.) Prueba. Por la observación de que a lo sumo un artículo, podemos sin pérdida de generalidad restringirnos a asignaciones donde cada postor recibe como máximo un artículo. Hay menos de (|S| + 1)k asignaciones de ese tipo, es decir, un número polinómico de asignaciones. Dado que podemos enumerar explícitamente los resultados, simplemente podemos resolver esto como una instancia de AMD que maximiza el pago, con programación lineal. 8. Investigaciones relacionadas sobre la complejidad en el diseño de mecanismos. Ha habido un considerable interés reciente en el diseño de mecanismos en la informática. Parte de ello se ha centrado en cuestiones de complejidad computacional, pero la mayor parte de ese trabajo ha buscado diseñar mecanismos que sean fáciles de ejecutar (por ejemplo, [20, 15, 19, 9, 12]), en lugar de estudiar la complejidad de diseñar el mecanismo. La pieza más cercana de trabajo anterior estudió la complejidad del diseño automatizado de mecanismos por un diseñador benevolente [5, 6]. Roughgarden ha estudiado la complejidad de diseñar una buena topología de red para agentes que eligen egoístamente los enlaces que utilizan [21]. Esto está relacionado con el diseño de mecanismos, pero difiere significativamente en que el diseñador solo tiene un control restringido sobre las reglas del juego porque no hay ninguna parte que pueda imponer el resultado (o pagos laterales). Además, no hay un informe explícito de preferencias. 9. CONCLUSIONES E INVESTIGACIONES FUTURAS A menudo, un resultado debe ser elegido en función de las preferencias informadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les sea más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente emergente llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración específica de agregación de preferencias en cuestión. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo, un entorno mucho más relevante para el comercio electrónico. En este contexto, al centro solo le importa qué resultado se elige y qué pagos se le realizan. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este escenario, demostramos que diseñar un mecanismo determinista óptimo es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Estos resultados de dureza implican dificultad en todos los entornos de diseño de mecanismos automatizados más generales con un diseñador egoísta. Los resultados de dureza se aplican ya sea que las restricciones de racionalidad individual (participación) se apliquen ex interim o ex post, y ya sea que el concepto de solución sea la implementación de estrategias dominantes o la implementación del equilibrio de Bayes-Nash. Luego demostramos que permitir la aleatorización en el mecanismo hace que el problema de diseño en todos estos escenarios sea computacionalmente sencillo. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de subasta combinatoria óptima (que maximiza los ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar un mecanismo determinístico óptimo es NP-completo incluso con un agente, pero diseñar un mecanismo aleatorio óptimo es fácil. La investigación futura incluye estudiar el diseño automatizado de mecanismos con un diseñador interesado en sí mismo en entornos más restringidos, como subastas (donde el objetivo del diseñador puede incluir preferencias sobre qué postor debería recibir el bien, así como los pagos). También queremos estudiar la complejidad del diseño de mecanismos automatizados en entornos donde los espacios de resultados y tipos tienen una estructura especial para que puedan representarse de manera más concisa. Finalmente, planeamos reunir un conjunto de datos de problemas de diseño de mecanismos del mundo real, tanto históricos como actuales, y aplicar el diseño de mecanismos automatizado a esos problemas. 10. REFERENCIAS [1] M. Armstrong. Subastas multi-objetivo óptimas. Revisión de Estudios Económicos, 67:455-481, 2000. [2] K. Arrow. La doctrina de los derechos de propiedad y la revelación de la demanda bajo información incompleta. En M. Boskin, editor, Economía y bienestar humano. New York Academic Press, 1979. [3] C. Avery y T. Hendershott. Agrupación y subastas óptimas de múltiples productos. Revisión de Estudios Económicos, 67:483-497, 2000. [4] E. H. Clarke. Precios escalonados de bienes públicos. Elección Pública, 11:17-33, 1971. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Actas de la 18ª Conferencia Anual sobre Incertidumbre en Inteligencia Artificial (UAI-02), páginas 103-110, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Diseño de mecanismos automatizados: Resultados de complejidad derivados del entorno de un solo agente. En Actas de la 5ta Conferencia Internacional de Comercio Electrónico (ICEC-03), páginas 17-24, Pittsburgh, PA, EE. UU., 2003. [7] V. Conitzer y T. Sandholm. Críticas computacionales del principio de revelación. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), Nueva York, NY, 2004. Breve ensayo. La versión completa apareció en el taller AAMAS-03 sobre Comercio Electrónico Mediado por Agentes (AMEC). [8] C. d'Aspremont y L. A. Gérard-Varet. Incentivos e información incompleta. Revista de Economía Pública, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou y S. Shenker. Compartiendo el costo de las transmisiones de multidifusión. Revista de Ciencias de la Computación y de Sistemas, 63:21-41, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 2000. [10] A. Gibbard. Manipulación de esquemas de votación. Econometrica, 41:587-602, 1973. [11] T. Groves.\nEconometrica, 41:587-602, 1973. [11] T. Groves. Incentivos en equipos. Econometrica, 41:617-631, 1973. [12] J. Hershberger y S. Suri. Precios de Vickrey y caminos más cortos: ¿Cuánto vale una arista? En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [13] L. Khachiyan. Un algoritmo polinómico en programación lineal. Matemática soviética. Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi y P. Mirchandani. El problema de satisfacibilidad mínimo. Revista SIAM de Matemáticas Discretas, 7(2):275-283, 1994. [15] D. Lehmann, L. I. O'Callaghan y Y. Shoham. Revelación de la verdad en subastas combinatorias rápidas y aproximadamente eficientes. Revista de la ACM, 49(5):577-602, 2002. La versión inicial apareció en las Actas de la Conferencia de Comercio Electrónico de la ACM (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [17] E. S. Maskin y J. Riley. Subastas multiunidad óptimas. En F. Hahn, editor, \"La economía de los mercados faltantes, la información y los juegos\", capítulo 14, páginas 312-335. Clarendon Press, Oxford, 1989. [18] R. Myerson.\nPrensa Clarendon, Oxford, 1989. [18] R. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6:58-73, 1981. [19] N. Nisan y A. Ronen. Mecanismos VCG computacionalmente factibles. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 242-252, Minneapolis, MN, 2000. [20] N. Nisan y A. Ronen. Diseño de mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166-196, 2001. Versión temprana en las Actas del Simposio Anual de la ACM sobre Teoría de la Computación (STOC), 1999. [21] T. Roughgarden. Diseñar redes para usuarios egoístas es difícil. En Actas del Simposio Anual sobre Fundamentos de la Ciencia de la Computación (FOCS), 2001. [22] T. Sandholm. Problemas en subastas computacionales de Vickrey. Revista Internacional de Comercio Electrónico, 4(3):107-129, 2000. Número especial sobre la Aplicación de Agentes Inteligentes para el Comercio Electrónico. Una versión corta y temprana apareció en la Segunda Conferencia Internacional sobre Sistemas Multiagente (ICMAS), páginas 299-306, 1996. [23] M. A. Satterthwaite. In Spanish, the translation would be: \"Inmutabilidad estratégica y condiciones de Arrow: teoremas de existencia y correspondencia para procedimientos de votación y funciones de bienestar social.\" Revista de Teoría Económica, 10:187-217, 1975. [24] W. Vickrey. Contrarrestando la especulación, subastas y ofertas selladas competitivas. Revista de Finanzas, 16:8-37, 1961. [25] R. V. Vohra. Problemas de investigación en subastas combinatorias. Mimeo, versión 29 de octubre de 2001. 141 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "automate mechanism design": {
            "translated_key": "automatizar el diseño de mecanismos",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Self-interested Automated Mechanism Design and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently proposed approach-called automated mechanism design-a mechanism is computed for the preference aggregation setting at hand.",
                "This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike the earlier work on automated mechanism design that studied a benevolent designer, in this paper we study automated mechanism design problems where the designer is self-interested.",
                "In this case, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy.",
                "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy.",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc.",
                "The preference aggregator generally does not know the agents preferences a priori.",
                "Rather, the agents report their preferences to the coordinator.",
                "Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully.",
                "Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen.",
                "Manipulability is a pervasive problem across preference aggregation mechanisms.",
                "A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.)",
                "What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective.",
                "This is the classic setting of mechanism design in game theory.",
                "In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself.",
                "This is the mechanism design setting most relevant to electronic commerce.",
                "In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear.",
                "It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences.",
                "The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments.",
                "The most common such constraint is that of individual rationality (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
                "For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences.",
                "Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it.",
                "Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off.",
                "On the other hand, the designer will not necessarily choose a social welfare maximizing outcome.",
                "For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected.",
                "Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0.",
                "Classical mechanism design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective.",
                "The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]).",
                "However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare.",
                "If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization.",
                "In practice, the designer may also be interested in the outcome per se.",
                "For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical.",
                "For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed.",
                "Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments.",
                "In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand.",
                "This approach addresses all of the downsides listed above.",
                "We formulate the mechanism design problem as an optimization problem.",
                "The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types.",
                "The output is a nonmanipulable mechanism that is optimal with respect to some objective.",
                "This approach is called automated mechanism design.",
                "The automated mechanism design approach has four advantages over the classical approach of designing general mechanisms.",
                "First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare).",
                "Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences.",
                "When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally.",
                "Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types).",
                "Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information.",
                "For example, imagine a company automatically creating its procurement mechanism based on statistical knowledge about its suppliers, rather than using a classical descending procurement auction.",
                "Fourth, the burden of design is shifted from humans to a machine.",
                "However, automated mechanism design requires the mechanism design optimization problem to be solved anew for each setting.",
                "Hence its computational complexity becomes a key issue.",
                "Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6].",
                "In this paper we study the computational complexity of automated mechanism design in the case of a self-interested designer.",
                "This is an important setting for automated mechanism design due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested.",
                "We also show that this problem is closely related to a particular optimal (revenue-maximizing) combinatorial auction design problem. 133 The rest of this paper is organized as follows.",
                "In Section 2, we justify the focus on nonmanipulable mechanisms.",
                "In Section 3, we define the problem we study.",
                "In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it.",
                "In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen.",
                "In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case.",
                "Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2.",
                "JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of automated mechanism design, we should justify our focus on nonmanipulable mechanisms.",
                "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any nonmanipulable mechanism.",
                "This does, however, turn out to be the case: given any mechanism, we can construct a nonmanipulable mechanism whose performance is identical, as follows.",
                "We build an interface layer between the agents and the original mechanism.",
                "The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer.",
                "The resulting outcome is the outcome of the new mechanism.",
                "Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism.",
                "This argument is known in the mechanism design literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22].",
                "However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.)",
                "Given this, we can focus on truthful mechanisms in the rest of the paper. 3.",
                "DEFINITIONS We now formalize the automated mechanism design setting.",
                "Definition 1.",
                "In an automated mechanism design setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize.",
                "There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent).",
                "In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness.",
                "However, in this paper, we focus on the case of a self-interested designer.",
                "A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer.",
                "Definition 2.",
                "A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i.",
                "In the case where g = 0 everywhere, the designer is said to be payment maximizing.",
                "In the case where payments are not possible, g constitutes the objective function by itself.",
                "We now define the kinds of mechanisms under study.",
                "By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them.",
                "Definition 3.",
                "We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing.",
                "The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator.",
                "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 Individual rationality (IR) constraints The first type of constraint is the following.",
                "The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism.",
                "Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.)",
                "This type of constraint is called an IR (individual rationality) constraint.",
                "There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism.",
                "Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type).",
                "We will not study this concept in this paper.",
                "Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others.",
                "Ex post IR means that the agent would always participate even if it knew everybodys type.",
                "We will define the latter two notions of IR formally.",
                "First, we need to formalize the concept of the fallback outcome.",
                "We assume that each agents fallback utility is zero for each one of its types.",
                "This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16].",
                "Definition 4.",
                "In any automated mechanism design setting with an IR constraint, there is a fallback outcome o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)",
                "We can now to define the notions of individual rationality.",
                "Definition 5.",
                "Individual rationality (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
                "A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments.",
                "A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
                "The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle).",
                "For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium.",
                "Definition 6.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known.",
                "Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
                "In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible.",
                "Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report.",
                "If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium.",
                "Definition 7.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth.",
                "Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible. 135 3.3 Automated mechanism design We can now define the computational problem we study.",
                "Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an automated mechanism design setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective.",
                "An interesting special case is the setting where there is only one agent.",
                "In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents.",
                "Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here.",
                "Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here.",
                "This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4.",
                "PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "To demonstrate NPhardness, we reduce from the MINSAT problem.",
                "Definition 9 (MINSAT).",
                "We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|).",
                "We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied.",
                "MINSAT was recently shown to be NP-complete [14].",
                "We can now present our result.",
                "Theorem 1.",
                "Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent payment-maximizing deterministic AMD instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|.",
                "For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the MINSAT solution, and π(θc) = |Θ| if c is satisfied.",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent.",
                "Clearly the agent is better off reporting truthfully, for a total utility of 0.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type.",
                "Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the IR constraint, the maximum payment we can extract from any type θv is |Θ|.",
                "Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.)",
                "Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1.",
                "It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible.",
                "However, it does not yet imply hardness for the special case where payments are not possible.",
                "We will prove hardness in this case in the next section. 5.",
                "SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "Theorem 2.",
                "Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent self-interested deterministic AMD without payments instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1.",
                "Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v).",
                "For every c ∈ C that is satisfied in the MINSAT solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ .",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "The only other outcome that the mechanism is allowed to choose under the IR constraint is o0.",
                "This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}.",
                "We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|.",
                "For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).)",
                "Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes.",
                "It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Both of our hardness results relied on the constraint that the mechanism should be deterministic.",
                "In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6.",
                "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of self-interested AMD tractable through linear programming, for any constant number of agents.",
                "Theorem 3.",
                "Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated.",
                "Proof.",
                "Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}.",
                "The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.)",
                "First, we show the IR constraints.",
                "For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
                "For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
                "Now, we show the solution concept constraints.",
                "For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
                "Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
                "All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
                "As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents.",
                "Thus the problem is solvable in polynomial time. 7.",
                "IMPLICATIONS FOR AN OPTIMAL COMBINATORIAL AUCTION DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated mechanism design for a self-interested designer on designing optimal combinatorial auctions.",
                "Consider a combinatorial auction with a set S of items for sale.",
                "For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi.",
                "The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.)",
                "The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18].",
                "However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25].",
                "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of complementarity and no substitutability has been solved recently [1].)",
                "Suppose we have free disposal-items can be thrown away at no cost.",
                "Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.)",
                "Definition 10.",
                "Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
                "We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item.",
                "The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type.",
                "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the payment maximizing AMD problem!",
                "Theorem 4.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types.",
                "Proof.",
                "The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming.",
                "To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal combinatorial auction design problem instance with a single bidder with best-only preferences.",
                "For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance).",
                "Let the expected revenue target value be the same in both instances.",
                "We show the instances are equivalent.",
                "First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function.",
                "Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.)",
                "Let the payment functions be the same in both instances.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same.",
                "It follows that there exists a solution to the optimal auction design instance.",
                "Now suppose there exists a solution to the optimal auction design instance.",
                "By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item.",
                "Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type.",
                "If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type.",
                "Let the payment functions be the same.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same.",
                "It follows that there exists a solution to the AMD instance.",
                "Fortunately, we can also carry through the easiness result for randomized mechanisms to this combinatorial auction setting-giving us one of the few known polynomial-time algorithms for an optimal combinatorial auction design problem.",
                "Theorem 5.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.)",
                "Proof.",
                "By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item.",
                "There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations.",
                "Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8.",
                "RELATED RESEARCH ON COMPLEXITY IN MECHANISM DESIGN There has been considerable recent interest in mechanism design in computer science.",
                "Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism.",
                "The closest piece of earlier work studied the complexity of automated mechanism design by a benevolent designer [5, 6].",
                "Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21].",
                "This is related to mechanism design, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments).",
                "Also, there is no explicit reporting of preferences. 9.",
                "CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently emerging approach-called automated mechanism design-a mechanism is computed for the specific preference aggregation setting at hand.",
                "This has several advantages, 139 but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike earlier work on automated mechanism design that studied a benevolent designer, in this paper we studied automated mechanism design problems where the designer is self-interesteda setting much more relevant for electronic commerce.",
                "In this setting, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "These hardness results imply hardness in all more general automated mechanism design settings with a self-interested designer.",
                "The hardness results apply whether the individual rationality (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation.",
                "We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy.",
                "Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy.",
                "Future research includes studying automated mechanism design with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments).",
                "We also want to study the complexity of automated mechanism design in settings where the outcome and type spaces have special structure so they can be represented more concisely.",
                "Finally, we plan to assemble a data set of real-world mechanism design problems-both historical and current-and apply automated mechanism design to those problems. 10.",
                "REFERENCES [1] M. Armstrong.",
                "Optimal multi-object auctions.",
                "Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow.",
                "The property rights doctrine and demand revelation under incomplete information.",
                "In M. Boskin, editor, Economics and human welfare.",
                "New York Academic Press, 1979. [3] C. Avery and T. Hendershott.",
                "Bundling and optimal auctions of multiple products.",
                "Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke.",
                "Multipart pricing of public goods.",
                "Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Automated mechanism design: Complexity results stemming from the single-agent setting.",
                "In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm.",
                "Computational criticisms of the revelation principle.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004.",
                "Short paper.",
                "Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet.",
                "Incentives and incomplete information.",
                "Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker.",
                "Sharing the cost of muliticast transmissions.",
                "Journal of Computer and System Sciences, 63:21-41, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard.",
                "Manipulation of voting schemes.",
                "Econometrica, 41:587-602, 1973. [11] T. Groves.",
                "Incentives in teams.",
                "Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri.",
                "Vickrey prices and shortest paths: What is an edge worth?",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan.",
                "A polynomial algorithm in linear programming.",
                "Soviet Math.",
                "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani.",
                "The minimum satisfiability problem.",
                "SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham.",
                "Truth revelation in rapid, approximately efficient combinatorial auctions.",
                "Journal of the ACM, 49(5):577-602, 2002.",
                "Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [17] E. S. Maskin and J. Riley.",
                "Optimal multi-unit auctions.",
                "In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335.",
                "Clarendon Press, Oxford, 1989. [18] R. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen.",
                "Computationally feasible VCG mechanisms.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behavior, 35:166-196, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden.",
                "Designing networks for selfish users is hard.",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm.",
                "Issues in computational Vickrey auctions.",
                "International Journal of Electronic Commerce, 4(3):107-129, 2000.",
                "Special Issue on 140 Applying Intelligent Agents for Electronic Commerce.",
                "A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite.",
                "Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions.",
                "Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey.",
                "Counterspeculation, auctions, and competitive sealed tenders.",
                "Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra.",
                "Research problems in combinatorial auctions.",
                "Mimeo, version Oct. 29, 2001. 141"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "combinatorial auction": {
            "translated_key": "subasta combinatoria",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-interested Automated Mechanism Design and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently proposed approach-called automated mechanism design-a mechanism is computed for the preference aggregation setting at hand.",
                "This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike the earlier work on automated mechanism design that studied a benevolent designer, in this paper we study automated mechanism design problems where the designer is self-interested.",
                "In this case, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy.",
                "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) <br>combinatorial auction</br> design problem, where the bidders have best-only preferences.",
                "We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy.",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc.",
                "The preference aggregator generally does not know the agents preferences a priori.",
                "Rather, the agents report their preferences to the coordinator.",
                "Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully.",
                "Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen.",
                "Manipulability is a pervasive problem across preference aggregation mechanisms.",
                "A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.)",
                "What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective.",
                "This is the classic setting of mechanism design in game theory.",
                "In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself.",
                "This is the mechanism design setting most relevant to electronic commerce.",
                "In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear.",
                "It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences.",
                "The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments.",
                "The most common such constraint is that of individual rationality (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
                "For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences.",
                "Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it.",
                "Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off.",
                "On the other hand, the designer will not necessarily choose a social welfare maximizing outcome.",
                "For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected.",
                "Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0.",
                "Classical mechanism design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective.",
                "The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]).",
                "However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare.",
                "If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization.",
                "In practice, the designer may also be interested in the outcome per se.",
                "For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical.",
                "For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed.",
                "Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments.",
                "In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand.",
                "This approach addresses all of the downsides listed above.",
                "We formulate the mechanism design problem as an optimization problem.",
                "The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types.",
                "The output is a nonmanipulable mechanism that is optimal with respect to some objective.",
                "This approach is called automated mechanism design.",
                "The automated mechanism design approach has four advantages over the classical approach of designing general mechanisms.",
                "First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare).",
                "Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences.",
                "When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally.",
                "Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types).",
                "Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information.",
                "For example, imagine a company automatically creating its procurement mechanism based on statistical knowledge about its suppliers, rather than using a classical descending procurement auction.",
                "Fourth, the burden of design is shifted from humans to a machine.",
                "However, automated mechanism design requires the mechanism design optimization problem to be solved anew for each setting.",
                "Hence its computational complexity becomes a key issue.",
                "Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6].",
                "In this paper we study the computational complexity of automated mechanism design in the case of a self-interested designer.",
                "This is an important setting for automated mechanism design due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested.",
                "We also show that this problem is closely related to a particular optimal (revenue-maximizing) <br>combinatorial auction</br> design problem. 133 The rest of this paper is organized as follows.",
                "In Section 2, we justify the focus on nonmanipulable mechanisms.",
                "In Section 3, we define the problem we study.",
                "In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it.",
                "In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen.",
                "In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case.",
                "Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2.",
                "JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of automated mechanism design, we should justify our focus on nonmanipulable mechanisms.",
                "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any nonmanipulable mechanism.",
                "This does, however, turn out to be the case: given any mechanism, we can construct a nonmanipulable mechanism whose performance is identical, as follows.",
                "We build an interface layer between the agents and the original mechanism.",
                "The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer.",
                "The resulting outcome is the outcome of the new mechanism.",
                "Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism.",
                "This argument is known in the mechanism design literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22].",
                "However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.)",
                "Given this, we can focus on truthful mechanisms in the rest of the paper. 3.",
                "DEFINITIONS We now formalize the automated mechanism design setting.",
                "Definition 1.",
                "In an automated mechanism design setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize.",
                "There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent).",
                "In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness.",
                "However, in this paper, we focus on the case of a self-interested designer.",
                "A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer.",
                "Definition 2.",
                "A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i.",
                "In the case where g = 0 everywhere, the designer is said to be payment maximizing.",
                "In the case where payments are not possible, g constitutes the objective function by itself.",
                "We now define the kinds of mechanisms under study.",
                "By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them.",
                "Definition 3.",
                "We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing.",
                "The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator.",
                "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 Individual rationality (IR) constraints The first type of constraint is the following.",
                "The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism.",
                "Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.)",
                "This type of constraint is called an IR (individual rationality) constraint.",
                "There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism.",
                "Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type).",
                "We will not study this concept in this paper.",
                "Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others.",
                "Ex post IR means that the agent would always participate even if it knew everybodys type.",
                "We will define the latter two notions of IR formally.",
                "First, we need to formalize the concept of the fallback outcome.",
                "We assume that each agents fallback utility is zero for each one of its types.",
                "This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16].",
                "Definition 4.",
                "In any automated mechanism design setting with an IR constraint, there is a fallback outcome o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)",
                "We can now to define the notions of individual rationality.",
                "Definition 5.",
                "Individual rationality (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
                "A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments.",
                "A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
                "The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle).",
                "For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium.",
                "Definition 6.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known.",
                "Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
                "In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible.",
                "Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report.",
                "If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium.",
                "Definition 7.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth.",
                "Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible. 135 3.3 Automated mechanism design We can now define the computational problem we study.",
                "Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an automated mechanism design setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective.",
                "An interesting special case is the setting where there is only one agent.",
                "In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents.",
                "Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here.",
                "Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here.",
                "This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4.",
                "PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "To demonstrate NPhardness, we reduce from the MINSAT problem.",
                "Definition 9 (MINSAT).",
                "We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|).",
                "We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied.",
                "MINSAT was recently shown to be NP-complete [14].",
                "We can now present our result.",
                "Theorem 1.",
                "Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent payment-maximizing deterministic AMD instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|.",
                "For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the MINSAT solution, and π(θc) = |Θ| if c is satisfied.",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent.",
                "Clearly the agent is better off reporting truthfully, for a total utility of 0.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type.",
                "Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the IR constraint, the maximum payment we can extract from any type θv is |Θ|.",
                "Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.)",
                "Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1.",
                "It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible.",
                "However, it does not yet imply hardness for the special case where payments are not possible.",
                "We will prove hardness in this case in the next section. 5.",
                "SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "Theorem 2.",
                "Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent self-interested deterministic AMD without payments instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1.",
                "Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v).",
                "For every c ∈ C that is satisfied in the MINSAT solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ .",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "The only other outcome that the mechanism is allowed to choose under the IR constraint is o0.",
                "This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}.",
                "We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|.",
                "For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).)",
                "Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes.",
                "It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Both of our hardness results relied on the constraint that the mechanism should be deterministic.",
                "In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6.",
                "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of self-interested AMD tractable through linear programming, for any constant number of agents.",
                "Theorem 3.",
                "Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated.",
                "Proof.",
                "Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}.",
                "The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.)",
                "First, we show the IR constraints.",
                "For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
                "For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
                "Now, we show the solution concept constraints.",
                "For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
                "Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
                "All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
                "As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents.",
                "Thus the problem is solvable in polynomial time. 7.",
                "IMPLICATIONS FOR AN OPTIMAL <br>combinatorial auction</br> DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated mechanism design for a self-interested designer on designing optimal combinatorial auctions.",
                "Consider a <br>combinatorial auction</br> with a set S of items for sale.",
                "For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi.",
                "The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.)",
                "The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18].",
                "However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25].",
                "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of complementarity and no substitutability has been solved recently [1].)",
                "Suppose we have free disposal-items can be thrown away at no cost.",
                "Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.)",
                "Definition 10.",
                "Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
                "We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item.",
                "The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type.",
                "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the payment maximizing AMD problem!",
                "Theorem 4.",
                "Given an optimal <br>combinatorial auction</br> design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types.",
                "Proof.",
                "The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming.",
                "To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal <br>combinatorial auction</br> design problem instance with a single bidder with best-only preferences.",
                "For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance).",
                "Let the expected revenue target value be the same in both instances.",
                "We show the instances are equivalent.",
                "First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function.",
                "Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.)",
                "Let the payment functions be the same in both instances.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same.",
                "It follows that there exists a solution to the optimal auction design instance.",
                "Now suppose there exists a solution to the optimal auction design instance.",
                "By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item.",
                "Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type.",
                "If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type.",
                "Let the payment functions be the same.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same.",
                "It follows that there exists a solution to the AMD instance.",
                "Fortunately, we can also carry through the easiness result for randomized mechanisms to this <br>combinatorial auction</br> setting-giving us one of the few known polynomial-time algorithms for an optimal <br>combinatorial auction</br> design problem.",
                "Theorem 5.",
                "Given an optimal <br>combinatorial auction</br> design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.)",
                "Proof.",
                "By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item.",
                "There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations.",
                "Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8.",
                "RELATED RESEARCH ON COMPLEXITY IN MECHANISM DESIGN There has been considerable recent interest in mechanism design in computer science.",
                "Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism.",
                "The closest piece of earlier work studied the complexity of automated mechanism design by a benevolent designer [5, 6].",
                "Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21].",
                "This is related to mechanism design, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments).",
                "Also, there is no explicit reporting of preferences. 9.",
                "CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently emerging approach-called automated mechanism design-a mechanism is computed for the specific preference aggregation setting at hand.",
                "This has several advantages, 139 but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike earlier work on automated mechanism design that studied a benevolent designer, in this paper we studied automated mechanism design problems where the designer is self-interesteda setting much more relevant for electronic commerce.",
                "In this setting, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "These hardness results imply hardness in all more general automated mechanism design settings with a self-interested designer.",
                "The hardness results apply whether the individual rationality (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation.",
                "We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy.",
                "Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) <br>combinatorial auction</br> design problem, where the bidders have best-only preferences.",
                "We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy.",
                "Future research includes studying automated mechanism design with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments).",
                "We also want to study the complexity of automated mechanism design in settings where the outcome and type spaces have special structure so they can be represented more concisely.",
                "Finally, we plan to assemble a data set of real-world mechanism design problems-both historical and current-and apply automated mechanism design to those problems. 10.",
                "REFERENCES [1] M. Armstrong.",
                "Optimal multi-object auctions.",
                "Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow.",
                "The property rights doctrine and demand revelation under incomplete information.",
                "In M. Boskin, editor, Economics and human welfare.",
                "New York Academic Press, 1979. [3] C. Avery and T. Hendershott.",
                "Bundling and optimal auctions of multiple products.",
                "Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke.",
                "Multipart pricing of public goods.",
                "Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Automated mechanism design: Complexity results stemming from the single-agent setting.",
                "In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm.",
                "Computational criticisms of the revelation principle.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004.",
                "Short paper.",
                "Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet.",
                "Incentives and incomplete information.",
                "Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker.",
                "Sharing the cost of muliticast transmissions.",
                "Journal of Computer and System Sciences, 63:21-41, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard.",
                "Manipulation of voting schemes.",
                "Econometrica, 41:587-602, 1973. [11] T. Groves.",
                "Incentives in teams.",
                "Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri.",
                "Vickrey prices and shortest paths: What is an edge worth?",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan.",
                "A polynomial algorithm in linear programming.",
                "Soviet Math.",
                "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani.",
                "The minimum satisfiability problem.",
                "SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham.",
                "Truth revelation in rapid, approximately efficient combinatorial auctions.",
                "Journal of the ACM, 49(5):577-602, 2002.",
                "Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [17] E. S. Maskin and J. Riley.",
                "Optimal multi-unit auctions.",
                "In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335.",
                "Clarendon Press, Oxford, 1989. [18] R. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen.",
                "Computationally feasible VCG mechanisms.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behavior, 35:166-196, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden.",
                "Designing networks for selfish users is hard.",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm.",
                "Issues in computational Vickrey auctions.",
                "International Journal of Electronic Commerce, 4(3):107-129, 2000.",
                "Special Issue on 140 Applying Intelligent Agents for Electronic Commerce.",
                "A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite.",
                "Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions.",
                "Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey.",
                "Counterspeculation, auctions, and competitive sealed tenders.",
                "Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra.",
                "Research problems in combinatorial auctions.",
                "Mimeo, version Oct. 29, 2001. 141"
            ],
            "original_annotated_samples": [
                "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) <br>combinatorial auction</br> design problem, where the bidders have best-only preferences.",
                "We also show that this problem is closely related to a particular optimal (revenue-maximizing) <br>combinatorial auction</br> design problem. 133 The rest of this paper is organized as follows.",
                "IMPLICATIONS FOR AN OPTIMAL <br>combinatorial auction</br> DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated mechanism design for a self-interested designer on designing optimal combinatorial auctions.",
                "Consider a <br>combinatorial auction</br> with a set S of items for sale.",
                "Given an optimal <br>combinatorial auction</br> design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types."
            ],
            "translated_annotated_samples": [
                "Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de <br>subasta combinatoria</br> óptima (maximizadora de ingresos), donde los postores tienen preferencias solo por lo mejor.",
                "También demostramos que este problema está estrechamente relacionado con un problema de diseño de <br>subasta combinatoria</br> óptima (maximización de ingresos) particular. El resto de este documento está organizado de la siguiente manera.",
                "IMPLICACIONES PARA UN PROBLEMA DE DISEÑO DE SUBASTA COMBINATORIA ÓPTIMA En esta sección, demostraremos algunas consecuencias interesantes del problema de diseño de mecanismos automatizados para un diseñador interesado en sí mismo en el diseño de subastas combinatorias óptimas.",
                "Considera una <br>subasta combinatoria</br> con un conjunto S de artículos en venta.",
                "Dado un problema de diseño de <br>subasta combinatoria</br> óptima bajo preferencias de mejor opción (dado por un conjunto de artículos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), diseñar la subasta determinística óptima es NP-completo, incluso para un único postor con una distribución uniforme sobre los tipos."
            ],
            "translated_text": "Diseño de mecanismos automatizados de interés propio e implicaciones para subastas combinatorias óptimas∗ Vincent Conitzer Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. conitzer@cs.cmu.edu Tuomas Sandholm Universidad Carnegie Mellon 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. sandholm@cs.cmu.edu RESUMEN A menudo, un resultado debe ser elegido en base a las preferencias reportadas por un grupo de agentes. La dificultad clave es que los agentes pueden informar sus preferencias de manera insincera para hacer que el resultado elegido les resulte más favorable. El diseño de mecanismos es el arte de diseñar las reglas del juego de manera que los agentes estén motivados a informar sus preferencias de manera veraz, y se elija un resultado deseable. En un enfoque recientemente propuesto, llamado diseño de mecanismos automatizado, se calcula un mecanismo para la configuración de agregación de preferencias actual. Esto tiene varias ventajas, pero el inconveniente es que el problema de optimización del diseño del mecanismo debe resolverse de nuevo cada vez. A diferencia de trabajos anteriores sobre el diseño automatizado de mecanismos que estudiaron a un diseñador benevolente, en este artículo estudiamos problemas de diseño automatizado de mecanismos donde el diseñador está interesado en sí mismo. En este caso, al centro solo le importa qué resultado se elige y qué pagos se le hacen. La razón por la que las preferencias de los agentes son relevantes es que el centro está obligado a asegurar que cada agente esté al menos tan bien como estaría si no hubiera participado en el mecanismo. En este contexto, demostramos que el diseño de mecanismos deterministas óptimos es NP-completo en dos casos especiales importantes: cuando el centro está interesado solo en los pagos realizados hacia él, y cuando los pagos no son posibles y el centro está interesado solo en el resultado elegido. Luego mostramos cómo permitir la aleatorización en el mecanismo hace que los problemas en este entorno sean computacionalmente fáciles. Finalmente, demostramos que el problema de AMD que maximiza el pago está estrechamente relacionado con una variante interesante del problema de diseño de <br>subasta combinatoria</br> óptima (maximizadora de ingresos), donde los postores tienen preferencias solo por lo mejor. Mostramos que aquí también, diseñar una subasta determinista óptima es NP-completo, pero diseñar una subasta aleatoria óptima es fácil. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Teoría 1. En entornos multiagentes, a menudo se debe elegir un resultado en función de las preferencias informadas por un grupo de agentes. Tales resultados podrían ser presidentes potenciales, planes conjuntos, asignaciones de bienes o recursos, etc. El agregador de preferencias generalmente no conoce las preferencias de los agentes de antemano. Más bien, los agentes informan sus preferencias al coordinador. Desafortunadamente, un agente puede tener un incentivo para informar incorrectamente sus preferencias con el fin de engañar al mecanismo y lograr que seleccione un resultado que sea más deseable para el agente que el resultado que se seleccionaría si el agente revelara sus preferencias de manera honesta. Tal manipulación es indeseable porque los mecanismos de agregación de preferencias están diseñados para agrupar las preferencias de una manera socialmente deseable, y si los agentes revelan sus preferencias de manera insincera, se podría elegir un resultado socialmente indeseable. La manipulabilidad es un problema generalizado en los mecanismos de agregación de preferencias. Un resultado negativo seminal, el teorema de Gibbard-Satterthwaite, muestra que bajo cualquier esquema de agregación de preferencias no dictatorial, si hay al menos 3 posibles resultados, existen preferencias bajo las cuales un agente está mejor reportando falsamente [10, 23]. (Un esquema de agregación de preferencias se llama dictatorial si uno de los agentes dicta el resultado sin importar las preferencias que reporten los otros agentes). Lo que le gustaría hacer al agregador es diseñar un mecanismo de agregación de preferencias para que 1) los agentes interesados reporten sus preferencias de manera veraz, y 2) el mecanismo elija un resultado que sea deseable desde la perspectiva de algún objetivo. Esta es la configuración clásica del diseño de mecanismos en la teoría de juegos. En este documento, estudiamos el caso en el que el diseñador actúa por interés propio, es decir, al diseñador no le importa directamente cómo se relaciona el resultado con las preferencias de los agentes, sino que está más preocupado por su propia agenda sobre cuál resultado debería ser elegido y en maximizar los pagos para sí mismo. Este es el entorno de diseño de mecanismos más relevante para el comercio electrónico. En el caso en que el diseñador del mecanismo esté interesado en maximizar alguna noción de bienestar social, la importancia de recopilar las preferencias de los agentes es clara. Quizás sea menos obvio por qué deberían ser recopilados cuando el diseñador está interesado en sí mismo y, por lo tanto, su objetivo no está directamente relacionado con las preferencias de los agentes. La razón de esto es que a menudo las preferencias de los agentes imponen límites en cómo el diseñador elige el resultado y los pagos. La restricción más común de este tipo es la de racionalidad individual (RI), lo que significa que el mecanismo no puede dejar a ningún agente en una situación peor a la que hubiera estado si no hubiera participado en el mecanismo. Por ejemplo, en el contexto del diseño óptimo de subastas, el diseñador (subastador) solo se preocupa por cuántos ingresos se recaudan, y no en sí mismo por cuán bien la asignación del bien (o bienes) corresponde a las preferencias de los agentes. Sin embargo, el diseñador no puede obligar a un agente a pagar más de lo que valora el paquete de bienes asignado a él. Por lo tanto, incluso un diseñador interesado en sí mismo elegirá un resultado que beneficie razonablemente a los agentes. Por otro lado, el diseñador no necesariamente elegirá un resultado que maximice el bienestar social. Por ejemplo, si el diseñador siempre elige un resultado que maximiza el bienestar social con respecto a las preferencias informadas, y obliga a cada agente a pagar la diferencia entre la utilidad que tiene ahora y la utilidad que habría tenido si no hubiera participado en el mecanismo, es fácil ver que los agentes pueden tener un incentivo para informar incorrectamente sus preferencias, lo que puede llevar realmente a recaudar menos ingresos. De hecho, uno de los resultados contraintuitivos de la teoría del diseño de subastas óptimas es que a veces el bien se asigna a nadie incluso cuando el subastador tiene un precio de reserva de 0. El diseño de mecanismos clásicos proporciona algunos mecanismos generales, que, bajo ciertas suposiciones, satisfacen alguna noción de no manipulabilidad y maximizan algún objetivo. La ventaja de estos mecanismos es que no dependen de información (incluso probabilística) sobre las preferencias de los agentes (por ejemplo, el mecanismo de Vickrey-Clarke-Groves (VCG) [24, 4, 11]), o pueden aplicarse fácilmente a cualquier distribución de probabilidad sobre las preferencias (por ejemplo, el mecanismo dAGVA [8, 2], la subasta de Myerson [18], y la subasta multiunidad de Maskin-Riley [17]). Sin embargo, los mecanismos generales también tienen importantes desventajas: • Los mecanismos generales más famosos y ampliamente aplicables, VCG y dAGVA, solo maximizan el bienestar social. Si el diseñador está interesado en sí mismo, como es el caso en muchos entornos de comercio electrónico, estos mecanismos no maximizan el objetivo del diseñador. • Los mecanismos generales que se centran en un diseñador interesado en sí mismo solo son aplicables en entornos muy restringidos, como la subasta de maximización de ingresos esperados de Myerson para vender un solo artículo, y la subasta de maximización de ingresos esperados de Maskin y Riley para vender múltiples unidades idénticas de un artículo. • Incluso en los entornos restringidos en los que se aplican estos mecanismos, solo permiten la maximización de pagos. En la práctica, el diseñador también puede estar interesado en el resultado en sí mismo. Por ejemplo, a un subastador le puede importar qué postor recibe el artículo. • A menudo se asume que los pagos laterales pueden ser utilizados para adaptar los incentivos de los agentes, pero esto no siempre es práctico. Por ejemplo, en los mercados electrónicos basados en trueque, como Recipco, firstbarter.com, BarterOne e Intagio, no se permiten los pagos laterales. Además, entre los agentes de software, podría ser más deseable construir mecanismos que no dependan de la capacidad de realizar pagos, ya que muchos agentes de software no cuentan con la infraestructura para hacer pagos. Por el contrario, seguimos un enfoque reciente donde el mecanismo se diseña automáticamente para el problema específico en cuestión. Este enfoque aborda todos los inconvenientes mencionados anteriormente. Formulamos el problema de diseño de mecanismos como un problema de optimización. La entrada se caracteriza por el número de agentes, los posibles tipos de agentes (preferencias) y las distribuciones previas de los agregadores sobre los tipos de agentes. La salida es un mecanismo no manipulable que es óptimo con respecto a algún objetivo. Este enfoque se llama diseño de mecanismos automatizado. El enfoque de diseño de mecanismos automatizado tiene cuatro ventajas sobre el enfoque clásico de diseñar mecanismos generales. Primero, se puede utilizar incluso en entornos que no cumplen con las suposiciones de los mecanismos clásicos (como la disponibilidad de pagos laterales o que el objetivo sea el bienestar social). Segundo, puede permitir a uno eludir resultados de imposibilidad (como el teorema de Gibbard-Satterthwaite) que establecen que no existe un mecanismo que sea deseable para todas las preferencias. Cuando el mecanismo está diseñado para la configuración actual, no importa que no funcione de manera más general. Tercero, puede generar mecanismos mejores (en términos de garantías de no manipulabilidad más sólidas y/o mejores resultados) que los mecanismos clásicos porque el mecanismo aprovecha las particularidades del entorno (la información probabilística que el diseñador tiene sobre los tipos de agentes). Dada la gran cantidad de información que las partes tienen entre sí hoy en día, es probable que este enfoque conduzca a ahorros enormes en comparación con los mecanismos clásicos, que en su mayoría ignoran esa información. Por ejemplo, imagina una empresa creando automáticamente su mecanismo de adquisiciones basado en el conocimiento estadístico sobre sus proveedores, en lugar de utilizar una subasta de adquisiciones descendente clásica. Cuarto, la carga del diseño se traslada de los humanos a una máquina. Sin embargo, el diseño automatizado de mecanismos requiere que el problema de optimización del diseño del mecanismo se resuelva de nuevo para cada configuración. Por lo tanto, su complejidad computacional se convierte en un tema clave. Investigaciones previas han estudiado esta pregunta para diseñadores benevolentes que desean maximizar, por ejemplo, el bienestar social [5, 6]. En este artículo estudiamos la complejidad computacional del diseño automatizado de mecanismos en el caso de un diseñador con interés propio. Esta es una configuración importante para el diseño de mecanismos automatizados debido a la escasez de mecanismos generales en esta área, y al hecho de que en la mayoría de las configuraciones de comercio electrónico el diseñador actúa en su propio interés. También demostramos que este problema está estrechamente relacionado con un problema de diseño de <br>subasta combinatoria</br> óptima (maximización de ingresos) particular. El resto de este documento está organizado de la siguiente manera. En la Sección 2, justificamos el enfoque en mecanismos no manipulables. En la Sección 3, definimos el problema que estudiamos. En la Sección 4, demostramos que diseñar un mecanismo determinista óptimo es NP-completo incluso cuando al diseñador solo le importan los pagos que recibe. En la Sección 5, demostramos que diseñar un mecanismo determinista óptimo también es NP-completo cuando los pagos no son posibles y el diseñador solo está interesado en el resultado elegido. En la Sección 6, demostramos que un mecanismo óptimo aleatorizado puede ser diseñado en tiempo polinómico incluso en el caso general. Finalmente, en la Sección 7, demostramos que para diseñar subastas combinatorias óptimas bajo preferencias de mejor opción solamente, nuestros resultados sobre AMD implican que este problema es NP-completo para subastas determinísticas, pero sencillo para subastas aleatorias. 2. JUSTIFICANDO EL ENFOQUE EN MECANISMOS NO MANIPULABLES Antes de definir el problema computacional del diseño automatizado de mecanismos, debemos justificar nuestro enfoque en mecanismos no manipulables. Después de todo, no es inmediatamente obvio que no haya mecanismos manipulables que, incluso cuando los agentes informan estratégicamente sus tipos y, por lo tanto, a veces de manera no veraz, aún logren mejores resultados (según el objetivo que usemos) que cualquier mecanismo no manipulable. Sin embargo, resulta ser el caso que, dado cualquier mecanismo, podemos construir un mecanismo no manipulable cuyo rendimiento es idéntico, de la siguiente manera. Construimos una capa de interfaz entre los agentes y el mecanismo original. Los agentes informan sus preferencias (o tipos) a la capa de interfaz; posteriormente, la capa de interfaz introduce en el mecanismo original los tipos que los agentes habrían informado estratégicamente al mecanismo original, si sus tipos fueran los declarados a la capa de interfaz. El resultado resultante es el resultado del nuevo mecanismo. Dado que la capa de interfaz actúa estratégicamente en nombre de cada agente, nunca hay un incentivo para informar falsamente a la capa de interfaz; por lo tanto, los tipos informados por la capa de interfaz son los tipos estratégicos que se habrían informado sin la capa de interfaz, por lo que los resultados son exactamente como habrían sido con el mecanismo original. Este argumento es conocido en la literatura de diseño de mecanismos como el principio de revelación [16]. (Existen dificultades computacionales al aplicar el principio de revelación en espacios de resultados y tipos combinatorios grandes [7, 22]). Sin embargo, dado que aquí nos enfocamos en espacios de resultados y tipos representados de forma plana, esto no es una preocupación aquí. Dado esto, podemos centrarnos en mecanismos veraces en el resto del documento. 3. DEFINICIONES Ahora formalizamos el entorno del diseño automatizado de mecanismos. Definición 1. En un entorno de diseño de mecanismos automatizados, se nos proporciona: • un conjunto finito de resultados O; • un conjunto finito de N agentes; • para cada agente i, 1. un conjunto finito de tipos Θi, 2. una distribución de probabilidad γi sobre Θi (en el caso de tipos correlacionados, hay una única distribución conjunta γ sobre Θ1 × . . . × ΘN), y 3. una función de utilidad ui: Θi × O → R; 1 • Una función objetivo cuya expectativa el diseñador desea maximizar. Existen muchas posibles funciones objetivo que el diseñador podría tener, por ejemplo, el bienestar social (donde el diseñador busca maximizar la suma de las utilidades de los agentes), o la utilidad mínima de cualquier agente (donde el diseñador busca maximizar la peor utilidad experimentada por cualquier agente). En ambos casos, el diseñador es benevolente, ya que, de alguna manera, el diseñador está buscando la felicidad colectiva de los agentes. Sin embargo, en este documento nos enfocamos en el caso de un diseñador interesado en sí mismo. Un diseñador egoísta solo se preocupa por el resultado elegido (es decir, al diseñador no le importa cómo se relaciona el resultado con las preferencias de los agentes, sino que tiene una preferencia fija sobre los resultados) y sobre los pagos netos realizados por los agentes, que fluyen hacia el diseñador. Definición 2. Un diseñador interesado tiene una función objetivo dada por g(o) + Σ i=1 πi, donde g : O → R indica las preferencias del diseñador sobre los resultados, y πi es el pago realizado por el agente i. En el caso en que g = 0 en todas partes, se dice que el diseñador está maximizando el pago. En el caso en que los pagos no sean posibles, g constituye la función objetivo por sí sola. Ahora definimos los tipos de mecanismos en estudio. Por el principio de revelación, podemos restringir la atención a mecanismos de revelación directa y veraz, donde los agentes informan directamente sus tipos y nunca tienen incentivos para informarlos de manera incorrecta. Definición 3. Consideramos los siguientes tipos de mecanismos: • Un mecanismo determinista sin pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O. • Un mecanismo aleatorio sin pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), donde P(O) es el conjunto de distribuciones de probabilidad sobre O. • Un mecanismo determinista con pagos consiste en una función de selección de resultados o: Θ1 × Θ2 × . . . × ΘN → O y, para cada agente i, una función de selección de pagos πi: Θ1 × Θ2 × . . . × ΘN → R, donde πi(θ1, . . . , θN ) da el pago realizado por el agente i cuando los tipos reportados son θ1, . . . , θN. Aunque esto sigue la notación estándar de la teoría de juegos [16], el hecho de que el agente tenga tanto una función de utilidad como un tipo puede resultar confuso. Los tipos codifican las diversas preferencias posibles que el agente pueda tener, y el tipo de los agentes no es conocido por el agregador. La función de utilidad es un conocimiento común, pero debido a que el tipo de agente es un parámetro en la función de utilidad de los agentes, el agregador no puede saber cuál es la utilidad de los agentes sin conocer el tipo de agente. Un mecanismo aleatorio con pagos consiste en una función de selección de distribución p: Θ1 × Θ2 × . . . × ΘN → P(O), y para cada agente i, una función de selección de pago πi: Θ1 × Θ2 × . . . × ΘN → R. Hay dos tipos de restricciones para el diseñador al construir el mecanismo. 3.1 Restricciones de racionalidad individual (IR) El primer tipo de restricción es el siguiente. La utilidad de cada agente debe ser al menos tan grande como la utilidad de respaldo de los agentes, es decir, la utilidad que el agente recibiría si no participara en el mecanismo. De lo contrario, ese agente no participaría en el mecanismo, y la participación de ningún agente puede perjudicar el objetivo de los diseñadores del mecanismo, ya que en el peor de los casos, el mecanismo puede ignorar a un agente fingiendo que el agente no está presente. (Además, si no se aplicara tal restricción, el diseñador simplemente podría hacer que los agentes paguen una cantidad infinita). Este tipo de restricción se llama restricción de IR (racionalidad individual). Existen tres posibles restricciones de IR diferentes: ex ante, ex interim y ex post, dependiendo de lo que el agente sabe sobre su propio tipo y los tipos de los demás al decidir si participar en el mecanismo. Ex ante IR significa que el agente participaría si no supiera absolutamente nada (ni siquiera su propio tipo). No estudiaremos este concepto en este documento. Ex interim IR significa que el agente siempre participaría si conociera solo su propio tipo, pero no el de los demás. Ex post IR significa que el agente siempre participaría incluso si conociera el tipo de todos. Definiremos formalmente las dos últimas nociones de IR. Primero, necesitamos formalizar el concepto del resultado de respaldo. Suponemos que la utilidad de respaldo de cada agente es cero para cada uno de sus tipos. Esto se hace sin pérdida de generalidad porque podemos agregar un término constante a la función de utilidad de un agente (para un tipo dado), sin afectar el comportamiento de toma de decisiones de ese agente maximizador de utilidad esperada [16]. Definición 4. En cualquier entorno de diseño de mecanismos automatizados con una restricción de IR, existe un resultado de contingencia o0 ∈ O donde, para cualquier agente i y cualquier tipo θi ∈ Θi, tenemos ui(θi, o0) = 0. (Además, en el caso de un diseñador egoísta, g(o0) = 0). Ahora podemos definir las nociones de racionalidad individual. Definición 5. La racionalidad individual (RI) se define como: • Un mecanismo determinista es ex interim RI si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0. Un mecanismo aleatorio es ex interim IR si para cualquier agente i, y cualquier tipo θi ∈ Θi, tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • Un mecanismo determinista es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 No aleatorizamos sobre los pagos porque mientras los agentes y el diseñador sean neutrales al riesgo con respecto a los pagos, es decir, su utilidad es lineal en los pagos, no hay razón para aleatorizar sobre los pagos. Un mecanismo aleatorio es ex post IR si para cualquier agente i, y cualquier vector de tipos (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , tenemos que Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 3.2 Restricciones de compatibilidad de incentivos (IC) El segundo tipo de restricción establece que los agentes nunca deben tener un incentivo para informar incorrectamente su tipo (como se justificó anteriormente mediante el principio de revelación). Para este tipo de restricción, las dos variantes más comunes (o conceptos de solución) son la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash. Definición 6. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en estrategias dominantes si decir la verdad siempre es óptimo incluso cuando los tipos reportados por los otros agentes ya son conocidos. Formalmente, para cualquier agente i, cualquier vector de tipos (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ). En el caso de mecanismos aleatorios tenemos Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. Por lo tanto, en la implementación de estrategias dominantes, decir la verdad es óptimo independientemente de lo que informen los otros agentes. Si es óptimo solo dado que los otros agentes son veraces, y dado que uno no conoce los tipos de los otros agentes, tenemos implementación en equilibrio de Bayes-Nash. Definición 7. En un entorno de diseño de mecanismos automatizados, se dice que un mecanismo implementa sus funciones de resultado y pago en equilibrio de Bayes-Nash si decir la verdad siempre es óptimo para un agente cuando ese agente aún no sabe nada sobre los tipos de los otros agentes, y los otros agentes están diciendo la verdad. Formalmente, para cualquier agente i, cualquier tipo θi ∈ Θi, y cualquier informe de tipo alternativo ˆθi ∈ Θi, en el caso de mecanismos deterministas tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )]. En el caso de mecanismos aleatorios tenemos que E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )]. Los términos relacionados con los pagos pueden ser omitidos en el caso de que los pagos no sean posibles. 135 3.3 Diseño de mecanismos automatizados Ahora podemos definir el problema computacional que estudiamos. Definición 8. (DISEÑO DE MECANISMOS AUTOMATIZADOS (AMD)) Se nos da: • un entorno de diseño de mecanismos automatizados, • una noción de IR (ex interim, ex post, o ninguna), • un concepto de solución (estrategias dominantes o Bayes-Nash), • si los pagos son posibles, • si la aleatorización es posible, • (en la variante de decisión del problema) un valor objetivo G. Se nos pregunta si existe un mecanismo del tipo especificado (en términos de pagos y aleatorización) que satisfaga tanto la noción de IR como el concepto de solución, y proporcione un valor esperado de al menos G para el objetivo. Un caso especial interesante es aquel en el que solo hay un agente. En este caso, el agente informante siempre sabe todo lo que hay que saber sobre los otros tipos de agentes, porque no hay otros agentes. Dado que el IR ex post y el IR ex interim solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de IR coinciden aquí. Además, dado que la implementación en estrategias dominantes y la implementación en equilibrio de Bayes-Nash solo difieren en lo que se asume que un agente sabe sobre los tipos de otros agentes, los dos conceptos de solución coinciden aquí. Esta observación resultará ser una herramienta útil para demostrar resultados de dificultad: si demostramos dificultad computacional en el escenario de un solo agente, esto implica inmediatamente dificultad para ambos conceptos de IR, para ambos conceptos de solución, para cualquier número de agentes. 4. En esta sección demostramos que es NP-completo diseñar un mecanismo determinístico que maximice la suma esperada de los pagos recolectados de los agentes. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Para demostrar la NP-dureza, reducimos desde el problema MINSAT. Definición 9 (MINSAT). Se nos da una fórmula φ en forma normal conjuntiva, representada por un conjunto de variables booleanas V y un conjunto de cláusulas C, y un entero K (K < |C|). Se nos pregunta si existe una asignación a las variables en V tal que se satisfacen a lo sumo K cláusulas en φ. MINSAT fue recientemente demostrado como NP-completo [14]. Ahora podemos presentar nuestro resultado. Teorema 1. El problema determinista de maximización de pagos de AMD es NP-completo, incluso para un solo agente, incluso con una distribución uniforme de tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista de maximización de pagos de un solo agente. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V } ∪ {−v : v ∈ V }. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Sea l ∈ c denota que el literal l ocurre en la cláusula c. Entonces, la función de utilidad de los agentes está dada por u(θc, ol) = |Θ| + 1 para todo l ∈ L con l ∈ c; u(θc, ol) = 0 para todo l ∈ L con l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc) = 0 para todo c ∈ C con c = c; u(θv, ol) = |Θ| para todo l ∈ L con v(l) = v; u(θv, ol) = 0 para todo l ∈ L con v(l) = v; u(θv, oc) = 0 para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ|, donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v) y π(θv) = |Θ|. Para cada c ∈ C, sea o(θc) = oc; sea π(θc) = |Θ| + 1 si c no está satisfecha en la solución MINSAT, y π(θc) = |Θ| si c está satisfecha. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es θv, entonces cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivo para informar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, cualquier otro informe le dará un resultado que no es mejor, por un pago que no es menor, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Porque además, ningún tipo que no sea θc conduce al resultado oc, informar cualquier otro tipo dará como resultado una utilidad de 0, mientras que aún se requiere un pago de al menos |Θ| por parte del agente. Claramente, el agente está mejor reportando honestamente, para una utilidad total de 0. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), el pago esperado de este mecanismo es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o y una función de pago π. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. Entonces, la utilidad que el agente obtiene del resultado dado para este tipo es 0, y por lo tanto, según la IR, no se puede extraer ningún pago del agente para este tipo. Dado que, nuevamente por IR, el pago máximo que se puede extraer para cualquier otro tipo es |Θ| + 1, se sigue que el pago esperado máximo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo cual contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o−v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por la restricción de IR, el pago máximo que podemos extraer de cualquier tipo θv es |Θ|. Dado que no puede haber incentivos para que el agente informe falsamente, para cualquier cláusula c satisfecha por la asignación dada, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ|. (Pues si extrajéramos más de este tipo, la utilidad del agente en este caso sería menor que 1; y si v es la variable que satisface c en la asignación, de modo que o(θv) = ol donde l ocurre en c, entonces al agente le convendría más informar θv en lugar del informe veraz θc, para obtener un resultado que valga |Θ|+1 para él mientras tiene que pagar como máximo |Θ|.) Finalmente, para cualquier cláusula insatisfecha c, según la restricción de IR, el pago máximo que podemos extraer para el tipo correspondiente θc es |Θ| + 1. Se deduce que el pago esperado de nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia de MINSAT. Dado que AMD, que maximiza el pago, es solo un caso especial de AMD para un diseñador egoísta en el que el diseñador no tiene preferencias sobre el resultado elegido, esto implica inmediatamente dificultades para el caso general de AMD para un diseñador egoísta en el que los pagos son posibles. Sin embargo, esto aún no implica dureza para el caso especial donde los pagos no son posibles. Demostraremos la dificultad en este caso en la próxima sección. 5. En esta sección demostramos que es NP-completo diseñar un mecanismo determinista que maximice la expectativa del objetivo del diseñador cuando no son posibles los pagos. Mostramos que este problema es difícil incluso en el entorno de un solo agente, demostrando así de inmediato que es difícil para ambos conceptos de IR, para ambos conceptos de solución. Teorema 2. Sin pagos, el diseño determinista de AMD para un diseñador egoísta es NP-completo, incluso para un solo agente, incluso con una distribución uniforme sobre los tipos. Prueba. Es fácil demostrar que el problema está en NP. Para demostrar la NP-dificultad, reducimos una instancia arbitraria de MINSAT a la siguiente instancia de AMD determinista auto-interesada de un solo agente sin pagos. Sea el conjunto de tipos de agentes Θ = {θc : c ∈ C} ∪ {θv : v ∈ V}, donde C es el conjunto de cláusulas en la instancia de MINSAT, y V es el conjunto de variables. Que la distribución de probabilidad sobre estos tipos sea uniforme. Deje que el conjunto de resultados sea O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L} ∪ {o∗}, donde L es el conjunto de literales, es decir, L = {+v : v ∈ V} ∪ {−v : v ∈ V}. Que la notación v(l) = v denote que v es la variable correspondiente al literal l, es decir, l ∈ {+v, −v}. Deje que l ∈ c denote que el literal l ocurre en la cláusula c. Luego, deje que la función de utilidad de los agentes esté dada por u(θc, ol) = 2 para todo l ∈ L con l ∈ c; u(θc, ol) = −1 para todo l ∈ L con l /∈ c; u(θc, oc) = 2; u(θc, oc) = −1 para todo c ∈ C con c = c; u(θc, o∗) = 1; u(θv, ol) = 1 para todo l ∈ L con v(l) = v; u(θv, ol) = −1 para todo l ∈ L con v(l) = v; u(θv, oc) = −1 para todo c ∈ C; u(θv, o∗) = −1. Que la función objetivo de los diseñadores esté dada por g(o∗ ) = |Θ|+1; g(ol) = |Θ| para todo l ∈ L; g(oc) = |Θ| para todo c ∈ C. El objetivo de la instancia de AMD es G = |Θ| + |C|−K |Θ| , donde K es el objetivo de la instancia de MINSAT. Mostramos que las instancias son equivalentes. Primero, supongamos que hay una solución para la instancia de MINSAT. Que la asignación de valores de verdad a las variables en esta solución esté dada por la función f: V → L (donde v(f(v)) = v para todo v ∈ V). Entonces, para cada v ∈ V, sea o(θv) = of(v). Para cada c ∈ C que se cumpla en la solución MINSAT, sea o(θc) = oc; para cada c ∈ C no satisfecho, sea o(θc) = o∗. Es sencillo comprobar que se cumple la restricción de IR. Ahora verificamos que el agente no tenga incentivos para informar de manera incorrecta. Si el tipo de los agentes es algún θv, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para reportar de manera incorrecta. Si el tipo de los agentes es algún θc donde c es una cláusula satisfecha, nuevamente, está obteniendo la utilidad máxima para ese tipo, por lo que no tiene incentivos para informar de manera incorrecta. El último caso a verificar es cuando el tipo de agentes es algún θc donde c es una cláusula insatisfecha. En este caso, observamos que para ninguno de los tipos, informarlo conduce a un resultado ol para un literal l ∈ c, precisamente porque la cláusula no se satisface en la instancia de MINSAT. Debido a que tampoco ningún tipo conduce al resultado oc, no hay ningún resultado que el mecanismo seleccione que le daría al agente una utilidad mayor a 1 para el tipo θc, y por lo tanto el agente no tiene incentivo para informar falsamente. Esto establece que el agente nunca tiene un incentivo para informar de manera incorrecta. Finalmente, demostramos que se alcanza el objetivo. Si s es el número de cláusulas satisfechas en la solución MINSAT (de modo que s ≤ K), entonces el valor esperado de la función objetivo de los diseñadores es |V||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. Por lo tanto, hay una solución para la instancia AMD. Ahora supongamos que hay una solución para la instancia de AMD, dada por una función de resultado o. Primero, supongamos que existe algún v ∈ V tal que o(θv) /∈ {o+v, o−v}. El único otro resultado que el mecanismo puede elegir bajo la restricción de IR es o0. Esto tiene un valor objetivo de 0, y dado que el valor más alto que la función objetivo alcanza es |Θ| + 1, se sigue que el valor esperado máximo de la función objetivo que se podría obtener es a lo sumo (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, lo que contradice que esta sea una solución para la instancia de AMD. Se deduce que en la solución de la instancia de AMD, para cada v ∈ V, o(θv) ∈ {o+v, o−v}. Podemos interpretar esto como una asignación de valores de verdad a las variables: v se establece como verdadero si o(θv) = o+v, y falso si o(θv) = o-v. Reclamamos que esta tarea es una solución a la instancia de MINSAT. Por lo anterior, para cualquier tipo θv, el valor de la función objetivo en este mecanismo será |Θ|. Para cualquier cláusula c satisfecha por la asignación dada, el valor de la función objetivo en el caso en que el agente informe el tipo θc será como máximo |Θ|. (Esto se debe a que no podemos elegir el resultado o∗ para dicho tipo, ya que en este caso el agente tendría un incentivo para informar θv en su lugar, donde v es la variable que satisface c en la asignación (de modo que o(θv) = ol donde l ocurre en c).) Finalmente, para cualquier cláusula insatisfecha c, el valor máximo que la función objetivo puede alcanzar en el caso en que el agente informa el tipo θc es |Θ| + 1, simplemente porque este es el valor más grande que la función alcanza en cualquier momento. Se deduce que el valor esperado de la función objetivo para nuestro mecanismo es a lo sumo V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ, donde s es el número de cláusulas 137 satisfechas. Dado que nuestro mecanismo logra el objetivo, se sigue que V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, lo cual, mediante simples manipulaciones algebraicas, es equivalente a s ≤ K. Por lo tanto, hay una solución para la instancia MINSAT. Ambos de nuestros resultados de dureza se basaron en la restricción de que el mecanismo debería ser determinista. En la siguiente sección, mostramos que la dificultad del diseño desaparece cuando permitimos la aleatorización en el mecanismo. 6. La aleatorización de AMD para un diseñador interesado en sí mismo es fácil. Ahora mostramos cómo permitir la aleatorización sobre los resultados hace que el problema de AMD auto-interesado sea manejable a través de la programación lineal, para cualquier número constante de agentes. Teorema 3. El AMD aleatorio con interés propio con un número constante de agentes es resoluble en tiempo polinómico mediante programación lineal, tanto con pagos como sin pagos, tanto para IR ex post como ex interim, y tanto para la implementación en estrategias dominantes como para la implementación en equilibrio de Bayes-Nash, incluso si los tipos están correlacionados. Prueba. Dado que los programas lineales pueden resolverse en tiempo polinómico [13], todo lo que necesitamos demostrar es que el número de variables y ecuaciones en nuestro programa es polinomial para cualquier número constante de agentes, es decir, exponencial solo en N. En todo momento, para determinar el tamaño del programa lineal, consideremos T = maxi{|Θi|}. Las variables de nuestro programa lineal serán las probabilidades (p(θ1, θ2, . . . , θN ))(o) (como máximo TN |O| variables) y los pagos πi(θ1, θ2, . . . , θN ) (como máximo NTN variables). (Mostramos el programa lineal para el caso en que los pagos son posibles; el caso sin pagos se obtiene fácilmente de esto simplemente omitiendo todas las variables de pago en el programa, o agregando restricciones adicionales que obliguen a los pagos a ser 0). Primero, mostramos las restricciones de IR. Para el IR ex post, agregamos las siguientes restricciones (como máximo NTN) al LP: • Para cada i ∈ {1, 2, . . . , N}, y para cada (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , agregamos ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0. Para el ex interino IR, agregamos las siguientes restricciones (como máximo NT) al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada θi ∈ Θi, agregamos θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0. Ahora, mostramos las restricciones del concepto de solución. Para la implementación en estrategias dominantes, agregamos las siguientes (a lo sumo NTN+1) restricciones al LP: • Para cada i ∈ {1, 2, . . . , N}, para cada (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ). Finalmente, para la implementación en el equilibrio de Bayes-Nash, agregamos las siguientes (a lo sumo NT2) restricciones al LP: • Para cada i ∈ {1, 2, ..., N}, para cada θi ∈ Θi, y para cada informe de tipo de alternativa ˆθi ∈ Θi, agregamos la restricción θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )). Todo lo que queda por hacer es dar la expresión que el diseñador busca maximizar, que es: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )). Como indicamos, el número de variables y restricciones es exponencial solo en N, por lo tanto, el programa lineal tiene un tamaño polinómico para un número constante de agentes. Por lo tanto, el problema es resoluble en tiempo polinómico. IMPLICACIONES PARA UN PROBLEMA DE DISEÑO DE SUBASTA COMBINATORIA ÓPTIMA En esta sección, demostraremos algunas consecuencias interesantes del problema de diseño de mecanismos automatizados para un diseñador interesado en sí mismo en el diseño de subastas combinatorias óptimas. Considera una <br>subasta combinatoria</br> con un conjunto S de artículos en venta. Para cualquier conjunto B ⊆ S, dejemos que ui(θi, B) sea la utilidad del postor i al recibir el conjunto B cuando el tipo del postor es θi. El problema de diseño de subasta óptima consiste en especificar las reglas de la subasta de manera que se maximice los ingresos esperados para el subastador. (Por el principio de revelación, sin pérdida de generalidad, podemos asumir que la subasta es veraz). El problema de diseño de subasta óptima se resuelve para el caso de un solo artículo mediante la famosa subasta de Myerson [18]. Sin embargo, el diseño de subastas óptimas en subastas combinatorias es un problema de investigación abierto reconocido [3, 25]. El problema está abierto incluso si solo hay dos artículos en venta. (El caso de dos artículos con una forma muy especial de complementariedad y sin sustituibilidad ha sido resuelto recientemente [1].) Supongamos que tenemos disposición libre: los artículos pueden ser desechados sin costo alguno. Además, supongamos que las preferencias de los postores tienen la siguiente estructura: cuando un postor recibe un conjunto de artículos, la utilidad del postor por ese conjunto está determinada únicamente por el mejor artículo en el conjunto. (Enfatizamos que qué artículo es el mejor puede depender del tipo de postor). Definición 10. Se dice que el postor i tiene preferencias solo por lo mejor sobre paquetes de artículos si existe una función vi: Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s). Hacemos la siguiente observación útil en este contexto: no tiene sentido otorgarle a un postor más de un artículo. La razón es que si el postor está informando honestamente, quitarle todos los artículos menos el de mayor valor no perjudicará al postor; y, mediante la disposición gratuita, hacerlo solo reducirá el incentivo para que este postor informe falsamente este tipo, cuando en realidad tiene otro tipo. Ahora demostramos que el problema de diseñar una subasta óptima determinista es NP-completo, mediante una reducción del problema AMD de maximización de pagos. Teorema 4. Dado un problema de diseño de <br>subasta combinatoria</br> óptima bajo preferencias de mejor opción (dado por un conjunto de artículos S y para cada postor i, un espacio de tipos finitos Θi y una función vi : Θi × S → R tal que para cualquier θi ∈ Θi, para cualquier B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), diseñar la subasta determinística óptima es NP-completo, incluso para un único postor con una distribución uniforme sobre los tipos. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "revenue maximization": {
            "translated_key": "maximización de ingresos",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Self-interested Automated Mechanism Design and Implications for Optimal Combinatorial Auctions∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA conitzer@cs.cmu.edu Tuomas Sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA sandholm@cs.cmu.edu ABSTRACT Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently proposed approach-called automated mechanism design-a mechanism is computed for the preference aggregation setting at hand.",
                "This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike the earlier work on automated mechanism design that studied a benevolent designer, in this paper we study automated mechanism design problems where the designer is self-interested.",
                "In this case, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we show that designing optimal deterministic mechanisms is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "We then show how allowing for randomization in the mechanism makes problems in this setting computationally easy.",
                "Finally, we show that the payment-maximizing AMD problem is closely related to an interesting variant of the optimal (revenuemaximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We show that here, too, designing an optimal deterministic auction is NPcomplete, but designing an optimal randomized auction is easy.",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In multiagent settings, often an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "Such outcomes could be potential presidents, joint plans, allocations of goods or resources, etc.",
                "The preference aggregator generally does not know the agents preferences a priori.",
                "Rather, the agents report their preferences to the coordinator.",
                "Unfortunately, an agent may have an incentive to misreport its preferences in order to mislead the mechanism into selecting an outcome that is more desirable to the agent than the outcome that would be selected if the agent revealed its preferences truthfully.",
                "Such manipulation is undesirable because preference aggregation mechanisms are tailored to aggregate preferences in a socially desirable way, and if the agents reveal their preferences insincerely, a socially undesirable outcome may be chosen.",
                "Manipulability is a pervasive problem across preference aggregation mechanisms.",
                "A seminal negative result, the Gibbard-Satterthwaite theorem, shows that under any nondictatorial preference aggregation scheme, if there are at least 3 possible outcomes, there are preferences under which an agent is better off reporting untruthfully [10, 23]. (A preference aggregation scheme is called dictatorial if one of the agents dictates the outcome no matter what preferences the other agents report.)",
                "What the aggregator would like to do is design a preference aggregation mechanism so that 1) the self-interested agents are motivated to report their preferences truthfully, and 2) the mechanism chooses an outcome that is desirable from the perspective of some objective.",
                "This is the classic setting of mechanism design in game theory.",
                "In this paper, we study the case where the designer is self-interested, that is, the designer does not directly care about how the out132 come relates to the agents preferences, but is rather concerned with its own agenda for which outcome should be chosen, and with maximizing payments to itself.",
                "This is the mechanism design setting most relevant to electronic commerce.",
                "In the case where the mechanism designer is interested in maximizing some notion of social welfare, the importance of collecting the agents preferences is clear.",
                "It is perhaps less obvious why they should be collected when the designer is self-interested and hence its objective is not directly related to the agents preferences.",
                "The reason for this is that often the agents preferences impose limits on how the designer chooses the outcome and payments.",
                "The most common such constraint is that of individual rationality (IR), which means that the mechanism cannot make any agent worse off than the agent would have been had it not participated in the mechanism.",
                "For instance, in the setting of optimal auction design, the designer (auctioneer) is only concerned with how much revenue is collected, and not per se with how well the allocation of the good (or goods) corresponds to the agents preferences.",
                "Nevertheless, the designer cannot force an agent to pay more than its valuation for the bundle of goods allocated to it.",
                "Therefore, even a self-interested designer will choose an outcome that makes the agents reasonably well off.",
                "On the other hand, the designer will not necessarily choose a social welfare maximizing outcome.",
                "For example, if the designer always chooses an outcome that maximizes social welfare with respect to the reported preferences, and forces each agent to pay the difference between the utility it has now and the utility it would have had if it had not participated in the mechanism, it is easy to see that agents may have an incentive to misreport their preferences-and this may actually lead to less revenue being collected.",
                "Indeed, one of the counterintuitive results of optimal auction design theory is that sometimes the good is allocated to nobody even when the auctioneer has a reservation price of 0.",
                "Classical mechanism design provides some general mechanisms, which, under certain assumptions, satisfy some notion of nonmanipulability and maximize some objective.",
                "The upside of these mechanisms is that they do not rely on (even probabilistic) information about the agents preferences (e.g., the Vickrey-Clarke-Groves (VCG) mechanism [24, 4, 11]), or they can be easily applied to any probability distribution over the preferences (e.g., the dAGVA mechanism [8, 2], the Myerson auction [18], and the Maskin-Riley multi-unit auction [17]).",
                "However, the general mechanisms also have significant downsides: • The most famous and most broadly applicable general mechanisms, VCG and dAGVA, only maximize social welfare.",
                "If the designer is self-interested, as is the case in many electronic commerce settings, these mechanisms do not maximize the designers objective. • The general mechanisms that do focus on a selfinterested designer are only applicable in very restricted settings-such as Myersons expected revenue maximizing auction for selling a single item, and Maskin and Rileys expected revenue maximizing auction for selling multiple identical units of an item. • Even in the restricted settings in which these mechanisms apply, the mechanisms only allow for payment maximization.",
                "In practice, the designer may also be interested in the outcome per se.",
                "For example, an auctioneer may care which bidder receives the item. • It is often assumed that side payments can be used to tailor the agents incentives, but this is not always practical.",
                "For example, in barter-based electronic marketplaces-such as Recipco, firstbarter.com, BarterOne, and Intagio-side payments are not allowed.",
                "Furthermore, among software agents, it might be more desirable to construct mechanisms that do not rely on the ability to make payments, because many software agents do not have the infrastructure to make payments.",
                "In contrast, we follow a recent approach where the mechanism is designed automatically for the specific problem at hand.",
                "This approach addresses all of the downsides listed above.",
                "We formulate the mechanism design problem as an optimization problem.",
                "The input is characterized by the number of agents, the agents possible types (preferences), and the aggregators prior distributions over the agents types.",
                "The output is a nonmanipulable mechanism that is optimal with respect to some objective.",
                "This approach is called automated mechanism design.",
                "The automated mechanism design approach has four advantages over the classical approach of designing general mechanisms.",
                "First, it can be used even in settings that do not satisfy the assumptions of the classical mechanisms (such as availability of side payments or that the objective is social welfare).",
                "Second, it may allow one to circumvent impossibility results (such as the Gibbard-Satterthwaite theorem) which state that there is no mechanism that is desirable across all preferences.",
                "When the mechanism is designed for the setting at hand, it does not matter that it would not work more generally.",
                "Third, it may yield better mechanisms (in terms of stronger nonmanipulability guarantees and/or better outcomes) than classical mechanisms because the mechanism capitalizes on the particulars of the setting (the probabilistic information that the designer has about the agents types).",
                "Given the vast amount of information that parties have about each other today, this approach is likely to lead to tremendous savings over classical mechanisms, which largely ignore that information.",
                "For example, imagine a company automatically creating its procurement mechanism based on statistical knowledge about its suppliers, rather than using a classical descending procurement auction.",
                "Fourth, the burden of design is shifted from humans to a machine.",
                "However, automated mechanism design requires the mechanism design optimization problem to be solved anew for each setting.",
                "Hence its computational complexity becomes a key issue.",
                "Previous research has studied this question for benevolent designers-that wish to maximize, for example, social welfare [5, 6].",
                "In this paper we study the computational complexity of automated mechanism design in the case of a self-interested designer.",
                "This is an important setting for automated mechanism design due to the shortage of general mechanisms in this area, and the fact that in most e-commerce settings the designer is self-interested.",
                "We also show that this problem is closely related to a particular optimal (revenue-maximizing) combinatorial auction design problem. 133 The rest of this paper is organized as follows.",
                "In Section 2, we justify the focus on nonmanipulable mechanisms.",
                "In Section 3, we define the problem we study.",
                "In Section 4, we show that designing an optimal deterministic mechanism is NP-complete even when the designer only cares about the payments made to it.",
                "In Section 5, we show that designing an optimal deterministic mechanism is also NP-complete when payments are not possible and the designer is only interested in the outcome chosen.",
                "In Section 6, we show that an optimal randomized mechanism can be designed in polynomial time even in the general case.",
                "Finally, in Section 7, we show that for designing optimal combinatorial auctions under best-only preferences, our results on AMD imply that this problem is NP-complete for deterministic auctions, but easy for randomized auctions. 2.",
                "JUSTIFYING THE FOCUS ON NONMANIPULABLE MECHANISMS Before we define the computational problem of automated mechanism design, we should justify our focus on nonmanipulable mechanisms.",
                "After all, it is not immediately obvious that there are no manipulable mechanisms that, even when agents report their types strategically and hence sometimes untruthfully, still reach better outcomes (according to whatever objective we use) than any nonmanipulable mechanism.",
                "This does, however, turn out to be the case: given any mechanism, we can construct a nonmanipulable mechanism whose performance is identical, as follows.",
                "We build an interface layer between the agents and the original mechanism.",
                "The agents report their preferences (or types) to the interface layer; subsequently, the interface layer inputs into the original mechanism the types that the agents would have strategically reported to the original mechanism, if their types were as declared to the interface layer.",
                "The resulting outcome is the outcome of the new mechanism.",
                "Since the interface layer acts strategically on each agents behalf, there is never an incentive to report falsely to the interface layer; and hence, the types reported by the interface layer are the strategic types that would have been reported without the interface layer, so the results are exactly as they would have been with the original mechanism.",
                "This argument is known in the mechanism design literature as the revelation principle [16]. (There are computational difficulties with applying the revelation principle in large combinatorial outcome and type spaces [7, 22].",
                "However, because here we focus on flatly represented outcome and type spaces, this is not a concern here.)",
                "Given this, we can focus on truthful mechanisms in the rest of the paper. 3.",
                "DEFINITIONS We now formalize the automated mechanism design setting.",
                "Definition 1.",
                "In an automated mechanism design setting, we are given: • a finite set of outcomes O; • a finite set of N agents; • for each agent i, 1. a finite set of types Θi, 2. a probability distribution γi over Θi (in the case of correlated types, there is a single joint distribution γ over Θ1 × . . . × ΘN ), and 3. a utility function ui : Θi × O → R; 1 • An objective function whose expectation the designer wishes to maximize.",
                "There are many possible objective functions the designer might have, for example, social welfare (where the designer seeks to maximize the sum of the agents utilities), or the minimum utility of any agent (where the designer seeks to maximize the worst utility had by any agent).",
                "In both of these cases, the designer is benevolent, because the designer, in some sense, is pursuing the agents collective happiness.",
                "However, in this paper, we focus on the case of a self-interested designer.",
                "A self-interested designer cares only about the outcome chosen (that is, the designer does not care how the outcome relates to the agents preferences, but rather has a fixed preference over the outcomes), and about the net payments made by the agents, which flow to the designer.",
                "Definition 2.",
                "A self-interested designer has an objective function given by g(o) + N i=1 πi, where g : O → R indicates the designers own preference over the outcomes, and πi is the payment made by agent i.",
                "In the case where g = 0 everywhere, the designer is said to be payment maximizing.",
                "In the case where payments are not possible, g constitutes the objective function by itself.",
                "We now define the kinds of mechanisms under study.",
                "By the revelation principle, we can restrict attention to truthful, direct revelation mechanisms, where agents report their types directly and never have an incentive to misreport them.",
                "Definition 3.",
                "We consider the following kinds of mechanism: • A deterministic mechanism without payments consists of an outcome selection function o : Θ1 × Θ2 × . . . × ΘN → O. • A randomized mechanism without payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), where P(O) is the set of probability distributions over O. • A deterministic mechanism with payments consists of an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN → O and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN ) gives the payment made by agent i when the reported types are θ1, . . . , θN . 1 Though this follows standard game theory notation [16], the fact that the agent has both a utility function and a type is perhaps confusing.",
                "The types encode the various possible preferences that the agent may turn out to have, and the agents type is not known to the aggregator.",
                "The utility function is common knowledge, but because the agents type is a parameter in the agents utility function, the aggregator cannot know what the agents utility is without knowing the agents type. 134 • A randomized mechanism with payments consists of a distribution selection function p : Θ1 × Θ2 × . . . × ΘN → P(O), and for each agent i, a payment selection function πi : Θ1 × Θ2 × . . . × ΘN → R.2 There are two types of constraint on the designer in building the mechanism. 3.1 Individual rationality (IR) constraints The first type of constraint is the following.",
                "The utility of each agent has to be at least as great as the agents fallback utility, that is, the utility that the agent would receive if it did not participate in the mechanism.",
                "Otherwise that agent would not participate in the mechanism-and no agents participation can ever hurt the mechanism designers objective because at worst, the mechanism can ignore an agent by pretending the agent is not there. (Furthermore, if no such constraint applied, the designer could simply make the agents pay an infinite amount.)",
                "This type of constraint is called an IR (individual rationality) constraint.",
                "There are three different possible IR constraints: ex ante, ex interim, and ex post, depending on what the agent knows about its own type and the others types when deciding whether to participate in the mechanism.",
                "Ex ante IR means that the agent would participate if it knew nothing at all (not even its own type).",
                "We will not study this concept in this paper.",
                "Ex interim IR means that the agent would always participate if it knew only its own type, but not those of the others.",
                "Ex post IR means that the agent would always participate even if it knew everybodys type.",
                "We will define the latter two notions of IR formally.",
                "First, we need to formalize the concept of the fallback outcome.",
                "We assume that each agents fallback utility is zero for each one of its types.",
                "This is without loss of generality because we can add a constant term to an agents utility function (for a given type), without affecting the decision-making behavior of that expected utility maximizing agent [16].",
                "Definition 4.",
                "In any automated mechanism design setting with an IR constraint, there is a fallback outcome o0 ∈ O where, for any agent i and any type θi ∈ Θi, we have ui(θi, o0) = 0. (Additionally, in the case of a self-interested designer, g(o0) = 0.)",
                "We can now to define the notions of individual rationality.",
                "Definition 5.",
                "Individual rationality (IR) is defined by: • A deterministic mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )] ≥ 0.",
                "A randomized mechanism is ex interim IR if for any agent i, and any type θi ∈ Θi, we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )] ≥ 0. • A deterministic mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥ 0. 2 We do not randomize over payments because as long as the agents and the designer are risk neutral with respect to payments, that is, their utility is linear in payments, there is no reason to randomize over payments.",
                "A randomized mechanism is ex post IR if for any agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN , we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.",
                "The terms involving payments can be left out in the case where payments are not possible. 3.2 Incentive compatibility (IC) constraints The second type of constraint says that the agents should never have an incentive to misreport their type (as justified above by the revelation principle).",
                "For this type of constraint, the two most common variants (or solution concepts) are implementation in dominant strategies, and implementation in Bayes-Nash equilibrium.",
                "Definition 6.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in dominant strategies if truthtelling is always optimal even when the types reported by the other agents are already known.",
                "Formally, for any agent i, any type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN , and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥ ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).",
                "In the case of randomized mechanisms we have Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥ Eo|θ1,.., ˆθi,..,θn [ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible.",
                "Thus, in dominant strategies implementation, truthtelling is optimal regardless of what the other agents report.",
                "If it is optimal only given that the other agents are truthful, and given that one does not know the other agents types, we have implementation in Bayes-Nash equilibrium.",
                "Definition 7.",
                "Given an automated mechanism design setting, a mechanism is said to implement its outcome and payment functions in Bayes-Nash equilibrium if truthtelling is always optimal to an agent when that agent does not yet know anything about the other agents types, and the other agents are telling the truth.",
                "Formally, for any agent i, any type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the case of deterministic mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , θi, . . . , θN ))− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi [ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "In the case of randomized mechanisms we have E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,..,θi,..,θn [ui(θi, o)− πi(θ1, . . . , θi, . . . , θN )] ≥ E(θ1,..,θi−1,θi+1,..,θN )|θi Eo|θ1,.., ˆθi,..,θn [ui(θi, o)− πi(θ1, . . . , ˆθi, . . . , θN )].",
                "The terms involving payments can be left out in the case where payments are not possible. 135 3.3 Automated mechanism design We can now define the computational problem we study.",
                "Definition 8. (AUTOMATED-MECHANISM-DESIGN (AMD)) We are given: • an automated mechanism design setting, • an IR notion (ex interim, ex post, or none), • a solution concept (dominant strategies or Bayes-Nash), • whether payments are possible, • whether randomization is possible, • (in the decision variant of the problem) a target value G. We are asked whether there exists a mechanism of the specified kind (in terms of payments and randomization) that satisfies both the IR notion and the solution concept, and gives an expected value of at least G for the objective.",
                "An interesting special case is the setting where there is only one agent.",
                "In this case, the reporting agent always knows everything there is to know about the other agents types-because there are no other agents.",
                "Since ex post and ex interim IR only differ on what an agent is assumed to know about other agents types, the two IR concepts coincide here.",
                "Also, because implementation in dominant strategies and implementation in Bayes-Nash equilibrium only differ on what an agent is assumed to know about other agents types, the two solution concepts coincide here.",
                "This observation will prove to be a useful tool in proving hardness results: if we prove computational hardness in the singleagent setting, this immediately implies hardness for both IR concepts, for both solution concepts, for any number of agents. 4.",
                "PAYMENT-MAXIMIZINGDETERMINISTIC AMD IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expected sum of the payments collected from the agents.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "To demonstrate NPhardness, we reduce from the MINSAT problem.",
                "Definition 9 (MINSAT).",
                "We are given a formula φ in conjunctive normal form, represented by a set of Boolean variables V and a set of clauses C, and an integer K (K < |C|).",
                "We are asked whether there exists an assignment to the variables in V such that at most K clauses in φ are satisfied.",
                "MINSAT was recently shown to be NP-complete [14].",
                "We can now present our result.",
                "Theorem 1.",
                "Payment-maximizing deterministic AMD is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent payment-maximizing deterministic AMD instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C} ∪ {ol : l ∈ L}, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = |Θ| + 1 for all l ∈ L with l ∈ c; u(θc, ol) = 0 for all l ∈ L with l /∈ c; u(θc, oc) = |Θ| + 1; u(θc, oc ) = 0 for all c ∈ C with c = c ; u(θv, ol) = |Θ| for all l ∈ L with v(l) = v; u(θv, ol) = 0 for all l ∈ L with v(l) = v; u(θv, oc) = 0 for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v) and π(θv) = |Θ|.",
                "For every c ∈ C, let o(θc) = oc; let π(θc) = |Θ| + 1 if c is not satisfied in the MINSAT solution, and π(θc) = |Θ| if c is satisfied.",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, then any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, any other report will give it an outcome that is no better, for a payment that is no less, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type besides θc leads to the outcome oc, reporting any other type will give an outcome with utility 0, while still forcing a payment of at least |Θ| from the agent.",
                "Clearly the agent is better off reporting truthfully, for a total utility of 0.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), the expected payment from this mechanism is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o and a payment function π.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "Then the utility that the agent derives from the given outcome for this type is 0, and hence, by IR, no payment can be extracted from the agent for this type.",
                "Because, again by IR, the maximum payment that can be extracted for any other type is |Θ| + 1, it follows that the maximum expected payment that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}. 136 We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the IR constraint, the maximum payment we can extract from any type θv is |Θ|.",
                "Because there can be no incentives for the agent to report falsely, for any clause c satisfied by the given assignment, the maximum payment we can extract for the corresponding type θc is |Θ|. (For if we extracted more from this type, the agents utility in this case would be less than 1; and if v is the variable satisfying c in the assignment, so that o(θv) = ol where l occurs in c, then the agent would be better off reporting θv instead of the truthful report θc, to get an outcome worth |Θ|+1 to it while having to pay at most |Θ|.)",
                "Finally, for any unsatisfied clause c, by the IR constraint, the maximum payment we can extract for the corresponding type θc is |Θ| + 1.",
                "It follows that the expected payment from our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Because payment-maximizing AMD is just the special case of AMD for a self-interested designer where the designer has no preferences over the outcome chosen, this immediately implies hardness for the general case of AMD for a selfinterested designer where payments are possible.",
                "However, it does not yet imply hardness for the special case where payments are not possible.",
                "We will prove hardness in this case in the next section. 5.",
                "SELF-INTERESTED DETERMINISTIC AMD WITHOUT PAYMENTS IS HARD In this section we demonstrate that it is NP-complete to design a deterministic mechanism that maximizes the expectation of the designers objective when payments are not possible.",
                "We show that this problem is hard even in the single-agent setting, thereby immediately showing it hard for both IR concepts, for both solution concepts.",
                "Theorem 2.",
                "Without payments, deterministic AMD for a self-interested designer is NP-complete, even for a single agent, even with a uniform distribution over types.",
                "Proof.",
                "It is easy to show that the problem is in NP.",
                "To show NP-hardness, we reduce an arbitrary MINSAT instance to the following single-agent self-interested deterministic AMD without payments instance.",
                "Let the agents type set be Θ = {θc : c ∈ C} ∪ {θv : v ∈ V }, where C is the set of clauses in the MINSAT instance, and V is the set of variables.",
                "Let the probability distribution over these types be uniform.",
                "Let the outcome set be O = {o0} ∪ {oc : c ∈ C}∪{ol : l ∈ L}∪{o∗ }, where L is the set of literals, that is, L = {+v : v ∈ V } ∪ {−v : v ∈ V }.",
                "Let the notation v(l) = v denote that v is the variable corresponding to the literal l, that is, l ∈ {+v, −v}.",
                "Let l ∈ c denote that the literal l occurs in clause c. Then, let the agents utility function be given by u(θc, ol) = 2 for all l ∈ L with l ∈ c; u(θc, ol) = −1 for all l ∈ L with l /∈ c; u(θc, oc) = 2; u(θc, oc ) = −1 for all c ∈ C with c = c ; u(θc, o∗ ) = 1; u(θv, ol) = 1 for all l ∈ L with v(l) = v; u(θv, ol) = −1 for all l ∈ L with v(l) = v; u(θv, oc) = −1 for all c ∈ C; u(θv, o∗ ) = −1.",
                "Let the designers objective function be given by g(o∗ ) = |Θ|+1; g(ol) = |Θ| for all l ∈ L; g(oc) = |Θ| for all c ∈ C. The goal of the AMD instance is G = |Θ| + |C|−K |Θ| , where K is the goal of the MINSAT instance.",
                "We show the instances are equivalent.",
                "First, suppose there is a solution to the MINSAT instance.",
                "Let the assignment of truth values to the variables in this solution be given by the function f : V → L (where v(f(v)) = v for all v ∈ V ).",
                "Then, for every v ∈ V , let o(θv) = of(v).",
                "For every c ∈ C that is satisfied in the MINSAT solution, let o(θc) = oc; for every unsatisfied c ∈ C, let o(θc) = o∗ .",
                "It is straightforward to check that the IR constraint is satisfied.",
                "We now check that the agent has no incentive to misreport.",
                "If the agents type is some θv, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "If the agents type is some θc where c is a satisfied clause, again, it is getting the maximum utility for that type, so it has no incentive to misreport.",
                "The final case to check is where the agents type is some θc where c is an unsatisfied clause.",
                "In this case, we observe that for none of the types, reporting it leads to an outcome ol for a literal l ∈ c, precisely because the clause is not satisfied in the MINSAT instance.",
                "Because also, no type leads to the outcome oc, there is no outcome that the mechanism ever selects that would give the agent utility greater than 1 for type θc, and hence the agent has no incentive to report falsely.",
                "This establishes that the agent never has an incentive to misreport.",
                "Finally, we show that the goal is reached.",
                "If s is the number of satisfied clauses in the MINSAT solution (so that s ≤ K), then the expected value of the designers objective function is |V ||Θ|+s|Θ|+(|C|−s)(|Θ|+1) |Θ| ≥ |V ||Θ|+K|Θ|+(|C|−K)(|Θ|+1) |Θ| = |Θ| + |C|−K |Θ| = G. So there is a solution to the AMD instance.",
                "Now suppose there is a solution to the AMD instance, given by an outcome function o.",
                "First, suppose there is some v ∈ V such that o(θv) /∈ {o+v, o−v}.",
                "The only other outcome that the mechanism is allowed to choose under the IR constraint is o0.",
                "This has an objective value of 0, and because the highest value the objective function ever takes is |Θ| + 1, it follows that the maximum expected value of the objective function that could be obtained is at most (|Θ|−1)(|Θ|+1) |Θ| < |Θ| < G, contradicting that this is a solution to the AMD instance.",
                "It follows that in the solution to the AMD instance, for every v ∈ V , o(θv) ∈ {o+v, o−v}.",
                "We can interpret this as an assignment of truth values to the variables: v is set to true if o(θv) = o+v, and to false if o(θv) = o−v.",
                "We claim this assignment is a solution to the MINSAT instance.",
                "By the above, for any type θv, the value of the objective function in this mechanism will be |Θ|.",
                "For any clause c satisfied by the given assignment, the value of the objective function in the case where the agent reports type θc will be at most |Θ|. (This is because we cannot choose the outcome o∗ for such a type, as in this case the agent would have an incentive to report θv instead, where v is the variable satisfying c in the assignment (so that o(θv) = ol where l occurs in c).)",
                "Finally, for any unsatisfied clause c, the maximum value the objective function can take in the case where the agent reports type θc is |Θ| + 1, simply because this is the largest value the function ever takes.",
                "It follows that the expected value of the objective function for our mechanism is at most V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ , where s is the number of satisfied 137 clauses.",
                "Because our mechanism achieves the goal, it follows that V |Θ|+s|Θ|+(|C|−s)(|Θ|+1) Θ ≥ G, which by simple algebraic manipulations is equivalent to s ≤ K. So there is a solution to the MINSAT instance.",
                "Both of our hardness results relied on the constraint that the mechanism should be deterministic.",
                "In the next section, we show that the hardness of design disappears when we allow for randomization in the mechanism. 6.",
                "RANDOMIZED AMD FOR A SELFINTERESTED DESIGNER IS EASY We now show how allowing for randomization over the outcomes makes the problem of self-interested AMD tractable through linear programming, for any constant number of agents.",
                "Theorem 3.",
                "Self-interested randomized AMD with a constant number of agents is solvable in polynomial time by linear programming, both with and without payments, both for ex post and ex interim IR, and both for implementation in dominant strategies and for implementation in Bayes-Nash equilibrium-even if the types are correlated.",
                "Proof.",
                "Because linear programs can be solved in polynomial time [13], all we need to show is that the number of variables and equations in our program is polynomial for any constant number of agents-that is, exponential only in N. Throughout, for purposes of determining the size of the linear program, let T = maxi{|Θi|}.",
                "The variables of our linear program will be the probabilities (p(θ1, θ2, . . . , θN ))(o) (at most TN |O| variables) and the payments πi(θ1, θ2, . . . , θN ) (at most NTN variables). (We show the linear program for the case where payments are possible; the case without payments is easily obtained from this by simply omitting all the payment variables in the program, or by adding additional constraints forcing the payments to be 0.)",
                "First, we show the IR constraints.",
                "For ex post IR, we add the following (at most NTN ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, and for every (θ1, θ2, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , we add ( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θN ) ≥ 0.",
                "For ex interim IR, we add the following (at most NT) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every θi ∈ Θi, we add θ1,... ,θN γ(θ1, . . . , θN |θi)(( o∈O (p(θ1, θ2, . . . , θN ))(o)u(θi, o))− πi(θ1, θ2, . . . , θN )) ≥ 0.",
                "Now, we show the solution concept constraints.",
                "For implementation in dominant strategies, we add the following (at most NTN+1 ) constraints to the LP: • For every i ∈ {1, 2, . . . , N}, for every (θ1, θ2, . . . , θi, . . . , θN ) ∈ Θ1 × Θ2 × . . . × ΘN , and for every alternative type report ˆθi ∈ Θi, we add the constraint ( o∈O (p(θ1, θ2, . . . , θi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , θi, . . . , θN ) ≥ ( o∈O (p(θ1, θ2, . . . , ˆθi, . . . , θN ))(o)u(θi, o)) − πi(θ1, θ2, . . . , ˆθi, . . . , θN ).",
                "Finally, for implementation in Bayes-Nash equilibrium, we add the following (at most NT2 ) constraints to the LP: • For every i ∈ {1, 2, ..., N}, for every θi ∈ Θi, and for every alternative type report ˆθi ∈ Θi, we add the constraint θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., θi, ..., θN )) ≥ θ1,...,θN γ(θ1, ..., θN |θi)(( o∈O (p(θ1, θ2, ..., ˆθi, ..., θN ))(o)u(θi, o)) − πi(θ1, θ2, ..., ˆθi, ..., θN )).",
                "All that is left to do is to give the expression the designer is seeking to maximize, which is: • θ1,...,θN γ(θ1, ..., θN )(( o∈O (p(θ1, θ2, ..., θi, ..., θN ))(o)g(o)) + N i=1 πi(θ1, θ2, ..., θN )).",
                "As we indicated, the number of variables and constraints is exponential only in N, and hence the linear program is of polynomial size for constant numbers of agents.",
                "Thus the problem is solvable in polynomial time. 7.",
                "IMPLICATIONS FOR AN OPTIMAL COMBINATORIAL AUCTION DESIGN PROBLEM In this section, we will demonstrate some interesting consequences of the problem of automated mechanism design for a self-interested designer on designing optimal combinatorial auctions.",
                "Consider a combinatorial auction with a set S of items for sale.",
                "For any bundle B ⊆ S, let ui(θi, B) be bidder is utility for receiving bundle B when the bidders type is θi.",
                "The optimal auction design problem is to specify the rules of the auction so as to maximize expected revenue to the auctioneer. (By the revelation principle, without loss of generality, we can assume the auction is truthful.)",
                "The optimal auction design problem is solved for the case of a single item by the famous Myerson auction [18].",
                "However, designing optimal auctions in combinatorial auctions is a recognized open research problem [3, 25].",
                "The problem is open even if there are only two items for sale. (The twoitem case with a very special form of complementarity and no substitutability has been solved recently [1].)",
                "Suppose we have free disposal-items can be thrown away at no cost.",
                "Also, suppose that the bidders preferences have the following structure: whenever a bidder receives a bundle of items, the bidders utility for that bundle is determined by the best item in the bundle only. (We emphasize that 138 which item is the best is allowed to depend on the bidders type.)",
                "Definition 10.",
                "Bidder i is said to have best-only preferences over bundles of items if there exists a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s).",
                "We make the following useful observation in this setting: there is no sense in awarding a bidder more than one item.",
                "The reason is that if the bidder is reporting truthfully, taking all but the highest valued item away from the bidder will not hurt the bidder; and, by free disposal, doing so can only reduce the incentive for this bidder to falsely report this type, when the bidder actually has another type.",
                "We now show that the problem of designing a deterministic optimal auction here is NP-complete, by a reduction from the payment maximizing AMD problem!",
                "Theorem 4.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), designing the optimal deterministic auction is NP-complete, even for a single bidder with a uniform distribution over types.",
                "Proof.",
                "The problem is in NP because we can nondeterministically generate an allocation rule, and then set the payments using linear programming.",
                "To show NP-hardness, we reduce an arbitrary paymentmaximizing deterministic AMD instance, with a single agent and a uniform distribution over types, to the following optimal combinatorial auction design problem instance with a single bidder with best-only preferences.",
                "For every outcome o ∈ O in the AMD instance (besides the outcome o0), let there be one item so ∈ S. Let the type space be the same, and let v(θi, so) = ui(θi, o) (where u is as specified in the AMD instance).",
                "Let the expected revenue target value be the same in both instances.",
                "We show the instances are equivalent.",
                "First suppose there exists a solution to the AMD instance, given by an outcome function and a payment function.",
                "Then, if the AMD solution chooses outcome o for a type, in the optimal auction solution, allocate {so} to the bidder for this type. (Unless o = o0, in which case we allocate {} to the bidder.)",
                "Let the payment functions be the same in both instances.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the optimal auction solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the auctioneer/designer is the same.",
                "It follows that there exists a solution to the optimal auction design instance.",
                "Now suppose there exists a solution to the optimal auction design instance.",
                "By the at-most-one-item observation, we can assume without loss of generality that the solution never allocates more than one item.",
                "Then, if the optimal auction solution allocates item so to the bidder for a type, in the AMD solution, let the mechanism choose outcome o for that type.",
                "If the optimal auction solution allocates nothing to the bidder for a type, in the AMD solution, let the mechanism choose outcome o0 for that type.",
                "Let the payment functions be the same.",
                "Then, the utility that an agent receives for reporting a type (given the true type) in either solution is the same, so we have incentive compatibility in the AMD solution.",
                "Moreover, because the type distribution and the payment function are the same, the expected revenue to the designer/auctioneer is the same.",
                "It follows that there exists a solution to the AMD instance.",
                "Fortunately, we can also carry through the easiness result for randomized mechanisms to this combinatorial auction setting-giving us one of the few known polynomial-time algorithms for an optimal combinatorial auction design problem.",
                "Theorem 5.",
                "Given an optimal combinatorial auction design problem under best-only preferences (given by a set of items S and for each bidder i, a finite type space Θi and a function vi : Θi × S → R such that for any θi ∈ Θi, for any B ⊆ S, ui(θi, B) = maxs∈B vi(θi, s)), if the number of bidders is a constant k, then the optimal randomized auction can be designed in polynomial time. (For any IC and IR constraints.)",
                "Proof.",
                "By the at-most-one-item observation, we can without loss of generality restrict ourselves to allocations where each bidder receives at most one item.",
                "There are fewer than (|S| + 1)k such allocations-that is, a polynomial number of allocations.",
                "Because we can list the outcomes explicitly, we can simply solve this as a payment-maximizing AMD instance, with linear programming. 8.",
                "RELATED RESEARCH ON COMPLEXITY IN MECHANISM DESIGN There has been considerable recent interest in mechanism design in computer science.",
                "Some of it has focused on issues of computational complexity, but most of that work has strived toward designing mechanisms that are easy to execute (e.g. [20, 15, 19, 9, 12]), rather than studying the complexity of designing the mechanism.",
                "The closest piece of earlier work studied the complexity of automated mechanism design by a benevolent designer [5, 6].",
                "Roughgarden has studied the complexity of designing a good network topology for agents that selfishly choose the links they use [21].",
                "This is related to mechanism design, but differs significantly in that the designer only has restricted control over the rules of the game because there is no party that can impose the outcome (or side payments).",
                "Also, there is no explicit reporting of preferences. 9.",
                "CONCLUSIONS AND FUTURE RESEARCH Often, an outcome must be chosen on the basis of the preferences reported by a group of agents.",
                "The key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves.",
                "Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully, and a desirable outcome is chosen.",
                "In a recently emerging approach-called automated mechanism design-a mechanism is computed for the specific preference aggregation setting at hand.",
                "This has several advantages, 139 but the downside is that the mechanism design optimization problem needs to be solved anew each time.",
                "Unlike earlier work on automated mechanism design that studied a benevolent designer, in this paper we studied automated mechanism design problems where the designer is self-interesteda setting much more relevant for electronic commerce.",
                "In this setting, the center cares only about which outcome is chosen and what payments are made to it.",
                "The reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism.",
                "In this setting, we showed that designing an optimal deterministic mechanism is NP-complete in two important special cases: when the center is interested only in the payments made to it, and when payments are not possible and the center is interested only in the outcome chosen.",
                "These hardness results imply hardness in all more general automated mechanism design settings with a self-interested designer.",
                "The hardness results apply whether the individual rationality (participation) constraints are applied ex interim or ex post, and whether the solution concept is dominant strategies implementation or Bayes-Nash equilibrium implementation.",
                "We then showed that allowing randomization in the mechanism makes the design problem in all these settings computationally easy.",
                "Finally, we showed that the paymentmaximizing AMD problem is closely related to an interesting variant of the optimal (revenue-maximizing) combinatorial auction design problem, where the bidders have best-only preferences.",
                "We showed that here, too, designing an optimal deterministic mechanism is NP-complete even with one agent, but designing an optimal randomized mechanism is easy.",
                "Future research includes studying automated mechanism design with a self-interested designer in more restricted settings such as auctions (where the designers objective may include preferences about which bidder should receive the good-as well as payments).",
                "We also want to study the complexity of automated mechanism design in settings where the outcome and type spaces have special structure so they can be represented more concisely.",
                "Finally, we plan to assemble a data set of real-world mechanism design problems-both historical and current-and apply automated mechanism design to those problems. 10.",
                "REFERENCES [1] M. Armstrong.",
                "Optimal multi-object auctions.",
                "Review of Economic Studies, 67:455-481, 2000. [2] K. Arrow.",
                "The property rights doctrine and demand revelation under incomplete information.",
                "In M. Boskin, editor, Economics and human welfare.",
                "New York Academic Press, 1979. [3] C. Avery and T. Hendershott.",
                "Bundling and optimal auctions of multiple products.",
                "Review of Economic Studies, 67:483-497, 2000. [4] E. H. Clarke.",
                "Multipart pricing of public goods.",
                "Public Choice, 11:17-33, 1971. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI-02), pages 103-110, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Automated mechanism design: Complexity results stemming from the single-agent setting.",
                "In Proceedings of the 5th International Conference on Electronic Commerce (ICEC-03), pages 17-24, Pittsburgh, PA, USA, 2003. [7] V. Conitzer and T. Sandholm.",
                "Computational criticisms of the revelation principle.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), New York, NY, 2004.",
                "Short paper.",
                "Full-length version appeared in the AAMAS-03 workshop on Agent-Mediated Electronic Commerce (AMEC). [8] C. dAspremont and L. A. G´erard-Varet.",
                "Incentives and incomplete information.",
                "Journal of Public Economics, 11:25-45, 1979. [9] J. Feigenbaum, C. Papadimitriou, and S. Shenker.",
                "Sharing the cost of muliticast transmissions.",
                "Journal of Computer and System Sciences, 63:21-41, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2000. [10] A. Gibbard.",
                "Manipulation of voting schemes.",
                "Econometrica, 41:587-602, 1973. [11] T. Groves.",
                "Incentives in teams.",
                "Econometrica, 41:617-631, 1973. [12] J. Hershberger and S. Suri.",
                "Vickrey prices and shortest paths: What is an edge worth?",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [13] L. Khachiyan.",
                "A polynomial algorithm in linear programming.",
                "Soviet Math.",
                "Doklady, 20:191-194, 1979. [14] R. Kohli, R. Krishnamurthi, and P. Mirchandani.",
                "The minimum satisfiability problem.",
                "SIAM Journal of Discrete Mathematics, 7(2):275-283, 1994. [15] D. Lehmann, L. I. OCallaghan, and Y. Shoham.",
                "Truth revelation in rapid, approximately efficient combinatorial auctions.",
                "Journal of the ACM, 49(5):577-602, 2002.",
                "Early version appeared in Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 1999. [16] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [17] E. S. Maskin and J. Riley.",
                "Optimal multi-unit auctions.",
                "In F. Hahn, editor, The Economics of Missing Markets, Information, and Games, chapter 14, pages 312-335.",
                "Clarendon Press, Oxford, 1989. [18] R. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operation Research, 6:58-73, 1981. [19] N. Nisan and A. Ronen.",
                "Computationally feasible VCG mechanisms.",
                "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), pages 242-252, Minneapolis, MN, 2000. [20] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behavior, 35:166-196, 2001.",
                "Early version in Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 1999. [21] T. Roughgarden.",
                "Designing networks for selfish users is hard.",
                "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2001. [22] T. Sandholm.",
                "Issues in computational Vickrey auctions.",
                "International Journal of Electronic Commerce, 4(3):107-129, 2000.",
                "Special Issue on 140 Applying Intelligent Agents for Electronic Commerce.",
                "A short, early version appeared at the Second International Conference on Multi-Agent Systems (ICMAS), pages 299-306, 1996. [23] M. A. Satterthwaite.",
                "Strategy-proofness and Arrows conditions: existence and correspondence theorems for voting procedures and social welfare functions.",
                "Journal of Economic Theory, 10:187-217, 1975. [24] W. Vickrey.",
                "Counterspeculation, auctions, and competitive sealed tenders.",
                "Journal of Finance, 16:8-37, 1961. [25] R. V. Vohra.",
                "Research problems in combinatorial auctions.",
                "Mimeo, version Oct. 29, 2001. 141"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        }
    }
}